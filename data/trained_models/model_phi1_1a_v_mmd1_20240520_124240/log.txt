Args:
Namespace(name='model_phi1_1a_v_mmd1', outdir='out/model_training/model_phi1_1a_v_mmd1', training_data='data/training_data/data_phi1_1a/training', validation_data='data/training_data/data_phi1_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3724887960

Training model...

Saving initial model state to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.4240302934997775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.4240302934997775 | validation: 5.062862720247544]
	TIME [epoch: 109 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.907937982196806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.907937982196806 | validation: 4.955055544453627]
	TIME [epoch: 8.43 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.32915314942889		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.32915314942889 | validation: 5.0311536831912544]
	TIME [epoch: 8.27 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.901458612151421		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.901458612151421 | validation: 4.779316588755715]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0207565826770395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.0207565826770395 | validation: 4.544430045910553]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.543592642270403		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.543592642270403 | validation: 3.9859186417991594]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.144474843481912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.144474843481912 | validation: 3.802879343838755]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0346064595761035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0346064595761035 | validation: 3.7637159985156545]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.816569690008614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.816569690008614 | validation: 3.5327384239883832]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.935730073635687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.935730073635687 | validation: 3.648163708421521]
	TIME [epoch: 8.26 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7215795202796587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7215795202796587 | validation: 3.414706175721384]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5630314861955332		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5630314861955332 | validation: 3.3574154161289833]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.512141436097903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.512141436097903 | validation: 3.114991057358443]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.195576544807626		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.195576544807626 | validation: 2.887253159953299]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4058867319933452		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4058867319933452 | validation: 2.9390356747779887]
	TIME [epoch: 8.29 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1526794371788		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1526794371788 | validation: 2.7920232152610946]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9799007458609827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9799007458609827 | validation: 2.6092886103329693]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8431229514478848		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8431229514478848 | validation: 2.859481070773362]
	TIME [epoch: 8.27 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7697985058342147		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7697985058342147 | validation: 2.497539423478785]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.727186411458658		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.727186411458658 | validation: 2.4060688834464554]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5358843406257574		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5358843406257574 | validation: 2.4197977556298977]
	TIME [epoch: 8.24 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6630721958332146		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6630721958332146 | validation: 2.205440182174521]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4544052667124552		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4544052667124552 | validation: 2.4618711526395924]
	TIME [epoch: 8.29 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5918071403395921		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5918071403395921 | validation: 2.242373876525511]
	TIME [epoch: 8.24 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4989053439497153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4989053439497153 | validation: 2.251332744377047]
	TIME [epoch: 8.25 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4352813748532132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4352813748532132 | validation: 2.223986432892327]
	TIME [epoch: 8.25 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.511516805063733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.511516805063733 | validation: 2.1471699078291038]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5271268379821867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5271268379821867 | validation: 2.1306640613786128]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.484968823802636		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.484968823802636 | validation: 2.1542298395855495]
	TIME [epoch: 8.29 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3387068484486249		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3387068484486249 | validation: 2.1441306657408776]
	TIME [epoch: 8.27 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3226021438221751		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3226021438221751 | validation: 2.050087242238387]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3960329192281646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3960329192281646 | validation: 2.1774267405183023]
	TIME [epoch: 8.27 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2876339883532018		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2876339883532018 | validation: 2.108828000321848]
	TIME [epoch: 8.28 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5101380110201548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5101380110201548 | validation: 1.933596799529215]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.268959862334069		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.268959862334069 | validation: 2.113120064268871]
	TIME [epoch: 8.26 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.371461000267478		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.371461000267478 | validation: 1.7350785581798465]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1596231708540965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1596231708540965 | validation: 1.4473794287664985]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.36184911357992		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.36184911357992 | validation: 1.5144445321117446]
	TIME [epoch: 8.25 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9551994837275184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9551994837275184 | validation: 1.135595964931234]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.868965246822087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.868965246822087 | validation: 1.473709011492916]
	TIME [epoch: 8.25 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8881163363126094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8881163363126094 | validation: 0.5690724122725199]
	TIME [epoch: 8.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6489532178392096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6489532178392096 | validation: 0.8788265293668143]
	TIME [epoch: 8.25 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6198192135414144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6198192135414144 | validation: 0.6685915142767137]
	TIME [epoch: 8.26 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5368940051853347		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5368940051853347 | validation: 0.8964955184092676]
	TIME [epoch: 8.27 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6496016471604444		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6496016471604444 | validation: 0.5934116532739505]
	TIME [epoch: 8.29 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4031754984458933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4031754984458933 | validation: 0.3940358959688275]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.628769898084196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.628769898084196 | validation: 1.0010671460123954]
	TIME [epoch: 8.25 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.68678834733407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.68678834733407 | validation: 0.4042130758453878]
	TIME [epoch: 8.25 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45807519917067707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45807519917067707 | validation: 0.48805718328923875]
	TIME [epoch: 8.25 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3898062979272845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3898062979272845 | validation: 0.43349330887576754]
	TIME [epoch: 8.28 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35570368643532324		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 0.35570368643532324 | validation: 0.4839097939157383]
	TIME [epoch: 8.26 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5473932340365492		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 0.5473932340365492 | validation: 0.6714998351717036]
	TIME [epoch: 8.25 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5021764948839664		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.5021764948839664 | validation: 0.3850669236514945]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31281279353794816		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 0.31281279353794816 | validation: 0.33315344119439155]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4818020681557946		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.4818020681557946 | validation: 0.3789691688034825]
	TIME [epoch: 8.27 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45156046752391404		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 0.45156046752391404 | validation: 0.3799696664573097]
	TIME [epoch: 8.29 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2819138120807683		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 0.2819138120807683 | validation: 0.2953409150333565]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4625122715534026		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 0.4625122715534026 | validation: 0.5295888652647968]
	TIME [epoch: 8.25 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3538043009944327		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 0.3538043009944327 | validation: 0.27147698747395654]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36289599453846155		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.36289599453846155 | validation: 0.44737609589630295]
	TIME [epoch: 8.25 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3807818402459405		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 0.3807818402459405 | validation: 0.33570330505840607]
	TIME [epoch: 8.29 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4411914302916399		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.4411914302916399 | validation: 0.5417290340831988]
	TIME [epoch: 8.25 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3434161938078539		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 0.3434161938078539 | validation: 0.24181130768110579]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3267725376802314		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 0.3267725376802314 | validation: 0.29289453768326523]
	TIME [epoch: 8.35 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40078691940884287		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.40078691940884287 | validation: 0.26000369021707515]
	TIME [epoch: 8.24 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2628698591691347		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 0.2628698591691347 | validation: 0.4774705343757448]
	TIME [epoch: 8.26 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33358807941145274		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 0.33358807941145274 | validation: 0.2800894562860472]
	TIME [epoch: 8.27 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2267647174215992		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 0.2267647174215992 | validation: 0.20252142968569115]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2518621836502381		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 0.2518621836502381 | validation: 0.3509278168434349]
	TIME [epoch: 8.35 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42293092359103623		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.42293092359103623 | validation: 0.6401536004853654]
	TIME [epoch: 8.25 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41871747342772636		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.41871747342772636 | validation: 0.4450401012644914]
	TIME [epoch: 8.25 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3860933169365818		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 0.3860933169365818 | validation: 0.600314664613331]
	TIME [epoch: 8.3 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4311432396590422		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 0.4311432396590422 | validation: 0.26413233199100694]
	TIME [epoch: 8.25 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2372394227898346		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 0.2372394227898346 | validation: 0.21467106990755708]
	TIME [epoch: 8.3 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24515180997768982		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.24515180997768982 | validation: 0.5723143266542402]
	TIME [epoch: 8.36 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4217524928786439		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 0.4217524928786439 | validation: 0.2927112235811392]
	TIME [epoch: 8.36 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32352501905084363		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 0.32352501905084363 | validation: 0.336874063388816]
	TIME [epoch: 8.26 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3205594060260557		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 0.3205594060260557 | validation: 0.28330665838387425]
	TIME [epoch: 8.29 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36311677075729587		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 0.36311677075729587 | validation: 0.2572282927746303]
	TIME [epoch: 8.25 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21140058309729323		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.21140058309729323 | validation: 0.3084543054558759]
	TIME [epoch: 8.31 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29326793125456097		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.29326793125456097 | validation: 0.2220009567871148]
	TIME [epoch: 8.33 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20298081324443706		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 0.20298081324443706 | validation: 0.21612644121065805]
	TIME [epoch: 8.32 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3494481396369027		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 0.3494481396369027 | validation: 0.4211572236571206]
	TIME [epoch: 8.3 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40514222747883355		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.40514222747883355 | validation: 0.3224663769931261]
	TIME [epoch: 8.32 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25392261627538143		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.25392261627538143 | validation: 0.17589713583069672]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19654727441900627		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.19654727441900627 | validation: 0.2474424180557059]
	TIME [epoch: 8.36 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2711372712342647		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.2711372712342647 | validation: 0.2625523790602696]
	TIME [epoch: 8.25 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22102002898409845		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 0.22102002898409845 | validation: 0.31334845066003886]
	TIME [epoch: 8.25 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29012336692274737		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.29012336692274737 | validation: 0.15297970481203554]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27964189395536304		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.27964189395536304 | validation: 0.33602200575178975]
	TIME [epoch: 8.24 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25426535751577584		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.25426535751577584 | validation: 0.23552147630332293]
	TIME [epoch: 8.24 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30193663827732153		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.30193663827732153 | validation: 0.24500092022362463]
	TIME [epoch: 8.25 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25069182517289834		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 0.25069182517289834 | validation: 0.18292165137212865]
	TIME [epoch: 8.24 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17384028822413344		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.17384028822413344 | validation: 0.33741995818735415]
	TIME [epoch: 8.28 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2761992983502025		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.2761992983502025 | validation: 0.34686452279077096]
	TIME [epoch: 8.27 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.276299964918315		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.276299964918315 | validation: 0.17710278331598583]
	TIME [epoch: 8.25 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19022849396192476		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.19022849396192476 | validation: 0.28812308477457127]
	TIME [epoch: 8.25 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36043871311258635		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.36043871311258635 | validation: 0.13801442264085667]
	TIME [epoch: 8.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1506554293037034		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.1506554293037034 | validation: 0.18556770068477602]
	TIME [epoch: 8.27 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27065567483461994		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.27065567483461994 | validation: 0.22587811018279197]
	TIME [epoch: 8.31 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21465642926791223		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.21465642926791223 | validation: 0.3035663732406667]
	TIME [epoch: 8.27 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2771811955649638		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.2771811955649638 | validation: 0.2698594413815235]
	TIME [epoch: 8.26 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2582615239222772		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.2582615239222772 | validation: 0.19876618363880838]
	TIME [epoch: 8.26 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16430795476703533		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.16430795476703533 | validation: 0.21574638652915307]
	TIME [epoch: 8.26 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19649297107544367		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.19649297107544367 | validation: 0.15214047062725006]
	TIME [epoch: 8.26 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2893036721027589		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.2893036721027589 | validation: 0.29351347362698665]
	TIME [epoch: 8.3 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23851172893785297		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.23851172893785297 | validation: 0.1855652976366456]
	TIME [epoch: 8.26 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20880477312520423		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.20880477312520423 | validation: 0.20326959903518238]
	TIME [epoch: 8.27 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2201829898618619		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.2201829898618619 | validation: 0.12764607344594558]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19821366953048009		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.19821366953048009 | validation: 0.32852559541778836]
	TIME [epoch: 8.26 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21862273751668854		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.21862273751668854 | validation: 0.6524148630577605]
	TIME [epoch: 8.29 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2893824263944065		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.2893824263944065 | validation: 0.1545585835953305]
	TIME [epoch: 8.26 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1778706727714593		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.1778706727714593 | validation: 0.2237677442048375]
	TIME [epoch: 8.26 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17492863411813905		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.17492863411813905 | validation: 0.11814756928622153]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_114.pth
	Model improved!!!
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1956175897906065		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.1956175897906065 | validation: 0.2164331902985373]
	TIME [epoch: 8.36 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16789548894133716		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.16789548894133716 | validation: 0.15684453538599458]
	TIME [epoch: 8.31 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32707802419200926		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.32707802419200926 | validation: 0.483593269835756]
	TIME [epoch: 8.35 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32232742816629767		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.32232742816629767 | validation: 0.14214665809069182]
	TIME [epoch: 8.3 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15158972432657059		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.15158972432657059 | validation: 0.12960178931746685]
	TIME [epoch: 8.25 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18782017870162082		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.18782017870162082 | validation: 0.1828574361823655]
	TIME [epoch: 8.27 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17020759926187076		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.17020759926187076 | validation: 0.10637428434787452]
	TIME [epoch: 8.36 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21131871368177602		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.21131871368177602 | validation: 0.19800801933743228]
	TIME [epoch: 8.48 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2029408319425295		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.2029408319425295 | validation: 0.18436400050713442]
	TIME [epoch: 8.33 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14550998923143327		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.14550998923143327 | validation: 0.11478027162246636]
	TIME [epoch: 8.27 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13397142610272636		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.13397142610272636 | validation: 0.14439212514923166]
	TIME [epoch: 8.3 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16851809573760612		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.16851809573760612 | validation: 0.212027771680879]
	TIME [epoch: 8.32 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2614136825593354		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.2614136825593354 | validation: 0.24666273172677722]
	TIME [epoch: 8.34 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21867753495385364		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.21867753495385364 | validation: 0.1354503928417255]
	TIME [epoch: 8.37 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12112293211151473		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.12112293211151473 | validation: 0.08428843915329379]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_129.pth
	Model improved!!!
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17796263086027087		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.17796263086027087 | validation: 0.1816947555586167]
	TIME [epoch: 8.34 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21072878828572703		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.21072878828572703 | validation: 0.16416507733386537]
	TIME [epoch: 8.24 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15786811921274507		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.15786811921274507 | validation: 0.10289546889489246]
	TIME [epoch: 8.24 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17643114337742288		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.17643114337742288 | validation: 0.18236124592254505]
	TIME [epoch: 8.29 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18394051997959376		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.18394051997959376 | validation: 0.11691794912988442]
	TIME [epoch: 8.26 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1733888219554951		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.1733888219554951 | validation: 0.16690028476065838]
	TIME [epoch: 8.25 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16763535164374255		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.16763535164374255 | validation: 0.1229070743270983]
	TIME [epoch: 8.25 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14033175848394236		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.14033175848394236 | validation: 0.18267680034764516]
	TIME [epoch: 8.25 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2208528313945573		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.2208528313945573 | validation: 0.16045687076635873]
	TIME [epoch: 8.24 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1289130221605366		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.1289130221605366 | validation: 0.11182101822788985]
	TIME [epoch: 8.3 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12935977078973915		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.12935977078973915 | validation: 0.09221279025403852]
	TIME [epoch: 8.25 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14708132534981216		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.14708132534981216 | validation: 0.2824911215476338]
	TIME [epoch: 8.24 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17723496482544085		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.17723496482544085 | validation: 0.2782297548496335]
	TIME [epoch: 8.24 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15753678866532728		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.15753678866532728 | validation: 0.09995323849046128]
	TIME [epoch: 8.25 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1340890651437455		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.1340890651437455 | validation: 0.07489866074493748]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_144.pth
	Model improved!!!
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0969404840352553		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.0969404840352553 | validation: 0.15112454914771156]
	TIME [epoch: 8.3 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1880010306857013		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.1880010306857013 | validation: 0.0967588289951326]
	TIME [epoch: 8.25 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10091485366522517		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.10091485366522517 | validation: 0.0828838050533487]
	TIME [epoch: 8.25 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14074875836750553		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.14074875836750553 | validation: 0.13215212817168895]
	TIME [epoch: 8.25 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17238967976249372		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.17238967976249372 | validation: 0.15877210745127968]
	TIME [epoch: 8.29 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15387799292613047		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.15387799292613047 | validation: 0.07070987100875369]
	TIME [epoch: 8.35 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11361419872400155		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.11361419872400155 | validation: 0.07163391249896092]
	TIME [epoch: 8.39 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11703325555101904		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.11703325555101904 | validation: 0.20183815670360367]
	TIME [epoch: 8.33 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16242564598098566		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.16242564598098566 | validation: 0.05231456341310939]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_153.pth
	Model improved!!!
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07413201683965781		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.07413201683965781 | validation: 0.057633528848331506]
	TIME [epoch: 8.35 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13618552941781636		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.13618552941781636 | validation: 0.13455472258912413]
	TIME [epoch: 8.27 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.172592250130936		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.172592250130936 | validation: 0.0993323402597309]
	TIME [epoch: 8.35 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10751151671867726		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.10751151671867726 | validation: 0.4358595133168275]
	TIME [epoch: 8.38 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.365315638933977		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.365315638933977 | validation: 0.3286344189759026]
	TIME [epoch: 8.33 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2561592844803837		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.2561592844803837 | validation: 0.30767694202547996]
	TIME [epoch: 8.25 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2387631867898668		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.2387631867898668 | validation: 0.3041494047400745]
	TIME [epoch: 8.28 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.256557845597165		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.256557845597165 | validation: 0.3104105632044995]
	TIME [epoch: 8.37 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23422237956392825		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.23422237956392825 | validation: 0.29354055570735815]
	TIME [epoch: 8.32 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2560817021265688		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.2560817021265688 | validation: 0.22793678436273312]
	TIME [epoch: 8.26 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21120204977391616		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.21120204977391616 | validation: 0.21474998808442594]
	TIME [epoch: 8.25 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16564556688690982		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.16564556688690982 | validation: 0.14627593950906728]
	TIME [epoch: 8.25 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15268041719767192		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.15268041719767192 | validation: 0.10087146369182406]
	TIME [epoch: 8.26 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09375416317038153		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.09375416317038153 | validation: 0.08813727542700583]
	TIME [epoch: 8.29 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11890175601681138		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.11890175601681138 | validation: 0.04857315047922195]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_168.pth
	Model improved!!!
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09842119604947283		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.09842119604947283 | validation: 0.12543638855037387]
	TIME [epoch: 8.34 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1410332653598597		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.1410332653598597 | validation: 0.05856825535753274]
	TIME [epoch: 8.25 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08745622093538205		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.08745622093538205 | validation: 0.05016819291173071]
	TIME [epoch: 8.25 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07559116177498412		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.07559116177498412 | validation: 0.07045278264102975]
	TIME [epoch: 8.29 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12268824167687829		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.12268824167687829 | validation: 0.08506342962156953]
	TIME [epoch: 8.26 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08329227682954622		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.08329227682954622 | validation: 0.10647611634691229]
	TIME [epoch: 8.25 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11099219964915365		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.11099219964915365 | validation: 0.06711239347637138]
	TIME [epoch: 8.25 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07975934593628188		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.07975934593628188 | validation: 0.07255280277167311]
	TIME [epoch: 8.25 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12110928897186474		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.12110928897186474 | validation: 0.16920725727720048]
	TIME [epoch: 8.26 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11735664478942388		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.11735664478942388 | validation: 0.04008235355276886]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_178.pth
	Model improved!!!
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06306764319396865		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.06306764319396865 | validation: 0.10654979598418644]
	TIME [epoch: 8.24 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12465590091664952		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.12465590091664952 | validation: 0.06512236501526332]
	TIME [epoch: 8.24 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09795504340207353		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.09795504340207353 | validation: 0.10242608494315433]
	TIME [epoch: 8.25 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07896976970864407		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.07896976970864407 | validation: 0.10759919242093177]
	TIME [epoch: 8.25 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0948726630827021		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.0948726630827021 | validation: 0.4701887139841222]
	TIME [epoch: 8.28 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44309505978700175		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.44309505978700175 | validation: 0.3027861088743277]
	TIME [epoch: 8.26 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22869592900219415		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.22869592900219415 | validation: 0.21427614645664064]
	TIME [epoch: 8.24 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16871050132473148		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.16871050132473148 | validation: 0.1853607304913554]
	TIME [epoch: 8.24 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13641282917011172		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.13641282917011172 | validation: 0.09481558867819666]
	TIME [epoch: 8.24 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07788444345855723		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.07788444345855723 | validation: 0.051550934392162545]
	TIME [epoch: 8.25 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06536470275396572		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.06536470275396572 | validation: 0.10883962805051772]
	TIME [epoch: 8.28 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1077645625593037		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.1077645625593037 | validation: 0.16130338264015215]
	TIME [epoch: 8.25 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12054964388644945		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.12054964388644945 | validation: 0.0669019026838578]
	TIME [epoch: 8.24 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06019865151300239		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.06019865151300239 | validation: 0.042289885198640714]
	TIME [epoch: 8.24 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06974064753501533		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.06974064753501533 | validation: 0.042930618612027724]
	TIME [epoch: 8.24 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07239441906284917		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.07239441906284917 | validation: 0.08426614784277456]
	TIME [epoch: 8.26 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06853685374959294		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.06853685374959294 | validation: 0.059590891709163596]
	TIME [epoch: 8.28 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08760004843867687		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.08760004843867687 | validation: 0.05876788707694115]
	TIME [epoch: 8.25 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07644958860182736		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.07644958860182736 | validation: 0.029951655864140548]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_197.pth
	Model improved!!!
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04486447599397331		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.04486447599397331 | validation: 0.03647486399183379]
	TIME [epoch: 8.25 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05576931107249654		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.05576931107249654 | validation: 0.042919418666581624]
	TIME [epoch: 8.24 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12104939567113371		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.12104939567113371 | validation: 0.05529264146926066]
	TIME [epoch: 8.28 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08336735020062684		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.08336735020062684 | validation: 0.044788822976523056]
	TIME [epoch: 8.25 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05015241067808703		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.05015241067808703 | validation: 0.039106769464982594]
	TIME [epoch: 8.25 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06473975708012253		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.06473975708012253 | validation: 0.060617301823191166]
	TIME [epoch: 8.25 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05137700434657329		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.05137700434657329 | validation: 0.07282239886452428]
	TIME [epoch: 8.24 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0874005218994222		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.0874005218994222 | validation: 0.04654944760556924]
	TIME [epoch: 8.25 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06562872112971421		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.06562872112971421 | validation: 0.04258508591959077]
	TIME [epoch: 8.29 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0531664199237718		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.0531664199237718 | validation: 0.10507421886782689]
	TIME [epoch: 8.24 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06095794786271505		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.06095794786271505 | validation: 0.023787882282195222]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_208.pth
	Model improved!!!
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04013211295533166		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.04013211295533166 | validation: 0.06076550289969475]
	TIME [epoch: 8.25 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07135340144596425		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.07135340144596425 | validation: 0.08647581989697029]
	TIME [epoch: 8.25 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06755802211585193		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.06755802211585193 | validation: 0.05932067628634973]
	TIME [epoch: 8.29 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06376555721695716		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.06376555721695716 | validation: 0.07545192311816543]
	TIME [epoch: 8.27 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061283278743084695		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.061283278743084695 | validation: 0.03387989569596818]
	TIME [epoch: 8.25 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04242621249723191		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.04242621249723191 | validation: 0.07506636975048206]
	TIME [epoch: 8.25 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11421545418459944		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.11421545418459944 | validation: 0.07173075420951797]
	TIME [epoch: 8.24 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05038240187395697		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.05038240187395697 | validation: 0.022256567715220138]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_216.pth
	Model improved!!!
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03633513608509552		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.03633513608509552 | validation: 0.05270576759480526]
	TIME [epoch: 8.31 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06393127566208244		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.06393127566208244 | validation: 0.06157123099380443]
	TIME [epoch: 8.26 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04344865757971804		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.04344865757971804 | validation: 0.02265094330113298]
	TIME [epoch: 8.26 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0442410765804197		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.0442410765804197 | validation: 0.06780775480960116]
	TIME [epoch: 8.26 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07081789868383807		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.07081789868383807 | validation: 0.03600659018018374]
	TIME [epoch: 8.26 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051361394322128405		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.051361394322128405 | validation: 0.04408834352023353]
	TIME [epoch: 8.3 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04898729938074842		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.04898729938074842 | validation: 0.062051190995105275]
	TIME [epoch: 8.28 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07033437354820704		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.07033437354820704 | validation: 0.0790135877703784]
	TIME [epoch: 8.27 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04474297050199766		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.04474297050199766 | validation: 0.02471571649900723]
	TIME [epoch: 8.27 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06521782645202256		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.06521782645202256 | validation: 0.06471498180421809]
	TIME [epoch: 8.27 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05059238030854071		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.05059238030854071 | validation: 0.11980419379539656]
	TIME [epoch: 8.27 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058283655324798636		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.058283655324798636 | validation: 0.022323452572005312]
	TIME [epoch: 8.31 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04357580028048457		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.04357580028048457 | validation: 0.039833140930676955]
	TIME [epoch: 8.26 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04713599944446199		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.04713599944446199 | validation: 0.04392493037713555]
	TIME [epoch: 8.26 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04028532007647498		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.04028532007647498 | validation: 0.14028665801136275]
	TIME [epoch: 8.26 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09188334023964413		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.09188334023964413 | validation: 0.04873384485364884]
	TIME [epoch: 8.26 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03255098234525839		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.03255098234525839 | validation: 0.03654192439110897]
	TIME [epoch: 8.28 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055270402514389416		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.055270402514389416 | validation: 0.06713794639135733]
	TIME [epoch: 8.3 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040843032806762894		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.040843032806762894 | validation: 0.022933415226065533]
	TIME [epoch: 8.26 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054818533646883126		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.054818533646883126 | validation: 0.041288110919751556]
	TIME [epoch: 8.26 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027986559673811633		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.027986559673811633 | validation: 0.027778375522733177]
	TIME [epoch: 8.26 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041464348500568154		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.041464348500568154 | validation: 0.031125416461491338]
	TIME [epoch: 8.26 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0422808635773534		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.0422808635773534 | validation: 0.06136706879632679]
	TIME [epoch: 8.31 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03909501691767669		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.03909501691767669 | validation: 0.03442288577633897]
	TIME [epoch: 8.27 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052970306482832505		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.052970306482832505 | validation: 0.06702407549127123]
	TIME [epoch: 8.26 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05721145565288062		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.05721145565288062 | validation: 0.025572311373911926]
	TIME [epoch: 8.26 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031211388489691634		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.031211388489691634 | validation: 0.03535098317620007]
	TIME [epoch: 8.26 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04948996793482591		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.04948996793482591 | validation: 0.056666745713503136]
	TIME [epoch: 8.27 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04345148861913955		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.04345148861913955 | validation: 0.02324595140795282]
	TIME [epoch: 8.3 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028738839868455116		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.028738839868455116 | validation: 0.04286460653763267]
	TIME [epoch: 8.27 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08600015072732912		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.08600015072732912 | validation: 0.0403100949988808]
	TIME [epoch: 8.26 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0333733998409717		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.0333733998409717 | validation: 0.028923975367361444]
	TIME [epoch: 8.26 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04813566097218064		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.04813566097218064 | validation: 0.05815443170386795]
	TIME [epoch: 8.26 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035121122228499106		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.035121122228499106 | validation: 0.026510289099932676]
	TIME [epoch: 8.3 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029446875103749194		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.029446875103749194 | validation: 0.04069723277005809]
	TIME [epoch: 8.27 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06302318460496066		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.06302318460496066 | validation: 0.030358169943846935]
	TIME [epoch: 8.26 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032865518566167935		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.032865518566167935 | validation: 0.014838929471467721]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_253.pth
	Model improved!!!
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025014821554835233		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.025014821554835233 | validation: 0.037944013356755416]
	TIME [epoch: 8.26 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04523040873646494		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.04523040873646494 | validation: 0.04423798557343138]
	TIME [epoch: 8.25 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039627284455547244		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.039627284455547244 | validation: 0.024714944634688665]
	TIME [epoch: 8.31 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02895984833776996		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.02895984833776996 | validation: 0.032411112854848836]
	TIME [epoch: 8.25 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035895215861313334		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.035895215861313334 | validation: 0.027260459505352524]
	TIME [epoch: 8.24 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02657522447065022		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.02657522447065022 | validation: 0.028397590336059316]
	TIME [epoch: 8.25 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05052836679949309		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.05052836679949309 | validation: 0.03744630343758877]
	TIME [epoch: 8.26 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03269704678055229		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.03269704678055229 | validation: 0.022890057889150533]
	TIME [epoch: 8.27 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05184330262283886		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.05184330262283886 | validation: 0.06137176291950234]
	TIME [epoch: 8.29 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03729122574659855		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.03729122574659855 | validation: 0.029119360720794938]
	TIME [epoch: 8.25 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05879842649217097		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.05879842649217097 | validation: 0.09853000294633373]
	TIME [epoch: 8.25 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07824182356775797		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.07824182356775797 | validation: 0.05080209618258436]
	TIME [epoch: 8.25 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03792376128304119		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.03792376128304119 | validation: 0.024976060944063364]
	TIME [epoch: 8.25 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03054903396991605		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.03054903396991605 | validation: 0.02779048260151194]
	TIME [epoch: 8.3 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024074928860470236		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.024074928860470236 | validation: 0.0269268536219359]
	TIME [epoch: 8.26 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035019048570894766		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.035019048570894766 | validation: 0.02429845899600227]
	TIME [epoch: 8.25 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030969240830624214		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.030969240830624214 | validation: 0.03734906045312435]
	TIME [epoch: 8.25 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04000843438335328		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.04000843438335328 | validation: 0.021598509763658992]
	TIME [epoch: 8.25 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036346390121292774		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.036346390121292774 | validation: 0.05227107423286891]
	TIME [epoch: 8.26 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04202102822934578		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.04202102822934578 | validation: 0.01587986379957771]
	TIME [epoch: 8.29 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018618795214844146		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.018618795214844146 | validation: 0.018043827485841428]
	TIME [epoch: 8.25 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025306041701584653		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.025306041701584653 | validation: 0.039448953876913564]
	TIME [epoch: 8.25 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039088658633319284		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.039088658633319284 | validation: 0.032862524905759576]
	TIME [epoch: 8.26 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03257342615584773		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.03257342615584773 | validation: 0.018754201076077066]
	TIME [epoch: 8.25 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01706548125682434		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.01706548125682434 | validation: 0.030225210028405253]
	TIME [epoch: 8.3 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03216043278772645		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.03216043278772645 | validation: 0.059555654956501045]
	TIME [epoch: 8.25 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041474365677655715		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.041474365677655715 | validation: 0.05614261820430996]
	TIME [epoch: 8.26 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04564744067029221		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.04564744067029221 | validation: 0.013871102053121767]
	TIME [epoch: 8.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_281.pth
	Model improved!!!
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025231358062330837		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.025231358062330837 | validation: 0.015889523163479167]
	TIME [epoch: 8.26 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022322569874068672		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.022322569874068672 | validation: 0.019633705626346226]
	TIME [epoch: 8.25 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04096786533110603		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.04096786533110603 | validation: 0.06072276242307609]
	TIME [epoch: 8.3 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03621060921571376		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.03621060921571376 | validation: 0.012510542098153575]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_285.pth
	Model improved!!!
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016159201641649867		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.016159201641649867 | validation: 0.025145276707238345]
	TIME [epoch: 8.25 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02881901263337885		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.02881901263337885 | validation: 0.06574790766809244]
	TIME [epoch: 8.25 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05310389490135166		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.05310389490135166 | validation: 0.05418071791889366]
	TIME [epoch: 8.25 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027713509116535397		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.027713509116535397 | validation: 0.02096396662054471]
	TIME [epoch: 8.27 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022371187132579625		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.022371187132579625 | validation: 0.03089298409382552]
	TIME [epoch: 8.27 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02607930055569467		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.02607930055569467 | validation: 0.01519768715761817]
	TIME [epoch: 8.25 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05257823293521127		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.05257823293521127 | validation: 0.021139201285023737]
	TIME [epoch: 8.25 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018191557404112643		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.018191557404112643 | validation: 0.010894807821840186]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_293.pth
	Model improved!!!
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0212509023102933		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.0212509023102933 | validation: 0.018632232632058168]
	TIME [epoch: 8.24 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025390152620890685		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.025390152620890685 | validation: 0.05100959921922402]
	TIME [epoch: 8.31 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037185040799620955		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.037185040799620955 | validation: 0.025862311841967835]
	TIME [epoch: 8.25 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020696931371697237		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.020696931371697237 | validation: 0.017837350585855786]
	TIME [epoch: 8.24 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0219413576854627		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.0219413576854627 | validation: 0.026981162274315976]
	TIME [epoch: 8.24 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028159034395577622		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.028159034395577622 | validation: 0.020490951592641277]
	TIME [epoch: 8.24 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01735209722329666		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.01735209722329666 | validation: 0.018373800187955196]
	TIME [epoch: 8.27 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024662517399827624		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.024662517399827624 | validation: 0.037809982273687176]
	TIME [epoch: 8.28 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04692787178735502		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.04692787178735502 | validation: 0.014554069582284484]
	TIME [epoch: 8.24 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017077856263196085		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.017077856263196085 | validation: 0.015934095646665786]
	TIME [epoch: 8.25 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01455475618047888		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.01455475618047888 | validation: 0.018184458695933055]
	TIME [epoch: 8.25 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030341894812975046		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.030341894812975046 | validation: 0.00988190987539649]
	TIME [epoch: 8.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_305.pth
	Model improved!!!
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025319647598326875		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.025319647598326875 | validation: 0.04711959033141906]
	TIME [epoch: 8.29 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046817521579188566		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.046817521579188566 | validation: 0.015761342583354623]
	TIME [epoch: 8.26 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014529904183281995		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.014529904183281995 | validation: 0.014903178689160444]
	TIME [epoch: 8.25 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01742094067687592		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.01742094067687592 | validation: 0.017224563839627668]
	TIME [epoch: 8.25 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020276488086665476		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.020276488086665476 | validation: 0.04134867898875462]
	TIME [epoch: 8.25 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035941236857575255		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.035941236857575255 | validation: 0.03832009219716905]
	TIME [epoch: 8.26 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020052085871631813		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.020052085871631813 | validation: 0.020093014885533993]
	TIME [epoch: 8.3 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015704258253625845		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.015704258253625845 | validation: 0.018073552876723638]
	TIME [epoch: 8.26 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03730827937915083		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.03730827937915083 | validation: 0.02301179190143476]
	TIME [epoch: 8.25 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0206563551926103		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.0206563551926103 | validation: 0.01694855120232151]
	TIME [epoch: 8.24 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027545847492535438		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.027545847492535438 | validation: 0.03505032806611746]
	TIME [epoch: 8.25 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06390760503988942		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.06390760503988942 | validation: 0.14577654248188385]
	TIME [epoch: 8.28 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07843572066651476		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.07843572066651476 | validation: 0.03752497468151216]
	TIME [epoch: 8.27 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02044411098015871		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.02044411098015871 | validation: 0.013341069640103908]
	TIME [epoch: 8.24 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012019958945750572		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.012019958945750572 | validation: 0.013939140485074794]
	TIME [epoch: 8.25 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02818390134895018		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.02818390134895018 | validation: 0.0619233108901146]
	TIME [epoch: 8.25 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028014057058102858		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.028014057058102858 | validation: 0.010006084682111291]
	TIME [epoch: 8.26 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011830903638756834		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.011830903638756834 | validation: 0.014363633195611583]
	TIME [epoch: 8.3 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012795893087578027		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.012795893087578027 | validation: 0.010558772062757973]
	TIME [epoch: 8.26 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015119144793432258		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.015119144793432258 | validation: 0.05322452633581259]
	TIME [epoch: 8.26 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04677548410249312		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.04677548410249312 | validation: 0.020026264399042943]
	TIME [epoch: 8.25 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018061832678982252		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.018061832678982252 | validation: 0.010095327777473104]
	TIME [epoch: 8.25 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013924056047961987		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.013924056047961987 | validation: 0.022118403494432858]
	TIME [epoch: 8.28 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02085213403767961		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.02085213403767961 | validation: 0.022541012703213223]
	TIME [epoch: 8.29 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03000445252727008		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.03000445252727008 | validation: 0.020155022479850494]
	TIME [epoch: 8.25 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016763837781133023		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.016763837781133023 | validation: 0.028871883282291257]
	TIME [epoch: 8.25 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028011877689962036		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.028011877689962036 | validation: 0.011859335733039437]
	TIME [epoch: 8.25 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010608213595665508		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.010608213595665508 | validation: 0.011128797268174123]
	TIME [epoch: 8.26 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026369235035131763		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.026369235035131763 | validation: 0.02145790806593507]
	TIME [epoch: 8.3 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01915257960973992		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.01915257960973992 | validation: 0.0770041835849802]
	TIME [epoch: 8.26 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053031895293540667		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.053031895293540667 | validation: 0.013400231645985455]
	TIME [epoch: 8.25 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01465571646891718		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.01465571646891718 | validation: 0.018489751832897187]
	TIME [epoch: 8.25 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020459800898812393		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.020459800898812393 | validation: 0.011951573139519594]
	TIME [epoch: 8.25 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014415089123030708		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.014415089123030708 | validation: 0.010926469832992867]
	TIME [epoch: 8.26 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01926766726960808		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.01926766726960808 | validation: 0.051758420183553096]
	TIME [epoch: 8.3 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029263929193124646		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.029263929193124646 | validation: 0.024849934567990752]
	TIME [epoch: 8.26 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0172500923512788		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.0172500923512788 | validation: 0.01951355200338742]
	TIME [epoch: 8.26 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013443991065449721		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.013443991065449721 | validation: 0.019497734549557114]
	TIME [epoch: 8.25 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02410421049981198		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.02410421049981198 | validation: 0.020160398252082885]
	TIME [epoch: 8.25 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011440923351930159		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.011440923351930159 | validation: 0.009218034315754662]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_345.pth
	Model improved!!!
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019674118427145892		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.019674118427145892 | validation: 0.1538279479442537]
	TIME [epoch: 8.27 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07906906101768918		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.07906906101768918 | validation: 0.030874688715032753]
	TIME [epoch: 8.25 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022373789322655376		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.022373789322655376 | validation: 0.0187470396096158]
	TIME [epoch: 8.25 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011985184775779784		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.011985184775779784 | validation: 0.01944174033734852]
	TIME [epoch: 8.26 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019688959351821914		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.019688959351821914 | validation: 0.0186513199725623]
	TIME [epoch: 8.26 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01255612417079487		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.01255612417079487 | validation: 0.016202736217583107]
	TIME [epoch: 8.29 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021280730936579072		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.021280730936579072 | validation: 0.03324037282683302]
	TIME [epoch: 8.25 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019764117911777426		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.019764117911777426 | validation: 0.01629397589540756]
	TIME [epoch: 8.25 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01705933178522312		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.01705933178522312 | validation: 0.01886141569307448]
	TIME [epoch: 8.25 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021721271014873565		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.021721271014873565 | validation: 0.017892021486420037]
	TIME [epoch: 8.25 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012109773542373232		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.012109773542373232 | validation: 0.008215228472541133]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_356.pth
	Model improved!!!
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07972647454042837		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.07972647454042837 | validation: 0.036085995604293784]
	TIME [epoch: 8.28 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0389308802092386		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.0389308802092386 | validation: 0.019130703463174317]
	TIME [epoch: 8.25 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016374688515955544		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.016374688515955544 | validation: 0.019875377852259898]
	TIME [epoch: 8.25 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01611566814082274		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.01611566814082274 | validation: 0.012849513390549551]
	TIME [epoch: 8.26 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01071795321278263		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.01071795321278263 | validation: 0.021921744714807487]
	TIME [epoch: 8.25 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01784570543774861		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.01784570543774861 | validation: 0.012293028267198717]
	TIME [epoch: 8.31 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01072523058652652		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.01072523058652652 | validation: 0.016566542126425728]
	TIME [epoch: 8.26 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024415250089331406		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.024415250089331406 | validation: 0.010758446299866328]
	TIME [epoch: 8.25 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0086503843807669		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.0086503843807669 | validation: 0.010189958966550994]
	TIME [epoch: 8.25 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016397721868260592		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.016397721868260592 | validation: 0.008356151441812957]
	TIME [epoch: 8.25 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024781071109252303		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.024781071109252303 | validation: 0.0270789724865214]
	TIME [epoch: 8.26 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015656698945988375		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.015656698945988375 | validation: 0.008813459455161193]
	TIME [epoch: 8.29 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00855187292490023		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.00855187292490023 | validation: 0.010165181857688556]
	TIME [epoch: 8.25 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013245463066434798		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.013245463066434798 | validation: 0.019565208415904624]
	TIME [epoch: 8.25 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024011048667304115		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.024011048667304115 | validation: 0.014717276883443148]
	TIME [epoch: 8.25 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00866942672814354		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.00866942672814354 | validation: 0.0134566071511855]
	TIME [epoch: 8.25 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009331682011888148		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.009331682011888148 | validation: 0.016308755787512216]
	TIME [epoch: 8.29 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022588671165061074		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.022588671165061074 | validation: 0.011247869350093122]
	TIME [epoch: 8.26 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01200001553830583		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.01200001553830583 | validation: 0.025464138376471296]
	TIME [epoch: 8.25 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01706782667134915		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.01706782667134915 | validation: 0.019149328389319462]
	TIME [epoch: 8.25 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01630396256385407		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.01630396256385407 | validation: 0.020339645554734692]
	TIME [epoch: 8.24 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012891036695181308		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.012891036695181308 | validation: 0.007582947787457576]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_378.pth
	Model improved!!!
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010469595654831125		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.010469595654831125 | validation: 0.021904958666844575]
	TIME [epoch: 8.3 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022964097539642923		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.022964097539642923 | validation: 0.023964942405716023]
	TIME [epoch: 8.25 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013230355087216063		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.013230355087216063 | validation: 0.007615877488071161]
	TIME [epoch: 8.25 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008108694601765326		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.008108694601765326 | validation: 0.010954728980651222]
	TIME [epoch: 8.25 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023157929201624263		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.023157929201624263 | validation: 0.010308718781844702]
	TIME [epoch: 8.25 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009192797771255768		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.009192797771255768 | validation: 0.00796161402647584]
	TIME [epoch: 8.3 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007279752155029744		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.007279752155029744 | validation: 0.014551147046085752]
	TIME [epoch: 8.27 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018540054861343136		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.018540054861343136 | validation: 0.009793494907639552]
	TIME [epoch: 8.25 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01521984178092145		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.01521984178092145 | validation: 0.018716604153260853]
	TIME [epoch: 8.25 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01777627947713891		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.01777627947713891 | validation: 0.02226941186105752]
	TIME [epoch: 8.25 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017520551720332924		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.017520551720332924 | validation: 0.006717416497363561]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_389.pth
	Model improved!!!
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006869277073673108		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.006869277073673108 | validation: 0.010487536391480161]
	TIME [epoch: 8.31 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01746492475806338		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.01746492475806338 | validation: 0.016712404279628598]
	TIME [epoch: 8.26 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010935129850356298		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.010935129850356298 | validation: 0.01022338552495054]
	TIME [epoch: 8.25 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010185100647434745		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.010185100647434745 | validation: 0.017826525045217985]
	TIME [epoch: 8.25 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019081350657671553		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.019081350657671553 | validation: 0.010302592722327652]
	TIME [epoch: 8.25 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00923165205104858		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.00923165205104858 | validation: 0.011263955988985292]
	TIME [epoch: 8.27 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011968961715576092		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.011968961715576092 | validation: 0.009613104537654786]
	TIME [epoch: 8.29 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011815751715763772		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.011815751715763772 | validation: 0.02800980020099145]
	TIME [epoch: 8.25 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018737173500934633		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.018737173500934633 | validation: 0.01340268773921897]
	TIME [epoch: 8.26 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009788858747863057		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.009788858747863057 | validation: 0.01166580005225678]
	TIME [epoch: 8.26 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0072481221768477145		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.0072481221768477145 | validation: 0.005751282604010318]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_400.pth
	Model improved!!!
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012989109430381455		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.012989109430381455 | validation: 0.011846609197141086]
	TIME [epoch: 8.3 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02267750504171784		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.02267750504171784 | validation: 0.006842941834500787]
	TIME [epoch: 8.26 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008538588040091057		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.008538588040091057 | validation: 0.011322012731657595]
	TIME [epoch: 8.25 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008820328470852446		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.008820328470852446 | validation: 0.00843541168786348]
	TIME [epoch: 8.24 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012661625041641745		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.012661625041641745 | validation: 0.016896811650799592]
	TIME [epoch: 8.25 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010465059519826386		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.010465059519826386 | validation: 0.008076948841655118]
	TIME [epoch: 8.27 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011161862498166922		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.011161862498166922 | validation: 0.015130973076187403]
	TIME [epoch: 8.29 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009509530828688759		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.009509530828688759 | validation: 0.013950946471038273]
	TIME [epoch: 8.25 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02205179362507764		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.02205179362507764 | validation: 0.013384382034594602]
	TIME [epoch: 8.25 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009940777725816159		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.009940777725816159 | validation: 0.007682398491765975]
	TIME [epoch: 8.25 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00814193438173133		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.00814193438173133 | validation: 0.011850361433556167]
	TIME [epoch: 8.25 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009756077964959416		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.009756077964959416 | validation: 0.01549420281614669]
	TIME [epoch: 8.3 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018952943837075124		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.018952943837075124 | validation: 0.012053782233581622]
	TIME [epoch: 8.26 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011213373314877081		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.011213373314877081 | validation: 0.011202317425329105]
	TIME [epoch: 8.25 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008350221552701539		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.008350221552701539 | validation: 0.01631028426498472]
	TIME [epoch: 8.25 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010447350443802609		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.010447350443802609 | validation: 0.007517209148900503]
	TIME [epoch: 8.25 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012433940807969973		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.012433940807969973 | validation: 0.02165551094567286]
	TIME [epoch: 8.25 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01662298556253175		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.01662298556253175 | validation: 0.011635097237290785]
	TIME [epoch: 8.29 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007077052235778992		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.007077052235778992 | validation: 0.010824517043931139]
	TIME [epoch: 8.25 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007769430540146586		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.007769430540146586 | validation: 0.02312767309834869]
	TIME [epoch: 8.25 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015992957604155915		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.015992957604155915 | validation: 0.0094195605887453]
	TIME [epoch: 8.25 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007272222864475942		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.007272222864475942 | validation: 0.016040852567161645]
	TIME [epoch: 8.25 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017435569420914135		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.017435569420914135 | validation: 0.007656570570955265]
	TIME [epoch: 8.29 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00712454554859529		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.00712454554859529 | validation: 0.006626905603374398]
	TIME [epoch: 8.26 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006863366672930226		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.006863366672930226 | validation: 0.007779517308070364]
	TIME [epoch: 8.24 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010320570357961793		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.010320570357961793 | validation: 0.016532784360535]
	TIME [epoch: 8.25 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018391150380534255		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.018391150380534255 | validation: 0.01276472320096177]
	TIME [epoch: 8.25 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00833252134493239		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.00833252134493239 | validation: 0.011457226482997507]
	TIME [epoch: 8.25 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009194415234357614		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.009194415234357614 | validation: 0.008739754199001713]
	TIME [epoch: 8.31 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007344198968480879		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.007344198968480879 | validation: 0.00761344703843597]
	TIME [epoch: 8.25 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010789215318648111		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.010789215318648111 | validation: 0.007981850548095228]
	TIME [epoch: 8.25 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012138180855124792		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.012138180855124792 | validation: 0.03620210336254419]
	TIME [epoch: 8.25 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015521960858963253		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.015521960858963253 | validation: 0.008094215996955397]
	TIME [epoch: 8.25 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005735084502394246		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.005735084502394246 | validation: 0.006426295366268605]
	TIME [epoch: 8.26 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007260057247042765		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.007260057247042765 | validation: 0.01097076045440306]
	TIME [epoch: 8.29 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012298586571143815		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.012298586571143815 | validation: 0.005177854206341098]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_436.pth
	Model improved!!!
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005400032917976592		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.005400032917976592 | validation: 0.004666662938030575]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_437.pth
	Model improved!!!
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01048014974512928		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.01048014974512928 | validation: 0.00751417329059264]
	TIME [epoch: 8.26 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009596528069995561		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.009596528069995561 | validation: 0.03617030456132953]
	TIME [epoch: 8.26 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01683267286971117		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.01683267286971117 | validation: 0.008012814161906478]
	TIME [epoch: 8.3 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007377131705832903		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.007377131705832903 | validation: 0.00937942042056612]
	TIME [epoch: 8.25 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008493240108979441		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.008493240108979441 | validation: 0.01371140472916419]
	TIME [epoch: 8.25 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009602707382285759		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.009602707382285759 | validation: 0.011532138351505189]
	TIME [epoch: 8.25 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01101338477893273		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.01101338477893273 | validation: 0.008333083267654967]
	TIME [epoch: 8.26 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0055298084367911915		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.0055298084367911915 | validation: 0.008928797689826334]
	TIME [epoch: 8.26 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011205171892450152		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.011205171892450152 | validation: 0.013449064533103648]
	TIME [epoch: 8.3 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010335676409446392		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.010335676409446392 | validation: 0.010787210964504461]
	TIME [epoch: 8.25 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006955330859354951		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.006955330859354951 | validation: 0.008071821898292088]
	TIME [epoch: 8.25 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011272149064711006		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.011272149064711006 | validation: 0.009519296169517119]
	TIME [epoch: 8.25 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0076870365647026965		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.0076870365647026965 | validation: 0.005578300166108661]
	TIME [epoch: 8.25 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005639240888403015		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.005639240888403015 | validation: 0.009294542358460271]
	TIME [epoch: 8.29 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0097889192314301		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.0097889192314301 | validation: 0.004927548202605308]
	TIME [epoch: 8.27 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006698048279069776		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.006698048279069776 | validation: 0.02236251885357709]
	TIME [epoch: 8.25 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012090318443558573		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.012090318443558573 | validation: 0.009906461795487898]
	TIME [epoch: 8.25 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01002533594918485		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.01002533594918485 | validation: 0.007588844177456925]
	TIME [epoch: 8.25 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008038413615768496		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.008038413615768496 | validation: 0.018262006359268234]
	TIME [epoch: 8.25 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009148119146767306		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.009148119146767306 | validation: 0.014039558168411168]
	TIME [epoch: 8.29 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008666825334453456		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.008666825334453456 | validation: 0.008130604393247262]
	TIME [epoch: 8.25 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005733568432435922		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.005733568432435922 | validation: 0.004009131230557105]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_459.pth
	Model improved!!!
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01236181425006105		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.01236181425006105 | validation: 0.012944728293825028]
	TIME [epoch: 8.33 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008426081198206821		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.008426081198206821 | validation: 0.0065050733518706785]
	TIME [epoch: 8.24 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004461551366386523		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.004461551366386523 | validation: 0.005496876109977179]
	TIME [epoch: 8.28 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007056176490183735		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.007056176490183735 | validation: 0.008042739184313797]
	TIME [epoch: 8.26 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009831292571823575		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.009831292571823575 | validation: 0.031590008423105914]
	TIME [epoch: 8.24 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016385934471370423		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.016385934471370423 | validation: 0.008472079885707692]
	TIME [epoch: 8.24 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006184077824592959		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.006184077824592959 | validation: 0.006145085608962972]
	TIME [epoch: 8.24 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004162653636963938		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.004162653636963938 | validation: 0.004962937031770913]
	TIME [epoch: 8.25 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006804812667080547		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.006804812667080547 | validation: 0.020918276149896213]
	TIME [epoch: 8.29 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013463138103101275		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.013463138103101275 | validation: 0.008318650214775597]
	TIME [epoch: 8.26 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010159804272644462		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.010159804272644462 | validation: 0.005155330305152781]
	TIME [epoch: 8.3 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004697375582560542		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.004697375582560542 | validation: 0.005466819935088104]
	TIME [epoch: 8.3 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004672090971232083		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.004672090971232083 | validation: 0.010301481668574902]
	TIME [epoch: 8.3 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01140145137911266		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.01140145137911266 | validation: 0.01137706459308193]
	TIME [epoch: 8.32 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0068440907894094455		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.0068440907894094455 | validation: 0.007997248336987459]
	TIME [epoch: 8.33 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005834053365811588		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.005834053365811588 | validation: 0.012603757354914258]
	TIME [epoch: 8.24 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010588778739455825		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.010588778739455825 | validation: 0.006284224501768182]
	TIME [epoch: 8.23 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008556522672272315		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.008556522672272315 | validation: 0.006848727661442593]
	TIME [epoch: 8.24 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004967149552310876		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.004967149552310876 | validation: 0.005658403091774091]
	TIME [epoch: 8.24 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007542672893737686		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.007542672893737686 | validation: 0.017148180336756455]
	TIME [epoch: 8.3 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01113203907578282		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.01113203907578282 | validation: 0.006419196863774072]
	TIME [epoch: 8.31 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006399432708657208		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.006399432708657208 | validation: 0.005548475210384207]
	TIME [epoch: 8.3 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011094369456159905		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.011094369456159905 | validation: 0.008059945534827091]
	TIME [epoch: 8.3 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005787320587903259		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.005787320587903259 | validation: 0.0047326909677995015]
	TIME [epoch: 8.3 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006077166285946993		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.006077166285946993 | validation: 0.0049902368296718316]
	TIME [epoch: 8.29 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004457449993804349		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.004457449993804349 | validation: 0.00798810942300117]
	TIME [epoch: 8.29 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009293351172115114		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.009293351172115114 | validation: 0.009310342205421648]
	TIME [epoch: 8.24 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00924184556968589		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.00924184556968589 | validation: 0.010022820784646159]
	TIME [epoch: 8.24 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007651265164892186		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.007651265164892186 | validation: 0.008422220455163219]
	TIME [epoch: 8.24 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004958609892680446		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.004958609892680446 | validation: 0.007854208031849582]
	TIME [epoch: 8.24 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007482668747006917		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.007482668747006917 | validation: 0.01440140444611607]
	TIME [epoch: 8.28 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008734051641095846		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.008734051641095846 | validation: 0.011038165654527922]
	TIME [epoch: 8.26 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006353198885275165		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.006353198885275165 | validation: 0.007871297340134066]
	TIME [epoch: 8.25 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005704639624605609		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.005704639624605609 | validation: 0.006256954318893509]
	TIME [epoch: 8.25 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00971045985299902		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.00971045985299902 | validation: 0.00962681003318212]
	TIME [epoch: 8.25 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012371281654517167		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.012371281654517167 | validation: 0.005976557377194572]
	TIME [epoch: 8.24 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005507236682118745		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.005507236682118745 | validation: 0.003663241330083355]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_496.pth
	Model improved!!!
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0066245886287482824		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.0066245886287482824 | validation: 0.0058003790693180604]
	TIME [epoch: 8.32 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005613223811582508		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.005613223811582508 | validation: 0.010496622752028851]
	TIME [epoch: 8.3 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005305046740128413		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.005305046740128413 | validation: 0.005461666445853986]
	TIME [epoch: 8.32 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006948811723073541		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.006948811723073541 | validation: 0.008451478504063786]
	TIME [epoch: 8.3 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009705345384412924		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.009705345384412924 | validation: 0.007248852573788914]
	TIME [epoch: 8.31 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005801923296619923		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.005801923296619923 | validation: 0.0032898978196060505]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_502.pth
	Model improved!!!
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004155525534056655		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.004155525534056655 | validation: 0.007139928013884262]
	TIME [epoch: 8.34 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007967003318177249		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.007967003318177249 | validation: 0.02218328086010602]
	TIME [epoch: 8.3 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010421097681800953		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.010421097681800953 | validation: 0.004385953160235839]
	TIME [epoch: 8.31 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00450108304811491		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.00450108304811491 | validation: 0.003757292092937406]
	TIME [epoch: 8.3 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009301737350687178		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.009301737350687178 | validation: 0.007006183769671498]
	TIME [epoch: 8.35 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009681375295295587		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.009681375295295587 | validation: 0.006376053104224448]
	TIME [epoch: 8.26 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004810871826015495		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.004810871826015495 | validation: 0.004916864347406979]
	TIME [epoch: 8.24 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006114445585818522		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.006114445585818522 | validation: 0.006106593003172534]
	TIME [epoch: 8.24 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0071691819490594996		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.0071691819490594996 | validation: 0.009669312134286928]
	TIME [epoch: 8.24 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006936496962257008		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.006936496962257008 | validation: 0.004373298621299654]
	TIME [epoch: 8.26 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004257187309367492		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.004257187309367492 | validation: 0.0071516214831781385]
	TIME [epoch: 8.28 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008800575662541221		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.008800575662541221 | validation: 0.004918210466907865]
	TIME [epoch: 8.25 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0052382636674072015		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.0052382636674072015 | validation: 0.005685308925490596]
	TIME [epoch: 8.25 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007017138567682857		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.007017138567682857 | validation: 0.004966672216962351]
	TIME [epoch: 8.25 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00499632343240377		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.00499632343240377 | validation: 0.004870963018692663]
	TIME [epoch: 8.29 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005080879375758377		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.005080879375758377 | validation: 0.008935408967480931]
	TIME [epoch: 8.33 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0096355537672731		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.0096355537672731 | validation: 0.004939818056932621]
	TIME [epoch: 8.3 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0050908126110844176		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.0050908126110844176 | validation: 0.007389043714475427]
	TIME [epoch: 8.3 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004946462426761747		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.004946462426761747 | validation: 0.00410244275138394]
	TIME [epoch: 8.29 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003227697407172616		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.003227697407172616 | validation: 0.009622047752578945]
	TIME [epoch: 8.26 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011609793980736418		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.011609793980736418 | validation: 0.0049914490840334775]
	TIME [epoch: 8.31 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004496664624450497		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.004496664624450497 | validation: 0.004562954135065045]
	TIME [epoch: 8.35 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004033920830475185		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.004033920830475185 | validation: 0.00561024083208041]
	TIME [epoch: 8.31 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007316683255764081		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.007316683255764081 | validation: 0.00974766120719903]
	TIME [epoch: 8.31 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005885302220431062		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.005885302220431062 | validation: 0.004313324147587389]
	TIME [epoch: 8.28 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00527686027879648		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.00527686027879648 | validation: 0.007762252238350419]
	TIME [epoch: 8.25 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00734264125636609		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.00734264125636609 | validation: 0.009518726238047465]
	TIME [epoch: 8.28 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005158606721069153		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.005158606721069153 | validation: 0.0037184458821879346]
	TIME [epoch: 8.26 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00667721139969545		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.00667721139969545 | validation: 0.006446721135734691]
	TIME [epoch: 8.24 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035310820824763565		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.0035310820824763565 | validation: 0.006099088840342658]
	TIME [epoch: 8.25 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009547932618249795		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.009547932618249795 | validation: 0.007639968529310422]
	TIME [epoch: 8.25 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005224398312486729		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.005224398312486729 | validation: 0.003754231725490674]
	TIME [epoch: 8.25 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004300247056416938		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.004300247056416938 | validation: 0.006393530295373179]
	TIME [epoch: 8.3 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0045942666034683236		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.0045942666034683236 | validation: 0.007880165292306077]
	TIME [epoch: 8.25 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006179820782298014		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.006179820782298014 | validation: 0.006512260721386594]
	TIME [epoch: 8.24 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008038083279060117		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.008038083279060117 | validation: 0.004875878661929869]
	TIME [epoch: 8.24 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005115474426209523		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.005115474426209523 | validation: 0.006256497983191639]
	TIME [epoch: 8.25 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0055770171328355985		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.0055770171328355985 | validation: 0.004766521896579825]
	TIME [epoch: 8.27 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0046907652535181955		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.0046907652535181955 | validation: 0.005406553505758392]
	TIME [epoch: 8.28 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0049953596719068336		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.0049953596719068336 | validation: 0.0059587437248650645]
	TIME [epoch: 8.26 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007598016852617163		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.007598016852617163 | validation: 0.003421876108734751]
	TIME [epoch: 8.32 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005630878840053286		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.005630878840053286 | validation: 0.00907503322852522]
	TIME [epoch: 8.34 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00680894533340082		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.00680894533340082 | validation: 0.005675481403010834]
	TIME [epoch: 8.34 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004562104721011177		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.004562104721011177 | validation: 0.004738476571966698]
	TIME [epoch: 8.29 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00377362355913481		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.00377362355913481 | validation: 0.0074568578165047]
	TIME [epoch: 8.26 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00791556311027623		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.00791556311027623 | validation: 0.013148827150177133]
	TIME [epoch: 8.32 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006765888982234488		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.006765888982234488 | validation: 0.00465267156475385]
	TIME [epoch: 8.3 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033751004414081017		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.0033751004414081017 | validation: 0.006518602567558059]
	TIME [epoch: 8.3 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0063960168676001		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.0063960168676001 | validation: 0.006285541852930321]
	TIME [epoch: 8.31 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004733463412766815		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.004733463412766815 | validation: 0.00798682191011657]
	TIME [epoch: 8.33 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006535173634664454		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.006535173634664454 | validation: 0.0037939361263080937]
	TIME [epoch: 8.24 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004117346393648967		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.004117346393648967 | validation: 0.006146460886269115]
	TIME [epoch: 8.25 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003498354160106887		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.003498354160106887 | validation: 0.00393524552411049]
	TIME [epoch: 8.25 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006126712529626805		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.006126712529626805 | validation: 0.008349788113286264]
	TIME [epoch: 8.26 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0065108285872053934		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.0065108285872053934 | validation: 0.0033339251160272153]
	TIME [epoch: 8.29 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007751012542273145		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.007751012542273145 | validation: 0.00827799546653534]
	TIME [epoch: 8.28 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005133822268741918		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.005133822268741918 | validation: 0.004851145616590429]
	TIME [epoch: 8.31 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005427605406038575		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.005427605406038575 | validation: 0.00909535578868329]
	TIME [epoch: 8.32 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004327321632234426		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.004327321632234426 | validation: 0.0037774315382650345]
	TIME [epoch: 8.32 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038223098742591333		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.0038223098742591333 | validation: 0.016317599291403775]
	TIME [epoch: 8.31 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008369522321676955		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.008369522321676955 | validation: 0.006446832742648413]
	TIME [epoch: 8.34 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00407008046006323		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.00407008046006323 | validation: 0.002504602913142877]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_564.pth
	Model improved!!!
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031737176043797255		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.0031737176043797255 | validation: 0.005936911544907254]
	TIME [epoch: 8.36 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005322450879778073		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.005322450879778073 | validation: 0.0037897963531448257]
	TIME [epoch: 8.25 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006104630136123913		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.006104630136123913 | validation: 0.01322354333231944]
	TIME [epoch: 8.25 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005949982458395371		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.005949982458395371 | validation: 0.0038839324754032113]
	TIME [epoch: 8.29 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004495287795118232		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.004495287795118232 | validation: 0.007870953125040136]
	TIME [epoch: 8.26 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005512833310561493		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.005512833310561493 | validation: 0.004587480662877083]
	TIME [epoch: 8.25 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004947609454384031		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.004947609454384031 | validation: 0.00637476745233416]
	TIME [epoch: 8.25 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004564775372774134		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.004564775372774134 | validation: 0.006529497616178914]
	TIME [epoch: 8.24 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005192599068128538		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.005192599068128538 | validation: 0.013828276036711036]
	TIME [epoch: 8.24 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005319458212324423		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.005319458212324423 | validation: 0.005174047137257418]
	TIME [epoch: 8.28 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005405063997234224		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.005405063997234224 | validation: 0.005245920057811144]
	TIME [epoch: 8.25 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035826396609375862		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.0035826396609375862 | validation: 0.0044308441196291865]
	TIME [epoch: 8.25 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037999259856093207		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.0037999259856093207 | validation: 0.004743362299586487]
	TIME [epoch: 8.24 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006745832737107819		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.006745832737107819 | validation: 0.004105474306582721]
	TIME [epoch: 8.24 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004212195887998751		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.004212195887998751 | validation: 0.004208255866762867]
	TIME [epoch: 8.25 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004686580415919513		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.004686580415919513 | validation: 0.005681749305071895]
	TIME [epoch: 8.29 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005116718540728696		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.005116718540728696 | validation: 0.005698963822256471]
	TIME [epoch: 8.29 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0041068287354265945		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.0041068287354265945 | validation: 0.0025443804802689728]
	TIME [epoch: 8.32 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003183620953850081		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.003183620953850081 | validation: 0.005848965742807825]
	TIME [epoch: 8.3 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00397292204200377		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.00397292204200377 | validation: 0.0098144216561502]
	TIME [epoch: 8.34 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008293594743214425		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.008293594743214425 | validation: 0.0033819029366205715]
	TIME [epoch: 8.36 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003218729871387987		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.003218729871387987 | validation: 0.004747046275365263]
	TIME [epoch: 8.33 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004175419901519703		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.004175419901519703 | validation: 0.0028018424045547644]
	TIME [epoch: 8.28 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026912750366941646		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.0026912750366941646 | validation: 0.0024451280890455084]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_588.pth
	Model improved!!!
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00595911467377214		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.00595911467377214 | validation: 0.004962319688990367]
	TIME [epoch: 8.25 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004916505273332207		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.004916505273332207 | validation: 0.0050070685315695505]
	TIME [epoch: 8.25 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004860574226950585		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.004860574226950585 | validation: 0.004978203676106787]
	TIME [epoch: 8.29 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037826226901970087		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.0037826226901970087 | validation: 0.004173764959386487]
	TIME [epoch: 8.24 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004935838027317757		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.004935838027317757 | validation: 0.006922059728870215]
	TIME [epoch: 8.24 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005612483349439303		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.005612483349439303 | validation: 0.0026571497547004334]
	TIME [epoch: 8.25 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036002609254750092		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.0036002609254750092 | validation: 0.005721216418760188]
	TIME [epoch: 8.24 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006119088639011484		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.006119088639011484 | validation: 0.0058156816188733775]
	TIME [epoch: 8.29 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004131119782347771		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.004131119782347771 | validation: 0.004804117387214812]
	TIME [epoch: 8.27 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003830921315755067		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.003830921315755067 | validation: 0.008278401055441068]
	TIME [epoch: 8.24 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005511099793664754		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.005511099793664754 | validation: 0.004987309582772805]
	TIME [epoch: 8.25 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0043900479290573695		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.0043900479290573695 | validation: 0.004259531154538007]
	TIME [epoch: 8.24 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005311885881923575		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.005311885881923575 | validation: 0.005005283611988164]
	TIME [epoch: 8.24 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003242931489197548		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.003242931489197548 | validation: 0.003596813820522593]
	TIME [epoch: 8.39 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006432540053119056		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.006432540053119056 | validation: 0.003279939376688074]
	TIME [epoch: 8.26 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004802575082488397		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.004802575082488397 | validation: 0.0030446248260373857]
	TIME [epoch: 8.26 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004059794291706799		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.004059794291706799 | validation: 0.003503215854192411]
	TIME [epoch: 8.25 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003124022742385891		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.003124022742385891 | validation: 0.0056161248703525185]
	TIME [epoch: 8.26 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032830115929458155		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.0032830115929458155 | validation: 0.0029280383421262995]
	TIME [epoch: 8.29 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004943894168407402		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.004943894168407402 | validation: 0.0038187756554558384]
	TIME [epoch: 8.29 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003585941238565303		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.003585941238565303 | validation: 0.0053642463223249615]
	TIME [epoch: 8.26 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035049912329667378		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.0035049912329667378 | validation: 0.008064471340172937]
	TIME [epoch: 8.26 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006039307707426479		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.006039307707426479 | validation: 0.006399787071768983]
	TIME [epoch: 8.25 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034658058029418976		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.0034658058029418976 | validation: 0.004337126419017345]
	TIME [epoch: 8.29 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003928809027222927		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.003928809027222927 | validation: 0.004848194850537068]
	TIME [epoch: 8.37 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038380644602969746		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.0038380644602969746 | validation: 0.0029254284245861096]
	TIME [epoch: 8.32 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003391867470638424		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.003391867470638424 | validation: 0.0067304900690798985]
	TIME [epoch: 8.32 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004347517139918503		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.004347517139918503 | validation: 0.002937234976297557]
	TIME [epoch: 8.31 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0065287676753137455		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.0065287676753137455 | validation: 0.006204244754331156]
	TIME [epoch: 8.27 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003953587837660775		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.003953587837660775 | validation: 0.0027329108251565896]
	TIME [epoch: 8.28 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026430588591057737		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.0026430588591057737 | validation: 0.004386154676228449]
	TIME [epoch: 8.29 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003793125154171291		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.003793125154171291 | validation: 0.00553021384558992]
	TIME [epoch: 8.26 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031096207841861245		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.0031096207841861245 | validation: 0.001677628351697968]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_621.pth
	Model improved!!!
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002666922526449141		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.002666922526449141 | validation: 0.004355549101237475]
	TIME [epoch: 8.33 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0047872431401229775		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.0047872431401229775 | validation: 0.0035204488930541426]
	TIME [epoch: 8.25 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030481020425028624		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.0030481020425028624 | validation: 0.003988894838588062]
	TIME [epoch: 8.29 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003133793624478613		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.003133793624478613 | validation: 0.0065262368917288465]
	TIME [epoch: 8.26 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004408071759857126		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.004408071759857126 | validation: 0.00633840798668812]
	TIME [epoch: 8.24 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004450412207084308		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.004450412207084308 | validation: 0.005727824965075321]
	TIME [epoch: 8.24 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035987894617436718		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.0035987894617436718 | validation: 0.0024542625980335563]
	TIME [epoch: 8.25 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002952793519791525		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.002952793519791525 | validation: 0.004200705840181747]
	TIME [epoch: 8.27 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003698314119771184		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.003698314119771184 | validation: 0.005957249559358257]
	TIME [epoch: 8.33 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005105039797381164		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.005105039797381164 | validation: 0.003060078509164404]
	TIME [epoch: 8.3 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030682407887813196		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.0030682407887813196 | validation: 0.0037673928709158746]
	TIME [epoch: 8.35 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037408325793215035		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.0037408325793215035 | validation: 0.0025805131086766952]
	TIME [epoch: 8.26 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024142128851898396		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.0024142128851898396 | validation: 0.003423726629766561]
	TIME [epoch: 8.25 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004877126828284975		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.004877126828284975 | validation: 0.004402501000806007]
	TIME [epoch: 8.29 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003799208878637659		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.003799208878637659 | validation: 0.0022943802158272323]
	TIME [epoch: 8.26 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027158787702952986		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.0027158787702952986 | validation: 0.004528675462200529]
	TIME [epoch: 8.25 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004099712231991505		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.004099712231991505 | validation: 0.004093099087840253]
	TIME [epoch: 8.25 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0064722229183211775		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.0064722229183211775 | validation: 0.009639184359613074]
	TIME [epoch: 8.25 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0039332144535959785		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.0039332144535959785 | validation: 0.004673159913600861]
	TIME [epoch: 8.25 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002908401650530692		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.002908401650530692 | validation: 0.007719305393073302]
	TIME [epoch: 8.3 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005213271483445277		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.005213271483445277 | validation: 0.004668758239066439]
	TIME [epoch: 8.25 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031226810924212655		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.0031226810924212655 | validation: 0.005503847620592636]
	TIME [epoch: 8.24 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002906758170571243		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.002906758170571243 | validation: 0.004145790645408543]
	TIME [epoch: 8.25 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0044848229284408046		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.0044848229284408046 | validation: 0.003967704602900196]
	TIME [epoch: 8.25 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024393350565690194		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.0024393350565690194 | validation: 0.003222186650334396]
	TIME [epoch: 8.27 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003219854930595416		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.003219854930595416 | validation: 0.003929190436456708]
	TIME [epoch: 8.29 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0042619773201732405		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.0042619773201732405 | validation: 0.0035930510759763726]
	TIME [epoch: 8.25 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003689792672510419		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.003689792672510419 | validation: 0.004525422800896693]
	TIME [epoch: 8.26 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035193162025829007		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.0035193162025829007 | validation: 0.0039037819259035347]
	TIME [epoch: 8.26 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024252348565304105		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.0024252348565304105 | validation: 0.002825465674168451]
	TIME [epoch: 8.29 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002773756557054573		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.002773756557054573 | validation: 0.004902246922258907]
	TIME [epoch: 8.35 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030488656126696503		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.0030488656126696503 | validation: 0.0022819821902524194]
	TIME [epoch: 8.31 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030360961045626978		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.0030360961045626978 | validation: 0.0015761791176071415]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_654.pth
	Model improved!!!
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002100372688649749		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.002100372688649749 | validation: 0.005380789777722763]
	TIME [epoch: 8.32 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0050797298263386605		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.0050797298263386605 | validation: 0.0030511702340322777]
	TIME [epoch: 8.25 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025470632015863366		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.0025470632015863366 | validation: 0.00524009932635499]
	TIME [epoch: 8.28 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002119362369733848		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.002119362369733848 | validation: 0.00427652979318611]
	TIME [epoch: 8.36 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029773175673535436		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.0029773175673535436 | validation: 0.0018370130421614208]
	TIME [epoch: 8.36 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024768020096572474		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.0024768020096572474 | validation: 0.0024370911306409474]
	TIME [epoch: 8.31 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026786253338669983		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.0026786253338669983 | validation: 0.005201349565670089]
	TIME [epoch: 8.25 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003243005937288177		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.003243005937288177 | validation: 0.001772873494830388]
	TIME [epoch: 8.25 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004164443647116496		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.004164443647116496 | validation: 0.0024049664409838325]
	TIME [epoch: 8.29 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017825770549026185		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.0017825770549026185 | validation: 0.0017231418088390943]
	TIME [epoch: 8.28 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019818306782336133		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.0019818306782336133 | validation: 0.0043220808824778615]
	TIME [epoch: 8.3 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00535647735303167		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.00535647735303167 | validation: 0.001654140901545743]
	TIME [epoch: 8.31 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002227791851175494		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.002227791851175494 | validation: 0.0033759898495754025]
	TIME [epoch: 8.26 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021009023848837785		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.0021009023848837785 | validation: 0.0023043291489228627]
	TIME [epoch: 8.26 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037663547680557735		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.0037663547680557735 | validation: 0.001883708683011509]
	TIME [epoch: 8.29 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021968038717891224		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.0021968038717891224 | validation: 0.0015513520695744844]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_670.pth
	Model improved!!!
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022892015890189294		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.0022892015890189294 | validation: 0.0019407228625293973]
	TIME [epoch: 8.33 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004006771134760057		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.004006771134760057 | validation: 0.002126039613825717]
	TIME [epoch: 8.24 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023422371346198717		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.0023422371346198717 | validation: 0.002766790852212]
	TIME [epoch: 8.23 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023997499870993637		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.0023997499870993637 | validation: 0.0030238803706272074]
	TIME [epoch: 8.28 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002485895009440357		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.002485895009440357 | validation: 0.0027263273401256505]
	TIME [epoch: 8.26 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0050799451222769		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.0050799451222769 | validation: 0.004559177693317889]
	TIME [epoch: 8.24 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028118220758510527		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.0028118220758510527 | validation: 0.002794368404626167]
	TIME [epoch: 8.24 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003095024765240832		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.003095024765240832 | validation: 0.0030521371535447905]
	TIME [epoch: 8.24 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032674300856919175		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.0032674300856919175 | validation: 0.0035014653327541606]
	TIME [epoch: 8.24 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033082879258961185		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.0033082879258961185 | validation: 0.0018499994692495756]
	TIME [epoch: 8.28 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017765070446823252		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.0017765070446823252 | validation: 0.0023485670662733845]
	TIME [epoch: 8.29 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017470253482430112		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.0017470253482430112 | validation: 0.0014134288460720336]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_682.pth
	Model improved!!!
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035950429037454883		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.0035950429037454883 | validation: 0.0020489385322599433]
	TIME [epoch: 8.3 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019816864392733727		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.0019816864392733727 | validation: 0.004973300739545237]
	TIME [epoch: 8.27 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003140369254153534		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.003140369254153534 | validation: 0.0013676853288708086]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_685.pth
	Model improved!!!
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018007761337450992		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.0018007761337450992 | validation: 0.0036387981383424134]
	TIME [epoch: 8.34 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029157121810454833		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.0029157121810454833 | validation: 0.0042565742938609]
	TIME [epoch: 8.23 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027371385890502162		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.0027371385890502162 | validation: 0.004163746637232692]
	TIME [epoch: 8.23 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004176988979330151		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.004176988979330151 | validation: 0.0035699042412208506]
	TIME [epoch: 8.28 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002233221012039107		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.002233221012039107 | validation: 0.004755361321089061]
	TIME [epoch: 8.29 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037589902564943286		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.0037589902564943286 | validation: 0.0027120923179536245]
	TIME [epoch: 8.31 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002356583050324532		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.002356583050324532 | validation: 0.002137251930754173]
	TIME [epoch: 8.23 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019998904199015517		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.0019998904199015517 | validation: 0.0017147025712360806]
	TIME [epoch: 8.23 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022828278600078213		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.0022828278600078213 | validation: 0.003442703458934271]
	TIME [epoch: 8.24 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032436643315240593		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.0032436643315240593 | validation: 0.0035714912616652866]
	TIME [epoch: 8.23 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021473506002025987		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.0021473506002025987 | validation: 0.002217074816016842]
	TIME [epoch: 8.25 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025502957035316966		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.0025502957035316966 | validation: 0.006758350578810782]
	TIME [epoch: 8.27 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003026279117397602		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.003026279117397602 | validation: 0.004425772350991798]
	TIME [epoch: 8.23 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003585078873039498		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.003585078873039498 | validation: 0.004940321789224626]
	TIME [epoch: 8.23 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027862065457309286		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.0027862065457309286 | validation: 0.0028909582584998876]
	TIME [epoch: 8.23 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002762031510785106		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.002762031510785106 | validation: 0.003048399543463651]
	TIME [epoch: 8.23 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036273464075656063		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.0036273464075656063 | validation: 0.0018333941066652208]
	TIME [epoch: 8.41 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017749363775250103		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.0017749363775250103 | validation: 0.0014338861127174808]
	TIME [epoch: 8.26 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020493261255913314		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.0020493261255913314 | validation: 0.0030584488533598126]
	TIME [epoch: 8.25 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002453399193635052		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.002453399193635052 | validation: 0.0020078449460180893]
	TIME [epoch: 8.28 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019305911487112028		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.0019305911487112028 | validation: 0.0039013262952886704]
	TIME [epoch: 8.26 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030363496785199423		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.0030363496785199423 | validation: 0.0026498472874380186]
	TIME [epoch: 8.31 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020847926549941898		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.0020847926549941898 | validation: 0.0020388947868877115]
	TIME [epoch: 8.37 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020602266783319705		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.0020602266783319705 | validation: 0.0024674003835461564]
	TIME [epoch: 8.29 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031260889393212466		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.0031260889393212466 | validation: 0.006433064615316547]
	TIME [epoch: 8.26 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002507502611807359		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.002507502611807359 | validation: 0.0025894488546325724]
	TIME [epoch: 8.25 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017929418581681341		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.0017929418581681341 | validation: 0.001503523100842708]
	TIME [epoch: 8.26 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021845794898910456		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.0021845794898910456 | validation: 0.0024084607164138]
	TIME [epoch: 8.3 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003278466505826179		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.003278466505826179 | validation: 0.001534474742804097]
	TIME [epoch: 8.27 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021150599675541907		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.0021150599675541907 | validation: 0.00267755431445321]
	TIME [epoch: 8.26 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002301650612388074		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.002301650612388074 | validation: 0.0011997307257725085]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_716.pth
	Model improved!!!
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001375801237240824		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.001375801237240824 | validation: 0.0011957655552417492]
	TIME [epoch: 8.36 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_717.pth
	Model improved!!!
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014179800581655372		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.0014179800581655372 | validation: 0.007604684080300902]
	TIME [epoch: 8.35 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031380626889638058		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.0031380626889638058 | validation: 0.007892493564548608]
	TIME [epoch: 8.29 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029878810896753214		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.0029878810896753214 | validation: 0.0023978607211569075]
	TIME [epoch: 8.29 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002143444351909658		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.002143444351909658 | validation: 0.0016984206686923367]
	TIME [epoch: 8.3 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016645348355630331		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.0016645348355630331 | validation: 0.003217388831534546]
	TIME [epoch: 8.29 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002381386745157283		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.002381386745157283 | validation: 0.0011844076876127145]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_723.pth
	Model improved!!!
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019328112889387171		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.0019328112889387171 | validation: 0.002162615080108359]
	TIME [epoch: 8.39 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002330874200008805		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.002330874200008805 | validation: 0.0033942339003085412]
	TIME [epoch: 8.25 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028761876753248725		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.0028761876753248725 | validation: 0.002897678258198746]
	TIME [epoch: 8.24 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020521700661617903		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.0020521700661617903 | validation: 0.0036204209480108487]
	TIME [epoch: 8.24 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018963526079800064		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.0018963526079800064 | validation: 0.0015593055247068702]
	TIME [epoch: 8.24 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002085451418026279		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.002085451418026279 | validation: 0.0018373753581175096]
	TIME [epoch: 8.28 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024758666407710857		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.0024758666407710857 | validation: 0.006027749942784541]
	TIME [epoch: 8.35 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019729730651680977		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.0019729730651680977 | validation: 0.0015545630817556423]
	TIME [epoch: 8.31 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015779025808676835		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.0015779025808676835 | validation: 0.0021308346270377497]
	TIME [epoch: 8.25 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002087273782376145		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.002087273782376145 | validation: 0.0022320565016963334]
	TIME [epoch: 8.24 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015657760610441997		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.0015657760610441997 | validation: 0.0014381186621866978]
	TIME [epoch: 8.24 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00195465685921682		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.00195465685921682 | validation: 0.0029537533672795097]
	TIME [epoch: 8.29 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003159416719987868		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.003159416719987868 | validation: 0.0029527235412598295]
	TIME [epoch: 8.27 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022650417971389154		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.0022650417971389154 | validation: 0.0017849305233503864]
	TIME [epoch: 8.24 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018419202321878945		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.0018419202321878945 | validation: 0.0017811400749673041]
	TIME [epoch: 8.25 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025080236865165986		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.0025080236865165986 | validation: 0.0032363754744404263]
	TIME [epoch: 8.25 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002438664061587974		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.002438664061587974 | validation: 0.002487431533496566]
	TIME [epoch: 8.25 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012721437506879258		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.0012721437506879258 | validation: 0.001963341065517355]
	TIME [epoch: 8.31 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017616665000769738		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.0017616665000769738 | validation: 0.001785430122923569]
	TIME [epoch: 8.31 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017722889362780981		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.0017722889362780981 | validation: 0.0018298106960429371]
	TIME [epoch: 8.32 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001805263363454615		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.001805263363454615 | validation: 0.0020053212170615693]
	TIME [epoch: 8.32 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019092671593601207		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.0019092671593601207 | validation: 0.0027368458412375444]
	TIME [epoch: 8.3 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022203267420500402		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.0022203267420500402 | validation: 0.007333671884080592]
	TIME [epoch: 8.31 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021037858187538654		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.0021037858187538654 | validation: 0.003378733609343176]
	TIME [epoch: 8.27 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017997189698648005		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.0017997189698648005 | validation: 0.00246698913824655]
	TIME [epoch: 8.24 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025939058297456963		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.0025939058297456963 | validation: 0.0020504890851375528]
	TIME [epoch: 8.24 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015483236175946402		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.0015483236175946402 | validation: 0.0010231097172954807]
	TIME [epoch: 8.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_750.pth
	Model improved!!!
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012261314095751105		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.0012261314095751105 | validation: 0.0013854565382286424]
	TIME [epoch: 8.33 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021998398825144295		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.0021998398825144295 | validation: 0.003452450110898119]
	TIME [epoch: 8.28 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019320329405894737		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.0019320329405894737 | validation: 0.001958678002324081]
	TIME [epoch: 8.24 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002073799739574271		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.002073799739574271 | validation: 0.002438774674284429]
	TIME [epoch: 8.23 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001515513390004888		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.001515513390004888 | validation: 0.0016826245110298636]
	TIME [epoch: 8.24 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016801039158756035		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.0016801039158756035 | validation: 0.004591181165401353]
	TIME [epoch: 8.23 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024217720035528494		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.0024217720035528494 | validation: 0.0018837250404020863]
	TIME [epoch: 8.31 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00129917587189453		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.00129917587189453 | validation: 0.0009424513408126538]
	TIME [epoch: 8.35 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_758.pth
	Model improved!!!
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001958923063965536		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.001958923063965536 | validation: 0.003716864585270566]
	TIME [epoch: 8.34 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016826016369612708		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.0016826016369612708 | validation: 0.0022887206986585734]
	TIME [epoch: 8.23 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002992408059250256		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.002992408059250256 | validation: 0.0023213332523828187]
	TIME [epoch: 8.23 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002259405272632878		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.002259405272632878 | validation: 0.0023451840017165086]
	TIME [epoch: 8.23 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014007818577735775		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.0014007818577735775 | validation: 0.009068418382095284]
	TIME [epoch: 8.27 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024916214838508954		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.0024916214838508954 | validation: 0.0026718952192600212]
	TIME [epoch: 8.26 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015392690324410319		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.0015392690324410319 | validation: 0.002246801894279178]
	TIME [epoch: 8.3 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018783926837238913		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.0018783926837238913 | validation: 0.0007158744231865962]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_766.pth
	Model improved!!!
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018541917049952738		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.0018541917049952738 | validation: 0.0034628596160937494]
	TIME [epoch: 8.31 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021953229542925005		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.0021953229542925005 | validation: 0.0027021046553922876]
	TIME [epoch: 8.25 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002141606548311519		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.002141606548311519 | validation: 0.002213528038528415]
	TIME [epoch: 8.27 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002404272204055324		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.002404272204055324 | validation: 0.0014597744543440412]
	TIME [epoch: 8.23 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015667917742349562		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.0015667917742349562 | validation: 0.001811897823169666]
	TIME [epoch: 8.24 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019368281598505113		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.0019368281598505113 | validation: 0.002613642334370889]
	TIME [epoch: 8.23 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002419853734967627		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.002419853734967627 | validation: 0.002284089939584276]
	TIME [epoch: 8.24 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00161347170142285		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.00161347170142285 | validation: 0.0012044076620951784]
	TIME [epoch: 8.28 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016228263424601153		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.0016228263424601153 | validation: 0.0016657695223353947]
	TIME [epoch: 8.25 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001785629245124852		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.001785629245124852 | validation: 0.0012627844974009434]
	TIME [epoch: 8.24 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013633931652478081		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.0013633931652478081 | validation: 0.001505440399879756]
	TIME [epoch: 8.24 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002063610861406234		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.002063610861406234 | validation: 0.0012753707787368392]
	TIME [epoch: 8.23 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018927556132328695		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.0018927556132328695 | validation: 0.001048476931958601]
	TIME [epoch: 8.23 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012901761125528224		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.0012901761125528224 | validation: 0.001645794904409101]
	TIME [epoch: 8.28 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014478670393043135		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.0014478670393043135 | validation: 0.0021171609017488864]
	TIME [epoch: 8.41 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015696178133483617		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.0015696178133483617 | validation: 0.0010207487454785963]
	TIME [epoch: 8.31 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021764349762558362		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.0021764349762558362 | validation: 0.004416019175079612]
	TIME [epoch: 8.25 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018493827334871628		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.0018493827334871628 | validation: 0.0014129689370908044]
	TIME [epoch: 8.27 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012314845224090623		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.0012314845224090623 | validation: 0.0019210285418952006]
	TIME [epoch: 8.26 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019505466696126822		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.0019505466696126822 | validation: 0.004339850154381675]
	TIME [epoch: 8.27 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002005910414404208		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.002005910414404208 | validation: 0.002475096629797167]
	TIME [epoch: 8.23 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015470240741464374		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.0015470240741464374 | validation: 0.0008675244626116223]
	TIME [epoch: 8.24 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011591583740324055		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.0011591583740324055 | validation: 0.0017994962827132506]
	TIME [epoch: 8.24 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015305730424876188		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.0015305730424876188 | validation: 0.001223825911675047]
	TIME [epoch: 8.24 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002293511990173579		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.002293511990173579 | validation: 0.0015260565064842595]
	TIME [epoch: 8.3 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014257173743313428		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.0014257173743313428 | validation: 0.0021634528430349888]
	TIME [epoch: 8.24 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000986817960867174		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.000986817960867174 | validation: 0.0012529808474528643]
	TIME [epoch: 8.24 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013597324668287068		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.0013597324668287068 | validation: 0.0019284451817106751]
	TIME [epoch: 8.24 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016842029768428428		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.0016842029768428428 | validation: 0.0011814118118176928]
	TIME [epoch: 8.24 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001414033377276012		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.001414033377276012 | validation: 0.0009999506952788702]
	TIME [epoch: 8.28 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015655816084243043		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.0015655816084243043 | validation: 0.002231863527004084]
	TIME [epoch: 8.34 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018459786459996304		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.0018459786459996304 | validation: 0.0017351601784270682]
	TIME [epoch: 8.29 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001161304975317942		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.001161304975317942 | validation: 0.002245034554570656]
	TIME [epoch: 8.23 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023862332558664177		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.0023862332558664177 | validation: 0.0015936691101701434]
	TIME [epoch: 8.23 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015798278436628729		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.0015798278436628729 | validation: 0.0008990852280825275]
	TIME [epoch: 8.24 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012545519325914609		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.0012545519325914609 | validation: 0.001524859111705105]
	TIME [epoch: 8.3 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013054964830186491		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.0013054964830186491 | validation: 0.001420340713320007]
	TIME [epoch: 8.27 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016942773527517697		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.0016942773527517697 | validation: 0.0019358707573980008]
	TIME [epoch: 8.25 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026669890621163965		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.0026669890621163965 | validation: 0.0029645314886678842]
	TIME [epoch: 8.26 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020426721503181496		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.0020426721503181496 | validation: 0.0023288387297261525]
	TIME [epoch: 8.26 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015186875587923547		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.0015186875587923547 | validation: 0.001557016601047244]
	TIME [epoch: 8.26 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015716042161335615		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.0015716042161335615 | validation: 0.0010734063549352442]
	TIME [epoch: 8.35 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012793008447509633		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.0012793008447509633 | validation: 0.0011089472766254715]
	TIME [epoch: 8.32 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010625900138373947		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.0010625900138373947 | validation: 0.0014296856529426617]
	TIME [epoch: 8.32 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016514226341746143		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.0016514226341746143 | validation: 0.000978099860780098]
	TIME [epoch: 8.33 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014118598311008367		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.0014118598311008367 | validation: 0.0012303234456057695]
	TIME [epoch: 8.32 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011770442736556948		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.0011770442736556948 | validation: 0.0015161550721548888]
	TIME [epoch: 8.3 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001563773070545576		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.001563773070545576 | validation: 0.001516407194996604]
	TIME [epoch: 8.27 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011636470530414513		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.0011636470530414513 | validation: 0.0012313452605995315]
	TIME [epoch: 8.25 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013325154382650677		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.0013325154382650677 | validation: 0.0021515584184178815]
	TIME [epoch: 8.25 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001471739387301925		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.001471739387301925 | validation: 0.001436639995775221]
	TIME [epoch: 8.25 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008886205723899074		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.0008886205723899074 | validation: 0.0010019108636386952]
	TIME [epoch: 8.26 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00138708554318455		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.00138708554318455 | validation: 0.0016542060405581056]
	TIME [epoch: 8.31 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013099207995121293		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.0013099207995121293 | validation: 0.0006746824457378464]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_820.pth
	Model improved!!!
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015078846263092169		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.0015078846263092169 | validation: 0.0021177392518146824]
	TIME [epoch: 8.35 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021073337522345987		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.0021073337522345987 | validation: 0.0027193850763830296]
	TIME [epoch: 8.24 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001987320544219631		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.001987320544219631 | validation: 0.0013859620032053669]
	TIME [epoch: 8.25 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015575322387737576		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.0015575322387737576 | validation: 0.0010069105996599666]
	TIME [epoch: 8.27 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008568150387686995		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.0008568150387686995 | validation: 0.0013870465525268605]
	TIME [epoch: 8.27 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001531948027714973		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.001531948027714973 | validation: 0.0013022828632014783]
	TIME [epoch: 8.28 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013795950642334887		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.0013795950642334887 | validation: 0.0009205826207794168]
	TIME [epoch: 8.32 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015564971856936254		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.0015564971856936254 | validation: 0.0014675113139380695]
	TIME [epoch: 8.33 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016273732380816868		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.0016273732380816868 | validation: 0.0022232090948692204]
	TIME [epoch: 8.25 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001141879206292226		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.001141879206292226 | validation: 0.0014679836038405682]
	TIME [epoch: 8.3 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012922117423903607		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.0012922117423903607 | validation: 0.0018735795604673537]
	TIME [epoch: 8.25 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010404803137374985		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.0010404803137374985 | validation: 0.0014171800214904887]
	TIME [epoch: 8.25 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011260471302841208		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.0011260471302841208 | validation: 0.0018567473305533993]
	TIME [epoch: 8.25 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016673969088914903		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.0016673969088914903 | validation: 0.0005980279416047152]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_834.pth
	Model improved!!!
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000701606601707207		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.000701606601707207 | validation: 0.0015550186767384765]
	TIME [epoch: 8.36 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013380341021060867		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.0013380341021060867 | validation: 0.0012526005732452273]
	TIME [epoch: 8.28 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015893403008405492		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.0015893403008405492 | validation: 0.0014661779253628327]
	TIME [epoch: 8.25 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018264869840774055		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.0018264869840774055 | validation: 0.002612248887445972]
	TIME [epoch: 8.25 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014976549098226985		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.0014976549098226985 | validation: 0.000955508746426128]
	TIME [epoch: 8.25 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009057850063884376		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.0009057850063884376 | validation: 0.0015814627266057064]
	TIME [epoch: 8.24 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014222589215779364		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.0014222589215779364 | validation: 0.0017135236205039989]
	TIME [epoch: 8.28 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013385459374528307		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.0013385459374528307 | validation: 0.0014074158746853209]
	TIME [epoch: 8.32 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010919630031523179		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.0010919630031523179 | validation: 0.0018783542556235738]
	TIME [epoch: 8.32 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014667530809675156		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.0014667530809675156 | validation: 0.001773214100323548]
	TIME [epoch: 8.26 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009414440334832578		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.0009414440334832578 | validation: 0.0009093620094079817]
	TIME [epoch: 8.25 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012877425577418936		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.0012877425577418936 | validation: 0.003751448445214793]
	TIME [epoch: 8.25 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001905574888833052		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.001905574888833052 | validation: 0.0005486662158150643]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_847.pth
	Model improved!!!
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00132423756059411		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.00132423756059411 | validation: 0.0008748162706993404]
	TIME [epoch: 8.24 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014229876980532046		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.0014229876980532046 | validation: 0.00166380362769251]
	TIME [epoch: 8.24 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009218579837511991		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.0009218579837511991 | validation: 0.0007180943166274325]
	TIME [epoch: 8.24 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012184749357251644		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.0012184749357251644 | validation: 0.002057724954350087]
	TIME [epoch: 8.24 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012442861977339404		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.0012442861977339404 | validation: 0.0012435352103757308]
	TIME [epoch: 8.29 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001273856318245186		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.001273856318245186 | validation: 0.0008939269248878335]
	TIME [epoch: 8.26 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012701880214410822		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.0012701880214410822 | validation: 0.0019066975674061721]
	TIME [epoch: 8.24 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015155223172532077		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.0015155223172532077 | validation: 0.0010823192040883267]
	TIME [epoch: 8.24 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009298088242523143		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.0009298088242523143 | validation: 0.0013228245760397686]
	TIME [epoch: 8.24 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010605865128685142		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.0010605865128685142 | validation: 0.0008376386293472908]
	TIME [epoch: 8.3 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000856233634336819		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.000856233634336819 | validation: 0.0014483767936562452]
	TIME [epoch: 8.37 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011759033858170069		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.0011759033858170069 | validation: 0.0027620868125355314]
	TIME [epoch: 8.31 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002076617644927038		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.002076617644927038 | validation: 0.0017250062360842089]
	TIME [epoch: 8.32 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016417663996879832		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.0016417663996879832 | validation: 0.00203062243164017]
	TIME [epoch: 8.27 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013391964245636568		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.0013391964245636568 | validation: 0.0012847901949563792]
	TIME [epoch: 8.24 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011376817642696018		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.0011376817642696018 | validation: 0.0016517079504534075]
	TIME [epoch: 8.26 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016369700858886753		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.0016369700858886753 | validation: 0.0014744612293051134]
	TIME [epoch: 8.27 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017712383942022597		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.0017712383942022597 | validation: 0.00141150081477008]
	TIME [epoch: 8.24 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001038798114983933		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.001038798114983933 | validation: 0.001228854766802594]
	TIME [epoch: 8.26 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007573872158683075		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.0007573872158683075 | validation: 0.0010894856095846946]
	TIME [epoch: 8.33 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001112041465818032		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.001112041465818032 | validation: 0.0008102651844945417]
	TIME [epoch: 8.31 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001395758707046441		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.001395758707046441 | validation: 0.002574020609041108]
	TIME [epoch: 8.28 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012979475059364328		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.0012979475059364328 | validation: 0.0006002174294641512]
	TIME [epoch: 8.24 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006790940538647885		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.0006790940538647885 | validation: 0.002705833876108632]
	TIME [epoch: 8.25 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013277221677622181		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.0013277221677622181 | validation: 0.0007799776139989154]
	TIME [epoch: 8.32 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007351759423381637		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.0007351759423381637 | validation: 0.0015696802331389651]
	TIME [epoch: 8.3 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009031015540628112		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.0009031015540628112 | validation: 0.001712862402265741]
	TIME [epoch: 8.32 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013744555106824743		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.0013744555106824743 | validation: 0.0015391796391503263]
	TIME [epoch: 8.36 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010881288047107293		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.0010881288047107293 | validation: 0.0007353115821377347]
	TIME [epoch: 8.24 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010399399216674868		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.0010399399216674868 | validation: 0.0005614064488260428]
	TIME [epoch: 8.24 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012376604954551112		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.0012376604954551112 | validation: 0.00161681707237042]
	TIME [epoch: 8.23 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015051977066436052		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.0015051977066436052 | validation: 0.0006387917710161304]
	TIME [epoch: 8.24 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009157319549082697		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.0009157319549082697 | validation: 0.0007862992064229398]
	TIME [epoch: 8.28 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008821573256874948		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.0008821573256874948 | validation: 0.0018614829789911662]
	TIME [epoch: 8.25 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032362390067500425		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.0032362390067500425 | validation: 0.011509709042607291]
	TIME [epoch: 8.23 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009190668503944267		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.009190668503944267 | validation: 0.0016616954675898014]
	TIME [epoch: 8.24 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018749446339290422		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.0018749446339290422 | validation: 0.0006275999014844285]
	TIME [epoch: 8.23 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008766816115159111		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.0008766816115159111 | validation: 0.0024275788954889388]
	TIME [epoch: 8.24 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009495868946034525		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.0009495868946034525 | validation: 0.0011133009996864072]
	TIME [epoch: 8.28 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007159115956995686		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.0007159115956995686 | validation: 0.001101842205513388]
	TIME [epoch: 8.24 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008723652473293624		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.0008723652473293624 | validation: 0.0010041546385291342]
	TIME [epoch: 8.24 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007965744541908669		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.0007965744541908669 | validation: 0.0012524696595439834]
	TIME [epoch: 8.24 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008906323192245165		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.0008906323192245165 | validation: 0.0037651155867923203]
	TIME [epoch: 8.24 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000906966192325617		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.000906966192325617 | validation: 0.000536153174259515]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_891.pth
	Model improved!!!
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029917115737637303		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.0029917115737637303 | validation: 0.0026327399709885537]
	TIME [epoch: 8.35 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001563733287500323		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.001563733287500323 | validation: 0.0014970135459561663]
	TIME [epoch: 8.23 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000919192885656979		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.000919192885656979 | validation: 0.0003903155550712674]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_894.pth
	Model improved!!!
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007278174702096996		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.0007278174702096996 | validation: 0.0015935983731334496]
	TIME [epoch: 8.3 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007997497320049858		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.0007997497320049858 | validation: 0.0008185103289133027]
	TIME [epoch: 8.23 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000947476889711441		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.000947476889711441 | validation: 0.0007080789336821871]
	TIME [epoch: 8.28 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009440214303880431		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.0009440214303880431 | validation: 0.0013602272421376692]
	TIME [epoch: 8.23 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012386170295373665		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.0012386170295373665 | validation: 0.001968744740390421]
	TIME [epoch: 8.23 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009265662888357258		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.0009265662888357258 | validation: 0.0004981723974122811]
	TIME [epoch: 8.23 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006307570217720433		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.0006307570217720433 | validation: 0.001720041024131092]
	TIME [epoch: 8.23 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013253330071506867		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.0013253330071506867 | validation: 0.0014175083676452064]
	TIME [epoch: 8.28 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002679439620081563		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.002679439620081563 | validation: 0.0021974174835478495]
	TIME [epoch: 8.26 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014734684506080946		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.0014734684506080946 | validation: 0.001990537864618802]
	TIME [epoch: 8.24 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011431993568695145		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.0011431993568695145 | validation: 0.0013416766844294879]
	TIME [epoch: 8.25 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009242314839242796		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.0009242314839242796 | validation: 0.0007942436568362794]
	TIME [epoch: 8.27 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011545333168176265		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.0011545333168176265 | validation: 0.0013677474429699857]
	TIME [epoch: 8.25 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010394745925832011		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.0010394745925832011 | validation: 0.0009383523252732174]
	TIME [epoch: 8.3 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00096266159945997		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.00096266159945997 | validation: 0.002422656133363466]
	TIME [epoch: 8.3 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011129518478326837		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.0011129518478326837 | validation: 0.0008149454555545343]
	TIME [epoch: 8.33 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000547467030068836		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.000547467030068836 | validation: 0.0035555931133922905]
	TIME [epoch: 8.3 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006832481375717179		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.0006832481375717179 | validation: 0.0007800351200984829]
	TIME [epoch: 8.25 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009122445662144368		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.0009122445662144368 | validation: 0.0009169148336867527]
	TIME [epoch: 8.27 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008171918049446878		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.0008171918049446878 | validation: 0.0014683941369717816]
	TIME [epoch: 8.29 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010640039804705997		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.0010640039804705997 | validation: 0.0006475753356616645]
	TIME [epoch: 8.25 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000854071655869705		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.000854071655869705 | validation: 0.0009287882302449644]
	TIME [epoch: 8.25 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000924901147028674		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.000924901147028674 | validation: 0.0006320815268802464]
	TIME [epoch: 8.25 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006148690113708096		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.0006148690113708096 | validation: 0.0014705531823441475]
	TIME [epoch: 8.25 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001341055805031085		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.001341055805031085 | validation: 0.000805160201417169]
	TIME [epoch: 8.3 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006776288584512946		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.0006776288584512946 | validation: 0.0005877802286011073]
	TIME [epoch: 8.26 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000699603394528538		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.000699603394528538 | validation: 0.0013065416110621974]
	TIME [epoch: 8.25 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009875744895010538		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.0009875744895010538 | validation: 0.0010888084657264285]
	TIME [epoch: 8.25 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006951495060217893		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.0006951495060217893 | validation: 0.0002987252906093989]
	TIME [epoch: 8.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_923.pth
	Model improved!!!
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000782594103450887		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.000782594103450887 | validation: 0.0009643539407158048]
	TIME [epoch: 8.34 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000862832457371595		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.000862832457371595 | validation: 0.0018327963709452515]
	TIME [epoch: 8.29 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001027200168620822		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.001027200168620822 | validation: 0.0010248916173142008]
	TIME [epoch: 8.24 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005229578439188849		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.0005229578439188849 | validation: 0.00112967901241261]
	TIME [epoch: 8.24 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012052902476933163		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.0012052902476933163 | validation: 0.004296989582094164]
	TIME [epoch: 8.24 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028434290074084894		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.0028434290074084894 | validation: 0.001387826921259311]
	TIME [epoch: 8.24 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010397713326413811		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.0010397713326413811 | validation: 0.0013777704923004217]
	TIME [epoch: 8.28 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009065950613638538		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.0009065950613638538 | validation: 0.0009050406524378004]
	TIME [epoch: 8.26 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006323206864291893		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.0006323206864291893 | validation: 0.0012969417889572901]
	TIME [epoch: 8.24 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008748063289784405		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.0008748063289784405 | validation: 0.0015078806939459889]
	TIME [epoch: 8.23 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007293846371407964		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.0007293846371407964 | validation: 0.0009323029598759342]
	TIME [epoch: 8.24 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006479672328045672		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.0006479672328045672 | validation: 0.000921512411193925]
	TIME [epoch: 8.24 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010462168611613384		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.0010462168611613384 | validation: 0.0029604978260483633]
	TIME [epoch: 8.29 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017025224441312597		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.0017025224441312597 | validation: 0.001425659051331821]
	TIME [epoch: 8.25 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010281381433469164		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.0010281381433469164 | validation: 0.0010116242166082427]
	TIME [epoch: 8.24 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005883149706749618		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.0005883149706749618 | validation: 0.0006207809107208844]
	TIME [epoch: 8.23 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007869355389845418		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.0007869355389845418 | validation: 0.0005298938727577375]
	TIME [epoch: 8.24 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007963092691591052		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.0007963092691591052 | validation: 0.0014915879527232895]
	TIME [epoch: 8.25 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008585295653463075		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.0008585295653463075 | validation: 0.0006815228999887788]
	TIME [epoch: 8.31 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006873556822826576		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.0006873556822826576 | validation: 0.002221869111122727]
	TIME [epoch: 8.29 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010457067119888338		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.0010457067119888338 | validation: 0.00040166753907126124]
	TIME [epoch: 8.27 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005573073143762364		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.0005573073143762364 | validation: 0.000896065220855257]
	TIME [epoch: 8.24 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007897480210967349		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.0007897480210967349 | validation: 0.0016332453158608641]
	TIME [epoch: 8.27 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009507831110937264		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.0009507831110937264 | validation: 0.0009221165776368201]
	TIME [epoch: 8.35 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009261785323253957		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.0009261785323253957 | validation: 0.0012790169048325915]
	TIME [epoch: 8.31 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001114323626303123		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.001114323626303123 | validation: 0.0010214949958477514]
	TIME [epoch: 8.32 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006793285082847902		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.0006793285082847902 | validation: 0.001192840245937]
	TIME [epoch: 8.3 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007523223534187251		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.0007523223534187251 | validation: 0.0011110885854953593]
	TIME [epoch: 8.24 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000796808816557256		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.000796808816557256 | validation: 0.0009813604726018363]
	TIME [epoch: 8.24 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007168974573106344		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.0007168974573106344 | validation: 0.0005038401995727986]
	TIME [epoch: 8.28 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007281869786679678		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.0007281869786679678 | validation: 0.0010663852070809591]
	TIME [epoch: 8.23 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009149750611154325		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.0009149750611154325 | validation: 0.000897501697239239]
	TIME [epoch: 8.23 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000941925175698749		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.000941925175698749 | validation: 0.0024235621112302904]
	TIME [epoch: 8.24 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008314790155830434		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.0008314790155830434 | validation: 0.0009031936383520005]
	TIME [epoch: 8.23 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007756885353072182		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.0007756885353072182 | validation: 0.0008753030239120117]
	TIME [epoch: 8.27 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006782189429897559		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.0006782189429897559 | validation: 0.0010964856188638015]
	TIME [epoch: 8.25 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001170585988662063		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.001170585988662063 | validation: 0.001384215483382171]
	TIME [epoch: 8.24 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008186222108905014		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.0008186222108905014 | validation: 0.002452100734862157]
	TIME [epoch: 8.23 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010234851356735646		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.0010234851356735646 | validation: 0.0005308604002056061]
	TIME [epoch: 8.23 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000511708507750128		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.000511708507750128 | validation: 0.0001820095741618362]
	TIME [epoch: 8.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_963.pth
	Model improved!!!
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000616576051478565		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.000616576051478565 | validation: 0.000248748654849452]
	TIME [epoch: 8.36 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006885869832881236		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.0006885869832881236 | validation: 0.0008361236835200073]
	TIME [epoch: 8.23 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000640232468323658		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.000640232468323658 | validation: 0.0013684056214099574]
	TIME [epoch: 8.23 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000660845071494502		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.000660845071494502 | validation: 0.0012775097055858975]
	TIME [epoch: 8.23 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007738203997176145		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.0007738203997176145 | validation: 0.000837809098431677]
	TIME [epoch: 8.29 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007068803450278016		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.0007068803450278016 | validation: 0.0004212992925120078]
	TIME [epoch: 8.32 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010430684712410682		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.0010430684712410682 | validation: 0.0006182442880761298]
	TIME [epoch: 8.32 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008791691822116841		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.0008791691822116841 | validation: 0.0015156429851337103]
	TIME [epoch: 8.3 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008357829001424013		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.0008357829001424013 | validation: 0.0014396427571275491]
	TIME [epoch: 8.27 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005575903537017521		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.0005575903537017521 | validation: 0.0008482245654152011]
	TIME [epoch: 8.23 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008046569319891117		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.0008046569319891117 | validation: 0.00044411294642016054]
	TIME [epoch: 8.23 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006500687517976172		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.0006500687517976172 | validation: 0.0010290368798040648]
	TIME [epoch: 8.28 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010411113185609874		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.0010411113185609874 | validation: 0.0007928886509685543]
	TIME [epoch: 8.25 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006598469939807014		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.0006598469939807014 | validation: 0.000346327335119212]
	TIME [epoch: 8.23 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006442507536384214		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.0006442507536384214 | validation: 0.0020205969012762103]
	TIME [epoch: 8.23 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007708403173194114		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.0007708403173194114 | validation: 0.000982113302891306]
	TIME [epoch: 8.24 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006191544607561837		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.0006191544607561837 | validation: 0.0011032840945241578]
	TIME [epoch: 8.24 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010613002056294243		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.0010613002056294243 | validation: 0.0008090882630639254]
	TIME [epoch: 8.28 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006810649709349339		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.0006810649709349339 | validation: 0.0006686642960674165]
	TIME [epoch: 8.23 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009931253996759417		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.0009931253996759417 | validation: 0.00026690589714752734]
	TIME [epoch: 8.24 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005978218219790792		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.0005978218219790792 | validation: 0.000699834836614139]
	TIME [epoch: 8.23 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007457008647028753		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.0007457008647028753 | validation: 0.00187169038789028]
	TIME [epoch: 8.26 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000980715563683125		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.000980715563683125 | validation: 0.0004418663735612674]
	TIME [epoch: 8.36 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005623597124927156		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.0005623597124927156 | validation: 0.0008690273984808759]
	TIME [epoch: 8.33 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006081553031017478		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.0006081553031017478 | validation: 0.00120012539097801]
	TIME [epoch: 8.24 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000659255656203819		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.000659255656203819 | validation: 0.0005431209186229715]
	TIME [epoch: 8.24 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011713897068167975		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.0011713897068167975 | validation: 0.00048764322839652864]
	TIME [epoch: 8.24 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004873438246625903		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.0004873438246625903 | validation: 0.0008680825854350286]
	TIME [epoch: 8.24 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005562559687766464		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.0005562559687766464 | validation: 0.0008061698133872461]
	TIME [epoch: 8.28 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008188193755371089		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.0008188193755371089 | validation: 0.0005582215671397624]
	TIME [epoch: 8.24 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005650848154381765		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.0005650848154381765 | validation: 0.0004230110661279003]
	TIME [epoch: 8.23 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007236452957605655		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.0007236452957605655 | validation: 0.0007789389924121419]
	TIME [epoch: 8.24 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006188775684298393		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.0006188775684298393 | validation: 0.0009459233477824079]
	TIME [epoch: 8.23 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006957113504115645		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.0006957113504115645 | validation: 0.0014384579144101099]
	TIME [epoch: 8.25 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007914597079312275		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.0007914597079312275 | validation: 0.0005676287438953782]
	TIME [epoch: 8.27 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005424647336160154		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.0005424647336160154 | validation: 0.0010701586595040001]
	TIME [epoch: 8.23 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006998310592455112		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.0006998310592455112 | validation: 0.0006532132310355277]
	TIME [epoch: 8.24 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006400268506304594		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.0006400268506304594 | validation: 0.0006061522709584102]
	TIME [epoch: 8.23 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004735546804249607		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.0004735546804249607 | validation: 0.0006227561295874509]
	TIME [epoch: 8.31 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010918436476041416		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.0010918436476041416 | validation: 0.001674720528883383]
	TIME [epoch: 8.29 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010072103144712725		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.0010072103144712725 | validation: 0.001944291189521576]
	TIME [epoch: 8.23 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005716397339756487		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.0005716397339756487 | validation: 0.0011943671644848682]
	TIME [epoch: 8.23 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006242166432964549		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.0006242166432964549 | validation: 0.0007753628437552581]
	TIME [epoch: 8.24 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005721460476588471		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.0005721460476588471 | validation: 0.0014845807972481344]
	TIME [epoch: 8.23 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006062726998642305		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.0006062726998642305 | validation: 0.00028111437603518135]
	TIME [epoch: 8.25 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005813946284260037		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.0005813946284260037 | validation: 0.0007150813032398036]
	TIME [epoch: 8.27 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009647097513980303		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.0009647097513980303 | validation: 0.0008507870881521412]
	TIME [epoch: 8.23 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006201051722486448		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.0006201051722486448 | validation: 0.000823106028830055]
	TIME [epoch: 8.23 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006994008484112711		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.0006994008484112711 | validation: 8.507109382093247e-05]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_1012.pth
	Model improved!!!
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007104693733300853		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.0007104693733300853 | validation: 0.0005077339162221444]
	TIME [epoch: 8.31 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005988721407385778		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.0005988721407385778 | validation: 0.0006256704906740015]
	TIME [epoch: 8.28 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003774272700695649		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.0003774272700695649 | validation: 0.000595310606489126]
	TIME [epoch: 8.25 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008044136895014155		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.0008044136895014155 | validation: 0.000283727879216487]
	TIME [epoch: 8.23 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007335635571964347		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.0007335635571964347 | validation: 0.00040820609559910897]
	TIME [epoch: 8.23 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006700143195129385		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.0006700143195129385 | validation: 0.0008360503222028628]
	TIME [epoch: 8.24 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005857248644727777		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.0005857248644727777 | validation: 0.0012020878292257687]
	TIME [epoch: 8.24 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006410973535409231		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.0006410973535409231 | validation: 0.002864692520243079]
	TIME [epoch: 8.28 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011462720913769213		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.0011462720913769213 | validation: 0.0008190578362878265]
	TIME [epoch: 8.24 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007505502663882108		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.0007505502663882108 | validation: 0.001013685502241283]
	TIME [epoch: 8.24 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007159095916234186		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.0007159095916234186 | validation: 0.0005828588994284551]
	TIME [epoch: 8.23 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005689951145953978		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.0005689951145953978 | validation: 0.000632829756583317]
	TIME [epoch: 8.23 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005439034311071101		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.0005439034311071101 | validation: 0.0011101621634145538]
	TIME [epoch: 8.27 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005126035025938316		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.0005126035025938316 | validation: 0.0013992302533289013]
	TIME [epoch: 8.25 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00058743444464502		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.00058743444464502 | validation: 0.00040180532291428237]
	TIME [epoch: 8.24 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007827251017098337		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.0007827251017098337 | validation: 0.0008739770351577852]
	TIME [epoch: 8.24 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006790498032879788		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.0006790498032879788 | validation: 0.0004992545212937341]
	TIME [epoch: 8.23 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005758732111528918		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.0005758732111528918 | validation: 0.0007515234885035343]
	TIME [epoch: 8.24 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000670406591425772		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.000670406591425772 | validation: 0.0010899587567585458]
	TIME [epoch: 8.27 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000532762438501265		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.000532762438501265 | validation: 0.0005437068874842232]
	TIME [epoch: 8.24 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00048351076729956046		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.00048351076729956046 | validation: 0.0008119954964757162]
	TIME [epoch: 8.23 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005159258620492273		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.0005159258620492273 | validation: 0.0011680984432719725]
	TIME [epoch: 8.23 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005492635953334647		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.0005492635953334647 | validation: 0.0007277267617101551]
	TIME [epoch: 8.23 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000514330811710289		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.000514330811710289 | validation: 0.0009071093510511555]
	TIME [epoch: 8.25 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006253888004780089		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.0006253888004780089 | validation: 0.0003555481172073094]
	TIME [epoch: 8.28 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006192512825725565		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.0006192512825725565 | validation: 0.0033275546068851467]
	TIME [epoch: 8.24 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008607586199274247		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.0008607586199274247 | validation: 0.001166490748823083]
	TIME [epoch: 8.23 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005659471315303971		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.0005659471315303971 | validation: 0.0010149970503130863]
	TIME [epoch: 8.24 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005752674207627986		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.0005752674207627986 | validation: 0.0002998484891720512]
	TIME [epoch: 8.3 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005228076230355335		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.0005228076230355335 | validation: 0.0005753962899860268]
	TIME [epoch: 8.36 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008010695395597522		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.0008010695395597522 | validation: 0.0002831428739489681]
	TIME [epoch: 8.27 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006478351991625635		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.0006478351991625635 | validation: 0.0007272345606764663]
	TIME [epoch: 8.23 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005721443618020025		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.0005721443618020025 | validation: 0.0008015162435478773]
	TIME [epoch: 8.24 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005525325448562481		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.0005525325448562481 | validation: 0.0007535202738336464]
	TIME [epoch: 8.23 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000540360970600599		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.000540360970600599 | validation: 0.0012139304389175258]
	TIME [epoch: 8.24 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004720259363498281		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.0004720259363498281 | validation: 0.0008779630096095907]
	TIME [epoch: 8.28 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00037996319218670793		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.00037996319218670793 | validation: 0.00011151888040482482]
	TIME [epoch: 8.25 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007819045516322307		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.0007819045516322307 | validation: 0.0004494664327137761]
	TIME [epoch: 8.23 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006703186844415779		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.0006703186844415779 | validation: 0.0007097001729159098]
	TIME [epoch: 8.24 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005314150993704516		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.0005314150993704516 | validation: 0.0006750934341517336]
	TIME [epoch: 8.23 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004702801030717112		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.0004702801030717112 | validation: 0.0007718299438824605]
	TIME [epoch: 8.27 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000663680760241068		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.000663680760241068 | validation: 0.0008667840101513749]
	TIME [epoch: 8.24 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007392794294941628		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.0007392794294941628 | validation: 0.00026285827680423864]
	TIME [epoch: 8.23 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004997886893004953		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.0004997886893004953 | validation: 0.00038217232920464376]
	TIME [epoch: 8.24 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00048381566768832386		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.00048381566768832386 | validation: 0.00042034439623617463]
	TIME [epoch: 8.24 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006470520743658696		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.0006470520743658696 | validation: 0.000899151387254383]
	TIME [epoch: 8.23 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006227935499129207		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.0006227935499129207 | validation: 0.0008258455204762862]
	TIME [epoch: 8.28 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00066020478632965		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.00066020478632965 | validation: 0.0006235784063762947]
	TIME [epoch: 8.24 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005807070260955898		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.0005807070260955898 | validation: 0.0004153304527805482]
	TIME [epoch: 8.23 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005299799696865883		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.0005299799696865883 | validation: 0.00037987333979273076]
	TIME [epoch: 8.23 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006786282643125155		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.0006786282643125155 | validation: 0.0005452671495117735]
	TIME [epoch: 8.23 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007162387388496977		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.0007162387388496977 | validation: 0.00046245185671847726]
	TIME [epoch: 8.24 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005984938675394824		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.0005984938675394824 | validation: 0.000591251543606016]
	TIME [epoch: 8.28 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007040614042842625		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.0007040614042842625 | validation: 0.000564754563472758]
	TIME [epoch: 8.23 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00048818033659520847		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.00048818033659520847 | validation: 0.0006044201250373353]
	TIME [epoch: 8.23 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006691441215121214		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.0006691441215121214 | validation: 0.0007014422642686916]
	TIME [epoch: 8.24 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004935912152340188		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.0004935912152340188 | validation: 0.00099754029958478]
	TIME [epoch: 8.24 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005133832372059438		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.0005133832372059438 | validation: 0.0008307758006235737]
	TIME [epoch: 8.28 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005396422068540863		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.0005396422068540863 | validation: 7.264505081460904e-05]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_1071.pth
	Model improved!!!
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006999128680935308		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.0006999128680935308 | validation: 0.001545490715117726]
	TIME [epoch: 8.35 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006973740415328161		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.0006973740415328161 | validation: 0.00036616478093918304]
	TIME [epoch: 8.22 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00045984871631255463		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.00045984871631255463 | validation: 0.0007133953398107894]
	TIME [epoch: 8.24 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004780175635514805		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.0004780175635514805 | validation: 0.000499333310058697]
	TIME [epoch: 8.24 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006239025572919134		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.0006239025572919134 | validation: 0.001113592238429944]
	TIME [epoch: 8.28 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002751070320987672		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.0002751070320987672 | validation: 0.0007877571915673514]
	TIME [epoch: 8.24 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004085399025480121		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.0004085399025480121 | validation: 0.0006193884075960608]
	TIME [epoch: 8.22 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00047854463538241364		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.00047854463538241364 | validation: 0.00010886569132494017]
	TIME [epoch: 8.23 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006385897616019787		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.0006385897616019787 | validation: 0.00040936341844852907]
	TIME [epoch: 8.24 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006454741739836076		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.0006454741739836076 | validation: 0.0010427229115647202]
	TIME [epoch: 8.27 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004830137487758732		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.0004830137487758732 | validation: 0.0008737506239711941]
	TIME [epoch: 8.25 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004834785648809911		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.0004834785648809911 | validation: 0.0004560759976566651]
	TIME [epoch: 8.26 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006327765212574608		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.0006327765212574608 | validation: 0.0003543634043198711]
	TIME [epoch: 8.31 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006021919019810268		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.0006021919019810268 | validation: 0.0006336445252052779]
	TIME [epoch: 8.3 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005243482773491237		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.0005243482773491237 | validation: 0.0014903767751660536]
	TIME [epoch: 8.24 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005941056881814995		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.0005941056881814995 | validation: 0.000825789976919693]
	TIME [epoch: 8.29 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000561738830707252		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.000561738830707252 | validation: 0.00043862043726238746]
	TIME [epoch: 8.24 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006026968211185359		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.0006026968211185359 | validation: 0.0006448046803888153]
	TIME [epoch: 8.24 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009178564658466452		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.0009178564658466452 | validation: 0.0007094785494541772]
	TIME [epoch: 8.23 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006382027327853919		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.0006382027327853919 | validation: 0.0006767964514619659]
	TIME [epoch: 8.23 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006482039907859425		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.0006482039907859425 | validation: 0.0006289098728673865]
	TIME [epoch: 8.25 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003764108361277996		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.0003764108361277996 | validation: 0.0006004438326105844]
	TIME [epoch: 8.27 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005959379711334386		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.0005959379711334386 | validation: 0.0003845189950388362]
	TIME [epoch: 8.23 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007108449447457601		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.0007108449447457601 | validation: 0.000813464802688042]
	TIME [epoch: 8.23 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003970359186434272		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.0003970359186434272 | validation: 0.0006817120470510769]
	TIME [epoch: 8.23 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000462351108045441		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.000462351108045441 | validation: 0.0007027437763200162]
	TIME [epoch: 8.24 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000688540448898504		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.000688540448898504 | validation: 0.002373206603921238]
	TIME [epoch: 8.28 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005573023076520002		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.0005573023076520002 | validation: 0.0007502379197774491]
	TIME [epoch: 8.26 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00038324114891392165		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.00038324114891392165 | validation: 0.0005514001386376801]
	TIME [epoch: 8.24 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00035379899934332305		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.00035379899934332305 | validation: 0.00033111646919921963]
	TIME [epoch: 8.24 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005563799005886791		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.0005563799005886791 | validation: 0.0009361767108308366]
	TIME [epoch: 8.33 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005626253648545727		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.0005626253648545727 | validation: 0.00029326308876065533]
	TIME [epoch: 8.24 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004035988842959748		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.0004035988842959748 | validation: 0.00013384758171484723]
	TIME [epoch: 8.28 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00023277492852161806		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.00023277492852161806 | validation: 0.00026935400463457085]
	TIME [epoch: 8.24 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007923717350434769		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.0007923717350434769 | validation: 0.0004767158992191494]
	TIME [epoch: 8.24 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003639757505073728		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.0003639757505073728 | validation: 0.0007647108404212721]
	TIME [epoch: 8.23 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005955961006883626		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.0005955961006883626 | validation: 0.0005600639760388848]
	TIME [epoch: 8.24 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006501766798535111		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.0006501766798535111 | validation: 0.0007435568292243212]
	TIME [epoch: 8.28 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005369728265295606		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.0005369728265295606 | validation: 0.0005370618606733899]
	TIME [epoch: 8.25 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005227732798797639		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.0005227732798797639 | validation: 0.0006513868095577067]
	TIME [epoch: 8.24 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005736356816061319		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.0005736356816061319 | validation: 0.00036474809586866904]
	TIME [epoch: 8.24 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00043192520781327895		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.00043192520781327895 | validation: 0.0008650251587352065]
	TIME [epoch: 8.24 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005090240092664285		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.0005090240092664285 | validation: 0.0006904010144021946]
	TIME [epoch: 8.24 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005340864991836316		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.0005340864991836316 | validation: 0.00034277043407652565]
	TIME [epoch: 8.29 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00034660689928883405		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.00034660689928883405 | validation: 0.00030552334593131293]
	TIME [epoch: 8.24 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003992887680818682		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.0003992887680818682 | validation: 0.00017877961899805328]
	TIME [epoch: 8.23 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005719682150424186		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.0005719682150424186 | validation: 0.0009012417129372796]
	TIME [epoch: 8.24 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004232355735447311		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.0004232355735447311 | validation: 0.0007141871701480813]
	TIME [epoch: 8.24 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000687103572203161		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.000687103572203161 | validation: 0.0010831413093125644]
	TIME [epoch: 8.25 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00047229945703487444		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.00047229945703487444 | validation: 0.0002432957766188082]
	TIME [epoch: 8.27 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006810095889887245		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.0006810095889887245 | validation: 0.0007050818506101857]
	TIME [epoch: 8.23 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005225601662938189		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.0005225601662938189 | validation: 0.0005637085971382829]
	TIME [epoch: 8.23 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00039842469986559135		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.00039842469986559135 | validation: 0.0007679822482581109]
	TIME [epoch: 8.24 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00045300593326719587		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.00045300593326719587 | validation: 0.0005164078883322062]
	TIME [epoch: 8.23 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005301603713594498		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.0005301603713594498 | validation: 0.0005540726295568854]
	TIME [epoch: 8.28 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000427896666548768		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.000427896666548768 | validation: 0.00023523872611593523]
	TIME [epoch: 8.25 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003956563912892748		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.0003956563912892748 | validation: 0.0005800338314869746]
	TIME [epoch: 8.24 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004990096584927066		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.0004990096584927066 | validation: 0.0011281039684519101]
	TIME [epoch: 8.24 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007398356182608604		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.0007398356182608604 | validation: 0.0002415434171398436]
	TIME [epoch: 8.24 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00048081037774603955		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.00048081037774603955 | validation: 0.00043721582180871013]
	TIME [epoch: 8.24 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000552216064862471		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.000552216064862471 | validation: 0.0005245335082057672]
	TIME [epoch: 8.28 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004306565395440949		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.0004306565395440949 | validation: 0.00044519307571951397]
	TIME [epoch: 8.24 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004656148910728151		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.0004656148910728151 | validation: 0.0005183723820663308]
	TIME [epoch: 8.24 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00042630043856142975		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.00042630043856142975 | validation: 0.00042110661482880124]
	TIME [epoch: 8.24 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006344241774894801		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.0006344241774894801 | validation: 0.001137118834135399]
	TIME [epoch: 8.23 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003511157511073524		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.0003511157511073524 | validation: 0.0006866173070986106]
	TIME [epoch: 8.27 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003792234755832429		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.0003792234755832429 | validation: 0.0011773166839693764]
	TIME [epoch: 8.25 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002523106007855045		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.0002523106007855045 | validation: 0.00019356859972107632]
	TIME [epoch: 8.23 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000582495431414684		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.000582495431414684 | validation: 0.00013339193654935498]
	TIME [epoch: 8.24 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00040541148428849906		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.00040541148428849906 | validation: 0.0005271322387573516]
	TIME [epoch: 8.24 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004598944615379272		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.0004598944615379272 | validation: 0.0009437322942787638]
	TIME [epoch: 8.24 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003951960199798073		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.0003951960199798073 | validation: 0.00020885923543016726]
	TIME [epoch: 8.29 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00028675329163451346		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.00028675329163451346 | validation: 0.0005925429980789403]
	TIME [epoch: 8.24 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00046055934681371374		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.00046055934681371374 | validation: 0.0004046485084655389]
	TIME [epoch: 8.24 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00035692045338900206		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.00035692045338900206 | validation: 0.00035705049842544765]
	TIME [epoch: 8.24 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00048130229044579976		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.00048130229044579976 | validation: 0.0006436434782634377]
	TIME [epoch: 8.24 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00041301404132026477		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.00041301404132026477 | validation: 0.0007659145647975123]
	TIME [epoch: 8.26 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00039445802401502834		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.00039445802401502834 | validation: 0.0003053991024412879]
	TIME [epoch: 8.27 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000511315975051625		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.000511315975051625 | validation: 0.0004350000242075103]
	TIME [epoch: 8.23 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00048572194419667646		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.00048572194419667646 | validation: 0.0007478358922414002]
	TIME [epoch: 8.23 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004150863860652576		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.0004150863860652576 | validation: 0.0006334406438004363]
	TIME [epoch: 8.24 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004493101587504129		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.0004493101587504129 | validation: 0.0010335780742537209]
	TIME [epoch: 8.23 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004251955832977527		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.0004251955832977527 | validation: 0.0008033219613018182]
	TIME [epoch: 8.28 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003978544202690741		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.0003978544202690741 | validation: 0.0011340100591458215]
	TIME [epoch: 8.25 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00031969618960153934		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.00031969618960153934 | validation: 0.0004177838564858663]
	TIME [epoch: 8.24 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00037173337792262664		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.00037173337792262664 | validation: 0.0007325752897167747]
	TIME [epoch: 8.24 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005410693145463456		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.0005410693145463456 | validation: 0.0002935560161777744]
	TIME [epoch: 8.23 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00028090379567700843		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.00028090379567700843 | validation: 0.0004502856005292557]
	TIME [epoch: 8.25 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00016022034048806356		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.00016022034048806356 | validation: 0.0005505699547360399]
	TIME [epoch: 8.27 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004489482647606962		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.0004489482647606962 | validation: 0.0005545230870145916]
	TIME [epoch: 8.24 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000472432402165844		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.000472432402165844 | validation: 0.00029650540962112084]
	TIME [epoch: 8.24 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003795501677912141		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.0003795501677912141 | validation: 0.0004265272885757119]
	TIME [epoch: 8.23 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005357505355452464		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.0005357505355452464 | validation: 0.0006725265885666402]
	TIME [epoch: 8.23 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005177547406694844		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.0005177547406694844 | validation: 0.0005987049693878302]
	TIME [epoch: 8.27 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00032196083586900095		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.00032196083586900095 | validation: 0.00032993600832941276]
	TIME [epoch: 8.26 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006668076966821426		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.0006668076966821426 | validation: 0.0005401868199233828]
	TIME [epoch: 8.23 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00047040119009339823		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.00047040119009339823 | validation: 0.00017169972859937756]
	TIME [epoch: 8.23 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005542694438871225		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.0005542694438871225 | validation: 0.0007046794216847268]
	TIME [epoch: 8.24 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003641361401755188		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.0003641361401755188 | validation: 0.0005552233261479796]
	TIME [epoch: 8.24 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004412338614556326		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.0004412338614556326 | validation: 0.0006385781955008127]
	TIME [epoch: 8.28 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00039724302338783543		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.00039724302338783543 | validation: 0.000600370388308181]
	TIME [epoch: 8.25 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002976706810666669		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.0002976706810666669 | validation: 0.0002671010873596336]
	TIME [epoch: 8.24 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00044476114004541613		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.00044476114004541613 | validation: 0.0006727445407918004]
	TIME [epoch: 8.23 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008120422594836171		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.0008120422594836171 | validation: 0.001473243157544559]
	TIME [epoch: 8.24 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006698022299935506		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.0006698022299935506 | validation: 0.0003290578188857038]
	TIME [epoch: 8.24 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00018457201757659215		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.00018457201757659215 | validation: 0.00023109243884209186]
	TIME [epoch: 8.28 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00031557897912589495		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.00031557897912589495 | validation: 0.00040326176913421376]
	TIME [epoch: 8.24 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00027331796054937076		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.00027331796054937076 | validation: 0.0010504830754716626]
	TIME [epoch: 8.24 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003587290697612104		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.0003587290697612104 | validation: 0.00030079339831137373]
	TIME [epoch: 8.24 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00040876463429639003		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.00040876463429639003 | validation: 0.0002935026402031156]
	TIME [epoch: 8.24 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004116526253737154		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.0004116526253737154 | validation: 0.00030597256170187317]
	TIME [epoch: 8.28 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004019459657011344		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.0004019459657011344 | validation: 0.00033812987516835234]
	TIME [epoch: 8.26 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004963614360245658		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.0004963614360245658 | validation: 0.0006065181986184269]
	TIME [epoch: 8.24 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004091440265643478		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.0004091440265643478 | validation: 0.0009290101669555116]
	TIME [epoch: 8.23 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00039815083266502564		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.00039815083266502564 | validation: 0.0009242791631031455]
	TIME [epoch: 8.23 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00032657119524858103		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.00032657119524858103 | validation: 0.00023537720109285056]
	TIME [epoch: 8.25 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002937493441899068		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.0002937493441899068 | validation: 0.0006159051815826917]
	TIME [epoch: 8.28 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00019874122858417985		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.00019874122858417985 | validation: 0.0009043769576003208]
	TIME [epoch: 8.24 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004372100334671869		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.0004372100334671869 | validation: 0.00043943389088938736]
	TIME [epoch: 8.24 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004279999282185052		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.0004279999282185052 | validation: 0.0009480787719097821]
	TIME [epoch: 8.25 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000610562048489175		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.000610562048489175 | validation: 0.000248270650561734]
	TIME [epoch: 8.23 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005618036121131302		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.0005618036121131302 | validation: 0.0008237466173780917]
	TIME [epoch: 8.25 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00044908151210917315		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.00044908151210917315 | validation: 0.0006817757562557336]
	TIME [epoch: 8.27 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003068956658547137		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.0003068956658547137 | validation: 0.00035928911711528497]
	TIME [epoch: 8.23 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00036925380137164043		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.00036925380137164043 | validation: 0.0003513956623209405]
	TIME [epoch: 8.23 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00020630368052887985		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.00020630368052887985 | validation: 0.0005849842043101692]
	TIME [epoch: 8.23 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00041479100566816767		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.00041479100566816767 | validation: 0.0010091035187188267]
	TIME [epoch: 8.24 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000315096103225395		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.000315096103225395 | validation: 0.0005621705364376917]
	TIME [epoch: 8.28 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000596493466226542		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.000596493466226542 | validation: 0.0006571194716348235]
	TIME [epoch: 8.24 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00028297865507176704		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.00028297865507176704 | validation: 0.0005545731785597913]
	TIME [epoch: 8.24 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00041295385832052097		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.00041295385832052097 | validation: 0.0012971489703158508]
	TIME [epoch: 8.25 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008037253276929901		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.0008037253276929901 | validation: 0.0011666979043725174]
	TIME [epoch: 8.24 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005796973445180143		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.0005796973445180143 | validation: 0.0003358849750688711]
	TIME [epoch: 8.26 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00032150679737076435		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.00032150679737076435 | validation: 0.0006463964532380828]
	TIME [epoch: 8.28 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005430517283332945		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.0005430517283332945 | validation: 0.0005508890026775771]
	TIME [epoch: 8.24 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005000071960253659		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.0005000071960253659 | validation: 0.0006583558408074649]
	TIME [epoch: 8.24 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003560530002033664		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.0003560530002033664 | validation: 0.0003903879491385274]
	TIME [epoch: 8.24 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00038508457903909554		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.00038508457903909554 | validation: 0.0004885467533086559]
	TIME [epoch: 8.24 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003158780014440472		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.0003158780014440472 | validation: 0.000490455350087978]
	TIME [epoch: 8.28 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003501710286548563		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.0003501710286548563 | validation: 0.0011187077143368818]
	TIME [epoch: 8.25 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005249577767569027		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.0005249577767569027 | validation: 0.0009066269917985377]
	TIME [epoch: 8.24 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005487365604584593		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.0005487365604584593 | validation: 0.0001675984940315116]
	TIME [epoch: 8.24 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00030562205979011803		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.00030562205979011803 | validation: 0.0004343907237148326]
	TIME [epoch: 8.24 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00040737734526396976		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.00040737734526396976 | validation: 0.0011830946169512613]
	TIME [epoch: 8.25 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00044291413115402013		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.00044291413115402013 | validation: 0.00031926933389731004]
	TIME [epoch: 8.28 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00028018033450393995		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.00028018033450393995 | validation: 0.0006008076376455227]
	TIME [epoch: 8.24 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005088413213190324		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.0005088413213190324 | validation: 0.00015985445307943992]
	TIME [epoch: 8.24 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002742664075116972		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.0002742664075116972 | validation: 0.0006584515381489267]
	TIME [epoch: 8.24 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004856808060743296		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.0004856808060743296 | validation: 0.0003581290131505242]
	TIME [epoch: 8.24 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002769683636550868		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.0002769683636550868 | validation: 0.0005221909212982743]
	TIME [epoch: 8.27 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00027533204770415366		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.00027533204770415366 | validation: 0.000961683241878613]
	TIME [epoch: 8.26 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000342553064152022		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.000342553064152022 | validation: 0.0002561617356639454]
	TIME [epoch: 8.24 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00041972218294805024		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.00041972218294805024 | validation: 0.00039663352560114884]
	TIME [epoch: 8.24 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002653417739268613		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.0002653417739268613 | validation: 0.00044530199713958574]
	TIME [epoch: 8.24 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002707984546993594		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.0002707984546993594 | validation: 0.0006085960799919069]
	TIME [epoch: 8.24 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003467793459083475		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.0003467793459083475 | validation: 0.00030609682278035687]
	TIME [epoch: 8.29 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00029883762298214036		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.00029883762298214036 | validation: 0.0011559682429510732]
	TIME [epoch: 8.24 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003537397473914483		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.0003537397473914483 | validation: 0.0005585123534747077]
	TIME [epoch: 8.24 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00032891154152405686		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.00032891154152405686 | validation: 0.0006762146696546614]
	TIME [epoch: 8.24 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003127591552177815		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.0003127591552177815 | validation: 0.0007284970276143392]
	TIME [epoch: 8.23 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003615581727150279		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.0003615581727150279 | validation: 0.000855730763348725]
	TIME [epoch: 8.24 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00030956630026302847		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.00030956630026302847 | validation: 0.00019074793259627842]
	TIME [epoch: 8.28 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003662420212219863		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.0003662420212219863 | validation: 0.0003786138190332285]
	TIME [epoch: 8.24 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00027635540515975123		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.00027635540515975123 | validation: 0.0006191762773986086]
	TIME [epoch: 8.24 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003558877707826476		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.0003558877707826476 | validation: 0.0003520851719083478]
	TIME [epoch: 8.24 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005202911502990523		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.0005202911502990523 | validation: 0.00062310539854262]
	TIME [epoch: 8.25 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00025905848522218334		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.00025905848522218334 | validation: 0.0008230277264267025]
	TIME [epoch: 8.28 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003139594787911775		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.0003139594787911775 | validation: 0.000995286552584905]
	TIME [epoch: 8.25 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00042479905949279		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.00042479905949279 | validation: 0.000555776531164165]
	TIME [epoch: 8.24 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002897641931344102		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.0002897641931344102 | validation: 0.0005163050564865364]
	TIME [epoch: 8.24 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003829854299762052		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.0003829854299762052 | validation: 0.0008320515912095595]
	TIME [epoch: 8.24 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00030438875772738697		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.00030438875772738697 | validation: 0.000640484286025349]
	TIME [epoch: 8.25 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00032665868682400133		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.00032665868682400133 | validation: 0.00052452465490655]
	TIME [epoch: 8.29 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000576874491997315		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.000576874491997315 | validation: 0.0004288708997774995]
	TIME [epoch: 8.24 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00034828584404838787		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.00034828584404838787 | validation: 0.0006038999283762596]
	TIME [epoch: 8.24 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00026208371166791246		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.00026208371166791246 | validation: 0.00027119436359622907]
	TIME [epoch: 8.23 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006199759612354283		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.0006199759612354283 | validation: 0.0003974125382550389]
	TIME [epoch: 8.24 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00042672592552116		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.00042672592552116 | validation: 0.00048782608369646584]
	TIME [epoch: 8.26 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004792214709620786		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.0004792214709620786 | validation: 0.00024003814529139603]
	TIME [epoch: 8.27 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005196743128829262		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.0005196743128829262 | validation: 0.0007615708765964699]
	TIME [epoch: 8.24 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002142480048988109		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.0002142480048988109 | validation: 0.0006818462597646829]
	TIME [epoch: 8.24 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00044539393287806227		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.00044539393287806227 | validation: 0.0007123133668710473]
	TIME [epoch: 8.24 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003018730657573885		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.0003018730657573885 | validation: 0.00020995094165318575]
	TIME [epoch: 8.24 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00034676698227371894		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.00034676698227371894 | validation: 0.000707245402948944]
	TIME [epoch: 8.28 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00025783734625037025		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.00025783734625037025 | validation: 0.0003979169640799345]
	TIME [epoch: 8.25 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00037835044504736935		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.00037835044504736935 | validation: 0.0005586147545626785]
	TIME [epoch: 8.24 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002521677273600955		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.0002521677273600955 | validation: 0.0005549800490811281]
	TIME [epoch: 8.24 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00040788101900580265		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.00040788101900580265 | validation: 0.0004270194717482205]
	TIME [epoch: 8.24 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003640150244735474		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.0003640150244735474 | validation: 0.00030057992843354243]
	TIME [epoch: 8.24 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004060165447021369		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.0004060165447021369 | validation: 0.0004599984022308563]
	TIME [epoch: 8.28 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004908963119566889		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.0004908963119566889 | validation: 0.00023490018141892932]
	TIME [epoch: 8.24 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00018712572277010107		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.00018712572277010107 | validation: 0.0001339051238924567]
	TIME [epoch: 8.24 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00033235930320786177		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.00033235930320786177 | validation: 0.00027752659909379763]
	TIME [epoch: 8.24 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00021042386368980837		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.00021042386368980837 | validation: 0.00038002872918078273]
	TIME [epoch: 8.24 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000247041959193431		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.000247041959193431 | validation: 0.0003055410338466826]
	TIME [epoch: 8.28 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00043362597663789044		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.00043362597663789044 | validation: 0.0019426427385396748]
	TIME [epoch: 8.25 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00047769824231649015		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.00047769824231649015 | validation: 0.0006778591091911066]
	TIME [epoch: 8.24 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000741849692112944		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.000741849692112944 | validation: 0.000594593793719831]
	TIME [epoch: 8.24 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003170774883413645		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.0003170774883413645 | validation: 0.0003729443721341692]
	TIME [epoch: 8.24 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003225216786351708		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.0003225216786351708 | validation: -1.8332304167334006e-05]
	TIME [epoch: 8.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_1271.pth
	Model improved!!!
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003770084083335785		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.0003770084083335785 | validation: 0.0003686064615468832]
	TIME [epoch: 8.28 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00030567871081277435		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.00030567871081277435 | validation: 0.0008122007444160665]
	TIME [epoch: 8.23 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002443961558992778		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.0002443961558992778 | validation: 0.00031066433689187534]
	TIME [epoch: 8.24 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003815926601579165		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.0003815926601579165 | validation: 0.0004748089120343692]
	TIME [epoch: 8.23 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002971302191272847		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.0002971302191272847 | validation: 0.0006754675868582831]
	TIME [epoch: 8.23 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003364967117448625		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.0003364967117448625 | validation: 0.00018949346636393203]
	TIME [epoch: 8.26 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00025000694696605396		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.00025000694696605396 | validation: 0.00021358855168949554]
	TIME [epoch: 8.26 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000204074450525612		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.000204074450525612 | validation: 0.0011453715566758973]
	TIME [epoch: 8.23 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002854131603963368		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.0002854131603963368 | validation: 0.0002145712011208225]
	TIME [epoch: 8.23 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002815660811553753		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.0002815660811553753 | validation: 0.00033414648131749216]
	TIME [epoch: 8.23 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00037892450563678986		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.00037892450563678986 | validation: 0.00045369169478553053]
	TIME [epoch: 8.23 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002611482672184149		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.0002611482672184149 | validation: 7.566736128010377e-05]
	TIME [epoch: 8.27 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002625813723549939		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.0002625813723549939 | validation: 0.00019679706720300772]
	TIME [epoch: 8.24 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005502500940145023		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.0005502500940145023 | validation: 0.0005629554750514344]
	TIME [epoch: 8.24 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003379305322096695		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.0003379305322096695 | validation: 0.0004518400834979426]
	TIME [epoch: 8.24 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00036259526938919054		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.00036259526938919054 | validation: 0.00045689608757045353]
	TIME [epoch: 8.24 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003715030822554646		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.0003715030822554646 | validation: 0.00021744165328172558]
	TIME [epoch: 8.25 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00029742221653942846		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.00029742221653942846 | validation: 0.00039617540640685524]
	TIME [epoch: 8.28 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00019465411627249884		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.00019465411627249884 | validation: 0.00048573800570772183]
	TIME [epoch: 8.24 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002194358849059417		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.0002194358849059417 | validation: 0.0003377062631149865]
	TIME [epoch: 8.24 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002706026288348955		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.0002706026288348955 | validation: 0.00026078733042213465]
	TIME [epoch: 8.24 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00034686879828239436		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.00034686879828239436 | validation: 0.0003080956757292013]
	TIME [epoch: 8.24 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001525147177594315		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.0001525147177594315 | validation: 0.0004990937112839919]
	TIME [epoch: 8.28 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004204655711231715		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.0004204655711231715 | validation: 0.000534632504707397]
	TIME [epoch: 8.25 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00042402839544966353		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.00042402839544966353 | validation: 0.0002687852910777959]
	TIME [epoch: 8.23 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003945572042272461		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.0003945572042272461 | validation: 0.0004552909611306495]
	TIME [epoch: 8.24 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002582060322006499		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.0002582060322006499 | validation: 0.0007393825472436655]
	TIME [epoch: 8.23 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002822000851219104		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.0002822000851219104 | validation: 0.0004480243806438198]
	TIME [epoch: 8.24 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002464296435475351		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.0002464296435475351 | validation: 0.00043897993158043035]
	TIME [epoch: 8.28 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002524294134731724		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.0002524294134731724 | validation: 0.0005605509357181635]
	TIME [epoch: 8.24 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00023291401010296122		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.00023291401010296122 | validation: 0.0003396216226099033]
	TIME [epoch: 8.24 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004025656541232303		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.0004025656541232303 | validation: 0.0006602953522473101]
	TIME [epoch: 8.23 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00035462442016467096		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.00035462442016467096 | validation: 6.0435045252628345e-05]
	TIME [epoch: 8.23 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002608192020143261		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.0002608192020143261 | validation: 0.00046353345589760853]
	TIME [epoch: 8.27 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004108155651440539		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.0004108155651440539 | validation: 0.0006321746898193101]
	TIME [epoch: 8.25 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002495780545388935		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.0002495780545388935 | validation: 7.925046099132693e-05]
	TIME [epoch: 8.23 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00024364498136104088		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.00024364498136104088 | validation: 0.00048788000266833007]
	TIME [epoch: 8.23 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000231922331085346		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.000231922331085346 | validation: 0.0007359645317951342]
	TIME [epoch: 8.24 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004946584759349974		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.0004946584759349974 | validation: 0.00047669926239483917]
	TIME [epoch: 8.23 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000296741881080683		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.000296741881080683 | validation: 0.00034474900679583965]
	TIME [epoch: 8.28 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00031444334959094286		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.00031444334959094286 | validation: 0.0003105211356671234]
	TIME [epoch: 8.24 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00013532716507157373		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.00013532716507157373 | validation: 0.00028509528468867543]
	TIME [epoch: 8.24 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00034888569040631535		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.00034888569040631535 | validation: 0.00045412060902510283]
	TIME [epoch: 8.24 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003468622918611153		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.0003468622918611153 | validation: 0.0003699739947081282]
	TIME [epoch: 8.24 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00021199800386687207		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.00021199800386687207 | validation: 0.0005975335602335728]
	TIME [epoch: 8.26 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004042841156356951		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.0004042841156356951 | validation: 0.0006255840162504862]
	TIME [epoch: 8.26 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00021454623686301198		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.00021454623686301198 | validation: 0.00041029148391379344]
	TIME [epoch: 8.23 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00011463208248497559		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.00011463208248497559 | validation: 0.0006712936618911982]
	TIME [epoch: 8.23 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00020574600226640994		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.00020574600226640994 | validation: 0.00030489275745713317]
	TIME [epoch: 8.23 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00031256843221300827		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.00031256843221300827 | validation: 0.0004003275824761205]
	TIME [epoch: 8.23 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00022569212420969743		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.00022569212420969743 | validation: 0.0003559436415357702]
	TIME [epoch: 8.27 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000312466141533396		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.000312466141533396 | validation: 0.0006139634687273273]
	TIME [epoch: 8.25 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003479613122121767		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.0003479613122121767 | validation: 0.00024507910936218293]
	TIME [epoch: 8.23 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003331354168299184		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.0003331354168299184 | validation: 0.0005552187913974898]
	TIME [epoch: 8.23 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002623807827267326		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.0002623807827267326 | validation: 0.0001869618772991304]
	TIME [epoch: 8.23 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00014495174602798032		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.00014495174602798032 | validation: 0.00037423751492726253]
	TIME [epoch: 8.24 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002883734490978218		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.0002883734490978218 | validation: 0.0002691117108052934]
	TIME [epoch: 8.28 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002837579412996447		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.0002837579412996447 | validation: 0.0003423955755656651]
	TIME [epoch: 8.24 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000178482336129977		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.000178482336129977 | validation: 0.0005413690074450628]
	TIME [epoch: 8.24 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00022594585929368847		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.00022594585929368847 | validation: 1.7008372773577018e-05]
	TIME [epoch: 8.24 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00026772404873366494		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.00026772404873366494 | validation: 0.00012922806654695052]
	TIME [epoch: 8.23 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000290287051624132		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.000290287051624132 | validation: 0.0006981378189343265]
	TIME [epoch: 8.25 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003711900570559372		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.0003711900570559372 | validation: 0.0003683190597920118]
	TIME [epoch: 8.26 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00018004542196034645		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.00018004542196034645 | validation: 0.0005763158948163278]
	TIME [epoch: 8.23 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005330231739663036		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.0005330231739663036 | validation: 0.0025415358685898087]
	TIME [epoch: 8.23 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007676289560843238		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.0007676289560843238 | validation: 0.0012938373711397224]
	TIME [epoch: 8.23 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00019287106203019522		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.00019287106203019522 | validation: 0.0002116724731620616]
	TIME [epoch: 8.23 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003073609144044711		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.0003073609144044711 | validation: 0.0004571377953397003]
	TIME [epoch: 8.28 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002579611247577942		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.0002579611247577942 | validation: 0.0003901138172697758]
	TIME [epoch: 8.24 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003487526815829532		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.0003487526815829532 | validation: 0.00038836697890236587]
	TIME [epoch: 8.23 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00036574252355954864		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.00036574252355954864 | validation: 0.0005234124223576524]
	TIME [epoch: 8.24 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00036844749896179765		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.00036844749896179765 | validation: 0.0008993947801602715]
	TIME [epoch: 8.24 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004865235062345057		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.0004865235062345057 | validation: 0.0002782384687037309]
	TIME [epoch: 8.25 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000351032998764953		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.000351032998764953 | validation: 0.00035415054792613265]
	TIME [epoch: 8.29 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001869035282595284		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.0001869035282595284 | validation: 0.0005225694604906677]
	TIME [epoch: 8.24 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00040817322297352046		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.00040817322297352046 | validation: 0.00018381929087071924]
	TIME [epoch: 8.23 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004318170430807087		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.0004318170430807087 | validation: 0.0006164169802399312]
	TIME [epoch: 8.23 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00035186615719149565		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.00035186615719149565 | validation: 0.00024608034719457363]
	TIME [epoch: 8.23 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004104678620589408		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.0004104678620589408 | validation: 0.00040780709103229904]
	TIME [epoch: 8.27 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003736285663508403		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.0003736285663508403 | validation: 0.0004527063694884017]
	TIME [epoch: 8.25 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00033368613682023085		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.00033368613682023085 | validation: 0.0002227779096254814]
	TIME [epoch: 8.23 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00042812221318523137		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.00042812221318523137 | validation: 0.0006269768942059964]
	TIME [epoch: 8.24 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00033448330453376366		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.00033448330453376366 | validation: 0.0003763411194869999]
	TIME [epoch: 8.24 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003081765207706644		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.0003081765207706644 | validation: 7.739761194321027e-05]
	TIME [epoch: 8.24 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000314495753324326		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.000314495753324326 | validation: 0.00030883815854556836]
	TIME [epoch: 8.28 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00044761138001663214		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.00044761138001663214 | validation: 0.0004207590621846622]
	TIME [epoch: 8.24 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003361142317492438		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.0003361142317492438 | validation: 0.00032372818492062017]
	TIME [epoch: 8.24 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002563985736427763		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.0002563985736427763 | validation: 0.0009030613737200674]
	TIME [epoch: 8.24 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00021350330942561337		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.00021350330942561337 | validation: 0.00045619478536914926]
	TIME [epoch: 8.24 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00021377859486332773		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.00021377859486332773 | validation: 0.0004685522676313339]
	TIME [epoch: 8.25 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002143113765617417		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.0002143113765617417 | validation: 0.00032402380872011437]
	TIME [epoch: 8.26 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00019141418688077018		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.00019141418688077018 | validation: 0.00041171678126639485]
	TIME [epoch: 8.23 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004856816020374824		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.0004856816020374824 | validation: 0.0003260613369500236]
	TIME [epoch: 8.23 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00022067116805243224		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.00022067116805243224 | validation: 0.00030775102789892995]
	TIME [epoch: 8.23 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002170920931807898		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.0002170920931807898 | validation: 0.00023774638518530813]
	TIME [epoch: 8.23 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003395988988301597		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.0003395988988301597 | validation: 0.0003060944475657932]
	TIME [epoch: 8.28 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00023595108818175235		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.00023595108818175235 | validation: 0.0001474191186423175]
	TIME [epoch: 8.25 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004332031429762695		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.0004332031429762695 | validation: 0.0005637180586849207]
	TIME [epoch: 8.24 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002609883900411294		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.0002609883900411294 | validation: 0.00036941438261098455]
	TIME [epoch: 8.23 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00037023946746948447		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.00037023946746948447 | validation: 0.001334301628246868]
	TIME [epoch: 8.23 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00034135511534316465		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.00034135511534316465 | validation: 0.00012115724894723546]
	TIME [epoch: 8.24 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003059100213222883		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.0003059100213222883 | validation: 0.0008178673724985384]
	TIME [epoch: 8.28 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00023109928632036625		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.00023109928632036625 | validation: 0.0006716617428410859]
	TIME [epoch: 8.24 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002345098483599597		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.0002345098483599597 | validation: 0.00040467118678970686]
	TIME [epoch: 8.23 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00021346847092894406		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.00021346847092894406 | validation: 0.0005299454561136753]
	TIME [epoch: 8.23 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00029231852044655284		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.00029231852044655284 | validation: 0.00025794884304703467]
	TIME [epoch: 8.23 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00029101779461872626		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.00029101779461872626 | validation: 0.000482217829372563]
	TIME [epoch: 8.28 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00021411866847203574		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.00021411866847203574 | validation: 0.000505554731368572]
	TIME [epoch: 8.25 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003584852506165768		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.0003584852506165768 | validation: 0.0005878647032940227]
	TIME [epoch: 8.23 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001846418284303979		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.0001846418284303979 | validation: 0.0006006532436398722]
	TIME [epoch: 8.24 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00026369273102511826		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.00026369273102511826 | validation: 0.0004698128541833162]
	TIME [epoch: 8.24 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00028140545453167915		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.00028140545453167915 | validation: 0.0003645135766830592]
	TIME [epoch: 8.23 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00030814219501845485		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.00030814219501845485 | validation: 0.0005790445446603947]
	TIME [epoch: 8.29 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00034407409069458497		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.00034407409069458497 | validation: 0.0004926539897803632]
	TIME [epoch: 8.25 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00025876948292539683		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.00025876948292539683 | validation: 0.0006034142246600122]
	TIME [epoch: 8.25 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00020298717976613003		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.00020298717976613003 | validation: 0.0006674954955210728]
	TIME [epoch: 8.24 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001797201163965825		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.0001797201163965825 | validation: 0.0003189079875329304]
	TIME [epoch: 8.24 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00030713020679427097		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.00030713020679427097 | validation: 6.335492906725284e-05]
	TIME [epoch: 8.25 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00024368392484061595		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.00024368392484061595 | validation: 0.00033850428327253824]
	TIME [epoch: 8.27 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003265097358467002		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.0003265097358467002 | validation: 0.0002789985107286288]
	TIME [epoch: 8.23 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002853229728620219		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.0002853229728620219 | validation: 0.00024090122084886368]
	TIME [epoch: 8.24 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000357156243730526		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.000357156243730526 | validation: 0.00021497519314371072]
	TIME [epoch: 8.24 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00016238156394637106		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.00016238156394637106 | validation: 0.0002807095279820171]
	TIME [epoch: 8.23 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00020871745577696887		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.00020871745577696887 | validation: 0.00037283973258882334]
	TIME [epoch: 8.28 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00023975381835095267		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.00023975381835095267 | validation: 0.0003539143104658118]
	TIME [epoch: 8.25 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00015967454895848368		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.00015967454895848368 | validation: 0.00027919610619922606]
	TIME [epoch: 8.23 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00042276492866255815		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.00042276492866255815 | validation: 0.0003361947679265453]
	TIME [epoch: 8.23 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004078567328275549		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.0004078567328275549 | validation: 0.0006924896697290679]
	TIME [epoch: 8.23 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002734662203256539		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.0002734662203256539 | validation: 0.0004245904992716918]
	TIME [epoch: 8.25 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00015076052122372998		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.00015076052122372998 | validation: 0.0005680151302980524]
	TIME [epoch: 8.28 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00028146348075278803		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.00028146348075278803 | validation: 0.00011348636538284929]
	TIME [epoch: 8.23 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.662382144359283e-05		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 9.662382144359283e-05 | validation: 0.00018549674294507135]
	TIME [epoch: 8.23 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003253767654468241		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.0003253767654468241 | validation: 0.00025221911962934395]
	TIME [epoch: 8.23 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00029564508908669443		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.00029564508908669443 | validation: 0.0006573290340760921]
	TIME [epoch: 8.23 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00031483623124613745		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.00031483623124613745 | validation: 0.00040882822704543375]
	TIME [epoch: 8.27 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00018721708774152492		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.00018721708774152492 | validation: 0.0004941436577284452]
	TIME [epoch: 8.25 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00030806815178518934		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.00030806815178518934 | validation: 0.00016198379434475906]
	TIME [epoch: 8.24 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00011279322061494622		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.00011279322061494622 | validation: 9.710228854037072e-05]
	TIME [epoch: 8.24 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001994582254636801		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.0001994582254636801 | validation: 0.00028659474860304624]
	TIME [epoch: 8.23 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001926512796230104		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.0001926512796230104 | validation: 0.00038892020207818677]
	TIME [epoch: 8.24 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003130318950349913		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.0003130318950349913 | validation: 0.0004986044559126431]
	TIME [epoch: 8.28 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00021515831498318416		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.00021515831498318416 | validation: 0.0005636666274789519]
	TIME [epoch: 8.24 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00032310841750577394		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.00032310841750577394 | validation: 0.00041830988507656923]
	TIME [epoch: 8.23 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004323905323202666		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.0004323905323202666 | validation: 0.0005236106241396081]
	TIME [epoch: 8.23 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003276585751135479		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.0003276585751135479 | validation: 0.00032370116865461455]
	TIME [epoch: 8.24 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00023922844099654372		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.00023922844099654372 | validation: 0.0004907400584570932]
	TIME [epoch: 8.26 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003048115593002154		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.0003048115593002154 | validation: 0.00013576603389623364]
	TIME [epoch: 8.26 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00022571624108010525		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.00022571624108010525 | validation: 0.0002895667112042499]
	TIME [epoch: 8.23 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00028799870333968714		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.00028799870333968714 | validation: 0.0004396105930230547]
	TIME [epoch: 8.23 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00042467971351087887		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.00042467971351087887 | validation: 4.4253678656482436e-05]
	TIME [epoch: 8.24 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00020506940544392794		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.00020506940544392794 | validation: 0.00041270267250875575]
	TIME [epoch: 8.23 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00027368442134677085		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.00027368442134677085 | validation: 0.00028730672711626236]
	TIME [epoch: 8.27 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001838260277610002		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.0001838260277610002 | validation: 0.0004685959665095778]
	TIME [epoch: 8.24 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003291464120036107		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.0003291464120036107 | validation: 0.0005748600361189009]
	TIME [epoch: 8.23 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002190598483406683		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.0002190598483406683 | validation: 0.00014328781326941356]
	TIME [epoch: 8.23 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002888010870577007		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.0002888010870577007 | validation: 0.0004694911929293131]
	TIME [epoch: 8.23 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00021066998556485306		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.00021066998556485306 | validation: 0.00016148382140664986]
	TIME [epoch: 8.24 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002866758626177763		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.0002866758626177763 | validation: 9.026439731174831e-05]
	TIME [epoch: 8.28 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00021602761950764184		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.00021602761950764184 | validation: 0.00036263652513119206]
	TIME [epoch: 8.24 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00021181110388876977		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.00021181110388876977 | validation: 0.0007785935389719398]
	TIME [epoch: 8.24 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00026812541774267885		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.00026812541774267885 | validation: 0.00047508454367900564]
	TIME [epoch: 8.23 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002326655546351404		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.0002326655546351404 | validation: 0.0004842957846553562]
	TIME [epoch: 8.23 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002293441502683895		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.0002293441502683895 | validation: 0.00029047864168664896]
	TIME [epoch: 8.27 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00047837069770554594		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.00047837069770554594 | validation: 0.0004967605985194599]
	TIME [epoch: 8.25 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003273359715829993		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.0003273359715829993 | validation: 0.00044515821155170966]
	TIME [epoch: 8.23 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00020806840326888644		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.00020806840326888644 | validation: 0.0005206879855169042]
	TIME [epoch: 8.23 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003868037187516367		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.0003868037187516367 | validation: 0.00016419187204223551]
	TIME [epoch: 8.23 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002660719145520287		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.0002660719145520287 | validation: 0.000589288700491668]
	TIME [epoch: 8.23 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00017930972121482446		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.00017930972121482446 | validation: 0.0002231770807944118]
	TIME [epoch: 8.28 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003412445580036221		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.0003412445580036221 | validation: 0.0004231382844617739]
	TIME [epoch: 8.23 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005927686379335986		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.0005927686379335986 | validation: 0.00016426085976177252]
	TIME [epoch: 8.23 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004071666627487398		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.0004071666627487398 | validation: 0.0007499705198990929]
	TIME [epoch: 8.23 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003872247833062477		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.0003872247833062477 | validation: 0.00028497749889456174]
	TIME [epoch: 8.24 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00030983307612846825		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.00030983307612846825 | validation: 0.0002738207229294476]
	TIME [epoch: 8.26 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00034168242580611465		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.00034168242580611465 | validation: 0.0004402950911365844]
	TIME [epoch: 8.27 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00037069855008288054		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.00037069855008288054 | validation: -2.2188903756915386e-05]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_1447.pth
	Model improved!!!
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00017463385797040828		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.00017463385797040828 | validation: 0.00011149947209070898]
	TIME [epoch: 8.24 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.03051991987669e-05		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 9.03051991987669e-05 | validation: 0.0006556462436261432]
	TIME [epoch: 8.23 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001841603677393282		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.0001841603677393282 | validation: 0.00010477966863942977]
	TIME [epoch: 8.23 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00027531430846596303		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.00027531430846596303 | validation: 0.0003499000303179738]
	TIME [epoch: 8.28 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002257901326834182		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.0002257901326834182 | validation: 0.00020810947198906951]
	TIME [epoch: 8.24 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00023957281690927922		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.00023957281690927922 | validation: 0.00041924709456373855]
	TIME [epoch: 8.23 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002590335558933603		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.0002590335558933603 | validation: 0.000405631393103822]
	TIME [epoch: 8.23 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00037839854461218494		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.00037839854461218494 | validation: 0.0005179479576827176]
	TIME [epoch: 8.22 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00038757114471288514		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.00038757114471288514 | validation: 0.0003731549375069756]
	TIME [epoch: 8.24 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00026442796570791096		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.00026442796570791096 | validation: 0.0006828454581248673]
	TIME [epoch: 8.28 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00016175347514116355		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.00016175347514116355 | validation: 0.0003123690704902371]
	TIME [epoch: 8.24 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00017640554842009414		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.00017640554842009414 | validation: 0.00033995561052722054]
	TIME [epoch: 8.24 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00015067742078387703		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.00015067742078387703 | validation: 0.00034143192874731376]
	TIME [epoch: 8.24 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002682359565002306		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.0002682359565002306 | validation: 0.000422602026246099]
	TIME [epoch: 8.23 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003009535556116321		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.0003009535556116321 | validation: 0.0002503626161906718]
	TIME [epoch: 8.27 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00022405891016112124		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.00022405891016112124 | validation: 0.00028066274539170966]
	TIME [epoch: 8.24 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002540059858816453		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.0002540059858816453 | validation: 0.00014933076709225547]
	TIME [epoch: 8.23 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00025319332572620553		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.00025319332572620553 | validation: 0.00036491319455962847]
	TIME [epoch: 8.24 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00022430742180771254		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.00022430742180771254 | validation: 0.00024341180743126412]
	TIME [epoch: 8.24 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00022415041631249213		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.00022415041631249213 | validation: 0.00047451434318755584]
	TIME [epoch: 8.23 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00021014806672673948		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.00021014806672673948 | validation: 0.00017081317069437586]
	TIME [epoch: 8.28 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002994017139812604		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.0002994017139812604 | validation: 0.00039532712388543257]
	TIME [epoch: 8.24 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003782414629223714		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.0003782414629223714 | validation: 0.0002650038868484428]
	TIME [epoch: 8.23 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00029606557176786285		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.00029606557176786285 | validation: 0.0007530966657543115]
	TIME [epoch: 8.23 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00026676479250648644		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.00026676479250648644 | validation: 0.00040156477153849404]
	TIME [epoch: 8.23 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001304131667144972		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.0001304131667144972 | validation: 7.722859460473775e-05]
	TIME [epoch: 8.26 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00027603923283534736		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.00027603923283534736 | validation: 0.0005012381755256943]
	TIME [epoch: 8.27 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00013815082417995472		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.00013815082417995472 | validation: 0.0006494945307732447]
	TIME [epoch: 8.23 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002595785270936706		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.0002595785270936706 | validation: 0.00019210046342599618]
	TIME [epoch: 8.23 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00019823530477336426		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.00019823530477336426 | validation: 0.0002668050318036519]
	TIME [epoch: 8.23 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00022400252674205088		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.00022400252674205088 | validation: 0.0004113384623314511]
	TIME [epoch: 8.23 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00032363827622897205		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.00032363827622897205 | validation: 0.00044240689630008494]
	TIME [epoch: 8.27 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.850381097444049e-05		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 9.850381097444049e-05 | validation: 0.0007404446590985145]
	TIME [epoch: 8.24 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002658628158971017		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.0002658628158971017 | validation: 0.0003993681084115908]
	TIME [epoch: 8.23 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00033640687532032423		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.00033640687532032423 | validation: 0.0006999009118399293]
	TIME [epoch: 8.23 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00036785190909751654		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.00036785190909751654 | validation: 0.00040065205365182965]
	TIME [epoch: 8.23 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00013021877527104488		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.00013021877527104488 | validation: 0.0003799087404858437]
	TIME [epoch: 8.24 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00022761232210599336		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.00022761232210599336 | validation: 0.0002453900550145116]
	TIME [epoch: 8.27 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003393426573791756		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.0003393426573791756 | validation: 0.00045418744380759527]
	TIME [epoch: 8.23 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00031508012746351286		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.00031508012746351286 | validation: 0.0003474872851012547]
	TIME [epoch: 8.23 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002556259629983082		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.0002556259629983082 | validation: 0.00047770374299980394]
	TIME [epoch: 8.23 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002891653633228124		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.0002891653633228124 | validation: 0.0003854101458614521]
	TIME [epoch: 8.24 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003363961439909311		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.0003363961439909311 | validation: 0.00032092330222288276]
	TIME [epoch: 8.27 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00019156751293003516		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.00019156751293003516 | validation: 0.0003036295443259771]
	TIME [epoch: 8.25 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00016853374896010466		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.00016853374896010466 | validation: -0.00015776507555937335]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_20240520_124240/states/model_phi1_1a_v_mmd1_1492.pth
	Model improved!!!
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.521675574138476e-05		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 8.521675574138476e-05 | validation: 0.00010974228479008376]
	TIME [epoch: 8.24 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00013099979487216773		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.00013099979487216773 | validation: 9.350882370280456e-05]
	TIME [epoch: 8.25 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002540820959514547		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.0002540820959514547 | validation: 0.0007930812403054937]
	TIME [epoch: 8.25 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00037676458337472307		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.00037676458337472307 | validation: 0.00047060159771491697]
	TIME [epoch: 8.29 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000297737792775169		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.000297737792775169 | validation: 6.523740182127024e-05]
	TIME [epoch: 8.24 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004059638217409898		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.0004059638217409898 | validation: 0.00035009692070782616]
	TIME [epoch: 8.24 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00027687877906890936		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.00027687877906890936 | validation: -5.552796264859174e-06]
	TIME [epoch: 8.24 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00025889535492885105		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.00025889535492885105 | validation: 0.00013699756854155965]
	TIME [epoch: 8.24 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002450619103863066		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.0002450619103863066 | validation: 0.00019770729322110547]
	TIME [epoch: 8.27 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00031944244137802416		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.00031944244137802416 | validation: 0.00024818714387622975]
	TIME [epoch: 8.27 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003892086174336613		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.0003892086174336613 | validation: 0.00022212667633196494]
	TIME [epoch: 8.24 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00023804523025633653		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.00023804523025633653 | validation: 0.0007631440194245611]
	TIME [epoch: 8.24 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00012649419738426992		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.00012649419738426992 | validation: 9.00889379142038e-05]
	TIME [epoch: 8.24 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00023419787114000834		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.00023419787114000834 | validation: 0.0003136440892744625]
	TIME [epoch: 8.25 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001682803045753074		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.0001682803045753074 | validation: 0.0005462450651078132]
	TIME [epoch: 8.28 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00033100956869742346		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.00033100956869742346 | validation: 0.0005845076359736261]
	TIME [epoch: 8.24 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.336590197809215e-05		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 9.336590197809215e-05 | validation: 0.000245271639019168]
	TIME [epoch: 8.24 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00031565748519790367		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.00031565748519790367 | validation: 0.0004047446247723343]
	TIME [epoch: 8.25 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00016470191482704857		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.00016470191482704857 | validation: 0.0009764997203720807]
	TIME [epoch: 8.24 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.842489171503965e-05		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 8.842489171503965e-05 | validation: 0.00037274529653111884]
	TIME [epoch: 8.26 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00027072733382383854		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.00027072733382383854 | validation: 0.00012181462908193908]
	TIME [epoch: 8.27 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00024294302501582534		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.00024294302501582534 | validation: 0.0001331998253095472]
	TIME [epoch: 8.24 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000345901200109298		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.000345901200109298 | validation: 0.0004007077424940348]
	TIME [epoch: 8.25 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00019994178767144112		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.00019994178767144112 | validation: 0.00049738288283059]
	TIME [epoch: 8.25 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00029028967984935064		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.00029028967984935064 | validation: 0.0007195301447546428]
	TIME [epoch: 8.24 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004202702752129565		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.0004202702752129565 | validation: 0.00028173493393304305]
	TIME [epoch: 8.29 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00014396408608819544		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.00014396408608819544 | validation: 0.00015473137161101748]
	TIME [epoch: 8.25 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00021421342763427734		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.00021421342763427734 | validation: 0.0004554470048756905]
	TIME [epoch: 8.24 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002714025083861633		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.0002714025083861633 | validation: 0.00039604571539170587]
	TIME [epoch: 8.24 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.931766218731643e-05		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 9.931766218731643e-05 | validation: 0.0001439891080131508]
	TIME [epoch: 8.24 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00015717338203136076		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.00015717338203136076 | validation: 0.0006679264877986909]
	TIME [epoch: 8.25 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00017544986365743332		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.00017544986365743332 | validation: 0.0003223487796928417]
	TIME [epoch: 8.28 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00023676576866734278		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.00023676576866734278 | validation: 0.00046147444329472175]
	TIME [epoch: 8.24 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000368718271778816		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.000368718271778816 | validation: 0.0007273058610383254]
	TIME [epoch: 8.23 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002513138172246827		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.0002513138172246827 | validation: 0.0007794098638813055]
	TIME [epoch: 8.24 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002639700823028341		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.0002639700823028341 | validation: 0.00010322566200264216]
	TIME [epoch: 8.24 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00025453472436750874		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.00025453472436750874 | validation: 0.0006929146631956247]
	TIME [epoch: 8.28 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00030507793906344924		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.00030507793906344924 | validation: 0.00011383524922443835]
	TIME [epoch: 8.26 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00037183819096278366		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.00037183819096278366 | validation: 0.0002760255193256267]
	TIME [epoch: 8.25 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001784647969240436		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.0001784647969240436 | validation: 0.00010009919885782992]
	TIME [epoch: 8.25 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00021794078344713897		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.00021794078344713897 | validation: 0.0003638408852911459]
	TIME [epoch: 8.24 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003026448721818238		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.0003026448721818238 | validation: 0.00033673740391374006]
	TIME [epoch: 8.24 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00026491262706855356		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.00026491262706855356 | validation: 0.00028402790103320807]
	TIME [epoch: 8.28 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003007274839760057		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.0003007274839760057 | validation: 5.5697824537255685e-05]
	TIME [epoch: 8.25 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003111953533668563		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.0003111953533668563 | validation: 0.000193885931912269]
	TIME [epoch: 8.24 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00027862671455403934		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.00027862671455403934 | validation: 0.00039710369859512174]
	TIME [epoch: 8.24 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.867745905547174e-05		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 7.867745905547174e-05 | validation: 0.00034091464955045313]
	TIME [epoch: 8.24 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00026261175653476696		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.00026261175653476696 | validation: 0.00012107428264261432]
	TIME [epoch: 8.26 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00031082414288693803		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.00031082414288693803 | validation: 0.00024287213930596164]
	TIME [epoch: 8.28 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005331949790304932		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.0005331949790304932 | validation: 0.00033959734793834336]
	TIME [epoch: 8.24 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003049262963908064		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.0003049262963908064 | validation: 0.0002741242392591179]
	TIME [epoch: 8.24 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00015565582055622685		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.00015565582055622685 | validation: 0.00023342378628291808]
	TIME [epoch: 8.24 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001754611264774737		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.0001754611264774737 | validation: 9.535214312868769e-05]
	TIME [epoch: 8.24 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001543766550108654		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.0001543766550108654 | validation: 0.0003497262777781112]
	TIME [epoch: 8.28 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00013603937295219516		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.00013603937295219516 | validation: 0.0005588733095303802]
	TIME [epoch: 8.25 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004355835791379352		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.0004355835791379352 | validation: 0.0007940138965251409]
	TIME [epoch: 8.24 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003187798156777244		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.0003187798156777244 | validation: 0.0004982408385195783]
	TIME [epoch: 8.24 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00025604360635520185		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.00025604360635520185 | validation: 0.0005657525887481079]
	TIME [epoch: 8.24 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.103409491586383e-05		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 1.103409491586383e-05 | validation: 0.0002403476740596826]
	TIME [epoch: 8.25 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00022238841023819412		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.00022238841023819412 | validation: 0.00030284074420444185]
	TIME [epoch: 8.28 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00024230648905706586		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.00024230648905706586 | validation: 0.0001642389491005334]
	TIME [epoch: 8.24 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00020197359098579913		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.00020197359098579913 | validation: 0.0006630657486161962]
	TIME [epoch: 8.24 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00023401923437589667		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.00023401923437589667 | validation: 0.00031723044575687536]
	TIME [epoch: 8.24 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002596086710459953		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.0002596086710459953 | validation: 0.00059534749120278]
	TIME [epoch: 8.24 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00015049148484106657		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.00015049148484106657 | validation: 0.00032329926628768123]
	TIME [epoch: 8.27 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00012366630229415776		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.00012366630229415776 | validation: 0.00015500140620132097]
	TIME [epoch: 8.25 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001635141860901504		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.0001635141860901504 | validation: 0.00022636557083309763]
	TIME [epoch: 8.24 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00034962573008321085		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.00034962573008321085 | validation: 0.00026122636091787754]
	TIME [epoch: 8.24 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00024701642144690154		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.00024701642144690154 | validation: 0.0006972473913748702]
	TIME [epoch: 8.24 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002946605021326374		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.0002946605021326374 | validation: 0.00045643445758455047]
	TIME [epoch: 8.24 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002639038672932872		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.0002639038672932872 | validation: 0.00014757965014891726]
	TIME [epoch: 8.28 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00012787627518323053		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.00012787627518323053 | validation: 0.0005050154708137074]
	TIME [epoch: 8.24 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00010915338386097707		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.00010915338386097707 | validation: 0.00022883285572471477]
	TIME [epoch: 8.23 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00026032425900704247		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.00026032425900704247 | validation: 0.0002866292144589427]
	TIME [epoch: 8.24 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00015987667978039168		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.00015987667978039168 | validation: 0.0001040540466251949]
	TIME [epoch: 8.23 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00020304478849087723		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.00020304478849087723 | validation: 0.0002542032986844012]
	TIME [epoch: 8.25 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003404689473407128		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.0003404689473407128 | validation: 0.0005498052781903811]
	TIME [epoch: 8.27 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002004049268288868		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.0002004049268288868 | validation: 0.00022899951279160114]
	TIME [epoch: 8.24 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003718302824084445		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.0003718302824084445 | validation: 0.00038929587074723495]
	TIME [epoch: 8.23 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002854887581649552		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.0002854887581649552 | validation: 0.00013078098222864387]
	TIME [epoch: 8.24 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00015301838758362128		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.00015301838758362128 | validation: 0.0001793634484633344]
	TIME [epoch: 8.24 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00013160878999977135		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.00013160878999977135 | validation: 0.0002802654558828808]
	TIME [epoch: 8.28 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00018110042180507867		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.00018110042180507867 | validation: 0.0007237333490433438]
	TIME [epoch: 8.25 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002058425111711746		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.0002058425111711746 | validation: 0.0002752884921810228]
	TIME [epoch: 8.24 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00015351272801759122		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.00015351272801759122 | validation: 3.723060271706305e-05]
	TIME [epoch: 8.24 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00018916755021240926		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.00018916755021240926 | validation: 0.0007274296539832941]
	TIME [epoch: 8.24 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002969477581160289		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.0002969477581160289 | validation: 0.00035270416782389]
	TIME [epoch: 8.24 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003295007808080102		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.0003295007808080102 | validation: 0.0006209708607863709]
	TIME [epoch: 8.28 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00034363763027432496		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.00034363763027432496 | validation: 0.00025431383876028767]
	TIME [epoch: 8.24 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00029266050798551203		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.00029266050798551203 | validation: 1.6601888767397093e-05]
	TIME [epoch: 8.24 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00028720934794932297		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.00028720934794932297 | validation: 0.0001095202023448172]
	TIME [epoch: 8.24 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00013975909272455868		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.00013975909272455868 | validation: 0.0005188596453589086]
	TIME [epoch: 8.24 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002302420469867188		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.0002302420469867188 | validation: 0.00038810051369393066]
	TIME [epoch: 8.27 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00020552874955669152		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.00020552874955669152 | validation: 0.00029064141020954804]
	TIME [epoch: 8.25 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001292786917013815		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.0001292786917013815 | validation: 0.0007804145765979867]
	TIME [epoch: 8.23 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003650536056397569		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.0003650536056397569 | validation: 0.00044265047919354574]
	TIME [epoch: 8.24 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00012419377935472342		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.00012419377935472342 | validation: 0.0004066316751642356]
	TIME [epoch: 8.24 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003137547614371039		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.0003137547614371039 | validation: 0.0006845331705895932]
	TIME [epoch: 8.24 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002089028739625054		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.0002089028739625054 | validation: 0.0007199980536796886]
	TIME [epoch: 8.29 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00026328766118579195		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.00026328766118579195 | validation: 0.0002287523602284489]
	TIME [epoch: 8.24 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00027011424631599604		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.00027011424631599604 | validation: 0.00025982695007015]
	TIME [epoch: 8.24 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00027710615106626426		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.00027710615106626426 | validation: 0.00032091552653658615]
	TIME [epoch: 8.24 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00022880657926585866		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.00022880657926585866 | validation: 0.00048762295911062203]
	TIME [epoch: 8.24 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00024314568048698296		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.00024314568048698296 | validation: 0.0005052280053046046]
	TIME [epoch: 8.25 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002189067189789178		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.0002189067189789178 | validation: 0.0005820162250908184]
	TIME [epoch: 8.27 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00019928032505634176		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.00019928032505634176 | validation: 0.0003818318377014362]
	TIME [epoch: 8.24 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00023374290021190315		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.00023374290021190315 | validation: 0.00034670650849637143]
	TIME [epoch: 8.24 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00021097791307373193		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.00021097791307373193 | validation: 0.0006886630259389053]
	TIME [epoch: 8.24 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002131312270439598		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.0002131312270439598 | validation: 0.00035447055791705214]
	TIME [epoch: 8.24 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002519218302256505		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.0002519218302256505 | validation: 0.00030129799160998695]
	TIME [epoch: 8.28 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00015844744174625493		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.00015844744174625493 | validation: 0.0003211403603089682]
	TIME [epoch: 8.24 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002971086113480099		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.0002971086113480099 | validation: 0.00036034116575076513]
	TIME [epoch: 8.24 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00032342264023416735		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.00032342264023416735 | validation: 0.0006355732421125442]
	TIME [epoch: 8.23 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.054277916246241e-06		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 2.054277916246241e-06 | validation: 0.00028147664537797736]
	TIME [epoch: 8.23 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00010206000571188589		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.00010206000571188589 | validation: 0.000246280766066862]
	TIME [epoch: 8.23 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00010566351654800666		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.00010566351654800666 | validation: 0.0005276002489373059]
	TIME [epoch: 8.26 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.381823825710978e-05		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 9.381823825710978e-05 | validation: 0.0008257467652185753]
	TIME [epoch: 8.23 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00031017905578119677		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.00031017905578119677 | validation: 0.00013034371378907483]
	TIME [epoch: 8.24 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00023607974193315352		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.00023607974193315352 | validation: 0.00026432114100907625]
	TIME [epoch: 8.23 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000438802013109755		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.000438802013109755 | validation: 0.0005120227531086501]
	TIME [epoch: 8.24 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002893200340771052		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.0002893200340771052 | validation: 0.00030481221636241427]
	TIME [epoch: 8.26 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00026525546583647296		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.00026525546583647296 | validation: 0.0004737694177275458]
	TIME [epoch: 8.25 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00020032508041789		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.00020032508041789 | validation: -5.721418799602151e-05]
	TIME [epoch: 8.24 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002414237891841453		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.0002414237891841453 | validation: 0.0002781164112197452]
	TIME [epoch: 8.23 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00021971282930575176		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.00021971282930575176 | validation: 0.0001493181814005009]
	TIME [epoch: 8.24 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003422644210014674		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.0003422644210014674 | validation: 0.0005140646236861901]
	TIME [epoch: 8.23 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004538508826695369		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.0004538508826695369 | validation: 0.0001806443906764468]
	TIME [epoch: 8.28 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00026483139168730665		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.00026483139168730665 | validation: 0.0004484330402108183]
	TIME [epoch: 8.23 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002561065993757037		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.0002561065993757037 | validation: 0.00033609739534678785]
	TIME [epoch: 8.23 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000213858889129664		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.000213858889129664 | validation: 0.00022277103492810912]
	TIME [epoch: 8.23 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00022546039847914505		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.00022546039847914505 | validation: 4.303646530639594e-05]
	TIME [epoch: 8.23 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00024171744675099329		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.00024171744675099329 | validation: 0.0003155826690354786]
	TIME [epoch: 8.24 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000296752029111216		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.000296752029111216 | validation: 0.00032545955638753376]
	TIME [epoch: 8.27 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003604655316755914		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.0003604655316755914 | validation: 0.0006871739221941456]
	TIME [epoch: 8.22 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00026099602040864124		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.00026099602040864124 | validation: 0.00027084377905840817]
	TIME [epoch: 8.23 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002871316221885802		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.0002871316221885802 | validation: 0.0004827571606092906]
	TIME [epoch: 8.23 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00021665661873826594		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.00021665661873826594 | validation: 1.8886373548891555e-05]
	TIME [epoch: 8.23 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002488218023768092		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.0002488218023768092 | validation: 0.0004208306814811733]
	TIME [epoch: 8.26 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00015698725206137		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.00015698725206137 | validation: 0.0005619034746826488]
	TIME [epoch: 8.25 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002135524421935646		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.0002135524421935646 | validation: 0.0005906375691204353]
	TIME [epoch: 8.23 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00016342981577866135		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.00016342981577866135 | validation: 0.0002596939842072459]
	TIME [epoch: 8.24 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00021237150152882123		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.00021237150152882123 | validation: 0.00012045307924689477]
	TIME [epoch: 8.23 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003164676405421491		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.0003164676405421491 | validation: 0.0001146084863759267]
	TIME [epoch: 8.24 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00018845130974770743		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.00018845130974770743 | validation: 0.0005912850848266312]
	TIME [epoch: 8.27 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00013698679431964055		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.00013698679431964055 | validation: 0.0006151437960397779]
	TIME [epoch: 8.23 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.263888137134325e-05		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 8.263888137134325e-05 | validation: 0.00020386756877845968]
	TIME [epoch: 8.23 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001678744977028357		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.0001678744977028357 | validation: 0.00034931488854361616]
	TIME [epoch: 8.23 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00022504536755533146		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.00022504536755533146 | validation: 0.00020166656605068934]
	TIME [epoch: 8.23 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00028265610004763933		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.00028265610004763933 | validation: 0.0003535677092089937]
	TIME [epoch: 8.26 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00033747563828141216		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.00033747563828141216 | validation: 0.00033914365511850076]
	TIME [epoch: 8.24 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001835715765821362		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.0001835715765821362 | validation: 0.000596496722604372]
	TIME [epoch: 8.23 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002770201133596932		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.0002770201133596932 | validation: 0.00020164769163035957]
	TIME [epoch: 8.22 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00025034936321310507		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.00025034936321310507 | validation: 0.00022786924930823195]
	TIME [epoch: 8.23 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00021705975680087807		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.00021705975680087807 | validation: 0.00032242977543165096]
	TIME [epoch: 8.23 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000216766179015123		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.000216766179015123 | validation: 0.0011481817662697545]
	TIME [epoch: 8.29 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00020145027672958894		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.00020145027672958894 | validation: 0.0003498784573009921]
	TIME [epoch: 8.23 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001899607220499515		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.0001899607220499515 | validation: 0.00025356190536901036]
	TIME [epoch: 8.24 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002882860022289264		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.0002882860022289264 | validation: 0.0005047617035305869]
	TIME [epoch: 8.24 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00020733886523334588		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.00020733886523334588 | validation: 0.0005906770798570138]
	TIME [epoch: 8.23 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00015273998044939695		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.00015273998044939695 | validation: 0.0005834296534176575]
	TIME [epoch: 8.25 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00025937124926026824		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.00025937124926026824 | validation: 0.00040599264459562166]
	TIME [epoch: 8.28 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.740936658925945e-05		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 7.740936658925945e-05 | validation: 7.255075196355864e-05]
	TIME [epoch: 8.23 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00023231059123588604		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.00023231059123588604 | validation: 0.00015483871041003817]
	TIME [epoch: 8.23 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002466749280246026		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.0002466749280246026 | validation: 0.00028742579390882476]
	TIME [epoch: 8.24 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00027746320171244366		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.00027746320171244366 | validation: 6.232107190650372e-05]
	TIME [epoch: 8.23 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00014568923836983272		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.00014568923836983272 | validation: 0.0007140018475428454]
	TIME [epoch: 8.28 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461880890751701e-05		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 4.461880890751701e-05 | validation: 0.00039970372456671214]
	TIME [epoch: 8.24 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00014528934404411476		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.00014528934404411476 | validation: 0.000334693078097339]
	TIME [epoch: 8.23 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00024011303837351573		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.00024011303837351573 | validation: 9.871832819996219e-05]
	TIME [epoch: 8.25 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001899509958781984		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.0001899509958781984 | validation: 0.0004900984237548824]
	TIME [epoch: 8.23 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00018988209376375045		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.00018988209376375045 | validation: 0.0006881214403196632]
	TIME [epoch: 8.24 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00029835559774227184		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.00029835559774227184 | validation: 9.241030123877027e-06]
	TIME [epoch: 8.27 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002544289651015477		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.0002544289651015477 | validation: 0.0002732914411165801]
	TIME [epoch: 8.24 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00010663695042376142		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.00010663695042376142 | validation: 0.0001666905763662916]
	TIME [epoch: 8.23 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.136344834157705e-05		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 8.136344834157705e-05 | validation: 0.0002690679827056668]
	TIME [epoch: 8.23 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00018950107665844995		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.00018950107665844995 | validation: 0.0005663382712749137]
	TIME [epoch: 8.23 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00026645346639481724		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.00026645346639481724 | validation: 0.00031772023711573017]
	TIME [epoch: 8.27 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001476805069512577		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.0001476805069512577 | validation: 0.0004400283672688312]
	TIME [epoch: 8.24 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6177851017522824e-05		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 5.6177851017522824e-05 | validation: 0.000674421188327985]
	TIME [epoch: 8.22 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002607103221510703		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.0002607103221510703 | validation: 0.0009331891237382877]
	TIME [epoch: 8.23 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001907198754379789		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.0001907198754379789 | validation: 0.0002041639382833251]
	TIME [epoch: 8.23 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00022486358467326806		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.00022486358467326806 | validation: 0.0005553987283206583]
	TIME [epoch: 8.23 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002578003724619408		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.0002578003724619408 | validation: 0.00014239110542916666]
	TIME [epoch: 8.28 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001260585707412556		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.0001260585707412556 | validation: 0.00042809981358943983]
	TIME [epoch: 8.25 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002529270461932809		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.0002529270461932809 | validation: 0.0005904701031172453]
	TIME [epoch: 8.24 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00023988556734826248		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.00023988556734826248 | validation: 0.000558440432085443]
	TIME [epoch: 8.23 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001665643914215078		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.0001665643914215078 | validation: 0.0006900116944272838]
	TIME [epoch: 8.24 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00014082170795796413		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.00014082170795796413 | validation: 0.0002156209216832181]
	TIME [epoch: 8.23 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003044287815073592		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.0003044287815073592 | validation: 0.0005007192380857717]
	TIME [epoch: 8.27 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000286352116569681		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.000286352116569681 | validation: 0.00013667096555500537]
	TIME [epoch: 8.23 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000258929382811798		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.000258929382811798 | validation: 0.0002694817742130402]
	TIME [epoch: 8.23 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00011620445227430998		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.00011620445227430998 | validation: 0.000431287549436429]
	TIME [epoch: 8.23 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003355689009020022		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.0003355689009020022 | validation: 0.0003837680116151514]
	TIME [epoch: 8.23 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00024554281853650004		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.00024554281853650004 | validation: 0.000463203426070967]
	TIME [epoch: 8.27 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00030519639004169435		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.00030519639004169435 | validation: 0.00041027185236185116]
	TIME [epoch: 8.25 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001598308912591462		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.0001598308912591462 | validation: 0.0002125031760946783]
	TIME [epoch: 8.23 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00017587409789804554		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.00017587409789804554 | validation: 0.0004974620453878949]
	TIME [epoch: 8.23 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00017671136518251365		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.00017671136518251365 | validation: 0.0007610269587835461]
	TIME [epoch: 8.24 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002097377705959629		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.0002097377705959629 | validation: 0.00011466871897916064]
	TIME [epoch: 8.25 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002575633443859997		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.0002575633443859997 | validation: -5.4323391881871085e-05]
	TIME [epoch: 8.28 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00020348122515014987		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.00020348122515014987 | validation: 0.00024000156079251146]
	TIME [epoch: 8.24 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003487450664384815		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.0003487450664384815 | validation: 0.0004146124092459225]
	TIME [epoch: 8.24 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.3743960934959476e-05		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 5.3743960934959476e-05 | validation: 0.00023518461614824027]
	TIME [epoch: 8.23 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00036088511980277005		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.00036088511980277005 | validation: 0.00024509117000989637]
	TIME [epoch: 8.24 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00019348166059689962		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.00019348166059689962 | validation: 0.0002677340842083487]
	TIME [epoch: 8.26 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.058781659171754e-05		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 7.058781659171754e-05 | validation: 0.0002738401835356639]
	TIME [epoch: 8.27 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002587787365489409		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.0002587787365489409 | validation: 0.00044664729262917024]
	TIME [epoch: 8.23 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00022701971447574955		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.00022701971447574955 | validation: 8.465056796171044e-05]
	TIME [epoch: 8.23 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00011255151900760164		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.00011255151900760164 | validation: 0.00029128357266880033]
	TIME [epoch: 8.23 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00034042809957514456		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.00034042809957514456 | validation: 0.0002700491750313052]
	TIME [epoch: 8.23 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002969918862795109		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.0002969918862795109 | validation: 0.00035057428123138484]
	TIME [epoch: 8.28 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001930773761148594		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.0001930773761148594 | validation: 0.00018321265184054083]
	TIME [epoch: 8.24 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002559241719925521		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.0002559241719925521 | validation: 0.00042314648787252553]
	TIME [epoch: 8.23 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00022715105316953974		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.00022715105316953974 | validation: 0.0001953977225740546]
	TIME [epoch: 8.23 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00028461763337682644		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.00028461763337682644 | validation: 0.00022988661078685802]
	TIME [epoch: 8.23 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00015240107921648673		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.00015240107921648673 | validation: 0.0004381069948423928]
	TIME [epoch: 8.25 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00017998693181741187		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.00017998693181741187 | validation: 0.00046047075747077934]
	TIME [epoch: 8.27 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00016254577815102246		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.00016254577815102246 | validation: 0.0002871138664104942]
	TIME [epoch: 8.23 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002485755241730696		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.0002485755241730696 | validation: 0.0005037097121438992]
	TIME [epoch: 8.23 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00019299343198910356		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.00019299343198910356 | validation: 0.00035257121329697403]
	TIME [epoch: 8.23 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002066799412279614		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.0002066799412279614 | validation: 0.00040883554865076737]
	TIME [epoch: 8.23 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003457467731631421		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.0003457467731631421 | validation: 0.00024698239662529085]
	TIME [epoch: 8.27 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00034943236464105644		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.00034943236464105644 | validation: 0.00013721509957851017]
	TIME [epoch: 8.24 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00015911918734241314		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.00015911918734241314 | validation: 0.00014434904098850954]
	TIME [epoch: 8.25 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00044085495316667614		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.00044085495316667614 | validation: 0.00024676961000323416]
	TIME [epoch: 8.24 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00029375007240441353		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.00029375007240441353 | validation: 0.00037013135467279666]
	TIME [epoch: 8.24 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7354063153138846e-05		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 5.7354063153138846e-05 | validation: 0.00013194511061895663]
	TIME [epoch: 8.24 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00027127950564771665		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.00027127950564771665 | validation: 0.0003683880844107028]
	TIME [epoch: 8.27 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00022808166904803674		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.00022808166904803674 | validation: 0.00029696660473470704]
	TIME [epoch: 8.23 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001301031740265215		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.0001301031740265215 | validation: 0.0005158163819503274]
	TIME [epoch: 8.23 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00025257639628313913		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.00025257639628313913 | validation: 0.00032092591728162653]
	TIME [epoch: 8.23 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001987780139801496		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.0001987780139801496 | validation: 0.00039489298304854793]
	TIME [epoch: 8.23 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00025104621066609226		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.00025104621066609226 | validation: 0.00022584974292684377]
	TIME [epoch: 8.27 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002289272865763712		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.0002289272865763712 | validation: 8.54742971481981e-05]
	TIME [epoch: 8.24 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00010282084877141706		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.00010282084877141706 | validation: 0.0005905962142593575]
	TIME [epoch: 8.23 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00019650631437035626		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.00019650631437035626 | validation: 0.0005187929273312318]
	TIME [epoch: 8.23 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004488271659880165		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.0004488271659880165 | validation: 0.00026603441916158755]
	TIME [epoch: 8.23 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001769354096313354		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.0001769354096313354 | validation: 0.0004585049418039722]
	TIME [epoch: 8.23 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.920349917728826e-05		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 3.920349917728826e-05 | validation: 0.0001333601411284171]
	TIME [epoch: 8.28 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.684219855460796e-05		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 9.684219855460796e-05 | validation: 0.0003653445122407266]
	TIME [epoch: 8.24 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00011753049069370403		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.00011753049069370403 | validation: 0.0004259021572790482]
	TIME [epoch: 8.24 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00021390348469339448		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.00021390348469339448 | validation: 0.00031308181649790704]
	TIME [epoch: 8.23 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00012060992696439566		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.00012060992696439566 | validation: 0.00034078785174268414]
	TIME [epoch: 8.23 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001054021527243878		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.0001054021527243878 | validation: 2.8724998038742733e-05]
	TIME [epoch: 8.25 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00020920534043605433		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.00020920534043605433 | validation: 0.0004682798249532416]
	TIME [epoch: 8.26 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00023889340691172435		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.00023889340691172435 | validation: 0.00011862548858810575]
	TIME [epoch: 8.24 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: -1.5049808864410663e-05		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: -1.5049808864410663e-05 | validation: 0.0007206542020990003]
	TIME [epoch: 8.24 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00025751317127358853		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.00025751317127358853 | validation: 0.00016800144389783698]
	TIME [epoch: 8.24 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00020848344168109413		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.00020848344168109413 | validation: 0.0005496482340368729]
	TIME [epoch: 8.23 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00020040780805526205		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.00020040780805526205 | validation: 0.00032627675287176316]
	TIME [epoch: 8.27 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00020817979479021087		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.00020817979479021087 | validation: 0.00037981195475517284]
	TIME [epoch: 8.25 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00016491784412619472		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.00016491784412619472 | validation: 0.00041185229921898616]
	TIME [epoch: 8.23 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00031698513819858066		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.00031698513819858066 | validation: 0.0002889255528215342]
	TIME [epoch: 8.23 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00018005601424729936		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.00018005601424729936 | validation: 8.548251241067551e-05]
	TIME [epoch: 8.23 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00027198511818904317		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.00027198511818904317 | validation: 0.0006352708824386433]
	TIME [epoch: 8.25 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00018529556063382515		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.00018529556063382515 | validation: 0.00043206693238126003]
	TIME [epoch: 8.28 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.348349833238957e-05		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 9.348349833238957e-05 | validation: 0.0007832596691361032]
	TIME [epoch: 8.24 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00031619480009891095		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.00031619480009891095 | validation: 0.0003293696460313402]
	TIME [epoch: 8.24 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003100164499087208		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.0003100164499087208 | validation: 0.0006244633027739983]
	TIME [epoch: 8.24 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00020007681083553466		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.00020007681083553466 | validation: 0.00017590590351145165]
	TIME [epoch: 8.24 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.235946995216523e-05		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 5.235946995216523e-05 | validation: 0.00014749002954640036]
	TIME [epoch: 8.28 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: -1.5286394221266653e-05		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: -1.5286394221266653e-05 | validation: 0.00020877270547493422]
	TIME [epoch: 8.25 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003173825567955382		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.0003173825567955382 | validation: 0.00032799550857450475]
	TIME [epoch: 8.23 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00024281637632854228		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.00024281637632854228 | validation: 0.00016437110545637523]
	TIME [epoch: 8.24 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00037264134424238704		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.00037264134424238704 | validation: 0.000271312488637224]
	TIME [epoch: 8.23 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00018944903643532896		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.00018944903643532896 | validation: 0.00030257174077596364]
	TIME [epoch: 8.23 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00013277022780976199		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.00013277022780976199 | validation: 0.0002834582002964598]
	TIME [epoch: 8.28 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00021765671708567002		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.00021765671708567002 | validation: 0.0005314820416467372]
	TIME [epoch: 8.23 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003445180186875221		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.0003445180186875221 | validation: 0.0003033107430901429]
	TIME [epoch: 8.23 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00022601910519936608		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.00022601910519936608 | validation: 0.0005276260546835231]
	TIME [epoch: 8.24 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00032002761047726863		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.00032002761047726863 | validation: 0.0014122060521161474]
	TIME [epoch: 8.24 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00019590370448753047		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.00019590370448753047 | validation: 0.00024452050380253265]
	TIME [epoch: 8.24 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003196943767422118		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.0003196943767422118 | validation: 0.0006244264875112009]
	TIME [epoch: 8.28 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00022841442118887303		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.00022841442118887303 | validation: 0.0004993059298173507]
	TIME [epoch: 8.23 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.708867561961518e-05		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 8.708867561961518e-05 | validation: 0.0002765309044803637]
	TIME [epoch: 8.24 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001096702447111746		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.0001096702447111746 | validation: 0.0001616755963695864]
	TIME [epoch: 8.23 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00038431468151646486		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.00038431468151646486 | validation: 0.0003686962819214141]
	TIME [epoch: 8.23 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002245968347001326		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.0002245968347001326 | validation: 7.906582200193846e-05]
	TIME [epoch: 8.28 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00025700573895359356		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.00025700573895359356 | validation: 0.00020616031391988178]
	TIME [epoch: 8.25 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00015152370774371995		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.00015152370774371995 | validation: 0.00035233778792645865]
	TIME [epoch: 8.23 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002961618994772746		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.0002961618994772746 | validation: 0.0002598721023723236]
	TIME [epoch: 8.24 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00013224705110024138		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.00013224705110024138 | validation: 6.344401174621518e-05]
	TIME [epoch: 8.23 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002297108916372903		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.0002297108916372903 | validation: 0.00030501945268591514]
	TIME [epoch: 8.24 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00014464685135252852		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.00014464685135252852 | validation: 0.00017324858991150726]
	TIME [epoch: 8.29 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002826934501170966		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.0002826934501170966 | validation: 0.00034467711023066096]
	TIME [epoch: 8.23 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00013498880733299522		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.00013498880733299522 | validation: 0.0003627867212350937]
	TIME [epoch: 8.24 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00010827809678405132		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.00010827809678405132 | validation: 0.0002827259415306163]
	TIME [epoch: 8.23 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00019207904285543378		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.00019207904285543378 | validation: 3.641733625263122e-05]
	TIME [epoch: 8.23 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00019732574036588078		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.00019732574036588078 | validation: 0.00037584308931901144]
	TIME [epoch: 8.25 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00013759720620387862		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.00013759720620387862 | validation: 0.0004240532433336854]
	TIME [epoch: 8.26 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00026713481245957784		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.00026713481245957784 | validation: 0.00016658336846087709]
	TIME [epoch: 8.23 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00035081618600026277		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.00035081618600026277 | validation: 0.00027326808582151506]
	TIME [epoch: 8.23 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00015653286863489527		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.00015653286863489527 | validation: 0.0005329661478757925]
	TIME [epoch: 8.23 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00016351757649786113		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.00016351757649786113 | validation: 0.00019659410678358213]
	TIME [epoch: 8.24 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00019495191335880624		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.00019495191335880624 | validation: 0.0008722049814622466]
	TIME [epoch: 8.27 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00023590490038817615		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.00023590490038817615 | validation: 0.0002311451370607358]
	TIME [epoch: 8.24 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.096933661501507e-05		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 9.096933661501507e-05 | validation: 0.0006646110678615554]
	TIME [epoch: 8.23 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4522772968062381e-05		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 1.4522772968062381e-05 | validation: 0.00023307873351945574]
	TIME [epoch: 8.24 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00019261298587975781		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.00019261298587975781 | validation: 0.00043682832602421587]
	TIME [epoch: 8.23 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000341318320800525		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.000341318320800525 | validation: 0.00036635314275890445]
	TIME [epoch: 8.25 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00014869716716514646		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.00014869716716514646 | validation: 0.0005610435213998164]
	TIME [epoch: 8.28 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00034577624144885056		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.00034577624144885056 | validation: 0.00020847003715042422]
	TIME [epoch: 8.24 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00018197197268541676		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.00018197197268541676 | validation: 7.770398254003208e-05]
	TIME [epoch: 8.23 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004437999602331593		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.0004437999602331593 | validation: 5.36119512725355e-05]
	TIME [epoch: 8.24 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004104882407586346		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.0004104882407586346 | validation: 0.00039598947779395833]
	TIME [epoch: 8.23 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000189134030605707		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.000189134030605707 | validation: 0.00018577675812476093]
	TIME [epoch: 8.27 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00037613016290648796		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.00037613016290648796 | validation: 0.00015855526183958447]
	TIME [epoch: 8.25 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00026386311748411665		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.00026386311748411665 | validation: 0.00013179565189837828]
	TIME [epoch: 8.23 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.710838187403011e-05		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 5.710838187403011e-05 | validation: 0.0006209506563693771]
	TIME [epoch: 8.23 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00036326613945737306		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.00036326613945737306 | validation: 0.00026910098130400597]
	TIME [epoch: 8.23 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00018017882502064663		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.00018017882502064663 | validation: 0.00047336497128866207]
	TIME [epoch: 8.24 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001756529707617298		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.0001756529707617298 | validation: 0.00011468985609713924]
	TIME [epoch: 8.28 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00022632246296893266		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.00022632246296893266 | validation: 0.00036245623363702074]
	TIME [epoch: 8.23 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002982190957148758		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.0002982190957148758 | validation: 8.178769863395895e-05]
	TIME [epoch: 8.23 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00018498518635025075		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.00018498518635025075 | validation: 0.0002321098604002705]
	TIME [epoch: 8.23 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.714211624800168e-05		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 3.714211624800168e-05 | validation: 0.00018798213854138892]
	TIME [epoch: 8.23 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002757793501305692		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.0002757793501305692 | validation: 0.0008205769050030414]
	TIME [epoch: 8.27 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00017057073920349853		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.00017057073920349853 | validation: 0.0004326982975662217]
	TIME [epoch: 8.25 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00021277590967821203		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.00021277590967821203 | validation: 0.00027347124337005193]
	TIME [epoch: 8.22 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002645535938171895		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.0002645535938171895 | validation: 0.00030461780816296626]
	TIME [epoch: 8.24 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00012275471520807347		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.00012275471520807347 | validation: 0.00031116319765969985]
	TIME [epoch: 8.23 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002577958827364604		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.0002577958827364604 | validation: 0.00032037338948976487]
	TIME [epoch: 8.23 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00022485640311588416		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.00022485640311588416 | validation: 0.000386033541619792]
	TIME [epoch: 8.28 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.622577970261071e-05		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 9.622577970261071e-05 | validation: 0.0001762110795154195]
	TIME [epoch: 8.23 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00022039452910047963		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.00022039452910047963 | validation: 0.0006436486547206668]
	TIME [epoch: 8.23 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00019546631853615935		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.00019546631853615935 | validation: 0.00019115695333531057]
	TIME [epoch: 8.23 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00013753624807144593		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.00013753624807144593 | validation: 0.00047125838000456623]
	TIME [epoch: 8.23 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00024600541608777934		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.00024600541608777934 | validation: 0.00030614224538017345]
	TIME [epoch: 8.25 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00013077863801977486		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.00013077863801977486 | validation: 9.845481972502236e-05]
	TIME [epoch: 8.27 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002707469127254485		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.0002707469127254485 | validation: 0.00025079318531350924]
	TIME [epoch: 8.23 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.998871546605413e-05		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 7.998871546605413e-05 | validation: 0.00019227133637665083]
	TIME [epoch: 8.23 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00015697575273777376		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.00015697575273777376 | validation: 9.470674700911008e-05]
	TIME [epoch: 8.23 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002004147643826848		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.0002004147643826848 | validation: 0.0002441967758314014]
	TIME [epoch: 8.23 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00021538110316393568		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.00021538110316393568 | validation: 0.0005494243028609969]
	TIME [epoch: 8.28 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00013737411067969352		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.00013737411067969352 | validation: 0.0003192395834586836]
	TIME [epoch: 8.24 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003303068735076484		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.0003303068735076484 | validation: 0.00010145368605095673]
	TIME [epoch: 8.23 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00012740603118915962		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.00012740603118915962 | validation: 0.0002544662253696455]
	TIME [epoch: 8.23 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00015191994087917273		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.00015191994087917273 | validation: 0.00042844993430480737]
	TIME [epoch: 8.23 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002326803095740164		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.0002326803095740164 | validation: 0.0003484259483388596]
	TIME [epoch: 8.24 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001150371178824119		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.0001150371178824119 | validation: 0.0003705423112884007]
	TIME [epoch: 8.28 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002912891908015498		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.0002912891908015498 | validation: 0.00022239689259058527]
	TIME [epoch: 8.24 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00028438218451193895		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.00028438218451193895 | validation: 0.0003770948883835548]
	TIME [epoch: 8.22 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002928544778147793		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.0002928544778147793 | validation: 0.0005371084322465114]
	TIME [epoch: 8.24 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00025843474577249827		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.00025843474577249827 | validation: 0.00019306655565338817]
	TIME [epoch: 8.23 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001351901748470501		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.0001351901748470501 | validation: 0.0001756265900836613]
	TIME [epoch: 8.27 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002193080670392391		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.0002193080670392391 | validation: 0.00036599179482549977]
	TIME [epoch: 8.24 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002344317431403715		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.0002344317431403715 | validation: 0.0003978064582842382]
	TIME [epoch: 8.24 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00017408481475227955		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.00017408481475227955 | validation: 0.00042047525756064096]
	TIME [epoch: 8.24 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00018650609401337827		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.00018650609401337827 | validation: 0.0005884255478815045]
	TIME [epoch: 8.23 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00019741509877464346		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.00019741509877464346 | validation: 0.00013437106741804515]
	TIME [epoch: 8.24 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001423434984755134		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.0001423434984755134 | validation: 0.00021081602800342215]
	TIME [epoch: 8.29 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00028120304297529986		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.00028120304297529986 | validation: 0.00014707026013227421]
	TIME [epoch: 8.24 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.611401404913478e-05		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 8.611401404913478e-05 | validation: 0.00015527111380311798]
	TIME [epoch: 8.24 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002511643868142444		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.0002511643868142444 | validation: 0.00046491886743494867]
	TIME [epoch: 8.23 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00022801665861367005		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.00022801665861367005 | validation: 0.0003845217104644263]
	TIME [epoch: 8.23 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00010972553367927018		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.00010972553367927018 | validation: 0.0005605921020766252]
	TIME [epoch: 8.25 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00012842213083043053		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.00012842213083043053 | validation: 0.00016566810079015593]
	TIME [epoch: 8.27 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00011786408439829432		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.00011786408439829432 | validation: 0.0001237761346856896]
	TIME [epoch: 8.23 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00029464415889264784		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.00029464415889264784 | validation: 0.00018304787420433843]
	TIME [epoch: 8.24 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00011167817554838422		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.00011167817554838422 | validation: 0.0001295242791654525]
	TIME [epoch: 8.23 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001379060125855012		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.0001379060125855012 | validation: 0.0005050824123090916]
	TIME [epoch: 8.24 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.703092540915703e-05		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 8.703092540915703e-05 | validation: 0.0010116371822307267]
	TIME [epoch: 8.27 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000163981971898961		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.000163981971898961 | validation: 0.0004349213111367023]
	TIME [epoch: 8.25 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00017124894267767825		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.00017124894267767825 | validation: 0.00047170111689077206]
	TIME [epoch: 8.22 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00014176424633765718		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.00014176424633765718 | validation: 0.00029615620849735615]
	TIME [epoch: 8.24 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00021149891568432834		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.00021149891568432834 | validation: 0.0004873723238121182]
	TIME [epoch: 8.23 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00023713669783175705		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.00023713669783175705 | validation: 0.00034479065529565746]
	TIME [epoch: 8.24 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00025492319588899106		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.00025492319588899106 | validation: 0.00018106828843719123]
	TIME [epoch: 8.27 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00020460189833422705		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.00020460189833422705 | validation: 0.00028973874130640276]
	TIME [epoch: 8.24 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.991887719587411e-05		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 9.991887719587411e-05 | validation: 0.00028240047758713513]
	TIME [epoch: 8.24 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00033162480301615285		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.00033162480301615285 | validation: 0.0001182739102594903]
	TIME [epoch: 8.24 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002106854599496526		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.0002106854599496526 | validation: 0.0005473003474554422]
	TIME [epoch: 8.23 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00026931879842192476		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.00026931879842192476 | validation: 0.0004441573812934463]
	TIME [epoch: 8.27 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.862570638826426e-05		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 6.862570638826426e-05 | validation: 2.8726248959888074e-05]
	TIME [epoch: 8.25 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1646945808107006e-05		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 3.1646945808107006e-05 | validation: 0.0003184477077978762]
	TIME [epoch: 8.24 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00018824086310435107		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.00018824086310435107 | validation: 0.0003929679121665872]
	TIME [epoch: 8.24 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00013848738981445298		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.00013848738981445298 | validation: 0.0001924082933207565]
	TIME [epoch: 8.23 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00019344262852142994		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.00019344262852142994 | validation: 0.00013718741390154944]
	TIME [epoch: 8.23 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00018322171433223812		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.00018322171433223812 | validation: 7.646043691875538e-05]
	TIME [epoch: 8.28 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00043121693119855587		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.00043121693119855587 | validation: 0.0002896603952805981]
	TIME [epoch: 8.24 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00022978786639509433		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.00022978786639509433 | validation: 0.0001942727880964936]
	TIME [epoch: 8.23 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00018865172658091378		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.00018865172658091378 | validation: 0.00041442763675632224]
	TIME [epoch: 8.23 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.199147505548153e-05		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 6.199147505548153e-05 | validation: 0.00044234583256778047]
	TIME [epoch: 8.23 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002566041071937868		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.0002566041071937868 | validation: 8.122646527262044e-05]
	TIME [epoch: 8.25 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00011806904411340203		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.00011806904411340203 | validation: -1.036961647761636e-05]
	TIME [epoch: 8.27 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.358995310197367e-05		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 4.358995310197367e-05 | validation: 0.0002286582804170676]
	TIME [epoch: 8.23 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002903655967546239		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.0002903655967546239 | validation: 0.0005732549608203064]
	TIME [epoch: 8.24 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00025690183833868723		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.00025690183833868723 | validation: 0.00024612340923026464]
	TIME [epoch: 8.23 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00036476477266529097		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.00036476477266529097 | validation: 0.0002547772357163094]
	TIME [epoch: 8.24 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00022227160531204505		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.00022227160531204505 | validation: 0.0003173391898613396]
	TIME [epoch: 8.28 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00016612273685819414		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.00016612273685819414 | validation: 0.00043911365011169856]
	TIME [epoch: 8.25 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002675024790138512		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.0002675024790138512 | validation: 0.00020450314413666517]
	TIME [epoch: 8.23 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000130516806766519		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.000130516806766519 | validation: 0.0001776516840100788]
	TIME [epoch: 8.23 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00015264293650717685		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.00015264293650717685 | validation: 0.0003678260530652988]
	TIME [epoch: 8.23 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001711897970617653		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.0001711897970617653 | validation: 2.0716439871373263e-06]
	TIME [epoch: 8.25 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00018638698974403334		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.00018638698974403334 | validation: 0.0002290525651596633]
	TIME [epoch: 8.28 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00017354878589499777		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.00017354878589499777 | validation: 0.0003786958538712879]
	TIME [epoch: 8.24 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00025361924794212285		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.00025361924794212285 | validation: 0.0004093119934641383]
	TIME [epoch: 8.22 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00014694643448324096		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.00014694643448324096 | validation: 7.476915931749061e-05]
	TIME [epoch: 8.24 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001898506866376828		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.0001898506866376828 | validation: 3.7161107821725986e-05]
	TIME [epoch: 8.23 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00015354703219208068		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.00015354703219208068 | validation: 0.0007624473474481936]
	TIME [epoch: 8.27 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.384312229820968e-05		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 7.384312229820968e-05 | validation: 0.00040439812138867205]
	TIME [epoch: 8.26 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.340705913255131e-05		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 8.340705913255131e-05 | validation: 0.0001671056793834955]
	TIME [epoch: 8.23 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003021251389854773		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.0003021251389854773 | validation: 0.0003180427786001747]
	TIME [epoch: 8.23 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00031167053777968846		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.00031167053777968846 | validation: 0.0004596007280407726]
	TIME [epoch: 8.24 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.947930703852043e-05		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 4.947930703852043e-05 | validation: 0.000374072704226526]
	TIME [epoch: 8.24 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003025256903109286		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.0003025256903109286 | validation: 0.00044789658853288826]
	TIME [epoch: 8.29 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00020951134805609884		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.00020951134805609884 | validation: 0.00038376835257096433]
	TIME [epoch: 8.24 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00023581703586310622		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.00023581703586310622 | validation: 0.0007231410868022366]
	TIME [epoch: 8.23 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00022260622648010252		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.00022260622648010252 | validation: 0.00037551151904109404]
	TIME [epoch: 8.23 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00019029889692773595		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.00019029889692773595 | validation: 0.00019304199321781558]
	TIME [epoch: 8.23 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001617691978227196		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.0001617691978227196 | validation: 0.00019492606987658244]
	TIME [epoch: 8.25 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00027602347877768874		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.00027602347877768874 | validation: 0.000333624813665657]
	TIME [epoch: 8.27 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002485785183928819		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.0002485785183928819 | validation: 8.578349673930675e-05]
	TIME [epoch: 8.23 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002533337786649985		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.0002533337786649985 | validation: 0.00019078989787365953]
	TIME [epoch: 8.23 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00017925553114642013		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.00017925553114642013 | validation: 0.00010650946111616656]
	TIME [epoch: 8.23 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00023939807872665853		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.00023939807872665853 | validation: 0.0004483968350221419]
	TIME [epoch: 8.23 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002067622056786078		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.0002067622056786078 | validation: 0.0003965187439928038]
	TIME [epoch: 8.29 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001601187822542831		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.0001601187822542831 | validation: 0.00025856462849029163]
	TIME [epoch: 8.24 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.384370096168612e-05		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 5.384370096168612e-05 | validation: 0.0002995544972174429]
	TIME [epoch: 8.23 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00018966875927244707		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.00018966875927244707 | validation: 0.00033261247473156356]
	TIME [epoch: 8.23 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00010650463243635144		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.00010650463243635144 | validation: 0.00023230443268735715]
	TIME [epoch: 8.24 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00026190892686415746		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.00026190892686415746 | validation: 0.0002712552414899845]
	TIME [epoch: 8.24 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.502510222823154e-05		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 6.502510222823154e-05 | validation: 0.0003037282003901387]
	TIME [epoch: 8.28 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002011378820363914		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.0002011378820363914 | validation: 0.0002330953493976864]
	TIME [epoch: 8.24 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00023425196758645697		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.00023425196758645697 | validation: 0.000242736240066189]
	TIME [epoch: 8.23 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00029297235153652587		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.00029297235153652587 | validation: 0.0002522230875286979]
	TIME [epoch: 8.24 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001866877388928714		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.0001866877388928714 | validation: 0.0006491751547242952]
	TIME [epoch: 8.24 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003039458690571384		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.0003039458690571384 | validation: 0.0006172688711297969]
	TIME [epoch: 8.28 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00015338285945131513		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.00015338285945131513 | validation: 0.0003015171837323098]
	TIME [epoch: 8.25 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.394180735831248e-05		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 8.394180735831248e-05 | validation: 0.0004035662448383945]
	TIME [epoch: 8.23 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00015124990642590542		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.00015124990642590542 | validation: 0.00024772516741819125]
	TIME [epoch: 8.23 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002706269932105032		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.0002706269932105032 | validation: -4.076190474886765e-05]
	TIME [epoch: 8.23 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00024101542262956976		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.00024101542262956976 | validation: 0.00033309451528777516]
	TIME [epoch: 8.23 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003459952931527641		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.0003459952931527641 | validation: 0.00028563735682159396]
	TIME [epoch: 8.29 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.201403573950029e-05		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 8.201403573950029e-05 | validation: 8.628253194980129e-05]
	TIME [epoch: 8.23 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001574403513679812		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.0001574403513679812 | validation: 0.00040627151701553817]
	TIME [epoch: 8.23 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001282945083813758		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.0001282945083813758 | validation: 0.0004829377370337769]
	TIME [epoch: 8.23 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00013379538758756017		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.00013379538758756017 | validation: 0.0006926818185944779]
	TIME [epoch: 8.23 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002255749495304664		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.0002255749495304664 | validation: 0.0003203389706283746]
	TIME [epoch: 8.25 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001637134206809754		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.0001637134206809754 | validation: 0.0005957059830828922]
	TIME [epoch: 8.27 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0996782623034436e-05		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 6.0996782623034436e-05 | validation: 0.00030725160493962186]
	TIME [epoch: 8.23 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.642341174307333e-05		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 9.642341174307333e-05 | validation: 0.0002754749239574617]
	TIME [epoch: 8.24 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.12420815523134e-05		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 9.12420815523134e-05 | validation: 0.0008186513862463559]
	TIME [epoch: 8.24 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00026201040045234427		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.00026201040045234427 | validation: 6.635123617086958e-05]
	TIME [epoch: 8.24 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003331046180638362		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.0003331046180638362 | validation: 0.0001457893137713544]
	TIME [epoch: 8.27 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001625876804180282		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.0001625876804180282 | validation: 0.0003634710168972468]
	TIME [epoch: 8.25 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000260418976057194		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.000260418976057194 | validation: 0.0003866928010015567]
	TIME [epoch: 8.24 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.962133133396864e-05		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 5.962133133396864e-05 | validation: 5.5117397981825346e-05]
	TIME [epoch: 8.24 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003724110394191169		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.0003724110394191169 | validation: 0.00047766705019921044]
	TIME [epoch: 8.24 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00019094215500511404		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.00019094215500511404 | validation: 0.0006200562929426238]
	TIME [epoch: 8.24 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00012895391540799795		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.00012895391540799795 | validation: 0.0005483714900782699]
	TIME [epoch: 8.29 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00020805099360600887		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.00020805099360600887 | validation: 0.00048571132148718377]
	TIME [epoch: 8.23 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3912189102016422e-05		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 2.3912189102016422e-05 | validation: 0.0002105426437678446]
	TIME [epoch: 8.24 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00018472204869623111		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.00018472204869623111 | validation: 0.000744586016027733]
	TIME [epoch: 8.24 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00021140654374574578		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.00021140654374574578 | validation: 0.0005815748891299055]
	TIME [epoch: 8.24 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00020066814397661916		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.00020066814397661916 | validation: 0.00017889334160162563]
	TIME [epoch: 8.28 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00024002587833285994		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.00024002587833285994 | validation: 0.00026506565790623425]
	TIME [epoch: 8.25 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002722054653001129		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.0002722054653001129 | validation: 0.0005021529216266085]
	TIME [epoch: 8.25 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00013798035882594517		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.00013798035882594517 | validation: 0.000288016840773901]
	TIME [epoch: 8.24 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00011830719235411968		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.00011830719235411968 | validation: 0.0003873512567028277]
	TIME [epoch: 8.24 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00010835073623055759		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.00010835073623055759 | validation: 0.0003860165094803705]
	TIME [epoch: 8.23 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002685647417009629		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.0002685647417009629 | validation: 0.0001473900447653236]
	TIME [epoch: 8.29 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00023054362889858893		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.00023054362889858893 | validation: 0.0006405962945854684]
	TIME [epoch: 8.24 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.658256445496206e-05		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 9.658256445496206e-05 | validation: 0.00038017801819506666]
	TIME [epoch: 8.23 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00021687123493497685		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.00021687123493497685 | validation: 0.00041467816639342647]
	TIME [epoch: 8.23 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00012570814400837072		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.00012570814400837072 | validation: 0.0004873379617064719]
	TIME [epoch: 8.23 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00023888427356616736		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.00023888427356616736 | validation: 0.0003617309543123613]
	TIME [epoch: 8.25 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003074560795091741		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.0003074560795091741 | validation: 0.0002937580865685572]
	TIME [epoch: 8.27 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00022456130344811442		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.00022456130344811442 | validation: 0.0007258515436550175]
	TIME [epoch: 8.24 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002717605088997992		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.0002717605088997992 | validation: 0.00034262484885105946]
	TIME [epoch: 8.22 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00011043910382761224		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.00011043910382761224 | validation: 0.000283031449024155]
	TIME [epoch: 8.24 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00017757889245056835		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.00017757889245056835 | validation: 0.00030755866990811144]
	TIME [epoch: 8.24 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000226067145410493		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.000226067145410493 | validation: -3.803639062296682e-05]
	TIME [epoch: 8.28 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.998335772714096e-05		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 8.998335772714096e-05 | validation: 0.00012092191337199229]
	TIME [epoch: 8.25 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002958071520921979		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.0002958071520921979 | validation: 0.00018363673387396771]
	TIME [epoch: 8.24 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.18355356693925e-05		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 8.18355356693925e-05 | validation: 0.0002425911664448277]
	TIME [epoch: 8.24 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00026759279731105505		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.00026759279731105505 | validation: 0.0009996534949190785]
	TIME [epoch: 8.23 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002369135732802157		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.0002369135732802157 | validation: 0.00038031319655772313]
	TIME [epoch: 8.24 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001382144421799396		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.0001382144421799396 | validation: 7.523616297990188e-05]
	TIME [epoch: 8.28 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001353076360788079		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.0001353076360788079 | validation: 0.00027866446319870517]
	TIME [epoch: 8.24 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.300565750016741e-05		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 6.300565750016741e-05 | validation: 0.00046375275527633876]
	TIME [epoch: 8.23 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001515063500760674		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.0001515063500760674 | validation: 0.0006584569716333437]
	TIME [epoch: 8.24 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000280658204923419		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.000280658204923419 | validation: 0.0003017332496780778]
	TIME [epoch: 8.23 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002221152365129777		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.0002221152365129777 | validation: 0.0001480100391426209]
	TIME [epoch: 8.28 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002284216247559634		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.0002284216247559634 | validation: 0.00023659618694799267]
	TIME [epoch: 8.25 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001381066638224273		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.0001381066638224273 | validation: -4.401340342541982e-05]
	TIME [epoch: 8.23 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00016166262367930086		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.00016166262367930086 | validation: 0.0001294363838108259]
	TIME [epoch: 8.23 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00020399051511824307		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.00020399051511824307 | validation: 6.947135240186242e-05]
	TIME [epoch: 8.24 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003211752978336351		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.0003211752978336351 | validation: 0.0002090175890118937]
	TIME [epoch: 8.23 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00014420780778728504		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.00014420780778728504 | validation: 0.00013769288924194887]
	TIME [epoch: 8.29 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00025645785072716864		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.00025645785072716864 | validation: 0.0004787424031711938]
	TIME [epoch: 8.22 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4136853650573725e-05		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 2.4136853650573725e-05 | validation: 0.000332133368679334]
	TIME [epoch: 8.23 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00010203439953200033		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.00010203439953200033 | validation: 0.0006088472227510975]
	TIME [epoch: 8.23 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00018731161095878246		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.00018731161095878246 | validation: 0.00011733838784205907]
	TIME [epoch: 8.23 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002686926721918779		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.0002686926721918779 | validation: 0.0007128946458597109]
	TIME [epoch: 8.26 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00024370739612804805		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.00024370739612804805 | validation: -2.5850694767113325e-05]
	TIME [epoch: 8.28 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.990192639112495e-05		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 9.990192639112495e-05 | validation: 0.0004940307488742999]
	TIME [epoch: 8.24 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00022490803997186128		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.00022490803997186128 | validation: 0.00020503288101666062]
	TIME [epoch: 8.23 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: -1.471531816230965e-05		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: -1.471531816230965e-05 | validation: 0.00012732767529691815]
	TIME [epoch: 8.23 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00017867010655954796		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.00017867010655954796 | validation: 0.0001245796528271761]
	TIME [epoch: 8.23 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00019541273397307246		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.00019541273397307246 | validation: 0.0001834729638627186]
	TIME [epoch: 8.28 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: -9.782458401597289e-08		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: -9.782458401597289e-08 | validation: 8.771994025591034e-05]
	TIME [epoch: 8.24 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00030706211290313344		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.00030706211290313344 | validation: 0.00036367319547799237]
	TIME [epoch: 8.21 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00012002497648202625		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.00012002497648202625 | validation: 0.00017549495022181817]
	TIME [epoch: 8.21 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00013184810235494516		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.00013184810235494516 | validation: 8.829534009699991e-05]
	TIME [epoch: 8.22 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00021554341335653393		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.00021554341335653393 | validation: 0.0008412039507464408]
	TIME [epoch: 8.21 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00011154396293385906		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.00011154396293385906 | validation: 0.0005865220008574976]
	TIME [epoch: 8.25 sec]
Finished training in 17615.789 seconds.
