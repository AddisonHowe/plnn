Args:
Namespace(name='model_phi1_1a_v1', outdir='out/model_training/model_phi1_1a_v1', training_data='data/training_data/data_phi1_1a/training', validation_data='data/training_data/data_phi1_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3919707562

Training model...

Saving initial model state to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 12.19466285613234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.19466285613234 | validation: 12.524460744850114]
	TIME [epoch: 119 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.658275070719903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.658275070719903 | validation: 11.602438747027929]
	TIME [epoch: 6.34 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.948625904410816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.948625904410816 | validation: 11.580398437580406]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.530792127563327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.530792127563327 | validation: 11.40200625470208]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.301278164946606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.301278164946606 | validation: 11.269154653220834]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.877308587852376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.877308587852376 | validation: 10.908719355815448]
	TIME [epoch: 6.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.560019431133338		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.560019431133338 | validation: 11.02356926476638]
	TIME [epoch: 6.25 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.437239558229653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.437239558229653 | validation: 10.604839822888856]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.777356711241634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.777356711241634 | validation: 10.896773908414556]
	TIME [epoch: 6.25 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.52023847908546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.52023847908546 | validation: 8.282952289134672]
	TIME [epoch: 6.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.164170500560901		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.164170500560901 | validation: 8.271358532243493]
	TIME [epoch: 6.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.98192609477244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.98192609477244 | validation: 8.198222711424613]
	TIME [epoch: 6.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.021849843859711		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.021849843859711 | validation: 8.031083797312155]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.75625737624656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.75625737624656 | validation: 8.086214946319707]
	TIME [epoch: 6.25 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.729402762281662		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.729402762281662 | validation: 7.695136834501298]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.4961210296821665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.4961210296821665 | validation: 7.573074607549338]
	TIME [epoch: 6.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.35763523549016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.35763523549016 | validation: 7.527245787990653]
	TIME [epoch: 6.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.436601418164028		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.436601418164028 | validation: 7.642489971432581]
	TIME [epoch: 6.27 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.343950556161351		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.343950556161351 | validation: 7.346743669734846]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.155345549722238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.155345549722238 | validation: 7.3514424825764895]
	TIME [epoch: 6.26 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.237778858493584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.237778858493584 | validation: 7.333628014957196]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.288268950531923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.288268950531923 | validation: 7.350608686295555]
	TIME [epoch: 6.26 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.09016241745569		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.09016241745569 | validation: 7.27656943835599]
	TIME [epoch: 6.32 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.986113174185327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.986113174185327 | validation: 7.610552829281799]
	TIME [epoch: 6.25 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0965265886838775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.0965265886838775 | validation: 7.217529671916632]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.996634545280097		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.996634545280097 | validation: 7.162321983538079]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9803837378968385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.9803837378968385 | validation: 7.263739088062829]
	TIME [epoch: 6.25 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.161444160882366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.161444160882366 | validation: 7.256162936651448]
	TIME [epoch: 6.28 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.022495838600394		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.022495838600394 | validation: 7.0581079236128215]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.009628314515867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.009628314515867 | validation: 7.1121207063591445]
	TIME [epoch: 6.25 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.163037502125036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.163037502125036 | validation: 7.1522986939246564]
	TIME [epoch: 6.25 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.991925560367378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.991925560367378 | validation: 7.180069693283031]
	TIME [epoch: 6.24 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.898310299044763		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.898310299044763 | validation: 7.076860696419569]
	TIME [epoch: 6.24 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.919807452114931		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.919807452114931 | validation: 7.432917097316834]
	TIME [epoch: 6.28 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.994397168436189		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.994397168436189 | validation: 7.099022905582149]
	TIME [epoch: 6.27 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.886748403641429		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.886748403641429 | validation: 7.450050201423796]
	TIME [epoch: 6.26 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0226551745841395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.0226551745841395 | validation: 6.992118580974291]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8429282282379145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8429282282379145 | validation: 6.9325810213211545]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.760571660959693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.760571660959693 | validation: 7.194388580406253]
	TIME [epoch: 6.25 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.794391608955607		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.794391608955607 | validation: 6.984306667508719]
	TIME [epoch: 6.28 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.714945042175449		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.714945042175449 | validation: 6.950300053126845]
	TIME [epoch: 6.27 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8436547079376755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8436547079376755 | validation: 7.0902406076400535]
	TIME [epoch: 6.24 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.212261112949373		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.212261112949373 | validation: 7.0047634170649244]
	TIME [epoch: 6.26 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6759019803643485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6759019803643485 | validation: 7.444448991139698]
	TIME [epoch: 6.25 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.852339274542704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.852339274542704 | validation: 6.940137811575449]
	TIME [epoch: 6.25 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.74300039034148		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.74300039034148 | validation: 7.073603346841816]
	TIME [epoch: 6.29 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.661363694026987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.661363694026987 | validation: 6.873389179931063]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.621909317528317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.621909317528317 | validation: 6.909687470451187]
	TIME [epoch: 6.24 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.609876544190933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.609876544190933 | validation: 7.186581425341469]
	TIME [epoch: 6.24 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.699838875703173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.699838875703173 | validation: 6.929142902364335]
	TIME [epoch: 6.25 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.557643237625027		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 5.557643237625027 | validation: 6.884227667451183]
	TIME [epoch: 6.25 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.663657655368781		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 5.663657655368781 | validation: 7.218516084064604]
	TIME [epoch: 6.29 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.731931525947951		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 5.731931525947951 | validation: 6.869809701693811]
	TIME [epoch: 6.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.561771013245789		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 5.561771013245789 | validation: 6.844793592862066]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.559115077295976		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 5.559115077295976 | validation: 6.910090746897085]
	TIME [epoch: 6.24 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.868626490011462		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 5.868626490011462 | validation: 6.855727604194579]
	TIME [epoch: 6.25 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.726792357796738		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 5.726792357796738 | validation: 6.844963109394108]
	TIME [epoch: 6.25 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.59052919112662		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 5.59052919112662 | validation: 7.355646674664926]
	TIME [epoch: 6.29 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.612242806777669		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 5.612242806777669 | validation: 6.906249263073101]
	TIME [epoch: 6.25 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.505871604904411		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 5.505871604904411 | validation: 6.891969804017991]
	TIME [epoch: 6.24 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.681875455672575		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 5.681875455672575 | validation: 6.88981392958784]
	TIME [epoch: 6.25 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.750010481439787		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 5.750010481439787 | validation: 6.980934085700774]
	TIME [epoch: 6.24 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.646939359191434		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 5.646939359191434 | validation: 6.791204553696263]
	TIME [epoch: 6.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.454869182885711		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 5.454869182885711 | validation: 6.942457780113276]
	TIME [epoch: 6.31 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.444941086024201		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 5.444941086024201 | validation: 6.877944659592716]
	TIME [epoch: 6.25 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.387622227605369		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 5.387622227605369 | validation: 7.036089383422945]
	TIME [epoch: 6.26 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6270829315538675		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 5.6270829315538675 | validation: 6.814729374914979]
	TIME [epoch: 6.25 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.462659686975681		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 5.462659686975681 | validation: 6.81226007833331]
	TIME [epoch: 6.25 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.413411560821461		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 5.413411560821461 | validation: 6.950255147151911]
	TIME [epoch: 6.26 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.5262324951087445		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 5.5262324951087445 | validation: 6.806768568957366]
	TIME [epoch: 6.29 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.645704440979939		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 5.645704440979939 | validation: 6.784377880162486]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.434660080051715		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 5.434660080051715 | validation: 6.762337581656368]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.437149645070468		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 5.437149645070468 | validation: 6.824162207912945]
	TIME [epoch: 6.25 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.391100054067042		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 5.391100054067042 | validation: 6.844894073534121]
	TIME [epoch: 6.24 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.390879416791733		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 5.390879416791733 | validation: 6.916768543600163]
	TIME [epoch: 6.28 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.363180679550925		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 5.363180679550925 | validation: 6.79295784899797]
	TIME [epoch: 6.27 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.3878204453676		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 5.3878204453676 | validation: 6.806969562067565]
	TIME [epoch: 6.25 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.345899071548259		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 5.345899071548259 | validation: 6.785437256555657]
	TIME [epoch: 6.25 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.414676515625436		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 5.414676515625436 | validation: 6.733719838827042]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.381311274447343		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 5.381311274447343 | validation: 6.759153364157189]
	TIME [epoch: 6.25 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.320943723090359		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 5.320943723090359 | validation: 6.870961578011514]
	TIME [epoch: 6.3 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.4372704999665356		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 5.4372704999665356 | validation: 6.698963976216669]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.3111115715696275		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 5.3111115715696275 | validation: 6.849879978739287]
	TIME [epoch: 6.25 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.404185114315575		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 5.404185114315575 | validation: 6.687852894255218]
	TIME [epoch: 6.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.280080406443714		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 5.280080406443714 | validation: 6.677965341605299]
	TIME [epoch: 6.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.4487853721740365		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 5.4487853721740365 | validation: 6.876091090563733]
	TIME [epoch: 6.25 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.267001414023472		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 5.267001414023472 | validation: 6.67466292229089]
	TIME [epoch: 6.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.300724850281242		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 5.300724850281242 | validation: 6.825073280059407]
	TIME [epoch: 6.25 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.279369097638085		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 5.279369097638085 | validation: 6.654068655119992]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.2800535764524055		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 5.2800535764524055 | validation: 6.7796613338733085]
	TIME [epoch: 6.24 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.389234119583617		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 5.389234119583617 | validation: 6.825651889924966]
	TIME [epoch: 6.24 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.282794778286065		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 5.282794778286065 | validation: 6.900876259366543]
	TIME [epoch: 6.25 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.332813882025013		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 5.332813882025013 | validation: 6.747340738651994]
	TIME [epoch: 6.29 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.240406881355092		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 5.240406881355092 | validation: 7.1412115551433715]
	TIME [epoch: 6.24 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.444704631864598		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 5.444704631864598 | validation: 6.806966410323017]
	TIME [epoch: 6.24 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.279329778067249		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 5.279329778067249 | validation: 6.7895428044445945]
	TIME [epoch: 6.24 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.419841033378747		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 5.419841033378747 | validation: 6.6411312749230245]
	TIME [epoch: 6.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.329969651638879		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 5.329969651638879 | validation: 6.636649463323117]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.19202921486819		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 5.19202921486819 | validation: 6.729288046217564]
	TIME [epoch: 6.28 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.239539255829303		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 5.239539255829303 | validation: 6.615331606627972]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.191011919426719		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 5.191011919426719 | validation: 6.658069590822189]
	TIME [epoch: 6.24 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.197895334913879		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 5.197895334913879 | validation: 6.741967618223574]
	TIME [epoch: 6.24 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.2331850987962785		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 5.2331850987962785 | validation: 6.608062026754807]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.119583561779286		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 5.119583561779286 | validation: 6.8084279988495275]
	TIME [epoch: 6.27 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.297415007701286		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 5.297415007701286 | validation: 6.589039273506691]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_105.pth
	Model improved!!!
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.147174349627207		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 5.147174349627207 | validation: 6.940315069006898]
	TIME [epoch: 6.26 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.227208035703407		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 5.227208035703407 | validation: 6.539283551004817]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.124408911985855		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 5.124408911985855 | validation: 6.56019200270896]
	TIME [epoch: 6.25 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.094616153573819		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 5.094616153573819 | validation: 6.492721490723008]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.030995274170967		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 5.030995274170967 | validation: 6.709084981724386]
	TIME [epoch: 6.29 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.137226749524388		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 5.137226749524388 | validation: 6.509630681519538]
	TIME [epoch: 6.25 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.07942366361416		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 5.07942366361416 | validation: 6.430947716967021]
	TIME [epoch: 6.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_112.pth
	Model improved!!!
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.0118183694031115		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 5.0118183694031115 | validation: 6.333732900981969]
	TIME [epoch: 6.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_113.pth
	Model improved!!!
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.936835589951858		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 4.936835589951858 | validation: 6.487181795663659]
	TIME [epoch: 6.25 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.950443767449985		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 4.950443767449985 | validation: 6.347180191384565]
	TIME [epoch: 6.25 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.015232512598441		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 5.015232512598441 | validation: 6.390086190693788]
	TIME [epoch: 6.29 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.863944544301833		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 4.863944544301833 | validation: 6.260541115692581]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.90408850622517		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 4.90408850622517 | validation: 6.263363483829162]
	TIME [epoch: 6.25 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.639167785895683		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 4.639167785895683 | validation: 6.4094263950105415]
	TIME [epoch: 6.24 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.791614154113023		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 4.791614154113023 | validation: 6.595507970308532]
	TIME [epoch: 6.24 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.795046278933132		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 4.795046278933132 | validation: 6.238362049652833]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.670694625522706		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 4.670694625522706 | validation: 6.331552410294908]
	TIME [epoch: 6.28 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.731530473021477		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 4.731530473021477 | validation: 6.025773019834985]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_123.pth
	Model improved!!!
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4617998113270785		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 4.4617998113270785 | validation: 6.054501005330781]
	TIME [epoch: 6.25 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.425164481449425		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 4.425164481449425 | validation: 6.029275569805495]
	TIME [epoch: 6.24 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.401812535039493		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 4.401812535039493 | validation: 6.049977334470951]
	TIME [epoch: 6.24 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.341355423422009		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 4.341355423422009 | validation: 5.920605776648529]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_127.pth
	Model improved!!!
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.395780095059204		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 4.395780095059204 | validation: 5.827189023802694]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.270591212068876		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 4.270591212068876 | validation: 5.691078541859241]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_129.pth
	Model improved!!!
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.286972398485306		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 4.286972398485306 | validation: 5.795216617090249]
	TIME [epoch: 6.25 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.206716708067843		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 4.206716708067843 | validation: 5.732563705252973]
	TIME [epoch: 6.23 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.187309499577954		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 4.187309499577954 | validation: 5.727348724732197]
	TIME [epoch: 6.24 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0827398981402485		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 4.0827398981402485 | validation: 5.74155723844872]
	TIME [epoch: 6.27 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.126112672634601		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 4.126112672634601 | validation: 5.412876075718912]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_134.pth
	Model improved!!!
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9985693989396967		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 3.9985693989396967 | validation: 5.532364147499274]
	TIME [epoch: 6.25 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9474839466028193		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 3.9474839466028193 | validation: 6.151811631957754]
	TIME [epoch: 6.25 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9636535482259454		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 3.9636535482259454 | validation: 5.508233933566065]
	TIME [epoch: 6.24 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.686729018009644		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 3.686729018009644 | validation: 4.686931689190741]
	TIME [epoch: 6.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_138.pth
	Model improved!!!
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.72076349114159		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 4.72076349114159 | validation: 4.623308992212394]
	TIME [epoch: 6.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_139.pth
	Model improved!!!
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2919186882873994		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 3.2919186882873994 | validation: 3.9972068406419012]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_140.pth
	Model improved!!!
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6042446862850825		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 2.6042446862850825 | validation: 3.4631772540417556]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.780002384830591		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 2.780002384830591 | validation: 2.616348549887151]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_142.pth
	Model improved!!!
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9557222789597066		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.9557222789597066 | validation: 2.646002635184582]
	TIME [epoch: 6.25 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.100946948270466		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 2.100946948270466 | validation: 4.617016561115799]
	TIME [epoch: 6.28 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2757257089067875		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 3.2757257089067875 | validation: 2.6800166395404537]
	TIME [epoch: 6.27 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4985220588804777		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 2.4985220588804777 | validation: 2.49272473929687]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_146.pth
	Model improved!!!
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.059957077061385		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 2.059957077061385 | validation: 2.730175150913903]
	TIME [epoch: 6.25 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9777571568303978		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.9777571568303978 | validation: 1.9125888462795833]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_148.pth
	Model improved!!!
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7298222607147125		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.7298222607147125 | validation: 1.6810886038952404]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_149.pth
	Model improved!!!
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.946919871366587		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.946919871366587 | validation: 2.126580705516138]
	TIME [epoch: 6.28 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4802444655054905		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 2.4802444655054905 | validation: 3.394293724344724]
	TIME [epoch: 6.26 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.533061105353661		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 2.533061105353661 | validation: 1.8080982398564682]
	TIME [epoch: 6.24 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9268675577862107		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.9268675577862107 | validation: 2.249224367334347]
	TIME [epoch: 6.24 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3085107404252208		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 2.3085107404252208 | validation: 2.2799285447707343]
	TIME [epoch: 6.24 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8806499365243992		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.8806499365243992 | validation: 2.0316909058660855]
	TIME [epoch: 6.24 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6188357309033687		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 2.6188357309033687 | validation: 2.361510826243359]
	TIME [epoch: 6.27 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9079637263828286		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 1.9079637263828286 | validation: 1.6313524875732552]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_157.pth
	Model improved!!!
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.01702348268123		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 2.01702348268123 | validation: 1.8653593782983453]
	TIME [epoch: 6.24 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7157320875626756		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 1.7157320875626756 | validation: 1.8427820302931128]
	TIME [epoch: 6.24 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5019370613619323		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.5019370613619323 | validation: 1.8513453511672473]
	TIME [epoch: 6.23 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.802861941182217		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.802861941182217 | validation: 1.4593918924226732]
	TIME [epoch: 6.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_161.pth
	Model improved!!!
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9101224191215365		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.9101224191215365 | validation: 2.015465588398287]
	TIME [epoch: 6.28 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6229235785069287		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.6229235785069287 | validation: 2.0175105835431655]
	TIME [epoch: 6.25 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7138791115281056		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 1.7138791115281056 | validation: 1.602683766119903]
	TIME [epoch: 6.25 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6581925618221263		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.6581925618221263 | validation: 1.3270664235242446]
	TIME [epoch: 6.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_165.pth
	Model improved!!!
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3388303294870434		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 1.3388303294870434 | validation: 2.183278401950873]
	TIME [epoch: 6.24 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7520725517365734		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.7520725517365734 | validation: 1.3356065967209632]
	TIME [epoch: 6.24 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3815248693628677		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.3815248693628677 | validation: 1.285374127123728]
	TIME [epoch: 6.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_168.pth
	Model improved!!!
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3073187255726393		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 2.3073187255726393 | validation: 2.779761530611921]
	TIME [epoch: 6.24 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.901286290650706		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.901286290650706 | validation: 3.2788557579487416]
	TIME [epoch: 6.24 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1205946070013972		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 2.1205946070013972 | validation: 1.6861058320305256]
	TIME [epoch: 6.23 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4767346424053884		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.4767346424053884 | validation: 1.6916709917930923]
	TIME [epoch: 6.23 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.559021756791182		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.559021756791182 | validation: 2.7783175754507816]
	TIME [epoch: 6.25 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8271782772374312		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.8271782772374312 | validation: 1.6437717940071566]
	TIME [epoch: 6.28 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7680938344736437		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 1.7680938344736437 | validation: 1.5779453281501798]
	TIME [epoch: 6.24 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3446650385487735		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 1.3446650385487735 | validation: 1.2298259425263987]
	TIME [epoch: 6.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_176.pth
	Model improved!!!
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2663045112456706		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.2663045112456706 | validation: 3.2736061871324598]
	TIME [epoch: 6.26 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6331300087741094		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 3.6331300087741094 | validation: 2.3089048086756727]
	TIME [epoch: 6.25 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4306814088023916		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 1.4306814088023916 | validation: 3.271091387844277]
	TIME [epoch: 6.27 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9454308416776767		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 1.9454308416776767 | validation: 1.3112270140585116]
	TIME [epoch: 6.28 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7175205949233554		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 1.7175205949233554 | validation: 1.3564355787186502]
	TIME [epoch: 6.26 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4301577307216777		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 1.4301577307216777 | validation: 1.7586298114854746]
	TIME [epoch: 6.25 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4329064073912667		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 1.4329064073912667 | validation: 1.018271449904508]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_183.pth
	Model improved!!!
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2051772672824517		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 1.2051772672824517 | validation: 1.1169225225336055]
	TIME [epoch: 6.26 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0856766946066696		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 1.0856766946066696 | validation: 1.1132088325289953]
	TIME [epoch: 6.28 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1575888594294566		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 1.1575888594294566 | validation: 0.962001367665635]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_186.pth
	Model improved!!!
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2648438910526072		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 1.2648438910526072 | validation: 2.0009057592677943]
	TIME [epoch: 6.26 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4912941709090206		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 1.4912941709090206 | validation: 2.1723035857535065]
	TIME [epoch: 6.26 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.771788351053727		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 1.771788351053727 | validation: 1.611928156777372]
	TIME [epoch: 6.25 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1949448855416032		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 1.1949448855416032 | validation: 0.8579097594048304]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_190.pth
	Model improved!!!
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0743468560691278		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 1.0743468560691278 | validation: 1.1604099202035323]
	TIME [epoch: 6.29 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1663440818469932		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 1.1663440818469932 | validation: 2.4817465647758024]
	TIME [epoch: 6.26 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5405581547676364		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 1.5405581547676364 | validation: 2.8735426172114464]
	TIME [epoch: 6.25 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5841892933126362		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 1.5841892933126362 | validation: 2.0735280799729034]
	TIME [epoch: 6.24 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7616435555282828		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 1.7616435555282828 | validation: 1.2896548923437]
	TIME [epoch: 6.24 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5020967038891848		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 1.5020967038891848 | validation: 2.1273449945294596]
	TIME [epoch: 6.25 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6695208078047863		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 1.6695208078047863 | validation: 1.6528641575402048]
	TIME [epoch: 6.29 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3767462741116292		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 1.3767462741116292 | validation: 2.4552315892520653]
	TIME [epoch: 6.27 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7649057795364715		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 1.7649057795364715 | validation: 1.0104223645970063]
	TIME [epoch: 6.25 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0445279801680019		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 1.0445279801680019 | validation: 2.6414428156242593]
	TIME [epoch: 6.26 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3471974466027676		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 1.3471974466027676 | validation: 1.4499531111600068]
	TIME [epoch: 6.25 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9727237744988728		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.9727237744988728 | validation: 0.8452110173671994]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_202.pth
	Model improved!!!
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8470528506055218		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.8470528506055218 | validation: 1.5597640585155945]
	TIME [epoch: 6.29 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2312346007472033		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 1.2312346007472033 | validation: 1.1196744662107998]
	TIME [epoch: 6.25 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1369488767481133		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 1.1369488767481133 | validation: 1.0203735609926865]
	TIME [epoch: 6.24 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.095634555621321		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 1.095634555621321 | validation: 0.7995263453889986]
	TIME [epoch: 6.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_206.pth
	Model improved!!!
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0287266102538606		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 1.0287266102538606 | validation: 0.7037506954082671]
	TIME [epoch: 6.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_207.pth
	Model improved!!!
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0369053479484875		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 1.0369053479484875 | validation: 2.2466331785269]
	TIME [epoch: 6.25 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.176074929435606		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 1.176074929435606 | validation: 0.993544985104295]
	TIME [epoch: 6.29 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9887250461078188		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.9887250461078188 | validation: 0.6749984660713335]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_210.pth
	Model improved!!!
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8139473045239113		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.8139473045239113 | validation: 0.9779669765524713]
	TIME [epoch: 6.25 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8488035678177477		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.8488035678177477 | validation: 1.427923874050688]
	TIME [epoch: 6.24 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9761397336041491		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.9761397336041491 | validation: 0.5300054762601946]
	TIME [epoch: 6.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_213.pth
	Model improved!!!
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7886351957961562		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.7886351957961562 | validation: 0.9637736097984123]
	TIME [epoch: 6.26 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1219541188784288		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 1.1219541188784288 | validation: 1.2537523899061846]
	TIME [epoch: 6.28 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8788311075296051		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.8788311075296051 | validation: 0.8919548564519904]
	TIME [epoch: 6.24 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1766760203036668		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 1.1766760203036668 | validation: 1.896935074240302]
	TIME [epoch: 6.24 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4424696181104881		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 1.4424696181104881 | validation: 1.3332231068821763]
	TIME [epoch: 6.24 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7916842208717216		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.7916842208717216 | validation: 0.5486621555269307]
	TIME [epoch: 6.24 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6896630882136714		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.6896630882136714 | validation: 1.5644422419486959]
	TIME [epoch: 6.25 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9783810851728929		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.9783810851728929 | validation: 0.647814467929946]
	TIME [epoch: 6.28 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1454525903724015		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 1.1454525903724015 | validation: 1.0825090697810216]
	TIME [epoch: 6.24 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1721777637671633		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 1.1721777637671633 | validation: 0.727606207699921]
	TIME [epoch: 6.24 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7935512656429995		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.7935512656429995 | validation: 0.7129411353517927]
	TIME [epoch: 6.24 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7682917313343		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.7682917313343 | validation: 0.5647501283903829]
	TIME [epoch: 6.24 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5835276870236836		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.5835276870236836 | validation: 0.6463784816950797]
	TIME [epoch: 6.26 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6232608246393356		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.6232608246393356 | validation: 1.0196556935056231]
	TIME [epoch: 6.27 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.882473234101266		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.882473234101266 | validation: 1.3860274450583963]
	TIME [epoch: 6.24 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9608708636294817		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.9608708636294817 | validation: 0.9103190262087937]
	TIME [epoch: 6.24 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0557884083881464		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 1.0557884083881464 | validation: 0.737430320090289]
	TIME [epoch: 6.24 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8633968278075052		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.8633968278075052 | validation: 0.5337356335821037]
	TIME [epoch: 6.24 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6477451558868143		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.6477451558868143 | validation: 1.2824417505125438]
	TIME [epoch: 6.26 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9804908583708786		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.9804908583708786 | validation: 0.7700658801417868]
	TIME [epoch: 6.27 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8344715192385814		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.8344715192385814 | validation: 0.5360649113515458]
	TIME [epoch: 6.24 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6019018295926608		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.6019018295926608 | validation: 0.5371695890787653]
	TIME [epoch: 6.24 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7817748470653543		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.7817748470653543 | validation: 0.9658955924454627]
	TIME [epoch: 6.24 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7926980620340587		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.7926980620340587 | validation: 0.6146166095933212]
	TIME [epoch: 6.24 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8106410016246373		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.8106410016246373 | validation: 0.6036098874883724]
	TIME [epoch: 6.26 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7325449489191392		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.7325449489191392 | validation: 0.6092408689286801]
	TIME [epoch: 6.26 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8594160713558511		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.8594160713558511 | validation: 0.731639835502141]
	TIME [epoch: 6.24 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7154331998099851		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.7154331998099851 | validation: 0.5946152395634126]
	TIME [epoch: 6.24 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6854031101655631		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.6854031101655631 | validation: 0.5893620608242403]
	TIME [epoch: 6.24 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5676961866142899		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.5676961866142899 | validation: 1.0828821446712948]
	TIME [epoch: 6.24 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7557253631014538		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.7557253631014538 | validation: 0.9027603050381625]
	TIME [epoch: 6.27 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7010962863660049		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.7010962863660049 | validation: 0.6466336958743772]
	TIME [epoch: 6.25 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5959533024706695		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.5959533024706695 | validation: 0.9455188653279835]
	TIME [epoch: 6.24 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7413770727691814		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.7413770727691814 | validation: 1.042949664469253]
	TIME [epoch: 6.24 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8764424380961586		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.8764424380961586 | validation: 0.4538538420192765]
	TIME [epoch: 6.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_248.pth
	Model improved!!!
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5059070705012447		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.5059070705012447 | validation: 0.8109127480780391]
	TIME [epoch: 6.25 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.570041799007124		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.570041799007124 | validation: 0.39008263093072043]
	TIME [epoch: 6.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_250.pth
	Model improved!!!
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9442570468669529		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.9442570468669529 | validation: 0.5735907891303927]
	TIME [epoch: 6.26 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5130912308107779		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.5130912308107779 | validation: 0.8833963320127912]
	TIME [epoch: 6.25 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7422890344543287		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.7422890344543287 | validation: 0.6280304454259544]
	TIME [epoch: 6.24 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7575326198833788		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.7575326198833788 | validation: 0.774549734491454]
	TIME [epoch: 6.25 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5695847581057815		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.5695847581057815 | validation: 0.9672533339792143]
	TIME [epoch: 6.24 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5837941945497437		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.5837941945497437 | validation: 0.8115614938402411]
	TIME [epoch: 6.28 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6949605070676161		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.6949605070676161 | validation: 1.0222918357702602]
	TIME [epoch: 6.25 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6710960251475969		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.6710960251475969 | validation: 1.0659042875200346]
	TIME [epoch: 6.25 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.59078582309818		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.59078582309818 | validation: 0.5685414741693441]
	TIME [epoch: 6.24 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5452208175694516		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.5452208175694516 | validation: 0.37372694204525536]
	TIME [epoch: 6.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_260.pth
	Model improved!!!
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5068580070174922		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.5068580070174922 | validation: 0.521850102030655]
	TIME [epoch: 6.24 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6566298701214068		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.6566298701214068 | validation: 0.7181941151074834]
	TIME [epoch: 6.29 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6106917968846255		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.6106917968846255 | validation: 0.4441754897809994]
	TIME [epoch: 6.25 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5926627937794018		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.5926627937794018 | validation: 0.6619042920627434]
	TIME [epoch: 6.24 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4948377649075144		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.4948377649075144 | validation: 0.7261555162780531]
	TIME [epoch: 6.24 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.597428924635597		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.597428924635597 | validation: 0.6450342304948278]
	TIME [epoch: 6.24 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6069737552287412		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.6069737552287412 | validation: 0.3084612674953942]
	TIME [epoch: 6.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_267.pth
	Model improved!!!
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47421634053514394		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.47421634053514394 | validation: 0.48151986370041855]
	TIME [epoch: 6.3 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5575134576516719		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.5575134576516719 | validation: 0.3613700714369573]
	TIME [epoch: 6.25 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4626634633621779		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.4626634633621779 | validation: 1.1207545294743515]
	TIME [epoch: 6.25 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9214568984696743		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.9214568984696743 | validation: 3.352665051090418]
	TIME [epoch: 6.25 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0742273434804863		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 2.0742273434804863 | validation: 1.5763601886919503]
	TIME [epoch: 6.25 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8076905996800875		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.8076905996800875 | validation: 0.5067198222889052]
	TIME [epoch: 6.25 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6542239336118796		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.6542239336118796 | validation: 0.4627990611350262]
	TIME [epoch: 6.3 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6912921771003118		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.6912921771003118 | validation: 0.6296108680422297]
	TIME [epoch: 6.26 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5473227137130315		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.5473227137130315 | validation: 0.7968684219700658]
	TIME [epoch: 6.25 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5666042635013381		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.5666042635013381 | validation: 0.47830474081161245]
	TIME [epoch: 6.25 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42876889487074776		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.42876889487074776 | validation: 1.2817908149471715]
	TIME [epoch: 6.24 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6530421358745142		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.6530421358745142 | validation: 0.6101963105494337]
	TIME [epoch: 6.25 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6314244932952423		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.6314244932952423 | validation: 0.3116089795107768]
	TIME [epoch: 6.29 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44904463644468456		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.44904463644468456 | validation: 0.7269223104507835]
	TIME [epoch: 6.25 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43582165363361214		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.43582165363361214 | validation: 0.5195645152071261]
	TIME [epoch: 6.25 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5251603817220896		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.5251603817220896 | validation: 0.2858295981788489]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_283.pth
	Model improved!!!
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45669725258541227		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.45669725258541227 | validation: 0.6495869120145948]
	TIME [epoch: 6.24 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5338190193552859		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.5338190193552859 | validation: 0.384261580900459]
	TIME [epoch: 6.25 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5885778478618124		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.5885778478618124 | validation: 0.4912372612608397]
	TIME [epoch: 6.29 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4127407998702471		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.4127407998702471 | validation: 0.6323288753919447]
	TIME [epoch: 6.25 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4813166835386277		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.4813166835386277 | validation: 0.390705827813005]
	TIME [epoch: 6.24 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4392233017854974		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.4392233017854974 | validation: 0.529367761654504]
	TIME [epoch: 6.24 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4838726171640785		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.4838726171640785 | validation: 0.4022056660389072]
	TIME [epoch: 6.24 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46896023542361814		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.46896023542361814 | validation: 0.45821877504365316]
	TIME [epoch: 6.25 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5528115479794729		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.5528115479794729 | validation: 0.4646557075690052]
	TIME [epoch: 6.29 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5439645999032553		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.5439645999032553 | validation: 0.7048548683159974]
	TIME [epoch: 6.25 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5580741132060929		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.5580741132060929 | validation: 0.8258782478774938]
	TIME [epoch: 6.25 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48919188730755647		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.48919188730755647 | validation: 0.538580032332054]
	TIME [epoch: 6.24 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42169209364563676		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.42169209364563676 | validation: 0.8946367303661673]
	TIME [epoch: 6.24 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48767262678571		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.48767262678571 | validation: 0.7076485784150168]
	TIME [epoch: 6.25 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48200030255477		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.48200030255477 | validation: 0.5108647081834836]
	TIME [epoch: 6.28 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1161171848115172		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 1.1161171848115172 | validation: 0.7649655809434704]
	TIME [epoch: 6.25 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8609258882428498		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.8609258882428498 | validation: 0.6460005474998702]
	TIME [epoch: 6.24 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6922592277826538		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.6922592277826538 | validation: 0.668182567978347]
	TIME [epoch: 6.24 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6836287370193751		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.6836287370193751 | validation: 0.37824142925865833]
	TIME [epoch: 6.24 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3935247488958674		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.3935247488958674 | validation: 0.339002319832554]
	TIME [epoch: 6.26 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36305934005157275		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.36305934005157275 | validation: 0.48726653334506365]
	TIME [epoch: 6.28 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46995105096373335		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.46995105096373335 | validation: 0.43401687691337537]
	TIME [epoch: 6.25 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46979460962279085		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.46979460962279085 | validation: 0.3103692399905653]
	TIME [epoch: 6.24 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45765082757016773		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.45765082757016773 | validation: 0.2378467352211147]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_307.pth
	Model improved!!!
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3090535102669904		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.3090535102669904 | validation: 0.8636776425879799]
	TIME [epoch: 6.24 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.674308095179964		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.674308095179964 | validation: 0.3888039612570434]
	TIME [epoch: 6.26 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36872276063555426		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.36872276063555426 | validation: 0.8258726597537791]
	TIME [epoch: 6.28 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5095150271268063		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.5095150271268063 | validation: 0.4844173337554922]
	TIME [epoch: 6.24 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3695807447862661		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.3695807447862661 | validation: 0.6560564386181651]
	TIME [epoch: 6.24 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4097522840145732		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.4097522840145732 | validation: 0.3001268516050244]
	TIME [epoch: 6.24 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6539455529475797		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.6539455529475797 | validation: 1.063408959465602]
	TIME [epoch: 6.24 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5867028107852333		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.5867028107852333 | validation: 0.4012260089553764]
	TIME [epoch: 6.26 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4013825427087204		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.4013825427087204 | validation: 0.3043987240936711]
	TIME [epoch: 6.27 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34290714900554753		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.34290714900554753 | validation: 0.27671127785662897]
	TIME [epoch: 6.25 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3743778197026309		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.3743778197026309 | validation: 0.3788498805043552]
	TIME [epoch: 6.24 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3579095178233203		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.3579095178233203 | validation: 2.4820141018595034]
	TIME [epoch: 6.24 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1123383317751332		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 1.1123383317751332 | validation: 1.1291228897052696]
	TIME [epoch: 6.24 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5454556429050081		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.5454556429050081 | validation: 0.38249504225162895]
	TIME [epoch: 6.26 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34638970491271565		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.34638970491271565 | validation: 0.4384718125204575]
	TIME [epoch: 6.27 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9704591330258259		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.9704591330258259 | validation: 1.0470752727535797]
	TIME [epoch: 6.24 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.624061321498112		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.624061321498112 | validation: 1.037247707524409]
	TIME [epoch: 6.24 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1487545046525394		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 1.1487545046525394 | validation: 0.7859317708587442]
	TIME [epoch: 6.24 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.662918189031285		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.662918189031285 | validation: 0.47241153000360536]
	TIME [epoch: 6.24 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42467550001800103		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.42467550001800103 | validation: 0.23807463447573363]
	TIME [epoch: 6.27 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3526365727474261		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.3526365727474261 | validation: 0.4856783463110296]
	TIME [epoch: 6.26 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37829608712072466		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.37829608712072466 | validation: 0.339184950119625]
	TIME [epoch: 6.24 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4231109372294043		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.4231109372294043 | validation: 0.3522989703559851]
	TIME [epoch: 6.24 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5008304169552686		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.5008304169552686 | validation: 0.40404944545466676]
	TIME [epoch: 6.24 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5144651463845483		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.5144651463845483 | validation: 0.22602938738919576]
	TIME [epoch: 6.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_332.pth
	Model improved!!!
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3934915665170318		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.3934915665170318 | validation: 0.2846268455526181]
	TIME [epoch: 6.26 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45024381100610084		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.45024381100610084 | validation: 0.4313421300234064]
	TIME [epoch: 6.25 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3357824782166571		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.3357824782166571 | validation: 0.4600367246212905]
	TIME [epoch: 6.23 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3575946624303596		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.3575946624303596 | validation: 0.40862970336677495]
	TIME [epoch: 6.23 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33855620423175414		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.33855620423175414 | validation: 0.35037684484543113]
	TIME [epoch: 6.23 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36338337156937367		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.36338337156937367 | validation: 0.4475299346153173]
	TIME [epoch: 6.22 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30100051123588056		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.30100051123588056 | validation: 0.3769731265654371]
	TIME [epoch: 6.27 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35724521594954706		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.35724521594954706 | validation: 0.3073702022153287]
	TIME [epoch: 6.26 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36897108213164803		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.36897108213164803 | validation: 0.3066859043281861]
	TIME [epoch: 6.24 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4169927149636843		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.4169927149636843 | validation: 0.7644121178450993]
	TIME [epoch: 6.25 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39425818383938827		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.39425818383938827 | validation: 0.8468471622722478]
	TIME [epoch: 6.24 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4045239362347943		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.4045239362347943 | validation: 0.6396275591108355]
	TIME [epoch: 6.25 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4264254903289296		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.4264254903289296 | validation: 0.7157546089730646]
	TIME [epoch: 6.28 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3491735276247649		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.3491735276247649 | validation: 0.3575689101561874]
	TIME [epoch: 6.27 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3887386458367267		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.3887386458367267 | validation: 0.4450392310566438]
	TIME [epoch: 6.25 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42501726260384526		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.42501726260384526 | validation: 0.28067182793502843]
	TIME [epoch: 6.25 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2661911714800346		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.2661911714800346 | validation: 0.6646598370713175]
	TIME [epoch: 6.25 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4928960020170067		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.4928960020170067 | validation: 0.3722089555039465]
	TIME [epoch: 6.25 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35374418016177794		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.35374418016177794 | validation: 1.3726145441618955]
	TIME [epoch: 6.28 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8546198297575497		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.8546198297575497 | validation: 1.1615040834467762]
	TIME [epoch: 6.27 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6339379939671775		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.6339379939671775 | validation: 0.4582697169951205]
	TIME [epoch: 6.26 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3593742432036864		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.3593742432036864 | validation: 0.321648620244204]
	TIME [epoch: 6.25 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28354191247516825		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.28354191247516825 | validation: 0.40585256146075505]
	TIME [epoch: 6.25 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4168753243851345		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.4168753243851345 | validation: 0.5258425923569385]
	TIME [epoch: 6.25 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.393684366571424		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.393684366571424 | validation: 0.3948437123460167]
	TIME [epoch: 6.28 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2747984925384798		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.2747984925384798 | validation: 0.28320471678784886]
	TIME [epoch: 6.26 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3217022985714858		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.3217022985714858 | validation: 0.39214356732396716]
	TIME [epoch: 6.25 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36769603127892864		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.36769603127892864 | validation: 0.28250812913513634]
	TIME [epoch: 6.25 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32742477602921816		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.32742477602921816 | validation: 0.4120146458902376]
	TIME [epoch: 6.24 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4277828866331562		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.4277828866331562 | validation: 0.5354148559748235]
	TIME [epoch: 6.24 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.505479768953218		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.505479768953218 | validation: 0.3251341504671217]
	TIME [epoch: 6.28 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3946195507804218		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.3946195507804218 | validation: 0.2798417837164038]
	TIME [epoch: 6.26 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2804431251932554		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.2804431251932554 | validation: 0.47814963132178956]
	TIME [epoch: 6.24 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.364020537545101		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.364020537545101 | validation: 0.36094242766259965]
	TIME [epoch: 6.24 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31283580681713163		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.31283580681713163 | validation: 0.27672443943669056]
	TIME [epoch: 6.23 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3139048302749236		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.3139048302749236 | validation: 0.5420647453506429]
	TIME [epoch: 6.24 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3501394906899783		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.3501394906899783 | validation: 1.3492287395078577]
	TIME [epoch: 6.27 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8272316735360672		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.8272316735360672 | validation: 0.4025640341468971]
	TIME [epoch: 6.25 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3539901816830862		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.3539901816830862 | validation: 0.3710225974925994]
	TIME [epoch: 6.23 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35729258205284764		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.35729258205284764 | validation: 0.3378747432928234]
	TIME [epoch: 6.24 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7712543806672368		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.7712543806672368 | validation: 0.5099806268694098]
	TIME [epoch: 6.24 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3454925647301731		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.3454925647301731 | validation: 0.37111246706855805]
	TIME [epoch: 6.24 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3764089689302958		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.3764089689302958 | validation: 0.3033264095164314]
	TIME [epoch: 6.28 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2749426345763805		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.2749426345763805 | validation: 0.3894572135974409]
	TIME [epoch: 6.26 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.307788388093083		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.307788388093083 | validation: 0.5694786247583198]
	TIME [epoch: 6.24 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3428222537900537		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.3428222537900537 | validation: 0.6400842451402919]
	TIME [epoch: 6.23 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48252156333715224		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.48252156333715224 | validation: 0.4985307785000098]
	TIME [epoch: 6.24 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2838258226729592		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.2838258226729592 | validation: 0.3526969040541038]
	TIME [epoch: 6.24 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2914461164157349		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.2914461164157349 | validation: 0.49055615197074764]
	TIME [epoch: 6.28 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5893034435811701		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.5893034435811701 | validation: 0.9727937245578627]
	TIME [epoch: 6.25 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4654164308723642		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.4654164308723642 | validation: 0.2910268576385664]
	TIME [epoch: 6.24 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3846140884669326		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.3846140884669326 | validation: 0.4574591660206392]
	TIME [epoch: 6.24 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3301758991917531		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.3301758991917531 | validation: 0.6829843055922622]
	TIME [epoch: 6.22 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41061177666566134		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.41061177666566134 | validation: 0.5877080755635764]
	TIME [epoch: 6.24 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37008663862103336		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.37008663862103336 | validation: 0.30950375467252333]
	TIME [epoch: 6.27 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42055896826915784		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.42055896826915784 | validation: 0.6507257695983505]
	TIME [epoch: 6.25 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3611664385960729		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.3611664385960729 | validation: 0.2824960354074846]
	TIME [epoch: 6.24 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34141887162402007		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.34141887162402007 | validation: 0.38007186092098033]
	TIME [epoch: 6.24 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5090517304623646		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.5090517304623646 | validation: 0.493140111370726]
	TIME [epoch: 6.24 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4158077089654584		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.4158077089654584 | validation: 0.4778674059854988]
	TIME [epoch: 6.23 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42233935396743877		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.42233935396743877 | validation: 0.8753188396648566]
	TIME [epoch: 6.28 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45166460935733027		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.45166460935733027 | validation: 0.7990427097126374]
	TIME [epoch: 6.24 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6061436300943082		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.6061436300943082 | validation: 0.32113631696892697]
	TIME [epoch: 6.23 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3333335612917889		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.3333335612917889 | validation: 0.6757314253989076]
	TIME [epoch: 6.23 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40182895185312506		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.40182895185312506 | validation: 0.27863186743180557]
	TIME [epoch: 6.24 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2592533100663538		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.2592533100663538 | validation: 0.20533005690888184]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_398.pth
	Model improved!!!
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30817345394540147		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.30817345394540147 | validation: 0.33515578732221285]
	TIME [epoch: 6.28 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3045896563399987		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.3045896563399987 | validation: 0.3178300520627998]
	TIME [epoch: 6.25 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2315051441100034		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.2315051441100034 | validation: 0.23854748729606046]
	TIME [epoch: 6.24 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3663594049256663		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.3663594049256663 | validation: 0.5067572703889865]
	TIME [epoch: 6.22 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4035399581163252		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.4035399581163252 | validation: 0.34929943312063405]
	TIME [epoch: 6.23 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36434748846260806		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.36434748846260806 | validation: 0.5103605037552437]
	TIME [epoch: 6.23 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2966657102319799		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.2966657102319799 | validation: 0.3626588288317257]
	TIME [epoch: 6.27 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3182639167948307		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.3182639167948307 | validation: 0.206778161409013]
	TIME [epoch: 6.24 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2304255759475927		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.2304255759475927 | validation: 0.22764264694140185]
	TIME [epoch: 6.22 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36126277955652364		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.36126277955652364 | validation: 0.39536790532810007]
	TIME [epoch: 6.23 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26930325482810974		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.26930325482810974 | validation: 0.20589596597050142]
	TIME [epoch: 6.23 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29070092427248323		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.29070092427248323 | validation: 0.3095208560213464]
	TIME [epoch: 6.24 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2889355880036106		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.2889355880036106 | validation: 0.35013962701532303]
	TIME [epoch: 6.27 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.67547582605164		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.67547582605164 | validation: 0.6810189939498523]
	TIME [epoch: 6.23 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4128173667245201		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.4128173667245201 | validation: 0.33866581512098054]
	TIME [epoch: 6.23 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29403973555280905		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.29403973555280905 | validation: 0.3152453610882248]
	TIME [epoch: 6.23 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3052336302905465		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.3052336302905465 | validation: 0.3117118535379735]
	TIME [epoch: 6.23 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26974296731833314		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.26974296731833314 | validation: 0.2775527110504047]
	TIME [epoch: 6.24 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3124060254891529		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.3124060254891529 | validation: 0.46218899150990733]
	TIME [epoch: 6.29 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6469233688441925		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.6469233688441925 | validation: 0.666998517116913]
	TIME [epoch: 6.24 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3516720421434899		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.3516720421434899 | validation: 0.3130785556900587]
	TIME [epoch: 6.23 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24290118855994158		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.24290118855994158 | validation: 0.17517966900162743]
	TIME [epoch: 6.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_420.pth
	Model improved!!!
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22338500476191184		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.22338500476191184 | validation: 0.33521374978959373]
	TIME [epoch: 6.24 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3362149668883998		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.3362149668883998 | validation: 0.22332362799491054]
	TIME [epoch: 6.24 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2660244431683392		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.2660244431683392 | validation: 0.2365729071590447]
	TIME [epoch: 6.29 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29367025279422987		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.29367025279422987 | validation: 0.3154646135831539]
	TIME [epoch: 6.24 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28143192924379845		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.28143192924379845 | validation: 0.22732517683626063]
	TIME [epoch: 6.24 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.258391444235477		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.258391444235477 | validation: 0.2817898772132059]
	TIME [epoch: 6.25 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22889731406946823		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.22889731406946823 | validation: 0.38934867674723056]
	TIME [epoch: 6.25 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.330553968754904		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.330553968754904 | validation: 0.20383651932288105]
	TIME [epoch: 6.25 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2375776475076955		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.2375776475076955 | validation: 0.25697414597804086]
	TIME [epoch: 6.29 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27173098505194077		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.27173098505194077 | validation: 0.3502821986699234]
	TIME [epoch: 6.26 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28337155203212855		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.28337155203212855 | validation: 0.22302386711087202]
	TIME [epoch: 6.26 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37763661071913623		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.37763661071913623 | validation: 0.3974860790986819]
	TIME [epoch: 6.24 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3532657185580245		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.3532657185580245 | validation: 0.32066901438779166]
	TIME [epoch: 6.25 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34633408958106837		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.34633408958106837 | validation: 0.25808602879455095]
	TIME [epoch: 6.26 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31469270865374904		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.31469270865374904 | validation: 0.3643483193391457]
	TIME [epoch: 6.29 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3299944506087469		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.3299944506087469 | validation: 0.35310319769686294]
	TIME [epoch: 6.25 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28753208092080357		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.28753208092080357 | validation: 0.2553838886851262]
	TIME [epoch: 6.25 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2428611447084374		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.2428611447084374 | validation: 0.23754319802873752]
	TIME [epoch: 6.24 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2354446196401276		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.2354446196401276 | validation: 0.23061164515056548]
	TIME [epoch: 6.25 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41078613091666427		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.41078613091666427 | validation: 0.26379853403457765]
	TIME [epoch: 6.26 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3097954438484618		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.3097954438484618 | validation: 0.5572232998416763]
	TIME [epoch: 6.29 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34753927285011266		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.34753927285011266 | validation: 0.2935623405340038]
	TIME [epoch: 6.25 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2835881255323956		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.2835881255323956 | validation: 0.4382483379438987]
	TIME [epoch: 6.24 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.278341622856133		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.278341622856133 | validation: 0.45618467115405803]
	TIME [epoch: 6.25 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3701377358091436		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.3701377358091436 | validation: 0.2977917708006183]
	TIME [epoch: 6.25 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2563886397559025		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.2563886397559025 | validation: 0.3035122240995831]
	TIME [epoch: 6.27 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2703633505417433		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.2703633505417433 | validation: 0.5380130303097203]
	TIME [epoch: 6.29 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5946665635295747		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.5946665635295747 | validation: 0.2427024890886969]
	TIME [epoch: 6.26 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3102208849168428		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.3102208849168428 | validation: 0.3180264318230693]
	TIME [epoch: 6.26 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36102396378105905		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.36102396378105905 | validation: 0.4502287375280003]
	TIME [epoch: 6.25 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3655729837891851		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.3655729837891851 | validation: 0.5540238422159938]
	TIME [epoch: 6.25 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30892316293802935		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.30892316293802935 | validation: 0.3988957612076456]
	TIME [epoch: 6.27 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34422184577859744		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.34422184577859744 | validation: 0.24267814289680764]
	TIME [epoch: 6.3 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3121800622375816		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.3121800622375816 | validation: 0.2796677603183888]
	TIME [epoch: 6.24 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2768441419235308		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.2768441419235308 | validation: 0.22711275520005852]
	TIME [epoch: 6.26 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2878385878407612		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.2878385878407612 | validation: 0.24767093084521474]
	TIME [epoch: 6.26 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.261104928300684		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.261104928300684 | validation: 0.31709885713277763]
	TIME [epoch: 6.26 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2695661674822922		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.2695661674822922 | validation: 0.2115547409284972]
	TIME [epoch: 6.27 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25843245483036514		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.25843245483036514 | validation: 0.2436052032709855]
	TIME [epoch: 6.3 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36796083865439594		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.36796083865439594 | validation: 0.2521689442671952]
	TIME [epoch: 6.26 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22203588636392807		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.22203588636392807 | validation: 0.4352431212351736]
	TIME [epoch: 6.24 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28489778508474173		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.28489778508474173 | validation: 0.21288375990059105]
	TIME [epoch: 6.25 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24766662579671006		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.24766662579671006 | validation: 0.38062029740607073]
	TIME [epoch: 6.25 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38037925880327306		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.38037925880327306 | validation: 0.38575215519368766]
	TIME [epoch: 6.27 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2836151074701616		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.2836151074701616 | validation: 0.6768670157918133]
	TIME [epoch: 6.29 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42468018958750764		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.42468018958750764 | validation: 0.7814272744145694]
	TIME [epoch: 6.26 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4055862937593465		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.4055862937593465 | validation: 0.24304394627262438]
	TIME [epoch: 6.25 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2858606609875711		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.2858606609875711 | validation: 0.2742928852156915]
	TIME [epoch: 6.25 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2928966076284146		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.2928966076284146 | validation: 0.2752137699279845]
	TIME [epoch: 6.26 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4026324787650415		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.4026324787650415 | validation: 0.602158903406164]
	TIME [epoch: 6.28 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34978777874798256		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.34978777874798256 | validation: 0.37031574530528544]
	TIME [epoch: 6.28 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3105177073068518		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.3105177073068518 | validation: 0.4514010314862863]
	TIME [epoch: 6.26 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3558172878129891		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.3558172878129891 | validation: 0.34024715327630856]
	TIME [epoch: 6.25 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3351924481562604		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.3351924481562604 | validation: 0.7876981918856685]
	TIME [epoch: 6.25 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4113395625901599		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.4113395625901599 | validation: 0.2066507721149341]
	TIME [epoch: 6.25 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2136731885537123		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.2136731885537123 | validation: 0.24960900460057622]
	TIME [epoch: 6.29 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23287619517627675		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.23287619517627675 | validation: 0.48052211315689675]
	TIME [epoch: 6.26 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2836694971092044		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.2836694971092044 | validation: 0.21804389078224565]
	TIME [epoch: 6.26 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25646445789529176		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.25646445789529176 | validation: 0.36191647024787255]
	TIME [epoch: 6.26 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32631644541671007		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.32631644541671007 | validation: 0.7736784427931339]
	TIME [epoch: 6.25 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33806016490814256		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.33806016490814256 | validation: 0.40347291287312553]
	TIME [epoch: 6.24 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25671837202176373		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.25671837202176373 | validation: 0.2835877344036587]
	TIME [epoch: 6.27 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23624838959008518		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.23624838959008518 | validation: 0.22039311784694743]
	TIME [epoch: 6.27 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3023762773533377		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.3023762773533377 | validation: 0.4303929512821475]
	TIME [epoch: 6.25 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3137176253239431		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.3137176253239431 | validation: 0.19419590791918012]
	TIME [epoch: 6.25 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21532233905607323		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.21532233905607323 | validation: 0.21086316142615352]
	TIME [epoch: 6.24 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21867906171486512		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.21867906171486512 | validation: 0.22028684898454226]
	TIME [epoch: 6.25 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23918491139680054		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.23918491139680054 | validation: 0.20883059489069747]
	TIME [epoch: 6.29 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2886983232942446		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.2886983232942446 | validation: 0.27109165245027267]
	TIME [epoch: 6.27 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24491096181321914		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.24491096181321914 | validation: 0.39164715782753146]
	TIME [epoch: 6.25 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.260111573400069		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.260111573400069 | validation: 0.24124833258018352]
	TIME [epoch: 6.25 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2694408575064722		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.2694408575064722 | validation: 0.20951550663886637]
	TIME [epoch: 6.26 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3074749731322614		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.3074749731322614 | validation: 0.30517618478937125]
	TIME [epoch: 6.25 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21871029246274395		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.21871029246274395 | validation: 0.2842431702868332]
	TIME [epoch: 6.28 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23146081865632281		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.23146081865632281 | validation: 0.43779802587642913]
	TIME [epoch: 6.26 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2953617580283067		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.2953617580283067 | validation: 0.3308548773057708]
	TIME [epoch: 6.25 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2630172458484094		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.2630172458484094 | validation: 0.20625549367903073]
	TIME [epoch: 6.24 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2526553386789289		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.2526553386789289 | validation: 0.5114800324758009]
	TIME [epoch: 6.25 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3335028341791089		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.3335028341791089 | validation: 0.4278348028002377]
	TIME [epoch: 6.25 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31555978518572286		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.31555978518572286 | validation: 0.29857308900348073]
	TIME [epoch: 6.28 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2174408721198715		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.2174408721198715 | validation: 0.2302177889144164]
	TIME [epoch: 6.27 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22088161425333896		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.22088161425333896 | validation: 0.2200132523351386]
	TIME [epoch: 6.25 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22302593507641433		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.22302593507641433 | validation: 0.3449580353801234]
	TIME [epoch: 6.25 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27797332281019116		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.27797332281019116 | validation: 0.27090984529824863]
	TIME [epoch: 6.25 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29355962565172583		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.29355962565172583 | validation: 0.32076779571212366]
	TIME [epoch: 6.25 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2624818403075636		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.2624818403075636 | validation: 0.3205818399037323]
	TIME [epoch: 6.27 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23734812228373053		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.23734812228373053 | validation: 0.17513110329421983]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_507.pth
	Model improved!!!
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25151076950334567		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.25151076950334567 | validation: 0.29680322805806525]
	TIME [epoch: 6.24 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18909840477354495		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.18909840477354495 | validation: 0.5416852800579538]
	TIME [epoch: 6.24 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28909429792814545		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.28909429792814545 | validation: 0.3565166803881629]
	TIME [epoch: 6.23 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22803636157109727		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.22803636157109727 | validation: 0.22240719504655243]
	TIME [epoch: 6.24 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22021951827607228		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.22021951827607228 | validation: 0.3024504989347947]
	TIME [epoch: 6.29 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3039957002582531		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.3039957002582531 | validation: 0.17988655560425407]
	TIME [epoch: 6.27 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3108024235006911		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.3108024235006911 | validation: 0.2795668871552559]
	TIME [epoch: 6.24 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24266314488367238		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.24266314488367238 | validation: 0.2595589814245567]
	TIME [epoch: 6.24 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23114494815212994		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.23114494815212994 | validation: 0.24634325146136377]
	TIME [epoch: 6.24 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24397631188524505		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.24397631188524505 | validation: 0.25779115206815223]
	TIME [epoch: 6.24 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20048811852874418		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.20048811852874418 | validation: 0.2050820203179487]
	TIME [epoch: 6.28 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18410950483145744		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.18410950483145744 | validation: 0.20107332381311235]
	TIME [epoch: 6.26 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3535509917990045		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.3535509917990045 | validation: 0.48437351635242165]
	TIME [epoch: 6.24 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35633128453239343		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.35633128453239343 | validation: 0.3419420745606649]
	TIME [epoch: 6.25 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3756670221921008		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.3756670221921008 | validation: 0.586230236348361]
	TIME [epoch: 6.25 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3118524012882589		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.3118524012882589 | validation: 0.2692670273003852]
	TIME [epoch: 6.25 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22816145757106593		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.22816145757106593 | validation: 0.49077749956378625]
	TIME [epoch: 6.29 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27041059036213205		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.27041059036213205 | validation: 0.21243596523246883]
	TIME [epoch: 6.26 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24274201640407578		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.24274201640407578 | validation: 0.3344225699415667]
	TIME [epoch: 6.25 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2630201114093931		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.2630201114093931 | validation: 0.20657248926461383]
	TIME [epoch: 6.24 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19857188406405657		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.19857188406405657 | validation: 0.3545585754646661]
	TIME [epoch: 6.24 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2558972720160771		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.2558972720160771 | validation: 0.3676676439279546]
	TIME [epoch: 6.25 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3068847370773521		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.3068847370773521 | validation: 0.3326898444660578]
	TIME [epoch: 6.29 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2223143956365515		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.2223143956365515 | validation: 0.9567305982916864]
	TIME [epoch: 6.25 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4862945137673234		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.4862945137673234 | validation: 0.6273547604125613]
	TIME [epoch: 6.24 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3799251702428359		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.3799251702428359 | validation: 0.4657694574320252]
	TIME [epoch: 6.24 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3084719863517933		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.3084719863517933 | validation: 0.3037913829584856]
	TIME [epoch: 6.25 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3486454045499927		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.3486454045499927 | validation: 0.33306453588297164]
	TIME [epoch: 6.24 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.264832195469901		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.264832195469901 | validation: 0.2269567569188698]
	TIME [epoch: 6.3 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19770099241515346		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.19770099241515346 | validation: 0.1940429206373125]
	TIME [epoch: 6.25 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1618936331526477		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.1618936331526477 | validation: 0.29608697689841856]
	TIME [epoch: 6.24 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29281732955064693		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.29281732955064693 | validation: 0.49773131820716887]
	TIME [epoch: 6.25 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42698316979633333		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.42698316979633333 | validation: 0.7024409938563956]
	TIME [epoch: 6.24 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3127784632864241		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.3127784632864241 | validation: 0.41360390245107237]
	TIME [epoch: 6.25 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21963102558712105		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.21963102558712105 | validation: 0.29438051975627005]
	TIME [epoch: 6.3 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22332999194367442		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.22332999194367442 | validation: 0.356205821762167]
	TIME [epoch: 6.25 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3115040836374871		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.3115040836374871 | validation: 0.2220155424729226]
	TIME [epoch: 6.24 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2544922980362893		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.2544922980362893 | validation: 0.277696822917372]
	TIME [epoch: 6.25 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2510069092533166		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.2510069092533166 | validation: 0.2231489865363514]
	TIME [epoch: 6.24 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23537922148715196		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.23537922148715196 | validation: 0.22162243115550312]
	TIME [epoch: 6.24 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1927684325093336		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.1927684325093336 | validation: 0.26054867726893993]
	TIME [epoch: 6.3 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22156329783155249		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.22156329783155249 | validation: 0.2799446271582091]
	TIME [epoch: 6.25 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3735681594146047		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.3735681594146047 | validation: 0.4531213768168353]
	TIME [epoch: 6.25 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3319576438073906		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.3319576438073906 | validation: 0.20906008398811377]
	TIME [epoch: 6.25 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2381997829204521		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.2381997829204521 | validation: 0.20682256576615127]
	TIME [epoch: 6.24 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25047230308242036		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.25047230308242036 | validation: 0.3246249616635058]
	TIME [epoch: 6.25 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2348857280867599		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.2348857280867599 | validation: 0.188579512338599]
	TIME [epoch: 6.29 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1842772059848587		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.1842772059848587 | validation: 0.521843018372978]
	TIME [epoch: 6.25 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3303265843425845		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.3303265843425845 | validation: 0.2432413836491982]
	TIME [epoch: 6.25 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28908751602465504		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.28908751602465504 | validation: 0.2193196520120349]
	TIME [epoch: 6.25 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16499667037885432		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.16499667037885432 | validation: 0.21694639831659163]
	TIME [epoch: 6.25 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17945319090996895		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.17945319090996895 | validation: 0.24220328211844944]
	TIME [epoch: 6.25 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1947221683938299		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.1947221683938299 | validation: 0.2089693468934108]
	TIME [epoch: 6.29 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27433788191026864		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.27433788191026864 | validation: 0.4247987914468947]
	TIME [epoch: 6.25 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3028188067630687		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.3028188067630687 | validation: 0.3178981641413199]
	TIME [epoch: 6.25 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26756280242837266		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.26756280242837266 | validation: 0.3030941052161063]
	TIME [epoch: 6.25 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1983590730256764		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.1983590730256764 | validation: 0.1713305793197507]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_564.pth
	Model improved!!!
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15825825508933652		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.15825825508933652 | validation: 0.23275180992415567]
	TIME [epoch: 6.24 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2329925188186544		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.2329925188186544 | validation: 0.1730004815325622]
	TIME [epoch: 6.29 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22810721912000698		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.22810721912000698 | validation: 0.21720059656028756]
	TIME [epoch: 6.24 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.237963786339647		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.237963786339647 | validation: 0.3837148209984862]
	TIME [epoch: 6.23 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2524331256588404		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.2524331256588404 | validation: 0.3365877567289469]
	TIME [epoch: 6.23 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26296586433470914		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.26296586433470914 | validation: 0.23943138701338554]
	TIME [epoch: 6.23 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17126500853016713		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.17126500853016713 | validation: 0.24884854928878325]
	TIME [epoch: 6.24 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19068616996388243		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.19068616996388243 | validation: 0.24860808083098823]
	TIME [epoch: 6.27 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22173701016944347		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.22173701016944347 | validation: 0.23130202769559444]
	TIME [epoch: 6.24 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22792985416914616		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.22792985416914616 | validation: 0.21940098297909988]
	TIME [epoch: 6.23 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21392356024080544		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.21392356024080544 | validation: 0.22103379421165753]
	TIME [epoch: 6.24 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17055952465739668		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.17055952465739668 | validation: 0.1846015292795311]
	TIME [epoch: 6.23 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24532946950965348		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.24532946950965348 | validation: 0.22111935630453172]
	TIME [epoch: 6.25 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24558486505032392		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.24558486505032392 | validation: 0.21644032700874366]
	TIME [epoch: 6.27 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19803964007503233		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.19803964007503233 | validation: 0.17776968283985656]
	TIME [epoch: 6.24 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17768450436215566		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.17768450436215566 | validation: 0.324709235842833]
	TIME [epoch: 6.23 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22652790044113222		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.22652790044113222 | validation: 0.17153203464123257]
	TIME [epoch: 6.24 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20332050091918924		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.20332050091918924 | validation: 0.2015545775984644]
	TIME [epoch: 6.24 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14188392732565389		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.14188392732565389 | validation: 0.1677446780439403]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_583.pth
	Model improved!!!
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26189572819739154		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.26189572819739154 | validation: 0.3586600861464203]
	TIME [epoch: 6.27 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21325704789803268		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.21325704789803268 | validation: 0.2120676946740073]
	TIME [epoch: 6.24 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17142455821165553		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.17142455821165553 | validation: 0.4287688153622161]
	TIME [epoch: 6.24 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.356086132978575		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.356086132978575 | validation: 0.2742549610197411]
	TIME [epoch: 6.24 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2817439121428645		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.2817439121428645 | validation: 0.359033781566482]
	TIME [epoch: 6.24 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2092024995758345		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.2092024995758345 | validation: 0.16910194868566783]
	TIME [epoch: 6.26 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2533946654495629		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.2533946654495629 | validation: 0.44915952965388567]
	TIME [epoch: 6.27 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3693541652582992		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.3693541652582992 | validation: 0.5240140876612638]
	TIME [epoch: 6.24 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3242692285794562		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.3242692285794562 | validation: 0.2171730467257859]
	TIME [epoch: 6.24 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2029438061556357		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.2029438061556357 | validation: 0.19542576721252525]
	TIME [epoch: 6.23 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20415309723518238		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.20415309723518238 | validation: 0.540051144572752]
	TIME [epoch: 6.24 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25637677111957297		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.25637677111957297 | validation: 0.22872678174726213]
	TIME [epoch: 6.25 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17348297315268452		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.17348297315268452 | validation: 0.1772440997783747]
	TIME [epoch: 6.27 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20114944470537816		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.20114944470537816 | validation: 0.13729507983738823]
	TIME [epoch: 6.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_597.pth
	Model improved!!!
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1940558226031074		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.1940558226031074 | validation: 0.2717275499641592]
	TIME [epoch: 6.23 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24573152492305872		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.24573152492305872 | validation: 0.19424376761461232]
	TIME [epoch: 6.22 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2452033769987773		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.2452033769987773 | validation: 0.2761643101682325]
	TIME [epoch: 6.23 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33309640760320497		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.33309640760320497 | validation: 0.45222595621966244]
	TIME [epoch: 6.26 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28343748539421043		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.28343748539421043 | validation: 0.1871170517067211]
	TIME [epoch: 6.25 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1959321036015672		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.1959321036015672 | validation: 0.2038570348555314]
	TIME [epoch: 6.24 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23424803872512023		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.23424803872512023 | validation: 0.20009830662382316]
	TIME [epoch: 6.23 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24500015757328814		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.24500015757328814 | validation: 0.17547142347103356]
	TIME [epoch: 6.23 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21121138603381384		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.21121138603381384 | validation: 0.3058961423048332]
	TIME [epoch: 6.23 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20241970027077746		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.20241970027077746 | validation: 0.2888199472864132]
	TIME [epoch: 6.26 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2023591935764142		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.2023591935764142 | validation: 0.21204115717180733]
	TIME [epoch: 6.25 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18860243869087462		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.18860243869087462 | validation: 0.1779174300049171]
	TIME [epoch: 6.24 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18690863823582898		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.18690863823582898 | validation: 0.15485157567095423]
	TIME [epoch: 6.23 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15962818489919484		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.15962818489919484 | validation: 0.2661169459532454]
	TIME [epoch: 6.24 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1620723058152589		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.1620723058152589 | validation: 0.2753009603306676]
	TIME [epoch: 6.23 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22297249915188783		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.22297249915188783 | validation: 0.21801647697171916]
	TIME [epoch: 6.26 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16101209329312677		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.16101209329312677 | validation: 0.2812934027534557]
	TIME [epoch: 6.26 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24736328245247785		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.24736328245247785 | validation: 0.22017260811534775]
	TIME [epoch: 6.24 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18247846773575654		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.18247846773575654 | validation: 0.19301762800686217]
	TIME [epoch: 6.24 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21900061405336085		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.21900061405336085 | validation: 0.1914471348679171]
	TIME [epoch: 6.24 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17855377311199594		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.17855377311199594 | validation: 0.20376038717352046]
	TIME [epoch: 6.26 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14163569973212395		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.14163569973212395 | validation: 0.25167915887055786]
	TIME [epoch: 6.27 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19615060139141438		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.19615060139141438 | validation: 0.31879528905335575]
	TIME [epoch: 6.26 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23497231074701758		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.23497231074701758 | validation: 0.21565987012951587]
	TIME [epoch: 6.24 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21602800508021983		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.21602800508021983 | validation: 0.2339601743109804]
	TIME [epoch: 6.24 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20717841943560933		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.20717841943560933 | validation: 0.17736891738587426]
	TIME [epoch: 6.24 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14706425072088558		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.14706425072088558 | validation: 0.16499577764194376]
	TIME [epoch: 6.25 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1579583523643756		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.1579583523643756 | validation: 0.19223496951181374]
	TIME [epoch: 6.28 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1475920064465925		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.1475920064465925 | validation: 0.2357808774223083]
	TIME [epoch: 6.26 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.163795178157861		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.163795178157861 | validation: 0.18488492565973452]
	TIME [epoch: 6.24 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13149421810360437		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.13149421810360437 | validation: 0.25311485417562596]
	TIME [epoch: 6.24 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3129245429849027		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.3129245429849027 | validation: 0.23907718220726645]
	TIME [epoch: 6.24 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14984828578798984		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.14984828578798984 | validation: 0.2522852752321943]
	TIME [epoch: 6.24 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2692821626774881		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.2692821626774881 | validation: 0.33664482600955553]
	TIME [epoch: 6.28 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2139825754198204		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.2139825754198204 | validation: 0.335555515146329]
	TIME [epoch: 6.25 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17557146861640438		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.17557146861640438 | validation: 0.19922136620838227]
	TIME [epoch: 6.25 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18061555394494203		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.18061555394494203 | validation: 0.16039128602299024]
	TIME [epoch: 6.24 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13445620572537076		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.13445620572537076 | validation: 0.3844103418832843]
	TIME [epoch: 6.26 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2107966517898792		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.2107966517898792 | validation: 0.18850290911095258]
	TIME [epoch: 6.23 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13630782701585767		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.13630782701585767 | validation: 0.14090721917270554]
	TIME [epoch: 6.28 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14117191047613636		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.14117191047613636 | validation: 0.130391108257301]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_638.pth
	Model improved!!!
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18871909245784407		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.18871909245784407 | validation: 0.4917978748105374]
	TIME [epoch: 6.25 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2523885640447239		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.2523885640447239 | validation: 0.22256299594798373]
	TIME [epoch: 6.24 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20835965518462907		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.20835965518462907 | validation: 0.1561954503938235]
	TIME [epoch: 6.24 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13976509039742097		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.13976509039742097 | validation: 0.17000558824811723]
	TIME [epoch: 6.24 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14387087478130464		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.14387087478130464 | validation: 0.3810402102843088]
	TIME [epoch: 6.29 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26196649182194676		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.26196649182194676 | validation: 0.2671050099829325]
	TIME [epoch: 6.25 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18627485699452112		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.18627485699452112 | validation: 0.25285709111941157]
	TIME [epoch: 6.24 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18656824673740338		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.18656824673740338 | validation: 0.19931945610151242]
	TIME [epoch: 6.24 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15572414820055636		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.15572414820055636 | validation: 0.18225166574173196]
	TIME [epoch: 6.24 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19736565721260121		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.19736565721260121 | validation: 0.19200457040496227]
	TIME [epoch: 6.24 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14116379805467533		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.14116379805467533 | validation: 0.16601882703950394]
	TIME [epoch: 6.29 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14040882982445313		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.14040882982445313 | validation: 0.13761960662237832]
	TIME [epoch: 6.25 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40745146805724924		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.40745146805724924 | validation: 0.3272070716969444]
	TIME [epoch: 6.24 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24838122768681564		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.24838122768681564 | validation: 0.24274343928807982]
	TIME [epoch: 6.28 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1695457748291244		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.1695457748291244 | validation: 0.1400312638935045]
	TIME [epoch: 6.24 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15012853555282604		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.15012853555282604 | validation: 0.16802694775452776]
	TIME [epoch: 6.24 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15580570955185943		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.15580570955185943 | validation: 0.15164093441530144]
	TIME [epoch: 6.29 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14318576398017788		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.14318576398017788 | validation: 0.17709654287133994]
	TIME [epoch: 6.25 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1499603221274236		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.1499603221274236 | validation: 0.18881822162503656]
	TIME [epoch: 6.24 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.135076370424697		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.135076370424697 | validation: 0.2956177829374113]
	TIME [epoch: 6.24 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26888877971046155		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.26888877971046155 | validation: 0.19369799566195903]
	TIME [epoch: 6.24 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19973713146012068		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.19973713146012068 | validation: 0.31089817393654384]
	TIME [epoch: 6.24 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18508916917579588		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.18508916917579588 | validation: 0.13676508040324625]
	TIME [epoch: 6.28 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2041694024444619		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.2041694024444619 | validation: 0.2139490352173417]
	TIME [epoch: 6.25 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2113366592337935		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.2113366592337935 | validation: 0.2131817496485544]
	TIME [epoch: 6.24 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16038280471823704		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.16038280471823704 | validation: 0.15375559180770548]
	TIME [epoch: 6.24 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13676333843714797		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.13676333843714797 | validation: 0.2729869704018353]
	TIME [epoch: 6.24 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21079614759891868		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.21079614759891868 | validation: 0.27200269115211195]
	TIME [epoch: 6.25 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16563917124706284		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.16563917124706284 | validation: 0.185056177245426]
	TIME [epoch: 6.29 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14705761537615286		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.14705761537615286 | validation: 0.16808272834509724]
	TIME [epoch: 6.25 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1464251754105395		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.1464251754105395 | validation: 0.17650654401472105]
	TIME [epoch: 6.25 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16288235709617846		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.16288235709617846 | validation: 0.24625067531371403]
	TIME [epoch: 6.25 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22021469293788157		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.22021469293788157 | validation: 0.3382229570134243]
	TIME [epoch: 6.25 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2193827530634172		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.2193827530634172 | validation: 0.21231488403660242]
	TIME [epoch: 6.25 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17871370865167774		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.17871370865167774 | validation: 0.3556718721491433]
	TIME [epoch: 6.29 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2724591851454872		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.2724591851454872 | validation: 0.2649934212393137]
	TIME [epoch: 6.26 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17368929989561957		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.17368929989561957 | validation: 0.2149751273378735]
	TIME [epoch: 6.26 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15849936727138578		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.15849936727138578 | validation: 0.14815516839668813]
	TIME [epoch: 6.25 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16835813933260027		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.16835813933260027 | validation: 0.2336535976132309]
	TIME [epoch: 6.25 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1836189826262189		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.1836189826262189 | validation: 0.181305628129636]
	TIME [epoch: 6.26 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14157949593494823		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.14157949593494823 | validation: 0.17334533095713262]
	TIME [epoch: 6.3 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1596553635931669		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.1596553635931669 | validation: 0.12822387003361493]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_680.pth
	Model improved!!!
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15268777173370457		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.15268777173370457 | validation: 0.2019906337425741]
	TIME [epoch: 6.25 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2198478928142788		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.2198478928142788 | validation: 0.2545906545097549]
	TIME [epoch: 6.25 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2599893898169266		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.2599893898169266 | validation: 0.30105698309228934]
	TIME [epoch: 6.25 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25773601413047476		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.25773601413047476 | validation: 0.25563036100725667]
	TIME [epoch: 6.27 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2707879509713732		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.2707879509713732 | validation: 0.25011627090409516]
	TIME [epoch: 6.29 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20398731043847448		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.20398731043847448 | validation: 0.16964120018706497]
	TIME [epoch: 6.27 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1924855434134782		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.1924855434134782 | validation: 0.17647701850056735]
	TIME [epoch: 6.25 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16978803026842457		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.16978803026842457 | validation: 0.1610267263227009]
	TIME [epoch: 6.25 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17183907579788849		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.17183907579788849 | validation: 0.27410882209474857]
	TIME [epoch: 6.25 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17566809499346722		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.17566809499346722 | validation: 0.2130476191786519]
	TIME [epoch: 6.27 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16404274441225988		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.16404274441225988 | validation: 0.1533588603215873]
	TIME [epoch: 6.29 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15312871533185785		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.15312871533185785 | validation: 0.15528096560045862]
	TIME [epoch: 6.26 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1612144200877834		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.1612144200877834 | validation: 0.2299715375168962]
	TIME [epoch: 6.26 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19202045263264644		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.19202045263264644 | validation: 0.17220524921788039]
	TIME [epoch: 6.25 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13771647240979742		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.13771647240979742 | validation: 0.15729061058153546]
	TIME [epoch: 6.25 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15269242606584485		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.15269242606584485 | validation: 0.3084644443352222]
	TIME [epoch: 6.26 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1916844288689862		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.1916844288689862 | validation: 0.1514353603043725]
	TIME [epoch: 6.29 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16024478302986708		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.16024478302986708 | validation: 0.19766533317958332]
	TIME [epoch: 6.25 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18360362493745253		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.18360362493745253 | validation: 0.17050318712572562]
	TIME [epoch: 6.25 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17161719738685913		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.17161719738685913 | validation: 0.20930882977001375]
	TIME [epoch: 6.25 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.157105517469182		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.157105517469182 | validation: 0.1469581923005761]
	TIME [epoch: 6.25 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12940273358345836		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.12940273358345836 | validation: 0.19684774827217782]
	TIME [epoch: 6.27 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1586081335004259		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.1586081335004259 | validation: 0.5075256047355953]
	TIME [epoch: 6.28 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2339419203012088		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.2339419203012088 | validation: 0.19337694348704798]
	TIME [epoch: 6.25 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18033422020663098		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.18033422020663098 | validation: 0.18046591675204865]
	TIME [epoch: 6.25 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16324442449214094		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.16324442449214094 | validation: 0.25681956429767744]
	TIME [epoch: 6.25 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21677687745053742		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.21677687745053742 | validation: 0.2392478118743317]
	TIME [epoch: 6.25 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15482006004982035		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.15482006004982035 | validation: 0.27174521987228006]
	TIME [epoch: 6.27 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20843981291450608		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.20843981291450608 | validation: 0.31335110912000363]
	TIME [epoch: 6.28 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20614421705935881		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.20614421705935881 | validation: 0.15655311306952235]
	TIME [epoch: 6.25 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13111168881830537		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.13111168881830537 | validation: 0.14860062915968197]
	TIME [epoch: 6.25 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18991883507362167		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.18991883507362167 | validation: 0.19618387121015224]
	TIME [epoch: 6.25 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16804223839943602		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.16804223839943602 | validation: 0.16703096926794614]
	TIME [epoch: 6.25 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15526733907571075		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.15526733907571075 | validation: 0.13233568946473145]
	TIME [epoch: 6.28 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14499837252884062		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.14499837252884062 | validation: 0.17704118007471184]
	TIME [epoch: 6.27 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1436007769941657		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.1436007769941657 | validation: 0.1554100092672446]
	TIME [epoch: 6.25 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17841602995672165		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.17841602995672165 | validation: 0.20436827917663125]
	TIME [epoch: 6.25 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1409880640565171		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.1409880640565171 | validation: 0.18751595592674491]
	TIME [epoch: 6.25 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1626580922731811		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.1626580922731811 | validation: 0.16147781823402813]
	TIME [epoch: 6.25 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15037294339415563		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.15037294339415563 | validation: 0.17945584709734289]
	TIME [epoch: 6.28 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12903106725611896		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.12903106725611896 | validation: 0.17300906458310694]
	TIME [epoch: 6.27 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15517308231942462		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.15517308231942462 | validation: 0.1851640181626018]
	TIME [epoch: 6.25 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14076475822870127		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.14076475822870127 | validation: 0.14937169972051362]
	TIME [epoch: 6.25 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16307128245412728		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.16307128245412728 | validation: 0.19884076162659]
	TIME [epoch: 6.25 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17847935135743578		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.17847935135743578 | validation: 0.19256928331942652]
	TIME [epoch: 6.25 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12106363010319918		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.12106363010319918 | validation: 0.1405257992200688]
	TIME [epoch: 6.28 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12092502090133037		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.12092502090133037 | validation: 0.38516458717830404]
	TIME [epoch: 6.27 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1970817941878004		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.1970817941878004 | validation: 0.17271410510471427]
	TIME [epoch: 6.26 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14135895006979204		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.14135895006979204 | validation: 0.1485468992461097]
	TIME [epoch: 6.25 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15121601181026234		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.15121601181026234 | validation: 0.16791661816887932]
	TIME [epoch: 6.25 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14065605672167453		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.14065605672167453 | validation: 0.20349243011669021]
	TIME [epoch: 6.25 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14085553629771225		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.14085553629771225 | validation: 0.22210225629857594]
	TIME [epoch: 6.28 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17963268898067852		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.17963268898067852 | validation: 0.2174370058478596]
	TIME [epoch: 6.27 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18223615134861848		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.18223615134861848 | validation: 0.1627138065590108]
	TIME [epoch: 6.25 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12468495808884261		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.12468495808884261 | validation: 0.15531974570900514]
	TIME [epoch: 6.25 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13297076285796497		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.13297076285796497 | validation: 0.18027700445159417]
	TIME [epoch: 6.25 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.117961284043694		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.117961284043694 | validation: 0.19092114894041717]
	TIME [epoch: 6.25 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17981230023075911		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.17981230023075911 | validation: 0.23527502162467778]
	TIME [epoch: 6.29 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15748537376411445		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.15748537376411445 | validation: 0.13786872632052277]
	TIME [epoch: 6.27 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12574994628165476		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.12574994628165476 | validation: 0.13750467535968125]
	TIME [epoch: 6.26 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14609252641740655		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.14609252641740655 | validation: 0.2624475799576925]
	TIME [epoch: 6.25 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17476589473691073		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.17476589473691073 | validation: 0.1709923840166316]
	TIME [epoch: 6.25 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15974399858944793		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.15974399858944793 | validation: 0.1930255279014642]
	TIME [epoch: 6.25 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15795233791834573		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.15795233791834573 | validation: 0.1307326005325652]
	TIME [epoch: 6.29 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13019737108974455		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.13019737108974455 | validation: 0.1556442475121525]
	TIME [epoch: 6.26 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1517394544162125		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.1517394544162125 | validation: 0.24594671116084219]
	TIME [epoch: 6.25 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15755227545964398		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.15755227545964398 | validation: 0.20997058369112903]
	TIME [epoch: 6.25 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20720246875515708		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.20720246875515708 | validation: 0.1971198447898881]
	TIME [epoch: 6.25 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1720727535459698		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.1720727535459698 | validation: 0.1473715507996972]
	TIME [epoch: 6.25 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12097858344639872		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.12097858344639872 | validation: 0.13379206244898484]
	TIME [epoch: 6.29 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12142620912277813		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.12142620912277813 | validation: 0.20805476304383613]
	TIME [epoch: 6.26 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16636448116197716		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.16636448116197716 | validation: 0.13891832302241197]
	TIME [epoch: 6.25 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13691323895804502		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.13691323895804502 | validation: 0.1632796408464534]
	TIME [epoch: 6.25 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18739350144812383		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.18739350144812383 | validation: 0.20209532421370519]
	TIME [epoch: 6.25 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1438198067315174		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.1438198067315174 | validation: 0.25312969857079737]
	TIME [epoch: 6.25 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1791416655111568		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.1791416655111568 | validation: 0.12503144303179697]
	TIME [epoch: 6.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_756.pth
	Model improved!!!
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12353854535539213		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.12353854535539213 | validation: 0.20134192703673473]
	TIME [epoch: 6.26 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13111670686577914		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.13111670686577914 | validation: 0.12764727556982888]
	TIME [epoch: 6.24 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11098411785311504		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.11098411785311504 | validation: 0.1453851445684814]
	TIME [epoch: 6.25 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11444783127511743		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.11444783127511743 | validation: 0.1529463758632727]
	TIME [epoch: 6.24 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13674777312000888		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.13674777312000888 | validation: 0.1956596257430292]
	TIME [epoch: 6.24 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16840162441107703		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.16840162441107703 | validation: 0.1572077780390138]
	TIME [epoch: 6.29 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16768992827213097		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.16768992827213097 | validation: 0.1355101521461283]
	TIME [epoch: 6.25 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11963840143268126		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.11963840143268126 | validation: 0.11760370450798466]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_764.pth
	Model improved!!!
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14221640227979512		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.14221640227979512 | validation: 0.13325575996301783]
	TIME [epoch: 6.24 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17800735940287382		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.17800735940287382 | validation: 0.20544500731887502]
	TIME [epoch: 6.24 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16970646555638125		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.16970646555638125 | validation: 0.289073717060346]
	TIME [epoch: 6.25 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19963326199713866		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.19963326199713866 | validation: 0.17508433742063512]
	TIME [epoch: 6.28 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1281814276965128		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.1281814276965128 | validation: 0.13839909537464729]
	TIME [epoch: 6.24 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1260339612708945		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.1260339612708945 | validation: 0.1626291058795461]
	TIME [epoch: 6.24 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19427138780274494		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.19427138780274494 | validation: 0.23507422434196698]
	TIME [epoch: 6.25 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15438438922343967		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.15438438922343967 | validation: 0.1265936712793942]
	TIME [epoch: 6.24 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1338639542369117		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.1338639542369117 | validation: 0.2133155609073405]
	TIME [epoch: 6.24 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15205574841040131		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.15205574841040131 | validation: 0.16573526383268]
	TIME [epoch: 6.28 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.126543558245035		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.126543558245035 | validation: 0.11210627319034464]
	TIME [epoch: 6.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_775.pth
	Model improved!!!
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1192820845714769		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.1192820845714769 | validation: 0.14163245382998252]
	TIME [epoch: 6.24 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1161460712754322		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.1161460712754322 | validation: 0.1510855218294141]
	TIME [epoch: 6.23 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11836220133691014		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.11836220133691014 | validation: 0.13394491099140404]
	TIME [epoch: 6.23 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15046765489444652		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.15046765489444652 | validation: 0.17407877509871547]
	TIME [epoch: 6.25 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15614183307014215		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.15614183307014215 | validation: 0.13838923614039123]
	TIME [epoch: 6.27 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14475869399752497		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.14475869399752497 | validation: 0.16617380269064905]
	TIME [epoch: 6.24 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15451165192915708		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.15451165192915708 | validation: 0.1595056186811541]
	TIME [epoch: 6.24 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11742795092234679		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.11742795092234679 | validation: 0.26345981580712946]
	TIME [epoch: 6.24 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17177767095876292		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.17177767095876292 | validation: 0.18149664019473047]
	TIME [epoch: 6.23 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12916004586229768		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.12916004586229768 | validation: 0.1481643229858927]
	TIME [epoch: 6.25 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13877851351616954		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.13877851351616954 | validation: 0.19881607083349967]
	TIME [epoch: 6.27 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16327793218930334		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.16327793218930334 | validation: 0.16955224842540592]
	TIME [epoch: 6.24 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1361660575629732		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.1361660575629732 | validation: 0.12763796166691968]
	TIME [epoch: 6.23 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14244200781343364		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.14244200781343364 | validation: 0.15611954741263193]
	TIME [epoch: 6.23 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15459911237901813		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.15459911237901813 | validation: 0.13115034090337613]
	TIME [epoch: 6.23 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11303652501609776		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.11303652501609776 | validation: 0.13733081795521151]
	TIME [epoch: 6.24 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1243322465329452		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.1243322465329452 | validation: 0.15260128785919885]
	TIME [epoch: 6.27 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14871620107870223		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.14871620107870223 | validation: 0.15878566222527213]
	TIME [epoch: 6.24 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12084451023324808		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.12084451023324808 | validation: 0.2212007477444467]
	TIME [epoch: 6.23 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1577503178921471		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.1577503178921471 | validation: 0.11460318591263613]
	TIME [epoch: 6.23 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11024673589601978		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.11024673589601978 | validation: 0.15263682048887217]
	TIME [epoch: 6.23 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11855476397152998		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.11855476397152998 | validation: 0.11639485840135974]
	TIME [epoch: 6.24 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11521732116869741		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.11521732116869741 | validation: 0.21256719165774604]
	TIME [epoch: 6.27 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.158569491606442		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.158569491606442 | validation: 0.15062583094548052]
	TIME [epoch: 6.24 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1473867205430025		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.1473867205430025 | validation: 0.16600456259534244]
	TIME [epoch: 6.23 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1514699979315342		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.1514699979315342 | validation: 0.15739301783855528]
	TIME [epoch: 6.23 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13170910207981523		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.13170910207981523 | validation: 0.1653475583987835]
	TIME [epoch: 6.23 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13975085157146988		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.13975085157146988 | validation: 0.1735725930163252]
	TIME [epoch: 6.24 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1431005805640876		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.1431005805640876 | validation: 0.16968852332394785]
	TIME [epoch: 6.27 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11802287735382778		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.11802287735382778 | validation: 0.1201466146398882]
	TIME [epoch: 6.25 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10971763673748833		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.10971763673748833 | validation: 0.18393659892865266]
	TIME [epoch: 6.23 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1222831843005255		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.1222831843005255 | validation: 0.1775406045109892]
	TIME [epoch: 6.23 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16281886359905373		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.16281886359905373 | validation: 0.2212480665041283]
	TIME [epoch: 6.23 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1488893383811808		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.1488893383811808 | validation: 0.14767068099066677]
	TIME [epoch: 6.24 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12164948807705875		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.12164948807705875 | validation: 0.19555437710589707]
	TIME [epoch: 6.27 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1472940019012405		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.1472940019012405 | validation: 0.12870220285634482]
	TIME [epoch: 6.23 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11835682283934026		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.11835682283934026 | validation: 0.1947283825444521]
	TIME [epoch: 6.23 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12019240360465738		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.12019240360465738 | validation: 0.2006497564271446]
	TIME [epoch: 6.23 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17360166475619837		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.17360166475619837 | validation: 0.20758768716730913]
	TIME [epoch: 6.23 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15647303446248265		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.15647303446248265 | validation: 0.16287701661035786]
	TIME [epoch: 6.25 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1640161955973951		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.1640161955973951 | validation: 0.15481422264693045]
	TIME [epoch: 6.26 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13827285265886338		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.13827285265886338 | validation: 0.10884146719269147]
	TIME [epoch: 6.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_817.pth
	Model improved!!!
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11484060740794017		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.11484060740794017 | validation: 0.12870942252935832]
	TIME [epoch: 6.23 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11280783798820604		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.11280783798820604 | validation: 0.16445409615840678]
	TIME [epoch: 6.23 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11455253231115606		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.11455253231115606 | validation: 0.1282678888316215]
	TIME [epoch: 6.23 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12063412129680853		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.12063412129680853 | validation: 0.1356473733491544]
	TIME [epoch: 6.25 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1197912994354394		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.1197912994354394 | validation: 0.12902660251395165]
	TIME [epoch: 6.25 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1413899806144155		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.1413899806144155 | validation: 0.13974769735545634]
	TIME [epoch: 6.23 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1238107297912738		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.1238107297912738 | validation: 0.15879582328528663]
	TIME [epoch: 6.23 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12565617746270366		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.12565617746270366 | validation: 0.17447978366143943]
	TIME [epoch: 6.23 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13668391472939118		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.13668391472939118 | validation: 0.1164236467765466]
	TIME [epoch: 6.23 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1161427316019223		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.1161427316019223 | validation: 0.14969294574972314]
	TIME [epoch: 6.26 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13927457105793256		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.13927457105793256 | validation: 0.14943021384877175]
	TIME [epoch: 6.25 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13027038031415955		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.13027038031415955 | validation: 0.13932702329435942]
	TIME [epoch: 6.23 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11421916063407583		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.11421916063407583 | validation: 0.13377762910036106]
	TIME [epoch: 6.23 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12055215967874236		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.12055215967874236 | validation: 0.21300126236063033]
	TIME [epoch: 6.23 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14386111391101764		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.14386111391101764 | validation: 0.16337753656017862]
	TIME [epoch: 6.23 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11779221191800082		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.11779221191800082 | validation: 0.14572815166539016]
	TIME [epoch: 6.26 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1400539766197879		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.1400539766197879 | validation: 0.18663513354830058]
	TIME [epoch: 6.25 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15714353686767268		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.15714353686767268 | validation: 0.19116947165843046]
	TIME [epoch: 6.23 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11703944018020904		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.11703944018020904 | validation: 0.12797198727201994]
	TIME [epoch: 6.23 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13113514448087135		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.13113514448087135 | validation: 0.1556418494429973]
	TIME [epoch: 6.23 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1226733755938363		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.1226733755938363 | validation: 0.1509774349220723]
	TIME [epoch: 6.24 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11582791396737319		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.11582791396737319 | validation: 0.14474924220530624]
	TIME [epoch: 6.27 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13967379889606718		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.13967379889606718 | validation: 0.1882567122251761]
	TIME [epoch: 6.26 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13192595315498593		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.13192595315498593 | validation: 0.1070453799316457]
	TIME [epoch: 6.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_841.pth
	Model improved!!!
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11796996812106074		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.11796996812106074 | validation: 0.13333232161337183]
	TIME [epoch: 6.23 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14563167444681038		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.14563167444681038 | validation: 0.12551752680012632]
	TIME [epoch: 6.23 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1166841818334776		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.1166841818334776 | validation: 0.12551611167396037]
	TIME [epoch: 6.23 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12047479878668253		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.12047479878668253 | validation: 0.13204543365251376]
	TIME [epoch: 6.27 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10836279596777552		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.10836279596777552 | validation: 0.11981143618451279]
	TIME [epoch: 6.24 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10271176513549159		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.10271176513549159 | validation: 0.13385500391315758]
	TIME [epoch: 6.23 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11452152790363669		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.11452152790363669 | validation: 0.18249758509793787]
	TIME [epoch: 6.23 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11894260583028134		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.11894260583028134 | validation: 0.12975434646674996]
	TIME [epoch: 6.23 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10601479215415782		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.10601479215415782 | validation: 0.10565299153445762]
	TIME [epoch: 6.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_850.pth
	Model improved!!!
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10684829408014986		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.10684829408014986 | validation: 0.14257570673206993]
	TIME [epoch: 6.28 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1345175671084912		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.1345175671084912 | validation: 0.16677771966221558]
	TIME [epoch: 6.25 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1377536676186669		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.1377536676186669 | validation: 0.12021995886283514]
	TIME [epoch: 6.24 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11834642860117056		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.11834642860117056 | validation: 0.15307298696050364]
	TIME [epoch: 6.24 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14024205142111767		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.14024205142111767 | validation: 0.14985306121791647]
	TIME [epoch: 6.23 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12167703005592403		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.12167703005592403 | validation: 0.1268137566328073]
	TIME [epoch: 6.24 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10473279679614646		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.10473279679614646 | validation: 0.1574579538076864]
	TIME [epoch: 6.29 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11342361528229705		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.11342361528229705 | validation: 0.13865998257306383]
	TIME [epoch: 6.24 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13993209204230955		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.13993209204230955 | validation: 0.1883094193855225]
	TIME [epoch: 6.24 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1673331280385946		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.1673331280385946 | validation: 0.21278990687305657]
	TIME [epoch: 6.25 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15705270742767646		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.15705270742767646 | validation: 0.25863616589000366]
	TIME [epoch: 6.24 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1590379821664405		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.1590379821664405 | validation: 0.1485136385485599]
	TIME [epoch: 6.25 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13097068416908367		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.13097068416908367 | validation: 0.1915789110715555]
	TIME [epoch: 6.29 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13164852400409766		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.13164852400409766 | validation: 0.17839484908817083]
	TIME [epoch: 6.24 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14156477435929563		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.14156477435929563 | validation: 0.14424562986232778]
	TIME [epoch: 6.24 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1396087546664485		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.1396087546664485 | validation: 0.15938277595040995]
	TIME [epoch: 6.24 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12346714705256857		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.12346714705256857 | validation: 0.16252815025065875]
	TIME [epoch: 6.24 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11423613256786752		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.11423613256786752 | validation: 0.15239594861933242]
	TIME [epoch: 6.24 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11131713676681675		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.11131713676681675 | validation: 0.12303137956889959]
	TIME [epoch: 6.29 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10496386853709479		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.10496386853709479 | validation: 0.19813450457305865]
	TIME [epoch: 6.24 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13099770936840827		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.13099770936840827 | validation: 0.16351290888913836]
	TIME [epoch: 6.24 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16229792870871565		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.16229792870871565 | validation: 0.1630361733533852]
	TIME [epoch: 6.24 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12311495845465978		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.12311495845465978 | validation: 0.16944691832599884]
	TIME [epoch: 6.25 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12420534684762624		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.12420534684762624 | validation: 0.16757329227385367]
	TIME [epoch: 6.24 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1922292882683831		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.1922292882683831 | validation: 0.24288686794187236]
	TIME [epoch: 6.29 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15960510444631182		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.15960510444631182 | validation: 0.14948359501782132]
	TIME [epoch: 6.24 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14583244799257652		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.14583244799257652 | validation: 0.19246362152493998]
	TIME [epoch: 6.24 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14115136029812742		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.14115136029812742 | validation: 0.1947967305846835]
	TIME [epoch: 6.24 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1142432511118976		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.1142432511118976 | validation: 0.14177661345804254]
	TIME [epoch: 6.23 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12339030364680653		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.12339030364680653 | validation: 0.15040085199161185]
	TIME [epoch: 6.24 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12476643291084615		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.12476643291084615 | validation: 0.18161437403558428]
	TIME [epoch: 6.29 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1561111559542087		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.1561111559542087 | validation: 0.20269365241416212]
	TIME [epoch: 6.25 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16364288099037871		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.16364288099037871 | validation: 0.17355578976972613]
	TIME [epoch: 6.24 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1359670785290038		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.1359670785290038 | validation: 0.157770884537994]
	TIME [epoch: 6.24 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1259865659059762		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.1259865659059762 | validation: 0.18061654334416583]
	TIME [epoch: 6.24 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13863545989423093		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.13863545989423093 | validation: 0.12821018204022744]
	TIME [epoch: 6.24 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13838729431198352		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.13838729431198352 | validation: 0.16755394269776205]
	TIME [epoch: 6.28 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11827633277540656		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.11827633277540656 | validation: 0.11339722500128621]
	TIME [epoch: 6.23 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11196173863472926		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.11196173863472926 | validation: 0.186144409843723]
	TIME [epoch: 6.24 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12127953340559353		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.12127953340559353 | validation: 0.15224138654507166]
	TIME [epoch: 6.24 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10584170178246374		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.10584170178246374 | validation: 0.19567952536086503]
	TIME [epoch: 6.23 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12991087994725248		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.12991087994725248 | validation: 0.12962432902344856]
	TIME [epoch: 6.25 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11861219682977023		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.11861219682977023 | validation: 0.139198412072306]
	TIME [epoch: 6.29 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11311758904632183		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.11311758904632183 | validation: 0.15335092987699206]
	TIME [epoch: 6.24 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11567674902859013		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.11567674902859013 | validation: 0.13411271403177805]
	TIME [epoch: 6.24 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12677045345426127		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.12677045345426127 | validation: 0.13887915822572003]
	TIME [epoch: 6.23 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11612668861847061		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.11612668861847061 | validation: 0.13942232259028303]
	TIME [epoch: 6.24 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14476586781730358		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.14476586781730358 | validation: 0.15719987890212223]
	TIME [epoch: 6.24 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11164782787482283		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.11164782787482283 | validation: 0.17722434121968453]
	TIME [epoch: 6.29 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13435836932595727		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.13435836932595727 | validation: 0.15584782689348553]
	TIME [epoch: 6.25 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12388820660964465		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.12388820660964465 | validation: 0.13205811554188052]
	TIME [epoch: 6.24 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11067565328635182		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.11067565328635182 | validation: 0.1377362957230277]
	TIME [epoch: 6.24 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1314429711373305		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.1314429711373305 | validation: 0.15112477335098756]
	TIME [epoch: 6.23 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11978797636710986		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.11978797636710986 | validation: 0.12036881851397312]
	TIME [epoch: 6.24 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1001992074808738		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.1001992074808738 | validation: 0.11815731405486724]
	TIME [epoch: 6.28 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09599001854190545		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.09599001854190545 | validation: 0.11513477146944354]
	TIME [epoch: 6.24 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10551662435121456		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.10551662435121456 | validation: 0.1389024550045412]
	TIME [epoch: 6.25 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10866897911011336		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.10866897911011336 | validation: 0.14713089866400048]
	TIME [epoch: 6.24 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1239452517316072		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.1239452517316072 | validation: 0.12920831512158923]
	TIME [epoch: 6.24 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11561051334437968		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.11561051334437968 | validation: 0.11842215969630948]
	TIME [epoch: 6.25 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.108677099764542		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.108677099764542 | validation: 0.10058397791571683]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_911.pth
	Model improved!!!
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10435918625481191		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.10435918625481191 | validation: 0.1534993145700451]
	TIME [epoch: 6.24 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.121378208417592		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.121378208417592 | validation: 0.14074065012324427]
	TIME [epoch: 6.23 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11932249792752715		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.11932249792752715 | validation: 0.12709139330744135]
	TIME [epoch: 6.24 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10802250716772754		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.10802250716772754 | validation: 0.13605938915501178]
	TIME [epoch: 6.23 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1157334338012162		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.1157334338012162 | validation: 0.17212499317311197]
	TIME [epoch: 6.24 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14314639114534775		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.14314639114534775 | validation: 0.2833838950645803]
	TIME [epoch: 6.26 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20353551743282833		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.20353551743282833 | validation: 0.18970868198905805]
	TIME [epoch: 6.23 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13119119061112505		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.13119119061112505 | validation: 0.14746609170132946]
	TIME [epoch: 6.23 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12980212726571197		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.12980212726571197 | validation: 0.38184747723500156]
	TIME [epoch: 6.23 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19987408409992113		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.19987408409992113 | validation: 0.20279346530622444]
	TIME [epoch: 6.23 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16971416170384793		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.16971416170384793 | validation: 0.1644933665881373]
	TIME [epoch: 6.24 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12878762817579562		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.12878762817579562 | validation: 0.16037183022213036]
	TIME [epoch: 6.26 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12837596677054963		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.12837596677054963 | validation: 0.14341199898915527]
	TIME [epoch: 6.28 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12471303727632192		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.12471303727632192 | validation: 0.13195509263049582]
	TIME [epoch: 6.23 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11531455996933054		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.11531455996933054 | validation: 0.1536544091139786]
	TIME [epoch: 6.23 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10712739762077927		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.10712739762077927 | validation: 0.12578654607801532]
	TIME [epoch: 6.23 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11607090655906332		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.11607090655906332 | validation: 0.1553534867504469]
	TIME [epoch: 6.25 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1196271872542935		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.1196271872542935 | validation: 0.15854689489070733]
	TIME [epoch: 6.26 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11584352210149036		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.11584352210149036 | validation: 0.1633194902751619]
	TIME [epoch: 6.24 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12286782452488293		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.12286782452488293 | validation: 0.1750784032695893]
	TIME [epoch: 6.23 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13041467247694472		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.13041467247694472 | validation: 0.1430296392607025]
	TIME [epoch: 6.23 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12512451224845667		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.12512451224845667 | validation: 0.16648662680848098]
	TIME [epoch: 6.23 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13033232398043604		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.13033232398043604 | validation: 0.1660745887545791]
	TIME [epoch: 6.26 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12684431587814954		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.12684431587814954 | validation: 0.15998753150971423]
	TIME [epoch: 6.24 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12704726731590993		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.12704726731590993 | validation: 0.1493266909266125]
	TIME [epoch: 6.24 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11665958070113785		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.11665958070113785 | validation: 0.14073933011900824]
	TIME [epoch: 6.23 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11533177628978838		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.11533177628978838 | validation: 0.1427305370150157]
	TIME [epoch: 6.24 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10844597402261476		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.10844597402261476 | validation: 0.10549234706902771]
	TIME [epoch: 6.24 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10222334489443721		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.10222334489443721 | validation: 0.12217238097119013]
	TIME [epoch: 6.26 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12456542541215813		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.12456542541215813 | validation: 0.15405596084551718]
	TIME [epoch: 6.24 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11850110281458605		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.11850110281458605 | validation: 0.13905681917683366]
	TIME [epoch: 6.23 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12637978443681958		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.12637978443681958 | validation: 0.1158317111658356]
	TIME [epoch: 6.23 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10549148669105131		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.10549148669105131 | validation: 0.12579921087418938]
	TIME [epoch: 6.23 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09722241944324486		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.09722241944324486 | validation: 0.1333564506298195]
	TIME [epoch: 6.23 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10248447182111335		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.10248447182111335 | validation: 0.1291221988393378]
	TIME [epoch: 6.26 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10183736352692446		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.10183736352692446 | validation: 0.1427206566138922]
	TIME [epoch: 6.24 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1310242366736539		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.1310242366736539 | validation: 0.12409313511904435]
	TIME [epoch: 6.23 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12110545345985815		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.12110545345985815 | validation: 0.15738219518297394]
	TIME [epoch: 6.23 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11246919122991401		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.11246919122991401 | validation: 0.12156371115187196]
	TIME [epoch: 6.22 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1091842270172112		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.1091842270172112 | validation: 0.1380576159375193]
	TIME [epoch: 6.23 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10417674805274046		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.10417674805274046 | validation: 0.11180011008116338]
	TIME [epoch: 6.26 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10734379856273354		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.10734379856273354 | validation: 0.11460258124478473]
	TIME [epoch: 6.24 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10752013739815852		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.10752013739815852 | validation: 0.13318907113220224]
	TIME [epoch: 6.23 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10982177047029168		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.10982177047029168 | validation: 0.12546209331923008]
	TIME [epoch: 6.23 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12578305890558666		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.12578305890558666 | validation: 0.15574556358228542]
	TIME [epoch: 6.24 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14518488573559693		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.14518488573559693 | validation: 0.14522491877617005]
	TIME [epoch: 6.23 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10469159845915704		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.10469159845915704 | validation: 0.12540693290706723]
	TIME [epoch: 6.28 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10582279618260168		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.10582279618260168 | validation: 0.13257933149593007]
	TIME [epoch: 6.25 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09260504750903786		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.09260504750903786 | validation: 0.1408366796835721]
	TIME [epoch: 6.23 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1009455516582973		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.1009455516582973 | validation: 0.12177014654553375]
	TIME [epoch: 6.23 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1151044851557052		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.1151044851557052 | validation: 0.16980538625857688]
	TIME [epoch: 6.23 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11107712861419242		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.11107712861419242 | validation: 0.11514081402883453]
	TIME [epoch: 6.23 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1055424614285223		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.1055424614285223 | validation: 0.12902471016347705]
	TIME [epoch: 6.26 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1062888351476941		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.1062888351476941 | validation: 0.12883973657533532]
	TIME [epoch: 6.25 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11538594678363734		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.11538594678363734 | validation: 0.16676632448935763]
	TIME [epoch: 6.23 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10891936732803119		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.10891936732803119 | validation: 0.15158844589785192]
	TIME [epoch: 6.23 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1205049579950358		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.1205049579950358 | validation: 0.15180801350161438]
	TIME [epoch: 6.23 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10648785830353266		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.10648785830353266 | validation: 0.13908214099018656]
	TIME [epoch: 6.24 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09509464013011927		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.09509464013011927 | validation: 0.14470989065965412]
	TIME [epoch: 6.27 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09252284224189825		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.09252284224189825 | validation: 0.1127271798111044]
	TIME [epoch: 6.25 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09993759695511864		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.09993759695511864 | validation: 0.11930620364550837]
	TIME [epoch: 6.23 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09792348779234498		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.09792348779234498 | validation: 0.10894620889888962]
	TIME [epoch: 6.23 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09967373100569323		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.09967373100569323 | validation: 0.1251016411889967]
	TIME [epoch: 6.23 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10824206405654438		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.10824206405654438 | validation: 0.13660836976829893]
	TIME [epoch: 6.23 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09689973684902581		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.09689973684902581 | validation: 0.10789888472016596]
	TIME [epoch: 6.26 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09568827122666945		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.09568827122666945 | validation: 0.13067134870850267]
	TIME [epoch: 6.25 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11051260073066121		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.11051260073066121 | validation: 0.12761950044161086]
	TIME [epoch: 6.23 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11364152855748433		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.11364152855748433 | validation: 0.14799440759926483]
	TIME [epoch: 6.23 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11489092744174115		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.11489092744174115 | validation: 0.13067120908277008]
	TIME [epoch: 6.23 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11045432375940259		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.11045432375940259 | validation: 0.12684129204141922]
	TIME [epoch: 6.23 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10213389217636405		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.10213389217636405 | validation: 0.1217865938303614]
	TIME [epoch: 6.26 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10062660881405994		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.10062660881405994 | validation: 0.14530835853885887]
	TIME [epoch: 6.24 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12462610449913887		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.12462610449913887 | validation: 0.1708572707530207]
	TIME [epoch: 6.24 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1301008972932738		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.1301008972932738 | validation: 0.10984595379288983]
	TIME [epoch: 6.23 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09840276227232642		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.09840276227232642 | validation: 0.11566949325404902]
	TIME [epoch: 6.23 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10824255510798228		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.10824255510798228 | validation: 0.14082726420096392]
	TIME [epoch: 6.23 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10166256645094035		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.10166256645094035 | validation: 0.10609805894965757]
	TIME [epoch: 6.27 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09298762546739452		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.09298762546739452 | validation: 0.14196669023537653]
	TIME [epoch: 6.24 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10798234133179052		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.10798234133179052 | validation: 0.11978890257665437]
	TIME [epoch: 6.24 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09876272875531841		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.09876272875531841 | validation: 0.10704455345672637]
	TIME [epoch: 6.23 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11416320651957472		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.11416320651957472 | validation: 0.13085726382563367]
	TIME [epoch: 6.23 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09305878334788262		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.09305878334788262 | validation: 0.10974289675483949]
	TIME [epoch: 6.23 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09424848289825745		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.09424848289825745 | validation: 0.11791610273520545]
	TIME [epoch: 6.27 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09597448097202853		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.09597448097202853 | validation: 0.09840526003794056]
	TIME [epoch: 6.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_995.pth
	Model improved!!!
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1042653602211321		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.1042653602211321 | validation: 0.12907986621897682]
	TIME [epoch: 6.23 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10909294560122261		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.10909294560122261 | validation: 0.12260897245697677]
	TIME [epoch: 6.23 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1084702338653239		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.1084702338653239 | validation: 0.12123037391831316]
	TIME [epoch: 6.23 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.115968635443008		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.115968635443008 | validation: 0.13156153908709847]
	TIME [epoch: 6.23 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12286000018043265		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.12286000018043265 | validation: 0.11617339128860327]
	TIME [epoch: 6.27 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11727053954648371		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.11727053954648371 | validation: 0.17405654582992736]
	TIME [epoch: 6.23 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11849961262224112		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.11849961262224112 | validation: 0.14858645912072846]
	TIME [epoch: 6.23 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10491187885793142		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.10491187885793142 | validation: 0.09085823346739344]
	TIME [epoch: 6.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_1003.pth
	Model improved!!!
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08956828255392107		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.08956828255392107 | validation: 0.13008969774423385]
	TIME [epoch: 6.25 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09292724400866897		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.09292724400866897 | validation: 0.10333519612423817]
	TIME [epoch: 6.25 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09811793229007168		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.09811793229007168 | validation: 0.11838020860793097]
	TIME [epoch: 6.29 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09789277784938279		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.09789277784938279 | validation: 0.12830268038754336]
	TIME [epoch: 6.25 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09830438924975601		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.09830438924975601 | validation: 0.12009489937440979]
	TIME [epoch: 6.24 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10941986090217967		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.10941986090217967 | validation: 0.1404300912409075]
	TIME [epoch: 6.24 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10534752256551634		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.10534752256551634 | validation: 0.14141139516629098]
	TIME [epoch: 6.24 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11035976552027853		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.11035976552027853 | validation: 0.17674662269442748]
	TIME [epoch: 6.25 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12766469670458228		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.12766469670458228 | validation: 0.14919565326942558]
	TIME [epoch: 6.29 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11062046629853442		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.11062046629853442 | validation: 0.1760043974180477]
	TIME [epoch: 6.25 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11355775973813652		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.11355775973813652 | validation: 0.10851672860988382]
	TIME [epoch: 6.24 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09202740365622734		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.09202740365622734 | validation: 0.14239243430285858]
	TIME [epoch: 6.24 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1091387681943699		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.1091387681943699 | validation: 0.1751175117570161]
	TIME [epoch: 6.24 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11642444332113323		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.11642444332113323 | validation: 0.13803399529360877]
	TIME [epoch: 6.25 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1022490722340923		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.1022490722340923 | validation: 0.11930362498747209]
	TIME [epoch: 6.29 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09637280309911166		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.09637280309911166 | validation: 0.12234886885127866]
	TIME [epoch: 6.25 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09944937280601579		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.09944937280601579 | validation: 0.10474158452566396]
	TIME [epoch: 6.25 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10430399079146677		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.10430399079146677 | validation: 0.10381203395224095]
	TIME [epoch: 6.26 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09685869238767084		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.09685869238767084 | validation: 0.11044568716348041]
	TIME [epoch: 6.25 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11721234490285745		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.11721234490285745 | validation: 0.17156693136800055]
	TIME [epoch: 6.27 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12762265693314157		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.12762265693314157 | validation: 0.11552205218606654]
	TIME [epoch: 6.3 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09999224614609753		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.09999224614609753 | validation: 0.10985329919786367]
	TIME [epoch: 6.26 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10249577319730924		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.10249577319730924 | validation: 0.21312500534207635]
	TIME [epoch: 6.26 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12035626444045808		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.12035626444045808 | validation: 0.10695626020413657]
	TIME [epoch: 6.26 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09490721043818325		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.09490721043818325 | validation: 0.10515343835962382]
	TIME [epoch: 6.26 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10629217030118875		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.10629217030118875 | validation: 0.14553237014396697]
	TIME [epoch: 6.27 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10833097734660226		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.10833097734660226 | validation: 0.1398551285578218]
	TIME [epoch: 6.3 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10581403905517488		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.10581403905517488 | validation: 0.13875198817481593]
	TIME [epoch: 6.26 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11144734015711862		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.11144734015711862 | validation: 0.12280796398832232]
	TIME [epoch: 6.26 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10041459109082548		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.10041459109082548 | validation: 0.13968613636308277]
	TIME [epoch: 6.26 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11158365306934265		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.11158365306934265 | validation: 0.13262905468331862]
	TIME [epoch: 6.26 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11758622969124971		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.11758622969124971 | validation: 0.12339306899636593]
	TIME [epoch: 6.27 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11209815516651518		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.11209815516651518 | validation: 0.13618673497782907]
	TIME [epoch: 6.3 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10974786327411798		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.10974786327411798 | validation: 0.12014192367280005]
	TIME [epoch: 6.26 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11310955770642185		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.11310955770642185 | validation: 0.1434432661553373]
	TIME [epoch: 6.26 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12923186408187914		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.12923186408187914 | validation: 0.13974073315778351]
	TIME [epoch: 6.26 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11462715667341054		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.11462715667341054 | validation: 0.14745222389707452]
	TIME [epoch: 6.26 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12346496593401404		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.12346496593401404 | validation: 0.1531558877453827]
	TIME [epoch: 6.28 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10860654053136154		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.10860654053136154 | validation: 0.11727881938754028]
	TIME [epoch: 6.29 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11096455961890163		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.11096455961890163 | validation: 0.13364271448712567]
	TIME [epoch: 6.28 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13946224886336794		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.13946224886336794 | validation: 0.15827056473686757]
	TIME [epoch: 6.26 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12599602503828103		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.12599602503828103 | validation: 0.12513243273323363]
	TIME [epoch: 6.26 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11889914019679182		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.11889914019679182 | validation: 0.1343397874027233]
	TIME [epoch: 6.25 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11991217901720379		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.11991217901720379 | validation: 0.1346062998318578]
	TIME [epoch: 6.29 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1036937443132008		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.1036937443132008 | validation: 0.11394393636890045]
	TIME [epoch: 6.28 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10052641261736156		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.10052641261736156 | validation: 0.11572576367951293]
	TIME [epoch: 6.26 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09977605926800774		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.09977605926800774 | validation: 0.11437572596584478]
	TIME [epoch: 6.26 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08997531507331516		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.08997531507331516 | validation: 0.11716090981039361]
	TIME [epoch: 6.26 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10326535699756614		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.10326535699756614 | validation: 0.13598431522525245]
	TIME [epoch: 6.26 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10630763848882528		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.10630763848882528 | validation: 0.1018124380827172]
	TIME [epoch: 6.29 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10082827959123777		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.10082827959123777 | validation: 0.10198026051267273]
	TIME [epoch: 6.28 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08760338826593873		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.08760338826593873 | validation: 0.11449710842655167]
	TIME [epoch: 6.26 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10506788075478576		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.10506788075478576 | validation: 0.12155005191971857]
	TIME [epoch: 6.26 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10619461501545255		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.10619461501545255 | validation: 0.11220721681719002]
	TIME [epoch: 6.26 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11200263612629963		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.11200263612629963 | validation: 0.18605369814735484]
	TIME [epoch: 6.26 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1413058810160745		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.1413058810160745 | validation: 0.14254675478251302]
	TIME [epoch: 6.29 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12482548570352896		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.12482548570352896 | validation: 0.12525454869825206]
	TIME [epoch: 6.28 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11581966116390333		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.11581966116390333 | validation: 0.13162601767562415]
	TIME [epoch: 6.26 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1130558700959696		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.1130558700959696 | validation: 0.13696646097626597]
	TIME [epoch: 6.26 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11734386759454371		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.11734386759454371 | validation: 0.120950735655434]
	TIME [epoch: 6.26 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0962438127659008		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.0962438127659008 | validation: 0.10664518841505136]
	TIME [epoch: 6.26 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11456915771742837		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.11456915771742837 | validation: 0.17465487818888348]
	TIME [epoch: 6.29 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1810762254548763		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.1810762254548763 | validation: 0.15591702570169866]
	TIME [epoch: 6.27 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1282640443399981		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.1282640443399981 | validation: 0.13889215364115948]
	TIME [epoch: 6.26 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1139897874313697		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.1139897874313697 | validation: 0.11762514875998956]
	TIME [epoch: 6.26 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09925466918328456		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.09925466918328456 | validation: 0.11540258011576009]
	TIME [epoch: 6.26 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10425227250165761		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.10425227250165761 | validation: 0.11358074886620263]
	TIME [epoch: 6.26 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11214410486901769		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.11214410486901769 | validation: 0.15768644446097094]
	TIME [epoch: 6.3 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11439795806552983		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.11439795806552983 | validation: 0.14110228846928072]
	TIME [epoch: 6.27 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10484587773983904		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.10484587773983904 | validation: 0.13860350464183788]
	TIME [epoch: 6.26 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11868614159709494		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.11868614159709494 | validation: 0.18191179222091694]
	TIME [epoch: 6.26 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12998088958555704		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.12998088958555704 | validation: 0.10189073302949489]
	TIME [epoch: 6.26 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09646109976131825		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.09646109976131825 | validation: 0.1093432904248462]
	TIME [epoch: 6.26 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09670062046185318		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.09670062046185318 | validation: 0.12068313825754313]
	TIME [epoch: 6.31 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09878394667565663		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.09878394667565663 | validation: 0.11428422805059452]
	TIME [epoch: 6.27 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11269888436290111		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.11269888436290111 | validation: 0.12280423446117031]
	TIME [epoch: 6.26 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09452290090281613		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.09452290090281613 | validation: 0.10836771539231908]
	TIME [epoch: 6.26 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09019450851302684		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.09019450851302684 | validation: 0.10570213803188272]
	TIME [epoch: 6.26 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.099185462205535		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.099185462205535 | validation: 0.12200231541512072]
	TIME [epoch: 6.25 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1121815767069073		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.1121815767069073 | validation: 0.17739747874179956]
	TIME [epoch: 6.3 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11830534653621218		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.11830534653621218 | validation: 0.14677866552456148]
	TIME [epoch: 6.26 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10686537815320309		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.10686537815320309 | validation: 0.1250855344686832]
	TIME [epoch: 6.26 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09918482812049909		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.09918482812049909 | validation: 0.11554549405207135]
	TIME [epoch: 6.26 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09152061059911942		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.09152061059911942 | validation: 0.09818228274965084]
	TIME [epoch: 6.26 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09867112960418584		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.09867112960418584 | validation: 0.10946794892565456]
	TIME [epoch: 6.26 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09518736393273007		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.09518736393273007 | validation: 0.11600693249075915]
	TIME [epoch: 6.3 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10078102485203591		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.10078102485203591 | validation: 0.10622221756549924]
	TIME [epoch: 6.27 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11540767186849049		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.11540767186849049 | validation: 0.13263289476914789]
	TIME [epoch: 6.26 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10174405605791567		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.10174405605791567 | validation: 0.13665509609051538]
	TIME [epoch: 6.25 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10233305944109526		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.10233305944109526 | validation: 0.13309920217107624]
	TIME [epoch: 6.26 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.110005371412581		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.110005371412581 | validation: 0.11601540584502129]
	TIME [epoch: 6.25 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10479001518351937		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.10479001518351937 | validation: 0.11748777733343888]
	TIME [epoch: 6.3 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11236015927871403		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.11236015927871403 | validation: 0.12031737836627555]
	TIME [epoch: 6.26 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11181776751283243		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.11181776751283243 | validation: 0.1614771022317642]
	TIME [epoch: 6.26 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11441567184796651		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.11441567184796651 | validation: 0.11974443836173398]
	TIME [epoch: 6.25 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10188681864472085		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.10188681864472085 | validation: 0.12418482502442713]
	TIME [epoch: 6.26 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11294300227836206		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.11294300227836206 | validation: 0.11501854914022476]
	TIME [epoch: 6.26 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10665774124632339		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.10665774124632339 | validation: 0.11372450186238045]
	TIME [epoch: 6.33 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09793486257626682		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.09793486257626682 | validation: 0.11357366126024508]
	TIME [epoch: 6.26 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10058369857018618		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.10058369857018618 | validation: 0.1167640517910955]
	TIME [epoch: 6.26 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09674891645576782		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.09674891645576782 | validation: 0.11042082942709247]
	TIME [epoch: 6.25 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09088915416476481		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.09088915416476481 | validation: 0.11067517133412347]
	TIME [epoch: 6.26 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09433965689112482		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.09433965689112482 | validation: 0.11745185681555737]
	TIME [epoch: 6.26 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09615948082561389		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.09615948082561389 | validation: 0.10241905917907568]
	TIME [epoch: 6.3 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09775258161593		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.09775258161593 | validation: 0.1325887431458841]
	TIME [epoch: 6.26 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09928908408482284		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.09928908408482284 | validation: 0.1458211851907739]
	TIME [epoch: 6.26 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11087236508375521		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.11087236508375521 | validation: 0.1091569263809136]
	TIME [epoch: 6.26 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09914008214630805		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.09914008214630805 | validation: 0.09732942870101288]
	TIME [epoch: 6.25 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09864661830218988		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.09864661830218988 | validation: 0.1111290040508292]
	TIME [epoch: 6.26 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09648241932919174		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.09648241932919174 | validation: 0.09627827266151909]
	TIME [epoch: 6.3 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09733283257541278		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.09733283257541278 | validation: 0.131780301155727]
	TIME [epoch: 6.26 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09866552896942948		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.09866552896942948 | validation: 0.11704071121838405]
	TIME [epoch: 6.26 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09536256153862138		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.09536256153862138 | validation: 0.10565712354321644]
	TIME [epoch: 6.25 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09481111616238214		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.09481111616238214 | validation: 0.11642084488474433]
	TIME [epoch: 6.25 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1085031668817209		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.1085031668817209 | validation: 0.11275788983539428]
	TIME [epoch: 6.26 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09906813355359363		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.09906813355359363 | validation: 0.12102059359058374]
	TIME [epoch: 6.3 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0944508122674721		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.0944508122674721 | validation: 0.12344917390213148]
	TIME [epoch: 6.26 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09383656395435112		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.09383656395435112 | validation: 0.10616189261796001]
	TIME [epoch: 6.26 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09794672485804451		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.09794672485804451 | validation: 0.11807606765894914]
	TIME [epoch: 6.25 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11302109652471032		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.11302109652471032 | validation: 0.12153611296805054]
	TIME [epoch: 6.25 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11482583979670707		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.11482583979670707 | validation: 0.12624019149345492]
	TIME [epoch: 6.27 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10740766985592287		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.10740766985592287 | validation: 0.11448657599148648]
	TIME [epoch: 6.29 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10384798756737881		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.10384798756737881 | validation: 0.12310802339701418]
	TIME [epoch: 6.26 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10706718955761524		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.10706718955761524 | validation: 0.10592773684570411]
	TIME [epoch: 6.25 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09584067787134395		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.09584067787134395 | validation: 0.09512928778919547]
	TIME [epoch: 6.25 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08646651207718603		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.08646651207718603 | validation: 0.10180694225494438]
	TIME [epoch: 6.25 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09556548858228284		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.09556548858228284 | validation: 0.12139689388009323]
	TIME [epoch: 6.27 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09665563804721128		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.09665563804721128 | validation: 0.10727679042092]
	TIME [epoch: 6.3 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11124499042386127		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.11124499042386127 | validation: 0.13474068535910017]
	TIME [epoch: 6.26 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12112492147123		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.12112492147123 | validation: 0.14596370692003569]
	TIME [epoch: 6.26 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11365115887316632		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.11365115887316632 | validation: 0.11176138385286868]
	TIME [epoch: 6.26 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10298997670815824		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.10298997670815824 | validation: 0.12981903379626006]
	TIME [epoch: 6.26 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10401672013763785		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.10401672013763785 | validation: 0.12301148475814094]
	TIME [epoch: 6.27 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09047739551685846		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.09047739551685846 | validation: 0.09484245740193716]
	TIME [epoch: 6.29 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08601017412243066		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.08601017412243066 | validation: 0.10153114494554594]
	TIME [epoch: 6.26 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09183024010417448		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.09183024010417448 | validation: 0.1003214345369815]
	TIME [epoch: 6.27 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08383699543725914		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.08383699543725914 | validation: 0.09594628839603006]
	TIME [epoch: 6.26 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09648592132306816		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.09648592132306816 | validation: 0.11647555150062766]
	TIME [epoch: 6.25 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09193026220945222		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.09193026220945222 | validation: 0.1314164934062269]
	TIME [epoch: 6.27 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09641840594352685		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.09641840594352685 | validation: 0.09828814571700761]
	TIME [epoch: 6.28 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08824049006830256		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.08824049006830256 | validation: 0.11010318813209248]
	TIME [epoch: 6.26 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08824852025819227		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.08824852025819227 | validation: 0.11363236718650184]
	TIME [epoch: 6.25 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08574570533674963		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.08574570533674963 | validation: 0.10686632093518417]
	TIME [epoch: 6.27 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09667238857570057		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.09667238857570057 | validation: 0.10847167485141658]
	TIME [epoch: 6.25 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10155173441733861		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.10155173441733861 | validation: 0.12736647099607784]
	TIME [epoch: 6.28 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09902313247714892		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.09902313247714892 | validation: 0.1252988680899867]
	TIME [epoch: 6.27 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09893880719903553		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.09893880719903553 | validation: 0.12787799838553215]
	TIME [epoch: 6.25 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10770355362837868		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.10770355362837868 | validation: 0.128571149580785]
	TIME [epoch: 6.25 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09349669411174875		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.09349669411174875 | validation: 0.1129772842832115]
	TIME [epoch: 6.26 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10146863237180478		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.10146863237180478 | validation: 0.11728649032007307]
	TIME [epoch: 6.25 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0886549355250833		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.0886549355250833 | validation: 0.10017170834873523]
	TIME [epoch: 6.29 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08832319572406244		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.08832319572406244 | validation: 0.11732335683081188]
	TIME [epoch: 6.27 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09113962566558134		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.09113962566558134 | validation: 0.10416842065046052]
	TIME [epoch: 6.25 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09362898573641963		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.09362898573641963 | validation: 0.12990598816064863]
	TIME [epoch: 6.25 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10330664006974077		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.10330664006974077 | validation: 0.13074210505436912]
	TIME [epoch: 6.25 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10337214166736124		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.10337214166736124 | validation: 0.11563817998129435]
	TIME [epoch: 6.25 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0969672175578592		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.0969672175578592 | validation: 0.11920667714214792]
	TIME [epoch: 6.28 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10417834593565468		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.10417834593565468 | validation: 0.11491340167155793]
	TIME [epoch: 6.26 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09556537704698687		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.09556537704698687 | validation: 0.10990776616742648]
	TIME [epoch: 6.25 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10179112766999705		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.10179112766999705 | validation: 0.11875591542824225]
	TIME [epoch: 6.28 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10142541251665647		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.10142541251665647 | validation: 0.12174723485319036]
	TIME [epoch: 6.25 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08387865746028157		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.08387865746028157 | validation: 0.12710360873293264]
	TIME [epoch: 6.25 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11094934218703385		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.11094934218703385 | validation: 0.11720146553776047]
	TIME [epoch: 6.28 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09922616625866858		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.09922616625866858 | validation: 0.10581091791726303]
	TIME [epoch: 6.26 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08959702107932598		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.08959702107932598 | validation: 0.11622355665820817]
	TIME [epoch: 6.25 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09213506610683196		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.09213506610683196 | validation: 0.11971830118137056]
	TIME [epoch: 6.25 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09368410632104524		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.09368410632104524 | validation: 0.11891436646331072]
	TIME [epoch: 6.25 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10411238914509584		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.10411238914509584 | validation: 0.1296590609645777]
	TIME [epoch: 6.25 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1123961804049389		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.1123961804049389 | validation: 0.12429794648258427]
	TIME [epoch: 6.28 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10566232933112266		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.10566232933112266 | validation: 0.1172990223355991]
	TIME [epoch: 6.26 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09393580255789173		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.09393580255789173 | validation: 0.10291543116838742]
	TIME [epoch: 6.25 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09777950376025961		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.09777950376025961 | validation: 0.10534639023881107]
	TIME [epoch: 6.24 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09383509948854833		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.09383509948854833 | validation: 0.13132589991924923]
	TIME [epoch: 6.24 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09418598716733367		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.09418598716733367 | validation: 0.10975727151589947]
	TIME [epoch: 6.25 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09110898764415072		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.09110898764415072 | validation: 0.10775494747646439]
	TIME [epoch: 6.29 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0870319840486953		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.0870319840486953 | validation: 0.10397092456398858]
	TIME [epoch: 6.26 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.086531471979636		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.086531471979636 | validation: 0.0996326708043582]
	TIME [epoch: 6.29 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0928993134749867		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.0928993134749867 | validation: 0.10232446543542817]
	TIME [epoch: 6.26 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09287043124056295		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.09287043124056295 | validation: 0.10343178227342381]
	TIME [epoch: 6.27 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08439369822545277		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.08439369822545277 | validation: 0.1009828858801847]
	TIME [epoch: 6.25 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0899823440343891		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.0899823440343891 | validation: 0.11114820087178384]
	TIME [epoch: 6.29 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10019168690405426		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.10019168690405426 | validation: 0.14451545103636443]
	TIME [epoch: 6.26 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1039954455293525		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.1039954455293525 | validation: 0.09937760976767053]
	TIME [epoch: 6.25 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0960140556580912		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.0960140556580912 | validation: 0.12963768815638427]
	TIME [epoch: 6.25 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09452053458619464		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.09452053458619464 | validation: 0.09896609255789758]
	TIME [epoch: 6.25 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09236688659306617		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.09236688659306617 | validation: 0.10424350975341623]
	TIME [epoch: 6.25 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09319799537090127		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.09319799537090127 | validation: 0.13048039300033723]
	TIME [epoch: 6.29 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10089016667549075		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.10089016667549075 | validation: 0.1084048428788805]
	TIME [epoch: 6.25 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10078588825573684		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.10078588825573684 | validation: 0.10544773172898017]
	TIME [epoch: 6.25 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09269323738483187		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.09269323738483187 | validation: 0.1506013826501934]
	TIME [epoch: 6.25 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10585590757234928		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.10585590757234928 | validation: 0.11137955737760004]
	TIME [epoch: 6.25 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09658323007911938		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.09658323007911938 | validation: 0.13575409886794176]
	TIME [epoch: 6.25 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10181915804293319		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.10181915804293319 | validation: 0.1260084854169179]
	TIME [epoch: 6.29 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09532935065761888		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.09532935065761888 | validation: 0.11028186617499874]
	TIME [epoch: 6.26 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08731270030161069		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.08731270030161069 | validation: 0.10491279554418387]
	TIME [epoch: 6.25 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09387883878349497		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.09387883878349497 | validation: 0.09090181693323747]
	TIME [epoch: 6.25 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08924081866041485		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.08924081866041485 | validation: 0.10812082119025054]
	TIME [epoch: 6.25 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08891886036003431		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.08891886036003431 | validation: 0.10446804748642116]
	TIME [epoch: 6.25 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09348194952964135		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.09348194952964135 | validation: 0.1192984569728949]
	TIME [epoch: 6.3 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09744829396515858		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.09744829396515858 | validation: 0.1134505776885211]
	TIME [epoch: 6.26 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10248998220802727		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.10248998220802727 | validation: 0.11059959552866613]
	TIME [epoch: 6.25 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09888339445077615		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.09888339445077615 | validation: 0.1108589213395467]
	TIME [epoch: 6.25 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09742650643071608		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.09742650643071608 | validation: 0.136660097905769]
	TIME [epoch: 6.25 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10220522620666657		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.10220522620666657 | validation: 0.11221114952662997]
	TIME [epoch: 6.26 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08978091748402597		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.08978091748402597 | validation: 0.11161156181848955]
	TIME [epoch: 6.3 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09275811966699885		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.09275811966699885 | validation: 0.125925248574621]
	TIME [epoch: 6.26 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11274893790671167		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.11274893790671167 | validation: 0.10457113051202682]
	TIME [epoch: 6.25 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0975424535757513		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.0975424535757513 | validation: 0.1269663457730214]
	TIME [epoch: 6.25 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09961829122925854		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.09961829122925854 | validation: 0.12005909738379619]
	TIME [epoch: 6.24 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0900731196762868		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.0900731196762868 | validation: 0.09687360964538608]
	TIME [epoch: 6.25 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08340067314597434		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.08340067314597434 | validation: 0.11707053564021422]
	TIME [epoch: 6.31 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09610386586358671		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.09610386586358671 | validation: 0.11702214178436476]
	TIME [epoch: 6.25 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09169486849389102		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.09169486849389102 | validation: 0.1056239515540056]
	TIME [epoch: 6.25 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08392714989403972		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.08392714989403972 | validation: 0.10318285446794936]
	TIME [epoch: 6.25 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08608096865270554		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.08608096865270554 | validation: 0.09529204608654618]
	TIME [epoch: 6.24 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0890174257255453		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.0890174257255453 | validation: 0.10821644422518686]
	TIME [epoch: 6.25 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09323866220416026		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.09323866220416026 | validation: 0.11674472558115201]
	TIME [epoch: 6.29 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08715784386183603		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.08715784386183603 | validation: 0.11632484212000879]
	TIME [epoch: 6.25 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09714568513188121		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.09714568513188121 | validation: 0.1254318214932429]
	TIME [epoch: 6.25 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09406626277372154		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.09406626277372154 | validation: 0.11552546158468059]
	TIME [epoch: 6.25 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09057316683343627		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.09057316683343627 | validation: 0.11607468160883616]
	TIME [epoch: 6.25 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09166756158007143		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.09166756158007143 | validation: 0.11231795730067815]
	TIME [epoch: 6.25 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08880566898117132		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.08880566898117132 | validation: 0.09931552066313581]
	TIME [epoch: 6.29 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09002257889807844		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.09002257889807844 | validation: 0.10295511493997578]
	TIME [epoch: 6.25 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09356644737431327		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.09356644737431327 | validation: 0.10757014366225756]
	TIME [epoch: 6.25 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08874007034104209		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.08874007034104209 | validation: 0.1100884390274422]
	TIME [epoch: 6.25 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08801127251056759		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.08801127251056759 | validation: 0.10598995707881155]
	TIME [epoch: 6.25 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0859985820377276		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.0859985820377276 | validation: 0.10348651876379612]
	TIME [epoch: 6.27 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09887546735629207		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.09887546735629207 | validation: 0.13349339317938644]
	TIME [epoch: 6.28 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10764631455088397		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.10764631455088397 | validation: 0.10383024099481328]
	TIME [epoch: 6.25 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09866525634418596		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.09866525634418596 | validation: 0.12172379983965075]
	TIME [epoch: 6.25 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09986073497405501		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.09986073497405501 | validation: 0.10846673108896232]
	TIME [epoch: 6.25 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10327972548521766		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.10327972548521766 | validation: 0.10701925361963713]
	TIME [epoch: 6.25 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1016101799688762		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.1016101799688762 | validation: 0.10386573674661329]
	TIME [epoch: 6.26 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09790544864429915		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.09790544864429915 | validation: 0.12657718868576756]
	TIME [epoch: 6.29 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09542336168104398		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.09542336168104398 | validation: 0.10819478404632234]
	TIME [epoch: 6.25 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08449396188221339		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.08449396188221339 | validation: 0.0949968326754025]
	TIME [epoch: 6.25 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0861409625439872		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.0861409625439872 | validation: 0.10664909143874496]
	TIME [epoch: 6.25 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08365684578548242		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.08365684578548242 | validation: 0.10865855352086727]
	TIME [epoch: 6.25 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08744669269722014		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.08744669269722014 | validation: 0.10025066332192235]
	TIME [epoch: 6.26 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08501586657450622		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.08501586657450622 | validation: 0.11997537741444211]
	TIME [epoch: 6.29 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09547655243669731		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.09547655243669731 | validation: 0.10204340181407907]
	TIME [epoch: 6.25 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09318361662274123		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.09318361662274123 | validation: 0.10590168300985323]
	TIME [epoch: 6.25 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08734809763370349		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.08734809763370349 | validation: 0.10499759829687544]
	TIME [epoch: 6.25 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10105134206750946		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.10105134206750946 | validation: 0.09328465276417583]
	TIME [epoch: 6.28 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08787469766318895		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.08787469766318895 | validation: 0.10977840943288436]
	TIME [epoch: 6.27 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09348355844829498		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.09348355844829498 | validation: 0.10316255257561763]
	TIME [epoch: 6.28 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08524989573544461		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.08524989573544461 | validation: 0.10651693418070995]
	TIME [epoch: 6.25 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08946753278966961		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.08946753278966961 | validation: 0.09747287885379965]
	TIME [epoch: 6.24 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0895675095856125		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.0895675095856125 | validation: 0.12555256111045127]
	TIME [epoch: 6.25 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10308992922682077		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.10308992922682077 | validation: 0.11750402933893417]
	TIME [epoch: 6.24 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09476225661032595		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.09476225661032595 | validation: 0.11515604214766095]
	TIME [epoch: 6.28 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09504900449508355		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.09504900449508355 | validation: 0.1127374148918771]
	TIME [epoch: 6.26 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09868319071150403		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.09868319071150403 | validation: 0.106744687018968]
	TIME [epoch: 6.25 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09360192593402517		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.09360192593402517 | validation: 0.1105842191493678]
	TIME [epoch: 6.24 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09167531002097626		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.09167531002097626 | validation: 0.10917777508774294]
	TIME [epoch: 6.24 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09250322460853203		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.09250322460853203 | validation: 0.1219647093523552]
	TIME [epoch: 6.24 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09612264918617708		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.09612264918617708 | validation: 0.10502316549823534]
	TIME [epoch: 6.28 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09231868355712326		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.09231868355712326 | validation: 0.11894645483052244]
	TIME [epoch: 6.26 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09912042331186761		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.09912042331186761 | validation: 0.1412256468202133]
	TIME [epoch: 6.25 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09412212587901464		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.09412212587901464 | validation: 0.11940695352848402]
	TIME [epoch: 6.24 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0996283484371949		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.0996283484371949 | validation: 0.12627924545655803]
	TIME [epoch: 6.24 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0964945612605482		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.0964945612605482 | validation: 0.11642653206714826]
	TIME [epoch: 6.24 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0890167476800316		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.0890167476800316 | validation: 0.11164535438148254]
	TIME [epoch: 6.27 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08559914053539487		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.08559914053539487 | validation: 0.11840043071276064]
	TIME [epoch: 6.26 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09331852637946499		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.09331852637946499 | validation: 0.0994689705097325]
	TIME [epoch: 6.25 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09412641098738214		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.09412641098738214 | validation: 0.10684174323680691]
	TIME [epoch: 6.24 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0955732123314509		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.0955732123314509 | validation: 0.09230815818439635]
	TIME [epoch: 6.24 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08645231206822154		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.08645231206822154 | validation: 0.09810597367398233]
	TIME [epoch: 6.24 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08720196877463354		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.08720196877463354 | validation: 0.12424720071973774]
	TIME [epoch: 6.28 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09892868254054485		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.09892868254054485 | validation: 0.11800523251132086]
	TIME [epoch: 6.26 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09149216898200939		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.09149216898200939 | validation: 0.1290545532403775]
	TIME [epoch: 6.25 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09163994175874478		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.09163994175874478 | validation: 0.09840821202800873]
	TIME [epoch: 6.24 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09848317721420158		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.09848317721420158 | validation: 0.11972865074771946]
	TIME [epoch: 6.25 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10167948685703022		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.10167948685703022 | validation: 0.12562912621818642]
	TIME [epoch: 6.24 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0927308479130763		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.0927308479130763 | validation: 0.10577461726541965]
	TIME [epoch: 6.27 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.089085870226123		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.089085870226123 | validation: 0.11566600728477676]
	TIME [epoch: 6.26 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09273208167693382		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.09273208167693382 | validation: 0.1161648498541113]
	TIME [epoch: 6.25 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09310994416995913		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.09310994416995913 | validation: 0.10515191704308251]
	TIME [epoch: 6.24 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09434830434944302		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.09434830434944302 | validation: 0.1300842981982654]
	TIME [epoch: 6.26 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09641091747186523		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.09641091747186523 | validation: 0.11125673062153399]
	TIME [epoch: 6.24 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08467817337741428		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.08467817337741428 | validation: 0.10805140761321119]
	TIME [epoch: 6.29 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09135933378538207		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.09135933378538207 | validation: 0.09541715726750225]
	TIME [epoch: 6.26 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08785021549756711		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.08785021549756711 | validation: 0.1093819007239217]
	TIME [epoch: 6.25 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09225400733862167		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.09225400733862167 | validation: 0.10284772020822905]
	TIME [epoch: 6.24 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08872480713167497		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.08872480713167497 | validation: 0.1039077300231312]
	TIME [epoch: 6.24 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09487261938001598		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.09487261938001598 | validation: 0.10733185023931607]
	TIME [epoch: 6.24 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0952473392596727		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.0952473392596727 | validation: 0.10983997364914627]
	TIME [epoch: 6.28 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08641920651230398		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.08641920651230398 | validation: 0.10021428249652872]
	TIME [epoch: 6.26 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08838916740680558		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.08838916740680558 | validation: 0.10991246321169579]
	TIME [epoch: 6.24 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08892336685384516		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.08892336685384516 | validation: 0.09273387206699751]
	TIME [epoch: 6.24 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09501462616612692		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.09501462616612692 | validation: 0.1155086753534092]
	TIME [epoch: 6.24 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09144750754301664		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.09144750754301664 | validation: 0.11718695136977503]
	TIME [epoch: 6.24 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09198695208763544		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.09198695208763544 | validation: 0.10576237823533938]
	TIME [epoch: 6.28 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09537895056924373		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.09537895056924373 | validation: 0.11288376705378005]
	TIME [epoch: 6.25 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08967338461361202		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.08967338461361202 | validation: 0.12362872284872321]
	TIME [epoch: 6.25 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0926274343739896		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.0926274343739896 | validation: 0.10350452067959805]
	TIME [epoch: 6.26 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08881074148572352		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.08881074148572352 | validation: 0.0967624024715947]
	TIME [epoch: 6.24 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09400137569428445		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.09400137569428445 | validation: 0.10185905225582569]
	TIME [epoch: 6.24 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08423478801030355		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.08423478801030355 | validation: 0.09014547780947882]
	TIME [epoch: 6.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_1303.pth
	Model improved!!!
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08432812854309998		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.08432812854309998 | validation: 0.09538928079661411]
	TIME [epoch: 6.25 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08593749573550327		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.08593749573550327 | validation: 0.09342670001867755]
	TIME [epoch: 6.24 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0863636825699727		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.0863636825699727 | validation: 0.10454413964461692]
	TIME [epoch: 6.24 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08849339109086796		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.08849339109086796 | validation: 0.11589712774070803]
	TIME [epoch: 6.24 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0883155575518099		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.0883155575518099 | validation: 0.1316640809312749]
	TIME [epoch: 6.24 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10188771522098136		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.10188771522098136 | validation: 0.1199399183857143]
	TIME [epoch: 6.29 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09029012826780475		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.09029012826780475 | validation: 0.12087186875843323]
	TIME [epoch: 6.25 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10864879867695222		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.10864879867695222 | validation: 0.13221371157487538]
	TIME [epoch: 6.24 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10226959254895958		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.10226959254895958 | validation: 0.11641454849194793]
	TIME [epoch: 6.25 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.092535968357017		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.092535968357017 | validation: 0.10688932224172071]
	TIME [epoch: 6.25 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0853526235468674		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.0853526235468674 | validation: 0.10456964022361956]
	TIME [epoch: 6.25 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08036866069526566		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.08036866069526566 | validation: 0.11484782912810976]
	TIME [epoch: 6.29 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08517132494213188		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.08517132494213188 | validation: 0.11066082927941231]
	TIME [epoch: 6.25 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08926292057239216		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.08926292057239216 | validation: 0.10715422850842876]
	TIME [epoch: 6.24 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08456825437508768		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.08456825437508768 | validation: 0.1176543801208865]
	TIME [epoch: 6.24 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09092870291729706		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.09092870291729706 | validation: 0.10924853935877588]
	TIME [epoch: 6.24 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09084974739278508		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.09084974739278508 | validation: 0.10675702660427638]
	TIME [epoch: 6.25 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09086378155966064		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.09086378155966064 | validation: 0.09583433857307105]
	TIME [epoch: 6.29 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08758058329872634		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.08758058329872634 | validation: 0.1282711091929341]
	TIME [epoch: 6.25 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09895221515438972		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.09895221515438972 | validation: 0.11856945820867988]
	TIME [epoch: 6.25 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09274248737528168		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.09274248737528168 | validation: 0.10204814813264207]
	TIME [epoch: 6.24 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08910222254936093		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.08910222254936093 | validation: 0.0989644791296464]
	TIME [epoch: 6.24 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08813522009744855		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.08813522009744855 | validation: 0.12428954165991607]
	TIME [epoch: 6.25 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0958508747898866		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.0958508747898866 | validation: 0.11107284752474098]
	TIME [epoch: 6.29 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08793435475429752		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.08793435475429752 | validation: 0.11127845362216462]
	TIME [epoch: 6.25 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08393967119881282		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.08393967119881282 | validation: 0.0910323166270777]
	TIME [epoch: 6.24 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08473937754499576		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.08473937754499576 | validation: 0.09551397155719286]
	TIME [epoch: 6.24 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09170796103409631		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.09170796103409631 | validation: 0.1103398577750831]
	TIME [epoch: 6.24 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09065396508942161		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.09065396508942161 | validation: 0.10826206594585665]
	TIME [epoch: 6.25 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0914785740328672		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.0914785740328672 | validation: 0.09819697133991458]
	TIME [epoch: 6.27 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09072866751953879		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.09072866751953879 | validation: 0.09986535231635532]
	TIME [epoch: 6.25 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09264333643740129		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.09264333643740129 | validation: 0.11586185967643078]
	TIME [epoch: 6.24 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08311157025988979		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.08311157025988979 | validation: 0.09800166216949754]
	TIME [epoch: 6.24 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09502403941276871		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.09502403941276871 | validation: 0.11127626569403926]
	TIME [epoch: 6.24 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08719015163663213		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.08719015163663213 | validation: 0.10390865752727214]
	TIME [epoch: 6.26 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09525442081772112		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.09525442081772112 | validation: 0.11255300797381745]
	TIME [epoch: 6.28 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09227979265260733		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.09227979265260733 | validation: 0.10976071830147174]
	TIME [epoch: 6.25 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09121086175644186		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.09121086175644186 | validation: 0.09594589050236627]
	TIME [epoch: 6.24 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08639780808865458		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.08639780808865458 | validation: 0.10009091918895296]
	TIME [epoch: 6.24 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08978650616924357		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.08978650616924357 | validation: 0.11517247444507617]
	TIME [epoch: 6.24 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08411592305243229		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.08411592305243229 | validation: 0.10838380462684635]
	TIME [epoch: 6.25 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08128967574693133		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.08128967574693133 | validation: 0.09614155957177759]
	TIME [epoch: 6.28 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08668133147912802		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.08668133147912802 | validation: 0.09759324857428389]
	TIME [epoch: 6.24 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0872379680477324		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.0872379680477324 | validation: 0.10022035270125049]
	TIME [epoch: 6.24 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08292997364659814		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.08292997364659814 | validation: 0.10548037453628302]
	TIME [epoch: 6.24 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08772086083227826		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.08772086083227826 | validation: 0.12009575384489632]
	TIME [epoch: 6.24 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0944981033218597		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.0944981033218597 | validation: 0.11555692067108872]
	TIME [epoch: 6.26 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08995230875693384		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.08995230875693384 | validation: 0.09579163396140589]
	TIME [epoch: 6.27 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09065510844856123		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.09065510844856123 | validation: 0.1044691562528447]
	TIME [epoch: 6.25 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09023293331745577		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.09023293331745577 | validation: 0.1018964623816949]
	TIME [epoch: 6.24 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09253372960851573		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.09253372960851573 | validation: 0.11426064418694298]
	TIME [epoch: 6.25 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08557573765932991		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.08557573765932991 | validation: 0.10262504561548011]
	TIME [epoch: 6.24 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08724722011015702		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.08724722011015702 | validation: 0.1107241016601859]
	TIME [epoch: 6.28 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10012720421020788		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.10012720421020788 | validation: 0.11562931069582344]
	TIME [epoch: 6.26 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09106120239305354		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.09106120239305354 | validation: 0.11644888632079617]
	TIME [epoch: 6.25 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09335522216131568		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.09335522216131568 | validation: 0.09376234901799074]
	TIME [epoch: 6.24 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08672616694690069		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.08672616694690069 | validation: 0.09533808868394017]
	TIME [epoch: 6.24 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08503032722218998		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.08503032722218998 | validation: 0.10840423869960389]
	TIME [epoch: 6.24 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09265933828502008		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.09265933828502008 | validation: 0.11381241687884093]
	TIME [epoch: 6.27 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08565378006612333		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.08565378006612333 | validation: 0.10063128214031332]
	TIME [epoch: 6.26 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08661996714820865		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.08661996714820865 | validation: 0.0982782993587243]
	TIME [epoch: 6.25 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08518619788254389		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.08518619788254389 | validation: 0.09648265100910475]
	TIME [epoch: 6.24 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0831493888840831		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.0831493888840831 | validation: 0.09407580371091845]
	TIME [epoch: 6.24 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08447915319752385		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.08447915319752385 | validation: 0.10504815156017558]
	TIME [epoch: 6.24 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08804895560554034		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.08804895560554034 | validation: 0.11053409185064039]
	TIME [epoch: 6.28 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0861109251679626		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.0861109251679626 | validation: 0.0953791558468873]
	TIME [epoch: 6.26 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08718280014413146		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.08718280014413146 | validation: 0.10971250076770435]
	TIME [epoch: 6.24 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08979771585262827		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.08979771585262827 | validation: 0.09975773820855766]
	TIME [epoch: 6.24 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08724626797446183		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.08724626797446183 | validation: 0.10150252530999083]
	TIME [epoch: 6.24 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08786180798260416		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.08786180798260416 | validation: 0.09398882982198584]
	TIME [epoch: 6.24 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08660066954843709		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.08660066954843709 | validation: 0.10687884833131525]
	TIME [epoch: 6.27 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08625542187940072		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.08625542187940072 | validation: 0.09352676712500105]
	TIME [epoch: 6.26 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08714839065667973		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.08714839065667973 | validation: 0.10733225491328784]
	TIME [epoch: 6.24 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09001584778241523		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.09001584778241523 | validation: 0.11076189677336151]
	TIME [epoch: 6.24 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08808365176245231		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.08808365176245231 | validation: 0.110180732489318]
	TIME [epoch: 6.46 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08464636298561663		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.08464636298561663 | validation: 0.0960429219407063]
	TIME [epoch: 6.23 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08086154510451501		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.08086154510451501 | validation: 0.08891063168994622]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_1380.pth
	Model improved!!!
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08543494599956974		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.08543494599956974 | validation: 0.10615690886847075]
	TIME [epoch: 6.26 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08710025009227186		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.08710025009227186 | validation: 0.11403589470744326]
	TIME [epoch: 6.23 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08534687944652902		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.08534687944652902 | validation: 0.10076710541790229]
	TIME [epoch: 6.23 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08912320080225464		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.08912320080225464 | validation: 0.10759367329656479]
	TIME [epoch: 6.27 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09299762469702297		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.09299762469702297 | validation: 0.1102414592322385]
	TIME [epoch: 6.23 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08986884372247057		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.08986884372247057 | validation: 0.10022534139855165]
	TIME [epoch: 6.27 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09148436614548779		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.09148436614548779 | validation: 0.11413270753936741]
	TIME [epoch: 6.24 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09124320114417914		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.09124320114417914 | validation: 0.11904163813257715]
	TIME [epoch: 6.23 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09104998266971627		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.09104998266971627 | validation: 0.11368151510402838]
	TIME [epoch: 6.23 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08901774495353881		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.08901774495353881 | validation: 0.09889410508382332]
	TIME [epoch: 6.23 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09218591391384705		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.09218591391384705 | validation: 0.1028081672062667]
	TIME [epoch: 6.23 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08666968715694463		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.08666968715694463 | validation: 0.12009035695128549]
	TIME [epoch: 6.27 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09769613964551535		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.09769613964551535 | validation: 0.10870763885161408]
	TIME [epoch: 6.24 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.090800380153396		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.090800380153396 | validation: 0.10697710842731266]
	TIME [epoch: 6.23 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09451696405993099		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.09451696405993099 | validation: 0.10387852639054135]
	TIME [epoch: 6.23 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09122918726328841		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.09122918726328841 | validation: 0.11391488315572801]
	TIME [epoch: 6.23 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09424917108466997		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.09424917108466997 | validation: 0.11696153302204104]
	TIME [epoch: 6.23 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09546276721578453		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.09546276721578453 | validation: 0.10551938741108552]
	TIME [epoch: 6.27 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09786610717107416		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.09786610717107416 | validation: 0.11443736553375189]
	TIME [epoch: 6.23 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1003444358506067		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.1003444358506067 | validation: 0.12796632086496762]
	TIME [epoch: 6.23 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10486487341890828		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.10486487341890828 | validation: 0.13223707355291775]
	TIME [epoch: 6.23 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10124654781714512		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.10124654781714512 | validation: 0.11704227141932572]
	TIME [epoch: 6.23 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09391671549503003		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.09391671549503003 | validation: 0.1175258115324322]
	TIME [epoch: 6.23 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10363793353859446		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.10363793353859446 | validation: 0.1034158618422348]
	TIME [epoch: 6.27 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09264640539042816		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.09264640539042816 | validation: 0.09923935860752517]
	TIME [epoch: 6.23 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08922778604422969		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.08922778604422969 | validation: 0.11135842365459167]
	TIME [epoch: 6.23 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09705983732252342		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.09705983732252342 | validation: 0.11643579210709305]
	TIME [epoch: 6.23 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09736913292198515		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.09736913292198515 | validation: 0.10142304895938466]
	TIME [epoch: 6.23 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09101079221303383		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.09101079221303383 | validation: 0.08718888763790979]
	TIME [epoch: 6.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_1409.pth
	Model improved!!!
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08945382642047979		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.08945382642047979 | validation: 0.11278625880740228]
	TIME [epoch: 6.28 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09411578566862872		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.09411578566862872 | validation: 0.09604275769107992]
	TIME [epoch: 6.24 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09591975953114158		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.09591975953114158 | validation: 0.11676614124224215]
	TIME [epoch: 6.23 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09213797380262348		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.09213797380262348 | validation: 0.1124104989748751]
	TIME [epoch: 6.23 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09259793294478544		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.09259793294478544 | validation: 0.11150992868408936]
	TIME [epoch: 6.23 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09343925688853644		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.09343925688853644 | validation: 0.1082418969167531]
	TIME [epoch: 6.23 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.095318161131554		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.095318161131554 | validation: 0.10330356368926577]
	TIME [epoch: 6.28 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09475873600648668		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.09475873600648668 | validation: 0.11330768996499735]
	TIME [epoch: 6.24 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08955988370309356		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.08955988370309356 | validation: 0.10496142774409843]
	TIME [epoch: 6.23 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09457598410353091		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.09457598410353091 | validation: 0.10130603420259365]
	TIME [epoch: 6.23 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08987718847179602		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.08987718847179602 | validation: 0.09409251806590707]
	TIME [epoch: 6.23 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08831000854244822		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.08831000854244822 | validation: 0.10410314854269928]
	TIME [epoch: 6.23 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08923398399499852		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.08923398399499852 | validation: 0.10130626665110908]
	TIME [epoch: 6.27 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09454553267897267		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.09454553267897267 | validation: 0.10756120904441316]
	TIME [epoch: 6.24 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09411793305263842		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.09411793305263842 | validation: 0.12171207676436052]
	TIME [epoch: 6.23 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09865632947617778		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.09865632947617778 | validation: 0.12388297296076387]
	TIME [epoch: 6.24 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10816277269393546		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.10816277269393546 | validation: 0.1324283869139744]
	TIME [epoch: 6.23 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10560570821665169		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.10560570821665169 | validation: 0.10501700751563921]
	TIME [epoch: 6.24 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09905624868158083		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.09905624868158083 | validation: 0.0991410608165312]
	TIME [epoch: 6.27 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09592807389288134		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.09592807389288134 | validation: 0.11209997959364525]
	TIME [epoch: 6.24 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09894542503376777		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.09894542503376777 | validation: 0.11285023429125177]
	TIME [epoch: 6.23 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09875605252216546		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.09875605252216546 | validation: 0.13610715105873689]
	TIME [epoch: 6.23 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10990857516173862		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.10990857516173862 | validation: 0.11757062425420023]
	TIME [epoch: 6.23 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09783788539553596		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.09783788539553596 | validation: 0.11754254011333179]
	TIME [epoch: 6.25 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1043106941121919		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.1043106941121919 | validation: 0.11338647202336595]
	TIME [epoch: 6.27 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09883095108388057		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.09883095108388057 | validation: 0.10913998371965815]
	TIME [epoch: 6.24 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09676672286098631		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.09676672286098631 | validation: 0.10769993047947332]
	TIME [epoch: 6.23 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09263017992466485		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.09263017992466485 | validation: 0.10019863822932767]
	TIME [epoch: 6.23 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0918546909489038		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.0918546909489038 | validation: 0.10344508411046158]
	TIME [epoch: 6.23 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09192869301496946		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.09192869301496946 | validation: 0.09438769707267877]
	TIME [epoch: 6.24 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0905557412384704		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.0905557412384704 | validation: 0.10325579520823897]
	TIME [epoch: 6.26 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09698809550963007		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.09698809550963007 | validation: 0.10496069110936525]
	TIME [epoch: 6.24 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08836253165483147		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.08836253165483147 | validation: 0.10398209182979314]
	TIME [epoch: 6.23 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09023613097826955		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.09023613097826955 | validation: 0.115219694257734]
	TIME [epoch: 6.23 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09217214712653381		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.09217214712653381 | validation: 0.11185707217026002]
	TIME [epoch: 6.27 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09098262583081027		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.09098262583081027 | validation: 0.10962764673093256]
	TIME [epoch: 6.25 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08788203454799343		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.08788203454799343 | validation: 0.10112354928678038]
	TIME [epoch: 6.27 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0861311591233416		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.0861311591233416 | validation: 0.10234672939249514]
	TIME [epoch: 6.24 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09023602503315412		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.09023602503315412 | validation: 0.096890734928262]
	TIME [epoch: 6.23 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08728660786633012		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.08728660786633012 | validation: 0.10553319608777365]
	TIME [epoch: 6.23 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08295884781088315		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.08295884781088315 | validation: 0.09873225641623369]
	TIME [epoch: 6.23 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08603685791018872		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.08603685791018872 | validation: 0.09053707350837559]
	TIME [epoch: 6.25 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08729498483920001		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.08729498483920001 | validation: 0.10936211386903187]
	TIME [epoch: 6.27 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08612694591977393		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.08612694591977393 | validation: 0.10148537770127347]
	TIME [epoch: 6.24 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08702063424818969		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.08702063424818969 | validation: 0.09615451820294618]
	TIME [epoch: 6.24 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08771606878283525		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.08771606878283525 | validation: 0.09878811705641063]
	TIME [epoch: 6.23 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08570940221590824		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.08570940221590824 | validation: 0.08501888290684831]
	TIME [epoch: 6.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_1456.pth
	Model improved!!!
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08769613580207944		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.08769613580207944 | validation: 0.10641367448622263]
	TIME [epoch: 6.26 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08603877385284722		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.08603877385284722 | validation: 0.11024663875253102]
	TIME [epoch: 6.25 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08748789199812573		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.08748789199812573 | validation: 0.09122853503125822]
	TIME [epoch: 6.23 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08326235809346978		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.08326235809346978 | validation: 0.09038083683486231]
	TIME [epoch: 6.23 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08980764371678712		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.08980764371678712 | validation: 0.1020069373754238]
	TIME [epoch: 6.23 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08248930033662874		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.08248930033662874 | validation: 0.09333671798937732]
	TIME [epoch: 6.23 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08568250184977617		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.08568250184977617 | validation: 0.10234369575772356]
	TIME [epoch: 6.26 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09140508243768605		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.09140508243768605 | validation: 0.09751604173986364]
	TIME [epoch: 6.24 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09013994718894743		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.09013994718894743 | validation: 0.1126509823287758]
	TIME [epoch: 6.23 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08702029190562442		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.08702029190562442 | validation: 0.09056315596919262]
	TIME [epoch: 6.23 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0851972683524408		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.0851972683524408 | validation: 0.10462271399003681]
	TIME [epoch: 6.23 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08822670936944396		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.08822670936944396 | validation: 0.10082866328372972]
	TIME [epoch: 6.23 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09216787042092174		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.09216787042092174 | validation: 0.1086430250016773]
	TIME [epoch: 6.26 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08890971636840811		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.08890971636840811 | validation: 0.10730716854931643]
	TIME [epoch: 6.24 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08822512268173414		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.08822512268173414 | validation: 0.11322148642396318]
	TIME [epoch: 6.23 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08788615445066437		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.08788615445066437 | validation: 0.09619267688580985]
	TIME [epoch: 6.23 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09204691926150366		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.09204691926150366 | validation: 0.10013047856145846]
	TIME [epoch: 6.22 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0842071122336324		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.0842071122336324 | validation: 0.09601765097105347]
	TIME [epoch: 6.22 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0866538092289335		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.0866538092289335 | validation: 0.10951031414694998]
	TIME [epoch: 6.27 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08568247347538954		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.08568247347538954 | validation: 0.10392988432633021]
	TIME [epoch: 6.24 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08650328877248449		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.08650328877248449 | validation: 0.08913800040474851]
	TIME [epoch: 6.23 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08340950519066906		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.08340950519066906 | validation: 0.09708989772071001]
	TIME [epoch: 6.23 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08666504085787156		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.08666504085787156 | validation: 0.10409774090946658]
	TIME [epoch: 6.23 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08532826367757626		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.08532826367757626 | validation: 0.0930347626861792]
	TIME [epoch: 6.23 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08512171064121768		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.08512171064121768 | validation: 0.09746000896185145]
	TIME [epoch: 6.26 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08362661619756265		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.08362661619756265 | validation: 0.097584765648912]
	TIME [epoch: 6.24 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08646550863572083		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.08646550863572083 | validation: 0.08870976522869614]
	TIME [epoch: 6.23 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08367091401504802		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.08367091401504802 | validation: 0.09083038049787963]
	TIME [epoch: 6.23 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0868315016677909		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.0868315016677909 | validation: 0.09485369016482825]
	TIME [epoch: 6.23 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08078925175351893		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.08078925175351893 | validation: 0.09918813665682685]
	TIME [epoch: 6.23 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0793969924623684		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.0793969924623684 | validation: 0.0962482774325962]
	TIME [epoch: 6.27 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08407613472264813		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.08407613472264813 | validation: 0.09905229532205355]
	TIME [epoch: 6.24 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08470296082755048		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.08470296082755048 | validation: 0.10824923726585847]
	TIME [epoch: 6.23 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08317421692676971		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.08317421692676971 | validation: 0.0917437955462185]
	TIME [epoch: 6.23 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0821535064636944		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.0821535064636944 | validation: 0.0923156153517967]
	TIME [epoch: 6.23 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08363989538885173		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.08363989538885173 | validation: 0.10005686551318851]
	TIME [epoch: 6.22 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08405889349067308		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.08405889349067308 | validation: 0.09824783746073593]
	TIME [epoch: 6.26 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08385804957069236		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.08385804957069236 | validation: 0.09644958373358042]
	TIME [epoch: 6.24 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08577986386691648		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.08577986386691648 | validation: 0.0921337259851336]
	TIME [epoch: 6.23 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08737274009502823		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.08737274009502823 | validation: 0.10585965041709303]
	TIME [epoch: 6.23 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08239671015402698		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.08239671015402698 | validation: 0.096655357311282]
	TIME [epoch: 6.23 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08530079163552406		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.08530079163552406 | validation: 0.09923348768199287]
	TIME [epoch: 6.23 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08097746822542709		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.08097746822542709 | validation: 0.10338896137146378]
	TIME [epoch: 6.26 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08815484552737185		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.08815484552737185 | validation: 0.09723365276763833]
	TIME [epoch: 6.23 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08611449947650253		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.08611449947650253 | validation: 0.10297189830429193]
	TIME [epoch: 6.22 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08877392689695447		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.08877392689695447 | validation: 0.09789736098194088]
	TIME [epoch: 6.23 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0815329765235144		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.0815329765235144 | validation: 0.110311910663227]
	TIME [epoch: 6.23 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08637112730316956		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.08637112730316956 | validation: 0.11177278466018334]
	TIME [epoch: 6.22 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08956124158162755		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.08956124158162755 | validation: 0.1083250226495753]
	TIME [epoch: 6.27 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08700726393200099		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.08700726393200099 | validation: 0.08575493301644412]
	TIME [epoch: 6.24 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07966478858713381		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.07966478858713381 | validation: 0.10720998538837932]
	TIME [epoch: 6.23 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08636585116734469		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.08636585116734469 | validation: 0.10101594352133748]
	TIME [epoch: 6.23 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08277584098101422		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.08277584098101422 | validation: 0.08610718035767748]
	TIME [epoch: 6.23 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08148068799415417		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.08148068799415417 | validation: 0.1035159061433312]
	TIME [epoch: 6.23 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.086060590984226		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.086060590984226 | validation: 0.10259061400461716]
	TIME [epoch: 6.27 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08418980706580848		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.08418980706580848 | validation: 0.10313555688692429]
	TIME [epoch: 6.23 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08620216879910184		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.08620216879910184 | validation: 0.09374479511935388]
	TIME [epoch: 6.23 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08432528328957445		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.08432528328957445 | validation: 0.09505329027102499]
	TIME [epoch: 6.23 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07997386795873282		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.07997386795873282 | validation: 0.10413802278567413]
	TIME [epoch: 6.23 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0843247005026092		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.0843247005026092 | validation: 0.10141940596151171]
	TIME [epoch: 6.23 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.088548411412433		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.088548411412433 | validation: 0.11191781393341352]
	TIME [epoch: 6.27 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08149590714590266		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.08149590714590266 | validation: 0.10223978109611306]
	TIME [epoch: 6.23 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08123926106693571		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.08123926106693571 | validation: 0.10104856901858224]
	TIME [epoch: 6.23 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08407416182065144		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.08407416182065144 | validation: 0.08408372611314917]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_1520.pth
	Model improved!!!
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08105914861230519		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.08105914861230519 | validation: 0.09188149999119041]
	TIME [epoch: 6.23 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08367825360146774		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.08367825360146774 | validation: 0.0945306813195777]
	TIME [epoch: 6.23 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0834021261306257		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.0834021261306257 | validation: 0.11004535455113582]
	TIME [epoch: 6.27 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0877183810235135		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.0877183810235135 | validation: 0.09707816248365572]
	TIME [epoch: 6.23 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08901278880647516		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.08901278880647516 | validation: 0.10326275341431823]
	TIME [epoch: 6.23 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0883731359689084		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.0883731359689084 | validation: 0.09587829333590037]
	TIME [epoch: 6.23 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08442408088275638		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.08442408088275638 | validation: 0.10201883962422767]
	TIME [epoch: 6.23 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0867008068231055		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.0867008068231055 | validation: 0.10409201059705142]
	TIME [epoch: 6.23 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08461459764626639		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.08461459764626639 | validation: 0.10940890808689605]
	TIME [epoch: 6.27 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08904894119926998		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.08904894119926998 | validation: 0.10093727864236998]
	TIME [epoch: 6.23 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08284577659230308		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.08284577659230308 | validation: 0.09747952903761194]
	TIME [epoch: 6.23 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08188434489710271		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.08188434489710271 | validation: 0.08804665691652248]
	TIME [epoch: 6.23 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08346847501499298		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.08346847501499298 | validation: 0.11998469727650748]
	TIME [epoch: 6.23 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08679000414326882		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.08679000414326882 | validation: 0.0971037249281449]
	TIME [epoch: 6.23 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08109401828059673		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.08109401828059673 | validation: 0.09386084135321895]
	TIME [epoch: 6.27 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08808033468045666		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.08808033468045666 | validation: 0.10806000505611453]
	TIME [epoch: 6.23 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08238016851857038		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.08238016851857038 | validation: 0.1060246013822108]
	TIME [epoch: 6.23 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.081810276913945		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.081810276913945 | validation: 0.10724119157127876]
	TIME [epoch: 6.23 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0830204137954981		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.0830204137954981 | validation: 0.10165668333159096]
	TIME [epoch: 6.23 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08502000637576015		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.08502000637576015 | validation: 0.08934216375526524]
	TIME [epoch: 6.24 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08783266794593969		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.08783266794593969 | validation: 0.09783061344652669]
	TIME [epoch: 6.27 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08628043853447942		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.08628043853447942 | validation: 0.10717128830903841]
	TIME [epoch: 6.23 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.080245667270418		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.080245667270418 | validation: 0.09561648354575314]
	TIME [epoch: 6.23 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08277153949845506		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.08277153949845506 | validation: 0.09669845266203028]
	TIME [epoch: 6.23 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08310478357157497		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.08310478357157497 | validation: 0.09508230919743901]
	TIME [epoch: 6.23 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08847171433459583		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.08847171433459583 | validation: 0.10223886703589172]
	TIME [epoch: 6.24 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08761568964020264		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.08761568964020264 | validation: 0.10758750885500197]
	TIME [epoch: 6.26 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08600819387354264		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.08600819387354264 | validation: 0.1035228472407505]
	TIME [epoch: 6.23 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0833202795628451		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.0833202795628451 | validation: 0.09637328446275553]
	TIME [epoch: 6.23 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08462247960517288		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.08462247960517288 | validation: 0.09806922680467742]
	TIME [epoch: 6.23 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0874317970055239		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.0874317970055239 | validation: 0.1067720681874963]
	TIME [epoch: 6.23 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08473668523879915		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.08473668523879915 | validation: 0.10448332906416999]
	TIME [epoch: 6.24 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0831962975664551		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.0831962975664551 | validation: 0.09549374593293411]
	TIME [epoch: 6.27 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08143670384084756		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.08143670384084756 | validation: 0.09056172206141946]
	TIME [epoch: 6.25 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08112316724653713		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.08112316724653713 | validation: 0.09944834822261711]
	TIME [epoch: 6.23 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08494226384866879		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.08494226384866879 | validation: 0.09643901912311534]
	TIME [epoch: 6.23 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08400789333420937		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.08400789333420937 | validation: 0.10588078316261684]
	TIME [epoch: 6.22 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08551482763459481		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.08551482763459481 | validation: 0.09473513986427343]
	TIME [epoch: 6.24 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08461863865796274		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.08461863865796274 | validation: 0.10608572145100076]
	TIME [epoch: 6.26 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07985136891266571		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.07985136891266571 | validation: 0.09832983280337948]
	TIME [epoch: 6.23 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0847687555963363		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.0847687555963363 | validation: 0.09220985737372628]
	TIME [epoch: 6.23 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08197069143475107		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.08197069143475107 | validation: 0.10050606117827768]
	TIME [epoch: 6.23 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0853569575978729		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.0853569575978729 | validation: 0.10052997088218867]
	TIME [epoch: 6.23 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08497928287725598		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.08497928287725598 | validation: 0.09733845512814482]
	TIME [epoch: 6.24 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08269218735292522		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.08269218735292522 | validation: 0.09572927214404348]
	TIME [epoch: 6.25 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08849834873492246		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.08849834873492246 | validation: 0.10305285523876613]
	TIME [epoch: 6.23 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08677481818660115		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.08677481818660115 | validation: 0.08683206547926355]
	TIME [epoch: 6.23 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.084244133495952		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.084244133495952 | validation: 0.09966140858347225]
	TIME [epoch: 6.23 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07507394228273137		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.07507394228273137 | validation: 0.08853491496257004]
	TIME [epoch: 6.23 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.083452373008126		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.083452373008126 | validation: 0.10527425056572763]
	TIME [epoch: 6.26 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0853830279120091		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.0853830279120091 | validation: 0.10409810202437386]
	TIME [epoch: 6.26 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08722605654752165		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.08722605654752165 | validation: 0.0928897431082003]
	TIME [epoch: 6.23 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08311582125636516		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.08311582125636516 | validation: 0.11392658051111687]
	TIME [epoch: 6.23 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08828319519312988		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.08828319519312988 | validation: 0.09332909002786542]
	TIME [epoch: 6.23 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08395460326390085		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.08395460326390085 | validation: 0.1000098232915839]
	TIME [epoch: 6.23 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08573362627267034		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.08573362627267034 | validation: 0.091151130268808]
	TIME [epoch: 6.26 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08481493558441906		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.08481493558441906 | validation: 0.09023159034947142]
	TIME [epoch: 6.24 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08651298818479122		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.08651298818479122 | validation: 0.10881472292660471]
	TIME [epoch: 6.23 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08803437562590886		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.08803437562590886 | validation: 0.09838001099681193]
	TIME [epoch: 6.23 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08444737373407873		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.08444737373407873 | validation: 0.09871120061844277]
	TIME [epoch: 6.23 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08039317364771503		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.08039317364771503 | validation: 0.10306758663875455]
	TIME [epoch: 6.23 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08520805171318341		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.08520805171318341 | validation: 0.10151713129433235]
	TIME [epoch: 6.26 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0846687700870526		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.0846687700870526 | validation: 0.09714848112912151]
	TIME [epoch: 6.25 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08398155574087385		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.08398155574087385 | validation: 0.1083361084906278]
	TIME [epoch: 6.23 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08467346869387284		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.08467346869387284 | validation: 0.10839661914505584]
	TIME [epoch: 6.23 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08201731267167395		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.08201731267167395 | validation: 0.10269936614926178]
	TIME [epoch: 6.23 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08259341406619022		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.08259341406619022 | validation: 0.10736883798159064]
	TIME [epoch: 6.23 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08756952872650403		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.08756952872650403 | validation: 0.11009379894795158]
	TIME [epoch: 6.29 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0885972023384567		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.0885972023384567 | validation: 0.10698956994440628]
	TIME [epoch: 6.24 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08803127043040453		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.08803127043040453 | validation: 0.09838669662471392]
	TIME [epoch: 6.23 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08876832644609489		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.08876832644609489 | validation: 0.09912360254318936]
	TIME [epoch: 6.23 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08429573159507522		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.08429573159507522 | validation: 0.09481813974529249]
	TIME [epoch: 6.24 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0883642658312064		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.0883642658312064 | validation: 0.08801848760609808]
	TIME [epoch: 6.23 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08103865261346285		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.08103865261346285 | validation: 0.09200298789886874]
	TIME [epoch: 6.26 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08333257703135367		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.08333257703135367 | validation: 0.09364622705911428]
	TIME [epoch: 6.25 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08166800078038929		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.08166800078038929 | validation: 0.09141726698853167]
	TIME [epoch: 6.23 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08551833900423757		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.08551833900423757 | validation: 0.09659559397386927]
	TIME [epoch: 6.23 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08232906766236495		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.08232906766236495 | validation: 0.11121632357831886]
	TIME [epoch: 6.23 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08423828214728461		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.08423828214728461 | validation: 0.10461284572359926]
	TIME [epoch: 6.23 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08270304754953023		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.08270304754953023 | validation: 0.10218790742966416]
	TIME [epoch: 6.26 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07973219414366745		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.07973219414366745 | validation: 0.09949079188055233]
	TIME [epoch: 6.23 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08568134700334815		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.08568134700334815 | validation: 0.09993988127654337]
	TIME [epoch: 6.23 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08793264158620794		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.08793264158620794 | validation: 0.09938361770298719]
	TIME [epoch: 6.23 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08616819568896773		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.08616819568896773 | validation: 0.09537779152540563]
	TIME [epoch: 6.23 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08863750790597971		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.08863750790597971 | validation: 0.1066913857092742]
	TIME [epoch: 6.24 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08512568357576869		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.08512568357576869 | validation: 0.09550692319206569]
	TIME [epoch: 6.26 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08342515901075338		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.08342515901075338 | validation: 0.09443267789053908]
	TIME [epoch: 6.24 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08177674517466252		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.08177674517466252 | validation: 0.09846833950690488]
	TIME [epoch: 6.23 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08100236497617569		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.08100236497617569 | validation: 0.10241199306329468]
	TIME [epoch: 6.23 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0813943889550289		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.0813943889550289 | validation: 0.10770764275931205]
	TIME [epoch: 6.23 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08745680697018415		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.08745680697018415 | validation: 0.09545511869250858]
	TIME [epoch: 6.23 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0803966312833377		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.0803966312833377 | validation: 0.08592698193415171]
	TIME [epoch: 6.26 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08619711490569812		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.08619711490569812 | validation: 0.09993943167911011]
	TIME [epoch: 6.24 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08995557403143425		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.08995557403143425 | validation: 0.094651664410671]
	TIME [epoch: 6.22 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0861293924706269		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.0861293924706269 | validation: 0.09073299641116023]
	TIME [epoch: 6.22 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08569688574052575		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.08569688574052575 | validation: 0.10131242939691587]
	TIME [epoch: 6.23 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08257483654311222		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.08257483654311222 | validation: 0.09164155120431104]
	TIME [epoch: 6.22 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08286146952339203		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.08286146952339203 | validation: 0.10449499752845862]
	TIME [epoch: 6.26 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08217131081820753		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.08217131081820753 | validation: 0.09509195403476808]
	TIME [epoch: 6.24 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08337285495167071		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.08337285495167071 | validation: 0.09130158081802349]
	TIME [epoch: 6.23 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08789151982900315		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.08789151982900315 | validation: 0.10007074818867981]
	TIME [epoch: 6.23 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08713445794291608		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.08713445794291608 | validation: 0.10091987545701372]
	TIME [epoch: 6.23 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08517330355937894		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.08517330355937894 | validation: 0.10759425684067274]
	TIME [epoch: 6.23 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09008792434660762		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.09008792434660762 | validation: 0.10186510401699914]
	TIME [epoch: 6.27 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08632989769227445		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.08632989769227445 | validation: 0.11216937138034497]
	TIME [epoch: 6.24 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08573958853417564		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.08573958853417564 | validation: 0.10992530408066793]
	TIME [epoch: 6.23 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08491807468011849		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.08491807468011849 | validation: 0.09441866870232354]
	TIME [epoch: 6.23 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08651463404333141		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.08651463404333141 | validation: 0.10450825437815708]
	TIME [epoch: 6.22 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08985827594380627		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.08985827594380627 | validation: 0.1139904248963643]
	TIME [epoch: 6.23 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08665616838925198		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.08665616838925198 | validation: 0.09924473366273172]
	TIME [epoch: 6.27 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08647903072186333		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.08647903072186333 | validation: 0.10507649020062212]
	TIME [epoch: 6.23 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08760739257580377		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.08760739257580377 | validation: 0.10128207800279593]
	TIME [epoch: 6.23 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08554345121393941		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.08554345121393941 | validation: 0.10235488283347058]
	TIME [epoch: 6.23 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08546747541589572		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.08546747541589572 | validation: 0.09727649666201607]
	TIME [epoch: 6.23 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08983669857615294		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.08983669857615294 | validation: 0.11148866234870052]
	TIME [epoch: 6.23 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0897579825485317		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.0897579825485317 | validation: 0.09918361042635788]
	TIME [epoch: 6.27 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08846129228461838		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.08846129228461838 | validation: 0.10132241078658363]
	TIME [epoch: 6.24 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08627203957683935		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.08627203957683935 | validation: 0.10814455097830171]
	TIME [epoch: 6.23 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08646881779708479		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.08646881779708479 | validation: 0.09895469598532015]
	TIME [epoch: 6.23 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0855637968562763		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.0855637968562763 | validation: 0.08961422428912265]
	TIME [epoch: 6.23 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08567435633545722		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.08567435633545722 | validation: 0.10192703763323949]
	TIME [epoch: 6.23 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08414912798340961		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.08414912798340961 | validation: 0.10832423664630908]
	TIME [epoch: 6.27 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.087327029380392		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.087327029380392 | validation: 0.10240506386492437]
	TIME [epoch: 6.23 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08683514606841965		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.08683514606841965 | validation: 0.08668177894551635]
	TIME [epoch: 6.23 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0817784478304495		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.0817784478304495 | validation: 0.10127158854113007]
	TIME [epoch: 6.23 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0784403866738881		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.0784403866738881 | validation: 0.09434650910474227]
	TIME [epoch: 6.23 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08021280661236943		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.08021280661236943 | validation: 0.08722108807362688]
	TIME [epoch: 6.23 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08376075891694494		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.08376075891694494 | validation: 0.09470021680114829]
	TIME [epoch: 6.27 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08384176470098487		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.08384176470098487 | validation: 0.10123096814598428]
	TIME [epoch: 6.23 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0853949785812346		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.0853949785812346 | validation: 0.1016469169977969]
	TIME [epoch: 6.23 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08312865039094897		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.08312865039094897 | validation: 0.09970380478975266]
	TIME [epoch: 6.23 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08478018949152273		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.08478018949152273 | validation: 0.11068383771810697]
	TIME [epoch: 6.22 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08347256756625543		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.08347256756625543 | validation: 0.10085133662003617]
	TIME [epoch: 6.23 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08610999940647382		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.08610999940647382 | validation: 0.09966405203904254]
	TIME [epoch: 6.27 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08579618580050391		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.08579618580050391 | validation: 0.10234761256320624]
	TIME [epoch: 6.24 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08453155833331961		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.08453155833331961 | validation: 0.0873310881523789]
	TIME [epoch: 6.23 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08304712459321309		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.08304712459321309 | validation: 0.10735641989866793]
	TIME [epoch: 6.23 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08182368459673119		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.08182368459673119 | validation: 0.10195787432488566]
	TIME [epoch: 6.23 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08325409248788374		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.08325409248788374 | validation: 0.10210647748204904]
	TIME [epoch: 6.23 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08853849583078965		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.08853849583078965 | validation: 0.0973275456749789]
	TIME [epoch: 6.27 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08327034628634866		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.08327034628634866 | validation: 0.10435107219347936]
	TIME [epoch: 6.23 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08283414605882888		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.08283414605882888 | validation: 0.09504747312883723]
	TIME [epoch: 6.23 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08403661046045634		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.08403661046045634 | validation: 0.10162354113047445]
	TIME [epoch: 6.23 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07874238029741977		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.07874238029741977 | validation: 0.09903936574750766]
	TIME [epoch: 6.22 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08251620135458992		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.08251620135458992 | validation: 0.09709060349559309]
	TIME [epoch: 6.23 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08218244604287932		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.08218244604287932 | validation: 0.11396972390892166]
	TIME [epoch: 6.27 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08495649275521049		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.08495649275521049 | validation: 0.10046558988755216]
	TIME [epoch: 6.23 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.083274542549135		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.083274542549135 | validation: 0.09020670184546498]
	TIME [epoch: 6.23 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08272129176097877		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.08272129176097877 | validation: 0.09699623125892487]
	TIME [epoch: 6.23 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08213629662795564		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.08213629662795564 | validation: 0.09518764317557177]
	TIME [epoch: 6.23 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08026035838245486		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.08026035838245486 | validation: 0.10001735989396945]
	TIME [epoch: 6.24 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08507568104778584		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.08507568104778584 | validation: 0.10827260358241436]
	TIME [epoch: 6.26 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08409723165788172		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.08409723165788172 | validation: 0.09762696759032835]
	TIME [epoch: 6.23 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0775184075369169		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.0775184075369169 | validation: 0.10218795674656833]
	TIME [epoch: 6.23 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07912125804694856		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.07912125804694856 | validation: 0.10325904426971971]
	TIME [epoch: 6.23 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08240289653420861		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.08240289653420861 | validation: 0.0952914156123348]
	TIME [epoch: 6.23 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0816506698392193		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.0816506698392193 | validation: 0.08483344724494307]
	TIME [epoch: 6.24 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08458649667943963		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.08458649667943963 | validation: 0.09389527211929065]
	TIME [epoch: 6.26 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08270787188967425		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.08270787188967425 | validation: 0.08215453562538597]
	TIME [epoch: 6.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_1679.pth
	Model improved!!!
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08532992606518155		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.08532992606518155 | validation: 0.10445585974913227]
	TIME [epoch: 6.23 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08557594051744491		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.08557594051744491 | validation: 0.08601196643331074]
	TIME [epoch: 6.23 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0839419488142025		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.0839419488142025 | validation: 0.09476452937130994]
	TIME [epoch: 6.23 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08096131576000322		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.08096131576000322 | validation: 0.1084556128904865]
	TIME [epoch: 6.26 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08625541674296902		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.08625541674296902 | validation: 0.10317490840655125]
	TIME [epoch: 6.24 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08657128503417418		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.08657128503417418 | validation: 0.09399122065033252]
	TIME [epoch: 6.23 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08683719550365865		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.08683719550365865 | validation: 0.09185231842852329]
	TIME [epoch: 6.23 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08544881199274977		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.08544881199274977 | validation: 0.0931804555502796]
	TIME [epoch: 6.23 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08495206243168418		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.08495206243168418 | validation: 0.10000309517753468]
	TIME [epoch: 6.23 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08677243629180574		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.08677243629180574 | validation: 0.10699544917466747]
	TIME [epoch: 6.26 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08304871447814438		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.08304871447814438 | validation: 0.10358098455659998]
	TIME [epoch: 6.24 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08444782226032378		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.08444782226032378 | validation: 0.09364628177636447]
	TIME [epoch: 6.23 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08177451845702831		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.08177451845702831 | validation: 0.09822327905391028]
	TIME [epoch: 6.24 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0830689651822076		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.0830689651822076 | validation: 0.09863178957441612]
	TIME [epoch: 6.23 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08532797464157903		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.08532797464157903 | validation: 0.09861840598995483]
	TIME [epoch: 6.23 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08609362393180273		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.08609362393180273 | validation: 0.08764023352351916]
	TIME [epoch: 6.26 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08074850154858139		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.08074850154858139 | validation: 0.1086158407576535]
	TIME [epoch: 6.24 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0804994832881415		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.0804994832881415 | validation: 0.09262777013666307]
	TIME [epoch: 6.25 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08758407343440638		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.08758407343440638 | validation: 0.10234446925647539]
	TIME [epoch: 6.23 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08781725170484718		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.08781725170484718 | validation: 0.09428238645271991]
	TIME [epoch: 6.23 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08340674066750185		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.08340674066750185 | validation: 0.10211550621870846]
	TIME [epoch: 6.23 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08511355492932893		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.08511355492932893 | validation: 0.09397045030274424]
	TIME [epoch: 6.26 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08335973131016296		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.08335973131016296 | validation: 0.09812137008209997]
	TIME [epoch: 6.25 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08704235559133347		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.08704235559133347 | validation: 0.09247870222452693]
	TIME [epoch: 6.23 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09155966700601138		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.09155966700601138 | validation: 0.09571215886009334]
	TIME [epoch: 6.23 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07939559462293844		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.07939559462293844 | validation: 0.09787838316712352]
	TIME [epoch: 6.23 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08382323393322327		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.08382323393322327 | validation: 0.10493986900370661]
	TIME [epoch: 6.23 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08306455535355987		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.08306455535355987 | validation: 0.10722188124636721]
	TIME [epoch: 6.26 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08575623413303199		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.08575623413303199 | validation: 0.10006946764695598]
	TIME [epoch: 6.24 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08585921821848945		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.08585921821848945 | validation: 0.08907214325135038]
	TIME [epoch: 6.23 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08505651639037556		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.08505651639037556 | validation: 0.09641167370643577]
	TIME [epoch: 6.23 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08676626793114371		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.08676626793114371 | validation: 0.10382408947057989]
	TIME [epoch: 6.23 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08698082418058185		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.08698082418058185 | validation: 0.09531285570381409]
	TIME [epoch: 6.23 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08654813661599933		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.08654813661599933 | validation: 0.09406827182089271]
	TIME [epoch: 6.26 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09075368799573824		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.09075368799573824 | validation: 0.10061558424671585]
	TIME [epoch: 6.24 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0887461419779		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.0887461419779 | validation: 0.10459593342927662]
	TIME [epoch: 6.23 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08524404591984326		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.08524404591984326 | validation: 0.09305901669404584]
	TIME [epoch: 6.23 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08135349050378404		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.08135349050378404 | validation: 0.09989087729589688]
	TIME [epoch: 6.24 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08404842044674925		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.08404842044674925 | validation: 0.0898357607320045]
	TIME [epoch: 6.23 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0818740812166375		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.0818740812166375 | validation: 0.09279188746776096]
	TIME [epoch: 6.27 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08588992613188856		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.08588992613188856 | validation: 0.10487999682860712]
	TIME [epoch: 6.24 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08514849919165926		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.08514849919165926 | validation: 0.10130653197267006]
	TIME [epoch: 6.23 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08229855114292015		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.08229855114292015 | validation: 0.10338861367731556]
	TIME [epoch: 6.23 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07987169481702089		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.07987169481702089 | validation: 0.099646622203789]
	TIME [epoch: 6.23 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08457846717277623		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.08457846717277623 | validation: 0.09553608494927626]
	TIME [epoch: 6.23 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08327443337845616		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.08327443337845616 | validation: 0.10304255657265479]
	TIME [epoch: 6.28 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.088035782561781		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.088035782561781 | validation: 0.10151779330068861]
	TIME [epoch: 6.24 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0817267436323071		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.0817267436323071 | validation: 0.09491251220278143]
	TIME [epoch: 6.23 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09003370134364816		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.09003370134364816 | validation: 0.10030366925774921]
	TIME [epoch: 6.23 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07929497886327154		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.07929497886327154 | validation: 0.10058737996073053]
	TIME [epoch: 6.23 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0894065965863595		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.0894065965863595 | validation: 0.09798644332533891]
	TIME [epoch: 6.23 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08734053604621661		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.08734053604621661 | validation: 0.09196801540284728]
	TIME [epoch: 6.27 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08647162873457084		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.08647162873457084 | validation: 0.09779655715977467]
	TIME [epoch: 6.24 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08128699246866299		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.08128699246866299 | validation: 0.10300835202526054]
	TIME [epoch: 6.23 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0892651680095036		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.0892651680095036 | validation: 0.09293125596848173]
	TIME [epoch: 6.23 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08313571442210077		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.08313571442210077 | validation: 0.1055704836878164]
	TIME [epoch: 6.23 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08067464996820302		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.08067464996820302 | validation: 0.10077183812456722]
	TIME [epoch: 6.23 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0817423480077328		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.0817423480077328 | validation: 0.09540143819782186]
	TIME [epoch: 6.27 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08141128554296247		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.08141128554296247 | validation: 0.09669128954508308]
	TIME [epoch: 6.24 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08226207130687974		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.08226207130687974 | validation: 0.0939583250782623]
	TIME [epoch: 6.23 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08355922378682207		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.08355922378682207 | validation: 0.09464971080781522]
	TIME [epoch: 6.23 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0822918247456012		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.0822918247456012 | validation: 0.096570191642405]
	TIME [epoch: 6.23 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08488777091444624		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.08488777091444624 | validation: 0.07964295828549776]
	TIME [epoch: 6.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_1742.pth
	Model improved!!!
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08739220592654245		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.08739220592654245 | validation: 0.09040618499962638]
	TIME [epoch: 6.27 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08714782224568945		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.08714782224568945 | validation: 0.09297938513044327]
	TIME [epoch: 6.23 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0901514744489213		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.0901514744489213 | validation: 0.10267935226695694]
	TIME [epoch: 6.22 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08628493031531104		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.08628493031531104 | validation: 0.09576473536291535]
	TIME [epoch: 6.23 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0822437715383922		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.0822437715383922 | validation: 0.10167948233317312]
	TIME [epoch: 6.23 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08344075866757725		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.08344075866757725 | validation: 0.0987800527738156]
	TIME [epoch: 6.23 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08676740185425214		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.08676740185425214 | validation: 0.08413409957356566]
	TIME [epoch: 6.27 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08515571486962187		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.08515571486962187 | validation: 0.09739694634177276]
	TIME [epoch: 6.23 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08362743677903636		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.08362743677903636 | validation: 0.09569085119961956]
	TIME [epoch: 6.23 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.083012883946343		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.083012883946343 | validation: 0.10360164500627621]
	TIME [epoch: 6.23 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0824579281066889		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.0824579281066889 | validation: 0.10050305394477646]
	TIME [epoch: 6.23 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08484595941074319		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.08484595941074319 | validation: 0.0990874210600475]
	TIME [epoch: 6.23 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08460787483919299		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.08460787483919299 | validation: 0.10104343269829509]
	TIME [epoch: 6.27 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0820866929509888		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.0820866929509888 | validation: 0.10351301882232122]
	TIME [epoch: 6.23 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08417466957005966		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.08417466957005966 | validation: 0.08891004916381995]
	TIME [epoch: 6.23 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08823439782518497		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.08823439782518497 | validation: 0.07904957370553244]
	TIME [epoch: 6.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_1758.pth
	Model improved!!!
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08435985398012438		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.08435985398012438 | validation: 0.08953784016050914]
	TIME [epoch: 6.23 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08625878789184988		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.08625878789184988 | validation: 0.09880632089865157]
	TIME [epoch: 6.24 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08535974489278046		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.08535974489278046 | validation: 0.10165476043681151]
	TIME [epoch: 6.27 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08035020351888576		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.08035020351888576 | validation: 0.08209277687723986]
	TIME [epoch: 6.24 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08351687571202072		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.08351687571202072 | validation: 0.08850121740749056]
	TIME [epoch: 6.23 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08507491999688903		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.08507491999688903 | validation: 0.09563061950763746]
	TIME [epoch: 6.23 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08306592529048065		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.08306592529048065 | validation: 0.10999378672040039]
	TIME [epoch: 6.23 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08805096174963865		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.08805096174963865 | validation: 0.1073056281905638]
	TIME [epoch: 6.24 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08650910399960056		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.08650910399960056 | validation: 0.09773767465767244]
	TIME [epoch: 6.26 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08577516161731935		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.08577516161731935 | validation: 0.10269429414175786]
	TIME [epoch: 6.23 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08708434194990114		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.08708434194990114 | validation: 0.09315632083207895]
	TIME [epoch: 6.23 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08216864608716892		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.08216864608716892 | validation: 0.10409096651850253]
	TIME [epoch: 6.23 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08182827196512785		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.08182827196512785 | validation: 0.08673619321573944]
	TIME [epoch: 6.23 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08539222307306452		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.08539222307306452 | validation: 0.09298508397267302]
	TIME [epoch: 6.25 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08510810858426487		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.08510810858426487 | validation: 0.09713901408042874]
	TIME [epoch: 6.26 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08449544523352215		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.08449544523352215 | validation: 0.08833414512781859]
	TIME [epoch: 6.23 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08589897147709426		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.08589897147709426 | validation: 0.10132590256724]
	TIME [epoch: 6.23 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08360044147401163		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.08360044147401163 | validation: 0.09192043124153954]
	TIME [epoch: 6.23 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08138309759522828		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.08138309759522828 | validation: 0.09428174816738102]
	TIME [epoch: 6.23 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08608522682824024		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.08608522682824024 | validation: 0.09223054125850305]
	TIME [epoch: 6.25 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0865482936466565		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.0865482936466565 | validation: 0.08728324619031522]
	TIME [epoch: 6.25 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08062854307845957		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.08062854307845957 | validation: 0.10773034655097083]
	TIME [epoch: 6.23 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0859029825767226		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.0859029825767226 | validation: 0.08308341688223189]
	TIME [epoch: 6.23 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08248125250002997		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.08248125250002997 | validation: 0.10215208662579771]
	TIME [epoch: 6.23 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08354463550965106		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.08354463550965106 | validation: 0.09902875119705684]
	TIME [epoch: 6.23 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08285181460169092		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.08285181460169092 | validation: 0.10360637442443088]
	TIME [epoch: 6.26 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0844891220428615		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.0844891220428615 | validation: 0.10623851557950388]
	TIME [epoch: 6.25 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08395484210809134		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.08395484210809134 | validation: 0.1012890691076844]
	TIME [epoch: 6.24 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08642426701176102		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.08642426701176102 | validation: 0.10099758963937189]
	TIME [epoch: 6.23 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0836267049329451		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.0836267049329451 | validation: 0.0939916144003893]
	TIME [epoch: 6.23 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08131495076189278		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.08131495076189278 | validation: 0.10586836952109815]
	TIME [epoch: 6.23 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0847733985341734		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.0847733985341734 | validation: 0.0998358065361181]
	TIME [epoch: 6.26 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08541248109036541		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.08541248109036541 | validation: 0.0928236556168594]
	TIME [epoch: 6.25 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07883634175793965		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.07883634175793965 | validation: 0.0911512718775848]
	TIME [epoch: 6.25 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08439077609354817		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.08439077609354817 | validation: 0.0911812437340836]
	TIME [epoch: 6.24 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08343127073828267		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.08343127073828267 | validation: 0.10667081663709016]
	TIME [epoch: 6.23 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08357100571025902		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.08357100571025902 | validation: 0.09680601284505871]
	TIME [epoch: 6.24 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08451847113229166		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.08451847113229166 | validation: 0.09808881563560418]
	TIME [epoch: 6.27 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08161803406327967		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.08161803406327967 | validation: 0.09575536382997163]
	TIME [epoch: 6.25 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08290014645744762		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.08290014645744762 | validation: 0.0941987594429366]
	TIME [epoch: 6.24 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07976965220516934		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.07976965220516934 | validation: 0.09163579235542067]
	TIME [epoch: 6.24 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08313174680474335		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.08313174680474335 | validation: 0.09913756673985188]
	TIME [epoch: 6.23 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08316295919109178		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.08316295919109178 | validation: 0.09911766630076477]
	TIME [epoch: 6.23 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08168236379508416		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.08168236379508416 | validation: 0.10214741837477231]
	TIME [epoch: 6.27 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08131533153270701		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.08131533153270701 | validation: 0.09104737851044366]
	TIME [epoch: 6.24 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08674612226471898		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.08674612226471898 | validation: 0.09839601177952326]
	TIME [epoch: 6.24 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08378200909279443		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.08378200909279443 | validation: 0.09521668248926332]
	TIME [epoch: 6.23 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08372271970712039		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.08372271970712039 | validation: 0.09952254080905727]
	TIME [epoch: 6.23 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09023245420223001		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.09023245420223001 | validation: 0.09756889374120235]
	TIME [epoch: 6.23 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08214961220275649		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.08214961220275649 | validation: 0.09909887409626403]
	TIME [epoch: 6.27 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08192841279624569		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.08192841279624569 | validation: 0.09372566670296761]
	TIME [epoch: 6.24 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08458112766682771		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.08458112766682771 | validation: 0.0926259792296511]
	TIME [epoch: 6.24 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08344318577652389		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.08344318577652389 | validation: 0.09124932909873018]
	TIME [epoch: 6.23 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07972629059239528		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.07972629059239528 | validation: 0.0969123585366956]
	TIME [epoch: 6.23 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08382703129539074		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.08382703129539074 | validation: 0.09949711954882083]
	TIME [epoch: 6.23 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.081508902781546		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.081508902781546 | validation: 0.09082705836716398]
	TIME [epoch: 6.27 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0813697651455776		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.0813697651455776 | validation: 0.10004852697985041]
	TIME [epoch: 6.25 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08180770838816248		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.08180770838816248 | validation: 0.09872673375427471]
	TIME [epoch: 6.23 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07983157893202406		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.07983157893202406 | validation: 0.08992177255301835]
	TIME [epoch: 6.23 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08042368166612172		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.08042368166612172 | validation: 0.09221523874686213]
	TIME [epoch: 6.24 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08694817439592148		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.08694817439592148 | validation: 0.10209303906956815]
	TIME [epoch: 6.23 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08008047131211005		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.08008047131211005 | validation: 0.10037479168385732]
	TIME [epoch: 6.27 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08480656542118589		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.08480656542118589 | validation: 0.09288278781547644]
	TIME [epoch: 6.24 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08323239160415234		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.08323239160415234 | validation: 0.09691772787096417]
	TIME [epoch: 6.23 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0793304126719463		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.0793304126719463 | validation: 0.1055586518420705]
	TIME [epoch: 6.23 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08095653931681882		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.08095653931681882 | validation: 0.08919872141031347]
	TIME [epoch: 6.23 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08188483011743555		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.08188483011743555 | validation: 0.09926641862222176]
	TIME [epoch: 6.23 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08167640220580133		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.08167640220580133 | validation: 0.09349698215866328]
	TIME [epoch: 6.27 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08795399672838569		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.08795399672838569 | validation: 0.10184207333807702]
	TIME [epoch: 6.24 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08087931491029327		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.08087931491029327 | validation: 0.09123217702438927]
	TIME [epoch: 6.24 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08127448934771056		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.08127448934771056 | validation: 0.09772454499611977]
	TIME [epoch: 6.24 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08252473834580007		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.08252473834580007 | validation: 0.094509926165835]
	TIME [epoch: 6.23 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08816162863935842		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.08816162863935842 | validation: 0.09266824819493849]
	TIME [epoch: 6.24 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0820969796396731		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.0820969796396731 | validation: 0.09511289507626035]
	TIME [epoch: 6.28 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08578730924167244		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.08578730924167244 | validation: 0.09311064331888248]
	TIME [epoch: 6.24 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08510897648043371		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.08510897648043371 | validation: 0.10191164244755983]
	TIME [epoch: 6.23 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08271211865535545		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.08271211865535545 | validation: 0.0934358705102794]
	TIME [epoch: 6.23 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08189855291934395		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.08189855291934395 | validation: 0.09635049328332719]
	TIME [epoch: 6.23 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08278984596197303		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.08278984596197303 | validation: 0.10668943454464744]
	TIME [epoch: 6.24 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08311923721858197		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.08311923721858197 | validation: 0.10531447476232343]
	TIME [epoch: 6.27 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08827508225340026		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.08827508225340026 | validation: 0.09268013676807688]
	TIME [epoch: 6.24 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08137437879283464		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.08137437879283464 | validation: 0.09800207626057576]
	TIME [epoch: 6.23 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07650246837006827		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.07650246837006827 | validation: 0.09714495272010457]
	TIME [epoch: 6.23 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08225693033775629		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.08225693033775629 | validation: 0.09610401942046937]
	TIME [epoch: 6.23 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08384944470252563		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.08384944470252563 | validation: 0.10124085287396625]
	TIME [epoch: 6.24 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0864850287812076		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.0864850287812076 | validation: 0.09818077238940462]
	TIME [epoch: 6.27 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08220823663986287		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.08220823663986287 | validation: 0.08815503410079939]
	TIME [epoch: 6.24 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08431717654092227		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.08431717654092227 | validation: 0.10182518107917984]
	TIME [epoch: 6.24 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07967247608894086		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.07967247608894086 | validation: 0.09911269933038647]
	TIME [epoch: 6.24 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07990120041299223		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.07990120041299223 | validation: 0.08647392979028012]
	TIME [epoch: 6.23 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08793614822340004		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.08793614822340004 | validation: 0.10038596841397923]
	TIME [epoch: 6.24 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08176456159319384		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.08176456159319384 | validation: 0.09596759044790926]
	TIME [epoch: 6.28 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0811389643806577		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.0811389643806577 | validation: 0.09747859972312745]
	TIME [epoch: 6.24 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08196996044423677		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.08196996044423677 | validation: 0.10027092089609771]
	TIME [epoch: 6.23 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08137325068261217		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.08137325068261217 | validation: 0.09387650258476873]
	TIME [epoch: 6.24 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08456342048403084		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.08456342048403084 | validation: 0.0891015539079699]
	TIME [epoch: 6.24 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08456902262595345		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.08456902262595345 | validation: 0.09403909570443325]
	TIME [epoch: 6.24 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08328099317432447		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.08328099317432447 | validation: 0.08986128366068367]
	TIME [epoch: 6.28 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08276120780501521		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.08276120780501521 | validation: 0.08975752809616067]
	TIME [epoch: 6.24 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08310639561045766		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.08310639561045766 | validation: 0.07080690914861151]
	TIME [epoch: 6.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_20240311_130654/states/model_phi1_1a_v1_1858.pth
	Model improved!!!
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08446787438523042		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.08446787438523042 | validation: 0.09750918596041494]
	TIME [epoch: 6.24 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08188686015772029		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.08188686015772029 | validation: 0.09478665667110064]
	TIME [epoch: 6.26 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08204277364498311		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.08204277364498311 | validation: 0.09784825923318866]
	TIME [epoch: 6.26 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08258144210028767		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.08258144210028767 | validation: 0.0947923843505014]
	TIME [epoch: 6.27 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08389578541843225		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.08389578541843225 | validation: 0.10034583551074591]
	TIME [epoch: 6.24 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07940454884728919		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.07940454884728919 | validation: 0.09074761741342546]
	TIME [epoch: 6.24 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08435242012420027		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.08435242012420027 | validation: 0.09296034974261078]
	TIME [epoch: 6.24 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08718237622527916		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.08718237622527916 | validation: 0.0893130885149579]
	TIME [epoch: 6.24 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08096444707956707		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.08096444707956707 | validation: 0.0948126474759034]
	TIME [epoch: 6.27 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08010591096939883		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.08010591096939883 | validation: 0.08688867913099142]
	TIME [epoch: 6.26 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08389060904779894		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.08389060904779894 | validation: 0.09476549561153483]
	TIME [epoch: 6.24 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08167609782239137		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.08167609782239137 | validation: 0.09488648126707983]
	TIME [epoch: 6.24 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08150021999961395		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.08150021999961395 | validation: 0.09684047369754051]
	TIME [epoch: 6.24 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08641234753246624		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.08641234753246624 | validation: 0.08868379442298574]
	TIME [epoch: 6.24 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08146012434152353		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.08146012434152353 | validation: 0.10791724696441801]
	TIME [epoch: 6.27 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08019783880913141		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.08019783880913141 | validation: 0.09622649599160248]
	TIME [epoch: 6.25 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0770999317775662		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.0770999317775662 | validation: 0.08937074163905091]
	TIME [epoch: 6.24 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08149700115415172		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.08149700115415172 | validation: 0.10476943199896015]
	TIME [epoch: 6.24 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08427248096346542		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.08427248096346542 | validation: 0.10113077321018454]
	TIME [epoch: 6.25 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08317104907614571		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.08317104907614571 | validation: 0.08349957086491394]
	TIME [epoch: 6.23 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0845557655884982		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.0845557655884982 | validation: 0.09646886935129509]
	TIME [epoch: 6.27 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08446031102062966		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.08446031102062966 | validation: 0.10177735086998942]
	TIME [epoch: 6.25 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08164067157326681		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.08164067157326681 | validation: 0.09228563343155202]
	TIME [epoch: 6.24 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08505470721929882		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.08505470721929882 | validation: 0.11175430257006641]
	TIME [epoch: 6.23 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08324156963475246		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.08324156963475246 | validation: 0.09407171679040682]
	TIME [epoch: 6.23 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0820236961641535		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.0820236961641535 | validation: 0.08971255853050214]
	TIME [epoch: 6.23 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08432932337330554		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.08432932337330554 | validation: 0.09681181520290705]
	TIME [epoch: 6.26 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08760436805070287		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.08760436805070287 | validation: 0.09237976019537042]
	TIME [epoch: 6.25 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08144403854483032		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.08144403854483032 | validation: 0.09501613811892642]
	TIME [epoch: 6.25 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0820607006714848		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.0820607006714848 | validation: 0.10166670259741978]
	TIME [epoch: 6.24 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08489754090167512		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.08489754090167512 | validation: 0.07652918004183938]
	TIME [epoch: 6.24 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07966993987243186		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.07966993987243186 | validation: 0.10852779050390773]
	TIME [epoch: 6.24 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08366911063245425		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.08366911063245425 | validation: 0.09487687357661745]
	TIME [epoch: 6.27 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0847999855531211		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.0847999855531211 | validation: 0.09122401430699112]
	TIME [epoch: 6.25 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08316446149437028		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.08316446149437028 | validation: 0.09833685572024331]
	TIME [epoch: 6.25 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08354177027978302		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.08354177027978302 | validation: 0.10251472652234987]
	TIME [epoch: 6.24 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08050055513096213		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.08050055513096213 | validation: 0.09120507252328545]
	TIME [epoch: 6.24 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07699043032108309		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.07699043032108309 | validation: 0.0900882899544883]
	TIME [epoch: 6.24 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0843240551156361		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.0843240551156361 | validation: 0.09191188043045104]
	TIME [epoch: 6.28 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08245784957422413		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.08245784957422413 | validation: 0.09144972585020186]
	TIME [epoch: 6.26 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08346073121863833		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.08346073121863833 | validation: 0.09568153642747812]
	TIME [epoch: 6.25 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08080237970940243		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.08080237970940243 | validation: 0.09188869340602968]
	TIME [epoch: 6.24 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07990589011362219		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.07990589011362219 | validation: 0.10540347149691714]
	TIME [epoch: 6.25 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08191158782474625		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.08191158782474625 | validation: 0.09677538183657466]
	TIME [epoch: 6.24 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08201624645666072		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.08201624645666072 | validation: 0.10593591305144011]
	TIME [epoch: 6.29 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0829903357844116		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.0829903357844116 | validation: 0.0915497953211492]
	TIME [epoch: 6.26 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07936717057927799		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.07936717057927799 | validation: 0.0983951823170256]
	TIME [epoch: 6.25 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08018152233661552		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.08018152233661552 | validation: 0.0996368382074049]
	TIME [epoch: 6.25 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08243884713368005		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.08243884713368005 | validation: 0.09115514975568399]
	TIME [epoch: 6.25 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0849124419620075		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.0849124419620075 | validation: 0.10438366379959987]
	TIME [epoch: 6.25 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08254484376988212		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.08254484376988212 | validation: 0.09702062137152337]
	TIME [epoch: 6.3 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07961797905056889		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.07961797905056889 | validation: 0.09405353273041668]
	TIME [epoch: 6.25 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08373827942003313		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.08373827942003313 | validation: 0.09382143426993392]
	TIME [epoch: 6.25 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08310662913079815		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.08310662913079815 | validation: 0.09014502028218471]
	TIME [epoch: 6.25 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08409834344598072		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.08409834344598072 | validation: 0.1045993999048904]
	TIME [epoch: 6.25 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08488476239997125		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.08488476239997125 | validation: 0.1180251070150482]
	TIME [epoch: 6.25 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08326917978408817		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.08326917978408817 | validation: 0.0953987907902448]
	TIME [epoch: 6.29 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08382645115011034		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.08382645115011034 | validation: 0.09041640487198699]
	TIME [epoch: 6.25 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0847399570726228		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.0847399570726228 | validation: 0.09157523185461222]
	TIME [epoch: 6.25 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08533376174017342		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.08533376174017342 | validation: 0.09552148828791857]
	TIME [epoch: 6.25 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0825661039318134		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.0825661039318134 | validation: 0.10432022423479936]
	TIME [epoch: 6.25 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08181287377421259		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.08181287377421259 | validation: 0.09236032042496908]
	TIME [epoch: 6.25 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08262156260804898		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.08262156260804898 | validation: 0.08651941202480473]
	TIME [epoch: 6.3 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0832672042952829		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.0832672042952829 | validation: 0.09704241711411918]
	TIME [epoch: 6.26 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07863897552156174		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.07863897552156174 | validation: 0.10125961276459089]
	TIME [epoch: 6.25 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08281103415951048		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.08281103415951048 | validation: 0.0989670394128136]
	TIME [epoch: 6.25 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08119930350379363		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.08119930350379363 | validation: 0.10777754357042962]
	TIME [epoch: 6.25 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08046082136786056		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.08046082136786056 | validation: 0.09426374439416328]
	TIME [epoch: 6.26 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08503664944180198		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.08503664944180198 | validation: 0.10196431733366473]
	TIME [epoch: 6.29 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07972282975818284		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.07972282975818284 | validation: 0.09452053726988607]
	TIME [epoch: 6.25 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08023995752640585		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.08023995752640585 | validation: 0.09289922639242643]
	TIME [epoch: 6.25 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08224601802311104		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.08224601802311104 | validation: 0.09497524005240726]
	TIME [epoch: 6.25 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08011275728766029		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.08011275728766029 | validation: 0.10129664290507068]
	TIME [epoch: 6.25 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08298033482244915		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.08298033482244915 | validation: 0.099700229165233]
	TIME [epoch: 6.26 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08390635621974177		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.08390635621974177 | validation: 0.09914186226645279]
	TIME [epoch: 6.3 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07924898777740509		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.07924898777740509 | validation: 0.10274042560063547]
	TIME [epoch: 6.25 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0808494977894179		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.0808494977894179 | validation: 0.08419111257617252]
	TIME [epoch: 6.25 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08338580636769474		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.08338580636769474 | validation: 0.08743295667933054]
	TIME [epoch: 6.26 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08177826289336695		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.08177826289336695 | validation: 0.09329823465157218]
	TIME [epoch: 6.25 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07993291982979571		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.07993291982979571 | validation: 0.09557639014966618]
	TIME [epoch: 6.26 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08228977519160771		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.08228977519160771 | validation: 0.10252201986262371]
	TIME [epoch: 6.3 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0789707165006952		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.0789707165006952 | validation: 0.09556453733438403]
	TIME [epoch: 6.25 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08045316368806806		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.08045316368806806 | validation: 0.0947017791383168]
	TIME [epoch: 6.25 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08157076057465593		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.08157076057465593 | validation: 0.09135668299946786]
	TIME [epoch: 6.25 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08111369568998716		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.08111369568998716 | validation: 0.10670571349981772]
	TIME [epoch: 6.25 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08292550653392503		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.08292550653392503 | validation: 0.08819570544377045]
	TIME [epoch: 6.26 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08232693768556072		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.08232693768556072 | validation: 0.09358822867534305]
	TIME [epoch: 6.28 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08336399526910297		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.08336399526910297 | validation: 0.10122851196719516]
	TIME [epoch: 6.25 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08051578188911773		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.08051578188911773 | validation: 0.10013803293373094]
	TIME [epoch: 6.25 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07957079921062289		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.07957079921062289 | validation: 0.09251229888620266]
	TIME [epoch: 6.24 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0824522944806189		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.0824522944806189 | validation: 0.10051141342819442]
	TIME [epoch: 6.25 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0802802886797954		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.0802802886797954 | validation: 0.09671065786190763]
	TIME [epoch: 6.27 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08063241129814341		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.08063241129814341 | validation: 0.09182087429289065]
	TIME [epoch: 6.28 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08221585109402066		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.08221585109402066 | validation: 0.1171854568555314]
	TIME [epoch: 6.25 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08598011917808164		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.08598011917808164 | validation: 0.09082628045940469]
	TIME [epoch: 6.25 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0738345008959784		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.0738345008959784 | validation: 0.09511262481631558]
	TIME [epoch: 6.26 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08278447504952509		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.08278447504952509 | validation: 0.09643822946940253]
	TIME [epoch: 6.25 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08347585358370499		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.08347585358370499 | validation: 0.09919374638024245]
	TIME [epoch: 6.28 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08318017986165344		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.08318017986165344 | validation: 0.0940756352052628]
	TIME [epoch: 6.27 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08427429615017044		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.08427429615017044 | validation: 0.09405131722124732]
	TIME [epoch: 6.25 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08002930499526419		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.08002930499526419 | validation: 0.10482464907755391]
	TIME [epoch: 6.25 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07888633153446589		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.07888633153446589 | validation: 0.09576716059964191]
	TIME [epoch: 6.25 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0814727168589748		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.0814727168589748 | validation: 0.10162368977049409]
	TIME [epoch: 6.25 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08006449417297146		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.08006449417297146 | validation: 0.09829414196983245]
	TIME [epoch: 6.28 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08234239619522454		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.08234239619522454 | validation: 0.08818196239468219]
	TIME [epoch: 6.28 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0841778937627405		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.0841778937627405 | validation: 0.09133926770858963]
	TIME [epoch: 6.25 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.083967877918497		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.083967877918497 | validation: 0.09480617628761356]
	TIME [epoch: 6.25 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0855260156805973		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.0855260156805973 | validation: 0.10189489575773936]
	TIME [epoch: 6.25 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08294105955012325		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.08294105955012325 | validation: 0.0945607117075406]
	TIME [epoch: 6.25 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08068640887067755		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.08068640887067755 | validation: 0.10393340028951012]
	TIME [epoch: 6.28 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07985032277947961		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.07985032277947961 | validation: 0.0991404612039352]
	TIME [epoch: 6.27 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07897049442125517		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.07897049442125517 | validation: 0.09128042671783043]
	TIME [epoch: 6.25 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07527301516144559		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.07527301516144559 | validation: 0.10581464986382348]
	TIME [epoch: 6.25 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08045551642284743		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.08045551642284743 | validation: 0.1038130275421913]
	TIME [epoch: 6.25 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08089588226588698		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.08089588226588698 | validation: 0.10644084716676083]
	TIME [epoch: 6.26 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07764813830511252		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.07764813830511252 | validation: 0.09296028317739904]
	TIME [epoch: 6.28 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08839533784795817		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.08839533784795817 | validation: 0.08834841124013404]
	TIME [epoch: 6.26 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08143359234966496		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.08143359234966496 | validation: 0.1020933648604384]
	TIME [epoch: 6.25 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08424142738064808		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.08424142738064808 | validation: 0.10641553230737781]
	TIME [epoch: 6.25 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07666281909717103		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.07666281909717103 | validation: 0.10058824510082855]
	TIME [epoch: 6.25 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08277469677009344		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.08277469677009344 | validation: 0.09688669829871074]
	TIME [epoch: 6.25 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08104840521958448		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.08104840521958448 | validation: 0.09151534977833573]
	TIME [epoch: 6.29 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0846954937885118		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.0846954937885118 | validation: 0.0918306703134527]
	TIME [epoch: 6.26 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08144626672922431		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.08144626672922431 | validation: 0.0938292253717428]
	TIME [epoch: 6.25 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08189906471795792		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.08189906471795792 | validation: 0.09376421544193544]
	TIME [epoch: 6.25 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08274446995543412		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.08274446995543412 | validation: 0.09553141998213098]
	TIME [epoch: 6.25 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08230952258800682		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.08230952258800682 | validation: 0.09495665785970767]
	TIME [epoch: 6.24 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07994102139631674		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.07994102139631674 | validation: 0.09427014533320108]
	TIME [epoch: 6.29 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08028303388672146		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.08028303388672146 | validation: 0.09639846521974661]
	TIME [epoch: 6.26 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08300418533068767		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.08300418533068767 | validation: 0.0840503779881189]
	TIME [epoch: 6.25 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08413705929558618		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.08413705929558618 | validation: 0.09593603828168465]
	TIME [epoch: 6.25 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08343389525379445		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.08343389525379445 | validation: 0.0938807355816006]
	TIME [epoch: 6.25 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08456112400252228		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.08456112400252228 | validation: 0.09813663116235964]
	TIME [epoch: 6.25 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08684064482771		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.08684064482771 | validation: 0.08363026219122985]
	TIME [epoch: 6.29 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08388884122782059		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.08388884122782059 | validation: 0.09589945434975632]
	TIME [epoch: 6.25 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08548037798878429		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.08548037798878429 | validation: 0.08924063014545049]
	TIME [epoch: 6.25 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0784511417831513		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.0784511417831513 | validation: 0.093756750584184]
	TIME [epoch: 6.25 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08158373302115766		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.08158373302115766 | validation: 0.08792929794033916]
	TIME [epoch: 6.25 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08009536385425463		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.08009536385425463 | validation: 0.08231305334626024]
	TIME [epoch: 6.26 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08140318267671807		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.08140318267671807 | validation: 0.0990502347649517]
	TIME [epoch: 6.29 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08501913341736123		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.08501913341736123 | validation: 0.09943629993888616]
	TIME [epoch: 6.25 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08148426403552268		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.08148426403552268 | validation: 0.1042408585976198]
	TIME [epoch: 6.25 sec]
Finished training in 12757.605 seconds.
