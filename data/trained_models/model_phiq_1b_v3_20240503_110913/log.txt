Args:
Namespace(name='model_phiq_1b_v3', outdir='out/model_training/model_phiq_1b_v3', training_data='data/training_data/data_phiq_1b/training', validation_data='data/training_data/data_phiq_1b/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.01, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.01, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.75, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1288938106

Training model...

Saving initial model state to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 4/4] avg loss: 10.687236853619481		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.687236853619481 | validation: 11.011209626384296]
	TIME [epoch: 171 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 4/4] avg loss: 10.225334912680085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.225334912680085 | validation: 10.637543193244728]
	TIME [epoch: 76.4 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 4/4] avg loss: 9.764284151561727		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.764284151561727 | validation: 10.373441802901562]
	TIME [epoch: 76.3 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 4/4] avg loss: 9.492290636188521		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.492290636188521 | validation: 10.053567381663324]
	TIME [epoch: 76.3 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 4/4] avg loss: 9.123668072970343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.123668072970343 | validation: 9.747619866585755]
	TIME [epoch: 76.3 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 4/4] avg loss: 8.679489290726291		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.679489290726291 | validation: 9.413003695352106]
	TIME [epoch: 76.3 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 4/4] avg loss: 8.336036794222105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.336036794222105 | validation: 9.309868284299647]
	TIME [epoch: 76.3 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 4/4] avg loss: 8.252751200715458		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.252751200715458 | validation: 9.365190967852058]
	TIME [epoch: 76.3 sec]
EPOCH 9/1000:
	Training over batches...
		[batch 4/4] avg loss: 8.112646588754723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.112646588754723 | validation: 9.114997005075434]
	TIME [epoch: 76.3 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_9.pth
	Model improved!!!
EPOCH 10/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.887429402320234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.887429402320234 | validation: 8.999300860046397]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_10.pth
	Model improved!!!
EPOCH 11/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.778543883966388		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.778543883966388 | validation: 8.798862508511892]
	TIME [epoch: 76.3 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_11.pth
	Model improved!!!
EPOCH 12/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.649048966137548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.649048966137548 | validation: 8.71534350315347]
	TIME [epoch: 76.3 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_12.pth
	Model improved!!!
EPOCH 13/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.548600654023438		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.548600654023438 | validation: 8.47729210214725]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_13.pth
	Model improved!!!
EPOCH 14/1000:
	Training over batches...
		[batch 4/4] avg loss: 8.186874003875781		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.186874003875781 | validation: 8.866275741672464]
	TIME [epoch: 76.2 sec]
EPOCH 15/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.637750151507474		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.637750151507474 | validation: 8.489668448411852]
	TIME [epoch: 76.2 sec]
EPOCH 16/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.408741863890565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.408741863890565 | validation: 8.305523986626504]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_16.pth
	Model improved!!!
EPOCH 17/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.387247716424053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.387247716424053 | validation: 8.429028792888605]
	TIME [epoch: 76.2 sec]
EPOCH 18/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.3019725595843346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.3019725595843346 | validation: 8.175920120830229]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_18.pth
	Model improved!!!
EPOCH 19/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.247132814821942		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.247132814821942 | validation: 8.216629229078968]
	TIME [epoch: 76.2 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.277824540452766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.277824540452766 | validation: 8.14365086437495]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_20.pth
	Model improved!!!
EPOCH 21/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.21541254512003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.21541254512003 | validation: 7.820887828409598]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_21.pth
	Model improved!!!
EPOCH 22/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.6611891217155845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.6611891217155845 | validation: 8.028436848551287]
	TIME [epoch: 76.2 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 4/4] avg loss: 8.212126360599129		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.212126360599129 | validation: 8.685582818083166]
	TIME [epoch: 76.2 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 4/4] avg loss: 8.040627051292937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.040627051292937 | validation: 7.6672305279522295]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_24.pth
	Model improved!!!
EPOCH 25/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.382669915057269		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.382669915057269 | validation: 7.830033047057878]
	TIME [epoch: 76.2 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.300823262734351		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.300823262734351 | validation: 8.297684512446978]
	TIME [epoch: 76.2 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.397454073270185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.397454073270185 | validation: 8.070017017749283]
	TIME [epoch: 76.1 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.206555225403201		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.206555225403201 | validation: 7.762176326890474]
	TIME [epoch: 76.2 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.116508493006918		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.116508493006918 | validation: 7.794556717481351]
	TIME [epoch: 76.2 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.19320828983445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.19320828983445 | validation: 7.882708590177181]
	TIME [epoch: 76.2 sec]
EPOCH 31/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.186302567868122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.186302567868122 | validation: 7.694579910750206]
	TIME [epoch: 76.2 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.069421417312137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.069421417312137 | validation: 7.5526050319287705]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_32.pth
	Model improved!!!
EPOCH 33/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.036626208536538		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.036626208536538 | validation: 7.641536730139105]
	TIME [epoch: 76.2 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.070573918041498		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.070573918041498 | validation: 7.545899418732527]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_34.pth
	Model improved!!!
EPOCH 35/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.017344340820168		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.017344340820168 | validation: 7.255362573649165]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_35.pth
	Model improved!!!
EPOCH 36/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.184096269493946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.184096269493946 | validation: 7.621230052523742]
	TIME [epoch: 76.2 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.036714322961211		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.036714322961211 | validation: 7.433773727947028]
	TIME [epoch: 76.2 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.950714985310072		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.950714985310072 | validation: 7.284351328864894]
	TIME [epoch: 76.2 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.3786195430193775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.3786195430193775 | validation: 7.408496760605884]
	TIME [epoch: 76.2 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.5546746023278715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.5546746023278715 | validation: 7.325097984074237]
	TIME [epoch: 76.2 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.191584732316811		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.191584732316811 | validation: 7.379935775300311]
	TIME [epoch: 76.2 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.295216177229316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.295216177229316 | validation: 7.289343327988032]
	TIME [epoch: 76.2 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.032595873025426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.032595873025426 | validation: 7.167796818091677]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_43.pth
	Model improved!!!
EPOCH 44/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.964394311654582		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.964394311654582 | validation: 7.21473473523703]
	TIME [epoch: 76.2 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.995104129405624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.995104129405624 | validation: 7.329288566789309]
	TIME [epoch: 76.2 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.332080394802483		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.332080394802483 | validation: 7.335721635976856]
	TIME [epoch: 76.4 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.375892390308507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.375892390308507 | validation: 7.241463765559315]
	TIME [epoch: 76.6 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.1083470296604965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.1083470296604965 | validation: 7.252369649432655]
	TIME [epoch: 76.7 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.070964072930593		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.070964072930593 | validation: 7.280170115679578]
	TIME [epoch: 76.6 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.060393527018852		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.060393527018852 | validation: 7.228306030624843]
	TIME [epoch: 76.5 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.019184551255194		[learning rate: 0.0099456]
	Learning Rate: 0.00994561
	LOSS [training: 7.019184551255194 | validation: 7.212762195643591]
	TIME [epoch: 76.4 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.963689471617508		[learning rate: 0.0098736]
	Learning Rate: 0.00987356
	LOSS [training: 6.963689471617508 | validation: 7.061571951195648]
	TIME [epoch: 76.7 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_52.pth
	Model improved!!!
EPOCH 53/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.882059179778791		[learning rate: 0.009802]
	Learning Rate: 0.00980202
	LOSS [training: 6.882059179778791 | validation: 7.130608572350981]
	TIME [epoch: 76.5 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.897632553733038		[learning rate: 0.009731]
	Learning Rate: 0.00973101
	LOSS [training: 6.897632553733038 | validation: 7.117304898118716]
	TIME [epoch: 76.4 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.861183785485601		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 6.861183785485601 | validation: 7.152861108033805]
	TIME [epoch: 76.6 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.851628437003577		[learning rate: 0.0095905]
	Learning Rate: 0.00959052
	LOSS [training: 6.851628437003577 | validation: 7.141869457771405]
	TIME [epoch: 76.6 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.870274730535071		[learning rate: 0.009521]
	Learning Rate: 0.00952104
	LOSS [training: 6.870274730535071 | validation: 7.094079125317159]
	TIME [epoch: 76.5 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.8616665725052925		[learning rate: 0.0094521]
	Learning Rate: 0.00945206
	LOSS [training: 6.8616665725052925 | validation: 7.037627554181794]
	TIME [epoch: 76.5 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_58.pth
	Model improved!!!
EPOCH 59/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.844986133237026		[learning rate: 0.0093836]
	Learning Rate: 0.00938358
	LOSS [training: 6.844986133237026 | validation: 7.124244709304877]
	TIME [epoch: 76.6 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.825345851038309		[learning rate: 0.0093156]
	Learning Rate: 0.00931559
	LOSS [training: 6.825345851038309 | validation: 6.903617182174171]
	TIME [epoch: 76.5 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_60.pth
	Model improved!!!
EPOCH 61/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.7600394003868916		[learning rate: 0.0092481]
	Learning Rate: 0.0092481
	LOSS [training: 6.7600394003868916 | validation: 6.818091748786898]
	TIME [epoch: 76.7 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_61.pth
	Model improved!!!
EPOCH 62/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.837815118767407		[learning rate: 0.0091811]
	Learning Rate: 0.0091811
	LOSS [training: 6.837815118767407 | validation: 6.8083822269874155]
	TIME [epoch: 76.5 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_62.pth
	Model improved!!!
EPOCH 63/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.918812069551325		[learning rate: 0.0091146]
	Learning Rate: 0.00911458
	LOSS [training: 6.918812069551325 | validation: 6.812749963616001]
	TIME [epoch: 76.6 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.839287300462125		[learning rate: 0.0090485]
	Learning Rate: 0.00904855
	LOSS [training: 6.839287300462125 | validation: 6.8129918298692]
	TIME [epoch: 76.8 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.74650485018159		[learning rate: 0.008983]
	Learning Rate: 0.00898299
	LOSS [training: 6.74650485018159 | validation: 6.868194838143716]
	TIME [epoch: 76.5 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.7048252094604734		[learning rate: 0.0089179]
	Learning Rate: 0.00891791
	LOSS [training: 6.7048252094604734 | validation: 6.74683657318606]
	TIME [epoch: 76.8 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_66.pth
	Model improved!!!
EPOCH 67/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.969340280992071		[learning rate: 0.0088533]
	Learning Rate: 0.0088533
	LOSS [training: 6.969340280992071 | validation: 7.007598035374663]
	TIME [epoch: 76.6 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 4/4] avg loss: 8.076239645165117		[learning rate: 0.0087892]
	Learning Rate: 0.00878916
	LOSS [training: 8.076239645165117 | validation: 7.394158765856008]
	TIME [epoch: 76.2 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 4/4] avg loss: 8.129109202435796		[learning rate: 0.0087255]
	Learning Rate: 0.00872548
	LOSS [training: 8.129109202435796 | validation: 7.5123395936129675]
	TIME [epoch: 76.7 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 4/4] avg loss: 8.455833726436996		[learning rate: 0.0086623]
	Learning Rate: 0.00866227
	LOSS [training: 8.455833726436996 | validation: 7.678326286756677]
	TIME [epoch: 76.6 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 4/4] avg loss: 8.535408060111504		[learning rate: 0.0085995]
	Learning Rate: 0.00859951
	LOSS [training: 8.535408060111504 | validation: 7.475136730573723]
	TIME [epoch: 76.7 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.816167656049851		[learning rate: 0.0085372]
	Learning Rate: 0.00853721
	LOSS [training: 7.816167656049851 | validation: 7.089221739613446]
	TIME [epoch: 76.8 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.512760107951431		[learning rate: 0.0084754]
	Learning Rate: 0.00847535
	LOSS [training: 7.512760107951431 | validation: 7.2497398845616825]
	TIME [epoch: 76.8 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.863313635080997		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 7.863313635080997 | validation: 6.787418614076076]
	TIME [epoch: 76.7 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.001977204601108		[learning rate: 0.008353]
	Learning Rate: 0.00835299
	LOSS [training: 7.001977204601108 | validation: 7.026665174401826]
	TIME [epoch: 76.6 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.783753389286003		[learning rate: 0.0082925]
	Learning Rate: 0.00829248
	LOSS [training: 6.783753389286003 | validation: 6.909849994698259]
	TIME [epoch: 76.5 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.765613995195631		[learning rate: 0.0082324]
	Learning Rate: 0.0082324
	LOSS [training: 6.765613995195631 | validation: 6.85665477049556]
	TIME [epoch: 76.4 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.804985979522511		[learning rate: 0.0081728]
	Learning Rate: 0.00817275
	LOSS [training: 6.804985979522511 | validation: 6.719760032934755]
	TIME [epoch: 76.5 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_78.pth
	Model improved!!!
EPOCH 79/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.935302149871828		[learning rate: 0.0081135]
	Learning Rate: 0.00811354
	LOSS [training: 6.935302149871828 | validation: 6.9628151981289585]
	TIME [epoch: 76.4 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.981293027519319		[learning rate: 0.0080548]
	Learning Rate: 0.00805476
	LOSS [training: 6.981293027519319 | validation: 6.817019477402819]
	TIME [epoch: 76.6 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.763930971567744		[learning rate: 0.0079964]
	Learning Rate: 0.0079964
	LOSS [training: 6.763930971567744 | validation: 6.812682613495475]
	TIME [epoch: 76.5 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.797616813036056		[learning rate: 0.0079385]
	Learning Rate: 0.00793847
	LOSS [training: 6.797616813036056 | validation: 6.846308002999386]
	TIME [epoch: 76.5 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.734749820138708		[learning rate: 0.007881]
	Learning Rate: 0.00788096
	LOSS [training: 6.734749820138708 | validation: 6.796197678895566]
	TIME [epoch: 76.5 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.706709902815356		[learning rate: 0.0078239]
	Learning Rate: 0.00782386
	LOSS [training: 6.706709902815356 | validation: 6.68619667563575]
	TIME [epoch: 76.5 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_84.pth
	Model improved!!!
EPOCH 85/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.741012019719084		[learning rate: 0.0077672]
	Learning Rate: 0.00776718
	LOSS [training: 6.741012019719084 | validation: 6.648112511355587]
	TIME [epoch: 76.6 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_85.pth
	Model improved!!!
EPOCH 86/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.956047811074795		[learning rate: 0.0077109]
	Learning Rate: 0.0077109
	LOSS [training: 6.956047811074795 | validation: 6.6569116405848145]
	TIME [epoch: 76.6 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.0780394631455446		[learning rate: 0.007655]
	Learning Rate: 0.00765504
	LOSS [training: 7.0780394631455446 | validation: 6.8618973744493035]
	TIME [epoch: 76.6 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.200638161650914		[learning rate: 0.0075996]
	Learning Rate: 0.00759958
	LOSS [training: 7.200638161650914 | validation: 6.658354032241734]
	TIME [epoch: 76.7 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.933546353994088		[learning rate: 0.0075445]
	Learning Rate: 0.00754452
	LOSS [training: 6.933546353994088 | validation: 6.704111793623863]
	TIME [epoch: 76.5 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.852122744043713		[learning rate: 0.0074899]
	Learning Rate: 0.00748986
	LOSS [training: 6.852122744043713 | validation: 6.751175287098441]
	TIME [epoch: 76.6 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.794179837854614		[learning rate: 0.0074356]
	Learning Rate: 0.0074356
	LOSS [training: 6.794179837854614 | validation: 6.772802830102766]
	TIME [epoch: 76.5 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.851257813842437		[learning rate: 0.0073817]
	Learning Rate: 0.00738173
	LOSS [training: 6.851257813842437 | validation: 6.648062327132973]
	TIME [epoch: 76.5 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_92.pth
	Model improved!!!
EPOCH 93/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.730716181349242		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 6.730716181349242 | validation: 6.712303924589023]
	TIME [epoch: 76.5 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.698663063991455		[learning rate: 0.0072752]
	Learning Rate: 0.00727515
	LOSS [training: 6.698663063991455 | validation: 6.685740770615755]
	TIME [epoch: 76.5 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.7341683516924595		[learning rate: 0.0072224]
	Learning Rate: 0.00722244
	LOSS [training: 6.7341683516924595 | validation: 6.555615725725719]
	TIME [epoch: 76.5 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_95.pth
	Model improved!!!
EPOCH 96/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.671988567348588		[learning rate: 0.0071701]
	Learning Rate: 0.00717012
	LOSS [training: 6.671988567348588 | validation: 6.643834104880026]
	TIME [epoch: 76.5 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.741511007281129		[learning rate: 0.0071182]
	Learning Rate: 0.00711817
	LOSS [training: 6.741511007281129 | validation: 6.568725628621637]
	TIME [epoch: 76.5 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.681984568582595		[learning rate: 0.0070666]
	Learning Rate: 0.0070666
	LOSS [training: 6.681984568582595 | validation: 6.6206265238825415]
	TIME [epoch: 76.5 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.746190508809691		[learning rate: 0.0070154]
	Learning Rate: 0.0070154
	LOSS [training: 6.746190508809691 | validation: 6.584137239370648]
	TIME [epoch: 76.5 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.617356005633406		[learning rate: 0.0069646]
	Learning Rate: 0.00696458
	LOSS [training: 6.617356005633406 | validation: 6.5744640070935]
	TIME [epoch: 76.5 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.593883514875408		[learning rate: 0.0069141]
	Learning Rate: 0.00691412
	LOSS [training: 6.593883514875408 | validation: 6.528934832274791]
	TIME [epoch: 76.4 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_101.pth
	Model improved!!!
EPOCH 102/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.597986939476504		[learning rate: 0.006864]
	Learning Rate: 0.00686403
	LOSS [training: 6.597986939476504 | validation: 6.612930665789484]
	TIME [epoch: 76.5 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.581157303228935		[learning rate: 0.0068143]
	Learning Rate: 0.0068143
	LOSS [training: 6.581157303228935 | validation: 6.68333487462853]
	TIME [epoch: 76.4 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.560888645708225		[learning rate: 0.0067649]
	Learning Rate: 0.00676493
	LOSS [training: 6.560888645708225 | validation: 6.552118562770856]
	TIME [epoch: 76.5 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.536587126503256		[learning rate: 0.0067159]
	Learning Rate: 0.00671592
	LOSS [training: 6.536587126503256 | validation: 6.375014285371841]
	TIME [epoch: 76.4 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_105.pth
	Model improved!!!
EPOCH 106/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.548297220301644		[learning rate: 0.0066673]
	Learning Rate: 0.00666726
	LOSS [training: 6.548297220301644 | validation: 6.447786701466832]
	TIME [epoch: 76.4 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.518889068459503		[learning rate: 0.006619]
	Learning Rate: 0.00661896
	LOSS [training: 6.518889068459503 | validation: 6.3105989837760434]
	TIME [epoch: 76.5 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_107.pth
	Model improved!!!
EPOCH 108/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.5251156033478175		[learning rate: 0.006571]
	Learning Rate: 0.006571
	LOSS [training: 6.5251156033478175 | validation: 6.4572558481627045]
	TIME [epoch: 76.4 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.459118687025631		[learning rate: 0.0065234]
	Learning Rate: 0.00652339
	LOSS [training: 6.459118687025631 | validation: 6.502862499334737]
	TIME [epoch: 76.4 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.465341949227288		[learning rate: 0.0064761]
	Learning Rate: 0.00647613
	LOSS [training: 6.465341949227288 | validation: 6.470282951225592]
	TIME [epoch: 76.5 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.516882370740554		[learning rate: 0.0064292]
	Learning Rate: 0.00642921
	LOSS [training: 6.516882370740554 | validation: 6.316480101739362]
	TIME [epoch: 76.4 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.466369560005619		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 6.466369560005619 | validation: 6.491534655651687]
	TIME [epoch: 76.4 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.398373569841468		[learning rate: 0.0063364]
	Learning Rate: 0.00633639
	LOSS [training: 6.398373569841468 | validation: 6.280570192084054]
	TIME [epoch: 76.5 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_113.pth
	Model improved!!!
EPOCH 114/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.371194688775772		[learning rate: 0.0062905]
	Learning Rate: 0.00629049
	LOSS [training: 6.371194688775772 | validation: 6.388941071321797]
	TIME [epoch: 76.4 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.430537785147473		[learning rate: 0.0062449]
	Learning Rate: 0.00624491
	LOSS [training: 6.430537785147473 | validation: 6.379714010397768]
	TIME [epoch: 76.5 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.563664002594037		[learning rate: 0.0061997]
	Learning Rate: 0.00619967
	LOSS [training: 6.563664002594037 | validation: 6.269385376879596]
	TIME [epoch: 76.6 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_116.pth
	Model improved!!!
EPOCH 117/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.465593846014544		[learning rate: 0.0061548]
	Learning Rate: 0.00615475
	LOSS [training: 6.465593846014544 | validation: 6.065612193742986]
	TIME [epoch: 76.4 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_117.pth
	Model improved!!!
EPOCH 118/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.532746391977769		[learning rate: 0.0061102]
	Learning Rate: 0.00611016
	LOSS [training: 6.532746391977769 | validation: 6.131056436020745]
	TIME [epoch: 76.4 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.364952134953079		[learning rate: 0.0060659]
	Learning Rate: 0.00606589
	LOSS [training: 6.364952134953079 | validation: 6.166042605840911]
	TIME [epoch: 76.4 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.349545708404894		[learning rate: 0.0060219]
	Learning Rate: 0.00602195
	LOSS [training: 6.349545708404894 | validation: 6.173647604327067]
	TIME [epoch: 76.4 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.4154244474245505		[learning rate: 0.0059783]
	Learning Rate: 0.00597832
	LOSS [training: 6.4154244474245505 | validation: 6.236414443133738]
	TIME [epoch: 76.5 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.386212205479756		[learning rate: 0.005935]
	Learning Rate: 0.005935
	LOSS [training: 6.386212205479756 | validation: 6.313277547767901]
	TIME [epoch: 76.4 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.388704875860727		[learning rate: 0.005892]
	Learning Rate: 0.00589201
	LOSS [training: 6.388704875860727 | validation: 6.3151331417434795]
	TIME [epoch: 76.4 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.382344632782144		[learning rate: 0.0058493]
	Learning Rate: 0.00584932
	LOSS [training: 6.382344632782144 | validation: 6.237981353082919]
	TIME [epoch: 76.5 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.347254717746267		[learning rate: 0.0058069]
	Learning Rate: 0.00580694
	LOSS [training: 6.347254717746267 | validation: 6.238140222330559]
	TIME [epoch: 76.5 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.363448280909405		[learning rate: 0.0057649]
	Learning Rate: 0.00576487
	LOSS [training: 6.363448280909405 | validation: 6.146452643380806]
	TIME [epoch: 76.5 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.358185800347108		[learning rate: 0.0057231]
	Learning Rate: 0.0057231
	LOSS [training: 6.358185800347108 | validation: 5.971378543849305]
	TIME [epoch: 76.5 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_127.pth
	Model improved!!!
EPOCH 128/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.290501160956042		[learning rate: 0.0056816]
	Learning Rate: 0.00568164
	LOSS [training: 6.290501160956042 | validation: 6.256105606342643]
	TIME [epoch: 76.5 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.295880318774897		[learning rate: 0.0056405]
	Learning Rate: 0.00564048
	LOSS [training: 6.295880318774897 | validation: 6.046875278105978]
	TIME [epoch: 76.5 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.344006527200474		[learning rate: 0.0055996]
	Learning Rate: 0.00559961
	LOSS [training: 6.344006527200474 | validation: 6.265056307614449]
	TIME [epoch: 76.5 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.62889148825678		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 6.62889148825678 | validation: 6.064975091825346]
	TIME [epoch: 76.7 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.322863962438148		[learning rate: 0.0055188]
	Learning Rate: 0.00551877
	LOSS [training: 6.322863962438148 | validation: 5.9104649494868005]
	TIME [epoch: 76.5 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_132.pth
	Model improved!!!
EPOCH 133/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.356819243379203		[learning rate: 0.0054788]
	Learning Rate: 0.00547878
	LOSS [training: 6.356819243379203 | validation: 6.186841031103919]
	TIME [epoch: 76.7 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.346513635698932		[learning rate: 0.0054391]
	Learning Rate: 0.00543909
	LOSS [training: 6.346513635698932 | validation: 6.064371745044042]
	TIME [epoch: 76.8 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.333213261670526		[learning rate: 0.0053997]
	Learning Rate: 0.00539968
	LOSS [training: 6.333213261670526 | validation: 6.130941440005019]
	TIME [epoch: 76.8 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.274255407828501		[learning rate: 0.0053606]
	Learning Rate: 0.00536056
	LOSS [training: 6.274255407828501 | validation: 5.845303355000838]
	TIME [epoch: 76.8 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_136.pth
	Model improved!!!
EPOCH 137/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.239252153318428		[learning rate: 0.0053217]
	Learning Rate: 0.00532173
	LOSS [training: 6.239252153318428 | validation: 5.965620097430303]
	TIME [epoch: 76.7 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.369181023382439		[learning rate: 0.0052832]
	Learning Rate: 0.00528317
	LOSS [training: 6.369181023382439 | validation: 5.912626885672445]
	TIME [epoch: 76.8 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.2762339750993394		[learning rate: 0.0052449]
	Learning Rate: 0.0052449
	LOSS [training: 6.2762339750993394 | validation: 6.108495195499245]
	TIME [epoch: 76.5 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.274645610045931		[learning rate: 0.0052069]
	Learning Rate: 0.0052069
	LOSS [training: 6.274645610045931 | validation: 5.999197395638687]
	TIME [epoch: 76.5 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.25228739553593		[learning rate: 0.0051692]
	Learning Rate: 0.00516917
	LOSS [training: 6.25228739553593 | validation: 6.077378882913775]
	TIME [epoch: 76.6 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.138408007576244		[learning rate: 0.0051317]
	Learning Rate: 0.00513172
	LOSS [training: 6.138408007576244 | validation: 5.870085476988353]
	TIME [epoch: 76.8 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.368746838206931		[learning rate: 0.0050945]
	Learning Rate: 0.00509454
	LOSS [training: 6.368746838206931 | validation: 5.860875077865261]
	TIME [epoch: 76.5 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.38614081774503		[learning rate: 0.0050576]
	Learning Rate: 0.00505763
	LOSS [training: 6.38614081774503 | validation: 5.945719315381766]
	TIME [epoch: 76.4 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.653909731638593		[learning rate: 0.005021]
	Learning Rate: 0.00502099
	LOSS [training: 6.653909731638593 | validation: 5.91444119568704]
	TIME [epoch: 76.3 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.38671201004707		[learning rate: 0.0049846]
	Learning Rate: 0.00498461
	LOSS [training: 6.38671201004707 | validation: 5.911586234518463]
	TIME [epoch: 76.4 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.414136868989204		[learning rate: 0.0049485]
	Learning Rate: 0.0049485
	LOSS [training: 6.414136868989204 | validation: 5.954906744636871]
	TIME [epoch: 76.4 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.33591244399863		[learning rate: 0.0049126]
	Learning Rate: 0.00491265
	LOSS [training: 6.33591244399863 | validation: 5.935285565500287]
	TIME [epoch: 76.4 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.204681972092125		[learning rate: 0.0048771]
	Learning Rate: 0.00487706
	LOSS [training: 6.204681972092125 | validation: 5.857768590787724]
	TIME [epoch: 76.4 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.204524347052014		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 6.204524347052014 | validation: 6.027709422393192]
	TIME [epoch: 76.4 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.191604764766952		[learning rate: 0.0048066]
	Learning Rate: 0.00480665
	LOSS [training: 6.191604764766952 | validation: 6.0053605863386075]
	TIME [epoch: 76.4 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.2116026529346104		[learning rate: 0.0047718]
	Learning Rate: 0.00477182
	LOSS [training: 6.2116026529346104 | validation: 6.0612688605089815]
	TIME [epoch: 76.4 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.2025783349482175		[learning rate: 0.0047373]
	Learning Rate: 0.00473725
	LOSS [training: 6.2025783349482175 | validation: 6.096624967715229]
	TIME [epoch: 76.4 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.195161643702267		[learning rate: 0.0047029]
	Learning Rate: 0.00470293
	LOSS [training: 6.195161643702267 | validation: 6.115020228819052]
	TIME [epoch: 76.4 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.184632925016129		[learning rate: 0.0046689]
	Learning Rate: 0.00466886
	LOSS [training: 6.184632925016129 | validation: 6.0226283524984385]
	TIME [epoch: 76.8 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.155053991819958		[learning rate: 0.004635]
	Learning Rate: 0.00463503
	LOSS [training: 6.155053991819958 | validation: 6.017980980882889]
	TIME [epoch: 76.4 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.106714258564375		[learning rate: 0.0046015]
	Learning Rate: 0.00460145
	LOSS [training: 6.106714258564375 | validation: 6.015118205659737]
	TIME [epoch: 76.4 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.162315670698126		[learning rate: 0.0045681]
	Learning Rate: 0.00456811
	LOSS [training: 6.162315670698126 | validation: 5.955567828610617]
	TIME [epoch: 76.4 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.0632651005357685		[learning rate: 0.004535]
	Learning Rate: 0.00453502
	LOSS [training: 6.0632651005357685 | validation: 5.658442152835422]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_159.pth
	Model improved!!!
EPOCH 160/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.1494639557866035		[learning rate: 0.0045022]
	Learning Rate: 0.00450216
	LOSS [training: 6.1494639557866035 | validation: 5.721559377126749]
	TIME [epoch: 76.2 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.23883097420291		[learning rate: 0.0044695]
	Learning Rate: 0.00446954
	LOSS [training: 6.23883097420291 | validation: 5.736203561388134]
	TIME [epoch: 76.2 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.103388396953855		[learning rate: 0.0044372]
	Learning Rate: 0.00443716
	LOSS [training: 6.103388396953855 | validation: 5.723350886951971]
	TIME [epoch: 76.2 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.185779553619952		[learning rate: 0.004405]
	Learning Rate: 0.00440501
	LOSS [training: 6.185779553619952 | validation: 5.777174084233679]
	TIME [epoch: 76.2 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.044408570620293		[learning rate: 0.0043731]
	Learning Rate: 0.0043731
	LOSS [training: 6.044408570620293 | validation: 5.938723112910429]
	TIME [epoch: 76.3 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.119346831587862		[learning rate: 0.0043414]
	Learning Rate: 0.00434142
	LOSS [training: 6.119346831587862 | validation: 5.8828543405723375]
	TIME [epoch: 76.2 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.05339517364118		[learning rate: 0.00431]
	Learning Rate: 0.00430996
	LOSS [training: 6.05339517364118 | validation: 5.715385969901141]
	TIME [epoch: 76.2 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.111093107563711		[learning rate: 0.0042787]
	Learning Rate: 0.00427874
	LOSS [training: 6.111093107563711 | validation: 5.744476624256296]
	TIME [epoch: 76.2 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.036329058444771		[learning rate: 0.0042477]
	Learning Rate: 0.00424774
	LOSS [training: 6.036329058444771 | validation: 5.834554213144098]
	TIME [epoch: 76.2 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.080820912323969		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 6.080820912323969 | validation: 5.863237741403995]
	TIME [epoch: 76.3 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.04104304912515		[learning rate: 0.0041864]
	Learning Rate: 0.00418641
	LOSS [training: 6.04104304912515 | validation: 5.619186212724141]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_170.pth
	Model improved!!!
EPOCH 171/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.17113646402305		[learning rate: 0.0041561]
	Learning Rate: 0.00415608
	LOSS [training: 6.17113646402305 | validation: 5.735918228585502]
	TIME [epoch: 76.2 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.467493532301509		[learning rate: 0.004126]
	Learning Rate: 0.00412597
	LOSS [training: 6.467493532301509 | validation: 5.593771203644215]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_172.pth
	Model improved!!!
EPOCH 173/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.220199516169643		[learning rate: 0.0040961]
	Learning Rate: 0.00409608
	LOSS [training: 6.220199516169643 | validation: 5.776283546076254]
	TIME [epoch: 76.2 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.175836695719545		[learning rate: 0.0040664]
	Learning Rate: 0.0040664
	LOSS [training: 6.175836695719545 | validation: 5.838443803685587]
	TIME [epoch: 76.2 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.089517165537715		[learning rate: 0.0040369]
	Learning Rate: 0.00403694
	LOSS [training: 6.089517165537715 | validation: 5.798526244259717]
	TIME [epoch: 76.2 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.996804874262338		[learning rate: 0.0040077]
	Learning Rate: 0.0040077
	LOSS [training: 5.996804874262338 | validation: 5.771733950935628]
	TIME [epoch: 76.2 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.041259437803296		[learning rate: 0.0039787]
	Learning Rate: 0.00397866
	LOSS [training: 6.041259437803296 | validation: 5.641591221196486]
	TIME [epoch: 76.2 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.183983771309206		[learning rate: 0.0039498]
	Learning Rate: 0.00394984
	LOSS [training: 6.183983771309206 | validation: 5.562954554092354]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_178.pth
	Model improved!!!
EPOCH 179/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.19791484965971		[learning rate: 0.0039212]
	Learning Rate: 0.00392122
	LOSS [training: 6.19791484965971 | validation: 5.566389430240406]
	TIME [epoch: 76.2 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.0515938498907405		[learning rate: 0.0038928]
	Learning Rate: 0.00389281
	LOSS [training: 6.0515938498907405 | validation: 5.660049730507211]
	TIME [epoch: 76.2 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.0875879311430285		[learning rate: 0.0038646]
	Learning Rate: 0.00386461
	LOSS [training: 6.0875879311430285 | validation: 5.635389075476095]
	TIME [epoch: 76.2 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.0765282035867125		[learning rate: 0.0038366]
	Learning Rate: 0.00383661
	LOSS [training: 6.0765282035867125 | validation: 5.59138626121557]
	TIME [epoch: 76.2 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.964416483317775		[learning rate: 0.0038088]
	Learning Rate: 0.00380881
	LOSS [training: 5.964416483317775 | validation: 5.716048711631988]
	TIME [epoch: 76.2 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.965501128481936		[learning rate: 0.0037812]
	Learning Rate: 0.00378122
	LOSS [training: 5.965501128481936 | validation: 5.673676967169811]
	TIME [epoch: 76.2 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.065711442251375		[learning rate: 0.0037538]
	Learning Rate: 0.00375382
	LOSS [training: 6.065711442251375 | validation: 5.80711537209755]
	TIME [epoch: 76.2 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.005938387885134		[learning rate: 0.0037266]
	Learning Rate: 0.00372663
	LOSS [training: 6.005938387885134 | validation: 5.651628352935857]
	TIME [epoch: 76.2 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.914194905275067		[learning rate: 0.0036996]
	Learning Rate: 0.00369963
	LOSS [training: 5.914194905275067 | validation: 5.687072715999905]
	TIME [epoch: 76.2 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.870087598435941		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 5.870087598435941 | validation: 5.562008174958654]
	TIME [epoch: 76.3 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_188.pth
	Model improved!!!
EPOCH 189/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.873764665344208		[learning rate: 0.0036462]
	Learning Rate: 0.00364621
	LOSS [training: 5.873764665344208 | validation: 5.644727716075231]
	TIME [epoch: 76.2 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.892505931567548		[learning rate: 0.0036198]
	Learning Rate: 0.0036198
	LOSS [training: 5.892505931567548 | validation: 5.688572665373309]
	TIME [epoch: 76.2 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.929789519305343		[learning rate: 0.0035936]
	Learning Rate: 0.00359357
	LOSS [training: 5.929789519305343 | validation: 5.548802631090072]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_191.pth
	Model improved!!!
EPOCH 192/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.874118641957222		[learning rate: 0.0035675]
	Learning Rate: 0.00356754
	LOSS [training: 5.874118641957222 | validation: 5.523648252314048]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_192.pth
	Model improved!!!
EPOCH 193/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.872560115901285		[learning rate: 0.0035417]
	Learning Rate: 0.00354169
	LOSS [training: 5.872560115901285 | validation: 5.522823427620855]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_193.pth
	Model improved!!!
EPOCH 194/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.87759573084357		[learning rate: 0.003516]
	Learning Rate: 0.00351603
	LOSS [training: 5.87759573084357 | validation: 5.409451250276015]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_194.pth
	Model improved!!!
EPOCH 195/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.794418260825175		[learning rate: 0.0034906]
	Learning Rate: 0.00349056
	LOSS [training: 5.794418260825175 | validation: 5.639768108171953]
	TIME [epoch: 76.2 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.744601631826228		[learning rate: 0.0034653]
	Learning Rate: 0.00346527
	LOSS [training: 5.744601631826228 | validation: 5.558031448223305]
	TIME [epoch: 76.1 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.6833364244254705		[learning rate: 0.0034402]
	Learning Rate: 0.00344016
	LOSS [training: 5.6833364244254705 | validation: 5.39369852298622]
	TIME [epoch: 76.1 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_197.pth
	Model improved!!!
EPOCH 198/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.6801554511030075		[learning rate: 0.0034152]
	Learning Rate: 0.00341524
	LOSS [training: 5.6801554511030075 | validation: 5.54385634241698]
	TIME [epoch: 76.2 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.69253518885346		[learning rate: 0.0033905]
	Learning Rate: 0.0033905
	LOSS [training: 5.69253518885346 | validation: 5.529937269312345]
	TIME [epoch: 76.3 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.687069259147057		[learning rate: 0.0033659]
	Learning Rate: 0.00336593
	LOSS [training: 5.687069259147057 | validation: 5.46521974562634]
	TIME [epoch: 76.2 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.600606006067441		[learning rate: 0.0033415]
	Learning Rate: 0.00334155
	LOSS [training: 5.600606006067441 | validation: 5.557376235195431]
	TIME [epoch: 76.3 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.595902163685487		[learning rate: 0.0033173]
	Learning Rate: 0.00331734
	LOSS [training: 5.595902163685487 | validation: 5.260523477925617]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_202.pth
	Model improved!!!
EPOCH 203/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.5238406274679726		[learning rate: 0.0032933]
	Learning Rate: 0.0032933
	LOSS [training: 5.5238406274679726 | validation: 5.295459583032082]
	TIME [epoch: 76.2 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.490662334278699		[learning rate: 0.0032694]
	Learning Rate: 0.00326944
	LOSS [training: 5.490662334278699 | validation: 5.326834805411672]
	TIME [epoch: 76.3 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.592710552965345		[learning rate: 0.0032458]
	Learning Rate: 0.00324576
	LOSS [training: 5.592710552965345 | validation: 5.2981073901234685]
	TIME [epoch: 76.2 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.61137976305937		[learning rate: 0.0032222]
	Learning Rate: 0.00322224
	LOSS [training: 5.61137976305937 | validation: 5.379062875018364]
	TIME [epoch: 76.2 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.525982968180202		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 5.525982968180202 | validation: 5.273866125915077]
	TIME [epoch: 76.3 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.705045366210151		[learning rate: 0.0031757]
	Learning Rate: 0.00317572
	LOSS [training: 5.705045366210151 | validation: 5.459674811231119]
	TIME [epoch: 76.2 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.588801989102814		[learning rate: 0.0031527]
	Learning Rate: 0.00315271
	LOSS [training: 5.588801989102814 | validation: 5.427781741372369]
	TIME [epoch: 76.2 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.484603386994344		[learning rate: 0.0031299]
	Learning Rate: 0.00312987
	LOSS [training: 5.484603386994344 | validation: 5.342419322623401]
	TIME [epoch: 76.2 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.423481649725084		[learning rate: 0.0031072]
	Learning Rate: 0.00310719
	LOSS [training: 5.423481649725084 | validation: 5.307780686748043]
	TIME [epoch: 76.2 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.4886863412908795		[learning rate: 0.0030847]
	Learning Rate: 0.00308468
	LOSS [training: 5.4886863412908795 | validation: 5.195641973531673]
	TIME [epoch: 76.3 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_212.pth
	Model improved!!!
EPOCH 213/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.351633773187232		[learning rate: 0.0030623]
	Learning Rate: 0.00306233
	LOSS [training: 5.351633773187232 | validation: 5.2341881773435155]
	TIME [epoch: 76.2 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.3743192092876315		[learning rate: 0.0030401]
	Learning Rate: 0.00304015
	LOSS [training: 5.3743192092876315 | validation: 5.236174341724562]
	TIME [epoch: 76.2 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.390777327963052		[learning rate: 0.0030181]
	Learning Rate: 0.00301812
	LOSS [training: 5.390777327963052 | validation: 5.304503934920062]
	TIME [epoch: 76.2 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.3360416278689256		[learning rate: 0.0029963]
	Learning Rate: 0.00299626
	LOSS [training: 5.3360416278689256 | validation: 5.08005069192065]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_216.pth
	Model improved!!!
EPOCH 217/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.266609850000123		[learning rate: 0.0029745]
	Learning Rate: 0.00297455
	LOSS [training: 5.266609850000123 | validation: 5.3255209714187]
	TIME [epoch: 76.2 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.491351658762752		[learning rate: 0.002953]
	Learning Rate: 0.002953
	LOSS [training: 5.491351658762752 | validation: 5.27731099185471]
	TIME [epoch: 76.2 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.4822466954559115		[learning rate: 0.0029316]
	Learning Rate: 0.0029316
	LOSS [training: 5.4822466954559115 | validation: 5.322049481641786]
	TIME [epoch: 76.2 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.36150220812706		[learning rate: 0.0029104]
	Learning Rate: 0.00291036
	LOSS [training: 5.36150220812706 | validation: 5.271876559897674]
	TIME [epoch: 76.2 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.328539358160412		[learning rate: 0.0028893]
	Learning Rate: 0.00288928
	LOSS [training: 5.328539358160412 | validation: 5.289600641166055]
	TIME [epoch: 76.2 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.3638769254767436		[learning rate: 0.0028683]
	Learning Rate: 0.00286835
	LOSS [training: 5.3638769254767436 | validation: 5.131706011165126]
	TIME [epoch: 76.2 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.383181627710727		[learning rate: 0.0028476]
	Learning Rate: 0.00284757
	LOSS [training: 5.383181627710727 | validation: 5.377002546824141]
	TIME [epoch: 76.2 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.529450077048434		[learning rate: 0.0028269]
	Learning Rate: 0.00282693
	LOSS [training: 5.529450077048434 | validation: 5.299353021144318]
	TIME [epoch: 76.2 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.406460879407272		[learning rate: 0.0028065]
	Learning Rate: 0.00280645
	LOSS [training: 5.406460879407272 | validation: 5.178001691947982]
	TIME [epoch: 76.2 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.272656606521889		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 5.272656606521889 | validation: 5.00920667094605]
	TIME [epoch: 76.3 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_226.pth
	Model improved!!!
EPOCH 227/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.274418277743056		[learning rate: 0.0027659]
	Learning Rate: 0.00276594
	LOSS [training: 5.274418277743056 | validation: 5.2307373731261615]
	TIME [epoch: 76.2 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.166656471823789		[learning rate: 0.0027459]
	Learning Rate: 0.0027459
	LOSS [training: 5.166656471823789 | validation: 5.43076234809982]
	TIME [epoch: 76.2 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.542843128353506		[learning rate: 0.002726]
	Learning Rate: 0.002726
	LOSS [training: 5.542843128353506 | validation: 5.0848084442690915]
	TIME [epoch: 76.2 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.237955681393084		[learning rate: 0.0027063]
	Learning Rate: 0.00270625
	LOSS [training: 5.237955681393084 | validation: 5.13785838798335]
	TIME [epoch: 76.2 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.169314161409478		[learning rate: 0.0026866]
	Learning Rate: 0.00268665
	LOSS [training: 5.169314161409478 | validation: 5.117428436810037]
	TIME [epoch: 76.2 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.1621452305045405		[learning rate: 0.0026672]
	Learning Rate: 0.00266718
	LOSS [training: 5.1621452305045405 | validation: 5.217944453008711]
	TIME [epoch: 76.2 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.193039223863031		[learning rate: 0.0026479]
	Learning Rate: 0.00264786
	LOSS [training: 5.193039223863031 | validation: 5.1349383066613035]
	TIME [epoch: 76.2 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.107497895951814		[learning rate: 0.0026287]
	Learning Rate: 0.00262867
	LOSS [training: 5.107497895951814 | validation: 4.980843815139972]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_234.pth
	Model improved!!!
EPOCH 235/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.241915967033614		[learning rate: 0.0026096]
	Learning Rate: 0.00260963
	LOSS [training: 5.241915967033614 | validation: 5.205911142657255]
	TIME [epoch: 76.2 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.298576220746206		[learning rate: 0.0025907]
	Learning Rate: 0.00259072
	LOSS [training: 5.298576220746206 | validation: 5.209682822063636]
	TIME [epoch: 76.1 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.21024226679137		[learning rate: 0.002572]
	Learning Rate: 0.00257195
	LOSS [training: 5.21024226679137 | validation: 4.961997547918597]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_237.pth
	Model improved!!!
EPOCH 238/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.0924456874035045		[learning rate: 0.0025533]
	Learning Rate: 0.00255332
	LOSS [training: 5.0924456874035045 | validation: 4.953784349668966]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_238.pth
	Model improved!!!
EPOCH 239/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.067971819363121		[learning rate: 0.0025348]
	Learning Rate: 0.00253482
	LOSS [training: 5.067971819363121 | validation: 4.981922937152596]
	TIME [epoch: 76.2 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.075713027236909		[learning rate: 0.0025165]
	Learning Rate: 0.00251646
	LOSS [training: 5.075713027236909 | validation: 4.969661762551742]
	TIME [epoch: 76.1 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.087713255568348		[learning rate: 0.0024982]
	Learning Rate: 0.00249823
	LOSS [training: 5.087713255568348 | validation: 4.978857637738351]
	TIME [epoch: 76.2 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.9951794197747645		[learning rate: 0.0024801]
	Learning Rate: 0.00248013
	LOSS [training: 4.9951794197747645 | validation: 4.890011482296504]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_242.pth
	Model improved!!!
EPOCH 243/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.038081782518219		[learning rate: 0.0024622]
	Learning Rate: 0.00246216
	LOSS [training: 5.038081782518219 | validation: 5.040296058232107]
	TIME [epoch: 76.2 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.024685387605107		[learning rate: 0.0024443]
	Learning Rate: 0.00244432
	LOSS [training: 5.024685387605107 | validation: 4.837627299260564]
	TIME [epoch: 76.1 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_244.pth
	Model improved!!!
EPOCH 245/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.011191863694152		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 5.011191863694152 | validation: 4.879158884900852]
	TIME [epoch: 76.1 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.934670347644527		[learning rate: 0.002409]
	Learning Rate: 0.00240903
	LOSS [training: 4.934670347644527 | validation: 4.8423664421198795]
	TIME [epoch: 76.2 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.934135189037126		[learning rate: 0.0023916]
	Learning Rate: 0.00239158
	LOSS [training: 4.934135189037126 | validation: 5.161689209871447]
	TIME [epoch: 76.2 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.347026110649467		[learning rate: 0.0023742]
	Learning Rate: 0.00237425
	LOSS [training: 5.347026110649467 | validation: 5.025365480613821]
	TIME [epoch: 76.2 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.074238494964456		[learning rate: 0.002357]
	Learning Rate: 0.00235705
	LOSS [training: 5.074238494964456 | validation: 4.884552429490254]
	TIME [epoch: 76.1 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.937493769506832		[learning rate: 0.00234]
	Learning Rate: 0.00233997
	LOSS [training: 4.937493769506832 | validation: 4.806789377612818]
	TIME [epoch: 76.1 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_250.pth
	Model improved!!!
EPOCH 251/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.920041038265006		[learning rate: 0.002323]
	Learning Rate: 0.00232302
	LOSS [training: 4.920041038265006 | validation: 4.822980185008582]
	TIME [epoch: 76.2 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.8818366108650615		[learning rate: 0.0023062]
	Learning Rate: 0.00230619
	LOSS [training: 4.8818366108650615 | validation: 4.683772051223352]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_252.pth
	Model improved!!!
EPOCH 253/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.8308323742400745		[learning rate: 0.0022895]
	Learning Rate: 0.00228948
	LOSS [training: 4.8308323742400745 | validation: 5.04523511879437]
	TIME [epoch: 76.2 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.955345596343191		[learning rate: 0.0022729]
	Learning Rate: 0.00227289
	LOSS [training: 4.955345596343191 | validation: 4.670559250259384]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_254.pth
	Model improved!!!
EPOCH 255/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.824706049399173		[learning rate: 0.0022564]
	Learning Rate: 0.00225643
	LOSS [training: 4.824706049399173 | validation: 4.7925477385384525]
	TIME [epoch: 76.2 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.8171439087164725		[learning rate: 0.0022401]
	Learning Rate: 0.00224008
	LOSS [training: 4.8171439087164725 | validation: 4.907047259856917]
	TIME [epoch: 76.2 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.815056085916787		[learning rate: 0.0022238]
	Learning Rate: 0.00222385
	LOSS [training: 4.815056085916787 | validation: 4.765073135502801]
	TIME [epoch: 76.2 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.74512312538986		[learning rate: 0.0022077]
	Learning Rate: 0.00220774
	LOSS [training: 4.74512312538986 | validation: 4.725677006154244]
	TIME [epoch: 76.2 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.747074787548916		[learning rate: 0.0021917]
	Learning Rate: 0.00219174
	LOSS [training: 4.747074787548916 | validation: 4.691113317362758]
	TIME [epoch: 76.2 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.792826573017734		[learning rate: 0.0021759]
	Learning Rate: 0.00217586
	LOSS [training: 4.792826573017734 | validation: 4.642990781767628]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_260.pth
	Model improved!!!
EPOCH 261/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.6832638351978275		[learning rate: 0.0021601]
	Learning Rate: 0.0021601
	LOSS [training: 4.6832638351978275 | validation: 4.607883426577395]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_261.pth
	Model improved!!!
EPOCH 262/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.657394116762987		[learning rate: 0.0021444]
	Learning Rate: 0.00214445
	LOSS [training: 4.657394116762987 | validation: 4.677254001043078]
	TIME [epoch: 76.2 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.6623105660503334		[learning rate: 0.0021289]
	Learning Rate: 0.00212891
	LOSS [training: 4.6623105660503334 | validation: 4.617672071923243]
	TIME [epoch: 76.3 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.610963017553044		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 4.610963017553044 | validation: 4.526019874691546]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_264.pth
	Model improved!!!
EPOCH 265/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.531221976433479		[learning rate: 0.0020982]
	Learning Rate: 0.00209818
	LOSS [training: 4.531221976433479 | validation: 4.422620954629381]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_265.pth
	Model improved!!!
EPOCH 266/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.533138614624307		[learning rate: 0.002083]
	Learning Rate: 0.00208298
	LOSS [training: 4.533138614624307 | validation: 4.517773076203729]
	TIME [epoch: 76.2 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.5678761787540445		[learning rate: 0.0020679]
	Learning Rate: 0.00206788
	LOSS [training: 4.5678761787540445 | validation: 4.484347664600136]
	TIME [epoch: 76.1 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.520627936143791		[learning rate: 0.0020529]
	Learning Rate: 0.0020529
	LOSS [training: 4.520627936143791 | validation: 4.396212987548512]
	TIME [epoch: 76.1 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_268.pth
	Model improved!!!
EPOCH 269/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.499022081135435		[learning rate: 0.002038]
	Learning Rate: 0.00203803
	LOSS [training: 4.499022081135435 | validation: 4.690783194567674]
	TIME [epoch: 76.2 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.524091921550433		[learning rate: 0.0020233]
	Learning Rate: 0.00202326
	LOSS [training: 4.524091921550433 | validation: 4.696565759760228]
	TIME [epoch: 76.2 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.610762500953994		[learning rate: 0.0020086]
	Learning Rate: 0.00200861
	LOSS [training: 4.610762500953994 | validation: 5.220045237116874]
	TIME [epoch: 76.1 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.63847181689553		[learning rate: 0.0019941]
	Learning Rate: 0.00199405
	LOSS [training: 4.63847181689553 | validation: 4.451005028367052]
	TIME [epoch: 76.1 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.51025354553905		[learning rate: 0.0019796]
	Learning Rate: 0.00197961
	LOSS [training: 4.51025354553905 | validation: 4.991290336590347]
	TIME [epoch: 76.2 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.668023831494964		[learning rate: 0.0019653]
	Learning Rate: 0.00196527
	LOSS [training: 4.668023831494964 | validation: 4.518389731710171]
	TIME [epoch: 76.1 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.532590947887621		[learning rate: 0.001951]
	Learning Rate: 0.00195103
	LOSS [training: 4.532590947887621 | validation: 4.783091841384521]
	TIME [epoch: 76.1 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.6138629065585945		[learning rate: 0.0019369]
	Learning Rate: 0.00193689
	LOSS [training: 4.6138629065585945 | validation: 4.832231343988268]
	TIME [epoch: 76.1 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.443394292831236		[learning rate: 0.0019229]
	Learning Rate: 0.00192286
	LOSS [training: 4.443394292831236 | validation: 4.392204157236757]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_277.pth
	Model improved!!!
EPOCH 278/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.364670875590295		[learning rate: 0.0019089]
	Learning Rate: 0.00190893
	LOSS [training: 4.364670875590295 | validation: 4.530734853300244]
	TIME [epoch: 76.1 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.385434416530754		[learning rate: 0.0018951]
	Learning Rate: 0.0018951
	LOSS [training: 4.385434416530754 | validation: 4.621086493002514]
	TIME [epoch: 76.1 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.434721715215174		[learning rate: 0.0018814]
	Learning Rate: 0.00188137
	LOSS [training: 4.434721715215174 | validation: 4.270044865303676]
	TIME [epoch: 76.1 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_280.pth
	Model improved!!!
EPOCH 281/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.299473275426749		[learning rate: 0.0018677]
	Learning Rate: 0.00186774
	LOSS [training: 4.299473275426749 | validation: 4.223765910363452]
	TIME [epoch: 76.1 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_281.pth
	Model improved!!!
EPOCH 282/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.30945313350788		[learning rate: 0.0018542]
	Learning Rate: 0.00185421
	LOSS [training: 4.30945313350788 | validation: 4.208850646210294]
	TIME [epoch: 76.1 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_282.pth
	Model improved!!!
EPOCH 283/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.265381136154116		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 4.265381136154116 | validation: 4.54950449607445]
	TIME [epoch: 76.1 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.366596039178531		[learning rate: 0.0018274]
	Learning Rate: 0.00182744
	LOSS [training: 4.366596039178531 | validation: 4.1917273290200505]
	TIME [epoch: 76.1 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_284.pth
	Model improved!!!
EPOCH 285/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.38171356728065		[learning rate: 0.0018142]
	Learning Rate: 0.0018142
	LOSS [training: 4.38171356728065 | validation: 4.182262893401087]
	TIME [epoch: 76.1 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_285.pth
	Model improved!!!
EPOCH 286/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.40978638422168		[learning rate: 0.0018011]
	Learning Rate: 0.00180105
	LOSS [training: 4.40978638422168 | validation: 4.940283400724457]
	TIME [epoch: 76.1 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.43235571667373		[learning rate: 0.001788]
	Learning Rate: 0.001788
	LOSS [training: 4.43235571667373 | validation: 4.406621733940124]
	TIME [epoch: 76.1 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.299121000579641		[learning rate: 0.001775]
	Learning Rate: 0.00177505
	LOSS [training: 4.299121000579641 | validation: 4.250602480458289]
	TIME [epoch: 76.1 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.266793864999148		[learning rate: 0.0017622]
	Learning Rate: 0.00176219
	LOSS [training: 4.266793864999148 | validation: 4.040218512275624]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_289.pth
	Model improved!!!
EPOCH 290/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.206128693307642		[learning rate: 0.0017494]
	Learning Rate: 0.00174942
	LOSS [training: 4.206128693307642 | validation: 4.278535598146814]
	TIME [epoch: 76.1 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.44949698619466		[learning rate: 0.0017367]
	Learning Rate: 0.00173675
	LOSS [training: 4.44949698619466 | validation: 5.0384067251447275]
	TIME [epoch: 76.1 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.358826201491177		[learning rate: 0.0017242]
	Learning Rate: 0.00172417
	LOSS [training: 4.358826201491177 | validation: 4.014484669886382]
	TIME [epoch: 76.1 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_292.pth
	Model improved!!!
EPOCH 293/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.12894741185555		[learning rate: 0.0017117]
	Learning Rate: 0.00171167
	LOSS [training: 4.12894741185555 | validation: 4.140943543464735]
	TIME [epoch: 76.1 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.253808446445672		[learning rate: 0.0016993]
	Learning Rate: 0.00169927
	LOSS [training: 4.253808446445672 | validation: 3.9814383924698706]
	TIME [epoch: 76.1 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_294.pth
	Model improved!!!
EPOCH 295/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.121923822004681		[learning rate: 0.001687]
	Learning Rate: 0.00168696
	LOSS [training: 4.121923822004681 | validation: 4.0545220041021315]
	TIME [epoch: 76.1 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.091968378767085		[learning rate: 0.0016747]
	Learning Rate: 0.00167474
	LOSS [training: 4.091968378767085 | validation: 4.382279993336606]
	TIME [epoch: 76.1 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.4387153501177465		[learning rate: 0.0016626]
	Learning Rate: 0.00166261
	LOSS [training: 4.4387153501177465 | validation: 4.746357888735403]
	TIME [epoch: 76.1 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.595875805289679		[learning rate: 0.0016506]
	Learning Rate: 0.00165056
	LOSS [training: 4.595875805289679 | validation: 5.4452534363979]
	TIME [epoch: 76.1 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.544980054157515		[learning rate: 0.0016386]
	Learning Rate: 0.0016386
	LOSS [training: 4.544980054157515 | validation: 4.733458381497949]
	TIME [epoch: 76.1 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.415387323060554		[learning rate: 0.0016267]
	Learning Rate: 0.00162673
	LOSS [training: 4.415387323060554 | validation: 4.591964383073648]
	TIME [epoch: 76.2 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.1913377366846785		[learning rate: 0.0016149]
	Learning Rate: 0.00161495
	LOSS [training: 4.1913377366846785 | validation: 4.181410659969373]
	TIME [epoch: 76.1 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.193180361390016		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 4.193180361390016 | validation: 4.7597308812028345]
	TIME [epoch: 76.2 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.418048552271534		[learning rate: 0.0015916]
	Learning Rate: 0.00159163
	LOSS [training: 4.418048552271534 | validation: 4.653697799198799]
	TIME [epoch: 76.1 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.4478875823690815		[learning rate: 0.0015801]
	Learning Rate: 0.0015801
	LOSS [training: 4.4478875823690815 | validation: 4.6899539469542475]
	TIME [epoch: 76.1 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.564902192935003		[learning rate: 0.0015687]
	Learning Rate: 0.00156865
	LOSS [training: 4.564902192935003 | validation: 5.545488933236023]
	TIME [epoch: 76.1 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.52867285707208		[learning rate: 0.0015573]
	Learning Rate: 0.00155729
	LOSS [training: 4.52867285707208 | validation: 4.980041740803646]
	TIME [epoch: 76.2 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.453865583622713		[learning rate: 0.001546]
	Learning Rate: 0.001546
	LOSS [training: 4.453865583622713 | validation: 3.9372929162042203]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_307.pth
	Model improved!!!
EPOCH 308/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.260499796902407		[learning rate: 0.0015348]
	Learning Rate: 0.0015348
	LOSS [training: 4.260499796902407 | validation: 4.476691211384418]
	TIME [epoch: 76.1 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.624969045782121		[learning rate: 0.0015237]
	Learning Rate: 0.00152368
	LOSS [training: 4.624969045782121 | validation: 5.798588667726992]
	TIME [epoch: 76.1 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.422118643114924		[learning rate: 0.0015126]
	Learning Rate: 0.00151264
	LOSS [training: 5.422118643114924 | validation: 6.3125316381521]
	TIME [epoch: 76.1 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.127400220832209		[learning rate: 0.0015017]
	Learning Rate: 0.00150169
	LOSS [training: 5.127400220832209 | validation: 4.265641669025208]
	TIME [epoch: 76.1 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.164557674499356		[learning rate: 0.0014908]
	Learning Rate: 0.00149081
	LOSS [training: 4.164557674499356 | validation: 4.432894037298721]
	TIME [epoch: 76.1 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.326750046997936		[learning rate: 0.00148]
	Learning Rate: 0.00148001
	LOSS [training: 4.326750046997936 | validation: 5.233311444212111]
	TIME [epoch: 76.1 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.435738692246888		[learning rate: 0.0014693]
	Learning Rate: 0.00146928
	LOSS [training: 4.435738692246888 | validation: 4.513731016257963]
	TIME [epoch: 76.1 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.231247792173523		[learning rate: 0.0014586]
	Learning Rate: 0.00145864
	LOSS [training: 4.231247792173523 | validation: 4.677073141685086]
	TIME [epoch: 76.1 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.251008703028665		[learning rate: 0.0014481]
	Learning Rate: 0.00144807
	LOSS [training: 4.251008703028665 | validation: 4.222660017546909]
	TIME [epoch: 76.1 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.190126912633538		[learning rate: 0.0014376]
	Learning Rate: 0.00143758
	LOSS [training: 4.190126912633538 | validation: 4.32290997772541]
	TIME [epoch: 76.1 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.5371391555839296		[learning rate: 0.0014272]
	Learning Rate: 0.00142716
	LOSS [training: 4.5371391555839296 | validation: 4.698951542846945]
	TIME [epoch: 76.1 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.287110345500287		[learning rate: 0.0014168]
	Learning Rate: 0.00141682
	LOSS [training: 4.287110345500287 | validation: 4.313012442849567]
	TIME [epoch: 76.1 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.09371996148603		[learning rate: 0.0014066]
	Learning Rate: 0.00140656
	LOSS [training: 4.09371996148603 | validation: 4.181500165332665]
	TIME [epoch: 76.1 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.260279732832307		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 4.260279732832307 | validation: 4.500611913382956]
	TIME [epoch: 76.1 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.685966201343483		[learning rate: 0.0013863]
	Learning Rate: 0.00138625
	LOSS [training: 4.685966201343483 | validation: 5.864288022912969]
	TIME [epoch: 76.1 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.264186535185033		[learning rate: 0.0013762]
	Learning Rate: 0.00137621
	LOSS [training: 5.264186535185033 | validation: 6.430138866529489]
	TIME [epoch: 76.1 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.917672214223484		[learning rate: 0.0013662]
	Learning Rate: 0.00136624
	LOSS [training: 4.917672214223484 | validation: 4.495821513480713]
	TIME [epoch: 76.1 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.131558346109206		[learning rate: 0.0013563]
	Learning Rate: 0.00135634
	LOSS [training: 4.131558346109206 | validation: 4.396833708634532]
	TIME [epoch: 76.1 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.559181921577648		[learning rate: 0.0013465]
	Learning Rate: 0.00134651
	LOSS [training: 4.559181921577648 | validation: 5.601080673701922]
	TIME [epoch: 76.1 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.917289367167775		[learning rate: 0.0013368]
	Learning Rate: 0.00133676
	LOSS [training: 4.917289367167775 | validation: 5.105987727420318]
	TIME [epoch: 76.2 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.629578992603663		[learning rate: 0.0013271]
	Learning Rate: 0.00132707
	LOSS [training: 4.629578992603663 | validation: 4.830295230929083]
	TIME [epoch: 76.2 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.349151553089935		[learning rate: 0.0013175]
	Learning Rate: 0.00131746
	LOSS [training: 4.349151553089935 | validation: 4.329409744281544]
	TIME [epoch: 76.2 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.343735757020157		[learning rate: 0.0013079]
	Learning Rate: 0.00130791
	LOSS [training: 4.343735757020157 | validation: 4.341557936644595]
	TIME [epoch: 76.1 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.1595934671384445		[learning rate: 0.0012984]
	Learning Rate: 0.00129844
	LOSS [training: 4.1595934671384445 | validation: 4.261917653098762]
	TIME [epoch: 76.2 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.071484365675348		[learning rate: 0.001289]
	Learning Rate: 0.00128903
	LOSS [training: 4.071484365675348 | validation: 3.8217327967632326]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_332.pth
	Model improved!!!
EPOCH 333/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.077163326925406		[learning rate: 0.0012797]
	Learning Rate: 0.00127969
	LOSS [training: 4.077163326925406 | validation: 3.751528846774806]
	TIME [epoch: 76.1 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_333.pth
	Model improved!!!
EPOCH 334/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.000227336439387		[learning rate: 0.0012704]
	Learning Rate: 0.00127042
	LOSS [training: 4.000227336439387 | validation: 3.88141671963037]
	TIME [epoch: 76.2 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.241809278578519		[learning rate: 0.0012612]
	Learning Rate: 0.00126122
	LOSS [training: 4.241809278578519 | validation: 4.311573239194043]
	TIME [epoch: 76.1 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.148746351145134		[learning rate: 0.0012521]
	Learning Rate: 0.00125208
	LOSS [training: 4.148746351145134 | validation: 3.8193099327273754]
	TIME [epoch: 76.1 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.130470015441237		[learning rate: 0.001243]
	Learning Rate: 0.00124301
	LOSS [training: 4.130470015441237 | validation: 4.491222389327559]
	TIME [epoch: 76.1 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.191505834731498		[learning rate: 0.001234]
	Learning Rate: 0.001234
	LOSS [training: 4.191505834731498 | validation: 3.903789987316317]
	TIME [epoch: 76.1 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.066658547605939		[learning rate: 0.0012251]
	Learning Rate: 0.00122506
	LOSS [training: 4.066658547605939 | validation: 4.353798417813458]
	TIME [epoch: 76.2 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.247050580496879		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 4.247050580496879 | validation: 3.9086103726292114]
	TIME [epoch: 76.2 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.977761719514584		[learning rate: 0.0012074]
	Learning Rate: 0.00120737
	LOSS [training: 3.977761719514584 | validation: 4.134595734304392]
	TIME [epoch: 76.2 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.9564066029516067		[learning rate: 0.0011986]
	Learning Rate: 0.00119863
	LOSS [training: 3.9564066029516067 | validation: 3.685258962177693]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_342.pth
	Model improved!!!
EPOCH 343/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.036177703917205		[learning rate: 0.0011899]
	Learning Rate: 0.00118994
	LOSS [training: 4.036177703917205 | validation: 4.953127376892114]
	TIME [epoch: 76.1 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.375171802921414		[learning rate: 0.0011813]
	Learning Rate: 0.00118132
	LOSS [training: 4.375171802921414 | validation: 5.095209557360241]
	TIME [epoch: 76.2 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.534529986832251		[learning rate: 0.0011728]
	Learning Rate: 0.00117276
	LOSS [training: 4.534529986832251 | validation: 5.0854876115923755]
	TIME [epoch: 76.2 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.635153053145314		[learning rate: 0.0011643]
	Learning Rate: 0.00116427
	LOSS [training: 4.635153053145314 | validation: 5.275192759167159]
	TIME [epoch: 76.1 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.513317764652594		[learning rate: 0.0011558]
	Learning Rate: 0.00115583
	LOSS [training: 4.513317764652594 | validation: 4.973184677096288]
	TIME [epoch: 76.1 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.684207167835682		[learning rate: 0.0011475]
	Learning Rate: 0.00114746
	LOSS [training: 4.684207167835682 | validation: 5.3439545616758455]
	TIME [epoch: 76.2 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.854134089661326		[learning rate: 0.0011391]
	Learning Rate: 0.00113914
	LOSS [training: 4.854134089661326 | validation: 5.103540587483497]
	TIME [epoch: 76.1 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.8450095184528355		[learning rate: 0.0011309]
	Learning Rate: 0.00113089
	LOSS [training: 4.8450095184528355 | validation: 5.074312077726866]
	TIME [epoch: 76.2 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.569711768455381		[learning rate: 0.0011227]
	Learning Rate: 0.0011227
	LOSS [training: 4.569711768455381 | validation: 4.957897404267511]
	TIME [epoch: 76.1 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.271155958555863		[learning rate: 0.0011146]
	Learning Rate: 0.00111456
	LOSS [training: 4.271155958555863 | validation: 4.895454874218027]
	TIME [epoch: 76.2 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.16718064268552		[learning rate: 0.0011065]
	Learning Rate: 0.00110649
	LOSS [training: 4.16718064268552 | validation: 3.672648250034904]
	TIME [epoch: 76.1 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_353.pth
	Model improved!!!
EPOCH 354/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.9861861977972226		[learning rate: 0.0010985]
	Learning Rate: 0.00109847
	LOSS [training: 3.9861861977972226 | validation: 3.985556422899622]
	TIME [epoch: 76.1 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.9396481002386268		[learning rate: 0.0010905]
	Learning Rate: 0.00109051
	LOSS [training: 3.9396481002386268 | validation: 3.8591978063040386]
	TIME [epoch: 76.1 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.9744166399321386		[learning rate: 0.0010826]
	Learning Rate: 0.00108261
	LOSS [training: 3.9744166399321386 | validation: 4.6814288716146155]
	TIME [epoch: 76.1 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.106490709327691		[learning rate: 0.0010748]
	Learning Rate: 0.00107477
	LOSS [training: 4.106490709327691 | validation: 4.352542505186962]
	TIME [epoch: 76.1 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.118026155070753		[learning rate: 0.001067]
	Learning Rate: 0.00106698
	LOSS [training: 4.118026155070753 | validation: 4.121193389898041]
	TIME [epoch: 76.1 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.119291344546603		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 4.119291344546603 | validation: 4.529484606786758]
	TIME [epoch: 76.1 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.25510427387996		[learning rate: 0.0010516]
	Learning Rate: 0.00105158
	LOSS [training: 4.25510427387996 | validation: 5.1308179667608185]
	TIME [epoch: 76.1 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.540878745118908		[learning rate: 0.001044]
	Learning Rate: 0.00104396
	LOSS [training: 4.540878745118908 | validation: 4.951575056967239]
	TIME [epoch: 76.1 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.4056061656943255		[learning rate: 0.0010364]
	Learning Rate: 0.0010364
	LOSS [training: 4.4056061656943255 | validation: 4.952078054080149]
	TIME [epoch: 76.1 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.5605168506145235		[learning rate: 0.0010289]
	Learning Rate: 0.00102889
	LOSS [training: 4.5605168506145235 | validation: 5.655316434340929]
	TIME [epoch: 76.1 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.6004873714985495		[learning rate: 0.0010214]
	Learning Rate: 0.00102143
	LOSS [training: 4.6004873714985495 | validation: 4.780042746566704]
	TIME [epoch: 76.1 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.125472487909009		[learning rate: 0.001014]
	Learning Rate: 0.00101403
	LOSS [training: 4.125472487909009 | validation: 3.8766049830659064]
	TIME [epoch: 76.1 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.927306537321349		[learning rate: 0.0010067]
	Learning Rate: 0.00100669
	LOSS [training: 3.927306537321349 | validation: 3.7343887943038006]
	TIME [epoch: 76.1 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.847182109925564		[learning rate: 0.00099939]
	Learning Rate: 0.000999394
	LOSS [training: 3.847182109925564 | validation: 3.6506204036279444]
	TIME [epoch: 76.1 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_367.pth
	Model improved!!!
EPOCH 368/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.8251597485175775		[learning rate: 0.00099215]
	Learning Rate: 0.000992154
	LOSS [training: 3.8251597485175775 | validation: 3.699844782271903]
	TIME [epoch: 76.2 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.9464861805344116		[learning rate: 0.00098497]
	Learning Rate: 0.000984966
	LOSS [training: 3.9464861805344116 | validation: 3.5789790982117755]
	TIME [epoch: 76.2 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_369.pth
	Model improved!!!
EPOCH 370/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.8550337461533797		[learning rate: 0.00097783]
	Learning Rate: 0.00097783
	LOSS [training: 3.8550337461533797 | validation: 3.8326551845111183]
	TIME [epoch: 76.2 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.8369746636445754		[learning rate: 0.00097075]
	Learning Rate: 0.000970745
	LOSS [training: 3.8369746636445754 | validation: 3.5627416430262504]
	TIME [epoch: 76.1 sec]
	Saving model to: out/model_training/model_phiq_1b_v3_20240503_110913/states/model_phiq_1b_v3_371.pth
	Model improved!!!
EPOCH 372/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.8465091788036814		[learning rate: 0.00096371]
	Learning Rate: 0.000963712
	LOSS [training: 3.8465091788036814 | validation: 3.6502112876631]
	TIME [epoch: 76.2 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.8449401860410317		[learning rate: 0.00095673]
	Learning Rate: 0.00095673
	LOSS [training: 3.8449401860410317 | validation: 3.7254065734737525]
	TIME [epoch: 76.2 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.8800226120040144		[learning rate: 0.0009498]
	Learning Rate: 0.000949799
	LOSS [training: 3.8800226120040144 | validation: 4.254002861689964]
	TIME [epoch: 76.1 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.8102338258520443		[learning rate: 0.00094292]
	Learning Rate: 0.000942918
	LOSS [training: 3.8102338258520443 | validation: 3.9089710249376406]
	TIME [epoch: 76.1 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.89958294497963		[learning rate: 0.00093609]
	Learning Rate: 0.000936086
	LOSS [training: 3.89958294497963 | validation: 3.6780753908740023]
	TIME [epoch: 76.2 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.778886362382248		[learning rate: 0.0009293]
	Learning Rate: 0.000929304
	LOSS [training: 3.778886362382248 | validation: 3.7097335389092114]
	TIME [epoch: 76.2 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.863613971127508		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 3.863613971127508 | validation: 3.695725791729224]
	TIME [epoch: 76.1 sec]
EPOCH 379/1000:
	Training over batches...
