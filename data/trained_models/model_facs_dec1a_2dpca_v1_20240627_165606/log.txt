Args:
Namespace(name='model_facs_dec1a_2dpca_v1', outdir='out/model_training/model_facs_dec1a_2dpca_v1', training_data='data/training_data/facs/pca/dec1/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs/pca/dec1/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=20, batch_size=100, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, ncells_sample=500, model_do_sample=False, dt=0.001, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 721377280

Training model...

Saving initial model state to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9142729438298152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9142729438298152 | validation: 0.6785662036141779]
	TIME [epoch: 116 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6866677547815391		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6866677547815391 | validation: 0.6428280963041896]
	TIME [epoch: 91.3 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6653613937062635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6653613937062635 | validation: 0.6177525961169207]
	TIME [epoch: 91.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6467484070159357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6467484070159357 | validation: 0.5916401050951088]
	TIME [epoch: 91.5 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5882798839607756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5882798839607756 | validation: 0.5584270570490237]
	TIME [epoch: 91.5 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.569636679923271		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.569636679923271 | validation: 0.5192485220154776]
	TIME [epoch: 91.6 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5323606378978938		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5323606378978938 | validation: 0.4803340545581257]
	TIME [epoch: 91.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5052618017630194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5052618017630194 | validation: 0.4493435793188988]
	TIME [epoch: 91.3 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.46738323312083424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46738323312083424 | validation: 0.39683253572564425]
	TIME [epoch: 91.3 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41988902821448626		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41988902821448626 | validation: 0.3400396649866272]
	TIME [epoch: 91.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3872719012403162		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3872719012403162 | validation: 0.2958955667854926]
	TIME [epoch: 91.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3419282534896081		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3419282534896081 | validation: 0.26441015208332697]
	TIME [epoch: 91.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30908717846157374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30908717846157374 | validation: 0.2429904439281379]
	TIME [epoch: 91.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27814199080796287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27814199080796287 | validation: 0.22795066132232375]
	TIME [epoch: 91.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.274375804526352		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.274375804526352 | validation: 0.211631447191942]
	TIME [epoch: 91.5 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24517005576226086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24517005576226086 | validation: 0.18977561773363785]
	TIME [epoch: 91.5 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23872912481050268		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23872912481050268 | validation: 0.1824890584685021]
	TIME [epoch: 91.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22290708335851012		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22290708335851012 | validation: 0.17679247468219322]
	TIME [epoch: 91.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.20253425714289924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20253425714289924 | validation: 0.15602655975174662]
	TIME [epoch: 91.3 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1882945410567103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1882945410567103 | validation: 0.19695146518984288]
	TIME [epoch: 91.3 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1791528539214338		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1791528539214338 | validation: 0.142195182384039]
	TIME [epoch: 91.3 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16277351561494452		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16277351561494452 | validation: 0.15187284537866952]
	TIME [epoch: 91.4 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1621040378456015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1621040378456015 | validation: 0.24306335222361172]
	TIME [epoch: 91.5 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16259530424838042		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16259530424838042 | validation: 0.12710410644911355]
	TIME [epoch: 91.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15677811176140763		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15677811176140763 | validation: 0.14061355221195135]
	TIME [epoch: 91.3 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16451267974265235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16451267974265235 | validation: 0.14175369844446534]
	TIME [epoch: 91.6 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15044092889204969		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15044092889204969 | validation: 0.12319072665180009]
	TIME [epoch: 91.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15563624688451047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15563624688451047 | validation: 0.13100321787959313]
	TIME [epoch: 91.6 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14519117743657914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14519117743657914 | validation: 0.12033886930254685]
	TIME [epoch: 91.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1408202210691917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1408202210691917 | validation: 0.24213400692884673]
	TIME [epoch: 91.4 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16709692176737984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16709692176737984 | validation: 0.11704312523165808]
	TIME [epoch: 91.5 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14049424772234914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14049424772234914 | validation: 0.1174113767390929]
	TIME [epoch: 91.5 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1409033922247484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1409033922247484 | validation: 0.14168563613955848]
	TIME [epoch: 91.5 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14603011137357433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14603011137357433 | validation: 0.1410420070772495]
	TIME [epoch: 91.4 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14172500312015754		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14172500312015754 | validation: 0.1171688607600967]
	TIME [epoch: 91.4 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13469205790485253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13469205790485253 | validation: 0.11188713564697217]
	TIME [epoch: 91.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1418281862286857		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1418281862286857 | validation: 0.11912427844501439]
	TIME [epoch: 91.5 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13722411535127652		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13722411535127652 | validation: 0.12974554129284535]
	TIME [epoch: 91.4 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13502229233219962		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13502229233219962 | validation: 0.11517848984666154]
	TIME [epoch: 91.4 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13111504437933766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13111504437933766 | validation: 0.11631173460644517]
	TIME [epoch: 91.5 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13610162712762638		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13610162712762638 | validation: 0.14922419098521839]
	TIME [epoch: 91.5 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12833365269254973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12833365269254973 | validation: 0.1133176430791821]
	TIME [epoch: 91.4 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13882596385011237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13882596385011237 | validation: 0.11241904883809788]
	TIME [epoch: 91.4 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12792658041787375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12792658041787375 | validation: 0.10909126678752465]
	TIME [epoch: 91.5 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12936871226468055		[learning rate: 0.0099823]
	Learning Rate: 0.0099823
	LOSS [training: 0.12936871226468055 | validation: 0.11040134443679939]
	TIME [epoch: 91.5 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13312363797592475		[learning rate: 0.0099426]
	Learning Rate: 0.0099426
	LOSS [training: 0.13312363797592475 | validation: 0.11226203960316235]
	TIME [epoch: 91.4 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12950525123272083		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.12950525123272083 | validation: 0.107285883496039]
	TIME [epoch: 91.5 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12823479464622467		[learning rate: 0.0098637]
	Learning Rate: 0.00986367
	LOSS [training: 0.12823479464622467 | validation: 0.1091259723619761]
	TIME [epoch: 91.5 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12694571250918898		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 0.12694571250918898 | validation: 0.1185419393172105]
	TIME [epoch: 91.5 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12359354625273035		[learning rate: 0.0097854]
	Learning Rate: 0.00978536
	LOSS [training: 0.12359354625273035 | validation: 0.11801014552859075]
	TIME [epoch: 91.5 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13316975454377358		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.13316975454377358 | validation: 0.1140941757575896]
	TIME [epoch: 91.6 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1259419147772652		[learning rate: 0.0097077]
	Learning Rate: 0.00970768
	LOSS [training: 0.1259419147772652 | validation: 0.10902389867833776]
	TIME [epoch: 91.6 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12318390267613223		[learning rate: 0.0096691]
	Learning Rate: 0.00966907
	LOSS [training: 0.12318390267613223 | validation: 0.1044103491333093]
	TIME [epoch: 91.5 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1258570566968917		[learning rate: 0.0096306]
	Learning Rate: 0.00963061
	LOSS [training: 0.1258570566968917 | validation: 0.12265288809035926]
	TIME [epoch: 91.5 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12429123355512466		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.12429123355512466 | validation: 0.11043778110489122]
	TIME [epoch: 91.3 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1212093354902451		[learning rate: 0.0095542]
	Learning Rate: 0.00955415
	LOSS [training: 0.1212093354902451 | validation: 0.10946477381136839]
	TIME [epoch: 91.3 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13208384529905934		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 0.13208384529905934 | validation: 0.11221400345669345]
	TIME [epoch: 91.3 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12637399581345077		[learning rate: 0.0094783]
	Learning Rate: 0.00947831
	LOSS [training: 0.12637399581345077 | validation: 0.10293505066654578]
	TIME [epoch: 91.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12189103536902995		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.12189103536902995 | validation: 0.10426171757567211]
	TIME [epoch: 91.5 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12165828334678497		[learning rate: 0.0094031]
	Learning Rate: 0.00940306
	LOSS [training: 0.12165828334678497 | validation: 0.12730570095627036]
	TIME [epoch: 91.5 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13467008300636352		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.13467008300636352 | validation: 0.10129211643999521]
	TIME [epoch: 91.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12300198449927918		[learning rate: 0.0093284]
	Learning Rate: 0.00932841
	LOSS [training: 0.12300198449927918 | validation: 0.10126484085113555]
	TIME [epoch: 91.3 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12009876913281688		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.12009876913281688 | validation: 0.10839585506776488]
	TIME [epoch: 91.3 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11917510457485503		[learning rate: 0.0092544]
	Learning Rate: 0.00925435
	LOSS [training: 0.11917510457485503 | validation: 0.11228718750141009]
	TIME [epoch: 91.3 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1192480455225141		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.1192480455225141 | validation: 0.11302558572069352]
	TIME [epoch: 91.3 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11785041658343347		[learning rate: 0.0091809]
	Learning Rate: 0.00918089
	LOSS [training: 0.11785041658343347 | validation: 0.10222979300557464]
	TIME [epoch: 91.3 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1214473979777894		[learning rate: 0.0091444]
	Learning Rate: 0.00914437
	LOSS [training: 0.1214473979777894 | validation: 0.10544472173709103]
	TIME [epoch: 91.3 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11897296609594783		[learning rate: 0.009108]
	Learning Rate: 0.009108
	LOSS [training: 0.11897296609594783 | validation: 0.125548349354943]
	TIME [epoch: 91.3 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12096330111318704		[learning rate: 0.0090718]
	Learning Rate: 0.00907178
	LOSS [training: 0.12096330111318704 | validation: 0.10442677491516214]
	TIME [epoch: 91.4 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12008259626995013		[learning rate: 0.0090357]
	Learning Rate: 0.00903569
	LOSS [training: 0.12008259626995013 | validation: 0.10061274540777956]
	TIME [epoch: 91.2 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11851929109692276		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.11851929109692276 | validation: 0.10586536219165452]
	TIME [epoch: 91.3 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12660437233657476		[learning rate: 0.008964]
	Learning Rate: 0.00896396
	LOSS [training: 0.12660437233657476 | validation: 0.09715601843487529]
	TIME [epoch: 91.3 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11916109937618195		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 0.11916109937618195 | validation: 0.105146961546972]
	TIME [epoch: 91.3 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11743125335539971		[learning rate: 0.0088928]
	Learning Rate: 0.0088928
	LOSS [training: 0.11743125335539971 | validation: 0.1057214412084754]
	TIME [epoch: 91.3 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12017695439312243		[learning rate: 0.0088574]
	Learning Rate: 0.00885743
	LOSS [training: 0.12017695439312243 | validation: 0.09590357027024621]
	TIME [epoch: 91.2 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11628388970318755		[learning rate: 0.0088222]
	Learning Rate: 0.0088222
	LOSS [training: 0.11628388970318755 | validation: 0.09767698723749532]
	TIME [epoch: 91.3 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.121206311550886		[learning rate: 0.0087871]
	Learning Rate: 0.00878711
	LOSS [training: 0.121206311550886 | validation: 0.09880641407981738]
	TIME [epoch: 91.4 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11953038949391755		[learning rate: 0.0087522]
	Learning Rate: 0.00875216
	LOSS [training: 0.11953038949391755 | validation: 0.09741590029164096]
	TIME [epoch: 91.2 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11461042745156741		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.11461042745156741 | validation: 0.09652376690313903]
	TIME [epoch: 91.3 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12068158845160824		[learning rate: 0.0086827]
	Learning Rate: 0.00868268
	LOSS [training: 0.12068158845160824 | validation: 0.09719577656091298]
	TIME [epoch: 91.3 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11541790396090436		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.11541790396090436 | validation: 0.09835532491781843]
	TIME [epoch: 91.3 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11813300853270164		[learning rate: 0.0086138]
	Learning Rate: 0.00861375
	LOSS [training: 0.11813300853270164 | validation: 0.10009351734151968]
	TIME [epoch: 91.3 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11970113380394093		[learning rate: 0.0085795]
	Learning Rate: 0.00857949
	LOSS [training: 0.11970113380394093 | validation: 0.10314905402042931]
	TIME [epoch: 91.3 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11803536835151689		[learning rate: 0.0085454]
	Learning Rate: 0.00854537
	LOSS [training: 0.11803536835151689 | validation: 0.11099469571029123]
	TIME [epoch: 91.3 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12385411260954293		[learning rate: 0.0085114]
	Learning Rate: 0.00851138
	LOSS [training: 0.12385411260954293 | validation: 0.09964076377049849]
	TIME [epoch: 91.3 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11788438377107428		[learning rate: 0.0084775]
	Learning Rate: 0.00847753
	LOSS [training: 0.11788438377107428 | validation: 0.1006992887043642]
	TIME [epoch: 91.2 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11830061606954471		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.11830061606954471 | validation: 0.09687302565651805]
	TIME [epoch: 91.4 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1154409537920329		[learning rate: 0.0084102]
	Learning Rate: 0.00841023
	LOSS [training: 0.1154409537920329 | validation: 0.09866245647012796]
	TIME [epoch: 91.2 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11348014317751914		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 0.11348014317751914 | validation: 0.09752129116956094]
	TIME [epoch: 91.2 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11446869682530084		[learning rate: 0.0083435]
	Learning Rate: 0.00834346
	LOSS [training: 0.11446869682530084 | validation: 0.10661295075063422]
	TIME [epoch: 91.3 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11793534724104274		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.11793534724104274 | validation: 0.10834733503202987]
	TIME [epoch: 91.3 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11471479421603238		[learning rate: 0.0082772]
	Learning Rate: 0.00827722
	LOSS [training: 0.11471479421603238 | validation: 0.11370718883266909]
	TIME [epoch: 91.3 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12286732617993475		[learning rate: 0.0082443]
	Learning Rate: 0.0082443
	LOSS [training: 0.12286732617993475 | validation: 0.1098746554104785]
	TIME [epoch: 91.4 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11224576093520315		[learning rate: 0.0082115]
	Learning Rate: 0.00821151
	LOSS [training: 0.11224576093520315 | validation: 0.0953941508811885]
	TIME [epoch: 91.3 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1153734063690475		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.1153734063690475 | validation: 0.10728472789580931]
	TIME [epoch: 91.4 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11837824857538995		[learning rate: 0.0081463]
	Learning Rate: 0.00814632
	LOSS [training: 0.11837824857538995 | validation: 0.10828904346348392]
	TIME [epoch: 91.4 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1135682309371638		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.1135682309371638 | validation: 0.11741647936521127]
	TIME [epoch: 91.4 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11810740342525278		[learning rate: 0.0080816]
	Learning Rate: 0.00808165
	LOSS [training: 0.11810740342525278 | validation: 0.09635191861869162]
	TIME [epoch: 91.4 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11647040723777913		[learning rate: 0.0080495]
	Learning Rate: 0.00804951
	LOSS [training: 0.11647040723777913 | validation: 0.09550825731058667]
	TIME [epoch: 91.5 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11353056169979427		[learning rate: 0.0080175]
	Learning Rate: 0.00801749
	LOSS [training: 0.11353056169979427 | validation: 0.09898720080101323]
	TIME [epoch: 91.4 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11094263699621165		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.11094263699621165 | validation: 0.09872980411225138]
	TIME [epoch: 91.4 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11418467298622074		[learning rate: 0.0079538]
	Learning Rate: 0.00795384
	LOSS [training: 0.11418467298622074 | validation: 0.09840368464403475]
	TIME [epoch: 91.2 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11782884121106749		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.11782884121106749 | validation: 0.09614953678882401]
	TIME [epoch: 91.3 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11469142606549856		[learning rate: 0.0078907]
	Learning Rate: 0.0078907
	LOSS [training: 0.11469142606549856 | validation: 0.09936833943596905]
	TIME [epoch: 91.3 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1154552239375713		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 0.1154552239375713 | validation: 0.11533853647750644]
	TIME [epoch: 91.3 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1168726576882025		[learning rate: 0.0078281]
	Learning Rate: 0.00782805
	LOSS [training: 0.1168726576882025 | validation: 0.09872098833796636]
	TIME [epoch: 91.3 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11534053116225922		[learning rate: 0.0077969]
	Learning Rate: 0.00779692
	LOSS [training: 0.11534053116225922 | validation: 0.10223591533258587]
	TIME [epoch: 91.3 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11580929455790473		[learning rate: 0.0077659]
	Learning Rate: 0.00776591
	LOSS [training: 0.11580929455790473 | validation: 0.09515638865609397]
	TIME [epoch: 91.3 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11506839746477654		[learning rate: 0.007735]
	Learning Rate: 0.00773502
	LOSS [training: 0.11506839746477654 | validation: 0.10133720818455134]
	TIME [epoch: 91.5 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11487224578772559		[learning rate: 0.0077043]
	Learning Rate: 0.00770426
	LOSS [training: 0.11487224578772559 | validation: 0.09689793166141272]
	TIME [epoch: 91.5 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11126170525181545		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.11126170525181545 | validation: 0.09559429394979596]
	TIME [epoch: 91.5 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1168160458710467		[learning rate: 0.0076431]
	Learning Rate: 0.00764309
	LOSS [training: 0.1168160458710467 | validation: 0.10501686966981619]
	TIME [epoch: 91.5 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11646398398928096		[learning rate: 0.0076127]
	Learning Rate: 0.00761269
	LOSS [training: 0.11646398398928096 | validation: 0.09624844441523396]
	TIME [epoch: 91.5 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11197767464820998		[learning rate: 0.0075824]
	Learning Rate: 0.00758242
	LOSS [training: 0.11197767464820998 | validation: 0.09415832510072333]
	TIME [epoch: 91.5 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_114.pth
	Model improved!!!
EPOCH 115/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11582236655780494		[learning rate: 0.0075523]
	Learning Rate: 0.00755226
	LOSS [training: 0.11582236655780494 | validation: 0.0945121049017907]
	TIME [epoch: 91.5 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11517877900678454		[learning rate: 0.0075222]
	Learning Rate: 0.00752222
	LOSS [training: 0.11517877900678454 | validation: 0.10052081407806004]
	TIME [epoch: 91.4 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11648520377657129		[learning rate: 0.0074923]
	Learning Rate: 0.0074923
	LOSS [training: 0.11648520377657129 | validation: 0.09968256150756835]
	TIME [epoch: 91.4 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11933971332597731		[learning rate: 0.0074625]
	Learning Rate: 0.0074625
	LOSS [training: 0.11933971332597731 | validation: 0.10268548620436138]
	TIME [epoch: 91.4 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1128138392386458		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.1128138392386458 | validation: 0.09782420405221307]
	TIME [epoch: 91.4 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11221847247859745		[learning rate: 0.0074033]
	Learning Rate: 0.00740326
	LOSS [training: 0.11221847247859745 | validation: 0.10827263959941671]
	TIME [epoch: 91.4 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11852535301285891		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.11852535301285891 | validation: 0.09400815584729214]
	TIME [epoch: 91.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11005050128388978		[learning rate: 0.0073445]
	Learning Rate: 0.00734449
	LOSS [training: 0.11005050128388978 | validation: 0.09584523098193984]
	TIME [epoch: 91.4 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11144767584329394		[learning rate: 0.0073153]
	Learning Rate: 0.00731528
	LOSS [training: 0.11144767584329394 | validation: 0.11310235738851518]
	TIME [epoch: 91.4 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12064896344157357		[learning rate: 0.0072862]
	Learning Rate: 0.00728618
	LOSS [training: 0.12064896344157357 | validation: 0.09411731471979887]
	TIME [epoch: 91.3 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11307092940286423		[learning rate: 0.0072572]
	Learning Rate: 0.0072572
	LOSS [training: 0.11307092940286423 | validation: 0.09885084739335821]
	TIME [epoch: 91.3 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11148886989355179		[learning rate: 0.0072283]
	Learning Rate: 0.00722834
	LOSS [training: 0.11148886989355179 | validation: 0.09340175092100797]
	TIME [epoch: 91.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_126.pth
	Model improved!!!
EPOCH 127/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11099220531600087		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.11099220531600087 | validation: 0.1004963692298505]
	TIME [epoch: 91.5 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11399069342651173		[learning rate: 0.007171]
	Learning Rate: 0.00717095
	LOSS [training: 0.11399069342651173 | validation: 0.09582746518169441]
	TIME [epoch: 91.5 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11778113202721799		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.11778113202721799 | validation: 0.09759600333577774]
	TIME [epoch: 91.4 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11155977814575585		[learning rate: 0.007114]
	Learning Rate: 0.00711403
	LOSS [training: 0.11155977814575585 | validation: 0.09321192700713715]
	TIME [epoch: 91.3 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_130.pth
	Model improved!!!
EPOCH 131/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11074486762233045		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.11074486762233045 | validation: 0.10302169266334985]
	TIME [epoch: 91.4 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11851211156926651		[learning rate: 0.0070575]
	Learning Rate: 0.00705755
	LOSS [training: 0.11851211156926651 | validation: 0.09984931772460412]
	TIME [epoch: 91.3 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11240955710419061		[learning rate: 0.0070295]
	Learning Rate: 0.00702948
	LOSS [training: 0.11240955710419061 | validation: 0.09882513817357172]
	TIME [epoch: 91.4 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11314099441928122		[learning rate: 0.0070015]
	Learning Rate: 0.00700152
	LOSS [training: 0.11314099441928122 | validation: 0.10243518596394716]
	TIME [epoch: 91.4 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1193985084503848		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.1193985084503848 | validation: 0.09477910903165779]
	TIME [epoch: 91.4 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11164076892575797		[learning rate: 0.0069459]
	Learning Rate: 0.00694594
	LOSS [training: 0.11164076892575797 | validation: 0.09704030450734945]
	TIME [epoch: 91.4 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10917376491343049		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 0.10917376491343049 | validation: 0.09608097885453878]
	TIME [epoch: 91.4 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11193150932176003		[learning rate: 0.0068908]
	Learning Rate: 0.00689079
	LOSS [training: 0.11193150932176003 | validation: 0.09909539740498095]
	TIME [epoch: 91.3 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11213417170979895		[learning rate: 0.0068634]
	Learning Rate: 0.00686339
	LOSS [training: 0.11213417170979895 | validation: 0.1035441275184387]
	TIME [epoch: 91.4 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1130531971763524		[learning rate: 0.0068361]
	Learning Rate: 0.00683609
	LOSS [training: 0.1130531971763524 | validation: 0.0955769664156059]
	TIME [epoch: 91.3 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11360375453822397		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.11360375453822397 | validation: 0.09257112128149206]
	TIME [epoch: 91.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1126270613368147		[learning rate: 0.0067818]
	Learning Rate: 0.00678182
	LOSS [training: 0.1126270613368147 | validation: 0.09327692398343576]
	TIME [epoch: 91.4 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11288533813602888		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.11288533813602888 | validation: 0.09656772879819109]
	TIME [epoch: 91.4 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11196047591947877		[learning rate: 0.006728]
	Learning Rate: 0.00672798
	LOSS [training: 0.11196047591947877 | validation: 0.1044912992508592]
	TIME [epoch: 91.5 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11514097712748514		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 0.11514097712748514 | validation: 0.10795388321463859]
	TIME [epoch: 91.4 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11304960848679199		[learning rate: 0.0066746]
	Learning Rate: 0.00667457
	LOSS [training: 0.11304960848679199 | validation: 0.0992161368784085]
	TIME [epoch: 91.4 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11186656797140289		[learning rate: 0.006648]
	Learning Rate: 0.00664802
	LOSS [training: 0.11186656797140289 | validation: 0.09516996296867503]
	TIME [epoch: 91.4 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11423961703792908		[learning rate: 0.0066216]
	Learning Rate: 0.00662158
	LOSS [training: 0.11423961703792908 | validation: 0.09277280915006847]
	TIME [epoch: 91.6 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10950213714184281		[learning rate: 0.0065952]
	Learning Rate: 0.00659524
	LOSS [training: 0.10950213714184281 | validation: 0.09889181740917541]
	TIME [epoch: 91.4 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11218707021956337		[learning rate: 0.006569]
	Learning Rate: 0.00656901
	LOSS [training: 0.11218707021956337 | validation: 0.0926978249545162]
	TIME [epoch: 91.5 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11295611570044145		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.11295611570044145 | validation: 0.09683889264780393]
	TIME [epoch: 91.4 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11423505953052267		[learning rate: 0.0065169]
	Learning Rate: 0.00651686
	LOSS [training: 0.11423505953052267 | validation: 0.09543286739563003]
	TIME [epoch: 91.4 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11084436332660956		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 0.11084436332660956 | validation: 0.09494852301310144]
	TIME [epoch: 91.5 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11191925089100864		[learning rate: 0.0064651]
	Learning Rate: 0.00646512
	LOSS [training: 0.11191925089100864 | validation: 0.09322153337233235]
	TIME [epoch: 91.5 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11089888215345345		[learning rate: 0.0064394]
	Learning Rate: 0.00643941
	LOSS [training: 0.11089888215345345 | validation: 0.09310748428983551]
	TIME [epoch: 91.5 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1102264801793158		[learning rate: 0.0064138]
	Learning Rate: 0.0064138
	LOSS [training: 0.1102264801793158 | validation: 0.0952955684433262]
	TIME [epoch: 91.4 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10824356635625293		[learning rate: 0.0063883]
	Learning Rate: 0.00638829
	LOSS [training: 0.10824356635625293 | validation: 0.10110913867690252]
	TIME [epoch: 91.5 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11241175370898995		[learning rate: 0.0063629]
	Learning Rate: 0.00636288
	LOSS [training: 0.11241175370898995 | validation: 0.09972146104622649]
	TIME [epoch: 91.6 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11189480817833908		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.11189480817833908 | validation: 0.09547202608070784]
	TIME [epoch: 91.4 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1089063821479328		[learning rate: 0.0063124]
	Learning Rate: 0.00631237
	LOSS [training: 0.1089063821479328 | validation: 0.09632909436088835]
	TIME [epoch: 91.5 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11103577239674371		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.11103577239674371 | validation: 0.10166686817577093]
	TIME [epoch: 91.5 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11060052489854479		[learning rate: 0.0062623]
	Learning Rate: 0.00626226
	LOSS [training: 0.11060052489854479 | validation: 0.097054171438442]
	TIME [epoch: 91.5 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11343023098286527		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.11343023098286527 | validation: 0.09641825448357641]
	TIME [epoch: 91.4 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11038289241194217		[learning rate: 0.0062125]
	Learning Rate: 0.00621254
	LOSS [training: 0.11038289241194217 | validation: 0.10263128669108527]
	TIME [epoch: 91.5 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11066560101045256		[learning rate: 0.0061878]
	Learning Rate: 0.00618783
	LOSS [training: 0.11066560101045256 | validation: 0.09979763680398113]
	TIME [epoch: 91.5 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11521422936495772		[learning rate: 0.0061632]
	Learning Rate: 0.00616322
	LOSS [training: 0.11521422936495772 | validation: 0.11004827730708411]
	TIME [epoch: 91.5 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11446461530756213		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.11446461530756213 | validation: 0.0990239080178103]
	TIME [epoch: 91.4 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11329758138470153		[learning rate: 0.0061143]
	Learning Rate: 0.00611429
	LOSS [training: 0.11329758138470153 | validation: 0.09022194950594124]
	TIME [epoch: 91.5 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_168.pth
	Model improved!!!
EPOCH 169/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10832077803981272		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 0.10832077803981272 | validation: 0.09493621158203755]
	TIME [epoch: 91.4 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11027564837580858		[learning rate: 0.0060658]
	Learning Rate: 0.00606575
	LOSS [training: 0.11027564837580858 | validation: 0.09839217588515291]
	TIME [epoch: 91.3 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11472493696219178		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.11472493696219178 | validation: 0.09271961022687428]
	TIME [epoch: 91.2 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11144094840942584		[learning rate: 0.0060176]
	Learning Rate: 0.0060176
	LOSS [training: 0.11144094840942584 | validation: 0.09178717636206547]
	TIME [epoch: 91.3 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10728978417770721		[learning rate: 0.0059937]
	Learning Rate: 0.00599366
	LOSS [training: 0.10728978417770721 | validation: 0.09344194713920609]
	TIME [epoch: 91.4 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11304606702337533		[learning rate: 0.0059698]
	Learning Rate: 0.00596982
	LOSS [training: 0.11304606702337533 | validation: 0.1012330572971341]
	TIME [epoch: 91.3 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11142826816067336		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.11142826816067336 | validation: 0.0944015111444705]
	TIME [epoch: 91.3 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11076721673249118		[learning rate: 0.0059224]
	Learning Rate: 0.00592243
	LOSS [training: 0.11076721673249118 | validation: 0.09376372213437531]
	TIME [epoch: 91.3 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11136590068761142		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 0.11136590068761142 | validation: 0.09330929732390456]
	TIME [epoch: 91.3 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10823424756800823		[learning rate: 0.0058754]
	Learning Rate: 0.00587541
	LOSS [training: 0.10823424756800823 | validation: 0.09910039225965854]
	TIME [epoch: 91.5 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1099495499471546		[learning rate: 0.005852]
	Learning Rate: 0.00585205
	LOSS [training: 0.1099495499471546 | validation: 0.0914922375934678]
	TIME [epoch: 91.5 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11237608017749919		[learning rate: 0.0058288]
	Learning Rate: 0.00582877
	LOSS [training: 0.11237608017749919 | validation: 0.09885949236424976]
	TIME [epoch: 91.3 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10829119355775539		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.10829119355775539 | validation: 0.09571537721202808]
	TIME [epoch: 91.4 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10909156938878235		[learning rate: 0.0057825]
	Learning Rate: 0.0057825
	LOSS [training: 0.10909156938878235 | validation: 0.09297801199336528]
	TIME [epoch: 91.3 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11073430824133462		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.11073430824133462 | validation: 0.09771778797640775]
	TIME [epoch: 91.4 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11011836032395236		[learning rate: 0.0057366]
	Learning Rate: 0.00573659
	LOSS [training: 0.11011836032395236 | validation: 0.0946278925079969]
	TIME [epoch: 91.4 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10976445205576778		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 0.10976445205576778 | validation: 0.10450937620543785]
	TIME [epoch: 91.3 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11174190267248707		[learning rate: 0.005691]
	Learning Rate: 0.00569105
	LOSS [training: 0.11174190267248707 | validation: 0.09316731302345957]
	TIME [epoch: 91.3 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.108514320826307		[learning rate: 0.0056684]
	Learning Rate: 0.00566841
	LOSS [training: 0.108514320826307 | validation: 0.1002526123314094]
	TIME [epoch: 91.3 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11063341683003464		[learning rate: 0.0056459]
	Learning Rate: 0.00564587
	LOSS [training: 0.11063341683003464 | validation: 0.09399069281259945]
	TIME [epoch: 91.3 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1102944160182456		[learning rate: 0.0056234]
	Learning Rate: 0.00562341
	LOSS [training: 0.1102944160182456 | validation: 0.09715370141118108]
	TIME [epoch: 91.3 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11059498089080236		[learning rate: 0.005601]
	Learning Rate: 0.00560105
	LOSS [training: 0.11059498089080236 | validation: 0.09488317560160507]
	TIME [epoch: 91.3 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11167813299076018		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.11167813299076018 | validation: 0.0928576925899421]
	TIME [epoch: 91.3 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10975033689278274		[learning rate: 0.0055566]
	Learning Rate: 0.00555658
	LOSS [training: 0.10975033689278274 | validation: 0.09435562925790564]
	TIME [epoch: 91.3 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10985389703351268		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.10985389703351268 | validation: 0.09585562864094424]
	TIME [epoch: 91.4 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11174285636689807		[learning rate: 0.0055125]
	Learning Rate: 0.00551247
	LOSS [training: 0.11174285636689807 | validation: 0.0920803919277698]
	TIME [epoch: 91.3 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10898394928971736		[learning rate: 0.0054905]
	Learning Rate: 0.00549054
	LOSS [training: 0.10898394928971736 | validation: 0.09191866369703483]
	TIME [epoch: 91.4 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11024926861683129		[learning rate: 0.0054687]
	Learning Rate: 0.00546871
	LOSS [training: 0.11024926861683129 | validation: 0.09329868824441444]
	TIME [epoch: 91.3 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1084185441650979		[learning rate: 0.005447]
	Learning Rate: 0.00544696
	LOSS [training: 0.1084185441650979 | validation: 0.09446486700156285]
	TIME [epoch: 91.3 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1115988325841722		[learning rate: 0.0054253]
	Learning Rate: 0.00542529
	LOSS [training: 0.1115988325841722 | validation: 0.09517012467253559]
	TIME [epoch: 91.3 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11016485298070619		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.11016485298070619 | validation: 0.09646557776096276]
	TIME [epoch: 91.4 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10808390666352521		[learning rate: 0.0053822]
	Learning Rate: 0.00538222
	LOSS [training: 0.10808390666352521 | validation: 0.09294674020815281]
	TIME [epoch: 91.3 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11232254328535429		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.11232254328535429 | validation: 0.09254447054337947]
	TIME [epoch: 91.6 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10695345443927629		[learning rate: 0.0053395]
	Learning Rate: 0.00533949
	LOSS [training: 0.10695345443927629 | validation: 0.09971732034751854]
	TIME [epoch: 91.5 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11043315894511517		[learning rate: 0.0053183]
	Learning Rate: 0.00531826
	LOSS [training: 0.11043315894511517 | validation: 0.09385743533662512]
	TIME [epoch: 91.6 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11205704483194436		[learning rate: 0.0052971]
	Learning Rate: 0.0052971
	LOSS [training: 0.11205704483194436 | validation: 0.09525946616934547]
	TIME [epoch: 91.6 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1105672646181061		[learning rate: 0.005276]
	Learning Rate: 0.00527604
	LOSS [training: 0.1105672646181061 | validation: 0.094651014409558]
	TIME [epoch: 91.5 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.110110858582131		[learning rate: 0.0052551]
	Learning Rate: 0.00525505
	LOSS [training: 0.110110858582131 | validation: 0.09758089978781168]
	TIME [epoch: 91.5 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11123665272712296		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.11123665272712296 | validation: 0.0921739758039981]
	TIME [epoch: 91.5 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11121610767604638		[learning rate: 0.0052133]
	Learning Rate: 0.00521333
	LOSS [training: 0.11121610767604638 | validation: 0.09222693449823766]
	TIME [epoch: 91.5 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11053648664507351		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 0.11053648664507351 | validation: 0.09176412203285539]
	TIME [epoch: 91.6 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1102864135327874		[learning rate: 0.0051719]
	Learning Rate: 0.00517194
	LOSS [training: 0.1102864135327874 | validation: 0.09352416239152553]
	TIME [epoch: 91.4 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10863698545422516		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.10863698545422516 | validation: 0.09505173621336956]
	TIME [epoch: 91.5 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10817603714785985		[learning rate: 0.0051309]
	Learning Rate: 0.00513089
	LOSS [training: 0.10817603714785985 | validation: 0.09589829160540975]
	TIME [epoch: 91.5 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10737078189993518		[learning rate: 0.0051105]
	Learning Rate: 0.00511048
	LOSS [training: 0.10737078189993518 | validation: 0.09393199888300122]
	TIME [epoch: 91.6 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1124728074251989		[learning rate: 0.0050902]
	Learning Rate: 0.00509015
	LOSS [training: 0.1124728074251989 | validation: 0.09520112896133662]
	TIME [epoch: 91.5 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10670013483019287		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.10670013483019287 | validation: 0.0931679485450592]
	TIME [epoch: 91.5 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10937115097690993		[learning rate: 0.0050497]
	Learning Rate: 0.00504974
	LOSS [training: 0.10937115097690993 | validation: 0.09448895148670003]
	TIME [epoch: 91.5 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11298089433456775		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 0.11298089433456775 | validation: 0.11710079449846196]
	TIME [epoch: 91.5 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11241366076530539		[learning rate: 0.0050097]
	Learning Rate: 0.00500965
	LOSS [training: 0.11241366076530539 | validation: 0.09395707919505396]
	TIME [epoch: 91.5 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10844564255104358		[learning rate: 0.0049897]
	Learning Rate: 0.00498973
	LOSS [training: 0.10844564255104358 | validation: 0.09524459894589021]
	TIME [epoch: 91.4 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10869881982758309		[learning rate: 0.0049699]
	Learning Rate: 0.00496988
	LOSS [training: 0.10869881982758309 | validation: 0.09191302749786243]
	TIME [epoch: 91.5 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10954640759510575		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.10954640759510575 | validation: 0.09220601984180916]
	TIME [epoch: 91.5 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10753161874298232		[learning rate: 0.0049304]
	Learning Rate: 0.00493043
	LOSS [training: 0.10753161874298232 | validation: 0.09294991691552083]
	TIME [epoch: 91.5 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10765351368027844		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.10765351368027844 | validation: 0.09423701460492809]
	TIME [epoch: 91.5 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10896576896444445		[learning rate: 0.0048913]
	Learning Rate: 0.00489129
	LOSS [training: 0.10896576896444445 | validation: 0.09230072895989143]
	TIME [epoch: 91.5 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10861148479938733		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.10861148479938733 | validation: 0.09357309214133429]
	TIME [epoch: 91.5 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10889032874103427		[learning rate: 0.0048525]
	Learning Rate: 0.00485245
	LOSS [training: 0.10889032874103427 | validation: 0.09387258802221884]
	TIME [epoch: 91.4 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10696167689146116		[learning rate: 0.0048332]
	Learning Rate: 0.00483316
	LOSS [training: 0.10696167689146116 | validation: 0.09281584409949137]
	TIME [epoch: 91.5 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10977498556935833		[learning rate: 0.0048139]
	Learning Rate: 0.00481393
	LOSS [training: 0.10977498556935833 | validation: 0.0982830344999027]
	TIME [epoch: 91.5 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11048096857129608		[learning rate: 0.0047948]
	Learning Rate: 0.00479479
	LOSS [training: 0.11048096857129608 | validation: 0.09396176209086256]
	TIME [epoch: 91.5 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10706577253658563		[learning rate: 0.0047757]
	Learning Rate: 0.00477572
	LOSS [training: 0.10706577253658563 | validation: 0.0941700254586289]
	TIME [epoch: 91.5 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10905932734498464		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.10905932734498464 | validation: 0.09770171680465942]
	TIME [epoch: 91.5 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11183304687716629		[learning rate: 0.0047378]
	Learning Rate: 0.0047378
	LOSS [training: 0.11183304687716629 | validation: 0.09414785721330467]
	TIME [epoch: 91.5 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1100229534854816		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 0.1100229534854816 | validation: 0.09232382525641322]
	TIME [epoch: 91.5 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10750537788340363		[learning rate: 0.0047002]
	Learning Rate: 0.00470019
	LOSS [training: 0.10750537788340363 | validation: 0.09602021433157716]
	TIME [epoch: 91.4 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10891210697173408		[learning rate: 0.0046815]
	Learning Rate: 0.0046815
	LOSS [training: 0.10891210697173408 | validation: 0.09261511566393162]
	TIME [epoch: 91.5 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10784590117905665		[learning rate: 0.0046629]
	Learning Rate: 0.00466288
	LOSS [training: 0.10784590117905665 | validation: 0.09369621584330753]
	TIME [epoch: 91.5 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10971633870885206		[learning rate: 0.0046443]
	Learning Rate: 0.00464433
	LOSS [training: 0.10971633870885206 | validation: 0.09231424262205963]
	TIME [epoch: 91.5 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10878830280988822		[learning rate: 0.0046259]
	Learning Rate: 0.00462586
	LOSS [training: 0.10878830280988822 | validation: 0.09459273203595894]
	TIME [epoch: 91.5 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10887627413194857		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.10887627413194857 | validation: 0.09202655909837652]
	TIME [epoch: 91.5 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1076731867555116		[learning rate: 0.0045891]
	Learning Rate: 0.00458913
	LOSS [training: 0.1076731867555116 | validation: 0.09407173069452787]
	TIME [epoch: 91.4 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1088892689556013		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.1088892689556013 | validation: 0.10319424740389585]
	TIME [epoch: 91.5 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10847801531409959		[learning rate: 0.0045527]
	Learning Rate: 0.0045527
	LOSS [training: 0.10847801531409959 | validation: 0.09366881079613978]
	TIME [epoch: 91.4 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1073614599382145		[learning rate: 0.0045346]
	Learning Rate: 0.00453459
	LOSS [training: 0.1073614599382145 | validation: 0.09275810005899163]
	TIME [epoch: 91.5 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1067887974903225		[learning rate: 0.0045166]
	Learning Rate: 0.00451656
	LOSS [training: 0.1067887974903225 | validation: 0.09352272128638162]
	TIME [epoch: 91.5 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10780962980205717		[learning rate: 0.0044986]
	Learning Rate: 0.0044986
	LOSS [training: 0.10780962980205717 | validation: 0.09248258725488386]
	TIME [epoch: 91.4 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10982321336345802		[learning rate: 0.0044807]
	Learning Rate: 0.0044807
	LOSS [training: 0.10982321336345802 | validation: 0.09395157356853542]
	TIME [epoch: 91.5 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10809470871926724		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.10809470871926724 | validation: 0.09221965911877003]
	TIME [epoch: 91.5 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10777827121705935		[learning rate: 0.0044451]
	Learning Rate: 0.00444513
	LOSS [training: 0.10777827121705935 | validation: 0.09328366774086784]
	TIME [epoch: 91.5 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10852200934945674		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 0.10852200934945674 | validation: 0.09117813752521546]
	TIME [epoch: 91.5 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10705390250041694		[learning rate: 0.0044098]
	Learning Rate: 0.00440984
	LOSS [training: 0.10705390250041694 | validation: 0.09323696492040764]
	TIME [epoch: 91.5 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11017031986533052		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.11017031986533052 | validation: 0.09240425041078368]
	TIME [epoch: 91.6 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10932472210006543		[learning rate: 0.0043748]
	Learning Rate: 0.00437483
	LOSS [training: 0.10932472210006543 | validation: 0.0952897020317202]
	TIME [epoch: 91.5 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10958135524942568		[learning rate: 0.0043574]
	Learning Rate: 0.00435743
	LOSS [training: 0.10958135524942568 | validation: 0.09179451467649039]
	TIME [epoch: 91.5 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10751945032793819		[learning rate: 0.0043401]
	Learning Rate: 0.0043401
	LOSS [training: 0.10751945032793819 | validation: 0.09860410711157622]
	TIME [epoch: 91.5 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10735521810281984		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.10735521810281984 | validation: 0.09618222849461493]
	TIME [epoch: 91.4 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10724266415381727		[learning rate: 0.0043056]
	Learning Rate: 0.00430565
	LOSS [training: 0.10724266415381727 | validation: 0.09474528862996892]
	TIME [epoch: 91.4 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10858478153492707		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.10858478153492707 | validation: 0.10107423490034426]
	TIME [epoch: 91.5 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11180531292365921		[learning rate: 0.0042715]
	Learning Rate: 0.00427147
	LOSS [training: 0.11180531292365921 | validation: 0.09238547869632441]
	TIME [epoch: 91.5 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10616963779619076		[learning rate: 0.0042545]
	Learning Rate: 0.00425448
	LOSS [training: 0.10616963779619076 | validation: 0.09564271967813186]
	TIME [epoch: 91.4 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10999385235771664		[learning rate: 0.0042376]
	Learning Rate: 0.00423756
	LOSS [training: 0.10999385235771664 | validation: 0.09189074894759677]
	TIME [epoch: 91.4 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10462449777124512		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.10462449777124512 | validation: 0.09319041083388127]
	TIME [epoch: 91.5 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10969327536747504		[learning rate: 0.0042039]
	Learning Rate: 0.00420391
	LOSS [training: 0.10969327536747504 | validation: 0.09594593018985957]
	TIME [epoch: 91.6 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10835579926981026		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.10835579926981026 | validation: 0.09152341815958336]
	TIME [epoch: 91.4 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10780287180141647		[learning rate: 0.0041705]
	Learning Rate: 0.00417054
	LOSS [training: 0.10780287180141647 | validation: 0.09623560254206191]
	TIME [epoch: 91.5 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10958630685516708		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 0.10958630685516708 | validation: 0.09220202518203587]
	TIME [epoch: 91.4 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10627678358198916		[learning rate: 0.0041374]
	Learning Rate: 0.00413743
	LOSS [training: 0.10627678358198916 | validation: 0.09302611536622625]
	TIME [epoch: 91.5 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10954616414544237		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.10954616414544237 | validation: 0.0940382275740745]
	TIME [epoch: 91.5 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10838581517800466		[learning rate: 0.0041046]
	Learning Rate: 0.00410458
	LOSS [training: 0.10838581517800466 | validation: 0.09368446593448936]
	TIME [epoch: 91.5 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10759617459309224		[learning rate: 0.0040883]
	Learning Rate: 0.00408826
	LOSS [training: 0.10759617459309224 | validation: 0.09299370979512749]
	TIME [epoch: 91.6 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10579404163668246		[learning rate: 0.004072]
	Learning Rate: 0.004072
	LOSS [training: 0.10579404163668246 | validation: 0.09003854818424815]
	TIME [epoch: 91.6 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_270.pth
	Model improved!!!
EPOCH 271/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10697280554856084		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.10697280554856084 | validation: 0.09422963558804887]
	TIME [epoch: 91.4 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10719506795059244		[learning rate: 0.0040397]
	Learning Rate: 0.00403967
	LOSS [training: 0.10719506795059244 | validation: 0.099456507978526]
	TIME [epoch: 91.4 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11013560085891912		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 0.11013560085891912 | validation: 0.09460958694779532]
	TIME [epoch: 91.4 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1053796622764776		[learning rate: 0.0040076]
	Learning Rate: 0.0040076
	LOSS [training: 0.1053796622764776 | validation: 0.09172525877989507]
	TIME [epoch: 91.5 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10962150633064316		[learning rate: 0.0039917]
	Learning Rate: 0.00399166
	LOSS [training: 0.10962150633064316 | validation: 0.09223422531429111]
	TIME [epoch: 91.4 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10685659240009297		[learning rate: 0.0039758]
	Learning Rate: 0.00397579
	LOSS [training: 0.10685659240009297 | validation: 0.09167441466228768]
	TIME [epoch: 91.4 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10996106039528329		[learning rate: 0.00396]
	Learning Rate: 0.00395997
	LOSS [training: 0.10996106039528329 | validation: 0.09410747546054381]
	TIME [epoch: 91.4 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10762286493864932		[learning rate: 0.0039442]
	Learning Rate: 0.00394422
	LOSS [training: 0.10762286493864932 | validation: 0.09160433174687857]
	TIME [epoch: 91.5 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10645675913234078		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.10645675913234078 | validation: 0.09221194343128238]
	TIME [epoch: 91.4 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10805885887124332		[learning rate: 0.0039129]
	Learning Rate: 0.00391291
	LOSS [training: 0.10805885887124332 | validation: 0.09148036684857379]
	TIME [epoch: 91.4 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1062732697074285		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.1062732697074285 | validation: 0.0953335578434706]
	TIME [epoch: 91.5 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10681084617350481		[learning rate: 0.0038818]
	Learning Rate: 0.00388185
	LOSS [training: 0.10681084617350481 | validation: 0.09398483968388316]
	TIME [epoch: 91.4 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11049154629748728		[learning rate: 0.0038664]
	Learning Rate: 0.00386641
	LOSS [training: 0.11049154629748728 | validation: 0.09061730535853597]
	TIME [epoch: 91.4 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10630532380562044		[learning rate: 0.003851]
	Learning Rate: 0.00385103
	LOSS [training: 0.10630532380562044 | validation: 0.09477309636134484]
	TIME [epoch: 91.4 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.108022960177164		[learning rate: 0.0038357]
	Learning Rate: 0.00383571
	LOSS [training: 0.108022960177164 | validation: 0.09165872366617468]
	TIME [epoch: 91.4 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10860823500352303		[learning rate: 0.0038205]
	Learning Rate: 0.00382046
	LOSS [training: 0.10860823500352303 | validation: 0.09302175736112642]
	TIME [epoch: 91.4 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10739482902442234		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.10739482902442234 | validation: 0.09426880002802637]
	TIME [epoch: 91.5 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10835433699086287		[learning rate: 0.0037901]
	Learning Rate: 0.00379013
	LOSS [training: 0.10835433699086287 | validation: 0.09125659822932283]
	TIME [epoch: 91.4 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10878084647769995		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.10878084647769995 | validation: 0.09117467847099779]
	TIME [epoch: 91.5 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10548077245933679		[learning rate: 0.00376]
	Learning Rate: 0.00376004
	LOSS [training: 0.10548077245933679 | validation: 0.0934690989929095]
	TIME [epoch: 91.4 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10778345113548138		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.10778345113548138 | validation: 0.09477413425970342]
	TIME [epoch: 91.5 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1080115716542816		[learning rate: 0.0037302]
	Learning Rate: 0.00373019
	LOSS [training: 0.1080115716542816 | validation: 0.09224159970248062]
	TIME [epoch: 91.6 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10563417830892968		[learning rate: 0.0037154]
	Learning Rate: 0.00371535
	LOSS [training: 0.10563417830892968 | validation: 0.09061836713439114]
	TIME [epoch: 91.6 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10817946666759293		[learning rate: 0.0037006]
	Learning Rate: 0.00370058
	LOSS [training: 0.10817946666759293 | validation: 0.10426654104698967]
	TIME [epoch: 91.8 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10803082082963252		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.10803082082963252 | validation: 0.09467118267296827]
	TIME [epoch: 91.7 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10779277918380832		[learning rate: 0.0036712]
	Learning Rate: 0.0036712
	LOSS [training: 0.10779277918380832 | validation: 0.10117946806376936]
	TIME [epoch: 91.8 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10974388513259356		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 0.10974388513259356 | validation: 0.09181442876661608]
	TIME [epoch: 91.7 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10436011125016055		[learning rate: 0.0036421]
	Learning Rate: 0.00364205
	LOSS [training: 0.10436011125016055 | validation: 0.091504085363288]
	TIME [epoch: 91.7 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10904442946224918		[learning rate: 0.0036276]
	Learning Rate: 0.00362757
	LOSS [training: 0.10904442946224918 | validation: 0.09612643982219993]
	TIME [epoch: 91.7 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10654231577887478		[learning rate: 0.0036131]
	Learning Rate: 0.00361314
	LOSS [training: 0.10654231577887478 | validation: 0.09236554176794305]
	TIME [epoch: 91.8 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10671676793894612		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.10671676793894612 | validation: 0.09331405562430123]
	TIME [epoch: 91.7 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10863204010092048		[learning rate: 0.0035845]
	Learning Rate: 0.00358445
	LOSS [training: 0.10863204010092048 | validation: 0.09351421064899812]
	TIME [epoch: 91.8 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10737612661354173		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.10737612661354173 | validation: 0.09452548656911082]
	TIME [epoch: 91.7 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10893091391530124		[learning rate: 0.003556]
	Learning Rate: 0.003556
	LOSS [training: 0.10893091391530124 | validation: 0.09276298447760256]
	TIME [epoch: 91.6 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1046407004671002		[learning rate: 0.0035419]
	Learning Rate: 0.00354185
	LOSS [training: 0.1046407004671002 | validation: 0.09326641855543857]
	TIME [epoch: 91.7 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1060490444121764		[learning rate: 0.0035278]
	Learning Rate: 0.00352777
	LOSS [training: 0.1060490444121764 | validation: 0.089261229360125]
	TIME [epoch: 91.7 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_165606/states/model_facs_dec1a_2dpca_v1_306.pth
	Model improved!!!
EPOCH 307/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10878809600462906		[learning rate: 0.0035137]
	Learning Rate: 0.00351374
	LOSS [training: 0.10878809600462906 | validation: 0.0937250047801337]
	TIME [epoch: 91.6 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10656084941175871		[learning rate: 0.0034998]
	Learning Rate: 0.00349976
	LOSS [training: 0.10656084941175871 | validation: 0.09222967153493614]
	TIME [epoch: 91.6 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10718678604025994		[learning rate: 0.0034858]
	Learning Rate: 0.00348584
	LOSS [training: 0.10718678604025994 | validation: 0.09306160470844864]
	TIME [epoch: 91.7 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10459541166441597		[learning rate: 0.003472]
	Learning Rate: 0.00347198
	LOSS [training: 0.10459541166441597 | validation: 0.0913623452852996]
	TIME [epoch: 91.5 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10609894628301195		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.10609894628301195 | validation: 0.09315387279385905]
	TIME [epoch: 91.6 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10782877745967473		[learning rate: 0.0034444]
	Learning Rate: 0.00344441
	LOSS [training: 0.10782877745967473 | validation: 0.09354173733953783]
	TIME [epoch: 91.7 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10870299286958268		[learning rate: 0.0034307]
	Learning Rate: 0.00343071
	LOSS [training: 0.10870299286958268 | validation: 0.09803641951239417]
	TIME [epoch: 91.5 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11122643403137793		[learning rate: 0.0034171]
	Learning Rate: 0.00341707
	LOSS [training: 0.11122643403137793 | validation: 0.09396949931093694]
	TIME [epoch: 91.6 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10890370785525536		[learning rate: 0.0034035]
	Learning Rate: 0.00340348
	LOSS [training: 0.10890370785525536 | validation: 0.0930770430016167]
	TIME [epoch: 91.6 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10695822163238139		[learning rate: 0.0033899]
	Learning Rate: 0.00338994
	LOSS [training: 0.10695822163238139 | validation: 0.10096607670260149]
	TIME [epoch: 91.5 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10843664562408034		[learning rate: 0.0033765]
	Learning Rate: 0.00337646
	LOSS [training: 0.10843664562408034 | validation: 0.09473367525257596]
	TIME [epoch: 91.8 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10687633374866246		[learning rate: 0.003363]
	Learning Rate: 0.00336303
	LOSS [training: 0.10687633374866246 | validation: 0.09486275539180114]
	TIME [epoch: 91.9 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10860054788661888		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.10860054788661888 | validation: 0.09161454851641741]
	TIME [epoch: 91.8 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1075913498035102		[learning rate: 0.0033363]
	Learning Rate: 0.00333633
	LOSS [training: 0.1075913498035102 | validation: 0.09374915590756014]
	TIME [epoch: 91.8 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10835963182483264		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.10835963182483264 | validation: 0.0992450463304701]
	TIME [epoch: 91.7 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10901621997148306		[learning rate: 0.0033098]
	Learning Rate: 0.00330985
	LOSS [training: 0.10901621997148306 | validation: 0.08940945421796688]
	TIME [epoch: 91.7 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10825534031340772		[learning rate: 0.0032967]
	Learning Rate: 0.00329668
	LOSS [training: 0.10825534031340772 | validation: 0.09336865229057827]
	TIME [epoch: 91.6 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10974370882277605		[learning rate: 0.0032836]
	Learning Rate: 0.00328357
	LOSS [training: 0.10974370882277605 | validation: 0.0958091476149604]
	TIME [epoch: 91.5 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10584577710267701		[learning rate: 0.0032705]
	Learning Rate: 0.00327051
	LOSS [training: 0.10584577710267701 | validation: 0.09373158521576688]
	TIME [epoch: 91.7 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10429851810978377		[learning rate: 0.0032575]
	Learning Rate: 0.0032575
	LOSS [training: 0.10429851810978377 | validation: 0.09197542471677762]
	TIME [epoch: 91.5 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10734692061577612		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.10734692061577612 | validation: 0.0914825329979535]
	TIME [epoch: 91.6 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10590522181832698		[learning rate: 0.0032316]
	Learning Rate: 0.00323164
	LOSS [training: 0.10590522181832698 | validation: 0.09466486856256925]
	TIME [epoch: 91.6 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10809280806325214		[learning rate: 0.0032188]
	Learning Rate: 0.00321879
	LOSS [training: 0.10809280806325214 | validation: 0.09325087755545182]
	TIME [epoch: 91.6 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10652169325690163		[learning rate: 0.003206]
	Learning Rate: 0.00320599
	LOSS [training: 0.10652169325690163 | validation: 0.09148875863959098]
	TIME [epoch: 91.6 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10782298318192407		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.10782298318192407 | validation: 0.09491895778104897]
	TIME [epoch: 91.7 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10903545224978016		[learning rate: 0.0031805]
	Learning Rate: 0.00318053
	LOSS [training: 0.10903545224978016 | validation: 0.09070878123333079]
	TIME [epoch: 91.6 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10525668649704989		[learning rate: 0.0031679]
	Learning Rate: 0.00316788
	LOSS [training: 0.10525668649704989 | validation: 0.09250673271789775]
	TIME [epoch: 91.6 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10784989186434249		[learning rate: 0.0031553]
	Learning Rate: 0.00315528
	LOSS [training: 0.10784989186434249 | validation: 0.09236012081465557]
	TIME [epoch: 91.4 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10530836148132178		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.10530836148132178 | validation: 0.09255432863773573]
	TIME [epoch: 91.6 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10732092226565168		[learning rate: 0.0031302]
	Learning Rate: 0.00313023
	LOSS [training: 0.10732092226565168 | validation: 0.09385123099236495]
	TIME [epoch: 91.5 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1074750017715574		[learning rate: 0.0031178]
	Learning Rate: 0.00311779
	LOSS [training: 0.1074750017715574 | validation: 0.09452344682242597]
	TIME [epoch: 91.6 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10896373871337169		[learning rate: 0.0031054]
	Learning Rate: 0.00310538
	LOSS [training: 0.10896373871337169 | validation: 0.09300612181444426]
	TIME [epoch: 91.6 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1064900364686666		[learning rate: 0.003093]
	Learning Rate: 0.00309303
	LOSS [training: 0.1064900364686666 | validation: 0.09347032986952462]
	TIME [epoch: 91.5 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10667156465967148		[learning rate: 0.0030807]
	Learning Rate: 0.00308073
	LOSS [training: 0.10667156465967148 | validation: 0.09262256584969983]
	TIME [epoch: 91.6 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1086065108471394		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.1086065108471394 | validation: 0.09208396580117936]
	TIME [epoch: 91.6 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10626592390577616		[learning rate: 0.0030563]
	Learning Rate: 0.00305627
	LOSS [training: 0.10626592390577616 | validation: 0.09095326732662672]
	TIME [epoch: 91.6 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10619976059074579		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.10619976059074579 | validation: 0.09223241055677604]
	TIME [epoch: 91.6 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10629302153533743		[learning rate: 0.003032]
	Learning Rate: 0.00303201
	LOSS [training: 0.10629302153533743 | validation: 0.09098098023328308]
	TIME [epoch: 91.4 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10562406566744123		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.10562406566744123 | validation: 0.09383166526825445]
	TIME [epoch: 91.6 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10648813571861714		[learning rate: 0.0030079]
	Learning Rate: 0.00300794
	LOSS [training: 0.10648813571861714 | validation: 0.09234660356165354]
	TIME [epoch: 91.6 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10906016078493114		[learning rate: 0.002996]
	Learning Rate: 0.00299598
	LOSS [training: 0.10906016078493114 | validation: 0.09292658904278715]
	TIME [epoch: 91.6 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10549850775967871		[learning rate: 0.0029841]
	Learning Rate: 0.00298406
	LOSS [training: 0.10549850775967871 | validation: 0.09306753793220687]
	TIME [epoch: 91.6 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10666476810483938		[learning rate: 0.0029722]
	Learning Rate: 0.00297219
	LOSS [training: 0.10666476810483938 | validation: 0.09139590347016585]
	TIME [epoch: 91.5 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10570921300302935		[learning rate: 0.0029604]
	Learning Rate: 0.00296037
	LOSS [training: 0.10570921300302935 | validation: 0.09208275096220214]
	TIME [epoch: 91.5 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1080629486014225		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.1080629486014225 | validation: 0.09369409577340151]
	TIME [epoch: 91.6 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10721759856338325		[learning rate: 0.0029369]
	Learning Rate: 0.00293687
	LOSS [training: 0.10721759856338325 | validation: 0.09149289662598271]
	TIME [epoch: 91.4 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10559982837383		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.10559982837383 | validation: 0.09612226561017785]
	TIME [epoch: 91.4 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1079632385889142		[learning rate: 0.0029136]
	Learning Rate: 0.00291355
	LOSS [training: 0.1079632385889142 | validation: 0.09159166636064905]
	TIME [epoch: 91.4 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10658093140704922		[learning rate: 0.002902]
	Learning Rate: 0.00290197
	LOSS [training: 0.10658093140704922 | validation: 0.0960469469094497]
	TIME [epoch: 91.6 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10597734973108354		[learning rate: 0.0028904]
	Learning Rate: 0.00289042
	LOSS [training: 0.10597734973108354 | validation: 0.09107645946744039]
	TIME [epoch: 91.5 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10528506780982966		[learning rate: 0.0028789]
	Learning Rate: 0.00287893
	LOSS [training: 0.10528506780982966 | validation: 0.09113056889599762]
	TIME [epoch: 91.4 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10624327445883172		[learning rate: 0.0028675]
	Learning Rate: 0.00286748
	LOSS [training: 0.10624327445883172 | validation: 0.0920046631457499]
	TIME [epoch: 91.4 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1047896181258837		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.1047896181258837 | validation: 0.0919677304235114]
	TIME [epoch: 91.4 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10450324059968608		[learning rate: 0.0028447]
	Learning Rate: 0.00284471
	LOSS [training: 0.10450324059968608 | validation: 0.09284989536583167]
	TIME [epoch: 91.5 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10642935568950661		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.10642935568950661 | validation: 0.0916799873443244]
	TIME [epoch: 91.6 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10600135679813578		[learning rate: 0.0028221]
	Learning Rate: 0.00282213
	LOSS [training: 0.10600135679813578 | validation: 0.0941687943049178]
	TIME [epoch: 91.5 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10604402290433296		[learning rate: 0.0028109]
	Learning Rate: 0.00281091
	LOSS [training: 0.10604402290433296 | validation: 0.0924099713986692]
	TIME [epoch: 91.5 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1056277243949908		[learning rate: 0.0027997]
	Learning Rate: 0.00279973
	LOSS [training: 0.1056277243949908 | validation: 0.08997909593007399]
	TIME [epoch: 91.4 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10749023426624878		[learning rate: 0.0027886]
	Learning Rate: 0.00278859
	LOSS [training: 0.10749023426624878 | validation: 0.09218102501674577]
	TIME [epoch: 91.4 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10664441443018255		[learning rate: 0.0027775]
	Learning Rate: 0.0027775
	LOSS [training: 0.10664441443018255 | validation: 0.08981657697559743]
	TIME [epoch: 91.4 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10622949533168209		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.10622949533168209 | validation: 0.09196306503618107]
	TIME [epoch: 91.5 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10793960843055737		[learning rate: 0.0027554]
	Learning Rate: 0.00275545
	LOSS [training: 0.10793960843055737 | validation: 0.09189398844056056]
	TIME [epoch: 91.6 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10684294603021417		[learning rate: 0.0027445]
	Learning Rate: 0.00274449
	LOSS [training: 0.10684294603021417 | validation: 0.09062543629664933]
	TIME [epoch: 91.4 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1071376262780022		[learning rate: 0.0027336]
	Learning Rate: 0.00273357
	LOSS [training: 0.1071376262780022 | validation: 0.09128556542928183]
	TIME [epoch: 91.5 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10523722789971786		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.10523722789971786 | validation: 0.09213084402082286]
	TIME [epoch: 91.4 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10485199796904073		[learning rate: 0.0027119]
	Learning Rate: 0.00271187
	LOSS [training: 0.10485199796904073 | validation: 0.09248686321290092]
	TIME [epoch: 91.6 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10766564963429687		[learning rate: 0.0027011]
	Learning Rate: 0.00270109
	LOSS [training: 0.10766564963429687 | validation: 0.09326247752537589]
	TIME [epoch: 91.5 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10369273838459409		[learning rate: 0.0026903]
	Learning Rate: 0.00269034
	LOSS [training: 0.10369273838459409 | validation: 0.09233742449198278]
	TIME [epoch: 91.4 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10507545990299955		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.10507545990299955 | validation: 0.09237182189843007]
	TIME [epoch: 91.7 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10420400339808678		[learning rate: 0.002669]
	Learning Rate: 0.00266899
	LOSS [training: 0.10420400339808678 | validation: 0.09225504548583374]
	TIME [epoch: 91.5 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10580555731272076		[learning rate: 0.0026584]
	Learning Rate: 0.00265837
	LOSS [training: 0.10580555731272076 | validation: 0.09312890863039625]
	TIME [epoch: 91.4 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10582657830108329		[learning rate: 0.0026478]
	Learning Rate: 0.0026478
	LOSS [training: 0.10582657830108329 | validation: 0.09146293224999534]
	TIME [epoch: 91.4 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10739599920286763		[learning rate: 0.0026373]
	Learning Rate: 0.00263727
	LOSS [training: 0.10739599920286763 | validation: 0.09240219304281252]
	TIME [epoch: 91.5 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10430352860688345		[learning rate: 0.0026268]
	Learning Rate: 0.00262678
	LOSS [training: 0.10430352860688345 | validation: 0.09486834355363064]
	TIME [epoch: 91.6 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10466306874208081		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.10466306874208081 | validation: 0.09325142796137344]
	TIME [epoch: 91.4 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10728734422874699		[learning rate: 0.0026059]
	Learning Rate: 0.00260592
	LOSS [training: 0.10728734422874699 | validation: 0.09217432533381059]
	TIME [epoch: 91.6 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10504053243242001		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.10504053243242001 | validation: 0.09522181026653835]
	TIME [epoch: 91.6 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10634437673548852		[learning rate: 0.0025852]
	Learning Rate: 0.00258523
	LOSS [training: 0.10634437673548852 | validation: 0.10393120792826219]
	TIME [epoch: 91.4 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10699860188106555		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.10699860188106555 | validation: 0.09162218397484731]
	TIME [epoch: 91.5 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10372953878537443		[learning rate: 0.0025647]
	Learning Rate: 0.00256471
	LOSS [training: 0.10372953878537443 | validation: 0.09183067216014942]
	TIME [epoch: 91.4 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10637969497083886		[learning rate: 0.0025545]
	Learning Rate: 0.00255451
	LOSS [training: 0.10637969497083886 | validation: 0.09340119836607814]
	TIME [epoch: 91.6 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10416184945106743		[learning rate: 0.0025444]
	Learning Rate: 0.00254435
	LOSS [training: 0.10416184945106743 | validation: 0.09515007987528436]
	TIME [epoch: 91.6 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10510341199281074		[learning rate: 0.0025342]
	Learning Rate: 0.00253423
	LOSS [training: 0.10510341199281074 | validation: 0.09304787722886912]
	TIME [epoch: 91.3 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10414443169903709		[learning rate: 0.0025242]
	Learning Rate: 0.00252415
	LOSS [training: 0.10414443169903709 | validation: 0.09470719943383911]
	TIME [epoch: 91.4 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10578989854398267		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.10578989854398267 | validation: 0.0917684173932473]
	TIME [epoch: 91.4 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10754121130131501		[learning rate: 0.0025041]
	Learning Rate: 0.00250411
	LOSS [training: 0.10754121130131501 | validation: 0.090295566142918]
	TIME [epoch: 91.4 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10364927035719779		[learning rate: 0.0024942]
	Learning Rate: 0.00249415
	LOSS [training: 0.10364927035719779 | validation: 0.08936980138238025]
	TIME [epoch: 91.3 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10682227655792516		[learning rate: 0.0024842]
	Learning Rate: 0.00248423
	LOSS [training: 0.10682227655792516 | validation: 0.08942077680043192]
	TIME [epoch: 91.4 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10450139868943825		[learning rate: 0.0024744]
	Learning Rate: 0.00247435
	LOSS [training: 0.10450139868943825 | validation: 0.08976519181544593]
	TIME [epoch: 91.3 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10639751859296243		[learning rate: 0.0024645]
	Learning Rate: 0.00246451
	LOSS [training: 0.10639751859296243 | validation: 0.09010766436330192]
	TIME [epoch: 91.4 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10757691414298681		[learning rate: 0.0024547]
	Learning Rate: 0.00245471
	LOSS [training: 0.10757691414298681 | validation: 0.09100030459880015]
	TIME [epoch: 91.4 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10533097436300475		[learning rate: 0.0024449]
	Learning Rate: 0.00244495
	LOSS [training: 0.10533097436300475 | validation: 0.09134156990550893]
	TIME [epoch: 91.4 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10512245251143486		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.10512245251143486 | validation: 0.09490596374253567]
	TIME [epoch: 91.4 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1056642965514847		[learning rate: 0.0024255]
	Learning Rate: 0.00242554
	LOSS [training: 0.1056642965514847 | validation: 0.09085061467897422]
	TIME [epoch: 91.6 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10718939763526221		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.10718939763526221 | validation: 0.09108586457111731]
	TIME [epoch: 91.4 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10796981992510735		[learning rate: 0.0024063]
	Learning Rate: 0.00240628
	LOSS [training: 0.10796981992510735 | validation: 0.08932845246973824]
	TIME [epoch: 91.5 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1065313670150197		[learning rate: 0.0023967]
	Learning Rate: 0.00239671
	LOSS [training: 0.1065313670150197 | validation: 0.09129619669537291]
	TIME [epoch: 91.5 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10471204517632315		[learning rate: 0.0023872]
	Learning Rate: 0.00238718
	LOSS [training: 0.10471204517632315 | validation: 0.09572633945527247]
	TIME [epoch: 91.4 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10723406222125464		[learning rate: 0.0023777]
	Learning Rate: 0.00237768
	LOSS [training: 0.10723406222125464 | validation: 0.09569841838325671]
	TIME [epoch: 91.4 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10633654019804029		[learning rate: 0.0023682]
	Learning Rate: 0.00236823
	LOSS [training: 0.10633654019804029 | validation: 0.09201775157243133]
	TIME [epoch: 91.5 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1061314421313239		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.1061314421313239 | validation: 0.09142020612673878]
	TIME [epoch: 91.5 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10635657810523154		[learning rate: 0.0023494]
	Learning Rate: 0.00234942
	LOSS [training: 0.10635657810523154 | validation: 0.09231118931625565]
	TIME [epoch: 91.6 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10718768845841826		[learning rate: 0.0023401]
	Learning Rate: 0.00234008
	LOSS [training: 0.10718768845841826 | validation: 0.09701788464254225]
	TIME [epoch: 91.6 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10749338717576376		[learning rate: 0.0023308]
	Learning Rate: 0.00233077
	LOSS [training: 0.10749338717576376 | validation: 0.09826409311510342]
	TIME [epoch: 91.5 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10770876847551436		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.10770876847551436 | validation: 0.09550391395456924]
	TIME [epoch: 91.7 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1077398965997583		[learning rate: 0.0023123]
	Learning Rate: 0.00231227
	LOSS [training: 0.1077398965997583 | validation: 0.09621564913559057]
	TIME [epoch: 91.5 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10907211499058708		[learning rate: 0.0023031]
	Learning Rate: 0.00230307
	LOSS [training: 0.10907211499058708 | validation: 0.09828300044883637]
	TIME [epoch: 91.6 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10868407370630251		[learning rate: 0.0022939]
	Learning Rate: 0.00229391
	LOSS [training: 0.10868407370630251 | validation: 0.09368885687504991]
	TIME [epoch: 91.5 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10707833566414954		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.10707833566414954 | validation: 0.09183143389689899]
	TIME [epoch: 91.6 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10486019358418236		[learning rate: 0.0022757]
	Learning Rate: 0.0022757
	LOSS [training: 0.10486019358418236 | validation: 0.09055079920633467]
	TIME [epoch: 91.6 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10471669731806127		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.10471669731806127 | validation: 0.0915552345828601]
	TIME [epoch: 91.4 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10509876218442488		[learning rate: 0.0022576]
	Learning Rate: 0.00225764
	LOSS [training: 0.10509876218442488 | validation: 0.09162616099771424]
	TIME [epoch: 91.5 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10435191477622788		[learning rate: 0.0022487]
	Learning Rate: 0.00224866
	LOSS [training: 0.10435191477622788 | validation: 0.09472954998084822]
	TIME [epoch: 91.5 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10705505832414998		[learning rate: 0.0022397]
	Learning Rate: 0.00223971
	LOSS [training: 0.10705505832414998 | validation: 0.09442391270620916]
	TIME [epoch: 91.5 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10761043706905271		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.10761043706905271 | validation: 0.09572560710638649]
	TIME [epoch: 91.5 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10533528504188581		[learning rate: 0.0022219]
	Learning Rate: 0.00222193
	LOSS [training: 0.10533528504188581 | validation: 0.09600135904366781]
	TIME [epoch: 91.6 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10508163312979299		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.10508163312979299 | validation: 0.09624757449767743]
	TIME [epoch: 91.6 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10798784188830714		[learning rate: 0.0022043]
	Learning Rate: 0.00220429
	LOSS [training: 0.10798784188830714 | validation: 0.09455273850645478]
	TIME [epoch: 91.6 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10568200322381316		[learning rate: 0.0021955]
	Learning Rate: 0.00219553
	LOSS [training: 0.10568200322381316 | validation: 0.09389625573726398]
	TIME [epoch: 91.6 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10749860171294306		[learning rate: 0.0021868]
	Learning Rate: 0.00218679
	LOSS [training: 0.10749860171294306 | validation: 0.09230103687912873]
	TIME [epoch: 91.4 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10592771333494536		[learning rate: 0.0021781]
	Learning Rate: 0.0021781
	LOSS [training: 0.10592771333494536 | validation: 0.09258121881442644]
	TIME [epoch: 91.4 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10597622896588924		[learning rate: 0.0021694]
	Learning Rate: 0.00216943
	LOSS [training: 0.10597622896588924 | validation: 0.09340757696242977]
	TIME [epoch: 91.6 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10752584422439318		[learning rate: 0.0021608]
	Learning Rate: 0.0021608
	LOSS [training: 0.10752584422439318 | validation: 0.09588925680289591]
	TIME [epoch: 91.5 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11066471345163774		[learning rate: 0.0021522]
	Learning Rate: 0.00215221
	LOSS [training: 0.11066471345163774 | validation: 0.09292694884970291]
	TIME [epoch: 91.4 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10798920474492255		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.10798920474492255 | validation: 0.0909033097520496]
	TIME [epoch: 91.5 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10583675108236999		[learning rate: 0.0021351]
	Learning Rate: 0.00213512
	LOSS [training: 0.10583675108236999 | validation: 0.09386835355139991]
	TIME [epoch: 91.5 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10747465585706285		[learning rate: 0.0021266]
	Learning Rate: 0.00212663
	LOSS [training: 0.10747465585706285 | validation: 0.09828533143276133]
	TIME [epoch: 91.4 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11222723601018364		[learning rate: 0.0021182]
	Learning Rate: 0.00211817
	LOSS [training: 0.11222723601018364 | validation: 0.10055590990140573]
	TIME [epoch: 91.4 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11081339148972275		[learning rate: 0.0021097]
	Learning Rate: 0.00210975
	LOSS [training: 0.11081339148972275 | validation: 0.0997042409476451]
	TIME [epoch: 91.5 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11604432612262944		[learning rate: 0.0021014]
	Learning Rate: 0.00210136
	LOSS [training: 0.11604432612262944 | validation: 0.09917347959784091]
	TIME [epoch: 91.4 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10837746275196675		[learning rate: 0.002093]
	Learning Rate: 0.002093
	LOSS [training: 0.10837746275196675 | validation: 0.09668452861576914]
	TIME [epoch: 91.4 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10784422902168901		[learning rate: 0.0020847]
	Learning Rate: 0.00208468
	LOSS [training: 0.10784422902168901 | validation: 0.0967288471552748]
	TIME [epoch: 91.5 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10911500103760702		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.10911500103760702 | validation: 0.09384678032707554]
	TIME [epoch: 91.4 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1071580548472715		[learning rate: 0.0020681]
	Learning Rate: 0.00206813
	LOSS [training: 0.1071580548472715 | validation: 0.09446372235896536]
	TIME [epoch: 91.5 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10846461680578783		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.10846461680578783 | validation: 0.09143492934671119]
	TIME [epoch: 91.4 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10707809640364413		[learning rate: 0.0020517]
	Learning Rate: 0.00205171
	LOSS [training: 0.10707809640364413 | validation: 0.09518626243865769]
	TIME [epoch: 91.3 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10882866830655616		[learning rate: 0.0020435]
	Learning Rate: 0.00204355
	LOSS [training: 0.10882866830655616 | validation: 0.09374784286241752]
	TIME [epoch: 91.5 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10748108303895704		[learning rate: 0.0020354]
	Learning Rate: 0.00203542
	LOSS [training: 0.10748108303895704 | validation: 0.0941941204084594]
	TIME [epoch: 91.4 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10818113963159542		[learning rate: 0.0020273]
	Learning Rate: 0.00202732
	LOSS [training: 0.10818113963159542 | validation: 0.0921519917059326]
	TIME [epoch: 91.4 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10935368623635543		[learning rate: 0.0020193]
	Learning Rate: 0.00201926
	LOSS [training: 0.10935368623635543 | validation: 0.09456986746437131]
	TIME [epoch: 91.3 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10644680124640167		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.10644680124640167 | validation: 0.09339468952293217]
	TIME [epoch: 91.4 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10526264402352771		[learning rate: 0.0020032]
	Learning Rate: 0.00200323
	LOSS [training: 0.10526264402352771 | validation: 0.0925920167140066]
	TIME [epoch: 91.6 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10706625326491982		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.10706625326491982 | validation: 0.09160564745428124]
	TIME [epoch: 91.4 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10674308868693977		[learning rate: 0.0019873]
	Learning Rate: 0.00198733
	LOSS [training: 0.10674308868693977 | validation: 0.09123161115833997]
	TIME [epoch: 91.4 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10521465127873625		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.10521465127873625 | validation: 0.09224133115158731]
	TIME [epoch: 91.5 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10750096142957652		[learning rate: 0.0019715]
	Learning Rate: 0.00197155
	LOSS [training: 0.10750096142957652 | validation: 0.09334287936666805]
	TIME [epoch: 91.4 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10479097521577893		[learning rate: 0.0019637]
	Learning Rate: 0.00196371
	LOSS [training: 0.10479097521577893 | validation: 0.09229412164317208]
	TIME [epoch: 91.5 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10764094591453502		[learning rate: 0.0019559]
	Learning Rate: 0.0019559
	LOSS [training: 0.10764094591453502 | validation: 0.09149601288523172]
	TIME [epoch: 91.5 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10470597908900665		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.10470597908900665 | validation: 0.09366660457092064]
	TIME [epoch: 91.5 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10738482382832554		[learning rate: 0.0019404]
	Learning Rate: 0.00194037
	LOSS [training: 0.10738482382832554 | validation: 0.09318105213191598]
	TIME [epoch: 91.4 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10812945312601041		[learning rate: 0.0019327]
	Learning Rate: 0.00193265
	LOSS [training: 0.10812945312601041 | validation: 0.09264693359311135]
	TIME [epoch: 91.5 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10681454115030659		[learning rate: 0.001925]
	Learning Rate: 0.00192497
	LOSS [training: 0.10681454115030659 | validation: 0.09142421774786438]
	TIME [epoch: 91.4 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10640759897328939		[learning rate: 0.0019173]
	Learning Rate: 0.00191731
	LOSS [training: 0.10640759897328939 | validation: 0.09185240236772627]
	TIME [epoch: 91.5 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.106844257007108		[learning rate: 0.0019097]
	Learning Rate: 0.00190968
	LOSS [training: 0.106844257007108 | validation: 0.09054915258743457]
	TIME [epoch: 91.4 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10620090815560267		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.10620090815560267 | validation: 0.09278797922575167]
	TIME [epoch: 91.4 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10905257717064192		[learning rate: 0.0018945]
	Learning Rate: 0.00189452
	LOSS [training: 0.10905257717064192 | validation: 0.09476837737127483]
	TIME [epoch: 91.5 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11122728739441394		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.11122728739441394 | validation: 0.10497842365481343]
	TIME [epoch: 91.4 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11256389925254312		[learning rate: 0.0018795]
	Learning Rate: 0.00187948
	LOSS [training: 0.11256389925254312 | validation: 0.09745329936541003]
	TIME [epoch: 91.5 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11148252056916602		[learning rate: 0.001872]
	Learning Rate: 0.00187201
	LOSS [training: 0.11148252056916602 | validation: 0.09548658045489317]
	TIME [epoch: 91.6 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11046053903449862		[learning rate: 0.0018646]
	Learning Rate: 0.00186456
	LOSS [training: 0.11046053903449862 | validation: 0.1007700262076586]
	TIME [epoch: 91.4 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1095800209300908		[learning rate: 0.0018571]
	Learning Rate: 0.00185715
	LOSS [training: 0.1095800209300908 | validation: 0.09814780190458341]
	TIME [epoch: 91.5 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10560334748267164		[learning rate: 0.0018498]
	Learning Rate: 0.00184976
	LOSS [training: 0.10560334748267164 | validation: 0.09341919874938619]
	TIME [epoch: 91.3 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10596350262729003		[learning rate: 0.0018424]
	Learning Rate: 0.0018424
	LOSS [training: 0.10596350262729003 | validation: 0.09639102578872465]
	TIME [epoch: 91.6 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10680687347551611		[learning rate: 0.0018351]
	Learning Rate: 0.00183508
	LOSS [training: 0.10680687347551611 | validation: 0.09490734787457877]
	TIME [epoch: 91.6 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10560932246406877		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.10560932246406877 | validation: 0.09153745411963683]
	TIME [epoch: 91.5 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10631692205006772		[learning rate: 0.0018205]
	Learning Rate: 0.00182051
	LOSS [training: 0.10631692205006772 | validation: 0.09158938417002252]
	TIME [epoch: 91.4 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10511403085736741		[learning rate: 0.0018133]
	Learning Rate: 0.00181327
	LOSS [training: 0.10511403085736741 | validation: 0.09165945866383009]
	TIME [epoch: 91.6 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10585038757834195		[learning rate: 0.0018061]
	Learning Rate: 0.00180605
	LOSS [training: 0.10585038757834195 | validation: 0.09380789507828992]
	TIME [epoch: 91.5 sec]
EPOCH 475/2000:
	Training over batches...
