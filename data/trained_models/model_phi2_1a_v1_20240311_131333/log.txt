Args:
Namespace(name='model_phi2_1a_v1', outdir='out/model_training/model_phi2_1a_v1', training_data='data/training_data/data_phi2_1a/training', validation_data='data/training_data/data_phi2_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3841146298

Training model...

Saving initial model state to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.400834082824076		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.400834082824076 | validation: 8.40113551707477]
	TIME [epoch: 112 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.096908604210695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.096908604210695 | validation: 7.187379492168511]
	TIME [epoch: 6.33 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.2121609131018865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.2121609131018865 | validation: 7.230085537474739]
	TIME [epoch: 6.27 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.4346088083686706		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.4346088083686706 | validation: 6.0476833463641935]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.1859100963645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.1859100963645 | validation: 4.737533261019156]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.199421597859338		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.199421597859338 | validation: 6.189324311673512]
	TIME [epoch: 6.31 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.669289573392874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.669289573392874 | validation: 3.77740098089155]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.883924851206184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.883924851206184 | validation: 2.6087291836397597]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0237306342828356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0237306342828356 | validation: 2.413841985389758]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.671965222806289		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.671965222806289 | validation: 2.895617887897923]
	TIME [epoch: 6.25 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5727874551541565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5727874551541565 | validation: 2.0282000828686995]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4409909173316966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4409909173316966 | validation: 1.6014182390661122]
	TIME [epoch: 6.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1721976799979994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1721976799979994 | validation: 1.5900533481341932]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2036192806453245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2036192806453245 | validation: 1.5215536525803004]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1053085332298083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1053085332298083 | validation: 1.427653429122038]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.132721263549512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.132721263549512 | validation: 1.5183284435975735]
	TIME [epoch: 6.25 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.170522858320902		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.170522858320902 | validation: 1.5335230949965315]
	TIME [epoch: 6.28 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9909761306284177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9909761306284177 | validation: 1.5017250567224345]
	TIME [epoch: 6.27 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0767585986365935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0767585986365935 | validation: 1.798398585742454]
	TIME [epoch: 6.26 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.976675588262782		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.976675588262782 | validation: 1.7138783200553673]
	TIME [epoch: 6.25 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1157343838326437		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1157343838326437 | validation: 1.8340845933052607]
	TIME [epoch: 6.25 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9640392762512566		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9640392762512566 | validation: 1.595976786633972]
	TIME [epoch: 6.24 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.169790476999637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.169790476999637 | validation: 1.2656119413145202]
	TIME [epoch: 6.28 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9133757831346418		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9133757831346418 | validation: 1.372488535378706]
	TIME [epoch: 6.3 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9326812150120407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9326812150120407 | validation: 1.2654758087050446]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9282803122099923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9282803122099923 | validation: 1.3045916434918878]
	TIME [epoch: 6.27 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2387667182965476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2387667182965476 | validation: 1.4530818365172302]
	TIME [epoch: 6.27 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8954905976773029		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8954905976773029 | validation: 1.4030435258582727]
	TIME [epoch: 6.26 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8702913510571095		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8702913510571095 | validation: 1.5115600168139922]
	TIME [epoch: 6.3 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8315817823687675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8315817823687675 | validation: 1.512878452775368]
	TIME [epoch: 6.28 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7627046918750526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7627046918750526 | validation: 1.3771128663812449]
	TIME [epoch: 6.26 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.77274649381117		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.77274649381117 | validation: 1.8062896165719962]
	TIME [epoch: 6.26 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7958884338352215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7958884338352215 | validation: 1.4247368475568707]
	TIME [epoch: 6.26 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8909598718858152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8909598718858152 | validation: 1.494975140898493]
	TIME [epoch: 6.26 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7664111636771918		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7664111636771918 | validation: 1.6767469511629605]
	TIME [epoch: 6.3 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7541940789966721		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7541940789966721 | validation: 1.8901201454722707]
	TIME [epoch: 6.27 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.781258409140329		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.781258409140329 | validation: 2.6672813902802837]
	TIME [epoch: 6.26 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2203180885747904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2203180885747904 | validation: 1.1695700160560103]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8130365593623496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8130365593623496 | validation: 1.2185410037802114]
	TIME [epoch: 6.26 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7483330732727527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7483330732727527 | validation: 1.5372458400599944]
	TIME [epoch: 6.26 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8122040988350017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8122040988350017 | validation: 1.2733234215244948]
	TIME [epoch: 6.31 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6824116368186286		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6824116368186286 | validation: 1.955945674605168]
	TIME [epoch: 6.27 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8400337640331552		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8400337640331552 | validation: 1.4837874072544075]
	TIME [epoch: 6.26 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7653476811121416		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7653476811121416 | validation: 1.1060074222942857]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4740183752738765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4740183752738765 | validation: 2.1928766377623274]
	TIME [epoch: 6.27 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8646135296946407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8646135296946407 | validation: 1.3263225405887598]
	TIME [epoch: 6.28 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6216480982179518		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6216480982179518 | validation: 1.117658231420077]
	TIME [epoch: 6.32 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6085728996232997		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6085728996232997 | validation: 1.3278225914837916]
	TIME [epoch: 6.27 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5512243790211608		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5512243790211608 | validation: 0.9925815328747808]
	TIME [epoch: 6.28 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6819347754077616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6819347754077616 | validation: 1.3978529920930198]
	TIME [epoch: 6.27 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5848448819293712		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 1.5848448819293712 | validation: 1.0188972047702551]
	TIME [epoch: 6.26 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.065948567899045		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 2.065948567899045 | validation: 0.9976970631779252]
	TIME [epoch: 6.27 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1639894398924953		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 2.1639894398924953 | validation: 1.074298818797171]
	TIME [epoch: 6.3 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.708759795736878		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 1.708759795736878 | validation: 1.333199261853826]
	TIME [epoch: 6.27 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4778371028523234		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 1.4778371028523234 | validation: 0.9438140985943357]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6022721845551722		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 1.6022721845551722 | validation: 1.7100558102591947]
	TIME [epoch: 6.27 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5981213977389814		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 1.5981213977389814 | validation: 1.2406725732522181]
	TIME [epoch: 6.26 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.39505997582951		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 1.39505997582951 | validation: 1.9812121146087116]
	TIME [epoch: 6.28 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8124426754489769		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 1.8124426754489769 | validation: 1.0264955640281817]
	TIME [epoch: 6.3 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5545297301560526		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 1.5545297301560526 | validation: 0.9688841308622795]
	TIME [epoch: 6.27 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5731512118936322		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 1.5731512118936322 | validation: 0.9253199199153501]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.415965593340815		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 1.415965593340815 | validation: 0.8769656421773081]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.44035073073389		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 1.44035073073389 | validation: 0.8888531266489841]
	TIME [epoch: 6.27 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.507889985403119		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 1.507889985403119 | validation: 0.901851363226476]
	TIME [epoch: 6.3 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4778392722212352		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 1.4778392722212352 | validation: 1.0280833120768842]
	TIME [epoch: 6.29 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4623071999726438		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 1.4623071999726438 | validation: 0.8947155184516455]
	TIME [epoch: 6.27 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5281840687228863		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 1.5281840687228863 | validation: 1.0049306274653849]
	TIME [epoch: 6.26 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3878935362511777		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 1.3878935362511777 | validation: 0.8807949749664367]
	TIME [epoch: 6.27 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5153664696197529		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 1.5153664696197529 | validation: 0.9543017587991053]
	TIME [epoch: 6.27 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5183758882762748		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 1.5183758882762748 | validation: 1.0350099493125258]
	TIME [epoch: 6.3 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3959755189865652		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 1.3959755189865652 | validation: 1.67649967065319]
	TIME [epoch: 6.29 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6166240497817954		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 1.6166240497817954 | validation: 0.9587547160276566]
	TIME [epoch: 6.27 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3355722356173798		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 1.3355722356173798 | validation: 1.4650827260427715]
	TIME [epoch: 6.28 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6111054953879163		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 1.6111054953879163 | validation: 0.8133648062111057]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4457964934326426		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 1.4457964934326426 | validation: 0.9780404793497919]
	TIME [epoch: 6.27 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9821482302022164		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 1.9821482302022164 | validation: 1.1545868893915037]
	TIME [epoch: 6.31 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6476587804291514		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 1.6476587804291514 | validation: 0.8535961336450553]
	TIME [epoch: 6.27 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.959752684088314		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 1.959752684088314 | validation: 0.9573309861342643]
	TIME [epoch: 6.27 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3232776624344404		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 1.3232776624344404 | validation: 1.167783279819932]
	TIME [epoch: 6.27 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5562289158048472		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 1.5562289158048472 | validation: 0.9708419342143062]
	TIME [epoch: 6.27 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3905271811665512		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 1.3905271811665512 | validation: 0.89979073035798]
	TIME [epoch: 6.27 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.321860242221152		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 1.321860242221152 | validation: 0.8731712295396574]
	TIME [epoch: 6.31 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3329411063758978		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 1.3329411063758978 | validation: 0.9230750566712751]
	TIME [epoch: 6.27 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3085052409506466		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 1.3085052409506466 | validation: 0.8418970013991862]
	TIME [epoch: 6.27 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2134810628210215		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 1.2134810628210215 | validation: 1.0651778273354262]
	TIME [epoch: 6.27 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2571343806341337		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 1.2571343806341337 | validation: 1.5613450637962982]
	TIME [epoch: 6.27 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4009024888073531		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 1.4009024888073531 | validation: 1.5196022922015735]
	TIME [epoch: 6.27 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5211370363189807		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 1.5211370363189807 | validation: 0.835524661610938]
	TIME [epoch: 6.31 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2248322637977385		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 1.2248322637977385 | validation: 0.903506127708203]
	TIME [epoch: 6.27 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2794524515649863		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.2794524515649863 | validation: 1.8840629579735366]
	TIME [epoch: 6.28 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.639935610263584		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 1.639935610263584 | validation: 0.792903056081408]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.220775369999368		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 1.220775369999368 | validation: 0.8276971953267579]
	TIME [epoch: 6.27 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.324145299382678		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 1.324145299382678 | validation: 0.9627446544163795]
	TIME [epoch: 6.28 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.286948328902032		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 1.286948328902032 | validation: 0.7705572174438196]
	TIME [epoch: 6.31 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2213882077015168		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 1.2213882077015168 | validation: 0.7152429088847393]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1586198065770144		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.1586198065770144 | validation: 0.8728446217411951]
	TIME [epoch: 6.27 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.364151771236324		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 1.364151771236324 | validation: 0.9463215218208374]
	TIME [epoch: 6.27 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2305319013375084		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.2305319013375084 | validation: 0.8048980442304972]
	TIME [epoch: 6.27 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1731245020677585		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.1731245020677585 | validation: 0.7776415967259196]
	TIME [epoch: 6.28 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.213458129460975		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 1.213458129460975 | validation: 0.7124742556323685]
	TIME [epoch: 6.31 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.127499953704644		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 1.127499953704644 | validation: 1.0636941064009366]
	TIME [epoch: 6.27 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1979923114565247		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 1.1979923114565247 | validation: 0.6556438205653905]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_102.pth
	Model improved!!!
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1462129800014873		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 1.1462129800014873 | validation: 0.7421755648863532]
	TIME [epoch: 6.27 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2758521407850207		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.2758521407850207 | validation: 0.8508982242750035]
	TIME [epoch: 6.27 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.267729077462334		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.267729077462334 | validation: 0.7647261965441843]
	TIME [epoch: 6.28 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0515721251988286		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 1.0515721251988286 | validation: 0.6287494904926161]
	TIME [epoch: 6.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1542562256096747		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 1.1542562256096747 | validation: 0.6506754122128762]
	TIME [epoch: 6.28 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1889819523082554		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 1.1889819523082554 | validation: 1.1251014965850166]
	TIME [epoch: 6.27 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2104032188387417		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 1.2104032188387417 | validation: 0.6157468252762025]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1251600276010625		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 1.1251600276010625 | validation: 0.8085190905258999]
	TIME [epoch: 6.27 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0834583775736246		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 1.0834583775736246 | validation: 0.6112048077630279]
	TIME [epoch: 6.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_111.pth
	Model improved!!!
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9700736838093864		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.9700736838093864 | validation: 0.9472150763582294]
	TIME [epoch: 6.29 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0609324856723712		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 1.0609324856723712 | validation: 0.7292360794784907]
	TIME [epoch: 6.27 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0314824491611587		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 1.0314824491611587 | validation: 0.6339822185326075]
	TIME [epoch: 6.26 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9603080288487034		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.9603080288487034 | validation: 0.6792073405570946]
	TIME [epoch: 6.26 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0853768543808362		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 1.0853768543808362 | validation: 0.5368812716036546]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_116.pth
	Model improved!!!
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9795831154139386		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.9795831154139386 | validation: 0.6652905206386671]
	TIME [epoch: 6.31 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9386653902977078		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.9386653902977078 | validation: 0.6002166053683001]
	TIME [epoch: 6.27 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9949389147654681		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.9949389147654681 | validation: 0.5864690063276187]
	TIME [epoch: 6.27 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.96080871679538		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.96080871679538 | validation: 0.8093561739005095]
	TIME [epoch: 6.27 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9953953404189949		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.9953953404189949 | validation: 0.5156444777118463]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9603976311363012		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.9603976311363012 | validation: 0.944757723700374]
	TIME [epoch: 6.28 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9798072555747751		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.9798072555747751 | validation: 0.5590453439094192]
	TIME [epoch: 6.31 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9080606163711727		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.9080606163711727 | validation: 0.8064323956055297]
	TIME [epoch: 6.27 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0316519644224196		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.0316519644224196 | validation: 0.5156379579987913]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_125.pth
	Model improved!!!
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9169593675090296		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.9169593675090296 | validation: 0.5111555018593017]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_126.pth
	Model improved!!!
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8828372758017855		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.8828372758017855 | validation: 0.539577486210455]
	TIME [epoch: 6.27 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.912274599011851		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.912274599011851 | validation: 0.5871918814223246]
	TIME [epoch: 6.27 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0034056210110023		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 1.0034056210110023 | validation: 0.532230803935887]
	TIME [epoch: 6.33 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9128546564068665		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.9128546564068665 | validation: 0.5800382093693058]
	TIME [epoch: 6.28 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9525677222574952		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.9525677222574952 | validation: 0.5413593403973374]
	TIME [epoch: 6.29 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9264783276895223		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.9264783276895223 | validation: 0.7150147031645872]
	TIME [epoch: 6.29 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9470892560727426		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.9470892560727426 | validation: 0.767442862629476]
	TIME [epoch: 6.28 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9670258077245533		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.9670258077245533 | validation: 0.566834553229304]
	TIME [epoch: 6.29 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8942024053104617		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.8942024053104617 | validation: 0.5114098917814333]
	TIME [epoch: 6.31 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9212303776388184		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.9212303776388184 | validation: 0.5242525965501545]
	TIME [epoch: 6.29 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9072027990022755		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.9072027990022755 | validation: 0.49107389154468956]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_137.pth
	Model improved!!!
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8703653121421615		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.8703653121421615 | validation: 0.5939607846028484]
	TIME [epoch: 6.29 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9453304989116748		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.9453304989116748 | validation: 0.5599525505001399]
	TIME [epoch: 6.29 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.98896696533313		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.98896696533313 | validation: 0.5063352863310452]
	TIME [epoch: 6.3 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8708680726499429		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.8708680726499429 | validation: 0.5130591586677873]
	TIME [epoch: 6.33 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9132473001496999		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.9132473001496999 | validation: 0.6942885441615672]
	TIME [epoch: 6.29 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9477595034133309		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.9477595034133309 | validation: 0.4763911231361966]
	TIME [epoch: 6.29 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_143.pth
	Model improved!!!
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9083141666685504		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.9083141666685504 | validation: 0.602223107751641]
	TIME [epoch: 6.28 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9238915307146538		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.9238915307146538 | validation: 0.5114195624952356]
	TIME [epoch: 6.29 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8752269930740437		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.8752269930740437 | validation: 0.6602817062274329]
	TIME [epoch: 6.31 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9446559817100255		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.9446559817100255 | validation: 0.48725087566452885]
	TIME [epoch: 6.31 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9067136128021297		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.9067136128021297 | validation: 0.5057687371211617]
	TIME [epoch: 6.28 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9479063070672885		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.9479063070672885 | validation: 0.47376693600251113]
	TIME [epoch: 6.28 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_149.pth
	Model improved!!!
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8548798153800288		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.8548798153800288 | validation: 0.466467751642064]
	TIME [epoch: 6.28 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9421914748151518		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.9421914748151518 | validation: 0.5993345187509166]
	TIME [epoch: 6.29 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9045188625389752		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.9045188625389752 | validation: 0.5242264898592968]
	TIME [epoch: 6.32 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8707186822555648		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.8707186822555648 | validation: 0.47460809270691734]
	TIME [epoch: 6.29 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.904895434518918		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.904895434518918 | validation: 0.5438511126517622]
	TIME [epoch: 6.27 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8500376173854307		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.8500376173854307 | validation: 0.49273211804271844]
	TIME [epoch: 6.28 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8683300306091559		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.8683300306091559 | validation: 0.5315013069620123]
	TIME [epoch: 6.29 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8387733694444879		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.8387733694444879 | validation: 0.4767065240711157]
	TIME [epoch: 6.27 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8766321805259545		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.8766321805259545 | validation: 0.47019929921357556]
	TIME [epoch: 6.33 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8281889599147636		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.8281889599147636 | validation: 0.558669047915727]
	TIME [epoch: 6.29 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8890000756810417		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.8890000756810417 | validation: 0.5081325795773509]
	TIME [epoch: 6.27 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8475947240122668		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.8475947240122668 | validation: 0.5967841898245816]
	TIME [epoch: 6.28 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.860363680336695		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.860363680336695 | validation: 0.5304051027721839]
	TIME [epoch: 6.27 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8992571110672423		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.8992571110672423 | validation: 0.45523155309754487]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_163.pth
	Model improved!!!
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8477300876115865		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.8477300876115865 | validation: 0.5004594345095242]
	TIME [epoch: 6.33 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8731664040468341		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.8731664040468341 | validation: 0.5075278227406013]
	TIME [epoch: 6.29 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1282628760218474		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 1.1282628760218474 | validation: 0.8343865553162129]
	TIME [epoch: 6.29 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9560720597652188		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.9560720597652188 | validation: 0.4979181125815152]
	TIME [epoch: 6.29 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.862737169936691		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.862737169936691 | validation: 0.45609344270172064]
	TIME [epoch: 6.29 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8243191261824379		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.8243191261824379 | validation: 0.4456936448598272]
	TIME [epoch: 6.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_169.pth
	Model improved!!!
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9053970759089582		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.9053970759089582 | validation: 0.48861713564169157]
	TIME [epoch: 6.34 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8431123624891872		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.8431123624891872 | validation: 0.4730069740066798]
	TIME [epoch: 6.29 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8993758772136597		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.8993758772136597 | validation: 0.5250972382765879]
	TIME [epoch: 6.28 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8304519542785112		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.8304519542785112 | validation: 0.4922095736128009]
	TIME [epoch: 6.28 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.850647565186587		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.850647565186587 | validation: 0.6840525430952851]
	TIME [epoch: 6.27 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8816648955299082		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.8816648955299082 | validation: 0.5257402265108776]
	TIME [epoch: 6.29 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9125022168880235		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.9125022168880235 | validation: 0.5083184189048412]
	TIME [epoch: 6.33 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9028155136382144		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.9028155136382144 | validation: 0.4664363238548659]
	TIME [epoch: 6.29 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8761451567140488		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.8761451567140488 | validation: 0.460560565971071]
	TIME [epoch: 6.29 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8515467654398713		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.8515467654398713 | validation: 0.5178362871560255]
	TIME [epoch: 6.29 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8789113230887002		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.8789113230887002 | validation: 0.522001334928581]
	TIME [epoch: 6.29 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8366829225056462		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.8366829225056462 | validation: 0.4876479410221012]
	TIME [epoch: 6.3 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8312896591568424		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.8312896591568424 | validation: 0.4894933344318039]
	TIME [epoch: 6.33 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8515147325863537		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.8515147325863537 | validation: 0.5836587844726832]
	TIME [epoch: 6.29 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8933743919237762		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.8933743919237762 | validation: 0.5219460126108625]
	TIME [epoch: 6.29 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8166917871702903		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.8166917871702903 | validation: 0.48269757337531394]
	TIME [epoch: 6.29 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8272504037153967		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.8272504037153967 | validation: 0.45909471514168665]
	TIME [epoch: 6.28 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8427090857010398		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.8427090857010398 | validation: 0.5198030698021439]
	TIME [epoch: 6.3 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8277642529275372		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.8277642529275372 | validation: 0.4660860267113371]
	TIME [epoch: 6.33 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8265675746759162		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.8265675746759162 | validation: 0.5228112767152322]
	TIME [epoch: 6.29 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.86031714712453		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.86031714712453 | validation: 0.5864614420139487]
	TIME [epoch: 6.29 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8471615599428858		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.8471615599428858 | validation: 0.46186055775452023]
	TIME [epoch: 6.29 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8772367584162749		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.8772367584162749 | validation: 0.4741107227363275]
	TIME [epoch: 6.28 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8360171303163947		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.8360171303163947 | validation: 0.6433181330587392]
	TIME [epoch: 6.29 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8551658695701503		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.8551658695701503 | validation: 0.516729858639891]
	TIME [epoch: 6.32 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8168816893846079		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.8168816893846079 | validation: 0.446306325116328]
	TIME [epoch: 6.29 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8170596400947939		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.8170596400947939 | validation: 0.4553762687660626]
	TIME [epoch: 6.29 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8621217240946055		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.8621217240946055 | validation: 0.5729448952887581]
	TIME [epoch: 6.29 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.852014286932343		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.852014286932343 | validation: 0.5530610166302133]
	TIME [epoch: 6.3 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.853143718836668		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.853143718836668 | validation: 0.5407877569671145]
	TIME [epoch: 6.32 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8238860183866528		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.8238860183866528 | validation: 0.5650894986555605]
	TIME [epoch: 6.31 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8329108955738802		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.8329108955738802 | validation: 0.4398498196298546]
	TIME [epoch: 6.29 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_201.pth
	Model improved!!!
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8901788982324425		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.8901788982324425 | validation: 0.4441138317256355]
	TIME [epoch: 6.28 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8605227550001572		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.8605227550001572 | validation: 0.4405078412478803]
	TIME [epoch: 6.28 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8088866120241692		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.8088866120241692 | validation: 0.48509686622825665]
	TIME [epoch: 6.27 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9255475934644936		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.9255475934644936 | validation: 0.5346471735927599]
	TIME [epoch: 6.32 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8342293360904363		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.8342293360904363 | validation: 0.4859055750511819]
	TIME [epoch: 6.31 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8270401378845973		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.8270401378845973 | validation: 0.4572883802175483]
	TIME [epoch: 6.29 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8559148064984167		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.8559148064984167 | validation: 0.5468280945431376]
	TIME [epoch: 6.28 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8285773552393235		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.8285773552393235 | validation: 0.44716724734201857]
	TIME [epoch: 6.28 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8191330958231129		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.8191330958231129 | validation: 0.5065808420892323]
	TIME [epoch: 6.28 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8110006585914399		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.8110006585914399 | validation: 0.4314728449590081]
	TIME [epoch: 6.32 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_211.pth
	Model improved!!!
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8385972951285985		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.8385972951285985 | validation: 0.4544573429291256]
	TIME [epoch: 6.3 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8118237339206703		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.8118237339206703 | validation: 0.4467715367685641]
	TIME [epoch: 6.27 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8079768776159859		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.8079768776159859 | validation: 0.5395022180031654]
	TIME [epoch: 6.28 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8149998750955639		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.8149998750955639 | validation: 0.5051825882991972]
	TIME [epoch: 6.29 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8110148404114863		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.8110148404114863 | validation: 0.4388113109575106]
	TIME [epoch: 6.28 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8006104021605319		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.8006104021605319 | validation: 0.46837296748905843]
	TIME [epoch: 6.33 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8283655661334743		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.8283655661334743 | validation: 0.6112658594662472]
	TIME [epoch: 6.29 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8293517644858966		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.8293517644858966 | validation: 0.4245935384946591]
	TIME [epoch: 6.29 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_219.pth
	Model improved!!!
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8116645909514826		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.8116645909514826 | validation: 0.4384038933247217]
	TIME [epoch: 6.27 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7902246885135372		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.7902246885135372 | validation: 0.5870461863497887]
	TIME [epoch: 6.28 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1759526693428355		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 1.1759526693428355 | validation: 0.9662259575169174]
	TIME [epoch: 6.28 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1094527181366658		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 1.1094527181366658 | validation: 0.5323074651745493]
	TIME [epoch: 6.33 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8257102858392281		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.8257102858392281 | validation: 0.46698465888929724]
	TIME [epoch: 6.29 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7849530337497016		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.7849530337497016 | validation: 0.442799386954868]
	TIME [epoch: 6.28 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8044762812339612		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.8044762812339612 | validation: 0.47500124884966444]
	TIME [epoch: 6.29 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8608909701819831		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.8608909701819831 | validation: 0.49120941063556]
	TIME [epoch: 6.29 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8104977818244588		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.8104977818244588 | validation: 0.41804814903891463]
	TIME [epoch: 6.29 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_228.pth
	Model improved!!!
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.790857808367327		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.790857808367327 | validation: 0.4251651554390028]
	TIME [epoch: 6.33 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.808648761250327		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.808648761250327 | validation: 0.4826519825194306]
	TIME [epoch: 6.29 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.797947857300002		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.797947857300002 | validation: 0.46680475393863696]
	TIME [epoch: 6.29 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7932780974901223		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.7932780974901223 | validation: 0.5037502768591917]
	TIME [epoch: 6.29 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7865514971734743		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.7865514971734743 | validation: 0.592722736926839]
	TIME [epoch: 6.29 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8574179869488139		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.8574179869488139 | validation: 0.4137702244988644]
	TIME [epoch: 6.29 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_234.pth
	Model improved!!!
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7941138215366277		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.7941138215366277 | validation: 0.42861525983865556]
	TIME [epoch: 6.32 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8016713516504856		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.8016713516504856 | validation: 0.44256464158499437]
	TIME [epoch: 6.28 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7817199345921344		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.7817199345921344 | validation: 0.4465727259239977]
	TIME [epoch: 6.29 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7806303935108199		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.7806303935108199 | validation: 0.4363480957289421]
	TIME [epoch: 6.29 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8019617913847651		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.8019617913847651 | validation: 0.42665766193602334]
	TIME [epoch: 6.28 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8143740642708046		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.8143740642708046 | validation: 0.41818179087116936]
	TIME [epoch: 6.31 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8187529945088732		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.8187529945088732 | validation: 0.4372352050909215]
	TIME [epoch: 6.32 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7967041533354435		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.7967041533354435 | validation: 0.5200837737889104]
	TIME [epoch: 6.28 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8129263562419566		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.8129263562419566 | validation: 0.3899671913544178]
	TIME [epoch: 6.29 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_243.pth
	Model improved!!!
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7547028258813278		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.7547028258813278 | validation: 0.42200488765149835]
	TIME [epoch: 6.29 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8151147154345195		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.8151147154345195 | validation: 0.42498350514102656]
	TIME [epoch: 6.29 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7922453858674454		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.7922453858674454 | validation: 0.4396112933717204]
	TIME [epoch: 6.34 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8005936403557159		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.8005936403557159 | validation: 0.45107268812805557]
	TIME [epoch: 6.32 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7608144918187822		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.7608144918187822 | validation: 0.4508048276575098]
	TIME [epoch: 6.3 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7834668530592768		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.7834668530592768 | validation: 0.4217727014832181]
	TIME [epoch: 6.3 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7895452015078168		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.7895452015078168 | validation: 0.4528878191481487]
	TIME [epoch: 6.3 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7788438279335363		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.7788438279335363 | validation: 0.42430773142961137]
	TIME [epoch: 6.3 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7792847556401031		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.7792847556401031 | validation: 0.4789257462843144]
	TIME [epoch: 6.32 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7873465616639361		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.7873465616639361 | validation: 0.6662335018914036]
	TIME [epoch: 6.33 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8585720723674988		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.8585720723674988 | validation: 0.4756197461855585]
	TIME [epoch: 6.3 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7977500567535882		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.7977500567535882 | validation: 0.46377814214931556]
	TIME [epoch: 6.29 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7599921262246836		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.7599921262246836 | validation: 0.4329233376357723]
	TIME [epoch: 6.29 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7629135427302174		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.7629135427302174 | validation: 0.4412847407976818]
	TIME [epoch: 6.29 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7616695465693806		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.7616695465693806 | validation: 0.4145695011796986]
	TIME [epoch: 6.33 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8231312522150065		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.8231312522150065 | validation: 0.4693892584681218]
	TIME [epoch: 6.32 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7985423410191408		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.7985423410191408 | validation: 0.48270124605119114]
	TIME [epoch: 6.29 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0352024777345243		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 1.0352024777345243 | validation: 0.4040996124923342]
	TIME [epoch: 6.28 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7619750154752973		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.7619750154752973 | validation: 0.45829555756458074]
	TIME [epoch: 6.29 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7669704842553026		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.7669704842553026 | validation: 0.39085351857396344]
	TIME [epoch: 6.3 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7520161665122576		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.7520161665122576 | validation: 0.4051474309959674]
	TIME [epoch: 6.33 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8147099603953913		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.8147099603953913 | validation: 0.4119167575697537]
	TIME [epoch: 6.31 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7726859402109871		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.7726859402109871 | validation: 0.38106542402533666]
	TIME [epoch: 6.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_266.pth
	Model improved!!!
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7414477412334283		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.7414477412334283 | validation: 0.42738197224573693]
	TIME [epoch: 6.28 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7489440351482758		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.7489440351482758 | validation: 0.38224405260842587]
	TIME [epoch: 6.28 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7521217085183655		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.7521217085183655 | validation: 0.4227970188700461]
	TIME [epoch: 6.29 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7613115972568228		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.7613115972568228 | validation: 0.467823976724725]
	TIME [epoch: 6.33 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7826868002329833		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.7826868002329833 | validation: 0.42166956999161764]
	TIME [epoch: 6.3 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7583129280392038		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.7583129280392038 | validation: 0.4015321100107957]
	TIME [epoch: 6.29 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7764866081699684		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.7764866081699684 | validation: 0.39451766202628785]
	TIME [epoch: 6.29 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.757430491553335		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.757430491553335 | validation: 0.37463070963646844]
	TIME [epoch: 6.28 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_274.pth
	Model improved!!!
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7477737459257251		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.7477737459257251 | validation: 0.3903402910821767]
	TIME [epoch: 6.29 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7767770683675869		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.7767770683675869 | validation: 0.40574259190848133]
	TIME [epoch: 6.32 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7445081935278132		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.7445081935278132 | validation: 0.38909119896887073]
	TIME [epoch: 6.29 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7418112892564623		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.7418112892564623 | validation: 0.37750840444619793]
	TIME [epoch: 6.28 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7849690372681223		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.7849690372681223 | validation: 0.42470105823510085]
	TIME [epoch: 6.28 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7871901638398252		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.7871901638398252 | validation: 0.44659912324435636]
	TIME [epoch: 6.28 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7537673945481694		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.7537673945481694 | validation: 0.4010880003722853]
	TIME [epoch: 6.29 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.081474846426067		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 1.081474846426067 | validation: 0.39620093883842566]
	TIME [epoch: 6.32 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7643458449734013		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.7643458449734013 | validation: 0.45347831213794537]
	TIME [epoch: 6.29 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.756642537579475		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.756642537579475 | validation: 0.39485845206740033]
	TIME [epoch: 6.29 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8106624694563227		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.8106624694563227 | validation: 0.44027131930099306]
	TIME [epoch: 6.28 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7617688495197055		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.7617688495197055 | validation: 0.39256040570750805]
	TIME [epoch: 6.28 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7330802953276554		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.7330802953276554 | validation: 0.5358893579738784]
	TIME [epoch: 6.28 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.787511350385947		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.787511350385947 | validation: 0.42727800616838474]
	TIME [epoch: 6.34 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7607357649194761		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.7607357649194761 | validation: 0.40971372465088907]
	TIME [epoch: 6.29 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7481270546996577		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.7481270546996577 | validation: 0.46891563249710133]
	TIME [epoch: 6.28 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8189342109403663		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.8189342109403663 | validation: 0.4183004136570488]
	TIME [epoch: 6.28 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7498191614691218		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.7498191614691218 | validation: 0.3853190984460292]
	TIME [epoch: 6.28 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7420967531993892		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.7420967531993892 | validation: 0.4266469899494841]
	TIME [epoch: 6.29 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7653000780031426		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.7653000780031426 | validation: 0.41387160842576676]
	TIME [epoch: 6.33 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7453244204430305		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.7453244204430305 | validation: 0.4262651802222927]
	TIME [epoch: 6.28 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7525109036598526		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.7525109036598526 | validation: 0.4166996269490181]
	TIME [epoch: 6.29 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7490569574395761		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.7490569574395761 | validation: 0.4036203959149621]
	TIME [epoch: 6.29 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7620396137664633		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.7620396137664633 | validation: 0.39296757737035043]
	TIME [epoch: 6.29 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7434558395828255		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.7434558395828255 | validation: 0.38911995912281533]
	TIME [epoch: 6.3 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7796934272808532		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.7796934272808532 | validation: 0.3711660520670186]
	TIME [epoch: 6.33 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_300.pth
	Model improved!!!
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7539195806562555		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.7539195806562555 | validation: 0.4400641606631054]
	TIME [epoch: 6.29 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7651153186427739		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.7651153186427739 | validation: 0.4546419133322584]
	TIME [epoch: 6.28 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7887293433566571		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.7887293433566571 | validation: 0.3863720877642572]
	TIME [epoch: 6.28 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7529762657864422		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.7529762657864422 | validation: 0.3939336920931058]
	TIME [epoch: 6.27 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7335546890968583		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.7335546890968583 | validation: 0.5310742814980942]
	TIME [epoch: 6.29 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7944110213315523		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.7944110213315523 | validation: 0.404572393143413]
	TIME [epoch: 6.31 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7468191877617827		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.7468191877617827 | validation: 0.37786303941384336]
	TIME [epoch: 6.27 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7512465589923535		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.7512465589923535 | validation: 0.3887053214480246]
	TIME [epoch: 6.28 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7381735987599972		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.7381735987599972 | validation: 0.38034199960619475]
	TIME [epoch: 6.28 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.740076048698685		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.740076048698685 | validation: 0.416833018818753]
	TIME [epoch: 6.27 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7291018918251372		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.7291018918251372 | validation: 0.3727074578628924]
	TIME [epoch: 6.3 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7291023645277672		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.7291023645277672 | validation: 0.5483305246955272]
	TIME [epoch: 6.29 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.796030926723488		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.796030926723488 | validation: 0.40137798056698026]
	TIME [epoch: 6.28 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7302587581074931		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.7302587581074931 | validation: 0.39343033336625677]
	TIME [epoch: 6.27 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7505544854354682		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.7505544854354682 | validation: 0.47809896565257776]
	TIME [epoch: 6.27 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7659012203886059		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.7659012203886059 | validation: 0.3922997865629781]
	TIME [epoch: 6.27 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7446642053352233		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.7446642053352233 | validation: 0.36434272954556385]
	TIME [epoch: 6.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_317.pth
	Model improved!!!
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7300380436493703		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.7300380436493703 | validation: 0.41606953502739985]
	TIME [epoch: 6.3 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.750652299211211		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.750652299211211 | validation: 0.37989039472277164]
	TIME [epoch: 6.28 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7401091646188483		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.7401091646188483 | validation: 0.3850518239591821]
	TIME [epoch: 6.27 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7356931809541685		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.7356931809541685 | validation: 0.4071722200439367]
	TIME [epoch: 6.28 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7455579409566204		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.7455579409566204 | validation: 0.3719299675873175]
	TIME [epoch: 6.27 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7476517389686845		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.7476517389686845 | validation: 0.3969010303266569]
	TIME [epoch: 6.31 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7421038094004379		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.7421038094004379 | validation: 0.3879810948580972]
	TIME [epoch: 6.29 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7280256711879669		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.7280256711879669 | validation: 0.4578718462674803]
	TIME [epoch: 6.28 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7483447735331563		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.7483447735331563 | validation: 0.39024828458263433]
	TIME [epoch: 6.28 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7472594340991101		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.7472594340991101 | validation: 0.42079254099885854]
	TIME [epoch: 6.28 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7654239630162067		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.7654239630162067 | validation: 0.39823408871113664]
	TIME [epoch: 6.28 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7668447759919883		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.7668447759919883 | validation: 0.38692986539513585]
	TIME [epoch: 6.33 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7290531453714667		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.7290531453714667 | validation: 0.37918797612703536]
	TIME [epoch: 6.29 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7325569388607749		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.7325569388607749 | validation: 0.35797239816453097]
	TIME [epoch: 6.28 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_331.pth
	Model improved!!!
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7171651657321153		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.7171651657321153 | validation: 0.363429956572289]
	TIME [epoch: 6.29 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7274884672470794		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.7274884672470794 | validation: 0.39658578630996566]
	TIME [epoch: 6.29 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7277316120773245		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.7277316120773245 | validation: 0.37942230004553873]
	TIME [epoch: 6.28 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7438786445258015		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.7438786445258015 | validation: 0.3664253132526291]
	TIME [epoch: 6.33 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7161278336954224		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.7161278336954224 | validation: 0.3804046198259702]
	TIME [epoch: 6.29 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7380503430153351		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.7380503430153351 | validation: 0.3773477942729533]
	TIME [epoch: 6.28 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7447863699213971		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.7447863699213971 | validation: 0.4078207106568606]
	TIME [epoch: 6.29 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7242884274298063		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.7242884274298063 | validation: 0.3762624735430685]
	TIME [epoch: 6.28 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7267867581905763		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.7267867581905763 | validation: 0.4004068871187302]
	TIME [epoch: 6.29 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7464725487959072		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.7464725487959072 | validation: 0.3600923932234619]
	TIME [epoch: 6.33 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.736262064184964		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.736262064184964 | validation: 0.3840930532845706]
	TIME [epoch: 6.3 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.738045715952292		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.738045715952292 | validation: 0.4050926777186189]
	TIME [epoch: 6.28 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7245569718439856		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.7245569718439856 | validation: 0.4492722766331509]
	TIME [epoch: 6.29 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7382449999414697		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.7382449999414697 | validation: 0.37196075800866873]
	TIME [epoch: 6.28 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7165282053579098		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.7165282053579098 | validation: 0.405332967232425]
	TIME [epoch: 6.29 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7679085794793427		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.7679085794793427 | validation: 0.39708895597243155]
	TIME [epoch: 6.33 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7411629845629948		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.7411629845629948 | validation: 0.3797764833024348]
	TIME [epoch: 6.3 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.751499092694045		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.751499092694045 | validation: 0.3997171302987406]
	TIME [epoch: 6.28 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7195671994116313		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.7195671994116313 | validation: 0.39052742206711233]
	TIME [epoch: 6.28 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7519890098527173		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.7519890098527173 | validation: 0.43407423169696313]
	TIME [epoch: 6.28 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8386412205746557		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.8386412205746557 | validation: 0.3818510754337716]
	TIME [epoch: 6.29 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7235875113481415		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.7235875113481415 | validation: 0.3926390747727976]
	TIME [epoch: 6.32 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7317603808711153		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.7317603808711153 | validation: 0.5150312799268375]
	TIME [epoch: 6.28 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7678341987551467		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.7678341987551467 | validation: 0.36000609765709124]
	TIME [epoch: 6.28 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7092929145041609		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.7092929145041609 | validation: 0.36237140438364335]
	TIME [epoch: 6.28 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7069574121518712		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.7069574121518712 | validation: 0.3806790271618171]
	TIME [epoch: 6.28 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.718547842509049		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.718547842509049 | validation: 0.36179475415841594]
	TIME [epoch: 6.28 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7143421763691831		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.7143421763691831 | validation: 0.41903012889397406]
	TIME [epoch: 6.33 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7367182571979117		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.7367182571979117 | validation: 0.41229167145446866]
	TIME [epoch: 6.29 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7322478223540991		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.7322478223540991 | validation: 0.4054737966145859]
	TIME [epoch: 6.28 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7332663055282048		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.7332663055282048 | validation: 0.38466309550157407]
	TIME [epoch: 6.31 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.766894500043902		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.766894500043902 | validation: 0.38214652639966873]
	TIME [epoch: 6.28 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7394383101457027		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.7394383101457027 | validation: 0.4023478597816417]
	TIME [epoch: 6.28 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7211966171948817		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.7211966171948817 | validation: 0.36825749233100025]
	TIME [epoch: 6.33 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7268686237344015		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.7268686237344015 | validation: 0.3699209951675983]
	TIME [epoch: 6.29 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.747834411744135		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.747834411744135 | validation: 0.43096029049315426]
	TIME [epoch: 6.29 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7423941336361506		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.7423941336361506 | validation: 0.36397246339673955]
	TIME [epoch: 6.28 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7045702861962028		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.7045702861962028 | validation: 0.4082513089388575]
	TIME [epoch: 6.27 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7304038496799121		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.7304038496799121 | validation: 0.41866411399636905]
	TIME [epoch: 6.29 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7325124743350211		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.7325124743350211 | validation: 0.3780401625271558]
	TIME [epoch: 6.31 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.712644752120286		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.712644752120286 | validation: 0.3679352686248429]
	TIME [epoch: 6.28 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7190257930787426		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.7190257930787426 | validation: 0.35788739898355987]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_373.pth
	Model improved!!!
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7134003468520911		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.7134003468520911 | validation: 0.37719214780349714]
	TIME [epoch: 6.29 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7254450121220241		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.7254450121220241 | validation: 0.3708672679829981]
	TIME [epoch: 6.28 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7271118603208242		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.7271118603208242 | validation: 0.3701729770536248]
	TIME [epoch: 6.29 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7407782238887284		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.7407782238887284 | validation: 0.43519620327827063]
	TIME [epoch: 6.32 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7218043323183225		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.7218043323183225 | validation: 0.37541101342862027]
	TIME [epoch: 6.28 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.712172246230187		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.712172246230187 | validation: 0.3699797377108024]
	TIME [epoch: 6.29 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7082366946553283		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.7082366946553283 | validation: 0.40630732284126597]
	TIME [epoch: 6.29 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7223313834855376		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.7223313834855376 | validation: 0.44992186725851385]
	TIME [epoch: 6.29 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7561229641205367		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.7561229641205367 | validation: 0.4108805329606234]
	TIME [epoch: 6.31 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7555341726964464		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.7555341726964464 | validation: 0.4679492464584906]
	TIME [epoch: 6.33 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7470420491489662		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.7470420491489662 | validation: 0.37165932692686887]
	TIME [epoch: 6.29 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.717459364142535		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.717459364142535 | validation: 0.3862039628765138]
	TIME [epoch: 6.29 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7531688498167686		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.7531688498167686 | validation: 0.39863781188296477]
	TIME [epoch: 6.29 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7245642399532701		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.7245642399532701 | validation: 0.3876130516560194]
	TIME [epoch: 6.29 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7097407216533673		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.7097407216533673 | validation: 0.3973993958717714]
	TIME [epoch: 6.31 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7357032132715454		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.7357032132715454 | validation: 0.39120641628598546]
	TIME [epoch: 6.33 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7138241561093042		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.7138241561093042 | validation: 0.4088844119411885]
	TIME [epoch: 6.3 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7437126909393876		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.7437126909393876 | validation: 0.40642270204918757]
	TIME [epoch: 6.3 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7250632019278802		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.7250632019278802 | validation: 0.3795319058220552]
	TIME [epoch: 6.29 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7324638426839752		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.7324638426839752 | validation: 0.394134398670765]
	TIME [epoch: 6.28 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7167742032460767		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.7167742032460767 | validation: 0.3897690523583367]
	TIME [epoch: 6.32 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7343858044514693		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.7343858044514693 | validation: 0.426892791217285]
	TIME [epoch: 6.36 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7332720008422431		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.7332720008422431 | validation: 0.3888917194094731]
	TIME [epoch: 6.28 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7195477127877066		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.7195477127877066 | validation: 0.34980703969473853]
	TIME [epoch: 6.28 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_397.pth
	Model improved!!!
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7076616376987243		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.7076616376987243 | validation: 0.3530639276173031]
	TIME [epoch: 6.28 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7270850022870458		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.7270850022870458 | validation: 0.3658676624294832]
	TIME [epoch: 6.28 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7077575044041352		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.7077575044041352 | validation: 0.3752704828665805]
	TIME [epoch: 6.32 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7299679114452409		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.7299679114452409 | validation: 0.360130206063719]
	TIME [epoch: 6.28 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7116621859030434		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.7116621859030434 | validation: 0.3641243115473563]
	TIME [epoch: 6.28 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7064263515583339		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.7064263515583339 | validation: 0.3656102848009631]
	TIME [epoch: 6.27 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7090071546569625		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.7090071546569625 | validation: 0.3908876672950125]
	TIME [epoch: 6.28 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7240018286273012		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.7240018286273012 | validation: 0.380877986975137]
	TIME [epoch: 6.3 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7249580608866588		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.7249580608866588 | validation: 0.4041424043925849]
	TIME [epoch: 6.33 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7185295182264884		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.7185295182264884 | validation: 0.37397160440067967]
	TIME [epoch: 6.3 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7108686587775964		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.7108686587775964 | validation: 0.3830484598406804]
	TIME [epoch: 6.28 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7270526361371035		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.7270526361371035 | validation: 0.3626049874209642]
	TIME [epoch: 6.28 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7164214011850045		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.7164214011850045 | validation: 0.3646391042040473]
	TIME [epoch: 6.28 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7132174300687529		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.7132174300687529 | validation: 0.4651973817442004]
	TIME [epoch: 6.29 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7595816374555303		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.7595816374555303 | validation: 0.407425009646609]
	TIME [epoch: 6.32 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7366175199395095		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.7366175199395095 | validation: 0.35779019780890686]
	TIME [epoch: 6.29 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7068687189031452		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.7068687189031452 | validation: 0.36664065710181537]
	TIME [epoch: 6.28 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7084883837347691		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.7084883837347691 | validation: 0.44811706551398556]
	TIME [epoch: 6.29 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7369023228975217		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.7369023228975217 | validation: 0.36047097816688056]
	TIME [epoch: 6.29 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.707348829797391		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.707348829797391 | validation: 0.38846648583872195]
	TIME [epoch: 6.29 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.702734841381224		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.702734841381224 | validation: 0.3521744718362483]
	TIME [epoch: 6.33 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7124869927362151		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.7124869927362151 | validation: 0.42468940834128804]
	TIME [epoch: 6.31 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.725347338092074		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.725347338092074 | validation: 0.37164424575644106]
	TIME [epoch: 6.29 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7073457968756257		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.7073457968756257 | validation: 0.3703806681741781]
	TIME [epoch: 6.29 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7176808294731838		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.7176808294731838 | validation: 0.3733973791273487]
	TIME [epoch: 6.29 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7211998614186603		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.7211998614186603 | validation: 0.4199347417565553]
	TIME [epoch: 6.3 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7286537173660566		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.7286537173660566 | validation: 0.36558978775215023]
	TIME [epoch: 6.33 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7084496664714118		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.7084496664714118 | validation: 0.35367850156315384]
	TIME [epoch: 6.3 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7170863217277105		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.7170863217277105 | validation: 0.376243889128172]
	TIME [epoch: 6.29 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7022124464393529		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.7022124464393529 | validation: 0.3629625652782998]
	TIME [epoch: 6.29 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7072370452775367		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.7072370452775367 | validation: 0.38879566172487656]
	TIME [epoch: 6.3 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.719045394914374		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.719045394914374 | validation: 0.39956886829540633]
	TIME [epoch: 6.28 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7172029441724774		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.7172029441724774 | validation: 0.38115277664838015]
	TIME [epoch: 6.34 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7164049090447604		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.7164049090447604 | validation: 0.3837236387394509]
	TIME [epoch: 6.29 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7127428128550961		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.7127428128550961 | validation: 0.36882224130368824]
	TIME [epoch: 6.29 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7055528213412607		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.7055528213412607 | validation: 0.36349940884690646]
	TIME [epoch: 6.29 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7015890022818398		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.7015890022818398 | validation: 0.3874794983300189]
	TIME [epoch: 6.28 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7119511594787593		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.7119511594787593 | validation: 0.3888336710794082]
	TIME [epoch: 6.3 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7565861123698711		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.7565861123698711 | validation: 0.3803703939219831]
	TIME [epoch: 6.33 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7083444574524018		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.7083444574524018 | validation: 0.4187537574582031]
	TIME [epoch: 6.29 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7139751930978263		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.7139751930978263 | validation: 0.4087176881237475]
	TIME [epoch: 6.29 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7075730963725737		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.7075730963725737 | validation: 0.36776459408671713]
	TIME [epoch: 6.28 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7066696229146905		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.7066696229146905 | validation: 0.3728945172332619]
	TIME [epoch: 6.28 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7139262846279466		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.7139262846279466 | validation: 0.37488309009732945]
	TIME [epoch: 6.29 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7109277718852427		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.7109277718852427 | validation: 0.42211664292207657]
	TIME [epoch: 6.33 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7427430435310644		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.7427430435310644 | validation: 0.34799779680184234]
	TIME [epoch: 6.29 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_443.pth
	Model improved!!!
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7365104561252193		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.7365104561252193 | validation: 0.36163713445398155]
	TIME [epoch: 6.29 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7293430939134541		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.7293430939134541 | validation: 0.3973335638786494]
	TIME [epoch: 6.28 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7237420412941367		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.7237420412941367 | validation: 0.36094560047335034]
	TIME [epoch: 6.28 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7190615190599134		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.7190615190599134 | validation: 0.3590880652835289]
	TIME [epoch: 6.3 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7118619781909017		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.7118619781909017 | validation: 0.39605272028201954]
	TIME [epoch: 6.32 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7217620250657085		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.7217620250657085 | validation: 0.35996626496660405]
	TIME [epoch: 6.28 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7089271921755693		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.7089271921755693 | validation: 0.3824687046177909]
	TIME [epoch: 6.29 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7195180038701696		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.7195180038701696 | validation: 0.4239315110537849]
	TIME [epoch: 6.29 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7253785773256541		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.7253785773256541 | validation: 0.42051382845647944]
	TIME [epoch: 6.28 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7292250438348057		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.7292250438348057 | validation: 0.3905008805468526]
	TIME [epoch: 6.29 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7313489916799264		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.7313489916799264 | validation: 0.35530007625322213]
	TIME [epoch: 6.32 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7029132252786041		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.7029132252786041 | validation: 0.3519610557864505]
	TIME [epoch: 6.29 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7080531571264466		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.7080531571264466 | validation: 0.3506065168660279]
	TIME [epoch: 6.29 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.708555708892531		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.708555708892531 | validation: 0.35964713431858475]
	TIME [epoch: 6.29 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7317479912604476		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.7317479912604476 | validation: 0.349234791378358]
	TIME [epoch: 6.28 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7178174636532976		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.7178174636532976 | validation: 0.36948328889455356]
	TIME [epoch: 6.32 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.731977039715596		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.731977039715596 | validation: 0.4162795754383502]
	TIME [epoch: 6.31 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7310990525624588		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.7310990525624588 | validation: 0.35690740224193435]
	TIME [epoch: 6.29 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.706774244969069		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.706774244969069 | validation: 0.38971119686609335]
	TIME [epoch: 6.28 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7132730099588095		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.7132730099588095 | validation: 0.40183479423032586]
	TIME [epoch: 6.29 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7106437375006152		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.7106437375006152 | validation: 0.36176487601622775]
	TIME [epoch: 6.28 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7032539966438063		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.7032539966438063 | validation: 0.3416994756876626]
	TIME [epoch: 6.32 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_465.pth
	Model improved!!!
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7085175912143982		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.7085175912143982 | validation: 0.3595731581669458]
	TIME [epoch: 6.32 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7021036218458321		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.7021036218458321 | validation: 0.34223647167164245]
	TIME [epoch: 6.29 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7082829567120285		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.7082829567120285 | validation: 0.3622789127976115]
	TIME [epoch: 6.27 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7090848602967997		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.7090848602967997 | validation: 0.38382092610586804]
	TIME [epoch: 6.29 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7112703925611807		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.7112703925611807 | validation: 0.34306965122932076]
	TIME [epoch: 6.28 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6934684147043935		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.6934684147043935 | validation: 0.3544879175197078]
	TIME [epoch: 6.32 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7042183783260442		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.7042183783260442 | validation: 0.40628298053683115]
	TIME [epoch: 6.31 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7299071230687457		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.7299071230687457 | validation: 0.3609156627725751]
	TIME [epoch: 6.28 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7008971213180246		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.7008971213180246 | validation: 0.35856311008940994]
	TIME [epoch: 6.28 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7157833409131703		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.7157833409131703 | validation: 0.370122893097942]
	TIME [epoch: 6.28 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7134891859264533		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.7134891859264533 | validation: 0.40437263037762555]
	TIME [epoch: 6.28 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7111194916910494		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.7111194916910494 | validation: 0.35686725058898683]
	TIME [epoch: 6.33 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6984726911676808		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.6984726911676808 | validation: 0.3948337222121524]
	TIME [epoch: 6.29 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7045632914345978		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.7045632914345978 | validation: 0.3514960548050162]
	TIME [epoch: 6.29 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6957842056774842		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.6957842056774842 | validation: 0.3622896455471165]
	TIME [epoch: 6.29 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7037415781225136		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.7037415781225136 | validation: 0.388980350751666]
	TIME [epoch: 6.3 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7464255733334043		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.7464255733334043 | validation: 0.3789559151955476]
	TIME [epoch: 6.29 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7227780470360973		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.7227780470360973 | validation: 0.38379192377628185]
	TIME [epoch: 6.34 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7340829472048961		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.7340829472048961 | validation: 0.4029634910741594]
	TIME [epoch: 6.3 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7227043897541219		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.7227043897541219 | validation: 0.369747159504837]
	TIME [epoch: 6.3 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7053504855842976		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.7053504855842976 | validation: 0.36661387476048424]
	TIME [epoch: 6.29 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7109434207263898		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.7109434207263898 | validation: 0.3881904573459563]
	TIME [epoch: 6.28 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7403144662679307		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.7403144662679307 | validation: 0.35794766625282154]
	TIME [epoch: 6.29 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7331791337965247		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.7331791337965247 | validation: 0.3652318481398882]
	TIME [epoch: 6.34 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6978397333995542		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.6978397333995542 | validation: 0.3468158730743022]
	TIME [epoch: 6.3 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7030115647087305		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.7030115647087305 | validation: 0.38505428404246095]
	TIME [epoch: 6.29 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7095658940795749		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.7095658940795749 | validation: 0.3998266481001364]
	TIME [epoch: 6.29 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7067612579814773		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.7067612579814773 | validation: 0.3609211957294615]
	TIME [epoch: 6.29 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7471552503879431		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.7471552503879431 | validation: 0.38030494120332503]
	TIME [epoch: 6.29 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7592541088873915		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.7592541088873915 | validation: 0.5357788626446774]
	TIME [epoch: 6.34 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7606911993222969		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.7606911993222969 | validation: 0.3692845843674889]
	TIME [epoch: 6.3 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7239776790188928		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.7239776790188928 | validation: 0.393198485321408]
	TIME [epoch: 6.29 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7074295577982618		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.7074295577982618 | validation: 0.36562139450518466]
	TIME [epoch: 6.3 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7067240351570103		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.7067240351570103 | validation: 0.3820878446283045]
	TIME [epoch: 6.28 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.722672835601073		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.722672835601073 | validation: 0.351851401435959]
	TIME [epoch: 6.29 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6947072526214448		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.6947072526214448 | validation: 0.3613555525650466]
	TIME [epoch: 6.34 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6986502727702636		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.6986502727702636 | validation: 0.3529531303223613]
	TIME [epoch: 6.3 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.691597673222633		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.691597673222633 | validation: 0.35443992790638235]
	TIME [epoch: 6.28 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7140851136098575		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.7140851136098575 | validation: 0.3748213556038549]
	TIME [epoch: 6.29 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7137484539453317		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.7137484539453317 | validation: 0.3666510167855416]
	TIME [epoch: 6.29 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7083787022650812		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.7083787022650812 | validation: 0.3478359846843185]
	TIME [epoch: 6.28 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6982513607534515		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.6982513607534515 | validation: 0.4012829458530465]
	TIME [epoch: 6.34 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7300291310402716		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.7300291310402716 | validation: 0.4519589563906366]
	TIME [epoch: 6.29 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7278429233747974		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.7278429233747974 | validation: 0.35852889931449794]
	TIME [epoch: 6.28 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.763435331908866		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.763435331908866 | validation: 0.3824359025110673]
	TIME [epoch: 6.28 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7230474407573586		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.7230474407573586 | validation: 0.3676247766617242]
	TIME [epoch: 6.28 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7159865276209121		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.7159865276209121 | validation: 0.3581488981238516]
	TIME [epoch: 6.28 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7239838894177872		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.7239838894177872 | validation: 0.38361910484527284]
	TIME [epoch: 6.33 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7149697289150659		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.7149697289150659 | validation: 0.3771570165705669]
	TIME [epoch: 6.28 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7165801323421482		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.7165801323421482 | validation: 0.4185381570893477]
	TIME [epoch: 6.29 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7241678675910485		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.7241678675910485 | validation: 0.35371947706965884]
	TIME [epoch: 6.29 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7043722957345206		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.7043722957345206 | validation: 0.3730582873150651]
	TIME [epoch: 6.29 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7034453954043113		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.7034453954043113 | validation: 0.3633947683389419]
	TIME [epoch: 6.31 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7083660618278536		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.7083660618278536 | validation: 0.3551270390630009]
	TIME [epoch: 6.33 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.696531996466271		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.696531996466271 | validation: 0.3543497689018972]
	TIME [epoch: 6.28 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7099722357263588		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.7099722357263588 | validation: 0.33775737011335233]
	TIME [epoch: 6.28 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_521.pth
	Model improved!!!
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6931813900219981		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.6931813900219981 | validation: 0.37374941801795997]
	TIME [epoch: 6.29 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.699706882781638		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.699706882781638 | validation: 0.3589985346783128]
	TIME [epoch: 6.29 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7011749121277135		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.7011749121277135 | validation: 0.3526201972186233]
	TIME [epoch: 6.31 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6992691752415839		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.6992691752415839 | validation: 0.3625171440856457]
	TIME [epoch: 6.33 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.696988352227647		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.696988352227647 | validation: 0.362053911221356]
	TIME [epoch: 6.3 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7007547352799887		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.7007547352799887 | validation: 0.34369422575129055]
	TIME [epoch: 6.3 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7091573637489368		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.7091573637489368 | validation: 0.35941448836339984]
	TIME [epoch: 6.29 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7047126077754644		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.7047126077754644 | validation: 0.35033490401468675]
	TIME [epoch: 6.29 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7049200280920636		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.7049200280920636 | validation: 0.353206716403572]
	TIME [epoch: 6.31 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7018426035214065		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.7018426035214065 | validation: 0.4156607225426351]
	TIME [epoch: 6.31 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7202942664198183		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.7202942664198183 | validation: 0.38897147774025503]
	TIME [epoch: 6.28 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7143527310263784		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.7143527310263784 | validation: 0.35648427205243716]
	TIME [epoch: 6.28 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.705468309015294		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.705468309015294 | validation: 0.37368905697064897]
	TIME [epoch: 6.28 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7058483300151145		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.7058483300151145 | validation: 0.38617991793293127]
	TIME [epoch: 6.29 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7054582030887933		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.7054582030887933 | validation: 0.34986201262925587]
	TIME [epoch: 6.31 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.702463479377068		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.702463479377068 | validation: 0.3680537803769082]
	TIME [epoch: 6.31 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7157544182811648		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.7157544182811648 | validation: 0.35281209114376044]
	TIME [epoch: 6.29 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.70415127984636		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.70415127984636 | validation: 0.3455710435572526]
	TIME [epoch: 6.29 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6974472490465704		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.6974472490465704 | validation: 0.3575317523900584]
	TIME [epoch: 6.29 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6999376059556175		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.6999376059556175 | validation: 0.3536693668906079]
	TIME [epoch: 6.28 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7049946737242165		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.7049946737242165 | validation: 0.3852409751046975]
	TIME [epoch: 6.32 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7028365741874489		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.7028365741874489 | validation: 0.34794600926244856]
	TIME [epoch: 6.32 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6949146348632935		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.6949146348632935 | validation: 0.33062170172947897]
	TIME [epoch: 6.29 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_544.pth
	Model improved!!!
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6998041689868906		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.6998041689868906 | validation: 0.35491062536533946]
	TIME [epoch: 6.29 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.711235819111024		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.711235819111024 | validation: 0.3535747968678912]
	TIME [epoch: 6.28 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7011097180582163		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.7011097180582163 | validation: 0.360712765588939]
	TIME [epoch: 6.28 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6994943474603189		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.6994943474603189 | validation: 0.3682808061243434]
	TIME [epoch: 6.33 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7101204312310327		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.7101204312310327 | validation: 0.3568661866882332]
	TIME [epoch: 6.29 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6995871333141845		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.6995871333141845 | validation: 0.3508364602498874]
	TIME [epoch: 6.29 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.69438241787507		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.69438241787507 | validation: 0.36190741859084063]
	TIME [epoch: 6.28 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7315678333925257		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.7315678333925257 | validation: 0.374238675983221]
	TIME [epoch: 6.28 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7229303901767863		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.7229303901767863 | validation: 0.41279433415461253]
	TIME [epoch: 6.28 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7306418955068696		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.7306418955068696 | validation: 0.37124540344553075]
	TIME [epoch: 6.32 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7039545315196634		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.7039545315196634 | validation: 0.3460890901203858]
	TIME [epoch: 6.29 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7036873432671831		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.7036873432671831 | validation: 0.349738593300838]
	TIME [epoch: 6.28 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.692269332486768		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.692269332486768 | validation: 0.35648335058773695]
	TIME [epoch: 6.29 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6990014257532494		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.6990014257532494 | validation: 0.348024245035592]
	TIME [epoch: 6.29 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7038307801238721		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.7038307801238721 | validation: 0.3591157248896775]
	TIME [epoch: 6.29 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7020023164776146		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.7020023164776146 | validation: 0.38281207012934954]
	TIME [epoch: 6.33 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7028536411125861		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.7028536411125861 | validation: 0.39292081687165964]
	TIME [epoch: 6.29 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7068249676355514		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.7068249676355514 | validation: 0.3452066189807447]
	TIME [epoch: 6.29 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6874832078209085		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.6874832078209085 | validation: 0.3630725554656402]
	TIME [epoch: 6.29 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7022798414908531		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.7022798414908531 | validation: 0.3630108341156481]
	TIME [epoch: 6.28 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.729520900665923		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.729520900665923 | validation: 0.3575475256013992]
	TIME [epoch: 6.29 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.695035303411057		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.695035303411057 | validation: 0.3422543185379239]
	TIME [epoch: 6.35 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6935225059957576		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.6935225059957576 | validation: 0.3531288701409762]
	TIME [epoch: 6.28 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6953367103570453		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.6953367103570453 | validation: 0.3559288174894879]
	TIME [epoch: 6.29 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7118649035137878		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.7118649035137878 | validation: 0.34021662661096674]
	TIME [epoch: 6.28 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6986829243964999		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.6986829243964999 | validation: 0.38799489505740414]
	TIME [epoch: 6.29 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7122722097754083		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.7122722097754083 | validation: 0.3645855208406873]
	TIME [epoch: 6.29 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6996780544414519		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.6996780544414519 | validation: 0.35637548376352524]
	TIME [epoch: 6.34 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6956937009262744		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.6956937009262744 | validation: 0.34407995284942716]
	TIME [epoch: 6.3 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6966639232356848		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.6966639232356848 | validation: 0.3603618281407106]
	TIME [epoch: 6.3 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6971674504160378		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.6971674504160378 | validation: 0.36389203585225943]
	TIME [epoch: 6.29 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6929611417098606		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.6929611417098606 | validation: 0.3361278416681232]
	TIME [epoch: 6.29 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6957373397559807		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.6957373397559807 | validation: 0.3488655227879648]
	TIME [epoch: 6.29 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6938383524907361		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.6938383524907361 | validation: 0.3889562332042646]
	TIME [epoch: 6.34 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7203451536556387		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.7203451536556387 | validation: 0.3495701542269126]
	TIME [epoch: 6.31 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7057838404269688		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.7057838404269688 | validation: 0.3712940650268762]
	TIME [epoch: 6.3 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.714946874959169		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.714946874959169 | validation: 0.3769802187276227]
	TIME [epoch: 6.3 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7013945992893148		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.7013945992893148 | validation: 0.34979434345153526]
	TIME [epoch: 6.3 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6999381821339903		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.6999381821339903 | validation: 0.38102610483333976]
	TIME [epoch: 6.31 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7040095442949241		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.7040095442949241 | validation: 0.3528449837140542]
	TIME [epoch: 6.34 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7004485391186083		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.7004485391186083 | validation: 0.36117512000875734]
	TIME [epoch: 6.3 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7020808946010864		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.7020808946010864 | validation: 0.35178502899163827]
	TIME [epoch: 6.3 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6905148212401632		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.6905148212401632 | validation: 0.34199650106492385]
	TIME [epoch: 6.29 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6919928037749719		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.6919928037749719 | validation: 0.3578359307945258]
	TIME [epoch: 6.3 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6945262922187879		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.6945262922187879 | validation: 0.3535854101244499]
	TIME [epoch: 6.31 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6876574404405795		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.6876574404405795 | validation: 0.3419408019538814]
	TIME [epoch: 6.34 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7019372391836407		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.7019372391836407 | validation: 0.37062039604687136]
	TIME [epoch: 6.29 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7048702972621791		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.7048702972621791 | validation: 0.3552157734184662]
	TIME [epoch: 6.29 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6981692768001276		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.6981692768001276 | validation: 0.3747191835280474]
	TIME [epoch: 6.3 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6955335402668982		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.6955335402668982 | validation: 0.3512255636198301]
	TIME [epoch: 6.29 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6930324703109965		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.6930324703109965 | validation: 0.34478242203330395]
	TIME [epoch: 6.32 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6938047476246774		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.6938047476246774 | validation: 0.35534529636294926]
	TIME [epoch: 6.34 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.712680711736752		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.712680711736752 | validation: 0.3490707230797068]
	TIME [epoch: 6.3 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6998811805203717		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.6998811805203717 | validation: 0.3755446514960015]
	TIME [epoch: 6.3 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7069545873312416		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.7069545873312416 | validation: 0.3587311578554456]
	TIME [epoch: 6.31 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6931359690271262		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.6931359690271262 | validation: 0.35693270869119037]
	TIME [epoch: 6.3 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7036081402392574		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.7036081402392574 | validation: 0.36728919999803133]
	TIME [epoch: 6.32 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6973537193137054		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.6973537193137054 | validation: 0.35406147771938645]
	TIME [epoch: 6.34 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7032103178020375		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.7032103178020375 | validation: 0.3527685656514183]
	TIME [epoch: 6.3 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7028201532250018		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.7028201532250018 | validation: 0.3521999963158285]
	TIME [epoch: 6.3 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.701500980325622		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.701500980325622 | validation: 0.3770520104685696]
	TIME [epoch: 6.3 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6949353325356881		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.6949353325356881 | validation: 0.34345957546027994]
	TIME [epoch: 6.3 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6939218280054436		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.6939218280054436 | validation: 0.3600267818320769]
	TIME [epoch: 6.33 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6970270095130243		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.6970270095130243 | validation: 0.39069564139170154]
	TIME [epoch: 6.32 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7042977817909536		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.7042977817909536 | validation: 0.35700346682170564]
	TIME [epoch: 6.31 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7042258444352827		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.7042258444352827 | validation: 0.3674460860799398]
	TIME [epoch: 6.3 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7030992097511534		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.7030992097511534 | validation: 0.36664768163537537]
	TIME [epoch: 6.3 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7014724375970498		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.7014724375970498 | validation: 0.35840336828436775]
	TIME [epoch: 6.3 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6958776182125261		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.6958776182125261 | validation: 0.3424513759102715]
	TIME [epoch: 6.33 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7000977250457256		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.7000977250457256 | validation: 0.375969392710326]
	TIME [epoch: 6.33 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6933252354151305		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.6933252354151305 | validation: 0.34472159027755706]
	TIME [epoch: 6.29 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6947851924134117		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.6947851924134117 | validation: 0.36868503214548437]
	TIME [epoch: 6.3 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7032849973062192		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.7032849973062192 | validation: 0.34996949242186737]
	TIME [epoch: 6.3 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.698876877599122		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.698876877599122 | validation: 0.3645188928532963]
	TIME [epoch: 6.3 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6973770547910301		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.6973770547910301 | validation: 0.39421470102903133]
	TIME [epoch: 6.35 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.717483437477713		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.717483437477713 | validation: 0.3569418991445449]
	TIME [epoch: 6.31 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.693144925292885		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.693144925292885 | validation: 0.3571008950597669]
	TIME [epoch: 6.3 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6984747776994563		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.6984747776994563 | validation: 0.3601373781906772]
	TIME [epoch: 6.3 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6998930269061621		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.6998930269061621 | validation: 0.3531563570081213]
	TIME [epoch: 6.31 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6926565922037274		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.6926565922037274 | validation: 0.35637440001200227]
	TIME [epoch: 6.3 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7012190986163749		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.7012190986163749 | validation: 0.37995530898384616]
	TIME [epoch: 6.35 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.706625600750436		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.706625600750436 | validation: 0.3626580761696658]
	TIME [epoch: 6.3 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7196393083899314		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.7196393083899314 | validation: 0.36724957008776815]
	TIME [epoch: 6.3 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.702532501912781		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.702532501912781 | validation: 0.3621623072867405]
	TIME [epoch: 6.29 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6923438205024359		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.6923438205024359 | validation: 0.36417101225648063]
	TIME [epoch: 6.29 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7050308501593823		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.7050308501593823 | validation: 0.3598692654792134]
	TIME [epoch: 6.29 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7067463487967952		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.7067463487967952 | validation: 0.36076126863314845]
	TIME [epoch: 6.35 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7001679447176147		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.7001679447176147 | validation: 0.36974195876743743]
	TIME [epoch: 6.31 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.727091864891035		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.727091864891035 | validation: 0.36899541667392005]
	TIME [epoch: 6.29 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6920085315083341		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.6920085315083341 | validation: 0.34428730424305753]
	TIME [epoch: 6.29 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6978944225314966		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.6978944225314966 | validation: 0.34717661642958164]
	TIME [epoch: 6.29 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6875343198516377		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.6875343198516377 | validation: 0.3557520727509798]
	TIME [epoch: 6.29 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6963928722652731		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.6963928722652731 | validation: 0.35242052898943627]
	TIME [epoch: 6.34 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7013191396212256		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.7013191396212256 | validation: 0.3494625927495924]
	TIME [epoch: 6.31 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6958028841086998		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.6958028841086998 | validation: 0.3498795591470691]
	TIME [epoch: 6.29 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6893956666764611		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.6893956666764611 | validation: 0.35476556042303764]
	TIME [epoch: 6.29 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6992640209640899		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.6992640209640899 | validation: 0.3377684715060667]
	TIME [epoch: 6.29 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6885893993987968		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.6885893993987968 | validation: 0.3627469354684898]
	TIME [epoch: 6.29 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.697965180517627		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.697965180517627 | validation: 0.3568108267602579]
	TIME [epoch: 6.35 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6978034479763686		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.6978034479763686 | validation: 0.3397010306020724]
	TIME [epoch: 6.31 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.702122175080156		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.702122175080156 | validation: 0.3627823416181768]
	TIME [epoch: 6.29 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7088169606576401		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.7088169606576401 | validation: 0.34669172341418775]
	TIME [epoch: 6.3 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6918852663945315		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.6918852663945315 | validation: 0.35466768376055974]
	TIME [epoch: 6.29 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7030418174608369		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.7030418174608369 | validation: 0.35500815990062345]
	TIME [epoch: 6.3 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7296153129091757		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.7296153129091757 | validation: 0.3681618589644304]
	TIME [epoch: 6.35 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7042916997749441		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.7042916997749441 | validation: 0.3388315360287194]
	TIME [epoch: 6.3 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6899483909202455		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.6899483909202455 | validation: 0.3639347210910112]
	TIME [epoch: 6.29 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6974586568088909		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.6974586568088909 | validation: 0.3391838359890061]
	TIME [epoch: 6.29 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7073878098966921		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.7073878098966921 | validation: 0.38235104468420406]
	TIME [epoch: 6.29 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6970916589739478		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.6970916589739478 | validation: 0.3434168973684159]
	TIME [epoch: 6.3 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6965101536539067		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.6965101536539067 | validation: 0.3545489340102281]
	TIME [epoch: 6.34 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7014521929467794		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.7014521929467794 | validation: 0.34675711064225584]
	TIME [epoch: 6.29 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7012317953648263		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.7012317953648263 | validation: 0.34850395975608495]
	TIME [epoch: 6.3 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6861472375451859		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.6861472375451859 | validation: 0.360584924122768]
	TIME [epoch: 6.29 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6916631649294325		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.6916631649294325 | validation: 0.36712590196770245]
	TIME [epoch: 6.3 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.700701537976397		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.700701537976397 | validation: 0.34964801473353935]
	TIME [epoch: 6.31 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.694467983403271		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.694467983403271 | validation: 0.3868743042279059]
	TIME [epoch: 6.34 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7014954928726994		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.7014954928726994 | validation: 0.36349023297459443]
	TIME [epoch: 6.3 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6985286230932211		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.6985286230932211 | validation: 0.3517926438784423]
	TIME [epoch: 6.3 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6956082369534193		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.6956082369534193 | validation: 0.3593554309709528]
	TIME [epoch: 6.3 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7044188813196917		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.7044188813196917 | validation: 0.36023665686014417]
	TIME [epoch: 6.3 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7049784122903433		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.7049784122903433 | validation: 0.35230283204026575]
	TIME [epoch: 6.3 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6911514954259622		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.6911514954259622 | validation: 0.3496136254061758]
	TIME [epoch: 6.34 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6914833830038531		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.6914833830038531 | validation: 0.35143200980577505]
	TIME [epoch: 6.3 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6938246101474476		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.6938246101474476 | validation: 0.3583504188270784]
	TIME [epoch: 6.29 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6961832947927453		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.6961832947927453 | validation: 0.3565039336948366]
	TIME [epoch: 6.29 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7141314137563288		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.7141314137563288 | validation: 0.416808412845909]
	TIME [epoch: 6.29 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7279212252237275		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.7279212252237275 | validation: 0.34987102884851906]
	TIME [epoch: 6.31 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6975427793828586		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.6975427793828586 | validation: 0.36467333111852396]
	TIME [epoch: 6.33 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.710331455335047		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.710331455335047 | validation: 0.35564335671809877]
	TIME [epoch: 6.29 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6920380695791218		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.6920380695791218 | validation: 0.3828284506142028]
	TIME [epoch: 6.3 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6990106040812345		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.6990106040812345 | validation: 0.3568533223862814]
	TIME [epoch: 6.3 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7030561993192672		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.7030561993192672 | validation: 0.3802345268528438]
	TIME [epoch: 6.3 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7030537081459615		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.7030537081459615 | validation: 0.35677775018071856]
	TIME [epoch: 6.32 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7082638370096818		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.7082638370096818 | validation: 0.3513433283388415]
	TIME [epoch: 6.33 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6934966618998353		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.6934966618998353 | validation: 0.3597181492989901]
	TIME [epoch: 6.59 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6916593493083171		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.6916593493083171 | validation: 0.35447670508635676]
	TIME [epoch: 6.28 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6947918288863011		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.6947918288863011 | validation: 0.3525065287152261]
	TIME [epoch: 6.29 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6952006231050974		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.6952006231050974 | validation: 0.3569224952003414]
	TIME [epoch: 6.28 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.693993841899559		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.693993841899559 | validation: 0.35233853136620824]
	TIME [epoch: 6.31 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6986408615798401		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.6986408615798401 | validation: 0.34948395097007967]
	TIME [epoch: 6.3 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7247143766446699		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.7247143766446699 | validation: 0.35370871082190664]
	TIME [epoch: 6.29 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6951033318172647		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.6951033318172647 | validation: 0.3552207620591431]
	TIME [epoch: 6.28 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6910244379700909		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.6910244379700909 | validation: 0.34704078764034074]
	TIME [epoch: 6.28 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6893619129796894		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.6893619129796894 | validation: 0.35522315858070125]
	TIME [epoch: 6.28 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.698692625711077		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.698692625711077 | validation: 0.35586865190396877]
	TIME [epoch: 6.33 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7129333989427478		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.7129333989427478 | validation: 0.3769504253702216]
	TIME [epoch: 6.29 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7023853261934837		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.7023853261934837 | validation: 0.35855152841268456]
	TIME [epoch: 6.28 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.70007866230795		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.70007866230795 | validation: 0.35242625627297175]
	TIME [epoch: 6.28 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6952120735599171		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.6952120735599171 | validation: 0.3692054016066894]
	TIME [epoch: 6.28 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7022837376017504		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.7022837376017504 | validation: 0.35892550668000495]
	TIME [epoch: 6.28 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6994855314445866		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.6994855314445866 | validation: 0.3500799262876795]
	TIME [epoch: 6.32 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6876988586213583		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.6876988586213583 | validation: 0.34410484357612475]
	TIME [epoch: 6.29 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6909677360480999		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.6909677360480999 | validation: 0.35243365030204593]
	TIME [epoch: 6.28 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6958045808626236		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.6958045808626236 | validation: 0.3517581893729934]
	TIME [epoch: 6.27 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7118058789045083		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.7118058789045083 | validation: 0.3570880933466194]
	TIME [epoch: 6.28 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6974458473713752		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.6974458473713752 | validation: 0.3658659835337419]
	TIME [epoch: 6.28 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6932855034668071		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.6932855034668071 | validation: 0.346146951900331]
	TIME [epoch: 6.32 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6938142105483315		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.6938142105483315 | validation: 0.3453194542127184]
	TIME [epoch: 6.28 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6924061389455609		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.6924061389455609 | validation: 0.3532943001334312]
	TIME [epoch: 6.27 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6942030934736971		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.6942030934736971 | validation: 0.3595385611252257]
	TIME [epoch: 6.27 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7108927961634643		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.7108927961634643 | validation: 0.3976377088726493]
	TIME [epoch: 6.27 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.707962299150276		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.707962299150276 | validation: 0.3583580580851866]
	TIME [epoch: 6.27 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.69024347666089		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.69024347666089 | validation: 0.34408382320322567]
	TIME [epoch: 6.31 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6931213778523129		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.6931213778523129 | validation: 0.3750636798559107]
	TIME [epoch: 6.28 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7086918351699091		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.7086918351699091 | validation: 0.3454465815655297]
	TIME [epoch: 6.27 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.690433035820136		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.690433035820136 | validation: 0.3461296129443806]
	TIME [epoch: 6.27 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7004080099668091		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.7004080099668091 | validation: 0.37815921333684566]
	TIME [epoch: 6.26 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6956578028508734		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.6956578028508734 | validation: 0.3685840871353705]
	TIME [epoch: 6.27 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6937493591470696		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.6937493591470696 | validation: 0.35241827116241]
	TIME [epoch: 6.32 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6894778453658397		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.6894778453658397 | validation: 0.34840989525150773]
	TIME [epoch: 6.27 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6917315358941419		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.6917315358941419 | validation: 0.3450651593318064]
	TIME [epoch: 6.27 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6916865043448398		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.6916865043448398 | validation: 0.35012484894337104]
	TIME [epoch: 6.27 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6916117532252481		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.6916117532252481 | validation: 0.3615680385346658]
	TIME [epoch: 6.27 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7042452092288689		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.7042452092288689 | validation: 0.35192767427991767]
	TIME [epoch: 6.27 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.690621405083058		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.690621405083058 | validation: 0.347103413081797]
	TIME [epoch: 6.32 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6923460366691803		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.6923460366691803 | validation: 0.3606142855553618]
	TIME [epoch: 6.28 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6990029785929744		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.6990029785929744 | validation: 0.3617287487276753]
	TIME [epoch: 6.28 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6960742916768279		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.6960742916768279 | validation: 0.34924468971402206]
	TIME [epoch: 6.27 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6966176407875141		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.6966176407875141 | validation: 0.37329759798867446]
	TIME [epoch: 6.29 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6968534244983189		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.6968534244983189 | validation: 0.3504331689575293]
	TIME [epoch: 6.29 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6989869830519143		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.6989869830519143 | validation: 0.35852126054731837]
	TIME [epoch: 6.33 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6944648064472734		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.6944648064472734 | validation: 0.35649092940790966]
	TIME [epoch: 6.29 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6937929156447342		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.6937929156447342 | validation: 0.3396966741982897]
	TIME [epoch: 6.29 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6875966882620851		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.6875966882620851 | validation: 0.3504814012769905]
	TIME [epoch: 6.28 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.694539438842628		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.694539438842628 | validation: 0.35751885796399074]
	TIME [epoch: 6.29 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6914653933686454		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.6914653933686454 | validation: 0.3573468674005165]
	TIME [epoch: 6.29 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6958321389324452		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.6958321389324452 | validation: 0.36593329911355016]
	TIME [epoch: 6.33 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6980152583526764		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.6980152583526764 | validation: 0.3502593969343601]
	TIME [epoch: 6.29 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7031478369063128		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.7031478369063128 | validation: 0.35615850437511043]
	TIME [epoch: 6.29 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6999668357874623		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.6999668357874623 | validation: 0.357584851867247]
	TIME [epoch: 6.29 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6967682434883969		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.6967682434883969 | validation: 0.3562047619240869]
	TIME [epoch: 6.29 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7010579296362538		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.7010579296362538 | validation: 0.3542696401034262]
	TIME [epoch: 6.29 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7034489590399848		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.7034489590399848 | validation: 0.34151520134019275]
	TIME [epoch: 6.33 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.692594937069891		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.692594937069891 | validation: 0.35877011004769704]
	TIME [epoch: 6.29 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7048251774711662		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.7048251774711662 | validation: 0.37191423902814463]
	TIME [epoch: 6.29 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6979325218940026		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.6979325218940026 | validation: 0.3544139992268919]
	TIME [epoch: 6.28 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6947949635796269		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.6947949635796269 | validation: 0.36692915696325157]
	TIME [epoch: 6.29 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6883020004288829		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.6883020004288829 | validation: 0.3428865680019624]
	TIME [epoch: 6.3 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6909774970655448		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.6909774970655448 | validation: 0.3520773833772055]
	TIME [epoch: 6.32 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.69271355364084		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.69271355364084 | validation: 0.3509623816630997]
	TIME [epoch: 6.28 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6943349919051378		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.6943349919051378 | validation: 0.34851839722757577]
	TIME [epoch: 6.29 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6976624376625666		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.6976624376625666 | validation: 0.3606933943102158]
	TIME [epoch: 6.28 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7005466401952304		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.7005466401952304 | validation: 0.349536234194732]
	TIME [epoch: 6.28 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6903214896188785		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.6903214896188785 | validation: 0.3570882480757747]
	TIME [epoch: 6.29 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.695163511108599		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.695163511108599 | validation: 0.34170470079969983]
	TIME [epoch: 6.32 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6943195047470336		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.6943195047470336 | validation: 0.35793290678619777]
	TIME [epoch: 6.29 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6974344916586885		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.6974344916586885 | validation: 0.3441514671305113]
	TIME [epoch: 6.29 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6904442198835525		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.6904442198835525 | validation: 0.3519715176503449]
	TIME [epoch: 6.29 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6953293057040142		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.6953293057040142 | validation: 0.356559500414206]
	TIME [epoch: 6.29 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6960630762847748		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.6960630762847748 | validation: 0.3812744197281468]
	TIME [epoch: 6.29 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7059033953680418		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.7059033953680418 | validation: 0.3498034419626265]
	TIME [epoch: 6.32 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6897650452475137		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.6897650452475137 | validation: 0.35209170867960304]
	TIME [epoch: 6.28 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6839843930316982		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.6839843930316982 | validation: 0.35061698791963986]
	TIME [epoch: 6.29 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6964042830313194		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.6964042830313194 | validation: 0.3483735170734198]
	TIME [epoch: 6.29 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6969720375301598		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.6969720375301598 | validation: 0.35356638543377816]
	TIME [epoch: 6.29 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7004594716841417		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.7004594716841417 | validation: 0.3393356436808207]
	TIME [epoch: 6.31 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6965410219578795		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.6965410219578795 | validation: 0.35434179975358154]
	TIME [epoch: 6.31 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6911945907618384		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.6911945907618384 | validation: 0.3499196811631903]
	TIME [epoch: 6.29 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6927825891435644		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.6927825891435644 | validation: 0.36655829619073554]
	TIME [epoch: 6.28 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6892967673706449		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.6892967673706449 | validation: 0.3590218467870417]
	TIME [epoch: 6.28 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6971547892863099		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.6971547892863099 | validation: 0.34929555993903355]
	TIME [epoch: 6.29 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6937606279405024		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.6937606279405024 | validation: 0.35482181981988253]
	TIME [epoch: 6.31 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6972470816333063		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.6972470816333063 | validation: 0.35549326688674165]
	TIME [epoch: 6.31 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6876197244500719		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.6876197244500719 | validation: 0.35137520063012906]
	TIME [epoch: 6.28 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6923654611535497		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.6923654611535497 | validation: 0.3543094303858939]
	TIME [epoch: 6.28 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6952866076963852		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.6952866076963852 | validation: 0.347448923216521]
	TIME [epoch: 6.28 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6921238973860077		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.6921238973860077 | validation: 0.34530050652617644]
	TIME [epoch: 6.28 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6900759698962292		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.6900759698962292 | validation: 0.34165677566515334]
	TIME [epoch: 6.31 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6840361052029391		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.6840361052029391 | validation: 0.36908099958531554]
	TIME [epoch: 6.3 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7015467675788837		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.7015467675788837 | validation: 0.34773548713448266]
	TIME [epoch: 6.29 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6862284754105062		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.6862284754105062 | validation: 0.3398140664888739]
	TIME [epoch: 6.28 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7046715987889703		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.7046715987889703 | validation: 0.3511113319008748]
	TIME [epoch: 6.28 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6918065667305494		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.6918065667305494 | validation: 0.34647070478050446]
	TIME [epoch: 6.28 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.689715506680458		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.689715506680458 | validation: 0.3377924255742429]
	TIME [epoch: 6.32 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6904647725572924		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.6904647725572924 | validation: 0.3597839172144948]
	TIME [epoch: 6.3 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6946270491425799		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.6946270491425799 | validation: 0.34483745071157335]
	TIME [epoch: 6.28 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6979971089839109		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.6979971089839109 | validation: 0.3740134951036782]
	TIME [epoch: 6.28 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6957938622151247		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.6957938622151247 | validation: 0.33932909118726606]
	TIME [epoch: 6.29 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6879458386247765		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.6879458386247765 | validation: 0.36057048085228144]
	TIME [epoch: 6.28 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.689474142158743		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.689474142158743 | validation: 0.3492405899892568]
	TIME [epoch: 6.32 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6866834173423452		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.6866834173423452 | validation: 0.3470948850014468]
	TIME [epoch: 6.29 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6878762443785101		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.6878762443785101 | validation: 0.3424322242500636]
	TIME [epoch: 6.28 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6877207703137014		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.6877207703137014 | validation: 0.34816510182351734]
	TIME [epoch: 6.28 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6937804240260712		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.6937804240260712 | validation: 0.35263834301817903]
	TIME [epoch: 6.28 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6878212120012498		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.6878212120012498 | validation: 0.34153110687474164]
	TIME [epoch: 6.29 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6877860369583768		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.6877860369583768 | validation: 0.3531515859350804]
	TIME [epoch: 6.32 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6871508394056647		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.6871508394056647 | validation: 0.3416750035930023]
	TIME [epoch: 6.29 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6926756241984509		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.6926756241984509 | validation: 0.3354707390093107]
	TIME [epoch: 6.28 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6906285347614959		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.6906285347614959 | validation: 0.3563048679299253]
	TIME [epoch: 6.28 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.695915090831641		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.695915090831641 | validation: 0.3506383229826213]
	TIME [epoch: 6.28 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6909669139721446		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.6909669139721446 | validation: 0.34343480004998794]
	TIME [epoch: 6.28 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6934800221362096		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.6934800221362096 | validation: 0.33635650380925103]
	TIME [epoch: 6.32 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6897864667932444		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.6897864667932444 | validation: 0.3519312584334353]
	TIME [epoch: 6.29 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.688343854395995		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.688343854395995 | validation: 0.35274497276720973]
	TIME [epoch: 6.29 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6893337991464287		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.6893337991464287 | validation: 0.3428053081413648]
	TIME [epoch: 6.28 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6920336590418686		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.6920336590418686 | validation: 0.35569025663098036]
	TIME [epoch: 6.28 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6888241658745539		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.6888241658745539 | validation: 0.33722934759679885]
	TIME [epoch: 6.28 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6877012640558113		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.6877012640558113 | validation: 0.3468440072625403]
	TIME [epoch: 6.32 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6838051150986899		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.6838051150986899 | validation: 0.34651998059212064]
	TIME [epoch: 6.29 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6899009176094278		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.6899009176094278 | validation: 0.3411253304595346]
	TIME [epoch: 6.28 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6846308213271814		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.6846308213271814 | validation: 0.3525535652629103]
	TIME [epoch: 6.28 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6911641897979398		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.6911641897979398 | validation: 0.3404584352737013]
	TIME [epoch: 6.28 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.690090207324826		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.690090207324826 | validation: 0.34560064356145226]
	TIME [epoch: 6.28 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6968812077458039		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.6968812077458039 | validation: 0.35388510362674847]
	TIME [epoch: 6.33 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.683580849080011		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.683580849080011 | validation: 0.3441025027556196]
	TIME [epoch: 6.29 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6841014928949235		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.6841014928949235 | validation: 0.3406888081485017]
	TIME [epoch: 6.28 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6902296576757829		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.6902296576757829 | validation: 0.3381727716063054]
	TIME [epoch: 6.28 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6909486170663419		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.6909486170663419 | validation: 0.3583241948834577]
	TIME [epoch: 6.28 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.694207182977311		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.694207182977311 | validation: 0.35144997140999473]
	TIME [epoch: 6.29 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.702172248782237		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.702172248782237 | validation: 0.35605390977775353]
	TIME [epoch: 6.33 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6881751789653137		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.6881751789653137 | validation: 0.34238056643077075]
	TIME [epoch: 6.29 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6866776585500712		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.6866776585500712 | validation: 0.33878152547995677]
	TIME [epoch: 6.29 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6900275434393746		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.6900275434393746 | validation: 0.35324146617806484]
	TIME [epoch: 6.3 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6977374072834038		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.6977374072834038 | validation: 0.35186377330512025]
	TIME [epoch: 6.28 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6873835744387669		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.6873835744387669 | validation: 0.3489666823189922]
	TIME [epoch: 6.3 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6863249051455027		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.6863249051455027 | validation: 0.34271862079757826]
	TIME [epoch: 6.33 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.683388656669527		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.683388656669527 | validation: 0.3375015757038515]
	TIME [epoch: 6.29 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6913755455523598		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.6913755455523598 | validation: 0.344002361906146]
	TIME [epoch: 6.29 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6913115213013727		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.6913115213013727 | validation: 0.3450034289631914]
	TIME [epoch: 6.28 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6909577543688141		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.6909577543688141 | validation: 0.34632048415419414]
	TIME [epoch: 6.29 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6849986704911654		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.6849986704911654 | validation: 0.3465688186283212]
	TIME [epoch: 6.3 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6859601711286136		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.6859601711286136 | validation: 0.3351256131143527]
	TIME [epoch: 6.32 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6907971904459482		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.6907971904459482 | validation: 0.34743785305501856]
	TIME [epoch: 6.29 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6870021491152972		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.6870021491152972 | validation: 0.3452850399414939]
	TIME [epoch: 6.29 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6851091440397216		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.6851091440397216 | validation: 0.3518538964398694]
	TIME [epoch: 6.29 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6914719808837222		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.6914719808837222 | validation: 0.34827531320444804]
	TIME [epoch: 6.28 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6888936643997104		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.6888936643997104 | validation: 0.35897930577828185]
	TIME [epoch: 6.3 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.694105410877936		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.694105410877936 | validation: 0.35598888097539216]
	TIME [epoch: 6.32 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6920854457854875		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.6920854457854875 | validation: 0.33436708075732147]
	TIME [epoch: 6.29 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6876635369733217		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.6876635369733217 | validation: 0.36228940115691255]
	TIME [epoch: 6.3 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7060586420799165		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.7060586420799165 | validation: 0.34806513098360986]
	TIME [epoch: 6.29 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6943644890138371		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.6943644890138371 | validation: 0.36521248736888334]
	TIME [epoch: 6.29 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6918008851078091		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.6918008851078091 | validation: 0.3423211080188101]
	TIME [epoch: 6.32 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6828031451524175		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.6828031451524175 | validation: 0.34565513855952656]
	TIME [epoch: 6.31 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6952372709685696		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.6952372709685696 | validation: 0.35560340198721363]
	TIME [epoch: 6.3 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6931165860038986		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.6931165860038986 | validation: 0.33831291225706206]
	TIME [epoch: 6.29 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6845328788656345		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.6845328788656345 | validation: 0.3454254343797127]
	TIME [epoch: 6.29 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6908051925172254		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.6908051925172254 | validation: 0.3450933595297301]
	TIME [epoch: 6.29 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6841599478542981		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.6841599478542981 | validation: 0.33457459593823724]
	TIME [epoch: 6.32 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6884473730399462		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.6884473730399462 | validation: 0.3462595804494546]
	TIME [epoch: 6.32 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6879179981300529		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.6879179981300529 | validation: 0.35311432434209095]
	TIME [epoch: 6.29 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6912986664932091		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.6912986664932091 | validation: 0.3491536783167076]
	TIME [epoch: 6.31 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6885162759437111		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.6885162759437111 | validation: 0.3519365695452165]
	TIME [epoch: 6.3 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6864277022250997		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.6864277022250997 | validation: 0.34491802450612596]
	TIME [epoch: 6.3 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6854188223448987		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.6854188223448987 | validation: 0.3493800990811567]
	TIME [epoch: 6.33 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.699524632356447		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.699524632356447 | validation: 0.3669394042508492]
	TIME [epoch: 6.32 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.70209104587724		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.70209104587724 | validation: 0.3651145746134336]
	TIME [epoch: 6.3 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7022192294605244		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.7022192294605244 | validation: 0.3641713682519894]
	TIME [epoch: 6.29 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6923409844200586		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.6923409844200586 | validation: 0.3435591797009035]
	TIME [epoch: 6.29 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6893283561483191		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.6893283561483191 | validation: 0.3449166750458088]
	TIME [epoch: 6.3 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.696421977133038		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.696421977133038 | validation: 0.36586706134617647]
	TIME [epoch: 6.33 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6942335529015718		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.6942335529015718 | validation: 0.34486861653855927]
	TIME [epoch: 6.31 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6904070977704229		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.6904070977704229 | validation: 0.3464615205367077]
	TIME [epoch: 6.29 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7019046024194732		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.7019046024194732 | validation: 0.3603770053222691]
	TIME [epoch: 6.3 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7042918569328558		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.7042918569328558 | validation: 0.35016286800511975]
	TIME [epoch: 6.29 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.695293561826258		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.695293561826258 | validation: 0.3459901709564336]
	TIME [epoch: 6.3 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.690414857871652		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.690414857871652 | validation: 0.3449016504401843]
	TIME [epoch: 6.33 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6872638670465143		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.6872638670465143 | validation: 0.348826072460171]
	TIME [epoch: 6.3 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6891099163400765		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.6891099163400765 | validation: 0.3467240269240919]
	TIME [epoch: 6.29 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6851342432914372		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.6851342432914372 | validation: 0.34812007896351443]
	TIME [epoch: 6.29 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6874475513540643		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.6874475513540643 | validation: 0.3395138666037113]
	TIME [epoch: 6.29 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6885749462539237		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.6885749462539237 | validation: 0.36733970325485976]
	TIME [epoch: 6.29 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7057945573822071		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.7057945573822071 | validation: 0.3530350292704117]
	TIME [epoch: 6.33 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6853028042693805		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.6853028042693805 | validation: 0.3417214377600204]
	TIME [epoch: 6.3 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.685080010388309		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.685080010388309 | validation: 0.34544970132112496]
	TIME [epoch: 6.29 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.68384417057039		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.68384417057039 | validation: 0.35781741052938093]
	TIME [epoch: 6.29 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.698330761284978		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.698330761284978 | validation: 0.34629476315734586]
	TIME [epoch: 6.29 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6881397800681193		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.6881397800681193 | validation: 0.349128323157705]
	TIME [epoch: 6.29 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6933134613579248		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.6933134613579248 | validation: 0.3413610941877995]
	TIME [epoch: 6.33 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6879454735658326		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.6879454735658326 | validation: 0.3437660104690121]
	TIME [epoch: 6.3 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6907287483335072		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.6907287483335072 | validation: 0.355674274257782]
	TIME [epoch: 6.29 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6832635688959953		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.6832635688959953 | validation: 0.3403844313259284]
	TIME [epoch: 6.3 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6862652624686336		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.6862652624686336 | validation: 0.3530618191837896]
	TIME [epoch: 6.29 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.690298442949648		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.690298442949648 | validation: 0.3370489580787109]
	TIME [epoch: 6.3 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6911469620486445		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.6911469620486445 | validation: 0.34491164830716503]
	TIME [epoch: 6.33 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6888105940840582		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.6888105940840582 | validation: 0.34237868554357404]
	TIME [epoch: 6.3 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6857351078448596		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.6857351078448596 | validation: 0.3401192325761575]
	TIME [epoch: 6.29 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6882486597074876		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.6882486597074876 | validation: 0.3453746173129062]
	TIME [epoch: 6.29 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6872181445851322		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.6872181445851322 | validation: 0.3534917868938476]
	TIME [epoch: 6.29 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6890525323401739		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.6890525323401739 | validation: 0.3451188326994801]
	TIME [epoch: 6.3 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6903734730427523		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.6903734730427523 | validation: 0.3434341323118239]
	TIME [epoch: 6.35 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6841321233825676		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.6841321233825676 | validation: 0.3485984568803711]
	TIME [epoch: 6.29 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6838008567384402		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.6838008567384402 | validation: 0.35933748195117843]
	TIME [epoch: 6.29 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.689561127164618		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.689561127164618 | validation: 0.34550575977187753]
	TIME [epoch: 6.3 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6851515133599082		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.6851515133599082 | validation: 0.34157102484559637]
	TIME [epoch: 6.29 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6842698192801532		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.6842698192801532 | validation: 0.3426820428165913]
	TIME [epoch: 6.3 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6901803838179483		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.6901803838179483 | validation: 0.3409347102137174]
	TIME [epoch: 6.33 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6882334740023424		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.6882334740023424 | validation: 0.3519879572653657]
	TIME [epoch: 6.29 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6853762085797986		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.6853762085797986 | validation: 0.35172584579490207]
	TIME [epoch: 6.29 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.681886432405939		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.681886432405939 | validation: 0.345905414874675]
	TIME [epoch: 6.3 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6822383781758279		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.6822383781758279 | validation: 0.3442574657829072]
	TIME [epoch: 6.29 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6886836935578896		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.6886836935578896 | validation: 0.33924154454063815]
	TIME [epoch: 6.3 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6833423279182904		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.6833423279182904 | validation: 0.33912202541679654]
	TIME [epoch: 6.33 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6818196895391646		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.6818196895391646 | validation: 0.3378279702003583]
	TIME [epoch: 6.3 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6895926548831687		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.6895926548831687 | validation: 0.35001032595392256]
	TIME [epoch: 6.29 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6904696146620419		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.6904696146620419 | validation: 0.34259323439275663]
	TIME [epoch: 6.29 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6900530121582387		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.6900530121582387 | validation: 0.3563732577091708]
	TIME [epoch: 6.29 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6911194471398557		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.6911194471398557 | validation: 0.3547915857690256]
	TIME [epoch: 6.3 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6963408573063904		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.6963408573063904 | validation: 0.34970386122851793]
	TIME [epoch: 6.34 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.686509087613127		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.686509087613127 | validation: 0.345618468766464]
	TIME [epoch: 6.29 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6882246065804204		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.6882246065804204 | validation: 0.3401903261830787]
	TIME [epoch: 6.29 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6871137989468623		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.6871137989468623 | validation: 0.3494818135794735]
	TIME [epoch: 6.28 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6966367684845136		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.6966367684845136 | validation: 0.3335423794094754]
	TIME [epoch: 6.29 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6845977348779255		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.6845977348779255 | validation: 0.33698606055926855]
	TIME [epoch: 6.31 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6896854883073815		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.6896854883073815 | validation: 0.3502258414132649]
	TIME [epoch: 6.33 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6868646257379909		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.6868646257379909 | validation: 0.3467479844678927]
	TIME [epoch: 6.29 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6900421965770743		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.6900421965770743 | validation: 0.3407163050926696]
	TIME [epoch: 6.29 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6929174805522732		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.6929174805522732 | validation: 0.3472219672358117]
	TIME [epoch: 6.3 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.685354618907329		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.685354618907329 | validation: 0.3475471012812787]
	TIME [epoch: 6.3 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.691197214134043		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.691197214134043 | validation: 0.36196767052567197]
	TIME [epoch: 6.31 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6894486079326507		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.6894486079326507 | validation: 0.3440418252769902]
	TIME [epoch: 6.32 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6885576841225878		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.6885576841225878 | validation: 0.3536565977343793]
	TIME [epoch: 6.29 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6942889949615065		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.6942889949615065 | validation: 0.35133974457745903]
	TIME [epoch: 6.3 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6873245343186052		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.6873245343186052 | validation: 0.3434041901480737]
	TIME [epoch: 6.28 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.691132182493999		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.691132182493999 | validation: 0.3582903797837283]
	TIME [epoch: 6.29 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6909556543088442		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.6909556543088442 | validation: 0.3461103894930614]
	TIME [epoch: 6.32 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6877521588546861		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.6877521588546861 | validation: 0.35217445263172836]
	TIME [epoch: 6.32 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6899493080062256		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.6899493080062256 | validation: 0.3549195153756211]
	TIME [epoch: 6.29 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6935695376825174		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.6935695376825174 | validation: 0.36046605683790744]
	TIME [epoch: 6.29 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7023486829350858		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.7023486829350858 | validation: 0.3596803235032577]
	TIME [epoch: 6.3 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6897103403581053		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.6897103403581053 | validation: 0.34355344376105407]
	TIME [epoch: 6.29 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6848532892565129		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.6848532892565129 | validation: 0.34584873177068504]
	TIME [epoch: 6.34 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6912150172539799		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.6912150172539799 | validation: 0.3414428911031463]
	TIME [epoch: 6.3 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6861105847015055		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.6861105847015055 | validation: 0.345566505940404]
	TIME [epoch: 6.29 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6853122998534233		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.6853122998534233 | validation: 0.34796900960704896]
	TIME [epoch: 6.3 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6856742657878093		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.6856742657878093 | validation: 0.3531447435161437]
	TIME [epoch: 6.29 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6884677933856953		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.6884677933856953 | validation: 0.3423163379946065]
	TIME [epoch: 6.29 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6892970716746538		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.6892970716746538 | validation: 0.3625638565455943]
	TIME [epoch: 6.33 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6935071025755679		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.6935071025755679 | validation: 0.3335714084452268]
	TIME [epoch: 6.3 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6858388961519932		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.6858388961519932 | validation: 0.34453776587022317]
	TIME [epoch: 6.29 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6861009005909643		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.6861009005909643 | validation: 0.348849219358903]
	TIME [epoch: 6.29 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6871415074815259		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.6871415074815259 | validation: 0.33804065285106544]
	TIME [epoch: 6.29 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6850931032202517		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.6850931032202517 | validation: 0.34485088351008103]
	TIME [epoch: 6.29 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.684606050978808		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.684606050978808 | validation: 0.34877592611908825]
	TIME [epoch: 6.35 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6803261861105289		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.6803261861105289 | validation: 0.34363144132763335]
	TIME [epoch: 6.3 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6870962027467211		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.6870962027467211 | validation: 0.3514216072827789]
	TIME [epoch: 6.29 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6882912694285461		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.6882912694285461 | validation: 0.3475226989064572]
	TIME [epoch: 6.29 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6847052294395197		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.6847052294395197 | validation: 0.3538922055314815]
	TIME [epoch: 6.28 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6868470490397487		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.6868470490397487 | validation: 0.3416564033281201]
	TIME [epoch: 6.3 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6900347814372144		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.6900347814372144 | validation: 0.3405817816298988]
	TIME [epoch: 6.34 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6876646320547146		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.6876646320547146 | validation: 0.3435367693247467]
	TIME [epoch: 6.3 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6867427725147585		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.6867427725147585 | validation: 0.3469429938963698]
	TIME [epoch: 6.3 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.690781808466773		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.690781808466773 | validation: 0.3368328464076045]
	TIME [epoch: 6.3 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6890163738583589		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.6890163738583589 | validation: 0.329419552855319]
	TIME [epoch: 6.29 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_949.pth
	Model improved!!!
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6888028631261267		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.6888028631261267 | validation: 0.3511777414518889]
	TIME [epoch: 6.3 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6893221884256178		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.6893221884256178 | validation: 0.3442496911247939]
	TIME [epoch: 6.35 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6839066915474664		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.6839066915474664 | validation: 0.33630187738165246]
	TIME [epoch: 6.29 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6854980644056959		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.6854980644056959 | validation: 0.3480139716468556]
	TIME [epoch: 6.29 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.686120240217712		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.686120240217712 | validation: 0.35314063892934]
	TIME [epoch: 6.28 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6905017456251892		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.6905017456251892 | validation: 0.3397422576654788]
	TIME [epoch: 6.29 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6879819922396482		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.6879819922396482 | validation: 0.3422129926628415]
	TIME [epoch: 6.29 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6896508584098701		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.6896508584098701 | validation: 0.3477023615709885]
	TIME [epoch: 6.33 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6923543180986192		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.6923543180986192 | validation: 0.3430243818766109]
	TIME [epoch: 6.28 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6854391135811642		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.6854391135811642 | validation: 0.34163460217798736]
	TIME [epoch: 6.3 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6855512834192737		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.6855512834192737 | validation: 0.34957537451663756]
	TIME [epoch: 6.28 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6896432983118004		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.6896432983118004 | validation: 0.3357378596389315]
	TIME [epoch: 6.29 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6834467049899339		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.6834467049899339 | validation: 0.3541627208817988]
	TIME [epoch: 6.3 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6886341036813093		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.6886341036813093 | validation: 0.3475077387449165]
	TIME [epoch: 6.33 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6874591433581668		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.6874591433581668 | validation: 0.34199498062149614]
	TIME [epoch: 6.28 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6884883887486443		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.6884883887486443 | validation: 0.33399191436458203]
	TIME [epoch: 6.3 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6843793842913855		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.6843793842913855 | validation: 0.3422432119734195]
	TIME [epoch: 6.29 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6844932445037789		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.6844932445037789 | validation: 0.3570800916782093]
	TIME [epoch: 6.28 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6899955355373119		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.6899955355373119 | validation: 0.3444568697376306]
	TIME [epoch: 6.3 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.688329534504253		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.688329534504253 | validation: 0.3363159002308792]
	TIME [epoch: 6.32 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6869555358614714		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.6869555358614714 | validation: 0.3528912508792117]
	TIME [epoch: 6.29 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6904540527132862		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.6904540527132862 | validation: 0.36445680419802345]
	TIME [epoch: 6.29 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6924639936957648		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.6924639936957648 | validation: 0.3503792042929304]
	TIME [epoch: 6.29 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6871705022513855		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.6871705022513855 | validation: 0.349257924015554]
	TIME [epoch: 6.29 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6850262279276034		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.6850262279276034 | validation: 0.3462628609881507]
	TIME [epoch: 6.31 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6859318436016408		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.6859318436016408 | validation: 0.3478503653739028]
	TIME [epoch: 6.33 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6873115068890948		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.6873115068890948 | validation: 0.34945864078009387]
	TIME [epoch: 6.3 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6947491218033525		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.6947491218033525 | validation: 0.347437108274381]
	TIME [epoch: 6.3 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6841726877873573		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.6841726877873573 | validation: 0.35663070571850547]
	TIME [epoch: 6.3 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6983242520953126		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.6983242520953126 | validation: 0.35161211949365967]
	TIME [epoch: 6.29 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6868407560022518		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.6868407560022518 | validation: 0.3384650891308426]
	TIME [epoch: 6.32 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6882379768887845		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.6882379768887845 | validation: 0.35107361425601885]
	TIME [epoch: 6.32 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6865146228193599		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.6865146228193599 | validation: 0.3485671700949436]
	TIME [epoch: 6.29 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6872479734623483		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.6872479734623483 | validation: 0.3415951654348574]
	TIME [epoch: 6.29 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6876243369327412		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.6876243369327412 | validation: 0.344512930296233]
	TIME [epoch: 6.3 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6864433217831001		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.6864433217831001 | validation: 0.33939868013567615]
	TIME [epoch: 6.29 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.683251459651407		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.683251459651407 | validation: 0.3491326893815365]
	TIME [epoch: 6.32 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6936233099628839		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.6936233099628839 | validation: 0.34788346042623425]
	TIME [epoch: 6.32 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6877933182704785		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.6877933182704785 | validation: 0.3474592282947845]
	TIME [epoch: 6.29 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6956449063607146		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.6956449063607146 | validation: 0.3552381913580762]
	TIME [epoch: 6.29 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6965195992266038		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.6965195992266038 | validation: 0.33796314139769]
	TIME [epoch: 6.3 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6844642541793649		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.6844642541793649 | validation: 0.3409696881137963]
	TIME [epoch: 6.29 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6904702892475425		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.6904702892475425 | validation: 0.3560591456345992]
	TIME [epoch: 6.34 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6935651441630901		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.6935651441630901 | validation: 0.3425869286579511]
	TIME [epoch: 6.31 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6826376645927463		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.6826376645927463 | validation: 0.34544240731782766]
	TIME [epoch: 6.29 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6918015666906898		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.6918015666906898 | validation: 0.3458261442853174]
	TIME [epoch: 6.3 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.68647038816408		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.68647038816408 | validation: 0.34900098907147037]
	TIME [epoch: 6.29 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6872840476966698		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.6872840476966698 | validation: 0.34808964932226927]
	TIME [epoch: 6.29 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6865016827412407		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.6865016827412407 | validation: 0.3391639682402952]
	TIME [epoch: 6.33 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6845084322128258		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.6845084322128258 | validation: 0.35946296234722924]
	TIME [epoch: 6.31 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6883410344944724		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.6883410344944724 | validation: 0.3497221112629107]
	TIME [epoch: 6.3 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6894684368074687		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.6894684368074687 | validation: 0.3398857021219386]
	TIME [epoch: 6.3 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6902691578026692		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.6902691578026692 | validation: 0.35849868557654874]
	TIME [epoch: 6.3 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7043143786021969		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.7043143786021969 | validation: 0.3458335103352378]
	TIME [epoch: 6.3 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6878180819559759		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.6878180819559759 | validation: 0.34640129828334376]
	TIME [epoch: 6.33 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6846978719211494		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.6846978719211494 | validation: 0.3429125868369548]
	TIME [epoch: 6.3 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6865046503236838		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.6865046503236838 | validation: 0.362162330477862]
	TIME [epoch: 6.29 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6927421334395557		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.6927421334395557 | validation: 0.3483549920475735]
	TIME [epoch: 6.3 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6836270448950916		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.6836270448950916 | validation: 0.34634055616319487]
	TIME [epoch: 6.29 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.686170825057314		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.686170825057314 | validation: 0.33736448443555656]
	TIME [epoch: 6.3 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6917458715073354		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.6917458715073354 | validation: 0.3490570213847414]
	TIME [epoch: 6.34 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6862755308409888		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.6862755308409888 | validation: 0.3375707418495064]
	TIME [epoch: 6.3 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6889802219327342		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.6889802219327342 | validation: 0.3377314545138693]
	TIME [epoch: 6.29 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.692032811595522		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.692032811595522 | validation: 0.3476206711851176]
	TIME [epoch: 6.3 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6897974480643295		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.6897974480643295 | validation: 0.3456120202007389]
	TIME [epoch: 6.3 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.68804344575718		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.68804344575718 | validation: 0.3472037843499411]
	TIME [epoch: 6.29 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6911691391838778		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.6911691391838778 | validation: 0.33962434522335516]
	TIME [epoch: 6.34 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6886094728822272		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.6886094728822272 | validation: 0.3434014083845452]
	TIME [epoch: 6.3 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6840372827103268		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.6840372827103268 | validation: 0.3432433959629849]
	TIME [epoch: 6.3 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6856668987759771		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.6856668987759771 | validation: 0.34526275981541943]
	TIME [epoch: 6.29 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6853903786147277		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.6853903786147277 | validation: 0.34647852060335066]
	TIME [epoch: 6.3 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6883622527528496		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.6883622527528496 | validation: 0.34957151102976775]
	TIME [epoch: 6.29 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6871422328869236		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.6871422328869236 | validation: 0.3476369721954047]
	TIME [epoch: 6.35 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6858024371465052		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.6858024371465052 | validation: 0.33865559263395606]
	TIME [epoch: 6.3 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6859946421587549		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.6859946421587549 | validation: 0.3529582116566492]
	TIME [epoch: 6.3 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6972262781965965		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.6972262781965965 | validation: 0.3638666622819009]
	TIME [epoch: 6.29 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6960265276678124		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.6960265276678124 | validation: 0.35116722746104745]
	TIME [epoch: 6.3 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6890209830360838		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.6890209830360838 | validation: 0.3497335772640145]
	TIME [epoch: 6.29 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6887508600868211		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.6887508600868211 | validation: 0.3405563123958988]
	TIME [epoch: 6.33 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6845444621660697		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.6845444621660697 | validation: 0.3430549611167098]
	TIME [epoch: 6.29 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6863851075676879		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.6863851075676879 | validation: 0.3384565739926956]
	TIME [epoch: 6.29 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6847049537159101		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.6847049537159101 | validation: 0.34726387123332403]
	TIME [epoch: 6.29 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.686006791267999		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.686006791267999 | validation: 0.34511242618688887]
	TIME [epoch: 6.29 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6880135260461535		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.6880135260461535 | validation: 0.346297347082862]
	TIME [epoch: 6.31 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6848652876377892		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.6848652876377892 | validation: 0.34351737834593726]
	TIME [epoch: 6.33 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.685347761965115		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.685347761965115 | validation: 0.34813902388472195]
	TIME [epoch: 6.29 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.686400733562208		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.686400733562208 | validation: 0.3429828956947636]
	TIME [epoch: 6.29 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6817609936418346		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.6817609936418346 | validation: 0.34304956417707916]
	TIME [epoch: 6.3 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6885947059946914		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.6885947059946914 | validation: 0.3477053896585476]
	TIME [epoch: 6.29 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6880111930002605		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.6880111930002605 | validation: 0.33503815477913496]
	TIME [epoch: 6.3 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6866275618727994		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.6866275618727994 | validation: 0.3433886816630832]
	TIME [epoch: 6.33 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6907367848819573		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.6907367848819573 | validation: 0.3508846558225879]
	TIME [epoch: 6.3 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6878206467144028		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.6878206467144028 | validation: 0.35388870942131334]
	TIME [epoch: 6.29 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6864702344333169		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.6864702344333169 | validation: 0.3405159026900329]
	TIME [epoch: 6.29 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6863756100962175		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.6863756100962175 | validation: 0.34999867131704887]
	TIME [epoch: 6.3 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.685747683759341		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.685747683759341 | validation: 0.35372043395306296]
	TIME [epoch: 6.32 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6847814992261766		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.6847814992261766 | validation: 0.3343309327582819]
	TIME [epoch: 6.31 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6866880502977748		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.6866880502977748 | validation: 0.3456596253644549]
	TIME [epoch: 6.31 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6856368450763044		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.6856368450763044 | validation: 0.3501694917644259]
	TIME [epoch: 6.28 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6846750155821043		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.6846750155821043 | validation: 0.34380244671701354]
	TIME [epoch: 6.29 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6836986572714836		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.6836986572714836 | validation: 0.34056628878832623]
	TIME [epoch: 6.29 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6840133862495655		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.6840133862495655 | validation: 0.34632928612741243]
	TIME [epoch: 6.32 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6838723127235888		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.6838723127235888 | validation: 0.3333092277692846]
	TIME [epoch: 6.31 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6873655587534725		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.6873655587534725 | validation: 0.3351167567235802]
	TIME [epoch: 6.29 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.688643050791073		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.688643050791073 | validation: 0.3337907149068307]
	TIME [epoch: 6.29 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6892559517648441		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.6892559517648441 | validation: 0.34525881448323975]
	TIME [epoch: 6.29 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6847837996842228		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.6847837996842228 | validation: 0.3543478203853852]
	TIME [epoch: 6.28 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6862181195623742		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.6862181195623742 | validation: 0.34575235601739557]
	TIME [epoch: 6.32 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6869468179356719		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.6869468179356719 | validation: 0.34669411179322085]
	TIME [epoch: 6.3 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6846907770077771		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.6846907770077771 | validation: 0.3531200110518949]
	TIME [epoch: 6.28 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.690622069075625		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.690622069075625 | validation: 0.3369063173622816]
	TIME [epoch: 6.3 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6874556283627974		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.6874556283627974 | validation: 0.3487258671962127]
	TIME [epoch: 6.29 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6854479669423483		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.6854479669423483 | validation: 0.3442693425417813]
	TIME [epoch: 6.28 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6883549688852657		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.6883549688852657 | validation: 0.35052201900911983]
	TIME [epoch: 6.33 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6845303969168808		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.6845303969168808 | validation: 0.3504643071130009]
	TIME [epoch: 6.3 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.689568594184788		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.689568594184788 | validation: 0.35430368217430575]
	TIME [epoch: 6.29 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6922132378728751		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.6922132378728751 | validation: 0.35384023028570966]
	TIME [epoch: 6.28 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6888021999160742		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.6888021999160742 | validation: 0.34955506101887723]
	TIME [epoch: 6.29 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.68788025952321		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.68788025952321 | validation: 0.3453037561089336]
	TIME [epoch: 6.29 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6851477816086184		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.6851477816086184 | validation: 0.3323291715796863]
	TIME [epoch: 6.34 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6834072053168795		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.6834072053168795 | validation: 0.3444140868685481]
	TIME [epoch: 6.3 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6906505553393392		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.6906505553393392 | validation: 0.34923265824921546]
	TIME [epoch: 6.29 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6881894420567713		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.6881894420567713 | validation: 0.3402575800530942]
	TIME [epoch: 6.29 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.683700875331213		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.683700875331213 | validation: 0.33378256567166253]
	TIME [epoch: 6.3 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6854699974948191		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.6854699974948191 | validation: 0.3425984726790601]
	TIME [epoch: 6.3 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6885716545417819		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.6885716545417819 | validation: 0.34141497654989944]
	TIME [epoch: 6.34 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.686781680316991		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.686781680316991 | validation: 0.3492080752241926]
	TIME [epoch: 6.3 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.688113905438273		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.688113905438273 | validation: 0.34426535624614435]
	TIME [epoch: 6.3 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6856545536028198		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.6856545536028198 | validation: 0.3479295967717241]
	TIME [epoch: 6.29 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6847058163997684		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.6847058163997684 | validation: 0.34173451482483086]
	TIME [epoch: 6.29 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6875752764530721		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.6875752764530721 | validation: 0.3475324788783201]
	TIME [epoch: 6.3 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6871940564826418		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.6871940564826418 | validation: 0.35146914633047394]
	TIME [epoch: 6.35 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6890480190669077		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.6890480190669077 | validation: 0.34282193829751256]
	TIME [epoch: 6.29 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6912197341959695		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.6912197341959695 | validation: 0.3475124894630176]
	TIME [epoch: 6.3 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6833210161054947		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.6833210161054947 | validation: 0.34543358418536924]
	TIME [epoch: 6.3 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6820212228046263		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.6820212228046263 | validation: 0.3488555534652745]
	TIME [epoch: 6.3 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6852262003273987		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.6852262003273987 | validation: 0.3432076403319791]
	TIME [epoch: 6.3 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6887835516889464		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.6887835516889464 | validation: 0.3513964969610551]
	TIME [epoch: 6.34 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6835309160030795		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.6835309160030795 | validation: 0.3445984343477422]
	TIME [epoch: 6.29 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6873671908900206		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.6873671908900206 | validation: 0.3377686704788493]
	TIME [epoch: 6.3 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6873594404963501		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.6873594404963501 | validation: 0.34039160296918236]
	TIME [epoch: 6.29 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6841283289126971		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.6841283289126971 | validation: 0.3547417804366852]
	TIME [epoch: 6.3 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6877501742594482		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.6877501742594482 | validation: 0.3394120400532534]
	TIME [epoch: 6.29 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6830428388017665		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.6830428388017665 | validation: 0.35397743960965466]
	TIME [epoch: 6.34 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6884729357684265		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.6884729357684265 | validation: 0.3429458483922339]
	TIME [epoch: 6.3 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6860341211571448		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.6860341211571448 | validation: 0.3488495319226159]
	TIME [epoch: 6.29 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.684828024975353		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.684828024975353 | validation: 0.3563279660810875]
	TIME [epoch: 6.29 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6900460006886524		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.6900460006886524 | validation: 0.3478688698340179]
	TIME [epoch: 6.3 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6918858454013243		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.6918858454013243 | validation: 0.34031321992123736]
	TIME [epoch: 6.3 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6876178104475748		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.6876178104475748 | validation: 0.343799101515312]
	TIME [epoch: 6.33 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6843239642260869		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.6843239642260869 | validation: 0.34430293191057426]
	TIME [epoch: 6.29 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6890794928571327		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.6890794928571327 | validation: 0.3530287653524957]
	TIME [epoch: 6.29 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6886824787830956		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.6886824787830956 | validation: 0.3387299037306848]
	TIME [epoch: 6.3 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6886831510246517		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.6886831510246517 | validation: 0.34438109066165923]
	TIME [epoch: 6.3 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6857003576954394		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.6857003576954394 | validation: 0.3448883674118456]
	TIME [epoch: 6.31 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6844247131238065		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.6844247131238065 | validation: 0.3510194747419854]
	TIME [epoch: 6.33 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6824680376375829		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.6824680376375829 | validation: 0.35738651794945736]
	TIME [epoch: 6.3 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6832431750958571		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.6832431750958571 | validation: 0.3494495824481314]
	TIME [epoch: 6.29 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6885724462426505		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.6885724462426505 | validation: 0.3388153054434532]
	TIME [epoch: 6.3 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6866157038567654		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.6866157038567654 | validation: 0.3466818585842706]
	TIME [epoch: 6.3 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6876936518505323		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.6876936518505323 | validation: 0.3466789832096798]
	TIME [epoch: 6.3 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6884587056148641		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.6884587056148641 | validation: 0.3413940482248313]
	TIME [epoch: 6.33 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6872131145147069		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.6872131145147069 | validation: 0.3397650531745954]
	TIME [epoch: 6.3 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6888524675700978		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.6888524675700978 | validation: 0.34836892119644675]
	TIME [epoch: 6.29 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6857797151699845		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.6857797151699845 | validation: 0.340066122872003]
	TIME [epoch: 6.28 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6869455019922075		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.6869455019922075 | validation: 0.34817419249394094]
	TIME [epoch: 6.29 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6834017258446142		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.6834017258446142 | validation: 0.34788055309280963]
	TIME [epoch: 6.31 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6796794459571182		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.6796794459571182 | validation: 0.34534669007000335]
	TIME [epoch: 6.34 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6901018514470874		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.6901018514470874 | validation: 0.34921720678255563]
	TIME [epoch: 6.29 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6877226721831968		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.6877226721831968 | validation: 0.3540061510059145]
	TIME [epoch: 6.29 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6851418681393525		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.6851418681393525 | validation: 0.34794690124959154]
	TIME [epoch: 6.29 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6823493995420267		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.6823493995420267 | validation: 0.3572838826800983]
	TIME [epoch: 6.29 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6907026616067211		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.6907026616067211 | validation: 0.34469095434068797]
	TIME [epoch: 6.31 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6842439402074971		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.6842439402074971 | validation: 0.3494890543647209]
	TIME [epoch: 6.32 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6884444692111658		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.6884444692111658 | validation: 0.34628536648571784]
	TIME [epoch: 6.29 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6863626882542911		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.6863626882542911 | validation: 0.34510835554799235]
	TIME [epoch: 6.28 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6846411084843737		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.6846411084843737 | validation: 0.35042904249759405]
	TIME [epoch: 6.29 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6872205129567883		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.6872205129567883 | validation: 0.3422724063019645]
	TIME [epoch: 6.29 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6886250566222749		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.6886250566222749 | validation: 0.3522115424996472]
	TIME [epoch: 6.34 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6864690692178979		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.6864690692178979 | validation: 0.33977920839222303]
	TIME [epoch: 6.31 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6830081017606098		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.6830081017606098 | validation: 0.3442895223457903]
	TIME [epoch: 6.29 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6849002139517727		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.6849002139517727 | validation: 0.34679936880620416]
	TIME [epoch: 6.29 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.68401742945953		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.68401742945953 | validation: 0.3415183454124628]
	TIME [epoch: 6.29 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6848052796642918		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.6848052796642918 | validation: 0.34187802153589886]
	TIME [epoch: 6.29 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6870882389866886		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.6870882389866886 | validation: 0.33978034863950113]
	TIME [epoch: 6.34 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6836359078721296		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.6836359078721296 | validation: 0.34568348775622754]
	TIME [epoch: 6.3 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6872311326012515		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.6872311326012515 | validation: 0.3385897372407694]
	TIME [epoch: 6.29 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6812730793315616		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.6812730793315616 | validation: 0.33391552935273244]
	TIME [epoch: 6.3 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6837585114269804		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.6837585114269804 | validation: 0.34792138858159083]
	TIME [epoch: 6.29 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6885878074251492		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.6885878074251492 | validation: 0.3456205354842072]
	TIME [epoch: 6.29 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6833771944616656		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.6833771944616656 | validation: 0.3415893074920282]
	TIME [epoch: 6.34 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6872422745863005		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.6872422745863005 | validation: 0.33771805942446187]
	TIME [epoch: 6.31 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6849612034298003		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.6849612034298003 | validation: 0.3457527763049589]
	TIME [epoch: 6.29 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6866556186294448		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.6866556186294448 | validation: 0.34334917983034546]
	TIME [epoch: 6.29 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6851053372160769		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.6851053372160769 | validation: 0.3387921009516924]
	TIME [epoch: 6.29 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.687841640811085		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.687841640811085 | validation: 0.3421256853999889]
	TIME [epoch: 6.3 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6863884307976781		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.6863884307976781 | validation: 0.340048592687367]
	TIME [epoch: 6.34 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.690507238595577		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.690507238595577 | validation: 0.3446555169154053]
	TIME [epoch: 6.29 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6874566573767009		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.6874566573767009 | validation: 0.34209799620964476]
	TIME [epoch: 6.29 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6846948330129589		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.6846948330129589 | validation: 0.3454460793779791]
	TIME [epoch: 6.29 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6858948215718491		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.6858948215718491 | validation: 0.35067839453119776]
	TIME [epoch: 6.3 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6853800192114977		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.6853800192114977 | validation: 0.34773391526350805]
	TIME [epoch: 6.3 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6870094783304409		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.6870094783304409 | validation: 0.3495913197783364]
	TIME [epoch: 6.34 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6857968606894749		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.6857968606894749 | validation: 0.34714045632305895]
	TIME [epoch: 6.3 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.686515485852179		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.686515485852179 | validation: 0.3472162899257972]
	TIME [epoch: 6.29 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6859898494615382		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.6859898494615382 | validation: 0.34978139732191116]
	TIME [epoch: 6.3 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6896731339107873		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.6896731339107873 | validation: 0.35021204093491665]
	TIME [epoch: 6.29 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6833929003192984		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.6833929003192984 | validation: 0.3391236053282293]
	TIME [epoch: 6.29 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6876262229312667		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.6876262229312667 | validation: 0.34327716521157353]
	TIME [epoch: 6.34 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6888230041950556		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.6888230041950556 | validation: 0.35130901560273115]
	TIME [epoch: 6.29 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6939575899589382		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.6939575899589382 | validation: 0.3547846925974351]
	TIME [epoch: 6.3 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.689697374086568		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.689697374086568 | validation: 0.3412601930428098]
	TIME [epoch: 6.29 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.687538815864899		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.687538815864899 | validation: 0.3468719294043848]
	TIME [epoch: 6.29 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6830327246445926		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.6830327246445926 | validation: 0.34233593830517484]
	TIME [epoch: 6.3 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6845964673262941		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.6845964673262941 | validation: 0.3415604525574439]
	TIME [epoch: 6.33 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6901816772030284		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.6901816772030284 | validation: 0.3443600690824508]
	TIME [epoch: 6.3 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6812847009973582		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.6812847009973582 | validation: 0.3424687082788269]
	TIME [epoch: 6.29 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6863139273757727		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.6863139273757727 | validation: 0.34471706672701163]
	TIME [epoch: 6.29 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.683278314017769		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.683278314017769 | validation: 0.34018842028417795]
	TIME [epoch: 6.29 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6860257486926576		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.6860257486926576 | validation: 0.3487534496697225]
	TIME [epoch: 6.31 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6845796740833601		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.6845796740833601 | validation: 0.34295635972639604]
	TIME [epoch: 6.33 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6836761470612025		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.6836761470612025 | validation: 0.3463839933945749]
	TIME [epoch: 6.29 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6868506153344013		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.6868506153344013 | validation: 0.3459004939983411]
	TIME [epoch: 6.29 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.680186331882872		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.680186331882872 | validation: 0.3420698734385028]
	TIME [epoch: 6.29 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6869681513071684		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.6869681513071684 | validation: 0.3531651610886704]
	TIME [epoch: 6.29 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6839832322686588		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.6839832322686588 | validation: 0.34610695968467864]
	TIME [epoch: 6.29 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6838666987922324		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.6838666987922324 | validation: 0.3434331810909398]
	TIME [epoch: 6.33 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6842682351641609		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.6842682351641609 | validation: 0.33665258144698207]
	TIME [epoch: 6.29 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6834117465485902		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.6834117465485902 | validation: 0.348717879058371]
	TIME [epoch: 6.3 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.683681076465372		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.683681076465372 | validation: 0.3429883718036696]
	TIME [epoch: 6.3 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6821728445392274		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.6821728445392274 | validation: 0.3482389126164107]
	TIME [epoch: 6.29 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6885009614985005		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.6885009614985005 | validation: 0.34536644020558666]
	TIME [epoch: 6.31 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.684977869951445		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.684977869951445 | validation: 0.3403678208621321]
	TIME [epoch: 6.31 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6871098694195983		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.6871098694195983 | validation: 0.3471717651709746]
	TIME [epoch: 6.3 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.685260450315748		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.685260450315748 | validation: 0.3444800850556662]
	TIME [epoch: 6.3 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6834363703087557		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.6834363703087557 | validation: 0.34522502268699684]
	TIME [epoch: 6.29 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6865019789416195		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.6865019789416195 | validation: 0.34537528489042085]
	TIME [epoch: 6.29 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6822967620930113		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.6822967620930113 | validation: 0.3402361534669569]
	TIME [epoch: 6.33 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6899605864638045		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.6899605864638045 | validation: 0.34774169786775144]
	TIME [epoch: 6.32 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6834358760180903		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.6834358760180903 | validation: 0.3422657798012388]
	TIME [epoch: 6.3 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6882411985507135		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.6882411985507135 | validation: 0.3486788681618301]
	TIME [epoch: 6.3 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6879081657851432		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.6879081657851432 | validation: 0.3416787824682448]
	TIME [epoch: 6.3 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.686640537041714		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.686640537041714 | validation: 0.3404716210680092]
	TIME [epoch: 6.3 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6845078657882178		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.6845078657882178 | validation: 0.3451806367276065]
	TIME [epoch: 6.34 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6824949335739179		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.6824949335739179 | validation: 0.35150285307892315]
	TIME [epoch: 6.32 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6864585954477377		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.6864585954477377 | validation: 0.3374638742396057]
	TIME [epoch: 6.3 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6859459374151066		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.6859459374151066 | validation: 0.33759466176543473]
	TIME [epoch: 6.3 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6860838054360856		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.6860838054360856 | validation: 0.3426604734288868]
	TIME [epoch: 6.3 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.684325127205597		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.684325127205597 | validation: 0.3375464442249511]
	TIME [epoch: 6.3 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6897991446139393		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.6897991446139393 | validation: 0.35309564563621576]
	TIME [epoch: 6.36 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6854730588647		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.6854730588647 | validation: 0.35174683409763857]
	TIME [epoch: 6.3 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6792889946176963		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.6792889946176963 | validation: 0.34060061808445574]
	TIME [epoch: 6.3 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6836882048190928		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.6836882048190928 | validation: 0.3364257628567844]
	TIME [epoch: 6.3 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6825591163572601		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.6825591163572601 | validation: 0.3369727596678765]
	TIME [epoch: 6.3 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.685596395752812		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.685596395752812 | validation: 0.33964009376615956]
	TIME [epoch: 6.29 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6839593940534769		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.6839593940534769 | validation: 0.3459193617251852]
	TIME [epoch: 6.35 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6860950806148013		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.6860950806148013 | validation: 0.3408987317007796]
	TIME [epoch: 6.3 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6810405455114423		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.6810405455114423 | validation: 0.3412853371029375]
	TIME [epoch: 6.38 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6832992456979552		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.6832992456979552 | validation: 0.3490258613149267]
	TIME [epoch: 6.3 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6843255349801881		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.6843255349801881 | validation: 0.3498467703052397]
	TIME [epoch: 6.3 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6795158023006809		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.6795158023006809 | validation: 0.341103416179493]
	TIME [epoch: 6.29 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6864457346399547		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.6864457346399547 | validation: 0.33630879078722997]
	TIME [epoch: 6.35 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6864105846229608		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.6864105846229608 | validation: 0.348668601152655]
	TIME [epoch: 6.3 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6884265769048431		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.6884265769048431 | validation: 0.3444162515009331]
	TIME [epoch: 6.3 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6814738082393565		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.6814738082393565 | validation: 0.3507799120330026]
	TIME [epoch: 6.3 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6870106233944214		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.6870106233944214 | validation: 0.34077610635287703]
	TIME [epoch: 6.29 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6817493714832765		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.6817493714832765 | validation: 0.3343705030860691]
	TIME [epoch: 6.3 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6824190180617035		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.6824190180617035 | validation: 0.33732418467555314]
	TIME [epoch: 6.35 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6834677897242291		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.6834677897242291 | validation: 0.3393501196184991]
	TIME [epoch: 6.3 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6833513731011394		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.6833513731011394 | validation: 0.3451640461929113]
	TIME [epoch: 6.3 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6859540900207742		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.6859540900207742 | validation: 0.3450069725270529]
	TIME [epoch: 6.29 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.680859328209174		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.680859328209174 | validation: 0.33693953554144845]
	TIME [epoch: 6.29 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.688652406306119		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.688652406306119 | validation: 0.34389101179896686]
	TIME [epoch: 6.3 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6842679756896128		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.6842679756896128 | validation: 0.3401530702364043]
	TIME [epoch: 6.34 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6836425747684443		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.6836425747684443 | validation: 0.34787808679014465]
	TIME [epoch: 6.3 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6857547795648534		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.6857547795648534 | validation: 0.3369202246273184]
	TIME [epoch: 6.31 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6843902024012666		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.6843902024012666 | validation: 0.34255775838181685]
	TIME [epoch: 6.29 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6870978761113726		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.6870978761113726 | validation: 0.3413353350304471]
	TIME [epoch: 6.29 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6872783904911888		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.6872783904911888 | validation: 0.3447330892457004]
	TIME [epoch: 6.3 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6856877732764881		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.6856877732764881 | validation: 0.33547759187554294]
	TIME [epoch: 6.34 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6882067589402767		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.6882067589402767 | validation: 0.35433009844636776]
	TIME [epoch: 6.29 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6885475081259016		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.6885475081259016 | validation: 0.3455352294649806]
	TIME [epoch: 6.29 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.683885610247364		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.683885610247364 | validation: 0.34940408252214034]
	TIME [epoch: 6.3 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6847579530251505		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.6847579530251505 | validation: 0.3405597999412556]
	TIME [epoch: 6.3 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6866948207202781		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.6866948207202781 | validation: 0.3493895266262915]
	TIME [epoch: 6.31 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6865931570507149		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.6865931570507149 | validation: 0.3417162319977553]
	TIME [epoch: 6.34 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6847977663719896		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.6847977663719896 | validation: 0.34001878609293174]
	TIME [epoch: 6.31 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6876767059902521		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.6876767059902521 | validation: 0.3425987040897803]
	TIME [epoch: 6.3 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6860350009932238		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.6860350009932238 | validation: 0.33724916694577234]
	TIME [epoch: 6.31 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6830883016597186		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.6830883016597186 | validation: 0.3439279258180398]
	TIME [epoch: 6.3 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.687286039302512		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.687286039302512 | validation: 0.33791159561371636]
	TIME [epoch: 6.32 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6846559739598944		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.6846559739598944 | validation: 0.3444559139307899]
	TIME [epoch: 6.34 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6849444158173321		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.6849444158173321 | validation: 0.34034491410253537]
	TIME [epoch: 6.3 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6862203621042916		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.6862203621042916 | validation: 0.34756799689978435]
	TIME [epoch: 6.3 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6834141690815781		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.6834141690815781 | validation: 0.348750493348126]
	TIME [epoch: 6.3 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6843482149783077		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.6843482149783077 | validation: 0.33696273337460225]
	TIME [epoch: 6.3 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6817914445732522		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.6817914445732522 | validation: 0.3363909936452726]
	TIME [epoch: 6.33 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.686609749852416		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.686609749852416 | validation: 0.34988743747803497]
	TIME [epoch: 6.33 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6843963154547892		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.6843963154547892 | validation: 0.3471248656049094]
	TIME [epoch: 6.29 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6831649993196113		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.6831649993196113 | validation: 0.3432784786621489]
	TIME [epoch: 6.29 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6866747595758401		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.6866747595758401 | validation: 0.34426295988306976]
	TIME [epoch: 6.3 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6837098255140233		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.6837098255140233 | validation: 0.3431421999309109]
	TIME [epoch: 6.29 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6814606317584528		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.6814606317584528 | validation: 0.34423773105084415]
	TIME [epoch: 6.32 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6861961506559855		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.6861961506559855 | validation: 0.34179071973648045]
	TIME [epoch: 6.32 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6894023276901291		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.6894023276901291 | validation: 0.3444570450550315]
	TIME [epoch: 6.3 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6849488251484379		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.6849488251484379 | validation: 0.34062405968255316]
	TIME [epoch: 6.3 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6811957828737437		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.6811957828737437 | validation: 0.3465737301953434]
	TIME [epoch: 6.29 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6817440821905916		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.6817440821905916 | validation: 0.3456636789351063]
	TIME [epoch: 6.3 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6813105408618122		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.6813105408618122 | validation: 0.3481430588042619]
	TIME [epoch: 6.34 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6833731012908374		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.6833731012908374 | validation: 0.34997573884643474]
	TIME [epoch: 6.3 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6838482784281459		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.6838482784281459 | validation: 0.34577717142821685]
	TIME [epoch: 6.3 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6816666165232732		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.6816666165232732 | validation: 0.3438148871021611]
	TIME [epoch: 6.3 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.68327939340966		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.68327939340966 | validation: 0.3415509759358127]
	TIME [epoch: 6.3 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6819175929630188		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.6819175929630188 | validation: 0.3449543838935873]
	TIME [epoch: 6.3 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6848040145999332		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.6848040145999332 | validation: 0.3439914478741807]
	TIME [epoch: 6.34 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6840319210496961		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.6840319210496961 | validation: 0.35073630800683797]
	TIME [epoch: 6.31 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.684121463983081		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.684121463983081 | validation: 0.33731160573413194]
	TIME [epoch: 6.3 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6864007900605918		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.6864007900605918 | validation: 0.34652229737062457]
	TIME [epoch: 6.31 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6843700484392218		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.6843700484392218 | validation: 0.33192400931759203]
	TIME [epoch: 6.3 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.685170498732953		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.685170498732953 | validation: 0.33511425550156576]
	TIME [epoch: 6.3 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6823226717455283		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.6823226717455283 | validation: 0.3484689856365547]
	TIME [epoch: 6.35 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.686561441638386		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.686561441638386 | validation: 0.33728365023937834]
	TIME [epoch: 6.31 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6882957896866235		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.6882957896866235 | validation: 0.3472940122816372]
	TIME [epoch: 6.31 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6882313926976302		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.6882313926976302 | validation: 0.326433007832767]
	TIME [epoch: 6.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_1273.pth
	Model improved!!!
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6832437290361175		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.6832437290361175 | validation: 0.3360074718789504]
	TIME [epoch: 6.31 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6858603949686009		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.6858603949686009 | validation: 0.34627716328953634]
	TIME [epoch: 6.31 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6877655034289242		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.6877655034289242 | validation: 0.3311061234887173]
	TIME [epoch: 6.35 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6847630137762967		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.6847630137762967 | validation: 0.3500360213141942]
	TIME [epoch: 6.31 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6886724346436585		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.6886724346436585 | validation: 0.3509841327658081]
	TIME [epoch: 6.3 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6823205675819981		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.6823205675819981 | validation: 0.3310400424442139]
	TIME [epoch: 6.3 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6837922845466955		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.6837922845466955 | validation: 0.3433431491905138]
	TIME [epoch: 6.3 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.680726755509857		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.680726755509857 | validation: 0.34388782704750265]
	TIME [epoch: 6.32 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6885572791300741		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.6885572791300741 | validation: 0.34279680463130785]
	TIME [epoch: 6.35 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6868764193017421		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.6868764193017421 | validation: 0.3403579852652898]
	TIME [epoch: 6.31 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6852984550552481		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.6852984550552481 | validation: 0.34306503541494776]
	TIME [epoch: 6.31 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6832086055488666		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.6832086055488666 | validation: 0.3425195699759013]
	TIME [epoch: 6.3 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6839381391395445		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.6839381391395445 | validation: 0.34676921361016366]
	TIME [epoch: 6.31 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6820847413649903		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.6820847413649903 | validation: 0.3389669967643937]
	TIME [epoch: 6.31 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.680386921851691		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.680386921851691 | validation: 0.3499460816354176]
	TIME [epoch: 6.35 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6840946865226885		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.6840946865226885 | validation: 0.33980918616301276]
	TIME [epoch: 6.31 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6836761309118038		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.6836761309118038 | validation: 0.3369277357455914]
	TIME [epoch: 6.31 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6815720030499004		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.6815720030499004 | validation: 0.34282700919616554]
	TIME [epoch: 6.3 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6824726809855426		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.6824726809855426 | validation: 0.339563264925897]
	TIME [epoch: 6.3 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6854189655383175		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.6854189655383175 | validation: 0.3358398279440852]
	TIME [epoch: 6.32 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6849177746343158		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.6849177746343158 | validation: 0.34816319017759373]
	TIME [epoch: 6.34 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6858290724682777		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.6858290724682777 | validation: 0.3428372765544571]
	TIME [epoch: 6.32 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6801180040682168		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.6801180040682168 | validation: 0.34258114642223786]
	TIME [epoch: 6.31 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6855027970343346		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.6855027970343346 | validation: 0.34848519823679436]
	TIME [epoch: 6.3 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6849071900951174		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.6849071900951174 | validation: 0.34111515665812153]
	TIME [epoch: 6.3 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6821928531625959		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.6821928531625959 | validation: 0.350765074253046]
	TIME [epoch: 6.33 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6839313829479965		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.6839313829479965 | validation: 0.3442582073868967]
	TIME [epoch: 6.33 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6843688507870022		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.6843688507870022 | validation: 0.343616722525732]
	TIME [epoch: 6.31 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6865615539713212		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.6865615539713212 | validation: 0.34287293125078155]
	TIME [epoch: 6.31 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.684000216451405		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.684000216451405 | validation: 0.3547862088777879]
	TIME [epoch: 6.31 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6840692016547456		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.6840692016547456 | validation: 0.34730695880298057]
	TIME [epoch: 6.31 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6830681318678926		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.6830681318678926 | validation: 0.3433199496177616]
	TIME [epoch: 6.34 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6869873745515355		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.6869873745515355 | validation: 0.34983913938271094]
	TIME [epoch: 6.32 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6827907611820873		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.6827907611820873 | validation: 0.34083653351104826]
	TIME [epoch: 6.3 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6870225551846979		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.6870225551846979 | validation: 0.3546533769661417]
	TIME [epoch: 6.32 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6866003186122411		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.6866003186122411 | validation: 0.34504660811734256]
	TIME [epoch: 6.32 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.682708119522075		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.682708119522075 | validation: 0.34207025818690223]
	TIME [epoch: 6.3 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.680174335567323		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.680174335567323 | validation: 0.3434056434172394]
	TIME [epoch: 6.36 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6865958040891702		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.6865958040891702 | validation: 0.3472948767774238]
	TIME [epoch: 6.32 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6860805742484896		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.6860805742484896 | validation: 0.34539966254810883]
	TIME [epoch: 6.31 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6843691017877755		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.6843691017877755 | validation: 0.33787430114235323]
	TIME [epoch: 6.31 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6831667301438369		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.6831667301438369 | validation: 0.33673969152559297]
	TIME [epoch: 6.31 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.682376697373593		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.682376697373593 | validation: 0.3460271982405091]
	TIME [epoch: 6.31 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6870340243474264		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.6870340243474264 | validation: 0.3288018315228296]
	TIME [epoch: 6.35 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6839223834444363		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.6839223834444363 | validation: 0.34863326159561525]
	TIME [epoch: 6.3 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6833997098014167		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.6833997098014167 | validation: 0.33932665420644303]
	TIME [epoch: 6.3 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6892751135693074		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.6892751135693074 | validation: 0.35275817145119304]
	TIME [epoch: 6.29 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6837913126547203		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.6837913126547203 | validation: 0.347827882086707]
	TIME [epoch: 6.29 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6836807029184191		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.6836807029184191 | validation: 0.3468535860718648]
	TIME [epoch: 6.3 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6843450975445416		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.6843450975445416 | validation: 0.34176104195928864]
	TIME [epoch: 6.35 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.681689228666795		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.681689228666795 | validation: 0.35213582869796606]
	TIME [epoch: 6.29 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6810811588328176		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.6810811588328176 | validation: 0.341624475521574]
	TIME [epoch: 6.3 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.684130513286795		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.684130513286795 | validation: 0.35136188077306224]
	TIME [epoch: 6.31 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6856317944987844		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.6856317944987844 | validation: 0.3352512010378495]
	TIME [epoch: 6.31 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6847679260251742		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.6847679260251742 | validation: 0.35402875956752977]
	TIME [epoch: 6.31 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6870689374416332		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.6870689374416332 | validation: 0.34379858251931505]
	TIME [epoch: 6.36 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6869284055521602		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.6869284055521602 | validation: 0.344095994327585]
	TIME [epoch: 6.32 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6859555937548742		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.6859555937548742 | validation: 0.3458645944026713]
	TIME [epoch: 6.31 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6800332664610392		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.6800332664610392 | validation: 0.34762562860768154]
	TIME [epoch: 6.31 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6856729474306315		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.6856729474306315 | validation: 0.34208454504503005]
	TIME [epoch: 6.3 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.679363034320991		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.679363034320991 | validation: 0.3415237925780781]
	TIME [epoch: 6.29 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6844889451271858		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.6844889451271858 | validation: 0.33203249522975004]
	TIME [epoch: 6.35 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6818048707514872		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.6818048707514872 | validation: 0.3453033834602278]
	TIME [epoch: 6.29 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6830754684081093		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.6830754684081093 | validation: 0.35068786216103953]
	TIME [epoch: 6.29 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6846480585526896		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.6846480585526896 | validation: 0.34044020576355394]
	TIME [epoch: 6.28 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.683828526045423		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.683828526045423 | validation: 0.349193084267881]
	TIME [epoch: 6.29 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6816010701780346		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.6816010701780346 | validation: 0.35359944922405334]
	TIME [epoch: 6.3 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.687372585326463		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.687372585326463 | validation: 0.3369911905653322]
	TIME [epoch: 6.32 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6820842899428647		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.6820842899428647 | validation: 0.34020886010879237]
	TIME [epoch: 6.29 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6877510103116337		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.6877510103116337 | validation: 0.3477317705381653]
	TIME [epoch: 6.28 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6858185443596249		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.6858185443596249 | validation: 0.3401691477333832]
	TIME [epoch: 6.29 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6867545736636834		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.6867545736636834 | validation: 0.3500777053860667]
	TIME [epoch: 6.29 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6850969158637223		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.6850969158637223 | validation: 0.33752766464451317]
	TIME [epoch: 6.3 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6868801435572549		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.6868801435572549 | validation: 0.33246480578326787]
	TIME [epoch: 6.32 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6818861928715994		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.6818861928715994 | validation: 0.33661459309430947]
	TIME [epoch: 6.29 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.681618788523316		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.681618788523316 | validation: 0.3446273976164794]
	TIME [epoch: 6.3 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6894029149081206		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.6894029149081206 | validation: 0.343266338901805]
	TIME [epoch: 6.28 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6872094562729965		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.6872094562729965 | validation: 0.3403688271901632]
	TIME [epoch: 6.29 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6848739528871504		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.6848739528871504 | validation: 0.328117364652781]
	TIME [epoch: 6.29 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6835044004766174		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.6835044004766174 | validation: 0.33584921153695274]
	TIME [epoch: 6.31 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6813703420654202		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.6813703420654202 | validation: 0.343859364325095]
	TIME [epoch: 6.28 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6838289188101871		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.6838289188101871 | validation: 0.3427334234594875]
	TIME [epoch: 6.29 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6876808852628129		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.6876808852628129 | validation: 0.3425555013041474]
	TIME [epoch: 6.29 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6797200263996905		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.6797200263996905 | validation: 0.34887421491012477]
	TIME [epoch: 6.28 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.680106614786776		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.680106614786776 | validation: 0.3399551647465041]
	TIME [epoch: 6.31 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6844109026390248		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.6844109026390248 | validation: 0.34076901080271715]
	TIME [epoch: 6.32 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6854436641707575		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.6854436641707575 | validation: 0.3421907250435814]
	TIME [epoch: 6.28 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.684452362578277		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.684452362578277 | validation: 0.34084102660359195]
	TIME [epoch: 6.29 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6858556377206301		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.6858556377206301 | validation: 0.34913427366758604]
	TIME [epoch: 6.29 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6814004164018129		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.6814004164018129 | validation: 0.34167355086602835]
	TIME [epoch: 6.28 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6850125402493568		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.6850125402493568 | validation: 0.34626143369084095]
	TIME [epoch: 6.31 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.682992694029548		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.682992694029548 | validation: 0.34722799067212173]
	TIME [epoch: 6.31 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6791417953953935		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.6791417953953935 | validation: 0.3486109807327131]
	TIME [epoch: 6.28 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6835549469075547		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.6835549469075547 | validation: 0.343745184171765]
	TIME [epoch: 6.28 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6837654150028037		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.6837654150028037 | validation: 0.3353879037762931]
	TIME [epoch: 6.28 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6866500733513		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.6866500733513 | validation: 0.34236075021119694]
	TIME [epoch: 6.28 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6841962681443218		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.6841962681443218 | validation: 0.34147969699276454]
	TIME [epoch: 6.32 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6842522087658451		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.6842522087658451 | validation: 0.3407585864279633]
	TIME [epoch: 6.3 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6844481496597228		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.6844481496597228 | validation: 0.33903307808476285]
	TIME [epoch: 6.28 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.684392274843174		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.684392274843174 | validation: 0.3435693924675781]
	TIME [epoch: 6.29 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6852535036692374		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.6852535036692374 | validation: 0.3406280262189771]
	TIME [epoch: 6.29 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6856724437850771		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.6856724437850771 | validation: 0.34306879135031665]
	TIME [epoch: 6.27 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6835396824262024		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.6835396824262024 | validation: 0.34235907083104833]
	TIME [epoch: 6.33 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6847169083742938		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.6847169083742938 | validation: 0.351047734720892]
	TIME [epoch: 6.31 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.686062499470553		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.686062499470553 | validation: 0.3338982395428962]
	TIME [epoch: 6.28 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6854282122779661		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.6854282122779661 | validation: 0.34061817610795403]
	TIME [epoch: 6.29 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6833998291636846		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.6833998291636846 | validation: 0.33986512243308054]
	TIME [epoch: 6.29 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6829880290113113		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.6829880290113113 | validation: 0.34246454929962844]
	TIME [epoch: 6.29 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6869681116542785		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.6869681116542785 | validation: 0.34802721697133654]
	TIME [epoch: 6.35 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6837431624595758		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.6837431624595758 | validation: 0.33656960792366497]
	TIME [epoch: 6.29 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6819173994289598		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.6819173994289598 | validation: 0.3364308825774851]
	TIME [epoch: 6.29 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6828210626481654		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.6828210626481654 | validation: 0.3450664086703491]
	TIME [epoch: 6.28 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6801851892460336		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.6801851892460336 | validation: 0.35203111501164924]
	TIME [epoch: 6.29 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6861732109416827		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.6861732109416827 | validation: 0.3463037013139243]
	TIME [epoch: 6.3 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6824876500349973		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.6824876500349973 | validation: 0.33702942319167906]
	TIME [epoch: 6.33 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6853223390056791		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.6853223390056791 | validation: 0.34717730384687406]
	TIME [epoch: 6.29 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.688048289599688		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.688048289599688 | validation: 0.34915043654641414]
	TIME [epoch: 6.3 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6822751403793351		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.6822751403793351 | validation: 0.3466938395134876]
	TIME [epoch: 6.28 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6821482203342673		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.6821482203342673 | validation: 0.3510906975579323]
	TIME [epoch: 6.29 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6865164863982758		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.6865164863982758 | validation: 0.3401964550399478]
	TIME [epoch: 6.28 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6826902032184734		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.6826902032184734 | validation: 0.3500466547840503]
	TIME [epoch: 6.33 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6859192504284983		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.6859192504284983 | validation: 0.3388164529217522]
	TIME [epoch: 6.28 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6859152775026427		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.6859152775026427 | validation: 0.3334491331264885]
	TIME [epoch: 6.29 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6836321883158624		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.6836321883158624 | validation: 0.3455942073642645]
	TIME [epoch: 6.28 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6872958659267971		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.6872958659267971 | validation: 0.3396575918073658]
	TIME [epoch: 6.29 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6836579764330851		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.6836579764330851 | validation: 0.3393023767271578]
	TIME [epoch: 6.29 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.684109570353246		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.684109570353246 | validation: 0.3448520899835232]
	TIME [epoch: 6.33 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6834257675790398		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.6834257675790398 | validation: 0.3369950026016011]
	TIME [epoch: 6.29 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6840542817955833		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.6840542817955833 | validation: 0.3497683453971387]
	TIME [epoch: 6.28 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.684183420248667		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.684183420248667 | validation: 0.3376512527599486]
	TIME [epoch: 6.29 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6820663997795485		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.6820663997795485 | validation: 0.33798704393515305]
	TIME [epoch: 6.28 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.683921854282554		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.683921854282554 | validation: 0.34292431010802615]
	TIME [epoch: 6.3 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6823111503643843		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.6823111503643843 | validation: 0.3510984042982795]
	TIME [epoch: 6.32 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6865975882716		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.6865975882716 | validation: 0.33726216974019435]
	TIME [epoch: 6.29 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.684952417657323		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.684952417657323 | validation: 0.34108748080277085]
	TIME [epoch: 6.3 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6839660643684207		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.6839660643684207 | validation: 0.33698364436072564]
	TIME [epoch: 6.29 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6878600293124334		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.6878600293124334 | validation: 0.3578912220567645]
	TIME [epoch: 6.28 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6861151385795549		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.6861151385795549 | validation: 0.3558128435644703]
	TIME [epoch: 6.31 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6868798210070901		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.6868798210070901 | validation: 0.3415598462419211]
	TIME [epoch: 6.32 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6887925667607973		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.6887925667607973 | validation: 0.3497309309165474]
	TIME [epoch: 6.28 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6843804430027842		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.6843804430027842 | validation: 0.3430313251741095]
	TIME [epoch: 6.29 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6840601688092225		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.6840601688092225 | validation: 0.3520164336778003]
	TIME [epoch: 6.29 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6822170559152275		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.6822170559152275 | validation: 0.3404145188755573]
	TIME [epoch: 6.29 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6812140569992562		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.6812140569992562 | validation: 0.34507309457732877]
	TIME [epoch: 6.3 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6856204694585176		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.6856204694585176 | validation: 0.3454487067259791]
	TIME [epoch: 6.33 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.684145809899033		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.684145809899033 | validation: 0.34156253760465893]
	TIME [epoch: 6.3 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6862143606158007		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.6862143606158007 | validation: 0.3328396551660927]
	TIME [epoch: 6.3 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6814858339278496		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.6814858339278496 | validation: 0.3440801136344057]
	TIME [epoch: 6.31 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6801730244335548		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.6801730244335548 | validation: 0.3412228259692509]
	TIME [epoch: 6.3 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6824154312626239		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.6824154312626239 | validation: 0.33656576442468417]
	TIME [epoch: 6.31 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6844791786872051		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.6844791786872051 | validation: 0.3377649171395492]
	TIME [epoch: 6.32 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6835346964799478		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.6835346964799478 | validation: 0.3432957961814606]
	TIME [epoch: 6.3 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6857804161380844		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.6857804161380844 | validation: 0.337721317413447]
	TIME [epoch: 6.31 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6837413787240905		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.6837413787240905 | validation: 0.3374903501206944]
	TIME [epoch: 6.29 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.68675977585868		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.68675977585868 | validation: 0.35849240263747617]
	TIME [epoch: 6.29 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6849325995974112		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.6849325995974112 | validation: 0.34046995212175857]
	TIME [epoch: 6.33 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6839282813439291		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.6839282813439291 | validation: 0.34572541865106654]
	TIME [epoch: 6.3 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6854239932318743		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.6854239932318743 | validation: 0.34192187245121924]
	TIME [epoch: 6.3 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.683810888031889		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.683810888031889 | validation: 0.34502626885355153]
	TIME [epoch: 6.29 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.684124274438971		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.684124274438971 | validation: 0.33308994482406756]
	TIME [epoch: 6.28 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6806651369657912		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.6806651369657912 | validation: 0.3443012687865142]
	TIME [epoch: 6.28 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6843389834357285		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.6843389834357285 | validation: 0.35135482691254427]
	TIME [epoch: 6.35 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6818092190615965		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.6818092190615965 | validation: 0.3440461105792006]
	TIME [epoch: 6.31 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6840214325620715		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.6840214325620715 | validation: 0.34230210466365885]
	TIME [epoch: 6.29 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6848856032368703		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.6848856032368703 | validation: 0.3452487248357295]
	TIME [epoch: 6.28 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6810934444496982		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.6810934444496982 | validation: 0.3486003673870313]
	TIME [epoch: 6.28 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6823979824219262		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.6823979824219262 | validation: 0.34301634867138264]
	TIME [epoch: 6.3 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6879335008195204		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.6879335008195204 | validation: 0.33276337864849864]
	TIME [epoch: 6.35 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6847119165458809		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.6847119165458809 | validation: 0.34210107084625946]
	TIME [epoch: 6.3 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6848432820604403		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.6848432820604403 | validation: 0.3406339375690467]
	TIME [epoch: 6.3 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6837750741313244		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.6837750741313244 | validation: 0.3330040960800059]
	TIME [epoch: 6.3 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.685764623006151		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.685764623006151 | validation: 0.33950841970267137]
	TIME [epoch: 6.29 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6830119977285128		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.6830119977285128 | validation: 0.33895957717337444]
	TIME [epoch: 6.29 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6854762854845267		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.6854762854845267 | validation: 0.33859202111314235]
	TIME [epoch: 6.34 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6852004546849998		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.6852004546849998 | validation: 0.3351279590147011]
	TIME [epoch: 6.29 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6867662468408718		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.6867662468408718 | validation: 0.3405457770566602]
	TIME [epoch: 6.29 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6804447450280862		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.6804447450280862 | validation: 0.3490936346505036]
	TIME [epoch: 6.29 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6852516461041069		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.6852516461041069 | validation: 0.34615076101927167]
	TIME [epoch: 6.28 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6838498215451729		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.6838498215451729 | validation: 0.33610306608872415]
	TIME [epoch: 6.3 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6833930301784663		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.6833930301784663 | validation: 0.3413437707181526]
	TIME [epoch: 6.33 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6846671436887908		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.6846671436887908 | validation: 0.34707741948393606]
	TIME [epoch: 6.3 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.684382683646827		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.684382683646827 | validation: 0.3406871522394264]
	TIME [epoch: 6.31 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6825576535582016		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.6825576535582016 | validation: 0.3379061465109507]
	TIME [epoch: 6.29 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6831871042188682		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.6831871042188682 | validation: 0.33530828618545433]
	TIME [epoch: 6.29 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6886260678648819		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.6886260678648819 | validation: 0.33534792148302817]
	TIME [epoch: 6.29 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6860591914659763		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.6860591914659763 | validation: 0.3368321182585752]
	TIME [epoch: 6.35 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6838751036001104		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.6838751036001104 | validation: 0.3403030219095664]
	TIME [epoch: 6.31 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6849074036981411		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.6849074036981411 | validation: 0.34034083993161485]
	TIME [epoch: 6.3 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6808096776990128		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.6808096776990128 | validation: 0.34677048488934087]
	TIME [epoch: 6.3 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6871646707931394		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.6871646707931394 | validation: 0.34154378357280735]
	TIME [epoch: 6.3 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6817072244412286		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.6817072244412286 | validation: 0.34548242355541675]
	TIME [epoch: 6.31 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6900767854867486		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.6900767854867486 | validation: 0.3463100245619587]
	TIME [epoch: 6.35 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.681690192629852		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.681690192629852 | validation: 0.3458993573219067]
	TIME [epoch: 6.31 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6843719971688685		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.6843719971688685 | validation: 0.33599979682902503]
	TIME [epoch: 6.3 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6828770641242041		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.6828770641242041 | validation: 0.34313229735210027]
	TIME [epoch: 6.3 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6874516486589188		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.6874516486589188 | validation: 0.339435882142631]
	TIME [epoch: 6.31 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6863328245399799		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.6863328245399799 | validation: 0.3489053859536776]
	TIME [epoch: 6.31 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6846483212438519		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.6846483212438519 | validation: 0.34628344749472817]
	TIME [epoch: 6.34 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6854533869847609		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.6854533869847609 | validation: 0.33809555133899094]
	TIME [epoch: 6.3 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6827283184308806		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.6827283184308806 | validation: 0.35169690049845814]
	TIME [epoch: 6.31 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.68514485563883		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.68514485563883 | validation: 0.33638833487542796]
	TIME [epoch: 6.29 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6847698490893097		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.6847698490893097 | validation: 0.338115914693085]
	TIME [epoch: 6.29 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6853881211808626		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.6853881211808626 | validation: 0.32821036469714066]
	TIME [epoch: 6.31 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6829279786633258		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.6829279786633258 | validation: 0.33997954315015416]
	TIME [epoch: 6.34 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6845172402406958		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.6845172402406958 | validation: 0.34879053984590846]
	TIME [epoch: 6.29 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6842243602942437		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.6842243602942437 | validation: 0.35297439191591395]
	TIME [epoch: 6.3 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6841428559483516		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.6841428559483516 | validation: 0.34240643037471113]
	TIME [epoch: 6.3 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6859399292589539		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.6859399292589539 | validation: 0.3422628621193134]
	TIME [epoch: 6.31 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6848580286341188		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.6848580286341188 | validation: 0.3311326546271229]
	TIME [epoch: 6.32 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6862660577215054		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.6862660577215054 | validation: 0.33465920470296034]
	TIME [epoch: 6.34 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6793209493433667		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.6793209493433667 | validation: 0.3439171913387554]
	TIME [epoch: 6.31 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6859500294202052		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.6859500294202052 | validation: 0.3409161472083136]
	TIME [epoch: 6.29 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6840580855424738		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.6840580855424738 | validation: 0.33937583403584426]
	TIME [epoch: 6.29 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6889481530492093		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.6889481530492093 | validation: 0.33454248335602527]
	TIME [epoch: 6.29 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6824670962452025		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.6824670962452025 | validation: 0.3483566290160177]
	TIME [epoch: 6.36 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6827993798192066		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.6827993798192066 | validation: 0.3474468287005369]
	TIME [epoch: 6.31 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6835562808357307		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.6835562808357307 | validation: 0.3463266305884378]
	TIME [epoch: 6.31 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6836861249420968		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.6836861249420968 | validation: 0.3366650333405221]
	TIME [epoch: 6.3 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6856048074312138		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.6856048074312138 | validation: 0.3460864716208624]
	TIME [epoch: 6.31 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6855377995608114		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.6855377995608114 | validation: 0.33432459943055426]
	TIME [epoch: 6.3 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6893119056396304		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.6893119056396304 | validation: 0.33811567150466565]
	TIME [epoch: 6.34 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6857784296557977		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.6857784296557977 | validation: 0.3323385185525152]
	TIME [epoch: 6.32 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6823757988860294		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.6823757988860294 | validation: 0.3330497990341415]
	TIME [epoch: 6.3 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6847771587492566		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.6847771587492566 | validation: 0.34827356081083927]
	TIME [epoch: 6.29 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6838810990405219		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.6838810990405219 | validation: 0.33373489347878177]
	TIME [epoch: 6.3 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6865701666189878		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.6865701666189878 | validation: 0.3343019498324784]
	TIME [epoch: 6.3 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6827452515154099		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.6827452515154099 | validation: 0.34913043093795876]
	TIME [epoch: 6.35 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6824774952439752		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.6824774952439752 | validation: 0.3463861328970379]
	TIME [epoch: 6.31 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.680741303596429		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.680741303596429 | validation: 0.3406190553850641]
	TIME [epoch: 6.29 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6836362283261577		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.6836362283261577 | validation: 0.3356541645750916]
	TIME [epoch: 6.3 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6837550161545627		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.6837550161545627 | validation: 0.3561578454422323]
	TIME [epoch: 6.31 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6862663194778826		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.6862663194778826 | validation: 0.347207881921422]
	TIME [epoch: 6.3 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6845975128371585		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.6845975128371585 | validation: 0.33497638882406533]
	TIME [epoch: 6.36 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6815314191289644		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.6815314191289644 | validation: 0.3444760792917094]
	TIME [epoch: 6.3 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6858457580198303		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.6858457580198303 | validation: 0.3464098199880224]
	TIME [epoch: 6.3 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6871403157153726		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.6871403157153726 | validation: 0.3478681374499679]
	TIME [epoch: 6.29 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6829680190975276		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.6829680190975276 | validation: 0.3395451652002377]
	TIME [epoch: 6.31 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6833447269580706		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.6833447269580706 | validation: 0.349626210642029]
	TIME [epoch: 6.3 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6809028942973729		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.6809028942973729 | validation: 0.3424711241446637]
	TIME [epoch: 6.35 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6853947715520838		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.6853947715520838 | validation: 0.34164965055875723]
	TIME [epoch: 6.31 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.682940931670159		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.682940931670159 | validation: 0.3394908324856401]
	TIME [epoch: 6.31 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6828084113581584		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.6828084113581584 | validation: 0.34255862607816234]
	TIME [epoch: 6.3 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6837585364547832		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.6837585364547832 | validation: 0.3437696200992777]
	TIME [epoch: 6.32 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6804479695796346		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.6804479695796346 | validation: 0.3354064420826537]
	TIME [epoch: 6.3 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6868549144491847		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.6868549144491847 | validation: 0.3494467433728153]
	TIME [epoch: 6.36 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6857645943393578		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.6857645943393578 | validation: 0.3407731423384045]
	TIME [epoch: 6.31 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6798315716707498		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.6798315716707498 | validation: 0.33020917356155904]
	TIME [epoch: 6.3 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6838081640507171		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.6838081640507171 | validation: 0.34334741891201986]
	TIME [epoch: 6.31 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6826565995238709		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.6826565995238709 | validation: 0.3501543947358145]
	TIME [epoch: 6.31 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6804182068888349		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.6804182068888349 | validation: 0.3422745009932928]
	TIME [epoch: 6.31 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.684941203519694		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.684941203519694 | validation: 0.3412179098274606]
	TIME [epoch: 6.35 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6838469195189351		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.6838469195189351 | validation: 0.34531946845832345]
	TIME [epoch: 6.3 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6822189494382495		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.6822189494382495 | validation: 0.3486037170788615]
	TIME [epoch: 6.31 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6855885829194839		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.6855885829194839 | validation: 0.3384840492621818]
	TIME [epoch: 6.3 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6798928163135771		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.6798928163135771 | validation: 0.34836279530911207]
	TIME [epoch: 6.31 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6833849003794545		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.6833849003794545 | validation: 0.3509431976541972]
	TIME [epoch: 6.32 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6826667172011078		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.6826667172011078 | validation: 0.3455481181595621]
	TIME [epoch: 6.35 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6839850017367913		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.6839850017367913 | validation: 0.3418511410416305]
	TIME [epoch: 6.32 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6823346186031084		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.6823346186031084 | validation: 0.35119096003550637]
	TIME [epoch: 6.3 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6832078549572125		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.6832078549572125 | validation: 0.34344124351875693]
	TIME [epoch: 6.3 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6840533754234416		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.6840533754234416 | validation: 0.34883381967166394]
	TIME [epoch: 6.31 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6822761153012348		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.6822761153012348 | validation: 0.3385211106651357]
	TIME [epoch: 6.32 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6823465583907663		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.6823465583907663 | validation: 0.3428563384558848]
	TIME [epoch: 6.33 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6827483256879432		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.6827483256879432 | validation: 0.34237303738361113]
	TIME [epoch: 6.31 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6838741313880952		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.6838741313880952 | validation: 0.3394905051996138]
	TIME [epoch: 6.31 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6843758947962538		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.6843758947962538 | validation: 0.3385808177835782]
	TIME [epoch: 6.3 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6835646609284459		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.6835646609284459 | validation: 0.3435480249666671]
	TIME [epoch: 6.31 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.684836371993341		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.684836371993341 | validation: 0.3401675392747842]
	TIME [epoch: 6.33 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.684149658514793		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.684149658514793 | validation: 0.3404641176510434]
	TIME [epoch: 6.33 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.684700338935369		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.684700338935369 | validation: 0.33443287532236393]
	TIME [epoch: 6.31 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6864301056325913		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.6864301056325913 | validation: 0.34147389082708063]
	TIME [epoch: 6.3 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.681465446649123		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.681465446649123 | validation: 0.3443938029695897]
	TIME [epoch: 6.31 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6813535596617669		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.6813535596617669 | validation: 0.33296067324943773]
	TIME [epoch: 6.3 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6820423022712649		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.6820423022712649 | validation: 0.333299759265055]
	TIME [epoch: 6.36 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6845014517049025		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.6845014517049025 | validation: 0.34099153345328004]
	TIME [epoch: 6.31 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.683689199281142		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.683689199281142 | validation: 0.33913769907918817]
	TIME [epoch: 6.3 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6862605426748545		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.6862605426748545 | validation: 0.34447829155740006]
	TIME [epoch: 6.31 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6809161582176297		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.6809161582176297 | validation: 0.33418941120215223]
	TIME [epoch: 6.28 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6834402373323523		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.6834402373323523 | validation: 0.3391692133937007]
	TIME [epoch: 6.29 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6860892433539688		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.6860892433539688 | validation: 0.3469583201683865]
	TIME [epoch: 6.34 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6874448615529805		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.6874448615529805 | validation: 0.34072814143446273]
	TIME [epoch: 6.29 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6853928114591107		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.6853928114591107 | validation: 0.33411538261241325]
	TIME [epoch: 6.28 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6801770972245542		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.6801770972245542 | validation: 0.3418534714039077]
	TIME [epoch: 6.3 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6787703781697378		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.6787703781697378 | validation: 0.35036490779752766]
	TIME [epoch: 6.3 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6842973598052362		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.6842973598052362 | validation: 0.3350489944374504]
	TIME [epoch: 6.29 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6821521318540539		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.6821521318540539 | validation: 0.34281894596706797]
	TIME [epoch: 6.34 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6872793568196679		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.6872793568196679 | validation: 0.34065100640065665]
	TIME [epoch: 6.3 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6847501217640055		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.6847501217640055 | validation: 0.35566675091716415]
	TIME [epoch: 6.29 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6821885179563704		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.6821885179563704 | validation: 0.3292122072760373]
	TIME [epoch: 6.29 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6816481418059382		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.6816481418059382 | validation: 0.34275817723009383]
	TIME [epoch: 6.3 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6871041663115439		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.6871041663115439 | validation: 0.34401065205481246]
	TIME [epoch: 6.29 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6824701590202431		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.6824701590202431 | validation: 0.32785671715017184]
	TIME [epoch: 6.33 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6835304559611933		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.6835304559611933 | validation: 0.3501156139574083]
	TIME [epoch: 6.3 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6828829361751684		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.6828829361751684 | validation: 0.3455742213620885]
	TIME [epoch: 6.3 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.683882052078805		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.683882052078805 | validation: 0.34150646409567154]
	TIME [epoch: 6.29 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6823267654053634		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.6823267654053634 | validation: 0.3413596214227111]
	TIME [epoch: 6.3 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6879109899547088		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.6879109899547088 | validation: 0.3434902143344239]
	TIME [epoch: 6.29 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6865140992404022		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.6865140992404022 | validation: 0.33742343198925784]
	TIME [epoch: 6.34 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.684765661745913		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.684765661745913 | validation: 0.3390573090979968]
	TIME [epoch: 6.29 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6872709664489923		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.6872709664489923 | validation: 0.3422262105012079]
	TIME [epoch: 6.28 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6851788919246959		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.6851788919246959 | validation: 0.3424855622947756]
	TIME [epoch: 6.3 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.681623531691236		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.681623531691236 | validation: 0.3346974439019137]
	TIME [epoch: 6.3 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6864240997485758		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.6864240997485758 | validation: 0.3461480949539741]
	TIME [epoch: 6.32 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6840448321413922		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.6840448321413922 | validation: 0.34660460084043293]
	TIME [epoch: 6.32 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6820824442521135		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.6820824442521135 | validation: 0.34511282051819325]
	TIME [epoch: 6.3 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.683145991040061		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.683145991040061 | validation: 0.3408593897624048]
	TIME [epoch: 6.3 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6829929505743317		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.6829929505743317 | validation: 0.33729162744704433]
	TIME [epoch: 6.3 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6839773327965565		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.6839773327965565 | validation: 0.3415836927378631]
	TIME [epoch: 6.3 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6811469698684978		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.6811469698684978 | validation: 0.34851684583457415]
	TIME [epoch: 6.29 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6846352745546949		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.6846352745546949 | validation: 0.3396801034364903]
	TIME [epoch: 6.34 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6863659819596447		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.6863659819596447 | validation: 0.3366303603171248]
	TIME [epoch: 6.28 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6828759875259499		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.6828759875259499 | validation: 0.34343211162736154]
	TIME [epoch: 6.3 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6839097455638725		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.6839097455638725 | validation: 0.33524226765985576]
	TIME [epoch: 6.29 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6840049889455028		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.6840049889455028 | validation: 0.34914527460103784]
	TIME [epoch: 6.28 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6840590346364632		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.6840590346364632 | validation: 0.3342266638588413]
	TIME [epoch: 6.29 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6833639110750765		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.6833639110750765 | validation: 0.3484315727616294]
	TIME [epoch: 6.34 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6824097197140276		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.6824097197140276 | validation: 0.3496228949338631]
	TIME [epoch: 6.3 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6855917805490652		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.6855917805490652 | validation: 0.3417120441681102]
	TIME [epoch: 6.3 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6825992156128408		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.6825992156128408 | validation: 0.33761668366862374]
	TIME [epoch: 6.31 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6782338459977948		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.6782338459977948 | validation: 0.3366945286761229]
	TIME [epoch: 6.3 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6849520557445647		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.6849520557445647 | validation: 0.3402256445096992]
	TIME [epoch: 6.34 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6861564878871899		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.6861564878871899 | validation: 0.3419132123335588]
	TIME [epoch: 6.34 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6826296610639897		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.6826296610639897 | validation: 0.351544842092133]
	TIME [epoch: 6.31 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6834822848112059		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.6834822848112059 | validation: 0.342801720749199]
	TIME [epoch: 6.29 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.681994756426851		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.681994756426851 | validation: 0.3372679012577086]
	TIME [epoch: 6.31 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6818050652192287		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.6818050652192287 | validation: 0.338670745015612]
	TIME [epoch: 6.3 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6813372163652078		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.6813372163652078 | validation: 0.3477991934882551]
	TIME [epoch: 6.33 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6840299565511876		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.6840299565511876 | validation: 0.3471678630218896]
	TIME [epoch: 6.32 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6838040940277508		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.6838040940277508 | validation: 0.3366861002135677]
	TIME [epoch: 6.3 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6785190812994493		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.6785190812994493 | validation: 0.3378592417103179]
	TIME [epoch: 6.29 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6844680544430866		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.6844680544430866 | validation: 0.3466588642266046]
	TIME [epoch: 6.29 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6792093744044096		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.6792093744044096 | validation: 0.3418201749155747]
	TIME [epoch: 6.31 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6796166298361848		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.6796166298361848 | validation: 0.34220518286615725]
	TIME [epoch: 6.34 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6808083924480783		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.6808083924480783 | validation: 0.3424695489274952]
	TIME [epoch: 6.3 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6819428312373768		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.6819428312373768 | validation: 0.3239157654116708]
	TIME [epoch: 6.28 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240311_131333/states/model_phi2_1a_v1_1608.pth
	Model improved!!!
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6792787263072473		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.6792787263072473 | validation: 0.3374016086993154]
	TIME [epoch: 6.29 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6847815827336035		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.6847815827336035 | validation: 0.3466622081056275]
	TIME [epoch: 6.29 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6827577992323357		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.6827577992323357 | validation: 0.3447970209367573]
	TIME [epoch: 6.3 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6867137205544602		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.6867137205544602 | validation: 0.3323723196699777]
	TIME [epoch: 6.34 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.685147592093559		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.685147592093559 | validation: 0.3399658365766842]
	TIME [epoch: 6.3 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6826019760761916		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.6826019760761916 | validation: 0.33611942213020446]
	TIME [epoch: 6.31 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6840061672489631		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.6840061672489631 | validation: 0.3396238627363073]
	TIME [epoch: 6.3 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6828786010836443		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.6828786010836443 | validation: 0.3443206636834977]
	TIME [epoch: 6.3 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6851956213676057		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.6851956213676057 | validation: 0.3418978945914975]
	TIME [epoch: 6.31 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6861963453265877		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.6861963453265877 | validation: 0.34091394029254646]
	TIME [epoch: 6.35 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6845864205174811		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.6845864205174811 | validation: 0.34359481999191976]
	TIME [epoch: 6.3 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6868885425766409		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.6868885425766409 | validation: 0.34391815101135204]
	TIME [epoch: 6.3 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6840333599575849		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.6840333599575849 | validation: 0.34792662030200533]
	TIME [epoch: 6.29 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6821010729509676		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.6821010729509676 | validation: 0.34779665028705686]
	TIME [epoch: 6.29 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.682408434909517		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.682408434909517 | validation: 0.3389171243998764]
	TIME [epoch: 6.3 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6841645853837139		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.6841645853837139 | validation: 0.3487695761152834]
	TIME [epoch: 6.33 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6847166671315811		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.6847166671315811 | validation: 0.3442255333348707]
	TIME [epoch: 6.3 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6842750796594906		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.6842750796594906 | validation: 0.3524129870103477]
	TIME [epoch: 6.29 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6843135275408108		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.6843135275408108 | validation: 0.34992933166673473]
	TIME [epoch: 6.28 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6826122592190998		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.6826122592190998 | validation: 0.3441542400325991]
	TIME [epoch: 6.3 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6879576578485538		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.6879576578485538 | validation: 0.3384210886633496]
	TIME [epoch: 6.3 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6815476231298377		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.6815476231298377 | validation: 0.340314012138889]
	TIME [epoch: 6.33 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6838867807658169		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.6838867807658169 | validation: 0.3509027064410469]
	TIME [epoch: 6.28 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6836183197404965		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.6836183197404965 | validation: 0.3394399468706901]
	TIME [epoch: 6.29 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6834178838785709		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.6834178838785709 | validation: 0.3517995461612305]
	TIME [epoch: 6.29 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6843800291495075		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.6843800291495075 | validation: 0.3456302581263907]
	TIME [epoch: 6.28 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6875477991028855		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.6875477991028855 | validation: 0.3427344026322337]
	TIME [epoch: 6.29 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6861744794600428		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.6861744794600428 | validation: 0.3420964815873742]
	TIME [epoch: 6.33 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6849823285150437		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.6849823285150437 | validation: 0.34662592719790875]
	TIME [epoch: 6.29 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6857787282605066		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.6857787282605066 | validation: 0.34502694250581145]
	TIME [epoch: 6.37 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6828853594943911		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.6828853594943911 | validation: 0.3454273564920912]
	TIME [epoch: 6.31 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6827892745954924		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.6827892745954924 | validation: 0.33884874092136996]
	TIME [epoch: 6.29 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6869307958558728		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.6869307958558728 | validation: 0.3401554326019528]
	TIME [epoch: 6.34 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6827500130431593		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.6827500130431593 | validation: 0.340480699610231]
	TIME [epoch: 6.33 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6854633596053425		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.6854633596053425 | validation: 0.34721512006729416]
	TIME [epoch: 6.3 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6851230059953701		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.6851230059953701 | validation: 0.33776467684927114]
	TIME [epoch: 6.3 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6860128766647485		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.6860128766647485 | validation: 0.3386612475971148]
	TIME [epoch: 6.29 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6848751997381844		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.6848751997381844 | validation: 0.3403942863417894]
	TIME [epoch: 6.3 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6847610746575671		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.6847610746575671 | validation: 0.34852849895713106]
	TIME [epoch: 6.33 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6806458382718819		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.6806458382718819 | validation: 0.3529725095032482]
	TIME [epoch: 6.34 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6852906015247229		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.6852906015247229 | validation: 0.3599756903673584]
	TIME [epoch: 6.31 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6825820931320336		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.6825820931320336 | validation: 0.3425213098664217]
	TIME [epoch: 6.32 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6864929486414061		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.6864929486414061 | validation: 0.3405335291527972]
	TIME [epoch: 6.31 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6836818123229028		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.6836818123229028 | validation: 0.34898332197164644]
	TIME [epoch: 6.3 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6809538162895635		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.6809538162895635 | validation: 0.3345228924349815]
	TIME [epoch: 6.33 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6825474852594839		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.6825474852594839 | validation: 0.3393065320452481]
	TIME [epoch: 6.29 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6839243138487141		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.6839243138487141 | validation: 0.3437660476094665]
	TIME [epoch: 6.3 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6866661920847257		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.6866661920847257 | validation: 0.3455068678060995]
	TIME [epoch: 6.3 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6871571852463141		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.6871571852463141 | validation: 0.3323106340952712]
	TIME [epoch: 6.3 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6840966969581515		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.6840966969581515 | validation: 0.33342216436317856]
	TIME [epoch: 6.29 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6840203509220295		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.6840203509220295 | validation: 0.3411662337182665]
	TIME [epoch: 6.34 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6829649264639572		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.6829649264639572 | validation: 0.3382198286571404]
	TIME [epoch: 6.3 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6846236632209499		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.6846236632209499 | validation: 0.3402612570697388]
	TIME [epoch: 6.31 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6839885035508395		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.6839885035508395 | validation: 0.33338197699960065]
	TIME [epoch: 6.3 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6867892510723221		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.6867892510723221 | validation: 0.33974732387220224]
	TIME [epoch: 6.3 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6825042303134812		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.6825042303134812 | validation: 0.34850991920006225]
	TIME [epoch: 6.29 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6817324534554997		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.6817324534554997 | validation: 0.3294466599491928]
	TIME [epoch: 6.34 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6853468927992049		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.6853468927992049 | validation: 0.3460783327785593]
	TIME [epoch: 6.31 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6821913074958192		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.6821913074958192 | validation: 0.34749049776792057]
	TIME [epoch: 6.31 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6835480855885779		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.6835480855885779 | validation: 0.3509855282442218]
	TIME [epoch: 6.3 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6835674328573079		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.6835674328573079 | validation: 0.3440398830460024]
	TIME [epoch: 6.3 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6873230460426674		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.6873230460426674 | validation: 0.3492121003800792]
	TIME [epoch: 6.29 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.684127697269016		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.684127697269016 | validation: 0.3500886430720322]
	TIME [epoch: 6.34 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6807560531343736		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.6807560531343736 | validation: 0.34667462605140054]
	TIME [epoch: 6.31 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6838150746145574		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.6838150746145574 | validation: 0.3417559430722057]
	TIME [epoch: 6.29 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6769780962539725		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.6769780962539725 | validation: 0.33066394037933705]
	TIME [epoch: 6.29 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6851973299729356		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.6851973299729356 | validation: 0.3347986533023262]
	TIME [epoch: 6.29 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6852126708085975		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.6852126708085975 | validation: 0.33879708168380923]
	TIME [epoch: 6.3 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6829311922044954		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.6829311922044954 | validation: 0.34570411288319913]
	TIME [epoch: 6.36 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6854889534389728		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.6854889534389728 | validation: 0.3444308732372974]
	TIME [epoch: 6.3 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6846731799033314		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.6846731799033314 | validation: 0.3412388238203265]
	TIME [epoch: 6.29 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6810921314676545		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.6810921314676545 | validation: 0.3399834853796846]
	TIME [epoch: 6.29 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.68355842286948		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.68355842286948 | validation: 0.34984887019169536]
	TIME [epoch: 6.29 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.684697149077516		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.684697149077516 | validation: 0.3404512228358734]
	TIME [epoch: 6.3 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6841410826200695		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.6841410826200695 | validation: 0.3398911427340251]
	TIME [epoch: 6.34 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6855381601959104		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.6855381601959104 | validation: 0.3506527840558824]
	TIME [epoch: 6.31 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6876972612843544		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.6876972612843544 | validation: 0.33546345339760747]
	TIME [epoch: 6.31 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6864369806168433		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.6864369806168433 | validation: 0.3433699891744623]
	TIME [epoch: 6.31 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6842000431331967		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.6842000431331967 | validation: 0.3426155276926545]
	TIME [epoch: 6.29 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6820058603448915		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.6820058603448915 | validation: 0.3419997507957721]
	TIME [epoch: 6.32 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.684791532656286		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.684791532656286 | validation: 0.32679918433205984]
	TIME [epoch: 6.34 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6809976892179794		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.6809976892179794 | validation: 0.3411074833135893]
	TIME [epoch: 6.32 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6838058362899836		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.6838058362899836 | validation: 0.3472972288512423]
	TIME [epoch: 6.32 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.682599877196612		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.682599877196612 | validation: 0.3439803918569625]
	TIME [epoch: 6.31 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6850946576012247		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.6850946576012247 | validation: 0.343386161239791]
	TIME [epoch: 6.31 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6811633425612089		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.6811633425612089 | validation: 0.34579832833871993]
	TIME [epoch: 6.31 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6833001835473583		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.6833001835473583 | validation: 0.34805449496353297]
	TIME [epoch: 6.32 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.682672354445065		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.682672354445065 | validation: 0.3480633948174443]
	TIME [epoch: 6.29 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6821987531034341		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.6821987531034341 | validation: 0.34371861242388263]
	TIME [epoch: 6.3 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6811285886955502		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.6811285886955502 | validation: 0.3452240804175106]
	TIME [epoch: 6.3 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.684156117138361		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.684156117138361 | validation: 0.34252523661923934]
	TIME [epoch: 6.31 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.682408416587923		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.682408416587923 | validation: 0.3438616429091841]
	TIME [epoch: 6.32 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6833247793689696		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.6833247793689696 | validation: 0.340362809803265]
	TIME [epoch: 6.32 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6857758633883093		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.6857758633883093 | validation: 0.34267738804498915]
	TIME [epoch: 6.3 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6789151490011169		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.6789151490011169 | validation: 0.34254483951955406]
	TIME [epoch: 6.3 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6852847282616905		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.6852847282616905 | validation: 0.3384142555336901]
	TIME [epoch: 6.31 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6867273397187997		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.6867273397187997 | validation: 0.33632421691753067]
	TIME [epoch: 6.3 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6857034669766372		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.6857034669766372 | validation: 0.3408946039764315]
	TIME [epoch: 6.34 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6848171221978012		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.6848171221978012 | validation: 0.3538031498996201]
	TIME [epoch: 6.34 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6836636026683799		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.6836636026683799 | validation: 0.3452074153837145]
	TIME [epoch: 6.3 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6841672482072534		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.6841672482072534 | validation: 0.34021088470047967]
	TIME [epoch: 6.31 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6872607770850272		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.6872607770850272 | validation: 0.34455080513200564]
	TIME [epoch: 6.31 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6823328628008039		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.6823328628008039 | validation: 0.34678597076642503]
	TIME [epoch: 6.3 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6851433138946281		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.6851433138946281 | validation: 0.3317159073245838]
	TIME [epoch: 6.33 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6842251828038782		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.6842251828038782 | validation: 0.3435281767651548]
	TIME [epoch: 6.3 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6829262523506379		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.6829262523506379 | validation: 0.3421744953676685]
	TIME [epoch: 6.3 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6842017469448373		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.6842017469448373 | validation: 0.34750690890360825]
	TIME [epoch: 6.3 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6823070330043798		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.6823070330043798 | validation: 0.3466803834560483]
	TIME [epoch: 6.32 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.685196770995338		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.685196770995338 | validation: 0.34062707092448674]
	TIME [epoch: 6.31 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6863517450778834		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.6863517450778834 | validation: 0.3466402552289249]
	TIME [epoch: 6.35 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6859978466426019		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.6859978466426019 | validation: 0.3488930653092141]
	TIME [epoch: 6.31 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6849634059625627		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.6849634059625627 | validation: 0.35060823367719457]
	TIME [epoch: 6.3 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6807262455885428		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.6807262455885428 | validation: 0.3391318945404648]
	TIME [epoch: 6.3 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6830634997234113		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.6830634997234113 | validation: 0.33345111733661364]
	TIME [epoch: 6.31 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6847153636198027		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.6847153636198027 | validation: 0.3351279211870412]
	TIME [epoch: 6.31 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6856913560916187		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.6856913560916187 | validation: 0.33697045368177325]
	TIME [epoch: 6.35 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6868603665457034		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.6868603665457034 | validation: 0.3467998672097963]
	TIME [epoch: 6.31 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6827521755727134		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.6827521755727134 | validation: 0.3558734080872913]
	TIME [epoch: 6.3 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6828607961113753		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.6828607961113753 | validation: 0.34587201094798187]
	TIME [epoch: 6.31 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6884522229274005		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.6884522229274005 | validation: 0.3358695209739012]
	TIME [epoch: 6.31 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6817813303335927		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.6817813303335927 | validation: 0.33877560507958177]
	TIME [epoch: 6.32 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6828069433815898		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.6828069433815898 | validation: 0.3436385247335477]
	TIME [epoch: 6.36 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6859471964962578		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.6859471964962578 | validation: 0.3393913395272332]
	TIME [epoch: 6.3 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6858248322597364		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.6858248322597364 | validation: 0.34034853741851206]
	TIME [epoch: 6.31 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6836167109386124		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.6836167109386124 | validation: 0.33743688230007785]
	TIME [epoch: 6.3 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6864854026261572		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.6864854026261572 | validation: 0.3446444018449623]
	TIME [epoch: 6.29 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6853836318822348		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.6853836318822348 | validation: 0.34501929183623203]
	TIME [epoch: 6.31 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6825951566546414		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.6825951566546414 | validation: 0.34721047194482013]
	TIME [epoch: 6.33 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.684014183175913		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.684014183175913 | validation: 0.34385749762739864]
	TIME [epoch: 6.3 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6827987395697772		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.6827987395697772 | validation: 0.3404294976200573]
	TIME [epoch: 6.31 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6819081517860199		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.6819081517860199 | validation: 0.3460180007433431]
	TIME [epoch: 6.29 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6800951693865546		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.6800951693865546 | validation: 0.34025211416613865]
	TIME [epoch: 6.31 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6850143987797407		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.6850143987797407 | validation: 0.3438136592514895]
	TIME [epoch: 6.32 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6837171511750837		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.6837171511750837 | validation: 0.335793960643076]
	TIME [epoch: 6.34 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6805149428885116		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.6805149428885116 | validation: 0.34114546101087057]
	TIME [epoch: 6.3 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6798508245736683		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.6798508245736683 | validation: 0.3503642834853816]
	TIME [epoch: 6.29 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6866052523795417		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.6866052523795417 | validation: 0.3415016534163095]
	TIME [epoch: 6.3 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6809136968522649		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.6809136968522649 | validation: 0.3422145205896888]
	TIME [epoch: 6.31 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6786463492049595		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.6786463492049595 | validation: 0.34278687934429897]
	TIME [epoch: 6.31 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6821073616891815		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.6821073616891815 | validation: 0.3514119764134233]
	TIME [epoch: 6.32 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6865313466300156		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.6865313466300156 | validation: 0.34425832842222776]
	TIME [epoch: 6.3 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.681599863162992		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.681599863162992 | validation: 0.3424787398185081]
	TIME [epoch: 6.29 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6816765055858927		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.6816765055858927 | validation: 0.3460155192590557]
	TIME [epoch: 6.3 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6832063413470039		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.6832063413470039 | validation: 0.34692218319525403]
	TIME [epoch: 6.31 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6818344611109944		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.6818344611109944 | validation: 0.3356033035316174]
	TIME [epoch: 6.32 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6863928672954123		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.6863928672954123 | validation: 0.3398736588067685]
	TIME [epoch: 6.32 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6811272911552161		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.6811272911552161 | validation: 0.35265019523523644]
	TIME [epoch: 6.31 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6835075996064099		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.6835075996064099 | validation: 0.3356630049592191]
	TIME [epoch: 6.29 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.68641686808429		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.68641686808429 | validation: 0.3459238885298951]
	TIME [epoch: 6.31 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6838582892299302		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.6838582892299302 | validation: 0.3389066984072908]
	TIME [epoch: 6.29 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6831529210871652		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.6831529210871652 | validation: 0.3394570093320556]
	TIME [epoch: 6.34 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6846857158617252		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.6846857158617252 | validation: 0.3506930026301448]
	TIME [epoch: 6.32 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6863628593413168		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.6863628593413168 | validation: 0.34098911967292383]
	TIME [epoch: 6.29 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6822944343559237		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.6822944343559237 | validation: 0.33538593698133035]
	TIME [epoch: 6.31 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.680348343264235		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.680348343264235 | validation: 0.3397978331146859]
	TIME [epoch: 6.3 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6836903131800395		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.6836903131800395 | validation: 0.3457447619015578]
	TIME [epoch: 6.3 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6796379911530213		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.6796379911530213 | validation: 0.33530165118344823]
	TIME [epoch: 6.34 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6789340421853052		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.6789340421853052 | validation: 0.3407336335961083]
	TIME [epoch: 6.31 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6831109761980341		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.6831109761980341 | validation: 0.34361258224205105]
	TIME [epoch: 6.31 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6839342963090983		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.6839342963090983 | validation: 0.3325779978870542]
	TIME [epoch: 6.31 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6820444687805635		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.6820444687805635 | validation: 0.34811052234914547]
	TIME [epoch: 6.31 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.683711234099218		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.683711234099218 | validation: 0.342457069731927]
	TIME [epoch: 6.31 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6849700750450529		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.6849700750450529 | validation: 0.349766180034006]
	TIME [epoch: 6.36 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6838458422680674		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.6838458422680674 | validation: 0.33385235402116414]
	TIME [epoch: 6.32 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6802971642717832		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.6802971642717832 | validation: 0.3520574846524616]
	TIME [epoch: 6.31 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.680459064394335		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.680459064394335 | validation: 0.3391948142328941]
	TIME [epoch: 6.31 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6878849445079452		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.6878849445079452 | validation: 0.3370525185733248]
	TIME [epoch: 6.3 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6832743002187134		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.6832743002187134 | validation: 0.3513693933564123]
	TIME [epoch: 6.31 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6840291753991349		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.6840291753991349 | validation: 0.3336965638733759]
	TIME [epoch: 6.35 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6850527016482356		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.6850527016482356 | validation: 0.3471854885278007]
	TIME [epoch: 6.32 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6819641930388327		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.6819641930388327 | validation: 0.34276579348820807]
	TIME [epoch: 6.29 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6831540163215936		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.6831540163215936 | validation: 0.3472327392177843]
	TIME [epoch: 6.3 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6831389762237491		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.6831389762237491 | validation: 0.3345139700646179]
	TIME [epoch: 6.31 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6836264339230816		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.6836264339230816 | validation: 0.33848381382768944]
	TIME [epoch: 6.3 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6804911676321934		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.6804911676321934 | validation: 0.33787235702863316]
	TIME [epoch: 6.37 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6827603571039418		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.6827603571039418 | validation: 0.3359398963641379]
	TIME [epoch: 6.3 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6815157913476806		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.6815157913476806 | validation: 0.34876665246369476]
	TIME [epoch: 6.28 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6809920180608973		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.6809920180608973 | validation: 0.34863940749332334]
	TIME [epoch: 6.3 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6803659158555838		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.6803659158555838 | validation: 0.33653755232119953]
	TIME [epoch: 6.3 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6810366848497059		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.6810366848497059 | validation: 0.3392458791306139]
	TIME [epoch: 6.33 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6820491082545181		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.6820491082545181 | validation: 0.3431833164883993]
	TIME [epoch: 6.33 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6819453208279815		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.6819453208279815 | validation: 0.3415862306799498]
	TIME [epoch: 6.31 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6819517868069482		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.6819517868069482 | validation: 0.3404788553707237]
	TIME [epoch: 6.3 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6871630110009966		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.6871630110009966 | validation: 0.33973381667729374]
	TIME [epoch: 6.3 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6857736963148757		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.6857736963148757 | validation: 0.3438136884413568]
	TIME [epoch: 6.3 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6847977693704914		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.6847977693704914 | validation: 0.3464618396560853]
	TIME [epoch: 6.31 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.688276295594908		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.688276295594908 | validation: 0.3399745881628347]
	TIME [epoch: 6.33 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6829453101581631		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.6829453101581631 | validation: 0.3432596701154671]
	TIME [epoch: 6.31 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6823335428348041		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.6823335428348041 | validation: 0.34032918581655214]
	TIME [epoch: 6.31 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6820419693165221		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.6820419693165221 | validation: 0.33850438413015865]
	TIME [epoch: 6.31 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6847478580611646		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.6847478580611646 | validation: 0.34826029051063956]
	TIME [epoch: 6.3 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6829336572429168		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.6829336572429168 | validation: 0.34255642763062255]
	TIME [epoch: 6.33 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6839439480697083		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.6839439480697083 | validation: 0.33365545565697835]
	TIME [epoch: 6.33 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6839918849590642		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.6839918849590642 | validation: 0.3462419428623461]
	TIME [epoch: 6.3 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.683036122661206		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.683036122661206 | validation: 0.3418182523000169]
	TIME [epoch: 6.29 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6824830003762005		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.6824830003762005 | validation: 0.3493249346493133]
	TIME [epoch: 6.3 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.679533114279215		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.679533114279215 | validation: 0.34302055532472386]
	TIME [epoch: 6.31 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6824212458578782		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.6824212458578782 | validation: 0.34799043435706434]
	TIME [epoch: 6.33 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6860595998124376		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.6860595998124376 | validation: 0.33445393478382834]
	TIME [epoch: 6.33 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6828676854239935		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.6828676854239935 | validation: 0.3388345303789741]
	TIME [epoch: 6.3 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6830839324262273		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.6830839324262273 | validation: 0.3378125442034065]
	TIME [epoch: 6.31 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.67918935684022		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.67918935684022 | validation: 0.3504860148240232]
	TIME [epoch: 6.3 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6833932321756868		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.6833932321756868 | validation: 0.344475795658793]
	TIME [epoch: 6.3 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6859851948044566		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.6859851948044566 | validation: 0.3404189738061268]
	TIME [epoch: 6.34 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6827701491578511		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.6827701491578511 | validation: 0.348094827334541]
	TIME [epoch: 6.31 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6809786836305302		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.6809786836305302 | validation: 0.3444260533798027]
	TIME [epoch: 6.32 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6854115770077142		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.6854115770077142 | validation: 0.34455944720663034]
	TIME [epoch: 6.29 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6806139148492788		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.6806139148492788 | validation: 0.34378095934570446]
	TIME [epoch: 6.3 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6829705685167585		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.6829705685167585 | validation: 0.3359586111237896]
	TIME [epoch: 6.3 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6785569529233992		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.6785569529233992 | validation: 0.3451702365051128]
	TIME [epoch: 6.34 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6860147862966136		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.6860147862966136 | validation: 0.33977842599845665]
	TIME [epoch: 6.3 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6823476668665528		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.6823476668665528 | validation: 0.34766033862387985]
	TIME [epoch: 6.3 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6822912542538949		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.6822912542538949 | validation: 0.3365506514860075]
	TIME [epoch: 6.3 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6855954555033836		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.6855954555033836 | validation: 0.3477063494907154]
	TIME [epoch: 6.29 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6846074600584199		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.6846074600584199 | validation: 0.3397869768714043]
	TIME [epoch: 6.3 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.680974497425367		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.680974497425367 | validation: 0.34874378789846733]
	TIME [epoch: 6.35 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6831035173256927		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.6831035173256927 | validation: 0.34471519189780003]
	TIME [epoch: 6.3 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6831863457759175		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.6831863457759175 | validation: 0.3404678368855523]
	TIME [epoch: 6.29 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6803632388382808		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.6803632388382808 | validation: 0.3499094223451136]
	TIME [epoch: 6.29 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6831742049231148		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.6831742049231148 | validation: 0.3446865828812771]
	TIME [epoch: 6.29 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6846552073754816		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.6846552073754816 | validation: 0.3316660644758889]
	TIME [epoch: 6.3 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.683513000505996		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.683513000505996 | validation: 0.3408650531230659]
	TIME [epoch: 6.34 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.683727480286271		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.683727480286271 | validation: 0.3477754190802462]
	TIME [epoch: 6.29 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6859876449641572		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.6859876449641572 | validation: 0.33238597868575415]
	TIME [epoch: 6.29 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6801413004880317		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.6801413004880317 | validation: 0.3400297062684809]
	TIME [epoch: 6.3 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6843133611012194		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.6843133611012194 | validation: 0.34047315490741303]
	TIME [epoch: 6.28 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6813285961594576		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.6813285961594576 | validation: 0.3435770427655359]
	TIME [epoch: 6.29 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6834825442747816		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.6834825442747816 | validation: 0.34650940670358316]
	TIME [epoch: 6.33 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6855887135772559		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.6855887135772559 | validation: 0.3392788401331945]
	TIME [epoch: 6.3 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6849049650685728		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.6849049650685728 | validation: 0.35285414943931065]
	TIME [epoch: 6.3 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6841782755631342		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.6841782755631342 | validation: 0.3375483848934794]
	TIME [epoch: 6.3 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6833091411639219		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.6833091411639219 | validation: 0.3359793774148671]
	TIME [epoch: 6.29 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6856304940497684		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.6856304940497684 | validation: 0.3401275640189956]
	TIME [epoch: 6.31 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6791093514589914		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.6791093514589914 | validation: 0.34358462837702625]
	TIME [epoch: 6.33 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6809918073669993		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.6809918073669993 | validation: 0.33343090282217014]
	TIME [epoch: 6.31 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6805706952174524		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.6805706952174524 | validation: 0.3351840171455239]
	TIME [epoch: 6.29 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6830261018993846		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.6830261018993846 | validation: 0.3383149942093745]
	TIME [epoch: 6.29 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.682162566574382		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.682162566574382 | validation: 0.34660513949090566]
	TIME [epoch: 6.31 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.685421276671166		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.685421276671166 | validation: 0.3371930915379366]
	TIME [epoch: 6.31 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6834581467316252		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.6834581467316252 | validation: 0.3445525875720827]
	TIME [epoch: 6.33 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6822540897411967		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.6822540897411967 | validation: 0.3298412041190863]
	TIME [epoch: 6.3 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6802239722961309		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.6802239722961309 | validation: 0.33923442997022846]
	TIME [epoch: 6.3 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6816167519076424		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.6816167519076424 | validation: 0.3544757946096101]
	TIME [epoch: 6.29 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6832697613770102		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.6832697613770102 | validation: 0.3432420586195528]
	TIME [epoch: 6.29 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6809774837923412		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.6809774837923412 | validation: 0.34708262896101877]
	TIME [epoch: 6.32 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6839343552570009		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.6839343552570009 | validation: 0.3466135091098906]
	TIME [epoch: 6.31 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6856536726039739		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.6856536726039739 | validation: 0.35024355932014656]
	TIME [epoch: 6.3 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6821501253781376		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.6821501253781376 | validation: 0.34451576288806807]
	TIME [epoch: 6.3 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6845884614950135		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.6845884614950135 | validation: 0.34279487522926544]
	TIME [epoch: 6.29 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6884330188035479		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.6884330188035479 | validation: 0.3405622907874131]
	TIME [epoch: 6.28 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6810271876118815		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.6810271876118815 | validation: 0.34222741008217167]
	TIME [epoch: 6.31 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6826995466981289		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.6826995466981289 | validation: 0.33067659225138746]
	TIME [epoch: 6.32 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6844273221547161		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.6844273221547161 | validation: 0.34203557068287205]
	TIME [epoch: 6.29 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6840824929955549		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.6840824929955549 | validation: 0.3459220753771474]
	TIME [epoch: 6.28 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6886161393596266		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.6886161393596266 | validation: 0.33894116418375425]
	TIME [epoch: 6.28 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6807018784221507		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.6807018784221507 | validation: 0.34447200518447063]
	TIME [epoch: 6.29 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6865996402224986		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.6865996402224986 | validation: 0.3360182534489932]
	TIME [epoch: 6.34 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6837297068512501		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.6837297068512501 | validation: 0.3386174723391325]
	TIME [epoch: 6.31 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6853723122474636		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.6853723122474636 | validation: 0.34178019334514037]
	TIME [epoch: 6.29 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6815152990256234		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.6815152990256234 | validation: 0.34313275668936394]
	TIME [epoch: 6.3 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6881166322222272		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.6881166322222272 | validation: 0.34783652201174303]
	TIME [epoch: 6.29 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6807018960775618		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.6807018960775618 | validation: 0.33710841637533867]
	TIME [epoch: 6.28 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6840958357010215		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.6840958357010215 | validation: 0.3252371238542081]
	TIME [epoch: 6.34 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6798761405290545		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.6798761405290545 | validation: 0.34868543414976877]
	TIME [epoch: 6.31 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6793004278739552		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.6793004278739552 | validation: 0.3365594585615913]
	TIME [epoch: 6.29 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6844169266892753		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.6844169266892753 | validation: 0.3411245393694859]
	TIME [epoch: 6.3 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.680119499971768		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.680119499971768 | validation: 0.3456519543899882]
	TIME [epoch: 6.29 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6844272637005056		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.6844272637005056 | validation: 0.34252783022818906]
	TIME [epoch: 6.29 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6831844620228809		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.6831844620228809 | validation: 0.33801340589274875]
	TIME [epoch: 6.34 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6793964534525074		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.6793964534525074 | validation: 0.33927966786101493]
	TIME [epoch: 6.3 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6889957368482672		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.6889957368482672 | validation: 0.34209516890260216]
	TIME [epoch: 6.3 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.681512878633058		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.681512878633058 | validation: 0.3353121035074447]
	TIME [epoch: 6.3 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6837478095156939		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.6837478095156939 | validation: 0.3491966402921787]
	TIME [epoch: 6.29 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6828962367401814		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.6828962367401814 | validation: 0.34481554527342106]
	TIME [epoch: 6.31 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6841445079587067		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.6841445079587067 | validation: 0.34156597072475503]
	TIME [epoch: 6.34 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6861684289621253		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.6861684289621253 | validation: 0.3381180013776155]
	TIME [epoch: 6.31 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6858877979298088		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.6858877979298088 | validation: 0.3507264814602149]
	TIME [epoch: 6.3 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6790089949598151		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.6790089949598151 | validation: 0.34649671342725896]
	TIME [epoch: 6.29 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6858619274246698		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.6858619274246698 | validation: 0.3373753997651908]
	TIME [epoch: 6.3 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6837463988925786		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.6837463988925786 | validation: 0.3273301605165486]
	TIME [epoch: 6.3 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6844282956451344		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.6844282956451344 | validation: 0.34720974128358617]
	TIME [epoch: 6.35 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6859455179562806		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.6859455179562806 | validation: 0.3489116948063551]
	TIME [epoch: 6.29 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6858612281901891		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.6858612281901891 | validation: 0.34205192956295827]
	TIME [epoch: 6.28 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6842195718647368		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.6842195718647368 | validation: 0.341291995873129]
	TIME [epoch: 6.3 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6818806487912387		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.6818806487912387 | validation: 0.3365909451570418]
	TIME [epoch: 6.31 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6831211258344636		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.6831211258344636 | validation: 0.33841159114563973]
	TIME [epoch: 6.28 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6878561069777306		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.6878561069777306 | validation: 0.3357415287089596]
	TIME [epoch: 6.32 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6806715527670114		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.6806715527670114 | validation: 0.33760834222924635]
	TIME [epoch: 6.3 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6854826845272546		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.6854826845272546 | validation: 0.3317367083688486]
	TIME [epoch: 6.29 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6842098171411793		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.6842098171411793 | validation: 0.339860075277134]
	TIME [epoch: 6.29 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.68478233134779		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.68478233134779 | validation: 0.3494546860795365]
	TIME [epoch: 6.29 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6822335028696096		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.6822335028696096 | validation: 0.34042878222768197]
	TIME [epoch: 6.32 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6793914214272938		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.6793914214272938 | validation: 0.34108948873505585]
	TIME [epoch: 6.34 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6862323475135332		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.6862323475135332 | validation: 0.33832804918958426]
	TIME [epoch: 6.3 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6870918359211083		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.6870918359211083 | validation: 0.3329204071166818]
	TIME [epoch: 6.29 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6822182720586838		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.6822182720586838 | validation: 0.33921232684014224]
	TIME [epoch: 6.3 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6830430905080619		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.6830430905080619 | validation: 0.34313144527370426]
	TIME [epoch: 6.29 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6870592539909893		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.6870592539909893 | validation: 0.3340035265922635]
	TIME [epoch: 6.32 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6838458602203699		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.6838458602203699 | validation: 0.34216790380235845]
	TIME [epoch: 6.32 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6840202726204144		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.6840202726204144 | validation: 0.34415653980636274]
	TIME [epoch: 6.29 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6822862737003961		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.6822862737003961 | validation: 0.3487016393263202]
	TIME [epoch: 6.31 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6860160798804974		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.6860160798804974 | validation: 0.3399918030432509]
	TIME [epoch: 6.29 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6881661072969816		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.6881661072969816 | validation: 0.3528900253020131]
	TIME [epoch: 6.3 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6828048575453107		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.6828048575453107 | validation: 0.33745640803771554]
	TIME [epoch: 6.32 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6782544358063879		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.6782544358063879 | validation: 0.3340783475050657]
	TIME [epoch: 6.33 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6871252529941166		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.6871252529941166 | validation: 0.34111575180557163]
	TIME [epoch: 6.3 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6826825629704816		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.6826825629704816 | validation: 0.3309203751212262]
	TIME [epoch: 6.29 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6837200885703708		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.6837200885703708 | validation: 0.34562625297521715]
	TIME [epoch: 6.29 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6832837980689964		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.6832837980689964 | validation: 0.3438249473268926]
	TIME [epoch: 6.29 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6818592937029772		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.6818592937029772 | validation: 0.33754303438178435]
	TIME [epoch: 6.35 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6836351267508918		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.6836351267508918 | validation: 0.33888108256508254]
	TIME [epoch: 6.31 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6846576474440382		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.6846576474440382 | validation: 0.3464369989195704]
	TIME [epoch: 6.29 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6817498076403329		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.6817498076403329 | validation: 0.3374250197253428]
	TIME [epoch: 6.3 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6825110064344952		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.6825110064344952 | validation: 0.3529051252196662]
	TIME [epoch: 6.32 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6812822864623003		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.6812822864623003 | validation: 0.3434896163164022]
	TIME [epoch: 6.3 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6841351343092965		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.6841351343092965 | validation: 0.33848885263297906]
	TIME [epoch: 6.33 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6853679217161917		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.6853679217161917 | validation: 0.3497865251393021]
	TIME [epoch: 6.33 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6850293263177916		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.6850293263177916 | validation: 0.3381241843515698]
	TIME [epoch: 6.29 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.683691498486225		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.683691498486225 | validation: 0.3453796858917434]
	TIME [epoch: 6.3 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6825158205961361		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.6825158205961361 | validation: 0.33605813075896396]
	TIME [epoch: 6.29 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.683964664947329		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.683964664947329 | validation: 0.3391093425659115]
	TIME [epoch: 6.3 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6826168074048835		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.6826168074048835 | validation: 0.34385835505808593]
	TIME [epoch: 6.35 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6796465523747963		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.6796465523747963 | validation: 0.34467974721542527]
	TIME [epoch: 6.32 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.685651190850268		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.685651190850268 | validation: 0.3418678115045477]
	TIME [epoch: 6.31 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.681420074931224		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.681420074931224 | validation: 0.33915700917196573]
	TIME [epoch: 6.31 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6826293330499692		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.6826293330499692 | validation: 0.3472024704124684]
	TIME [epoch: 6.29 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6832313797165308		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.6832313797165308 | validation: 0.3409922511540797]
	TIME [epoch: 6.29 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6819922699250003		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.6819922699250003 | validation: 0.3368864269001927]
	TIME [epoch: 6.34 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6865151265056689		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.6865151265056689 | validation: 0.33625026545531445]
	TIME [epoch: 6.29 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.684244050461327		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.684244050461327 | validation: 0.3433928279818261]
	TIME [epoch: 6.28 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6832443646745101		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.6832443646745101 | validation: 0.3407830206109515]
	TIME [epoch: 6.28 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6859738220513152		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.6859738220513152 | validation: 0.3399312793361982]
	TIME [epoch: 6.29 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.681425796646197		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.681425796646197 | validation: 0.3360884015277364]
	TIME [epoch: 6.3 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6836726278123082		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.6836726278123082 | validation: 0.34569893840192073]
	TIME [epoch: 6.34 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6862421933305074		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.6862421933305074 | validation: 0.3484438934679818]
	TIME [epoch: 6.29 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6815891213042002		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.6815891213042002 | validation: 0.3355581766512094]
	TIME [epoch: 6.29 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6813236739766285		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.6813236739766285 | validation: 0.34045854456454244]
	TIME [epoch: 6.28 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6800820294011809		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.6800820294011809 | validation: 0.34198585443616764]
	TIME [epoch: 6.28 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6805301971522009		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.6805301971522009 | validation: 0.33879228608774364]
	TIME [epoch: 6.31 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.683731728280752		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.683731728280752 | validation: 0.34377592788352956]
	TIME [epoch: 6.34 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6856325171361849		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.6856325171361849 | validation: 0.3434690311484125]
	TIME [epoch: 6.29 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6824323751031619		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.6824323751031619 | validation: 0.3416341820802812]
	TIME [epoch: 6.29 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6861336292236422		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.6861336292236422 | validation: 0.33547063267307564]
	TIME [epoch: 6.31 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6800420122038165		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.6800420122038165 | validation: 0.34382187245988866]
	TIME [epoch: 6.28 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6830671949868776		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.6830671949868776 | validation: 0.33717941047680944]
	TIME [epoch: 6.3 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6880100037859358		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.6880100037859358 | validation: 0.34007580510367585]
	TIME [epoch: 6.33 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6812549395704894		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.6812549395704894 | validation: 0.3424250947403779]
	TIME [epoch: 6.3 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6863628667051241		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.6863628667051241 | validation: 0.344888119534149]
	TIME [epoch: 6.31 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6837473129971573		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.6837473129971573 | validation: 0.3367632701960725]
	TIME [epoch: 6.31 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6837354947582847		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.6837354947582847 | validation: 0.3449485955227116]
	TIME [epoch: 6.3 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6843915055205988		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.6843915055205988 | validation: 0.3394574627771564]
	TIME [epoch: 6.34 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6835169118561126		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.6835169118561126 | validation: 0.3371891324129192]
	TIME [epoch: 6.32 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6802939299537842		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.6802939299537842 | validation: 0.3452515827024397]
	TIME [epoch: 6.29 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6821769206548618		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.6821769206548618 | validation: 0.342157496840875]
	TIME [epoch: 6.3 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.680422672902135		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.680422672902135 | validation: 0.3418410688684531]
	TIME [epoch: 6.3 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6820523879557174		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.6820523879557174 | validation: 0.3465790192037003]
	TIME [epoch: 6.29 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6812373725456338		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.6812373725456338 | validation: 0.3376230974808036]
	TIME [epoch: 6.32 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6835670174631165		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.6835670174631165 | validation: 0.33587585327107133]
	TIME [epoch: 6.32 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6805974497167031		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.6805974497167031 | validation: 0.3424628878102428]
	TIME [epoch: 6.27 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.68114980447415		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.68114980447415 | validation: 0.3350780651338018]
	TIME [epoch: 6.3 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6888807251356239		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.6888807251356239 | validation: 0.34379713604077305]
	TIME [epoch: 6.28 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6868989927426541		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.6868989927426541 | validation: 0.3408923201837168]
	TIME [epoch: 6.29 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6848227087211447		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.6848227087211447 | validation: 0.3380288700555317]
	TIME [epoch: 6.34 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6807727829497192		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.6807727829497192 | validation: 0.34575156569327714]
	TIME [epoch: 6.3 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6808843140207717		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.6808843140207717 | validation: 0.34623264779617424]
	TIME [epoch: 6.29 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6848630558258724		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.6848630558258724 | validation: 0.33883023055861183]
	TIME [epoch: 6.3 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6860134487223766		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.6860134487223766 | validation: 0.3402311902758107]
	TIME [epoch: 6.28 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6825661660666843		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.6825661660666843 | validation: 0.3451101768543629]
	TIME [epoch: 6.3 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6881075341257847		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.6881075341257847 | validation: 0.3378054341539319]
	TIME [epoch: 6.34 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6801694726118331		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.6801694726118331 | validation: 0.3448708070840337]
	TIME [epoch: 6.31 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6849673222373635		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.6849673222373635 | validation: 0.34967278547863906]
	TIME [epoch: 6.31 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.682653015301425		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.682653015301425 | validation: 0.33585396505402415]
	TIME [epoch: 6.29 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6789974311275658		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.6789974311275658 | validation: 0.3448547045336051]
	TIME [epoch: 6.28 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6827808031054793		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.6827808031054793 | validation: 0.34823279081922165]
	TIME [epoch: 6.29 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6820081721568703		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.6820081721568703 | validation: 0.33730281508184023]
	TIME [epoch: 6.36 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.684763393843246		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.684763393843246 | validation: 0.3358242654636543]
	TIME [epoch: 6.32 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6848113263835789		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.6848113263835789 | validation: 0.3371641242541923]
	TIME [epoch: 6.29 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6801417321549645		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.6801417321549645 | validation: 0.3368094006852683]
	TIME [epoch: 6.3 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6856421407480346		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.6856421407480346 | validation: 0.34484614257973595]
	TIME [epoch: 6.3 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6839531713248397		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.6839531713248397 | validation: 0.33806528487617216]
	TIME [epoch: 6.31 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6823164918649338		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.6823164918649338 | validation: 0.3402486641222097]
	TIME [epoch: 6.35 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6850887119923612		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.6850887119923612 | validation: 0.3436249170046284]
	TIME [epoch: 6.31 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6806124791629021		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.6806124791629021 | validation: 0.33736492935614715]
	TIME [epoch: 6.29 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6841729890027674		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.6841729890027674 | validation: 0.3455995631224838]
	TIME [epoch: 6.32 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6844069505403534		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.6844069505403534 | validation: 0.3374606336650805]
	TIME [epoch: 6.3 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6843340378406514		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.6843340378406514 | validation: 0.33870030310401583]
	TIME [epoch: 6.3 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6810186117816133		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.6810186117816133 | validation: 0.34484763653499073]
	TIME [epoch: 6.35 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6840806945258885		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.6840806945258885 | validation: 0.33851878401075913]
	TIME [epoch: 6.32 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6816570213599673		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.6816570213599673 | validation: 0.3433715514329815]
	TIME [epoch: 6.3 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6790267601906435		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.6790267601906435 | validation: 0.3316229245620378]
	TIME [epoch: 6.3 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6861487590823148		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.6861487590823148 | validation: 0.34067212455363094]
	TIME [epoch: 6.31 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6818777467340587		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.6818777467340587 | validation: 0.3440812714147317]
	TIME [epoch: 6.32 sec]
Finished training in 12808.437 seconds.
