Args:
Namespace(name='model_algphiq_1a_v_mmd4', outdir='out/model_training/model_algphiq_1a_v_mmd4', training_data='data/training_data/data_phiq_1a/training', validation_data='data/training_data/data_phiq_1a/validation', model_type='quadratic', nsims_training=None, nsims_validation=None, num_epochs=500, passes_per_epoch=1, batch_size=250, patience=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=False, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 250], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=False, confinement_factor=1.0, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], phi_final_act='softplus', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=0.0, init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.1], optimizer='rms', momentum=0.0, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1671603906

Training model...

Saving initial model state to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 4/4] avg loss: 0.8373437590601038		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8373437590601038 | validation: 0.8180577221677272]
	TIME [epoch: 110 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 4/4] avg loss: 0.8043882182855777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8043882182855777 | validation: 0.7866436050726542]
	TIME [epoch: 4.33 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 4/4] avg loss: 0.7752686047548124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7752686047548124 | validation: 0.7587281202342118]
	TIME [epoch: 4.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_3.pth
	Model improved!!!
EPOCH 4/500:
	Training over batches...
		[batch 4/4] avg loss: 0.7473001768811283		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7473001768811283 | validation: 0.7310973421303921]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 4/4] avg loss: 0.7179080962415985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7179080962415985 | validation: 0.701550598588232]
	TIME [epoch: 4.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_5.pth
	Model improved!!!
EPOCH 6/500:
	Training over batches...
		[batch 4/4] avg loss: 0.6881555336426459		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6881555336426459 | validation: 0.668538821855839]
	TIME [epoch: 4.08 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_6.pth
	Model improved!!!
EPOCH 7/500:
	Training over batches...
		[batch 4/4] avg loss: 0.657864117592449		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.657864117592449 | validation: 0.6387853770974188]
	TIME [epoch: 4.11 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_7.pth
	Model improved!!!
EPOCH 8/500:
	Training over batches...
		[batch 4/4] avg loss: 0.6242643644931496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6242643644931496 | validation: 0.6052459712641293]
	TIME [epoch: 4.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_8.pth
	Model improved!!!
EPOCH 9/500:
	Training over batches...
		[batch 4/4] avg loss: 0.5908341275225202		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5908341275225202 | validation: 0.5690794135364154]
	TIME [epoch: 4.11 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_9.pth
	Model improved!!!
EPOCH 10/500:
	Training over batches...
		[batch 4/4] avg loss: 0.5544595582020071		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5544595582020071 | validation: 0.5327842094604903]
	TIME [epoch: 4.12 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_10.pth
	Model improved!!!
EPOCH 11/500:
	Training over batches...
		[batch 4/4] avg loss: 0.5167735653390184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5167735653390184 | validation: 0.4951457877458143]
	TIME [epoch: 4.12 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_11.pth
	Model improved!!!
EPOCH 12/500:
	Training over batches...
		[batch 4/4] avg loss: 0.4772238103839691		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4772238103839691 | validation: 0.4530993239352097]
	TIME [epoch: 4.16 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_12.pth
	Model improved!!!
EPOCH 13/500:
	Training over batches...
		[batch 4/4] avg loss: 0.43503005576670023		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43503005576670023 | validation: 0.41168527956903633]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_13.pth
	Model improved!!!
EPOCH 14/500:
	Training over batches...
		[batch 4/4] avg loss: 0.39068238611394657		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39068238611394657 | validation: 0.3634840934947959]
	TIME [epoch: 4.09 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_14.pth
	Model improved!!!
EPOCH 15/500:
	Training over batches...
		[batch 4/4] avg loss: 0.33721160385843385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33721160385843385 | validation: 0.3004524381823499]
	TIME [epoch: 4.11 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_15.pth
	Model improved!!!
EPOCH 16/500:
	Training over batches...
		[batch 4/4] avg loss: 0.28061436689048547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28061436689048547 | validation: 0.2531397894872356]
	TIME [epoch: 4.11 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_16.pth
	Model improved!!!
EPOCH 17/500:
	Training over batches...
		[batch 4/4] avg loss: 0.22550537421100383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22550537421100383 | validation: 0.17942708790859138]
	TIME [epoch: 4.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_17.pth
	Model improved!!!
EPOCH 18/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13650828396807205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13650828396807205 | validation: 0.0892609302876591]
	TIME [epoch: 4.11 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_18.pth
	Model improved!!!
EPOCH 19/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07175808663846112		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07175808663846112 | validation: 0.054916277476248734]
	TIME [epoch: 4.19 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_19.pth
	Model improved!!!
EPOCH 20/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04883638265945766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04883638265945766 | validation: 0.043098233588000454]
	TIME [epoch: 4.16 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_20.pth
	Model improved!!!
EPOCH 21/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04042107204552585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04042107204552585 | validation: 0.037892299151394485]
	TIME [epoch: 4.11 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_21.pth
	Model improved!!!
EPOCH 22/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03648944230345243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03648944230345243 | validation: 0.035167916550714676]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_22.pth
	Model improved!!!
EPOCH 23/500:
	Training over batches...
		[batch 4/4] avg loss: 0.034269058675707995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.034269058675707995 | validation: 0.03352958502731104]
	TIME [epoch: 4.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_23.pth
	Model improved!!!
EPOCH 24/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03294384254413886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03294384254413886 | validation: 0.032432709570908796]
	TIME [epoch: 4.09 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_24.pth
	Model improved!!!
EPOCH 25/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03205500157270652		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03205500157270652 | validation: 0.031730838253739096]
	TIME [epoch: 4.12 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_25.pth
	Model improved!!!
EPOCH 26/500:
	Training over batches...
		[batch 4/4] avg loss: 0.031422652150897123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.031422652150897123 | validation: 0.031199726641052698]
	TIME [epoch: 4.17 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_26.pth
	Model improved!!!
EPOCH 27/500:
	Training over batches...
		[batch 4/4] avg loss: 0.030995680148898974		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.030995680148898974 | validation: 0.03080219873300901]
	TIME [epoch: 4.15 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_27.pth
	Model improved!!!
EPOCH 28/500:
	Training over batches...
		[batch 4/4] avg loss: 0.030649611743049476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.030649611743049476 | validation: 0.03054043940614412]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_28.pth
	Model improved!!!
EPOCH 29/500:
	Training over batches...
		[batch 4/4] avg loss: 0.030420825010424785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.030420825010424785 | validation: 0.030323791255348034]
	TIME [epoch: 4.11 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_29.pth
	Model improved!!!
EPOCH 30/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03023020455505877		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03023020455505877 | validation: 0.030161581706267017]
	TIME [epoch: 4.11 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_30.pth
	Model improved!!!
EPOCH 31/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03008431661426684		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03008431661426684 | validation: 0.030040928368654136]
	TIME [epoch: 4.11 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_31.pth
	Model improved!!!
EPOCH 32/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0299750451816919		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0299750451816919 | validation: 0.029937862945752763]
	TIME [epoch: 4.12 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_32.pth
	Model improved!!!
EPOCH 33/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029885778010215996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.029885778010215996 | validation: 0.029868981437765105]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_33.pth
	Model improved!!!
EPOCH 34/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029821852259161074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.029821852259161074 | validation: 0.02981507937227448]
	TIME [epoch: 4.17 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_34.pth
	Model improved!!!
EPOCH 35/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029767767103377876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.029767767103377876 | validation: 0.02975997401358952]
	TIME [epoch: 4.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_35.pth
	Model improved!!!
EPOCH 36/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02972247450992702		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02972247450992702 | validation: 0.029719703839491532]
	TIME [epoch: 4.09 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_36.pth
	Model improved!!!
EPOCH 37/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0296903510089028		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0296903510089028 | validation: 0.029694479127855937]
	TIME [epoch: 4.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_37.pth
	Model improved!!!
EPOCH 38/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029662764900892025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.029662764900892025 | validation: 0.029665182791040332]
	TIME [epoch: 4.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_38.pth
	Model improved!!!
EPOCH 39/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02963951741997619		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02963951741997619 | validation: 0.0296483201139342]
	TIME [epoch: 4.11 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_39.pth
	Model improved!!!
EPOCH 40/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029623488654851447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.029623488654851447 | validation: 0.029633005621966708]
	TIME [epoch: 4.12 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_40.pth
	Model improved!!!
EPOCH 41/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029608871337992608		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.029608871337992608 | validation: 0.029618595580173934]
	TIME [epoch: 4.16 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_41.pth
	Model improved!!!
EPOCH 42/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02959758375632776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02959758375632776 | validation: 0.029609350805501783]
	TIME [epoch: 4.12 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_42.pth
	Model improved!!!
EPOCH 43/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02958919177512615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02958919177512615 | validation: 0.029601049284924547]
	TIME [epoch: 4.12 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_43.pth
	Model improved!!!
EPOCH 44/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029581308064294508		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.029581308064294508 | validation: 0.029593577323885033]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_44.pth
	Model improved!!!
EPOCH 45/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029575347726126747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.029575347726126747 | validation: 0.029588701084183593]
	TIME [epoch: 4.12 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_45.pth
	Model improved!!!
EPOCH 46/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029570865811523423		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.029570865811523423 | validation: 0.029582808690823772]
	TIME [epoch: 4.11 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_46.pth
	Model improved!!!
EPOCH 47/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02956587948491381		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02956587948491381 | validation: 0.0295798533523522]
	TIME [epoch: 4.11 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_47.pth
	Model improved!!!
EPOCH 48/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02956221240651468		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02956221240651468 | validation: 0.02957783181393703]
	TIME [epoch: 4.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_48.pth
	Model improved!!!
EPOCH 49/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029560784928119428		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.029560784928119428 | validation: 0.029574379988887498]
	TIME [epoch: 4.11 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_49.pth
	Model improved!!!
EPOCH 50/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02955848956791452		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02955848956791452 | validation: 0.02957235007810173]
	TIME [epoch: 4.07 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_50.pth
	Model improved!!!
EPOCH 51/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029556930236711524		[learning rate: 0.0098855]
	Learning Rate: 0.00988553
	LOSS [training: 0.029556930236711524 | validation: 0.029571758573027657]
	TIME [epoch: 112 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_51.pth
	Model improved!!!
EPOCH 52/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029555475286185656		[learning rate: 0.0097349]
	Learning Rate: 0.00973494
	LOSS [training: 0.029555475286185656 | validation: 0.029570063689489518]
	TIME [epoch: 8.08 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_52.pth
	Model improved!!!
EPOCH 53/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02955395238220449		[learning rate: 0.0095866]
	Learning Rate: 0.00958665
	LOSS [training: 0.02955395238220449 | validation: 0.029569425546039054]
	TIME [epoch: 8.04 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_53.pth
	Model improved!!!
EPOCH 54/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029553496293106947		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.029553496293106947 | validation: 0.02956881236003099]
	TIME [epoch: 8.11 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_54.pth
	Model improved!!!
EPOCH 55/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029552859164085253		[learning rate: 0.0092968]
	Learning Rate: 0.0092968
	LOSS [training: 0.029552859164085253 | validation: 0.029567938904539688]
	TIME [epoch: 8.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_55.pth
	Model improved!!!
EPOCH 56/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02955196188429938		[learning rate: 0.0091552]
	Learning Rate: 0.00915517
	LOSS [training: 0.02955196188429938 | validation: 0.029567159942986816]
	TIME [epoch: 8.05 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_56.pth
	Model improved!!!
EPOCH 57/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029551545538506658		[learning rate: 0.0090157]
	Learning Rate: 0.00901571
	LOSS [training: 0.029551545538506658 | validation: 0.02956662873015003]
	TIME [epoch: 8.07 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_57.pth
	Model improved!!!
EPOCH 58/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02955093802993241		[learning rate: 0.0088784]
	Learning Rate: 0.00887837
	LOSS [training: 0.02955093802993241 | validation: 0.029566389352707615]
	TIME [epoch: 8.08 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_58.pth
	Model improved!!!
EPOCH 59/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02955103171147445		[learning rate: 0.0087431]
	Learning Rate: 0.00874312
	LOSS [training: 0.02955103171147445 | validation: 0.029566245632354722]
	TIME [epoch: 8.12 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_59.pth
	Model improved!!!
EPOCH 60/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029551006322656073		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 0.029551006322656073 | validation: 0.029566275356372747]
	TIME [epoch: 8.06 sec]
EPOCH 61/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029550688329536473		[learning rate: 0.0084788]
	Learning Rate: 0.00847878
	LOSS [training: 0.029550688329536473 | validation: 0.02956589311219429]
	TIME [epoch: 8.08 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_61.pth
	Model improved!!!
EPOCH 62/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02955044928840738		[learning rate: 0.0083496]
	Learning Rate: 0.00834962
	LOSS [training: 0.02955044928840738 | validation: 0.029565622915697358]
	TIME [epoch: 8.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_62.pth
	Model improved!!!
EPOCH 63/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0295502046388388		[learning rate: 0.0082224]
	Learning Rate: 0.00822243
	LOSS [training: 0.0295502046388388 | validation: 0.029565585117072905]
	TIME [epoch: 8.14 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_63.pth
	Model improved!!!
EPOCH 64/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02955017769485269		[learning rate: 0.0080972]
	Learning Rate: 0.00809717
	LOSS [training: 0.02955017769485269 | validation: 0.029565548186741973]
	TIME [epoch: 8.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_64.pth
	Model improved!!!
EPOCH 65/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02955015917513988		[learning rate: 0.0079738]
	Learning Rate: 0.00797382
	LOSS [training: 0.02955015917513988 | validation: 0.029565387845050965]
	TIME [epoch: 8.12 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_65.pth
	Model improved!!!
EPOCH 66/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029550012053159023		[learning rate: 0.0078524]
	Learning Rate: 0.00785236
	LOSS [training: 0.029550012053159023 | validation: 0.02956534672609116]
	TIME [epoch: 8.13 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_66.pth
	Model improved!!!
EPOCH 67/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549968269629245		[learning rate: 0.0077327]
	Learning Rate: 0.00773274
	LOSS [training: 0.029549968269629245 | validation: 0.02956535072123334]
	TIME [epoch: 8.16 sec]
EPOCH 68/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549939500482916		[learning rate: 0.0076149]
	Learning Rate: 0.00761494
	LOSS [training: 0.029549939500482916 | validation: 0.029565429850195127]
	TIME [epoch: 8.14 sec]
EPOCH 69/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549798522410752		[learning rate: 0.0074989]
	Learning Rate: 0.00749894
	LOSS [training: 0.029549798522410752 | validation: 0.029565528430509663]
	TIME [epoch: 8.12 sec]
EPOCH 70/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029550247511343587		[learning rate: 0.0073847]
	Learning Rate: 0.00738471
	LOSS [training: 0.029550247511343587 | validation: 0.029565698774119124]
	TIME [epoch: 8.13 sec]
EPOCH 71/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029550157312963957		[learning rate: 0.0072722]
	Learning Rate: 0.00727221
	LOSS [training: 0.029550157312963957 | validation: 0.02956546948456666]
	TIME [epoch: 8.1 sec]
EPOCH 72/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02955024578113715		[learning rate: 0.0071614]
	Learning Rate: 0.00716143
	LOSS [training: 0.02955024578113715 | validation: 0.029565531699003087]
	TIME [epoch: 8.16 sec]
EPOCH 73/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02955011539828908		[learning rate: 0.0070523]
	Learning Rate: 0.00705234
	LOSS [training: 0.02955011539828908 | validation: 0.02956536679773898]
	TIME [epoch: 8.1 sec]
EPOCH 74/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029550002045239172		[learning rate: 0.0069449]
	Learning Rate: 0.00694491
	LOSS [training: 0.029550002045239172 | validation: 0.029565456440865973]
	TIME [epoch: 8.09 sec]
EPOCH 75/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02955000346911944		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.02955000346911944 | validation: 0.029565355055663295]
	TIME [epoch: 8.09 sec]
EPOCH 76/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954997553270359		[learning rate: 0.0067349]
	Learning Rate: 0.00673493
	LOSS [training: 0.02954997553270359 | validation: 0.029565319871936255]
	TIME [epoch: 8.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_76.pth
	Model improved!!!
EPOCH 77/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954995885742971		[learning rate: 0.0066323]
	Learning Rate: 0.00663234
	LOSS [training: 0.02954995885742971 | validation: 0.029565357057792847]
	TIME [epoch: 8.11 sec]
EPOCH 78/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549945052770206		[learning rate: 0.0065313]
	Learning Rate: 0.00653131
	LOSS [training: 0.029549945052770206 | validation: 0.0295653748926216]
	TIME [epoch: 8.07 sec]
EPOCH 79/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549964687166533		[learning rate: 0.0064318]
	Learning Rate: 0.00643181
	LOSS [training: 0.029549964687166533 | validation: 0.029565405613084017]
	TIME [epoch: 8.07 sec]
EPOCH 80/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954997660429962		[learning rate: 0.0063338]
	Learning Rate: 0.00633383
	LOSS [training: 0.02954997660429962 | validation: 0.029565315741941794]
	TIME [epoch: 8.06 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_80.pth
	Model improved!!!
EPOCH 81/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02955003821227569		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.02955003821227569 | validation: 0.029565398050629896]
	TIME [epoch: 8.09 sec]
EPOCH 82/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954999606480458		[learning rate: 0.0061423]
	Learning Rate: 0.00614233
	LOSS [training: 0.02954999606480458 | validation: 0.029565356415895708]
	TIME [epoch: 8.11 sec]
EPOCH 83/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549996477201333		[learning rate: 0.0060488]
	Learning Rate: 0.00604876
	LOSS [training: 0.029549996477201333 | validation: 0.02956541248115305]
	TIME [epoch: 8.09 sec]
EPOCH 84/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549965445366998		[learning rate: 0.0059566]
	Learning Rate: 0.00595662
	LOSS [training: 0.029549965445366998 | validation: 0.029565310126617554]
	TIME [epoch: 8.08 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_84.pth
	Model improved!!!
EPOCH 85/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549921173001717		[learning rate: 0.0058659]
	Learning Rate: 0.00586588
	LOSS [training: 0.029549921173001717 | validation: 0.029565291349036835]
	TIME [epoch: 8.08 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_85.pth
	Model improved!!!
EPOCH 86/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549920320703957		[learning rate: 0.0057765]
	Learning Rate: 0.00577653
	LOSS [training: 0.029549920320703957 | validation: 0.029565268052207418]
	TIME [epoch: 8.13 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_86.pth
	Model improved!!!
EPOCH 87/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549978899426163		[learning rate: 0.0056885]
	Learning Rate: 0.00568853
	LOSS [training: 0.029549978899426163 | validation: 0.02956535656530976]
	TIME [epoch: 8.12 sec]
EPOCH 88/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954994368231896		[learning rate: 0.0056019]
	Learning Rate: 0.00560187
	LOSS [training: 0.02954994368231896 | validation: 0.029565305453007458]
	TIME [epoch: 8.13 sec]
EPOCH 89/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549967044287185		[learning rate: 0.0055165]
	Learning Rate: 0.00551654
	LOSS [training: 0.029549967044287185 | validation: 0.02956532809897218]
	TIME [epoch: 8.11 sec]
EPOCH 90/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0295500222596771		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.0295500222596771 | validation: 0.029565365954681726]
	TIME [epoch: 8.12 sec]
EPOCH 91/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549955691362657		[learning rate: 0.0053497]
	Learning Rate: 0.00534975
	LOSS [training: 0.029549955691362657 | validation: 0.029565295721091667]
	TIME [epoch: 8.16 sec]
EPOCH 92/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549944335925143		[learning rate: 0.0052683]
	Learning Rate: 0.00526825
	LOSS [training: 0.029549944335925143 | validation: 0.029565318036112793]
	TIME [epoch: 8.12 sec]
EPOCH 93/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549935807167305		[learning rate: 0.005188]
	Learning Rate: 0.005188
	LOSS [training: 0.029549935807167305 | validation: 0.029565311777232428]
	TIME [epoch: 8.13 sec]
EPOCH 94/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549959061885653		[learning rate: 0.005109]
	Learning Rate: 0.00510897
	LOSS [training: 0.029549959061885653 | validation: 0.029565312207513482]
	TIME [epoch: 8.13 sec]
EPOCH 95/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029550026835466623		[learning rate: 0.0050311]
	Learning Rate: 0.00503114
	LOSS [training: 0.029550026835466623 | validation: 0.02956527283489562]
	TIME [epoch: 8.14 sec]
EPOCH 96/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549928819332646		[learning rate: 0.0049545]
	Learning Rate: 0.0049545
	LOSS [training: 0.029549928819332646 | validation: 0.02956523860117703]
	TIME [epoch: 8.16 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_96.pth
	Model improved!!!
EPOCH 97/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549883325982358		[learning rate: 0.004879]
	Learning Rate: 0.00487903
	LOSS [training: 0.029549883325982358 | validation: 0.029565277888962]
	TIME [epoch: 8.05 sec]
EPOCH 98/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549788928758952		[learning rate: 0.0048047]
	Learning Rate: 0.0048047
	LOSS [training: 0.029549788928758952 | validation: 0.029565240231800065]
	TIME [epoch: 8.02 sec]
EPOCH 99/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954988939404782		[learning rate: 0.0047315]
	Learning Rate: 0.00473151
	LOSS [training: 0.02954988939404782 | validation: 0.029565238074605607]
	TIME [epoch: 8.01 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_99.pth
	Model improved!!!
EPOCH 100/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954987526719663		[learning rate: 0.0046594]
	Learning Rate: 0.00465944
	LOSS [training: 0.02954987526719663 | validation: 0.029565231358746186]
	TIME [epoch: 8.02 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_100.pth
	Model improved!!!
EPOCH 101/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549861605122275		[learning rate: 0.0045885]
	Learning Rate: 0.00458846
	LOSS [training: 0.029549861605122275 | validation: 0.02956522382117604]
	TIME [epoch: 122 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_101.pth
	Model improved!!!
EPOCH 102/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954986703656853		[learning rate: 0.0045186]
	Learning Rate: 0.00451856
	LOSS [training: 0.02954986703656853 | validation: 0.02956522805041225]
	TIME [epoch: 18.4 sec]
EPOCH 103/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549867605936107		[learning rate: 0.0044497]
	Learning Rate: 0.00444973
	LOSS [training: 0.029549867605936107 | validation: 0.029565225061602387]
	TIME [epoch: 18.4 sec]
EPOCH 104/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549865656655423		[learning rate: 0.0043819]
	Learning Rate: 0.00438194
	LOSS [training: 0.029549865656655423 | validation: 0.029565210651262032]
	TIME [epoch: 18.5 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_104.pth
	Model improved!!!
EPOCH 105/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549857199362907		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 0.029549857199362907 | validation: 0.029565233404482666]
	TIME [epoch: 18.4 sec]
EPOCH 106/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954985653175266		[learning rate: 0.0042495]
	Learning Rate: 0.00424946
	LOSS [training: 0.02954985653175266 | validation: 0.029565225032979543]
	TIME [epoch: 18.4 sec]
EPOCH 107/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549845591948176		[learning rate: 0.0041847]
	Learning Rate: 0.00418472
	LOSS [training: 0.029549845591948176 | validation: 0.029565237608752293]
	TIME [epoch: 18.3 sec]
EPOCH 108/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549850374128685		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.029549850374128685 | validation: 0.029565244072729924]
	TIME [epoch: 18.4 sec]
EPOCH 109/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954984874138255		[learning rate: 0.0040582]
	Learning Rate: 0.0040582
	LOSS [training: 0.02954984874138255 | validation: 0.029565211948237514]
	TIME [epoch: 18.3 sec]
EPOCH 110/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549874768917968		[learning rate: 0.0039964]
	Learning Rate: 0.00399638
	LOSS [training: 0.029549874768917968 | validation: 0.029565215260767552]
	TIME [epoch: 18.4 sec]
EPOCH 111/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954986949231979		[learning rate: 0.0039355]
	Learning Rate: 0.0039355
	LOSS [training: 0.02954986949231979 | validation: 0.029565202397285675]
	TIME [epoch: 18.4 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_111.pth
	Model improved!!!
EPOCH 112/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954983742379494		[learning rate: 0.0038755]
	Learning Rate: 0.00387555
	LOSS [training: 0.02954983742379494 | validation: 0.029565206266831692]
	TIME [epoch: 18.5 sec]
EPOCH 113/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549850937369792		[learning rate: 0.0038165]
	Learning Rate: 0.00381651
	LOSS [training: 0.029549850937369792 | validation: 0.029565202828354696]
	TIME [epoch: 18.5 sec]
EPOCH 114/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549829638698368		[learning rate: 0.0037584]
	Learning Rate: 0.00375837
	LOSS [training: 0.029549829638698368 | validation: 0.02956518946196804]
	TIME [epoch: 18.5 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_114.pth
	Model improved!!!
EPOCH 115/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549836374447625		[learning rate: 0.0037011]
	Learning Rate: 0.00370112
	LOSS [training: 0.029549836374447625 | validation: 0.029565188900393204]
	TIME [epoch: 18.4 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_115.pth
	Model improved!!!
EPOCH 116/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549838236418206		[learning rate: 0.0036447]
	Learning Rate: 0.00364474
	LOSS [training: 0.029549838236418206 | validation: 0.029565196022697644]
	TIME [epoch: 18.4 sec]
EPOCH 117/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549837844070552		[learning rate: 0.0035892]
	Learning Rate: 0.00358922
	LOSS [training: 0.029549837844070552 | validation: 0.029565284668255296]
	TIME [epoch: 18.4 sec]
EPOCH 118/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549842914037765		[learning rate: 0.0035345]
	Learning Rate: 0.00353454
	LOSS [training: 0.029549842914037765 | validation: 0.029565196755138266]
	TIME [epoch: 18.5 sec]
EPOCH 119/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954986200437457		[learning rate: 0.0034807]
	Learning Rate: 0.0034807
	LOSS [training: 0.02954986200437457 | validation: 0.029565232525813494]
	TIME [epoch: 18.5 sec]
EPOCH 120/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954986799174006		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 0.02954986799174006 | validation: 0.029565192793584466]
	TIME [epoch: 18.5 sec]
EPOCH 121/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954985883608892		[learning rate: 0.0033755]
	Learning Rate: 0.00337546
	LOSS [training: 0.02954985883608892 | validation: 0.029565196429250123]
	TIME [epoch: 18.5 sec]
EPOCH 122/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954983279407191		[learning rate: 0.003324]
	Learning Rate: 0.00332404
	LOSS [training: 0.02954983279407191 | validation: 0.029565206994476387]
	TIME [epoch: 18.5 sec]
EPOCH 123/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0295498320981468		[learning rate: 0.0032734]
	Learning Rate: 0.00327341
	LOSS [training: 0.0295498320981468 | validation: 0.029565188072993104]
	TIME [epoch: 18.5 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_123.pth
	Model improved!!!
EPOCH 124/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954985111911862		[learning rate: 0.0032235]
	Learning Rate: 0.00322354
	LOSS [training: 0.02954985111911862 | validation: 0.029565231196395456]
	TIME [epoch: 18.5 sec]
EPOCH 125/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954985622848731		[learning rate: 0.0031744]
	Learning Rate: 0.00317444
	LOSS [training: 0.02954985622848731 | validation: 0.029565200163753927]
	TIME [epoch: 18.4 sec]
EPOCH 126/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549833935475008		[learning rate: 0.0031261]
	Learning Rate: 0.00312608
	LOSS [training: 0.029549833935475008 | validation: 0.029565210565228157]
	TIME [epoch: 18.4 sec]
EPOCH 127/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549839810587137		[learning rate: 0.0030785]
	Learning Rate: 0.00307846
	LOSS [training: 0.029549839810587137 | validation: 0.029565241544523294]
	TIME [epoch: 18.4 sec]
EPOCH 128/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549831311794464		[learning rate: 0.0030316]
	Learning Rate: 0.00303156
	LOSS [training: 0.029549831311794464 | validation: 0.02956527314772855]
	TIME [epoch: 18.4 sec]
EPOCH 129/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549879859051192		[learning rate: 0.0029854]
	Learning Rate: 0.00298538
	LOSS [training: 0.029549879859051192 | validation: 0.029565199965490705]
	TIME [epoch: 18.4 sec]
EPOCH 130/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549855322145154		[learning rate: 0.0029399]
	Learning Rate: 0.0029399
	LOSS [training: 0.029549855322145154 | validation: 0.029565294619525763]
	TIME [epoch: 18.5 sec]
EPOCH 131/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954984543480856		[learning rate: 0.0028951]
	Learning Rate: 0.00289512
	LOSS [training: 0.02954984543480856 | validation: 0.029565201565820032]
	TIME [epoch: 18.4 sec]
EPOCH 132/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549894181144763		[learning rate: 0.002851]
	Learning Rate: 0.00285102
	LOSS [training: 0.029549894181144763 | validation: 0.029565204036630866]
	TIME [epoch: 18.5 sec]
EPOCH 133/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954987435291979		[learning rate: 0.0028076]
	Learning Rate: 0.00280759
	LOSS [training: 0.02954987435291979 | validation: 0.02956527460662791]
	TIME [epoch: 18.4 sec]
EPOCH 134/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549845867742373		[learning rate: 0.0027648]
	Learning Rate: 0.00276482
	LOSS [training: 0.029549845867742373 | validation: 0.029565239650495047]
	TIME [epoch: 18.5 sec]
EPOCH 135/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549853640950186		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.029549853640950186 | validation: 0.02956525788845695]
	TIME [epoch: 18.5 sec]
EPOCH 136/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549846401924502		[learning rate: 0.0026812]
	Learning Rate: 0.00268123
	LOSS [training: 0.029549846401924502 | validation: 0.029565202675512367]
	TIME [epoch: 18.5 sec]
EPOCH 137/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954984077626334		[learning rate: 0.0026404]
	Learning Rate: 0.00264038
	LOSS [training: 0.02954984077626334 | validation: 0.02956520869131389]
	TIME [epoch: 18.5 sec]
EPOCH 138/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549828651191795		[learning rate: 0.0026002]
	Learning Rate: 0.00260016
	LOSS [training: 0.029549828651191795 | validation: 0.02956521016170164]
	TIME [epoch: 18.5 sec]
EPOCH 139/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549859994201007		[learning rate: 0.0025606]
	Learning Rate: 0.00256055
	LOSS [training: 0.029549859994201007 | validation: 0.029565193731339333]
	TIME [epoch: 18.4 sec]
EPOCH 140/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954989045044741		[learning rate: 0.0025215]
	Learning Rate: 0.00252154
	LOSS [training: 0.02954989045044741 | validation: 0.029565198553649304]
	TIME [epoch: 18.5 sec]
EPOCH 141/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549841649258456		[learning rate: 0.0024831]
	Learning Rate: 0.00248313
	LOSS [training: 0.029549841649258456 | validation: 0.029565201599395234]
	TIME [epoch: 18.4 sec]
EPOCH 142/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954984089226949		[learning rate: 0.0024453]
	Learning Rate: 0.00244531
	LOSS [training: 0.02954984089226949 | validation: 0.029565207435516584]
	TIME [epoch: 18.5 sec]
EPOCH 143/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549891963246172		[learning rate: 0.0024081]
	Learning Rate: 0.00240806
	LOSS [training: 0.029549891963246172 | validation: 0.029565197183478633]
	TIME [epoch: 18.4 sec]
EPOCH 144/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549828997413364		[learning rate: 0.0023714]
	Learning Rate: 0.00237137
	LOSS [training: 0.029549828997413364 | validation: 0.02956523198534486]
	TIME [epoch: 18.5 sec]
EPOCH 145/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549830989310886		[learning rate: 0.0023352]
	Learning Rate: 0.00233525
	LOSS [training: 0.029549830989310886 | validation: 0.0295652003854042]
	TIME [epoch: 18.3 sec]
EPOCH 146/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549830488385526		[learning rate: 0.0022997]
	Learning Rate: 0.00229968
	LOSS [training: 0.029549830488385526 | validation: 0.029565192694416657]
	TIME [epoch: 18.5 sec]
EPOCH 147/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954987711088751		[learning rate: 0.0022646]
	Learning Rate: 0.00226464
	LOSS [training: 0.02954987711088751 | validation: 0.029565198173956236]
	TIME [epoch: 18.4 sec]
EPOCH 148/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549850307718433		[learning rate: 0.0022301]
	Learning Rate: 0.00223015
	LOSS [training: 0.029549850307718433 | validation: 0.029565201356751603]
	TIME [epoch: 18.5 sec]
EPOCH 149/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549830496417857		[learning rate: 0.0021962]
	Learning Rate: 0.00219617
	LOSS [training: 0.029549830496417857 | validation: 0.029565254146931896]
	TIME [epoch: 18.4 sec]
EPOCH 150/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549835360651176		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: 0.029549835360651176 | validation: 0.029565208795427955]
	TIME [epoch: 18.5 sec]
EPOCH 151/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549830646099114		[learning rate: 0.0021298]
	Learning Rate: 0.00212977
	LOSS [training: 0.029549830646099114 | validation: 0.02956520087925988]
	TIME [epoch: 18.4 sec]
EPOCH 152/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549839744137926		[learning rate: 0.0020973]
	Learning Rate: 0.00209733
	LOSS [training: 0.029549839744137926 | validation: 0.029565212075397994]
	TIME [epoch: 18.4 sec]
EPOCH 153/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549849181763916		[learning rate: 0.0020654]
	Learning Rate: 0.00206538
	LOSS [training: 0.029549849181763916 | validation: 0.02956518832103297]
	TIME [epoch: 18.4 sec]
EPOCH 154/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954984011379403		[learning rate: 0.0020339]
	Learning Rate: 0.00203392
	LOSS [training: 0.02954984011379403 | validation: 0.029565240482772467]
	TIME [epoch: 18.4 sec]
EPOCH 155/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0295498393369884		[learning rate: 0.0020029]
	Learning Rate: 0.00200293
	LOSS [training: 0.0295498393369884 | validation: 0.029565200936046254]
	TIME [epoch: 18.4 sec]
EPOCH 156/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549844693815074		[learning rate: 0.0019724]
	Learning Rate: 0.00197242
	LOSS [training: 0.029549844693815074 | validation: 0.029565182048396914]
	TIME [epoch: 18.5 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_156.pth
	Model improved!!!
EPOCH 157/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954984234271213		[learning rate: 0.0019424]
	Learning Rate: 0.00194238
	LOSS [training: 0.02954984234271213 | validation: 0.029565202254128092]
	TIME [epoch: 18.6 sec]
EPOCH 158/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954985631828356		[learning rate: 0.0019128]
	Learning Rate: 0.00191279
	LOSS [training: 0.02954985631828356 | validation: 0.0295651977461989]
	TIME [epoch: 18.6 sec]
EPOCH 159/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549825177748703		[learning rate: 0.0018836]
	Learning Rate: 0.00188365
	LOSS [training: 0.029549825177748703 | validation: 0.02956519178728013]
	TIME [epoch: 18.6 sec]
EPOCH 160/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0295498219256244		[learning rate: 0.001855]
	Learning Rate: 0.00185495
	LOSS [training: 0.0295498219256244 | validation: 0.029565192781396937]
	TIME [epoch: 18.6 sec]
EPOCH 161/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954983422181702		[learning rate: 0.0018267]
	Learning Rate: 0.0018267
	LOSS [training: 0.02954983422181702 | validation: 0.02956521508717201]
	TIME [epoch: 18.6 sec]
EPOCH 162/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549830156640644		[learning rate: 0.0017989]
	Learning Rate: 0.00179887
	LOSS [training: 0.029549830156640644 | validation: 0.029565204307567303]
	TIME [epoch: 18.6 sec]
EPOCH 163/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549833699215912		[learning rate: 0.0017715]
	Learning Rate: 0.00177147
	LOSS [training: 0.029549833699215912 | validation: 0.029565191661657508]
	TIME [epoch: 18.6 sec]
EPOCH 164/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549843108106044		[learning rate: 0.0017445]
	Learning Rate: 0.00174448
	LOSS [training: 0.029549843108106044 | validation: 0.029565207184372305]
	TIME [epoch: 18.6 sec]
EPOCH 165/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549839162082113		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: 0.029549839162082113 | validation: 0.029565192162361864]
	TIME [epoch: 18.6 sec]
EPOCH 166/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549828078764866		[learning rate: 0.0016917]
	Learning Rate: 0.00169174
	LOSS [training: 0.029549828078764866 | validation: 0.029565211417697662]
	TIME [epoch: 18.6 sec]
EPOCH 167/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0295498204531098		[learning rate: 0.001666]
	Learning Rate: 0.00166597
	LOSS [training: 0.0295498204531098 | validation: 0.029565183260428167]
	TIME [epoch: 18.6 sec]
EPOCH 168/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954982842805496		[learning rate: 0.0016406]
	Learning Rate: 0.00164059
	LOSS [training: 0.02954982842805496 | validation: 0.02956521148049423]
	TIME [epoch: 18.6 sec]
EPOCH 169/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549830076943038		[learning rate: 0.0016156]
	Learning Rate: 0.0016156
	LOSS [training: 0.029549830076943038 | validation: 0.029565198171727355]
	TIME [epoch: 18.6 sec]
EPOCH 170/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549821318314847		[learning rate: 0.001591]
	Learning Rate: 0.00159099
	LOSS [training: 0.029549821318314847 | validation: 0.029565206985752296]
	TIME [epoch: 18.6 sec]
EPOCH 171/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549823287298		[learning rate: 0.0015668]
	Learning Rate: 0.00156675
	LOSS [training: 0.029549823287298 | validation: 0.029565186277252513]
	TIME [epoch: 18.6 sec]
EPOCH 172/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549851390566907		[learning rate: 0.0015429]
	Learning Rate: 0.00154288
	LOSS [training: 0.029549851390566907 | validation: 0.029565206081018834]
	TIME [epoch: 18.6 sec]
EPOCH 173/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549833022278812		[learning rate: 0.0015194]
	Learning Rate: 0.00151938
	LOSS [training: 0.029549833022278812 | validation: 0.029565183830807355]
	TIME [epoch: 18.6 sec]
EPOCH 174/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549860610096575		[learning rate: 0.0014962]
	Learning Rate: 0.00149624
	LOSS [training: 0.029549860610096575 | validation: 0.02956520070979523]
	TIME [epoch: 18.5 sec]
EPOCH 175/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549846694642237		[learning rate: 0.0014734]
	Learning Rate: 0.00147344
	LOSS [training: 0.029549846694642237 | validation: 0.02956518230585603]
	TIME [epoch: 18.6 sec]
EPOCH 176/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549831787140966		[learning rate: 0.001451]
	Learning Rate: 0.001451
	LOSS [training: 0.029549831787140966 | validation: 0.029565183715023736]
	TIME [epoch: 18.6 sec]
EPOCH 177/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549839659242544		[learning rate: 0.0014289]
	Learning Rate: 0.00142889
	LOSS [training: 0.029549839659242544 | validation: 0.02956518574185578]
	TIME [epoch: 18.6 sec]
EPOCH 178/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549822905553642		[learning rate: 0.0014071]
	Learning Rate: 0.00140713
	LOSS [training: 0.029549822905553642 | validation: 0.029565190939894723]
	TIME [epoch: 18.5 sec]
EPOCH 179/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954983453144159		[learning rate: 0.0013857]
	Learning Rate: 0.00138569
	LOSS [training: 0.02954983453144159 | validation: 0.029565183336808454]
	TIME [epoch: 18.5 sec]
EPOCH 180/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549833116331102		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: 0.029549833116331102 | validation: 0.02956518567655249]
	TIME [epoch: 18.5 sec]
EPOCH 181/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954984071679346		[learning rate: 0.0013438]
	Learning Rate: 0.0013438
	LOSS [training: 0.02954984071679346 | validation: 0.029565176837104856]
	TIME [epoch: 18.5 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_181.pth
	Model improved!!!
EPOCH 182/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549853529928803		[learning rate: 0.0013233]
	Learning Rate: 0.00132333
	LOSS [training: 0.029549853529928803 | validation: 0.02956517965823726]
	TIME [epoch: 18.4 sec]
EPOCH 183/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954981993215253		[learning rate: 0.0013032]
	Learning Rate: 0.00130317
	LOSS [training: 0.02954981993215253 | validation: 0.029565175060040548]
	TIME [epoch: 18.5 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_183.pth
	Model improved!!!
EPOCH 184/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0295498158248174		[learning rate: 0.0012833]
	Learning Rate: 0.00128332
	LOSS [training: 0.0295498158248174 | validation: 0.029565182931897555]
	TIME [epoch: 18.5 sec]
EPOCH 185/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549837952212762		[learning rate: 0.0012638]
	Learning Rate: 0.00126377
	LOSS [training: 0.029549837952212762 | validation: 0.02956517541068073]
	TIME [epoch: 18.5 sec]
EPOCH 186/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549850212255514		[learning rate: 0.0012445]
	Learning Rate: 0.00124451
	LOSS [training: 0.029549850212255514 | validation: 0.029565196687028845]
	TIME [epoch: 18.5 sec]
EPOCH 187/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549822498231137		[learning rate: 0.0012256]
	Learning Rate: 0.00122556
	LOSS [training: 0.029549822498231137 | validation: 0.02956517752013546]
	TIME [epoch: 18.5 sec]
EPOCH 188/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549827032158124		[learning rate: 0.0012069]
	Learning Rate: 0.00120689
	LOSS [training: 0.029549827032158124 | validation: 0.029565174661990615]
	TIME [epoch: 18.5 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_188.pth
	Model improved!!!
EPOCH 189/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549807619466316		[learning rate: 0.0011885]
	Learning Rate: 0.0011885
	LOSS [training: 0.029549807619466316 | validation: 0.029565185597049064]
	TIME [epoch: 18.6 sec]
EPOCH 190/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549814617664052		[learning rate: 0.0011704]
	Learning Rate: 0.0011704
	LOSS [training: 0.029549814617664052 | validation: 0.029565179070389826]
	TIME [epoch: 18.5 sec]
EPOCH 191/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954981420169076		[learning rate: 0.0011526]
	Learning Rate: 0.00115257
	LOSS [training: 0.02954981420169076 | validation: 0.029565203413275547]
	TIME [epoch: 18.5 sec]
EPOCH 192/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549815294371208		[learning rate: 0.001135]
	Learning Rate: 0.00113501
	LOSS [training: 0.029549815294371208 | validation: 0.029565174023709843]
	TIME [epoch: 18.5 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_192.pth
	Model improved!!!
EPOCH 193/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549810279439818		[learning rate: 0.0011177]
	Learning Rate: 0.00111772
	LOSS [training: 0.029549810279439818 | validation: 0.029565181352970663]
	TIME [epoch: 18.5 sec]
EPOCH 194/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549816947183748		[learning rate: 0.0011007]
	Learning Rate: 0.00110069
	LOSS [training: 0.029549816947183748 | validation: 0.029565175248993783]
	TIME [epoch: 18.4 sec]
EPOCH 195/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954981393496051		[learning rate: 0.0010839]
	Learning Rate: 0.00108393
	LOSS [training: 0.02954981393496051 | validation: 0.02956519517422294]
	TIME [epoch: 18.5 sec]
EPOCH 196/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549810328145115		[learning rate: 0.0010674]
	Learning Rate: 0.00106741
	LOSS [training: 0.029549810328145115 | validation: 0.029565169596265532]
	TIME [epoch: 18.5 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_196.pth
	Model improved!!!
EPOCH 197/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954980865600065		[learning rate: 0.0010512]
	Learning Rate: 0.00105115
	LOSS [training: 0.02954980865600065 | validation: 0.029565205009564503]
	TIME [epoch: 18.4 sec]
EPOCH 198/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954981845888736		[learning rate: 0.0010351]
	Learning Rate: 0.00103514
	LOSS [training: 0.02954981845888736 | validation: 0.02956516977758562]
	TIME [epoch: 18.3 sec]
EPOCH 199/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549812002178363		[learning rate: 0.0010194]
	Learning Rate: 0.00101937
	LOSS [training: 0.029549812002178363 | validation: 0.029565183792170685]
	TIME [epoch: 18.4 sec]
EPOCH 200/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954981934499302		[learning rate: 0.0010038]
	Learning Rate: 0.00100384
	LOSS [training: 0.02954981934499302 | validation: 0.02956517292409548]
	TIME [epoch: 18.3 sec]
EPOCH 201/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954981171561532		[learning rate: 0.00098855]
	Learning Rate: 0.000988553
	LOSS [training: 0.02954981171561532 | validation: 0.02956517392233357]
	TIME [epoch: 18.4 sec]
EPOCH 202/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954986687229922		[learning rate: 0.00097349]
	Learning Rate: 0.000973494
	LOSS [training: 0.02954986687229922 | validation: 0.029565191455378642]
	TIME [epoch: 18.4 sec]
EPOCH 203/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954982888032444		[learning rate: 0.00095866]
	Learning Rate: 0.000958664
	LOSS [training: 0.02954982888032444 | validation: 0.0295652013314556]
	TIME [epoch: 18.5 sec]
EPOCH 204/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549812492470916		[learning rate: 0.00094406]
	Learning Rate: 0.000944061
	LOSS [training: 0.029549812492470916 | validation: 0.029565172920324047]
	TIME [epoch: 18.4 sec]
EPOCH 205/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549814866558086		[learning rate: 0.00092968]
	Learning Rate: 0.00092968
	LOSS [training: 0.029549814866558086 | validation: 0.02956518584458297]
	TIME [epoch: 18.4 sec]
EPOCH 206/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549816285437916		[learning rate: 0.00091552]
	Learning Rate: 0.000915518
	LOSS [training: 0.029549816285437916 | validation: 0.029565175039833535]
	TIME [epoch: 18.4 sec]
EPOCH 207/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549813422755825		[learning rate: 0.00090157]
	Learning Rate: 0.000901571
	LOSS [training: 0.029549813422755825 | validation: 0.02956517531849786]
	TIME [epoch: 18.4 sec]
EPOCH 208/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549813554628376		[learning rate: 0.00088784]
	Learning Rate: 0.000887837
	LOSS [training: 0.029549813554628376 | validation: 0.029565175678379282]
	TIME [epoch: 18.4 sec]
EPOCH 209/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954981062865947		[learning rate: 0.00087431]
	Learning Rate: 0.000874312
	LOSS [training: 0.02954981062865947 | validation: 0.029565178819179264]
	TIME [epoch: 18.5 sec]
EPOCH 210/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0295498218279066		[learning rate: 0.00086099]
	Learning Rate: 0.000860994
	LOSS [training: 0.0295498218279066 | validation: 0.029565244089825436]
	TIME [epoch: 18.4 sec]
EPOCH 211/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954982461136401		[learning rate: 0.00084788]
	Learning Rate: 0.000847878
	LOSS [training: 0.02954982461136401 | validation: 0.029565186487387117]
	TIME [epoch: 18.5 sec]
EPOCH 212/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549846673725098		[learning rate: 0.00083496]
	Learning Rate: 0.000834962
	LOSS [training: 0.029549846673725098 | validation: 0.029565182617725838]
	TIME [epoch: 18.4 sec]
EPOCH 213/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954982356007712		[learning rate: 0.00082224]
	Learning Rate: 0.000822243
	LOSS [training: 0.02954982356007712 | validation: 0.029565189449706826]
	TIME [epoch: 18.4 sec]
EPOCH 214/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954981350521625		[learning rate: 0.00080972]
	Learning Rate: 0.000809717
	LOSS [training: 0.02954981350521625 | validation: 0.029565178729385747]
	TIME [epoch: 18.4 sec]
EPOCH 215/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549828968816208		[learning rate: 0.00079738]
	Learning Rate: 0.000797382
	LOSS [training: 0.029549828968816208 | validation: 0.029565209108442382]
	TIME [epoch: 18.4 sec]
EPOCH 216/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954981444365462		[learning rate: 0.00078524]
	Learning Rate: 0.000785236
	LOSS [training: 0.02954981444365462 | validation: 0.029565182780804337]
	TIME [epoch: 18.4 sec]
EPOCH 217/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549811532127556		[learning rate: 0.00077327]
	Learning Rate: 0.000773274
	LOSS [training: 0.029549811532127556 | validation: 0.029565172996987528]
	TIME [epoch: 18.4 sec]
EPOCH 218/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549821052576506		[learning rate: 0.00076149]
	Learning Rate: 0.000761494
	LOSS [training: 0.029549821052576506 | validation: 0.029565174653458634]
	TIME [epoch: 18.4 sec]
EPOCH 219/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549823305126156		[learning rate: 0.00074989]
	Learning Rate: 0.000749894
	LOSS [training: 0.029549823305126156 | validation: 0.029565175377920076]
	TIME [epoch: 18.4 sec]
EPOCH 220/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0295498121921597		[learning rate: 0.00073847]
	Learning Rate: 0.000738471
	LOSS [training: 0.0295498121921597 | validation: 0.02956522770568667]
	TIME [epoch: 18.4 sec]
EPOCH 221/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549814646808923		[learning rate: 0.00072722]
	Learning Rate: 0.000727221
	LOSS [training: 0.029549814646808923 | validation: 0.029565179264651305]
	TIME [epoch: 18.4 sec]
EPOCH 222/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954983188705137		[learning rate: 0.00071614]
	Learning Rate: 0.000716143
	LOSS [training: 0.02954983188705137 | validation: 0.029565318545370412]
	TIME [epoch: 18.4 sec]
EPOCH 223/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549823481224598		[learning rate: 0.00070523]
	Learning Rate: 0.000705234
	LOSS [training: 0.029549823481224598 | validation: 0.029565194561339214]
	TIME [epoch: 18.4 sec]
EPOCH 224/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549840016247646		[learning rate: 0.00069449]
	Learning Rate: 0.000694491
	LOSS [training: 0.029549840016247646 | validation: 0.029565171516949533]
	TIME [epoch: 18.4 sec]
EPOCH 225/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549811943949185		[learning rate: 0.00068391]
	Learning Rate: 0.000683912
	LOSS [training: 0.029549811943949185 | validation: 0.029565171718006086]
	TIME [epoch: 18.4 sec]
EPOCH 226/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549815988686147		[learning rate: 0.00067349]
	Learning Rate: 0.000673493
	LOSS [training: 0.029549815988686147 | validation: 0.029565194445183185]
	TIME [epoch: 18.4 sec]
EPOCH 227/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954981682116745		[learning rate: 0.00066323]
	Learning Rate: 0.000663234
	LOSS [training: 0.02954981682116745 | validation: 0.029565178335356657]
	TIME [epoch: 18.4 sec]
EPOCH 228/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954983819495131		[learning rate: 0.00065313]
	Learning Rate: 0.00065313
	LOSS [training: 0.02954983819495131 | validation: 0.02956517864595872]
	TIME [epoch: 18.4 sec]
EPOCH 229/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0295498303338339		[learning rate: 0.00064318]
	Learning Rate: 0.000643181
	LOSS [training: 0.0295498303338339 | validation: 0.02956517840960203]
	TIME [epoch: 18.4 sec]
EPOCH 230/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954981049559966		[learning rate: 0.00063338]
	Learning Rate: 0.000633383
	LOSS [training: 0.02954981049559966 | validation: 0.02956517522202836]
	TIME [epoch: 18.4 sec]
EPOCH 231/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549805996409342		[learning rate: 0.00062373]
	Learning Rate: 0.000623735
	LOSS [training: 0.029549805996409342 | validation: 0.0295651781898282]
	TIME [epoch: 18.4 sec]
EPOCH 232/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549817263611423		[learning rate: 0.00061423]
	Learning Rate: 0.000614233
	LOSS [training: 0.029549817263611423 | validation: 0.029565177092617616]
	TIME [epoch: 18.3 sec]
EPOCH 233/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549820217763114		[learning rate: 0.00060488]
	Learning Rate: 0.000604876
	LOSS [training: 0.029549820217763114 | validation: 0.02956517695465049]
	TIME [epoch: 18.3 sec]
EPOCH 234/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549813752676		[learning rate: 0.00059566]
	Learning Rate: 0.000595662
	LOSS [training: 0.029549813752676 | validation: 0.02956518532819555]
	TIME [epoch: 18.4 sec]
EPOCH 235/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549813346867376		[learning rate: 0.00058659]
	Learning Rate: 0.000586588
	LOSS [training: 0.029549813346867376 | validation: 0.029565175406059588]
	TIME [epoch: 18.4 sec]
EPOCH 236/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549817709641116		[learning rate: 0.00057765]
	Learning Rate: 0.000577652
	LOSS [training: 0.029549817709641116 | validation: 0.029565271691677907]
	TIME [epoch: 18.4 sec]
EPOCH 237/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954981572095887		[learning rate: 0.00056885]
	Learning Rate: 0.000568853
	LOSS [training: 0.02954981572095887 | validation: 0.029565199758522592]
	TIME [epoch: 18.4 sec]
EPOCH 238/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549816473398976		[learning rate: 0.00056019]
	Learning Rate: 0.000560187
	LOSS [training: 0.029549816473398976 | validation: 0.02956518269273482]
	TIME [epoch: 18.5 sec]
EPOCH 239/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549813968672654		[learning rate: 0.00055165]
	Learning Rate: 0.000551654
	LOSS [training: 0.029549813968672654 | validation: 0.02956517920721745]
	TIME [epoch: 18.4 sec]
EPOCH 240/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549821570740133		[learning rate: 0.00054325]
	Learning Rate: 0.00054325
	LOSS [training: 0.029549821570740133 | validation: 0.029565175590925426]
	TIME [epoch: 18.4 sec]
EPOCH 241/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549804478517225		[learning rate: 0.00053497]
	Learning Rate: 0.000534975
	LOSS [training: 0.029549804478517225 | validation: 0.0295651749141021]
	TIME [epoch: 18.5 sec]
EPOCH 242/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549811447759596		[learning rate: 0.00052683]
	Learning Rate: 0.000526825
	LOSS [training: 0.029549811447759596 | validation: 0.029565173449913155]
	TIME [epoch: 18.4 sec]
EPOCH 243/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549830845271116		[learning rate: 0.0005188]
	Learning Rate: 0.0005188
	LOSS [training: 0.029549830845271116 | validation: 0.029565170982355865]
	TIME [epoch: 18.4 sec]
EPOCH 244/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954982650771094		[learning rate: 0.0005109]
	Learning Rate: 0.000510897
	LOSS [training: 0.02954982650771094 | validation: 0.029565201080459923]
	TIME [epoch: 18.4 sec]
EPOCH 245/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549817154726196		[learning rate: 0.00050311]
	Learning Rate: 0.000503114
	LOSS [training: 0.029549817154726196 | validation: 0.029565179507210833]
	TIME [epoch: 18.4 sec]
EPOCH 246/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954985345428211		[learning rate: 0.00049545]
	Learning Rate: 0.00049545
	LOSS [training: 0.02954985345428211 | validation: 0.02956517902791684]
	TIME [epoch: 18.4 sec]
EPOCH 247/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549808419110906		[learning rate: 0.0004879]
	Learning Rate: 0.000487903
	LOSS [training: 0.029549808419110906 | validation: 0.029565180445857202]
	TIME [epoch: 18.4 sec]
EPOCH 248/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549831299027097		[learning rate: 0.00048047]
	Learning Rate: 0.00048047
	LOSS [training: 0.029549831299027097 | validation: 0.029565189367328357]
	TIME [epoch: 18.3 sec]
EPOCH 249/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549828744561964		[learning rate: 0.00047315]
	Learning Rate: 0.000473151
	LOSS [training: 0.029549828744561964 | validation: 0.029565193514928655]
	TIME [epoch: 18.1 sec]
EPOCH 250/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954981062367755		[learning rate: 0.00046594]
	Learning Rate: 0.000465944
	LOSS [training: 0.02954981062367755 | validation: 0.029565190317164765]
	TIME [epoch: 18.1 sec]
EPOCH 251/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954981159988171		[learning rate: 0.00045885]
	Learning Rate: 0.000458846
	LOSS [training: 0.02954981159988171 | validation: 0.029565173492072383]
	TIME [epoch: 143 sec]
EPOCH 252/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549825339814522		[learning rate: 0.00045186]
	Learning Rate: 0.000451856
	LOSS [training: 0.029549825339814522 | validation: 0.029565190393784902]
	TIME [epoch: 40.6 sec]
EPOCH 253/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549815897831698		[learning rate: 0.00044497]
	Learning Rate: 0.000444973
	LOSS [training: 0.029549815897831698 | validation: 0.02956522062697058]
	TIME [epoch: 40.7 sec]
EPOCH 254/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954980981553095		[learning rate: 0.00043819]
	Learning Rate: 0.000438194
	LOSS [training: 0.02954980981553095 | validation: 0.029565189219973316]
	TIME [epoch: 40.8 sec]
EPOCH 255/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549809105539712		[learning rate: 0.00043152]
	Learning Rate: 0.000431519
	LOSS [training: 0.029549809105539712 | validation: 0.02956518522643764]
	TIME [epoch: 40.7 sec]
EPOCH 256/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954980907510628		[learning rate: 0.00042495]
	Learning Rate: 0.000424946
	LOSS [training: 0.02954980907510628 | validation: 0.029565182278793067]
	TIME [epoch: 40.7 sec]
EPOCH 257/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549808997418308		[learning rate: 0.00041847]
	Learning Rate: 0.000418472
	LOSS [training: 0.029549808997418308 | validation: 0.02956517319872303]
	TIME [epoch: 40.8 sec]
EPOCH 258/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549810662100322		[learning rate: 0.0004121]
	Learning Rate: 0.000412098
	LOSS [training: 0.029549810662100322 | validation: 0.029565173588068098]
	TIME [epoch: 40.7 sec]
EPOCH 259/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549816097392413		[learning rate: 0.00040582]
	Learning Rate: 0.00040582
	LOSS [training: 0.029549816097392413 | validation: 0.029565179178621902]
	TIME [epoch: 40.7 sec]
EPOCH 260/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549807453888407		[learning rate: 0.00039964]
	Learning Rate: 0.000399638
	LOSS [training: 0.029549807453888407 | validation: 0.029565175182426663]
	TIME [epoch: 40.7 sec]
EPOCH 261/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549806567154488		[learning rate: 0.00039355]
	Learning Rate: 0.00039355
	LOSS [training: 0.029549806567154488 | validation: 0.02956517145553069]
	TIME [epoch: 40.6 sec]
EPOCH 262/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954982721123047		[learning rate: 0.00038755]
	Learning Rate: 0.000387555
	LOSS [training: 0.02954982721123047 | validation: 0.029565211092395877]
	TIME [epoch: 40.6 sec]
EPOCH 263/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954980759245726		[learning rate: 0.00038165]
	Learning Rate: 0.000381651
	LOSS [training: 0.02954980759245726 | validation: 0.02956517927677326]
	TIME [epoch: 40.6 sec]
EPOCH 264/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549811123532502		[learning rate: 0.00037584]
	Learning Rate: 0.000375837
	LOSS [training: 0.029549811123532502 | validation: 0.029565190273734436]
	TIME [epoch: 40.6 sec]
EPOCH 265/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549810084499698		[learning rate: 0.00037011]
	Learning Rate: 0.000370112
	LOSS [training: 0.029549810084499698 | validation: 0.02956517149615157]
	TIME [epoch: 40.6 sec]
EPOCH 266/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549813887824697		[learning rate: 0.00036447]
	Learning Rate: 0.000364474
	LOSS [training: 0.029549813887824697 | validation: 0.029565174572110914]
	TIME [epoch: 40.6 sec]
EPOCH 267/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549829843719753		[learning rate: 0.00035892]
	Learning Rate: 0.000358922
	LOSS [training: 0.029549829843719753 | validation: 0.029565188779130173]
	TIME [epoch: 40.6 sec]
EPOCH 268/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549809598910893		[learning rate: 0.00035345]
	Learning Rate: 0.000353454
	LOSS [training: 0.029549809598910893 | validation: 0.02956517392392566]
	TIME [epoch: 40.6 sec]
EPOCH 269/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549820330885955		[learning rate: 0.00034807]
	Learning Rate: 0.00034807
	LOSS [training: 0.029549820330885955 | validation: 0.0295651825204324]
	TIME [epoch: 40.7 sec]
EPOCH 270/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549812795385568		[learning rate: 0.00034277]
	Learning Rate: 0.000342768
	LOSS [training: 0.029549812795385568 | validation: 0.029565174243399613]
	TIME [epoch: 40.6 sec]
EPOCH 271/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549808667781577		[learning rate: 0.00033755]
	Learning Rate: 0.000337546
	LOSS [training: 0.029549808667781577 | validation: 0.029565185985992032]
	TIME [epoch: 40.7 sec]
EPOCH 272/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549807130016724		[learning rate: 0.0003324]
	Learning Rate: 0.000332404
	LOSS [training: 0.029549807130016724 | validation: 0.02956517172499591]
	TIME [epoch: 40.8 sec]
EPOCH 273/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549815219486464		[learning rate: 0.00032734]
	Learning Rate: 0.000327341
	LOSS [training: 0.029549815219486464 | validation: 0.029565196128662173]
	TIME [epoch: 40.8 sec]
EPOCH 274/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954981202669442		[learning rate: 0.00032235]
	Learning Rate: 0.000322354
	LOSS [training: 0.02954981202669442 | validation: 0.02956520377069073]
	TIME [epoch: 40.7 sec]
EPOCH 275/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549829297721063		[learning rate: 0.00031744]
	Learning Rate: 0.000317444
	LOSS [training: 0.029549829297721063 | validation: 0.029565182212836896]
	TIME [epoch: 40.7 sec]
EPOCH 276/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954981268131967		[learning rate: 0.00031261]
	Learning Rate: 0.000312608
	LOSS [training: 0.02954981268131967 | validation: 0.0295651859387508]
	TIME [epoch: 40.7 sec]
EPOCH 277/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0295498125887284		[learning rate: 0.00030785]
	Learning Rate: 0.000307846
	LOSS [training: 0.0295498125887284 | validation: 0.029565179231139167]
	TIME [epoch: 40.8 sec]
EPOCH 278/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954980771041348		[learning rate: 0.00030316]
	Learning Rate: 0.000303156
	LOSS [training: 0.02954980771041348 | validation: 0.029565176041933823]
	TIME [epoch: 40.7 sec]
EPOCH 279/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0295498183116769		[learning rate: 0.00029854]
	Learning Rate: 0.000298538
	LOSS [training: 0.0295498183116769 | validation: 0.02956517795334193]
	TIME [epoch: 40.7 sec]
EPOCH 280/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954981232881106		[learning rate: 0.00029399]
	Learning Rate: 0.000293991
	LOSS [training: 0.02954981232881106 | validation: 0.0295651806849574]
	TIME [epoch: 40.8 sec]
EPOCH 281/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954980934961661		[learning rate: 0.00028951]
	Learning Rate: 0.000289512
	LOSS [training: 0.02954980934961661 | validation: 0.029565213879033048]
	TIME [epoch: 40.7 sec]
EPOCH 282/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549814689358543		[learning rate: 0.0002851]
	Learning Rate: 0.000285102
	LOSS [training: 0.029549814689358543 | validation: 0.02956518041522634]
	TIME [epoch: 40.8 sec]
EPOCH 283/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0295498206673733		[learning rate: 0.00028076]
	Learning Rate: 0.000280759
	LOSS [training: 0.0295498206673733 | validation: 0.02956517573546124]
	TIME [epoch: 40.6 sec]
EPOCH 284/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549814186186636		[learning rate: 0.00027648]
	Learning Rate: 0.000276482
	LOSS [training: 0.029549814186186636 | validation: 0.02956517608328036]
	TIME [epoch: 40.5 sec]
EPOCH 285/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954981849926975		[learning rate: 0.00027227]
	Learning Rate: 0.00027227
	LOSS [training: 0.02954981849926975 | validation: 0.02956517916932544]
	TIME [epoch: 40.4 sec]
EPOCH 286/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954981238243815		[learning rate: 0.00026812]
	Learning Rate: 0.000268123
	LOSS [training: 0.02954981238243815 | validation: 0.029565186301484178]
	TIME [epoch: 40.5 sec]
EPOCH 287/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549831424720827		[learning rate: 0.00026404]
	Learning Rate: 0.000264038
	LOSS [training: 0.029549831424720827 | validation: 0.029565180031431937]
	TIME [epoch: 40.6 sec]
EPOCH 288/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549812590150597		[learning rate: 0.00026002]
	Learning Rate: 0.000260016
	LOSS [training: 0.029549812590150597 | validation: 0.02956517372727534]
	TIME [epoch: 40.4 sec]
EPOCH 289/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954980729398124		[learning rate: 0.00025606]
	Learning Rate: 0.000256055
	LOSS [training: 0.02954980729398124 | validation: 0.029565173077506814]
	TIME [epoch: 40.5 sec]
EPOCH 290/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549826512780483		[learning rate: 0.00025215]
	Learning Rate: 0.000252154
	LOSS [training: 0.029549826512780483 | validation: 0.029565268587091402]
	TIME [epoch: 40.5 sec]
EPOCH 291/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954981569347778		[learning rate: 0.00024831]
	Learning Rate: 0.000248313
	LOSS [training: 0.02954981569347778 | validation: 0.02956517201227725]
	TIME [epoch: 40.4 sec]
EPOCH 292/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954981268788152		[learning rate: 0.00024453]
	Learning Rate: 0.000244531
	LOSS [training: 0.02954981268788152 | validation: 0.02956517242461848]
	TIME [epoch: 40.4 sec]
EPOCH 293/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549829909171075		[learning rate: 0.00024081]
	Learning Rate: 0.000240806
	LOSS [training: 0.029549829909171075 | validation: 0.029565188691661762]
	TIME [epoch: 40.4 sec]
EPOCH 294/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549811494038663		[learning rate: 0.00023714]
	Learning Rate: 0.000237137
	LOSS [training: 0.029549811494038663 | validation: 0.029565177470484212]
	TIME [epoch: 40.4 sec]
EPOCH 295/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549849008604655		[learning rate: 0.00023352]
	Learning Rate: 0.000233525
	LOSS [training: 0.029549849008604655 | validation: 0.02956517133550302]
	TIME [epoch: 40.4 sec]
EPOCH 296/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02954980643818706		[learning rate: 0.00022997]
	Learning Rate: 0.000229968
	LOSS [training: 0.02954980643818706 | validation: 0.029565202589993258]
	TIME [epoch: 40.5 sec]
EPOCH 297/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029549826062504794		[learning rate: 0.00022646]
	Learning Rate: 0.000226464
	LOSS [training: 0.029549826062504794 | validation: 0.02956517150387726]
	TIME [epoch: 40.4 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20240711_014001/states/model_algphiq_1a_v_mmd4_297.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 5768.731 seconds.
