Args:
Namespace(name='model_algphiq_1a_v_mmd3', outdir='out/model_training/model_algphiq_1a_v_mmd3', training_data='data/training_data/data_phiq_1a/training', validation_data='data/training_data/data_phiq_1a/validation', model_type='quadratic', nsims_training=None, nsims_validation=None, num_epochs=500, passes_per_epoch=1, batch_size=250, patience=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=False, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 250], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=False, confinement_factor=1.0, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], phi_final_act='softplus', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=0.0, init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.3], optimizer='rms', momentum=0.0, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3197469889

Training model...

Saving initial model state to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 4/4] avg loss: 5.042031139992105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.042031139992105 | validation: 5.119665573190108]
	TIME [epoch: 95.2 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 4/4] avg loss: 5.01553783526294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.01553783526294 | validation: 5.096913559560747]
	TIME [epoch: 4.26 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 4/4] avg loss: 4.99060035484182		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.99060035484182 | validation: 5.069929807460415]
	TIME [epoch: 4.18 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_3.pth
	Model improved!!!
EPOCH 4/500:
	Training over batches...
		[batch 4/4] avg loss: 4.962285632147434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.962285632147434 | validation: 5.042422536982571]
	TIME [epoch: 4.18 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 4/4] avg loss: 4.929547509581697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.929547509581697 | validation: 5.009852934186833]
	TIME [epoch: 4.19 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_5.pth
	Model improved!!!
EPOCH 6/500:
	Training over batches...
		[batch 4/4] avg loss: 4.890658200315618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.890658200315618 | validation: 4.968298018003056]
	TIME [epoch: 4.22 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_6.pth
	Model improved!!!
EPOCH 7/500:
	Training over batches...
		[batch 4/4] avg loss: 4.844095828298364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.844095828298364 | validation: 4.920331534029219]
	TIME [epoch: 4.19 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_7.pth
	Model improved!!!
EPOCH 8/500:
	Training over batches...
		[batch 4/4] avg loss: 4.7841973256871935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.7841973256871935 | validation: 4.854867524245779]
	TIME [epoch: 4.18 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_8.pth
	Model improved!!!
EPOCH 9/500:
	Training over batches...
		[batch 4/4] avg loss: 4.707555402371227		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.707555402371227 | validation: 4.769026147738078]
	TIME [epoch: 4.18 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_9.pth
	Model improved!!!
EPOCH 10/500:
	Training over batches...
		[batch 4/4] avg loss: 4.601010429939741		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.601010429939741 | validation: 4.640768331017516]
	TIME [epoch: 4.17 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_10.pth
	Model improved!!!
EPOCH 11/500:
	Training over batches...
		[batch 4/4] avg loss: 4.434954982697045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.434954982697045 | validation: 4.417606925577027]
	TIME [epoch: 4.18 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_11.pth
	Model improved!!!
EPOCH 12/500:
	Training over batches...
		[batch 4/4] avg loss: 4.138614729977628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.138614729977628 | validation: 3.909591974193522]
	TIME [epoch: 4.17 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_12.pth
	Model improved!!!
EPOCH 13/500:
	Training over batches...
		[batch 4/4] avg loss: 3.691472836114142		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.691472836114142 | validation: 3.634574898816872]
	TIME [epoch: 4.18 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_13.pth
	Model improved!!!
EPOCH 14/500:
	Training over batches...
		[batch 4/4] avg loss: 3.502612615775415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.502612615775415 | validation: 3.4507197774785796]
	TIME [epoch: 4.19 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_14.pth
	Model improved!!!
EPOCH 15/500:
	Training over batches...
		[batch 4/4] avg loss: 3.342050322431203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.342050322431203 | validation: 3.2559035912996297]
	TIME [epoch: 4.22 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_15.pth
	Model improved!!!
EPOCH 16/500:
	Training over batches...
		[batch 4/4] avg loss: 3.151189783340217		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.151189783340217 | validation: 3.019586878243296]
	TIME [epoch: 4.19 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_16.pth
	Model improved!!!
EPOCH 17/500:
	Training over batches...
		[batch 4/4] avg loss: 2.9149255320126186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9149255320126186 | validation: 2.731147128106014]
	TIME [epoch: 4.18 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_17.pth
	Model improved!!!
EPOCH 18/500:
	Training over batches...
		[batch 4/4] avg loss: 2.6511292901102355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6511292901102355 | validation: 2.3948930269218867]
	TIME [epoch: 4.18 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_18.pth
	Model improved!!!
EPOCH 19/500:
	Training over batches...
		[batch 4/4] avg loss: 2.3251321735013426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3251321735013426 | validation: 2.0220033794242553]
	TIME [epoch: 4.17 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_19.pth
	Model improved!!!
EPOCH 20/500:
	Training over batches...
		[batch 4/4] avg loss: 1.9441251507925368		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9441251507925368 | validation: 1.5983671657191203]
	TIME [epoch: 4.17 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_20.pth
	Model improved!!!
EPOCH 21/500:
	Training over batches...
		[batch 4/4] avg loss: 1.587809510640394		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.587809510640394 | validation: 1.3371708817316255]
	TIME [epoch: 4.17 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_21.pth
	Model improved!!!
EPOCH 22/500:
	Training over batches...
		[batch 4/4] avg loss: 1.384871347060077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.384871347060077 | validation: 1.1615090420116465]
	TIME [epoch: 4.18 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_22.pth
	Model improved!!!
EPOCH 23/500:
	Training over batches...
		[batch 4/4] avg loss: 1.1873660319375638		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1873660319375638 | validation: 1.0038820364416376]
	TIME [epoch: 4.21 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_23.pth
	Model improved!!!
EPOCH 24/500:
	Training over batches...
		[batch 4/4] avg loss: 1.0439969663392412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0439969663392412 | validation: 0.8840114027741299]
	TIME [epoch: 4.2 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_24.pth
	Model improved!!!
EPOCH 25/500:
	Training over batches...
		[batch 4/4] avg loss: 0.9331832804023756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9331832804023756 | validation: 0.8188350909897504]
	TIME [epoch: 4.18 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_25.pth
	Model improved!!!
EPOCH 26/500:
	Training over batches...
		[batch 4/4] avg loss: 0.8576938901315032		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8576938901315032 | validation: 0.7823059124245455]
	TIME [epoch: 4.17 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_26.pth
	Model improved!!!
EPOCH 27/500:
	Training over batches...
		[batch 4/4] avg loss: 0.8193911268498244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8193911268498244 | validation: 0.7444724256071045]
	TIME [epoch: 4.17 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_27.pth
	Model improved!!!
EPOCH 28/500:
	Training over batches...
		[batch 4/4] avg loss: 0.7921737518571242		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7921737518571242 | validation: 0.7142287808432677]
	TIME [epoch: 4.17 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_28.pth
	Model improved!!!
EPOCH 29/500:
	Training over batches...
		[batch 4/4] avg loss: 0.7544796496320998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7544796496320998 | validation: 0.6800159708018533]
	TIME [epoch: 4.2 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_29.pth
	Model improved!!!
EPOCH 30/500:
	Training over batches...
		[batch 4/4] avg loss: 0.7232124832160552		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7232124832160552 | validation: 0.6476128457119339]
	TIME [epoch: 4.19 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_30.pth
	Model improved!!!
EPOCH 31/500:
	Training over batches...
		[batch 4/4] avg loss: 0.6889424694123469		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6889424694123469 | validation: 0.6138965545484028]
	TIME [epoch: 4.21 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_31.pth
	Model improved!!!
EPOCH 32/500:
	Training over batches...
		[batch 4/4] avg loss: 0.6626044391129546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6626044391129546 | validation: 0.5841493443533458]
	TIME [epoch: 4.24 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_32.pth
	Model improved!!!
EPOCH 33/500:
	Training over batches...
		[batch 4/4] avg loss: 0.6253231359795933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6253231359795933 | validation: 0.5546477826512829]
	TIME [epoch: 4.2 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_33.pth
	Model improved!!!
EPOCH 34/500:
	Training over batches...
		[batch 4/4] avg loss: 0.5979313696796029		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5979313696796029 | validation: 0.5296663126031971]
	TIME [epoch: 4.18 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_34.pth
	Model improved!!!
EPOCH 35/500:
	Training over batches...
		[batch 4/4] avg loss: 0.5668499431853644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5668499431853644 | validation: 0.4915729700931591]
	TIME [epoch: 4.18 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_35.pth
	Model improved!!!
EPOCH 36/500:
	Training over batches...
		[batch 4/4] avg loss: 0.5382875133735502		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5382875133735502 | validation: 0.4651146974600937]
	TIME [epoch: 4.2 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_36.pth
	Model improved!!!
EPOCH 37/500:
	Training over batches...
		[batch 4/4] avg loss: 0.5074018836394107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5074018836394107 | validation: 0.44344610337723933]
	TIME [epoch: 4.19 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_37.pth
	Model improved!!!
EPOCH 38/500:
	Training over batches...
		[batch 4/4] avg loss: 0.4826478345204176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4826478345204176 | validation: 0.4192083003472356]
	TIME [epoch: 4.18 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_38.pth
	Model improved!!!
EPOCH 39/500:
	Training over batches...
		[batch 4/4] avg loss: 0.4558411356019813		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4558411356019813 | validation: 0.3878603001886233]
	TIME [epoch: 4.19 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_39.pth
	Model improved!!!
EPOCH 40/500:
	Training over batches...
		[batch 4/4] avg loss: 0.4282978785146173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4282978785146173 | validation: 0.36224178438863935]
	TIME [epoch: 4.21 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_40.pth
	Model improved!!!
EPOCH 41/500:
	Training over batches...
		[batch 4/4] avg loss: 0.4069896398764821		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4069896398764821 | validation: 0.3427977277820814]
	TIME [epoch: 4.24 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_41.pth
	Model improved!!!
EPOCH 42/500:
	Training over batches...
		[batch 4/4] avg loss: 0.3839705648542918		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3839705648542918 | validation: 0.3196205506160714]
	TIME [epoch: 4.2 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_42.pth
	Model improved!!!
EPOCH 43/500:
	Training over batches...
		[batch 4/4] avg loss: 0.35899092155397283		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35899092155397283 | validation: 0.29841672922358]
	TIME [epoch: 4.2 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_43.pth
	Model improved!!!
EPOCH 44/500:
	Training over batches...
		[batch 4/4] avg loss: 0.3352803998914797		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3352803998914797 | validation: 0.2857499821391631]
	TIME [epoch: 4.2 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_44.pth
	Model improved!!!
EPOCH 45/500:
	Training over batches...
		[batch 4/4] avg loss: 0.3219842174165212		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3219842174165212 | validation: 0.26639645295670983]
	TIME [epoch: 4.19 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_45.pth
	Model improved!!!
EPOCH 46/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2986311370225636		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2986311370225636 | validation: 0.2515182786085049]
	TIME [epoch: 4.19 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_46.pth
	Model improved!!!
EPOCH 47/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2935207075361626		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2935207075361626 | validation: 0.23689121116954445]
	TIME [epoch: 4.19 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_47.pth
	Model improved!!!
EPOCH 48/500:
	Training over batches...
		[batch 4/4] avg loss: 0.27391933170460736		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27391933170460736 | validation: 0.2244474798474952]
	TIME [epoch: 4.18 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_48.pth
	Model improved!!!
EPOCH 49/500:
	Training over batches...
		[batch 4/4] avg loss: 0.26339249175737195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26339249175737195 | validation: 0.21558879636026895]
	TIME [epoch: 4.17 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_49.pth
	Model improved!!!
EPOCH 50/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2473198548164955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2473198548164955 | validation: 0.20541608734049915]
	TIME [epoch: 4.22 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_50.pth
	Model improved!!!
EPOCH 51/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2394967377592193		[learning rate: 0.0098855]
	Learning Rate: 0.00988553
	LOSS [training: 0.2394967377592193 | validation: 0.19474344798094784]
	TIME [epoch: 98.7 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_51.pth
	Model improved!!!
EPOCH 52/500:
	Training over batches...
		[batch 4/4] avg loss: 0.22909168571790117		[learning rate: 0.0097349]
	Learning Rate: 0.00973494
	LOSS [training: 0.22909168571790117 | validation: 0.18833401368565722]
	TIME [epoch: 8.24 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_52.pth
	Model improved!!!
EPOCH 53/500:
	Training over batches...
		[batch 4/4] avg loss: 0.22019321092894167		[learning rate: 0.0095866]
	Learning Rate: 0.00958665
	LOSS [training: 0.22019321092894167 | validation: 0.18314281618445152]
	TIME [epoch: 8.21 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_53.pth
	Model improved!!!
EPOCH 54/500:
	Training over batches...
		[batch 4/4] avg loss: 0.214956740420638		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.214956740420638 | validation: 0.17795197012505293]
	TIME [epoch: 8.22 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_54.pth
	Model improved!!!
EPOCH 55/500:
	Training over batches...
		[batch 4/4] avg loss: 0.20548173185575663		[learning rate: 0.0092968]
	Learning Rate: 0.0092968
	LOSS [training: 0.20548173185575663 | validation: 0.17579207539858405]
	TIME [epoch: 8.16 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_55.pth
	Model improved!!!
EPOCH 56/500:
	Training over batches...
		[batch 4/4] avg loss: 0.20631038909777988		[learning rate: 0.0091552]
	Learning Rate: 0.00915517
	LOSS [training: 0.20631038909777988 | validation: 0.16745802137342714]
	TIME [epoch: 8.17 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_56.pth
	Model improved!!!
EPOCH 57/500:
	Training over batches...
		[batch 4/4] avg loss: 0.19547588829930546		[learning rate: 0.0090157]
	Learning Rate: 0.00901571
	LOSS [training: 0.19547588829930546 | validation: 0.17067294671559707]
	TIME [epoch: 8.17 sec]
EPOCH 58/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1948878235311836		[learning rate: 0.0088784]
	Learning Rate: 0.00887837
	LOSS [training: 0.1948878235311836 | validation: 0.17066274582159863]
	TIME [epoch: 8.16 sec]
EPOCH 59/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1931878590210829		[learning rate: 0.0087431]
	Learning Rate: 0.00874312
	LOSS [training: 0.1931878590210829 | validation: 0.1630700914508662]
	TIME [epoch: 8.18 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_59.pth
	Model improved!!!
EPOCH 60/500:
	Training over batches...
		[batch 4/4] avg loss: 0.19224713923681713		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 0.19224713923681713 | validation: 0.16776953678515602]
	TIME [epoch: 8.21 sec]
EPOCH 61/500:
	Training over batches...
		[batch 4/4] avg loss: 0.19003307739055486		[learning rate: 0.0084788]
	Learning Rate: 0.00847878
	LOSS [training: 0.19003307739055486 | validation: 0.16634364368416804]
	TIME [epoch: 8.18 sec]
EPOCH 62/500:
	Training over batches...
		[batch 4/4] avg loss: 0.18783436313176521		[learning rate: 0.0083496]
	Learning Rate: 0.00834962
	LOSS [training: 0.18783436313176521 | validation: 0.16668496311314346]
	TIME [epoch: 8.17 sec]
EPOCH 63/500:
	Training over batches...
		[batch 4/4] avg loss: 0.18940106225158157		[learning rate: 0.0082224]
	Learning Rate: 0.00822243
	LOSS [training: 0.18940106225158157 | validation: 0.1648029910982982]
	TIME [epoch: 8.18 sec]
EPOCH 64/500:
	Training over batches...
		[batch 4/4] avg loss: 0.19048106841407772		[learning rate: 0.0080972]
	Learning Rate: 0.00809717
	LOSS [training: 0.19048106841407772 | validation: 0.16428845748546814]
	TIME [epoch: 8.18 sec]
EPOCH 65/500:
	Training over batches...
		[batch 4/4] avg loss: 0.18770409179199934		[learning rate: 0.0079738]
	Learning Rate: 0.00797382
	LOSS [training: 0.18770409179199934 | validation: 0.16050958060837384]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_65.pth
	Model improved!!!
EPOCH 66/500:
	Training over batches...
		[batch 4/4] avg loss: 0.18549342388934797		[learning rate: 0.0078524]
	Learning Rate: 0.00785236
	LOSS [training: 0.18549342388934797 | validation: 0.16416017603917749]
	TIME [epoch: 8.23 sec]
EPOCH 67/500:
	Training over batches...
		[batch 4/4] avg loss: 0.18214041609475456		[learning rate: 0.0077327]
	Learning Rate: 0.00773274
	LOSS [training: 0.18214041609475456 | validation: 0.16222260749047618]
	TIME [epoch: 8.17 sec]
EPOCH 68/500:
	Training over batches...
		[batch 4/4] avg loss: 0.18360596349394642		[learning rate: 0.0076149]
	Learning Rate: 0.00761494
	LOSS [training: 0.18360596349394642 | validation: 0.15707487625103284]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_68.pth
	Model improved!!!
EPOCH 69/500:
	Training over batches...
		[batch 4/4] avg loss: 0.18436168491032978		[learning rate: 0.0074989]
	Learning Rate: 0.00749894
	LOSS [training: 0.18436168491032978 | validation: 0.1584509514715216]
	TIME [epoch: 8.18 sec]
EPOCH 70/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1820365862019987		[learning rate: 0.0073847]
	Learning Rate: 0.00738471
	LOSS [training: 0.1820365862019987 | validation: 0.15983458174967874]
	TIME [epoch: 8.17 sec]
EPOCH 71/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1815286728475337		[learning rate: 0.0072722]
	Learning Rate: 0.00727221
	LOSS [training: 0.1815286728475337 | validation: 0.1558402699431776]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_71.pth
	Model improved!!!
EPOCH 72/500:
	Training over batches...
		[batch 4/4] avg loss: 0.18479068203446744		[learning rate: 0.0071614]
	Learning Rate: 0.00716143
	LOSS [training: 0.18479068203446744 | validation: 0.16062057567437887]
	TIME [epoch: 8.21 sec]
EPOCH 73/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1804223875638652		[learning rate: 0.0070523]
	Learning Rate: 0.00705234
	LOSS [training: 0.1804223875638652 | validation: 0.15802312307269611]
	TIME [epoch: 8.17 sec]
EPOCH 74/500:
	Training over batches...
		[batch 4/4] avg loss: 0.17962596484682974		[learning rate: 0.0069449]
	Learning Rate: 0.00694491
	LOSS [training: 0.17962596484682974 | validation: 0.15936930001253735]
	TIME [epoch: 8.17 sec]
EPOCH 75/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1822973890759149		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.1822973890759149 | validation: 0.15667917742935605]
	TIME [epoch: 8.17 sec]
EPOCH 76/500:
	Training over batches...
		[batch 4/4] avg loss: 0.18315840424760615		[learning rate: 0.0067349]
	Learning Rate: 0.00673493
	LOSS [training: 0.18315840424760615 | validation: 0.16008780230566794]
	TIME [epoch: 8.17 sec]
EPOCH 77/500:
	Training over batches...
		[batch 4/4] avg loss: 0.18004562602922933		[learning rate: 0.0066323]
	Learning Rate: 0.00663234
	LOSS [training: 0.18004562602922933 | validation: 0.16186813235915332]
	TIME [epoch: 8.21 sec]
EPOCH 78/500:
	Training over batches...
		[batch 4/4] avg loss: 0.17765232358928307		[learning rate: 0.0065313]
	Learning Rate: 0.00653131
	LOSS [training: 0.17765232358928307 | validation: 0.15280234795941064]
	TIME [epoch: 8.21 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_78.pth
	Model improved!!!
EPOCH 79/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1808647962737147		[learning rate: 0.0064318]
	Learning Rate: 0.00643181
	LOSS [training: 0.1808647962737147 | validation: 0.15353685416171797]
	TIME [epoch: 8.21 sec]
EPOCH 80/500:
	Training over batches...
		[batch 4/4] avg loss: 0.17997025951112947		[learning rate: 0.0063338]
	Learning Rate: 0.00633383
	LOSS [training: 0.17997025951112947 | validation: 0.1556567741157368]
	TIME [epoch: 8.2 sec]
EPOCH 81/500:
	Training over batches...
		[batch 4/4] avg loss: 0.17867465622568482		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.17867465622568482 | validation: 0.15254013458664148]
	TIME [epoch: 8.18 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_81.pth
	Model improved!!!
EPOCH 82/500:
	Training over batches...
		[batch 4/4] avg loss: 0.17567948723061552		[learning rate: 0.0061423]
	Learning Rate: 0.00614233
	LOSS [training: 0.17567948723061552 | validation: 0.1546174081588262]
	TIME [epoch: 8.21 sec]
EPOCH 83/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1808015826369454		[learning rate: 0.0060488]
	Learning Rate: 0.00604876
	LOSS [training: 0.1808015826369454 | validation: 0.1540773636445825]
	TIME [epoch: 8.22 sec]
EPOCH 84/500:
	Training over batches...
		[batch 4/4] avg loss: 0.17629628615256462		[learning rate: 0.0059566]
	Learning Rate: 0.00595662
	LOSS [training: 0.17629628615256462 | validation: 0.1540109245115936]
	TIME [epoch: 8.17 sec]
EPOCH 85/500:
	Training over batches...
		[batch 4/4] avg loss: 0.17543093175027916		[learning rate: 0.0058659]
	Learning Rate: 0.00586588
	LOSS [training: 0.17543093175027916 | validation: 0.14951692108798775]
	TIME [epoch: 8.2 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_85.pth
	Model improved!!!
EPOCH 86/500:
	Training over batches...
		[batch 4/4] avg loss: 0.17676293013405248		[learning rate: 0.0057765]
	Learning Rate: 0.00577653
	LOSS [training: 0.17676293013405248 | validation: 0.1527201482365586]
	TIME [epoch: 8.2 sec]
EPOCH 87/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1755553483277903		[learning rate: 0.0056885]
	Learning Rate: 0.00568853
	LOSS [training: 0.1755553483277903 | validation: 0.14837984865791004]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_87.pth
	Model improved!!!
EPOCH 88/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1731987576126311		[learning rate: 0.0056019]
	Learning Rate: 0.00560187
	LOSS [training: 0.1731987576126311 | validation: 0.15158802683867512]
	TIME [epoch: 8.21 sec]
EPOCH 89/500:
	Training over batches...
		[batch 4/4] avg loss: 0.17288264568080086		[learning rate: 0.0055165]
	Learning Rate: 0.00551654
	LOSS [training: 0.17288264568080086 | validation: 0.14896816009700187]
	TIME [epoch: 8.21 sec]
EPOCH 90/500:
	Training over batches...
		[batch 4/4] avg loss: 0.17304337650107102		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.17304337650107102 | validation: 0.15200769595923963]
	TIME [epoch: 8.18 sec]
EPOCH 91/500:
	Training over batches...
		[batch 4/4] avg loss: 0.17623749657066834		[learning rate: 0.0053497]
	Learning Rate: 0.00534975
	LOSS [training: 0.17623749657066834 | validation: 0.15303695463957465]
	TIME [epoch: 8.17 sec]
EPOCH 92/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1728585168130018		[learning rate: 0.0052683]
	Learning Rate: 0.00526825
	LOSS [training: 0.1728585168130018 | validation: 0.14970772603486165]
	TIME [epoch: 8.17 sec]
EPOCH 93/500:
	Training over batches...
		[batch 4/4] avg loss: 0.17262337117839965		[learning rate: 0.005188]
	Learning Rate: 0.005188
	LOSS [training: 0.17262337117839965 | validation: 0.14881870168620936]
	TIME [epoch: 8.16 sec]
EPOCH 94/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1724033478076752		[learning rate: 0.005109]
	Learning Rate: 0.00510897
	LOSS [training: 0.1724033478076752 | validation: 0.14992718564792473]
	TIME [epoch: 8.19 sec]
EPOCH 95/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1736877158005506		[learning rate: 0.0050311]
	Learning Rate: 0.00503114
	LOSS [training: 0.1736877158005506 | validation: 0.1471610492130851]
	TIME [epoch: 8.18 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_95.pth
	Model improved!!!
EPOCH 96/500:
	Training over batches...
		[batch 4/4] avg loss: 0.16990608137396482		[learning rate: 0.0049545]
	Learning Rate: 0.0049545
	LOSS [training: 0.16990608137396482 | validation: 0.14745307909966426]
	TIME [epoch: 8.16 sec]
EPOCH 97/500:
	Training over batches...
		[batch 4/4] avg loss: 0.17190567213285765		[learning rate: 0.004879]
	Learning Rate: 0.00487903
	LOSS [training: 0.17190567213285765 | validation: 0.1478119232940283]
	TIME [epoch: 8.16 sec]
EPOCH 98/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1704142692524954		[learning rate: 0.0048047]
	Learning Rate: 0.0048047
	LOSS [training: 0.1704142692524954 | validation: 0.1494529998624225]
	TIME [epoch: 8.16 sec]
EPOCH 99/500:
	Training over batches...
		[batch 4/4] avg loss: 0.17101911425977348		[learning rate: 0.0047315]
	Learning Rate: 0.00473151
	LOSS [training: 0.17101911425977348 | validation: 0.14822909517616653]
	TIME [epoch: 8.16 sec]
EPOCH 100/500:
	Training over batches...
		[batch 4/4] avg loss: 0.17067157726399884		[learning rate: 0.0046594]
	Learning Rate: 0.00465944
	LOSS [training: 0.17067157726399884 | validation: 0.14543157957136327]
	TIME [epoch: 8.21 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_100.pth
	Model improved!!!
EPOCH 101/500:
	Training over batches...
		[batch 4/4] avg loss: 0.16993077549939084		[learning rate: 0.0045885]
	Learning Rate: 0.00458846
	LOSS [training: 0.16993077549939084 | validation: 0.14450947156209437]
	TIME [epoch: 110 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_101.pth
	Model improved!!!
EPOCH 102/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1709246672447401		[learning rate: 0.0045186]
	Learning Rate: 0.00451856
	LOSS [training: 0.1709246672447401 | validation: 0.1462037448187008]
	TIME [epoch: 18.7 sec]
EPOCH 103/500:
	Training over batches...
		[batch 4/4] avg loss: 0.17114714773152137		[learning rate: 0.0044497]
	Learning Rate: 0.00444973
	LOSS [training: 0.17114714773152137 | validation: 0.14673319980963795]
	TIME [epoch: 18.6 sec]
EPOCH 104/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1709085831016176		[learning rate: 0.0043819]
	Learning Rate: 0.00438194
	LOSS [training: 0.1709085831016176 | validation: 0.14866848877185945]
	TIME [epoch: 18.6 sec]
EPOCH 105/500:
	Training over batches...
		[batch 4/4] avg loss: 0.16882733355852947		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 0.16882733355852947 | validation: 0.14617023062630186]
	TIME [epoch: 18.6 sec]
EPOCH 106/500:
	Training over batches...
		[batch 4/4] avg loss: 0.16723431836370417		[learning rate: 0.0042495]
	Learning Rate: 0.00424946
	LOSS [training: 0.16723431836370417 | validation: 0.1481507085621923]
	TIME [epoch: 18.6 sec]
EPOCH 107/500:
	Training over batches...
		[batch 4/4] avg loss: 0.16744528659471858		[learning rate: 0.0041847]
	Learning Rate: 0.00418472
	LOSS [training: 0.16744528659471858 | validation: 0.14285388306143862]
	TIME [epoch: 18.6 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_107.pth
	Model improved!!!
EPOCH 108/500:
	Training over batches...
		[batch 4/4] avg loss: 0.16849810077265429		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.16849810077265429 | validation: 0.14161892088122732]
	TIME [epoch: 18.6 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_108.pth
	Model improved!!!
EPOCH 109/500:
	Training over batches...
		[batch 4/4] avg loss: 0.16621042254054053		[learning rate: 0.0040582]
	Learning Rate: 0.0040582
	LOSS [training: 0.16621042254054053 | validation: 0.14416806372801816]
	TIME [epoch: 18.6 sec]
EPOCH 110/500:
	Training over batches...
		[batch 4/4] avg loss: 0.16618615280849658		[learning rate: 0.0039964]
	Learning Rate: 0.00399638
	LOSS [training: 0.16618615280849658 | validation: 0.14229668174459723]
	TIME [epoch: 18.6 sec]
EPOCH 111/500:
	Training over batches...
		[batch 4/4] avg loss: 0.16383136858752362		[learning rate: 0.0039355]
	Learning Rate: 0.0039355
	LOSS [training: 0.16383136858752362 | validation: 0.1392061481052005]
	TIME [epoch: 18.6 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_111.pth
	Model improved!!!
EPOCH 112/500:
	Training over batches...
		[batch 4/4] avg loss: 0.16467620098263586		[learning rate: 0.0038755]
	Learning Rate: 0.00387555
	LOSS [training: 0.16467620098263586 | validation: 0.13797547991053394]
	TIME [epoch: 18.6 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_112.pth
	Model improved!!!
EPOCH 113/500:
	Training over batches...
		[batch 4/4] avg loss: 0.16122453375814377		[learning rate: 0.0038165]
	Learning Rate: 0.00381651
	LOSS [training: 0.16122453375814377 | validation: 0.13526128973342846]
	TIME [epoch: 18.6 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_113.pth
	Model improved!!!
EPOCH 114/500:
	Training over batches...
		[batch 4/4] avg loss: 0.16162349772231657		[learning rate: 0.0037584]
	Learning Rate: 0.00375837
	LOSS [training: 0.16162349772231657 | validation: 0.1391547548658885]
	TIME [epoch: 18.6 sec]
EPOCH 115/500:
	Training over batches...
		[batch 4/4] avg loss: 0.16330351502251664		[learning rate: 0.0037011]
	Learning Rate: 0.00370112
	LOSS [training: 0.16330351502251664 | validation: 0.13831521804281766]
	TIME [epoch: 18.6 sec]
EPOCH 116/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15900852762246556		[learning rate: 0.0036447]
	Learning Rate: 0.00364474
	LOSS [training: 0.15900852762246556 | validation: 0.1429692113268028]
	TIME [epoch: 18.5 sec]
EPOCH 117/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1595762070554868		[learning rate: 0.0035892]
	Learning Rate: 0.00358922
	LOSS [training: 0.1595762070554868 | validation: 0.1374228838745175]
	TIME [epoch: 18.6 sec]
EPOCH 118/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15959591856040703		[learning rate: 0.0035345]
	Learning Rate: 0.00353454
	LOSS [training: 0.15959591856040703 | validation: 0.13806022104503685]
	TIME [epoch: 18.6 sec]
EPOCH 119/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15780388675762153		[learning rate: 0.0034807]
	Learning Rate: 0.0034807
	LOSS [training: 0.15780388675762153 | validation: 0.13412925085037974]
	TIME [epoch: 18.6 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_119.pth
	Model improved!!!
EPOCH 120/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15541931416426796		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 0.15541931416426796 | validation: 0.13373780586596792]
	TIME [epoch: 18.6 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_120.pth
	Model improved!!!
EPOCH 121/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1564644478663671		[learning rate: 0.0033755]
	Learning Rate: 0.00337546
	LOSS [training: 0.1564644478663671 | validation: 0.1317517518756891]
	TIME [epoch: 18.5 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_121.pth
	Model improved!!!
EPOCH 122/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15505459319323944		[learning rate: 0.003324]
	Learning Rate: 0.00332404
	LOSS [training: 0.15505459319323944 | validation: 0.1339206053775585]
	TIME [epoch: 18.6 sec]
EPOCH 123/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15545490857599653		[learning rate: 0.0032734]
	Learning Rate: 0.00327341
	LOSS [training: 0.15545490857599653 | validation: 0.135823328244156]
	TIME [epoch: 18.6 sec]
EPOCH 124/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1534217622011818		[learning rate: 0.0032235]
	Learning Rate: 0.00322354
	LOSS [training: 0.1534217622011818 | validation: 0.13058211592544355]
	TIME [epoch: 18.5 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_124.pth
	Model improved!!!
EPOCH 125/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15108780154596363		[learning rate: 0.0031744]
	Learning Rate: 0.00317444
	LOSS [training: 0.15108780154596363 | validation: 0.13108289939568285]
	TIME [epoch: 18.6 sec]
EPOCH 126/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15125981535176486		[learning rate: 0.0031261]
	Learning Rate: 0.00312608
	LOSS [training: 0.15125981535176486 | validation: 0.12871302102644203]
	TIME [epoch: 18.6 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_126.pth
	Model improved!!!
EPOCH 127/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15104727460567077		[learning rate: 0.0030785]
	Learning Rate: 0.00307846
	LOSS [training: 0.15104727460567077 | validation: 0.12662315715614064]
	TIME [epoch: 18.6 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_127.pth
	Model improved!!!
EPOCH 128/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15021001036766418		[learning rate: 0.0030316]
	Learning Rate: 0.00303156
	LOSS [training: 0.15021001036766418 | validation: 0.12702168678153158]
	TIME [epoch: 18.7 sec]
EPOCH 129/500:
	Training over batches...
		[batch 4/4] avg loss: 0.148684505922831		[learning rate: 0.0029854]
	Learning Rate: 0.00298538
	LOSS [training: 0.148684505922831 | validation: 0.1268262698838121]
	TIME [epoch: 18.6 sec]
EPOCH 130/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1479691751807145		[learning rate: 0.0029399]
	Learning Rate: 0.0029399
	LOSS [training: 0.1479691751807145 | validation: 0.12120752684946803]
	TIME [epoch: 18.6 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_130.pth
	Model improved!!!
EPOCH 131/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14751907495510092		[learning rate: 0.0028951]
	Learning Rate: 0.00289512
	LOSS [training: 0.14751907495510092 | validation: 0.12133313700986575]
	TIME [epoch: 18.6 sec]
EPOCH 132/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14305422539088786		[learning rate: 0.002851]
	Learning Rate: 0.00285102
	LOSS [training: 0.14305422539088786 | validation: 0.12270174378510271]
	TIME [epoch: 18.6 sec]
EPOCH 133/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1436859326200272		[learning rate: 0.0028076]
	Learning Rate: 0.00280759
	LOSS [training: 0.1436859326200272 | validation: 0.12346905823878163]
	TIME [epoch: 18.6 sec]
EPOCH 134/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14339479505362296		[learning rate: 0.0027648]
	Learning Rate: 0.00276482
	LOSS [training: 0.14339479505362296 | validation: 0.12499846739850819]
	TIME [epoch: 18.6 sec]
EPOCH 135/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14147929987904806		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.14147929987904806 | validation: 0.11915739423113347]
	TIME [epoch: 18.6 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_135.pth
	Model improved!!!
EPOCH 136/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14123154342667915		[learning rate: 0.0026812]
	Learning Rate: 0.00268123
	LOSS [training: 0.14123154342667915 | validation: 0.1177526271129826]
	TIME [epoch: 18.6 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_136.pth
	Model improved!!!
EPOCH 137/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1400990300103353		[learning rate: 0.0026404]
	Learning Rate: 0.00264038
	LOSS [training: 0.1400990300103353 | validation: 0.11804564544654009]
	TIME [epoch: 18.6 sec]
EPOCH 138/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13833740029775163		[learning rate: 0.0026002]
	Learning Rate: 0.00260016
	LOSS [training: 0.13833740029775163 | validation: 0.11555992199532378]
	TIME [epoch: 18.6 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_138.pth
	Model improved!!!
EPOCH 139/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1397585323759026		[learning rate: 0.0025606]
	Learning Rate: 0.00256055
	LOSS [training: 0.1397585323759026 | validation: 0.1193378302473011]
	TIME [epoch: 18.6 sec]
EPOCH 140/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13588419024510634		[learning rate: 0.0025215]
	Learning Rate: 0.00252154
	LOSS [training: 0.13588419024510634 | validation: 0.11377687817180385]
	TIME [epoch: 18.6 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_140.pth
	Model improved!!!
EPOCH 141/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13807756145986916		[learning rate: 0.0024831]
	Learning Rate: 0.00248313
	LOSS [training: 0.13807756145986916 | validation: 0.11648750681716535]
	TIME [epoch: 18.6 sec]
EPOCH 142/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13597679368261995		[learning rate: 0.0024453]
	Learning Rate: 0.00244531
	LOSS [training: 0.13597679368261995 | validation: 0.11260527618140809]
	TIME [epoch: 18.5 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_142.pth
	Model improved!!!
EPOCH 143/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13385122191345428		[learning rate: 0.0024081]
	Learning Rate: 0.00240806
	LOSS [training: 0.13385122191345428 | validation: 0.11243853527377602]
	TIME [epoch: 18.6 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_143.pth
	Model improved!!!
EPOCH 144/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1330087503914943		[learning rate: 0.0023714]
	Learning Rate: 0.00237137
	LOSS [training: 0.1330087503914943 | validation: 0.11389402760809042]
	TIME [epoch: 18.6 sec]
EPOCH 145/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13266349349498607		[learning rate: 0.0023352]
	Learning Rate: 0.00233525
	LOSS [training: 0.13266349349498607 | validation: 0.11274102891317127]
	TIME [epoch: 18.5 sec]
EPOCH 146/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13012696814541638		[learning rate: 0.0022997]
	Learning Rate: 0.00229968
	LOSS [training: 0.13012696814541638 | validation: 0.10864312468473428]
	TIME [epoch: 18.6 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_146.pth
	Model improved!!!
EPOCH 147/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12965602996324588		[learning rate: 0.0022646]
	Learning Rate: 0.00226464
	LOSS [training: 0.12965602996324588 | validation: 0.10804018998400909]
	TIME [epoch: 18.5 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_147.pth
	Model improved!!!
EPOCH 148/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12940963491787377		[learning rate: 0.0022301]
	Learning Rate: 0.00223015
	LOSS [training: 0.12940963491787377 | validation: 0.10907962420948863]
	TIME [epoch: 18.6 sec]
EPOCH 149/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12798061630174248		[learning rate: 0.0021962]
	Learning Rate: 0.00219617
	LOSS [training: 0.12798061630174248 | validation: 0.10853134122691664]
	TIME [epoch: 18.6 sec]
EPOCH 150/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1277021951527216		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: 0.1277021951527216 | validation: 0.10948148467470316]
	TIME [epoch: 18.6 sec]
EPOCH 151/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12562481905138376		[learning rate: 0.0021298]
	Learning Rate: 0.00212977
	LOSS [training: 0.12562481905138376 | validation: 0.10842156423664087]
	TIME [epoch: 18.6 sec]
EPOCH 152/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12473500554514041		[learning rate: 0.0020973]
	Learning Rate: 0.00209733
	LOSS [training: 0.12473500554514041 | validation: 0.1066293871681942]
	TIME [epoch: 18.6 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_152.pth
	Model improved!!!
EPOCH 153/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12474079581656879		[learning rate: 0.0020654]
	Learning Rate: 0.00206538
	LOSS [training: 0.12474079581656879 | validation: 0.10473770110607028]
	TIME [epoch: 18.6 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_153.pth
	Model improved!!!
EPOCH 154/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12327352671318695		[learning rate: 0.0020339]
	Learning Rate: 0.00203392
	LOSS [training: 0.12327352671318695 | validation: 0.105002228220861]
	TIME [epoch: 18.6 sec]
EPOCH 155/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12227152856336646		[learning rate: 0.0020029]
	Learning Rate: 0.00200293
	LOSS [training: 0.12227152856336646 | validation: 0.1039515435337156]
	TIME [epoch: 18.6 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_155.pth
	Model improved!!!
EPOCH 156/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12204355895885802		[learning rate: 0.0019724]
	Learning Rate: 0.00197242
	LOSS [training: 0.12204355895885802 | validation: 0.10385474565836089]
	TIME [epoch: 18.7 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_156.pth
	Model improved!!!
EPOCH 157/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12103989055155812		[learning rate: 0.0019424]
	Learning Rate: 0.00194238
	LOSS [training: 0.12103989055155812 | validation: 0.1030468859330714]
	TIME [epoch: 18.6 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_157.pth
	Model improved!!!
EPOCH 158/500:
	Training over batches...
		[batch 4/4] avg loss: 0.11972764130652733		[learning rate: 0.0019128]
	Learning Rate: 0.00191279
	LOSS [training: 0.11972764130652733 | validation: 0.0986599375208101]
	TIME [epoch: 18.6 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_158.pth
	Model improved!!!
EPOCH 159/500:
	Training over batches...
		[batch 4/4] avg loss: 0.11958434966141235		[learning rate: 0.0018836]
	Learning Rate: 0.00188365
	LOSS [training: 0.11958434966141235 | validation: 0.10219393672336702]
	TIME [epoch: 18.6 sec]
EPOCH 160/500:
	Training over batches...
		[batch 4/4] avg loss: 0.11804448252783678		[learning rate: 0.001855]
	Learning Rate: 0.00185495
	LOSS [training: 0.11804448252783678 | validation: 0.10055818406874853]
	TIME [epoch: 18.6 sec]
EPOCH 161/500:
	Training over batches...
		[batch 4/4] avg loss: 0.11685995332643148		[learning rate: 0.0018267]
	Learning Rate: 0.0018267
	LOSS [training: 0.11685995332643148 | validation: 0.09938058026835754]
	TIME [epoch: 18.6 sec]
EPOCH 162/500:
	Training over batches...
		[batch 4/4] avg loss: 0.11616501312859782		[learning rate: 0.0017989]
	Learning Rate: 0.00179887
	LOSS [training: 0.11616501312859782 | validation: 0.0969632404225283]
	TIME [epoch: 18.6 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_162.pth
	Model improved!!!
EPOCH 163/500:
	Training over batches...
		[batch 4/4] avg loss: 0.11560323522238225		[learning rate: 0.0017715]
	Learning Rate: 0.00177147
	LOSS [training: 0.11560323522238225 | validation: 0.09563157514199293]
	TIME [epoch: 18.6 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_163.pth
	Model improved!!!
EPOCH 164/500:
	Training over batches...
		[batch 4/4] avg loss: 0.11459906323736288		[learning rate: 0.0017445]
	Learning Rate: 0.00174448
	LOSS [training: 0.11459906323736288 | validation: 0.1003274933720801]
	TIME [epoch: 18.6 sec]
EPOCH 165/500:
	Training over batches...
		[batch 4/4] avg loss: 0.11358759776987877		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: 0.11358759776987877 | validation: 0.09476333887000145]
	TIME [epoch: 18.6 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_165.pth
	Model improved!!!
EPOCH 166/500:
	Training over batches...
		[batch 4/4] avg loss: 0.11260366722549232		[learning rate: 0.0016917]
	Learning Rate: 0.00169174
	LOSS [training: 0.11260366722549232 | validation: 0.09625436297851933]
	TIME [epoch: 18.6 sec]
EPOCH 167/500:
	Training over batches...
		[batch 4/4] avg loss: 0.11355482502594258		[learning rate: 0.001666]
	Learning Rate: 0.00166597
	LOSS [training: 0.11355482502594258 | validation: 0.09715770895057146]
	TIME [epoch: 18.6 sec]
EPOCH 168/500:
	Training over batches...
		[batch 4/4] avg loss: 0.11056306766708274		[learning rate: 0.0016406]
	Learning Rate: 0.00164059
	LOSS [training: 0.11056306766708274 | validation: 0.09387381270876466]
	TIME [epoch: 18.6 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_168.pth
	Model improved!!!
EPOCH 169/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1098043962170767		[learning rate: 0.0016156]
	Learning Rate: 0.0016156
	LOSS [training: 0.1098043962170767 | validation: 0.09065302289285589]
	TIME [epoch: 18.6 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_169.pth
	Model improved!!!
EPOCH 170/500:
	Training over batches...
		[batch 4/4] avg loss: 0.11032586974028853		[learning rate: 0.001591]
	Learning Rate: 0.00159099
	LOSS [training: 0.11032586974028853 | validation: 0.09377667043307757]
	TIME [epoch: 18.6 sec]
EPOCH 171/500:
	Training over batches...
		[batch 4/4] avg loss: 0.10904664627763103		[learning rate: 0.0015668]
	Learning Rate: 0.00156675
	LOSS [training: 0.10904664627763103 | validation: 0.09175075224496088]
	TIME [epoch: 18.4 sec]
EPOCH 172/500:
	Training over batches...
		[batch 4/4] avg loss: 0.10798100986708879		[learning rate: 0.0015429]
	Learning Rate: 0.00154288
	LOSS [training: 0.10798100986708879 | validation: 0.09037207058823271]
	TIME [epoch: 18.4 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_172.pth
	Model improved!!!
EPOCH 173/500:
	Training over batches...
		[batch 4/4] avg loss: 0.10863652983479732		[learning rate: 0.0015194]
	Learning Rate: 0.00151938
	LOSS [training: 0.10863652983479732 | validation: 0.09084731274259526]
	TIME [epoch: 18.4 sec]
EPOCH 174/500:
	Training over batches...
		[batch 4/4] avg loss: 0.10750065009497059		[learning rate: 0.0014962]
	Learning Rate: 0.00149624
	LOSS [training: 0.10750065009497059 | validation: 0.08963713253503636]
	TIME [epoch: 18.4 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_174.pth
	Model improved!!!
EPOCH 175/500:
	Training over batches...
		[batch 4/4] avg loss: 0.10658430666266926		[learning rate: 0.0014734]
	Learning Rate: 0.00147344
	LOSS [training: 0.10658430666266926 | validation: 0.0885993492013693]
	TIME [epoch: 18.4 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_175.pth
	Model improved!!!
EPOCH 176/500:
	Training over batches...
		[batch 4/4] avg loss: 0.10526036706842155		[learning rate: 0.001451]
	Learning Rate: 0.001451
	LOSS [training: 0.10526036706842155 | validation: 0.08724871029397155]
	TIME [epoch: 18.4 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_176.pth
	Model improved!!!
EPOCH 177/500:
	Training over batches...
		[batch 4/4] avg loss: 0.10444966989747223		[learning rate: 0.0014289]
	Learning Rate: 0.00142889
	LOSS [training: 0.10444966989747223 | validation: 0.08856994218955996]
	TIME [epoch: 18.4 sec]
EPOCH 178/500:
	Training over batches...
		[batch 4/4] avg loss: 0.10500202494870695		[learning rate: 0.0014071]
	Learning Rate: 0.00140713
	LOSS [training: 0.10500202494870695 | validation: 0.08955500559297923]
	TIME [epoch: 18.4 sec]
EPOCH 179/500:
	Training over batches...
		[batch 4/4] avg loss: 0.10296667462671334		[learning rate: 0.0013857]
	Learning Rate: 0.00138569
	LOSS [training: 0.10296667462671334 | validation: 0.09011634668189493]
	TIME [epoch: 18.4 sec]
EPOCH 180/500:
	Training over batches...
		[batch 4/4] avg loss: 0.10278857754720402		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: 0.10278857754720402 | validation: 0.08691049881463284]
	TIME [epoch: 18.4 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_180.pth
	Model improved!!!
EPOCH 181/500:
	Training over batches...
		[batch 4/4] avg loss: 0.10230447854987602		[learning rate: 0.0013438]
	Learning Rate: 0.0013438
	LOSS [training: 0.10230447854987602 | validation: 0.08739713674778227]
	TIME [epoch: 18.5 sec]
EPOCH 182/500:
	Training over batches...
		[batch 4/4] avg loss: 0.10074309405968576		[learning rate: 0.0013233]
	Learning Rate: 0.00132333
	LOSS [training: 0.10074309405968576 | validation: 0.0878156957691354]
	TIME [epoch: 18.4 sec]
EPOCH 183/500:
	Training over batches...
		[batch 4/4] avg loss: 0.09991108318779435		[learning rate: 0.0013032]
	Learning Rate: 0.00130317
	LOSS [training: 0.09991108318779435 | validation: 0.08758600657509875]
	TIME [epoch: 18.5 sec]
EPOCH 184/500:
	Training over batches...
		[batch 4/4] avg loss: 0.10030968681381873		[learning rate: 0.0012833]
	Learning Rate: 0.00128332
	LOSS [training: 0.10030968681381873 | validation: 0.08668897506136923]
	TIME [epoch: 18.5 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_184.pth
	Model improved!!!
EPOCH 185/500:
	Training over batches...
		[batch 4/4] avg loss: 0.10036770736250522		[learning rate: 0.0012638]
	Learning Rate: 0.00126377
	LOSS [training: 0.10036770736250522 | validation: 0.08422915675534995]
	TIME [epoch: 18.5 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_185.pth
	Model improved!!!
EPOCH 186/500:
	Training over batches...
		[batch 4/4] avg loss: 0.09907377131764651		[learning rate: 0.0012445]
	Learning Rate: 0.00124451
	LOSS [training: 0.09907377131764651 | validation: 0.08168790364254033]
	TIME [epoch: 18.5 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_186.pth
	Model improved!!!
EPOCH 187/500:
	Training over batches...
		[batch 4/4] avg loss: 0.09923913523183418		[learning rate: 0.0012256]
	Learning Rate: 0.00122556
	LOSS [training: 0.09923913523183418 | validation: 0.08311992221778836]
	TIME [epoch: 18.4 sec]
EPOCH 188/500:
	Training over batches...
		[batch 4/4] avg loss: 0.09930701641104406		[learning rate: 0.0012069]
	Learning Rate: 0.00120689
	LOSS [training: 0.09930701641104406 | validation: 0.08369035151218204]
	TIME [epoch: 18.5 sec]
EPOCH 189/500:
	Training over batches...
		[batch 4/4] avg loss: 0.09604783002077322		[learning rate: 0.0011885]
	Learning Rate: 0.0011885
	LOSS [training: 0.09604783002077322 | validation: 0.08380677709955629]
	TIME [epoch: 18.5 sec]
EPOCH 190/500:
	Training over batches...
		[batch 4/4] avg loss: 0.09700856988285478		[learning rate: 0.0011704]
	Learning Rate: 0.0011704
	LOSS [training: 0.09700856988285478 | validation: 0.08271043361183467]
	TIME [epoch: 18.4 sec]
EPOCH 191/500:
	Training over batches...
		[batch 4/4] avg loss: 0.09601317626967715		[learning rate: 0.0011526]
	Learning Rate: 0.00115257
	LOSS [training: 0.09601317626967715 | validation: 0.07970096247357378]
	TIME [epoch: 18.5 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_191.pth
	Model improved!!!
EPOCH 192/500:
	Training over batches...
		[batch 4/4] avg loss: 0.09588596191746752		[learning rate: 0.001135]
	Learning Rate: 0.00113501
	LOSS [training: 0.09588596191746752 | validation: 0.08027159413474212]
	TIME [epoch: 18.4 sec]
EPOCH 193/500:
	Training over batches...
		[batch 4/4] avg loss: 0.09563813011127247		[learning rate: 0.0011177]
	Learning Rate: 0.00111772
	LOSS [training: 0.09563813011127247 | validation: 0.07907462721881797]
	TIME [epoch: 18.4 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_193.pth
	Model improved!!!
EPOCH 194/500:
	Training over batches...
		[batch 4/4] avg loss: 0.09587228441868798		[learning rate: 0.0011007]
	Learning Rate: 0.00110069
	LOSS [training: 0.09587228441868798 | validation: 0.08112931260773787]
	TIME [epoch: 18.5 sec]
EPOCH 195/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0932424651131671		[learning rate: 0.0010839]
	Learning Rate: 0.00108393
	LOSS [training: 0.0932424651131671 | validation: 0.0791356162674712]
	TIME [epoch: 18.4 sec]
EPOCH 196/500:
	Training over batches...
		[batch 4/4] avg loss: 0.09348284145164415		[learning rate: 0.0010674]
	Learning Rate: 0.00106741
	LOSS [training: 0.09348284145164415 | validation: 0.07935442882627411]
	TIME [epoch: 18.4 sec]
EPOCH 197/500:
	Training over batches...
		[batch 4/4] avg loss: 0.09285514154319434		[learning rate: 0.0010512]
	Learning Rate: 0.00105115
	LOSS [training: 0.09285514154319434 | validation: 0.07780370894828302]
	TIME [epoch: 18.5 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_197.pth
	Model improved!!!
EPOCH 198/500:
	Training over batches...
		[batch 4/4] avg loss: 0.09188031570734981		[learning rate: 0.0010351]
	Learning Rate: 0.00103514
	LOSS [training: 0.09188031570734981 | validation: 0.07956703877222354]
	TIME [epoch: 18.4 sec]
EPOCH 199/500:
	Training over batches...
		[batch 4/4] avg loss: 0.09375198896716175		[learning rate: 0.0010194]
	Learning Rate: 0.00101937
	LOSS [training: 0.09375198896716175 | validation: 0.08007027805989957]
	TIME [epoch: 18.4 sec]
EPOCH 200/500:
	Training over batches...
		[batch 4/4] avg loss: 0.09046576949178005		[learning rate: 0.0010038]
	Learning Rate: 0.00100384
	LOSS [training: 0.09046576949178005 | validation: 0.07849650623220336]
	TIME [epoch: 18.4 sec]
EPOCH 201/500:
	Training over batches...
		[batch 4/4] avg loss: 0.09072216250814213		[learning rate: 0.00098855]
	Learning Rate: 0.000988553
	LOSS [training: 0.09072216250814213 | validation: 0.07791793341175847]
	TIME [epoch: 18.4 sec]
EPOCH 202/500:
	Training over batches...
		[batch 4/4] avg loss: 0.09005860746490062		[learning rate: 0.00097349]
	Learning Rate: 0.000973494
	LOSS [training: 0.09005860746490062 | validation: 0.0738346805661325]
	TIME [epoch: 18.5 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_202.pth
	Model improved!!!
EPOCH 203/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08824511841448598		[learning rate: 0.00095866]
	Learning Rate: 0.000958664
	LOSS [training: 0.08824511841448598 | validation: 0.07494407353975546]
	TIME [epoch: 18.4 sec]
EPOCH 204/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08883272821756454		[learning rate: 0.00094406]
	Learning Rate: 0.000944061
	LOSS [training: 0.08883272821756454 | validation: 0.07499655077351988]
	TIME [epoch: 18.3 sec]
EPOCH 205/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08879727741148394		[learning rate: 0.00092968]
	Learning Rate: 0.00092968
	LOSS [training: 0.08879727741148394 | validation: 0.07380618029709882]
	TIME [epoch: 18.4 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_205.pth
	Model improved!!!
EPOCH 206/500:
	Training over batches...
		[batch 4/4] avg loss: 0.088499761023322		[learning rate: 0.00091552]
	Learning Rate: 0.000915518
	LOSS [training: 0.088499761023322 | validation: 0.07254828399767058]
	TIME [epoch: 18.4 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_206.pth
	Model improved!!!
EPOCH 207/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08849344715269589		[learning rate: 0.00090157]
	Learning Rate: 0.000901571
	LOSS [training: 0.08849344715269589 | validation: 0.07639994096905248]
	TIME [epoch: 18.4 sec]
EPOCH 208/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0879242793481974		[learning rate: 0.00088784]
	Learning Rate: 0.000887837
	LOSS [training: 0.0879242793481974 | validation: 0.0727550803524137]
	TIME [epoch: 18.4 sec]
EPOCH 209/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08524543699437344		[learning rate: 0.00087431]
	Learning Rate: 0.000874312
	LOSS [training: 0.08524543699437344 | validation: 0.07220589305054344]
	TIME [epoch: 18.4 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_209.pth
	Model improved!!!
EPOCH 210/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08704274561146176		[learning rate: 0.00086099]
	Learning Rate: 0.000860994
	LOSS [training: 0.08704274561146176 | validation: 0.07249740643720472]
	TIME [epoch: 18.5 sec]
EPOCH 211/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08598067590892662		[learning rate: 0.00084788]
	Learning Rate: 0.000847878
	LOSS [training: 0.08598067590892662 | validation: 0.07179224311660534]
	TIME [epoch: 18.4 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_211.pth
	Model improved!!!
EPOCH 212/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08482106634830915		[learning rate: 0.00083496]
	Learning Rate: 0.000834962
	LOSS [training: 0.08482106634830915 | validation: 0.0722679204366389]
	TIME [epoch: 18.4 sec]
EPOCH 213/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08557330429564182		[learning rate: 0.00082224]
	Learning Rate: 0.000822243
	LOSS [training: 0.08557330429564182 | validation: 0.07104587760458571]
	TIME [epoch: 18.5 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_213.pth
	Model improved!!!
EPOCH 214/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08489879411430329		[learning rate: 0.00080972]
	Learning Rate: 0.000809717
	LOSS [training: 0.08489879411430329 | validation: 0.0711986167152282]
	TIME [epoch: 18.4 sec]
EPOCH 215/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08579680881199392		[learning rate: 0.00079738]
	Learning Rate: 0.000797382
	LOSS [training: 0.08579680881199392 | validation: 0.0728206569115817]
	TIME [epoch: 18.4 sec]
EPOCH 216/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08466288730237737		[learning rate: 0.00078524]
	Learning Rate: 0.000785236
	LOSS [training: 0.08466288730237737 | validation: 0.07399824980631006]
	TIME [epoch: 18.5 sec]
EPOCH 217/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08299027948823211		[learning rate: 0.00077327]
	Learning Rate: 0.000773274
	LOSS [training: 0.08299027948823211 | validation: 0.07102904477955303]
	TIME [epoch: 18.4 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_217.pth
	Model improved!!!
EPOCH 218/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0842285269070925		[learning rate: 0.00076149]
	Learning Rate: 0.000761494
	LOSS [training: 0.0842285269070925 | validation: 0.06886203738222134]
	TIME [epoch: 18.4 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_218.pth
	Model improved!!!
EPOCH 219/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08347001930225252		[learning rate: 0.00074989]
	Learning Rate: 0.000749894
	LOSS [training: 0.08347001930225252 | validation: 0.07148239680250042]
	TIME [epoch: 18.4 sec]
EPOCH 220/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08241729087806285		[learning rate: 0.00073847]
	Learning Rate: 0.000738471
	LOSS [training: 0.08241729087806285 | validation: 0.06876592418321037]
	TIME [epoch: 18.4 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_220.pth
	Model improved!!!
EPOCH 221/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0832349374285416		[learning rate: 0.00072722]
	Learning Rate: 0.000727221
	LOSS [training: 0.0832349374285416 | validation: 0.0672944419425514]
	TIME [epoch: 18.4 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_221.pth
	Model improved!!!
EPOCH 222/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0820214269171045		[learning rate: 0.00071614]
	Learning Rate: 0.000716143
	LOSS [training: 0.0820214269171045 | validation: 0.06808325268642604]
	TIME [epoch: 18.4 sec]
EPOCH 223/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08143731188592838		[learning rate: 0.00070523]
	Learning Rate: 0.000705234
	LOSS [training: 0.08143731188592838 | validation: 0.06767752286743443]
	TIME [epoch: 18.3 sec]
EPOCH 224/500:
	Training over batches...
		[batch 4/4] avg loss: 0.080995632725164		[learning rate: 0.00069449]
	Learning Rate: 0.000694491
	LOSS [training: 0.080995632725164 | validation: 0.07009671705181943]
	TIME [epoch: 18.4 sec]
EPOCH 225/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08052107239935108		[learning rate: 0.00068391]
	Learning Rate: 0.000683912
	LOSS [training: 0.08052107239935108 | validation: 0.07145627168403332]
	TIME [epoch: 18.4 sec]
EPOCH 226/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08021714798770474		[learning rate: 0.00067349]
	Learning Rate: 0.000673493
	LOSS [training: 0.08021714798770474 | validation: 0.06992611011296065]
	TIME [epoch: 18.4 sec]
EPOCH 227/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07882542609182748		[learning rate: 0.00066323]
	Learning Rate: 0.000663234
	LOSS [training: 0.07882542609182748 | validation: 0.06355246628073709]
	TIME [epoch: 18.4 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_227.pth
	Model improved!!!
EPOCH 228/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08059759098864722		[learning rate: 0.00065313]
	Learning Rate: 0.00065313
	LOSS [training: 0.08059759098864722 | validation: 0.06759132670890075]
	TIME [epoch: 18.4 sec]
EPOCH 229/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07846928875714601		[learning rate: 0.00064318]
	Learning Rate: 0.000643181
	LOSS [training: 0.07846928875714601 | validation: 0.06580251204298992]
	TIME [epoch: 18.4 sec]
EPOCH 230/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07971746324800104		[learning rate: 0.00063338]
	Learning Rate: 0.000633383
	LOSS [training: 0.07971746324800104 | validation: 0.06543432039811799]
	TIME [epoch: 18.4 sec]
EPOCH 231/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07778818927923228		[learning rate: 0.00062373]
	Learning Rate: 0.000623735
	LOSS [training: 0.07778818927923228 | validation: 0.06557769040264153]
	TIME [epoch: 18.4 sec]
EPOCH 232/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07817806490262669		[learning rate: 0.00061423]
	Learning Rate: 0.000614233
	LOSS [training: 0.07817806490262669 | validation: 0.06440846428290183]
	TIME [epoch: 18.4 sec]
EPOCH 233/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07699667922093703		[learning rate: 0.00060488]
	Learning Rate: 0.000604876
	LOSS [training: 0.07699667922093703 | validation: 0.06508700992592191]
	TIME [epoch: 18.4 sec]
EPOCH 234/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07782033137534329		[learning rate: 0.00059566]
	Learning Rate: 0.000595662
	LOSS [training: 0.07782033137534329 | validation: 0.06507584844485441]
	TIME [epoch: 18.4 sec]
EPOCH 235/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07760055344458089		[learning rate: 0.00058659]
	Learning Rate: 0.000586588
	LOSS [training: 0.07760055344458089 | validation: 0.06520151704969918]
	TIME [epoch: 18.4 sec]
EPOCH 236/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07725140295341923		[learning rate: 0.00057765]
	Learning Rate: 0.000577652
	LOSS [training: 0.07725140295341923 | validation: 0.06694560440313432]
	TIME [epoch: 18.4 sec]
EPOCH 237/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0757313869456862		[learning rate: 0.00056885]
	Learning Rate: 0.000568853
	LOSS [training: 0.0757313869456862 | validation: 0.06394772128436524]
	TIME [epoch: 18.4 sec]
EPOCH 238/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07673228659601028		[learning rate: 0.00056019]
	Learning Rate: 0.000560187
	LOSS [training: 0.07673228659601028 | validation: 0.06375460216087181]
	TIME [epoch: 18.4 sec]
EPOCH 239/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0757395237554613		[learning rate: 0.00055165]
	Learning Rate: 0.000551654
	LOSS [training: 0.0757395237554613 | validation: 0.06216841660257709]
	TIME [epoch: 18.4 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_239.pth
	Model improved!!!
EPOCH 240/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0750810374990954		[learning rate: 0.00054325]
	Learning Rate: 0.00054325
	LOSS [training: 0.0750810374990954 | validation: 0.06303567328183236]
	TIME [epoch: 18.4 sec]
EPOCH 241/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07538885491119342		[learning rate: 0.00053497]
	Learning Rate: 0.000534975
	LOSS [training: 0.07538885491119342 | validation: 0.06447013534343825]
	TIME [epoch: 18.3 sec]
EPOCH 242/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07510562811799529		[learning rate: 0.00052683]
	Learning Rate: 0.000526825
	LOSS [training: 0.07510562811799529 | validation: 0.06120765525886377]
	TIME [epoch: 18.3 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_242.pth
	Model improved!!!
EPOCH 243/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07427683744176135		[learning rate: 0.0005188]
	Learning Rate: 0.0005188
	LOSS [training: 0.07427683744176135 | validation: 0.06493212532918523]
	TIME [epoch: 18.4 sec]
EPOCH 244/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07474867364305732		[learning rate: 0.0005109]
	Learning Rate: 0.000510897
	LOSS [training: 0.07474867364305732 | validation: 0.06253571626568859]
	TIME [epoch: 18.4 sec]
EPOCH 245/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07498199759323457		[learning rate: 0.00050311]
	Learning Rate: 0.000503114
	LOSS [training: 0.07498199759323457 | validation: 0.06444347623924239]
	TIME [epoch: 18.4 sec]
EPOCH 246/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07478769770788267		[learning rate: 0.00049545]
	Learning Rate: 0.00049545
	LOSS [training: 0.07478769770788267 | validation: 0.06200035924808302]
	TIME [epoch: 18.4 sec]
EPOCH 247/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0744975856341936		[learning rate: 0.0004879]
	Learning Rate: 0.000487903
	LOSS [training: 0.0744975856341936 | validation: 0.0607521063485945]
	TIME [epoch: 18.3 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_247.pth
	Model improved!!!
EPOCH 248/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07408754118490918		[learning rate: 0.00048047]
	Learning Rate: 0.00048047
	LOSS [training: 0.07408754118490918 | validation: 0.062317159282799385]
	TIME [epoch: 18.4 sec]
EPOCH 249/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07394938118776301		[learning rate: 0.00047315]
	Learning Rate: 0.000473151
	LOSS [training: 0.07394938118776301 | validation: 0.06150157101057949]
	TIME [epoch: 18.4 sec]
EPOCH 250/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07329722212418402		[learning rate: 0.00046594]
	Learning Rate: 0.000465944
	LOSS [training: 0.07329722212418402 | validation: 0.06060337004601778]
	TIME [epoch: 18.3 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_250.pth
	Model improved!!!
EPOCH 251/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07348044577241783		[learning rate: 0.00045885]
	Learning Rate: 0.000458846
	LOSS [training: 0.07348044577241783 | validation: 0.060747111735706155]
	TIME [epoch: 129 sec]
EPOCH 252/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07145435091144928		[learning rate: 0.00045186]
	Learning Rate: 0.000451856
	LOSS [training: 0.07145435091144928 | validation: 0.061783149051167496]
	TIME [epoch: 40.9 sec]
EPOCH 253/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07260124402554279		[learning rate: 0.00044497]
	Learning Rate: 0.000444973
	LOSS [training: 0.07260124402554279 | validation: 0.06091272874038795]
	TIME [epoch: 40.8 sec]
EPOCH 254/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07194754232980224		[learning rate: 0.00043819]
	Learning Rate: 0.000438194
	LOSS [training: 0.07194754232980224 | validation: 0.06351082475822253]
	TIME [epoch: 40.8 sec]
EPOCH 255/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07232200793609662		[learning rate: 0.00043152]
	Learning Rate: 0.000431519
	LOSS [training: 0.07232200793609662 | validation: 0.059287685820512664]
	TIME [epoch: 40.8 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_255.pth
	Model improved!!!
EPOCH 256/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07166577628679596		[learning rate: 0.00042495]
	Learning Rate: 0.000424946
	LOSS [training: 0.07166577628679596 | validation: 0.06090868883874686]
	TIME [epoch: 40.8 sec]
EPOCH 257/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07022955815485372		[learning rate: 0.00041847]
	Learning Rate: 0.000418472
	LOSS [training: 0.07022955815485372 | validation: 0.060785170215883526]
	TIME [epoch: 40.8 sec]
EPOCH 258/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07062669415575695		[learning rate: 0.0004121]
	Learning Rate: 0.000412098
	LOSS [training: 0.07062669415575695 | validation: 0.05943671374138781]
	TIME [epoch: 40.8 sec]
EPOCH 259/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0716931647759794		[learning rate: 0.00040582]
	Learning Rate: 0.00040582
	LOSS [training: 0.0716931647759794 | validation: 0.05896657005014415]
	TIME [epoch: 40.8 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_259.pth
	Model improved!!!
EPOCH 260/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07065230599679183		[learning rate: 0.00039964]
	Learning Rate: 0.000399638
	LOSS [training: 0.07065230599679183 | validation: 0.061556645552671235]
	TIME [epoch: 40.8 sec]
EPOCH 261/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07088991787985298		[learning rate: 0.00039355]
	Learning Rate: 0.00039355
	LOSS [training: 0.07088991787985298 | validation: 0.060183118699933695]
	TIME [epoch: 40.8 sec]
EPOCH 262/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07091638289624663		[learning rate: 0.00038755]
	Learning Rate: 0.000387555
	LOSS [training: 0.07091638289624663 | validation: 0.058222112069428456]
	TIME [epoch: 40.8 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_262.pth
	Model improved!!!
EPOCH 263/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0689869014229273		[learning rate: 0.00038165]
	Learning Rate: 0.000381651
	LOSS [training: 0.0689869014229273 | validation: 0.059073814546332246]
	TIME [epoch: 40.8 sec]
EPOCH 264/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0697441899821489		[learning rate: 0.00037584]
	Learning Rate: 0.000375837
	LOSS [training: 0.0697441899821489 | validation: 0.059439351312704974]
	TIME [epoch: 40.8 sec]
EPOCH 265/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07035611085783539		[learning rate: 0.00037011]
	Learning Rate: 0.000370112
	LOSS [training: 0.07035611085783539 | validation: 0.05891203918169517]
	TIME [epoch: 40.8 sec]
EPOCH 266/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06891881164850297		[learning rate: 0.00036447]
	Learning Rate: 0.000364474
	LOSS [training: 0.06891881164850297 | validation: 0.058398168963883924]
	TIME [epoch: 40.8 sec]
EPOCH 267/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06848939658801309		[learning rate: 0.00035892]
	Learning Rate: 0.000358922
	LOSS [training: 0.06848939658801309 | validation: 0.060479764655650026]
	TIME [epoch: 40.8 sec]
EPOCH 268/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06930881455862808		[learning rate: 0.00035345]
	Learning Rate: 0.000353454
	LOSS [training: 0.06930881455862808 | validation: 0.058276638886908136]
	TIME [epoch: 40.8 sec]
EPOCH 269/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06871463028186547		[learning rate: 0.00034807]
	Learning Rate: 0.00034807
	LOSS [training: 0.06871463028186547 | validation: 0.05796333182369546]
	TIME [epoch: 40.8 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_269.pth
	Model improved!!!
EPOCH 270/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06882070713141247		[learning rate: 0.00034277]
	Learning Rate: 0.000342768
	LOSS [training: 0.06882070713141247 | validation: 0.058714015226617414]
	TIME [epoch: 40.8 sec]
EPOCH 271/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06842038948106413		[learning rate: 0.00033755]
	Learning Rate: 0.000337546
	LOSS [training: 0.06842038948106413 | validation: 0.05689303763576602]
	TIME [epoch: 40.8 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_271.pth
	Model improved!!!
EPOCH 272/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06778386301475486		[learning rate: 0.0003324]
	Learning Rate: 0.000332404
	LOSS [training: 0.06778386301475486 | validation: 0.057195882488975475]
	TIME [epoch: 40.8 sec]
EPOCH 273/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0685033087105229		[learning rate: 0.00032734]
	Learning Rate: 0.000327341
	LOSS [training: 0.0685033087105229 | validation: 0.05802560247672744]
	TIME [epoch: 40.8 sec]
EPOCH 274/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06932363267373358		[learning rate: 0.00032235]
	Learning Rate: 0.000322354
	LOSS [training: 0.06932363267373358 | validation: 0.055259302757558096]
	TIME [epoch: 40.8 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_274.pth
	Model improved!!!
EPOCH 275/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06748848685220007		[learning rate: 0.00031744]
	Learning Rate: 0.000317444
	LOSS [training: 0.06748848685220007 | validation: 0.0581573263982956]
	TIME [epoch: 40.9 sec]
EPOCH 276/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06775742325120047		[learning rate: 0.00031261]
	Learning Rate: 0.000312608
	LOSS [training: 0.06775742325120047 | validation: 0.05594843645277024]
	TIME [epoch: 40.9 sec]
EPOCH 277/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0672431507938066		[learning rate: 0.00030785]
	Learning Rate: 0.000307846
	LOSS [training: 0.0672431507938066 | validation: 0.05655924666678361]
	TIME [epoch: 40.8 sec]
EPOCH 278/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06734919356933985		[learning rate: 0.00030316]
	Learning Rate: 0.000303156
	LOSS [training: 0.06734919356933985 | validation: 0.05653917335103158]
	TIME [epoch: 40.9 sec]
EPOCH 279/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06701365082627345		[learning rate: 0.00029854]
	Learning Rate: 0.000298538
	LOSS [training: 0.06701365082627345 | validation: 0.0569203055942243]
	TIME [epoch: 40.8 sec]
EPOCH 280/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06724888341319994		[learning rate: 0.00029399]
	Learning Rate: 0.000293991
	LOSS [training: 0.06724888341319994 | validation: 0.05692219237912792]
	TIME [epoch: 40.8 sec]
EPOCH 281/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06695450910280129		[learning rate: 0.00028951]
	Learning Rate: 0.000289512
	LOSS [training: 0.06695450910280129 | validation: 0.05516666210285652]
	TIME [epoch: 40.8 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_281.pth
	Model improved!!!
EPOCH 282/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06586395803083234		[learning rate: 0.0002851]
	Learning Rate: 0.000285102
	LOSS [training: 0.06586395803083234 | validation: 0.056199563499669467]
	TIME [epoch: 40.8 sec]
EPOCH 283/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06686706575470568		[learning rate: 0.00028076]
	Learning Rate: 0.000280759
	LOSS [training: 0.06686706575470568 | validation: 0.05464930588202705]
	TIME [epoch: 40.8 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_283.pth
	Model improved!!!
EPOCH 284/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06678363519132158		[learning rate: 0.00027648]
	Learning Rate: 0.000276482
	LOSS [training: 0.06678363519132158 | validation: 0.05669140876310798]
	TIME [epoch: 40.8 sec]
EPOCH 285/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06701593408710946		[learning rate: 0.00027227]
	Learning Rate: 0.00027227
	LOSS [training: 0.06701593408710946 | validation: 0.055455180697174464]
	TIME [epoch: 40.8 sec]
EPOCH 286/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06661383563523002		[learning rate: 0.00026812]
	Learning Rate: 0.000268123
	LOSS [training: 0.06661383563523002 | validation: 0.05665123861448838]
	TIME [epoch: 40.8 sec]
EPOCH 287/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06549533743065429		[learning rate: 0.00026404]
	Learning Rate: 0.000264038
	LOSS [training: 0.06549533743065429 | validation: 0.057512060896483794]
	TIME [epoch: 40.8 sec]
EPOCH 288/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06625526250775013		[learning rate: 0.00026002]
	Learning Rate: 0.000260016
	LOSS [training: 0.06625526250775013 | validation: 0.05477783298596357]
	TIME [epoch: 40.8 sec]
EPOCH 289/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06542703005725703		[learning rate: 0.00025606]
	Learning Rate: 0.000256055
	LOSS [training: 0.06542703005725703 | validation: 0.054548639444616034]
	TIME [epoch: 40.8 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_289.pth
	Model improved!!!
EPOCH 290/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06568883726349319		[learning rate: 0.00025215]
	Learning Rate: 0.000252154
	LOSS [training: 0.06568883726349319 | validation: 0.05500456218444593]
	TIME [epoch: 40.7 sec]
EPOCH 291/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06491079563712979		[learning rate: 0.00024831]
	Learning Rate: 0.000248313
	LOSS [training: 0.06491079563712979 | validation: 0.05631143006857492]
	TIME [epoch: 40.8 sec]
EPOCH 292/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06553731975617491		[learning rate: 0.00024453]
	Learning Rate: 0.000244531
	LOSS [training: 0.06553731975617491 | validation: 0.0536049644754729]
	TIME [epoch: 40.7 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_292.pth
	Model improved!!!
EPOCH 293/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06485475374973834		[learning rate: 0.00024081]
	Learning Rate: 0.000240806
	LOSS [training: 0.06485475374973834 | validation: 0.05235866926139393]
	TIME [epoch: 40.7 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_293.pth
	Model improved!!!
EPOCH 294/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06418578944834583		[learning rate: 0.00023714]
	Learning Rate: 0.000237137
	LOSS [training: 0.06418578944834583 | validation: 0.055110135339848654]
	TIME [epoch: 40.7 sec]
EPOCH 295/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0656043141026218		[learning rate: 0.00023352]
	Learning Rate: 0.000233525
	LOSS [training: 0.0656043141026218 | validation: 0.05644705318753014]
	TIME [epoch: 40.8 sec]
EPOCH 296/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0647847234106596		[learning rate: 0.00022997]
	Learning Rate: 0.000229968
	LOSS [training: 0.0647847234106596 | validation: 0.05289386735912299]
	TIME [epoch: 40.7 sec]
EPOCH 297/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06377706647668378		[learning rate: 0.00022646]
	Learning Rate: 0.000226464
	LOSS [training: 0.06377706647668378 | validation: 0.055369939274713315]
	TIME [epoch: 40.7 sec]
EPOCH 298/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06451622894842297		[learning rate: 0.00022301]
	Learning Rate: 0.000223015
	LOSS [training: 0.06451622894842297 | validation: 0.052151396541781955]
	TIME [epoch: 40.7 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_298.pth
	Model improved!!!
EPOCH 299/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06319763599052497		[learning rate: 0.00021962]
	Learning Rate: 0.000219617
	LOSS [training: 0.06319763599052497 | validation: 0.0529457297583235]
	TIME [epoch: 40.7 sec]
EPOCH 300/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06420531683399971		[learning rate: 0.00021627]
	Learning Rate: 0.000216272
	LOSS [training: 0.06420531683399971 | validation: 0.05383321067201784]
	TIME [epoch: 40.7 sec]
EPOCH 301/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06351495157471403		[learning rate: 0.00021298]
	Learning Rate: 0.000212977
	LOSS [training: 0.06351495157471403 | validation: 0.052527108020394134]
	TIME [epoch: 40.9 sec]
EPOCH 302/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06454560307701773		[learning rate: 0.00020973]
	Learning Rate: 0.000209733
	LOSS [training: 0.06454560307701773 | validation: 0.054131164272935094]
	TIME [epoch: 40.8 sec]
EPOCH 303/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06415301159355052		[learning rate: 0.00020654]
	Learning Rate: 0.000206538
	LOSS [training: 0.06415301159355052 | validation: 0.05275891450535547]
	TIME [epoch: 40.7 sec]
EPOCH 304/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06267814112837349		[learning rate: 0.00020339]
	Learning Rate: 0.000203392
	LOSS [training: 0.06267814112837349 | validation: 0.05426991682398909]
	TIME [epoch: 40.7 sec]
EPOCH 305/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06407332842196681		[learning rate: 0.00020029]
	Learning Rate: 0.000200293
	LOSS [training: 0.06407332842196681 | validation: 0.052618569606107356]
	TIME [epoch: 40.8 sec]
EPOCH 306/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06182865048999371		[learning rate: 0.00019724]
	Learning Rate: 0.000197242
	LOSS [training: 0.06182865048999371 | validation: 0.0527676330321412]
	TIME [epoch: 40.8 sec]
EPOCH 307/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06358648312085714		[learning rate: 0.00019424]
	Learning Rate: 0.000194238
	LOSS [training: 0.06358648312085714 | validation: 0.052570518744208566]
	TIME [epoch: 40.7 sec]
EPOCH 308/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06260873326666198		[learning rate: 0.00019128]
	Learning Rate: 0.000191279
	LOSS [training: 0.06260873326666198 | validation: 0.05174464469133638]
	TIME [epoch: 40.7 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_308.pth
	Model improved!!!
EPOCH 309/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06262553633008093		[learning rate: 0.00018836]
	Learning Rate: 0.000188365
	LOSS [training: 0.06262553633008093 | validation: 0.05128418041760352]
	TIME [epoch: 40.7 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_309.pth
	Model improved!!!
EPOCH 310/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06297467217993262		[learning rate: 0.0001855]
	Learning Rate: 0.000185495
	LOSS [training: 0.06297467217993262 | validation: 0.05524053283243491]
	TIME [epoch: 40.8 sec]
EPOCH 311/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06293644992030352		[learning rate: 0.00018267]
	Learning Rate: 0.00018267
	LOSS [training: 0.06293644992030352 | validation: 0.05217822161391811]
	TIME [epoch: 40.7 sec]
EPOCH 312/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06346794813786992		[learning rate: 0.00017989]
	Learning Rate: 0.000179887
	LOSS [training: 0.06346794813786992 | validation: 0.051977494626312765]
	TIME [epoch: 40.7 sec]
EPOCH 313/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0619382408381249		[learning rate: 0.00017715]
	Learning Rate: 0.000177147
	LOSS [training: 0.0619382408381249 | validation: 0.05240162948875336]
	TIME [epoch: 40.8 sec]
EPOCH 314/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0624516388534144		[learning rate: 0.00017445]
	Learning Rate: 0.000174448
	LOSS [training: 0.0624516388534144 | validation: 0.05109958450083994]
	TIME [epoch: 40.7 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_314.pth
	Model improved!!!
EPOCH 315/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06173558863057181		[learning rate: 0.00017179]
	Learning Rate: 0.000171791
	LOSS [training: 0.06173558863057181 | validation: 0.0526508768971587]
	TIME [epoch: 40.7 sec]
EPOCH 316/500:
	Training over batches...
		[batch 4/4] avg loss: 0.062493546650541826		[learning rate: 0.00016917]
	Learning Rate: 0.000169174
	LOSS [training: 0.062493546650541826 | validation: 0.05221797768195645]
	TIME [epoch: 40.8 sec]
EPOCH 317/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06333210458487544		[learning rate: 0.0001666]
	Learning Rate: 0.000166597
	LOSS [training: 0.06333210458487544 | validation: 0.05311423295737737]
	TIME [epoch: 40.8 sec]
EPOCH 318/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06179712368979341		[learning rate: 0.00016406]
	Learning Rate: 0.000164059
	LOSS [training: 0.06179712368979341 | validation: 0.05306564663390699]
	TIME [epoch: 40.8 sec]
EPOCH 319/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06206781147310138		[learning rate: 0.00016156]
	Learning Rate: 0.00016156
	LOSS [training: 0.06206781147310138 | validation: 0.05037667422093907]
	TIME [epoch: 40.8 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_319.pth
	Model improved!!!
EPOCH 320/500:
	Training over batches...
		[batch 4/4] avg loss: 0.062053947633543716		[learning rate: 0.0001591]
	Learning Rate: 0.000159099
	LOSS [training: 0.062053947633543716 | validation: 0.05040899283009512]
	TIME [epoch: 40.7 sec]
EPOCH 321/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06259802470042053		[learning rate: 0.00015668]
	Learning Rate: 0.000156675
	LOSS [training: 0.06259802470042053 | validation: 0.049621314088899825]
	TIME [epoch: 40.7 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_321.pth
	Model improved!!!
EPOCH 322/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06140961561135756		[learning rate: 0.00015429]
	Learning Rate: 0.000154288
	LOSS [training: 0.06140961561135756 | validation: 0.052128915306637366]
	TIME [epoch: 40.8 sec]
EPOCH 323/500:
	Training over batches...
		[batch 4/4] avg loss: 0.061914585852083426		[learning rate: 0.00015194]
	Learning Rate: 0.000151938
	LOSS [training: 0.061914585852083426 | validation: 0.05087466203689209]
	TIME [epoch: 40.8 sec]
EPOCH 324/500:
	Training over batches...
		[batch 4/4] avg loss: 0.061674082017065555		[learning rate: 0.00014962]
	Learning Rate: 0.000149624
	LOSS [training: 0.061674082017065555 | validation: 0.05036638640277005]
	TIME [epoch: 40.7 sec]
EPOCH 325/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0624204912121348		[learning rate: 0.00014734]
	Learning Rate: 0.000147344
	LOSS [training: 0.0624204912121348 | validation: 0.05527969170786491]
	TIME [epoch: 40.7 sec]
EPOCH 326/500:
	Training over batches...
		[batch 4/4] avg loss: 0.061590190551305116		[learning rate: 0.0001451]
	Learning Rate: 0.0001451
	LOSS [training: 0.061590190551305116 | validation: 0.048859039147544525]
	TIME [epoch: 40.7 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_326.pth
	Model improved!!!
EPOCH 327/500:
	Training over batches...
		[batch 4/4] avg loss: 0.061908008269579234		[learning rate: 0.00014289]
	Learning Rate: 0.000142889
	LOSS [training: 0.061908008269579234 | validation: 0.049312485239517326]
	TIME [epoch: 40.7 sec]
EPOCH 328/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06092126884838707		[learning rate: 0.00014071]
	Learning Rate: 0.000140713
	LOSS [training: 0.06092126884838707 | validation: 0.051317621228749485]
	TIME [epoch: 40.7 sec]
EPOCH 329/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06107935001452566		[learning rate: 0.00013857]
	Learning Rate: 0.000138569
	LOSS [training: 0.06107935001452566 | validation: 0.05069597414755686]
	TIME [epoch: 40.7 sec]
EPOCH 330/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06087477210363708		[learning rate: 0.00013646]
	Learning Rate: 0.000136458
	LOSS [training: 0.06087477210363708 | validation: 0.05109800358047802]
	TIME [epoch: 40.8 sec]
EPOCH 331/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06054367997007491		[learning rate: 0.00013438]
	Learning Rate: 0.00013438
	LOSS [training: 0.06054367997007491 | validation: 0.05015129279199364]
	TIME [epoch: 40.7 sec]
EPOCH 332/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06046024852433851		[learning rate: 0.00013233]
	Learning Rate: 0.000132333
	LOSS [training: 0.06046024852433851 | validation: 0.05241258007639977]
	TIME [epoch: 40.7 sec]
EPOCH 333/500:
	Training over batches...
		[batch 4/4] avg loss: 0.059740520162092345		[learning rate: 0.00013032]
	Learning Rate: 0.000130317
	LOSS [training: 0.059740520162092345 | validation: 0.05248892433634149]
	TIME [epoch: 40.8 sec]
EPOCH 334/500:
	Training over batches...
		[batch 4/4] avg loss: 0.061173219097606715		[learning rate: 0.00012833]
	Learning Rate: 0.000128332
	LOSS [training: 0.061173219097606715 | validation: 0.049021781946801304]
	TIME [epoch: 40.8 sec]
EPOCH 335/500:
	Training over batches...
		[batch 4/4] avg loss: 0.060887610596499296		[learning rate: 0.00012638]
	Learning Rate: 0.000126377
	LOSS [training: 0.060887610596499296 | validation: 0.049448370974135465]
	TIME [epoch: 40.7 sec]
EPOCH 336/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06086430598382236		[learning rate: 0.00012445]
	Learning Rate: 0.000124451
	LOSS [training: 0.06086430598382236 | validation: 0.0522448639494323]
	TIME [epoch: 40.7 sec]
EPOCH 337/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06045095958210354		[learning rate: 0.00012256]
	Learning Rate: 0.000122556
	LOSS [training: 0.06045095958210354 | validation: 0.053314106470134986]
	TIME [epoch: 40.7 sec]
EPOCH 338/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06091230634873716		[learning rate: 0.00012069]
	Learning Rate: 0.000120689
	LOSS [training: 0.06091230634873716 | validation: 0.050680422053633226]
	TIME [epoch: 40.8 sec]
EPOCH 339/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06134455985097645		[learning rate: 0.00011885]
	Learning Rate: 0.00011885
	LOSS [training: 0.06134455985097645 | validation: 0.049935962721028175]
	TIME [epoch: 40.8 sec]
EPOCH 340/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06091281431581394		[learning rate: 0.00011704]
	Learning Rate: 0.00011704
	LOSS [training: 0.06091281431581394 | validation: 0.04850699323577902]
	TIME [epoch: 40.8 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_340.pth
	Model improved!!!
EPOCH 341/500:
	Training over batches...
		[batch 4/4] avg loss: 0.059228814244894776		[learning rate: 0.00011526]
	Learning Rate: 0.000115257
	LOSS [training: 0.059228814244894776 | validation: 0.04954386104890915]
	TIME [epoch: 40.9 sec]
EPOCH 342/500:
	Training over batches...
		[batch 4/4] avg loss: 0.061258302656660456		[learning rate: 0.0001135]
	Learning Rate: 0.000113501
	LOSS [training: 0.061258302656660456 | validation: 0.05076922572199296]
	TIME [epoch: 40.8 sec]
EPOCH 343/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06108815594207082		[learning rate: 0.00011177]
	Learning Rate: 0.000111772
	LOSS [training: 0.06108815594207082 | validation: 0.04905782727330626]
	TIME [epoch: 40.8 sec]
EPOCH 344/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05958487006538741		[learning rate: 0.00011007]
	Learning Rate: 0.000110069
	LOSS [training: 0.05958487006538741 | validation: 0.0505870806923471]
	TIME [epoch: 40.8 sec]
EPOCH 345/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05967288583097702		[learning rate: 0.00010839]
	Learning Rate: 0.000108393
	LOSS [training: 0.05967288583097702 | validation: 0.050396057097937486]
	TIME [epoch: 40.8 sec]
EPOCH 346/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06026783947996205		[learning rate: 0.00010674]
	Learning Rate: 0.000106742
	LOSS [training: 0.06026783947996205 | validation: 0.04942488478562994]
	TIME [epoch: 40.8 sec]
EPOCH 347/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05952359036718826		[learning rate: 0.00010512]
	Learning Rate: 0.000105115
	LOSS [training: 0.05952359036718826 | validation: 0.05023377973870985]
	TIME [epoch: 40.8 sec]
EPOCH 348/500:
	Training over batches...
		[batch 4/4] avg loss: 0.060361217074790835		[learning rate: 0.00010351]
	Learning Rate: 0.000103514
	LOSS [training: 0.060361217074790835 | validation: 0.04840014071575299]
	TIME [epoch: 40.8 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_348.pth
	Model improved!!!
EPOCH 349/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05975378904787653		[learning rate: 0.00010194]
	Learning Rate: 0.000101937
	LOSS [training: 0.05975378904787653 | validation: 0.04915984269118793]
	TIME [epoch: 40.8 sec]
EPOCH 350/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05908286419936214		[learning rate: 0.00010038]
	Learning Rate: 0.000100385
	LOSS [training: 0.05908286419936214 | validation: 0.0490350082738796]
	TIME [epoch: 40.7 sec]
EPOCH 351/500:
	Training over batches...
		[batch 4/4] avg loss: 0.059683129492294935		[learning rate: 9.8855e-05]
	Learning Rate: 9.88553e-05
	LOSS [training: 0.059683129492294935 | validation: 0.04615690952358656]
	TIME [epoch: 40.8 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_351.pth
	Model improved!!!
EPOCH 352/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05995249840856727		[learning rate: 9.7349e-05]
	Learning Rate: 9.73494e-05
	LOSS [training: 0.05995249840856727 | validation: 0.04954265075731751]
	TIME [epoch: 40.8 sec]
EPOCH 353/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05914204535130843		[learning rate: 9.5866e-05]
	Learning Rate: 9.58665e-05
	LOSS [training: 0.05914204535130843 | validation: 0.05024098954827917]
	TIME [epoch: 40.8 sec]
EPOCH 354/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05998282756929428		[learning rate: 9.4406e-05]
	Learning Rate: 9.44061e-05
	LOSS [training: 0.05998282756929428 | validation: 0.049863578137415494]
	TIME [epoch: 40.8 sec]
EPOCH 355/500:
	Training over batches...
		[batch 4/4] avg loss: 0.058621062475151454		[learning rate: 9.2968e-05]
	Learning Rate: 9.2968e-05
	LOSS [training: 0.058621062475151454 | validation: 0.051146989682472874]
	TIME [epoch: 40.7 sec]
EPOCH 356/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05904123787772422		[learning rate: 9.1552e-05]
	Learning Rate: 9.15518e-05
	LOSS [training: 0.05904123787772422 | validation: 0.05098364682412922]
	TIME [epoch: 40.8 sec]
EPOCH 357/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05930551457331453		[learning rate: 9.0157e-05]
	Learning Rate: 9.01571e-05
	LOSS [training: 0.05930551457331453 | validation: 0.047862889006666715]
	TIME [epoch: 40.8 sec]
EPOCH 358/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05828081550321769		[learning rate: 8.8784e-05]
	Learning Rate: 8.87837e-05
	LOSS [training: 0.05828081550321769 | validation: 0.046292744737169184]
	TIME [epoch: 40.8 sec]
EPOCH 359/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06012435211375494		[learning rate: 8.7431e-05]
	Learning Rate: 8.74312e-05
	LOSS [training: 0.06012435211375494 | validation: 0.05100433638230451]
	TIME [epoch: 40.8 sec]
EPOCH 360/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05954759162016269		[learning rate: 8.6099e-05]
	Learning Rate: 8.60994e-05
	LOSS [training: 0.05954759162016269 | validation: 0.05186917006175178]
	TIME [epoch: 40.7 sec]
EPOCH 361/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0584396897993245		[learning rate: 8.4788e-05]
	Learning Rate: 8.47878e-05
	LOSS [training: 0.0584396897993245 | validation: 0.04882139029513237]
	TIME [epoch: 40.7 sec]
EPOCH 362/500:
	Training over batches...
		[batch 4/4] avg loss: 0.059653048512746484		[learning rate: 8.3496e-05]
	Learning Rate: 8.34962e-05
	LOSS [training: 0.059653048512746484 | validation: 0.04734551780213431]
	TIME [epoch: 40.8 sec]
EPOCH 363/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05884409647294541		[learning rate: 8.2224e-05]
	Learning Rate: 8.22243e-05
	LOSS [training: 0.05884409647294541 | validation: 0.04921574333762195]
	TIME [epoch: 40.8 sec]
EPOCH 364/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05976648861601795		[learning rate: 8.0972e-05]
	Learning Rate: 8.09717e-05
	LOSS [training: 0.05976648861601795 | validation: 0.0505440088366311]
	TIME [epoch: 40.8 sec]
EPOCH 365/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05922891353629455		[learning rate: 7.9738e-05]
	Learning Rate: 7.97382e-05
	LOSS [training: 0.05922891353629455 | validation: 0.04866553511243358]
	TIME [epoch: 40.8 sec]
EPOCH 366/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05965469398233998		[learning rate: 7.8524e-05]
	Learning Rate: 7.85235e-05
	LOSS [training: 0.05965469398233998 | validation: 0.048507730338811526]
	TIME [epoch: 40.8 sec]
EPOCH 367/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05759421961127445		[learning rate: 7.7327e-05]
	Learning Rate: 7.73274e-05
	LOSS [training: 0.05759421961127445 | validation: 0.05098183219974499]
	TIME [epoch: 40.9 sec]
EPOCH 368/500:
	Training over batches...
		[batch 4/4] avg loss: 0.058874466703961986		[learning rate: 7.6149e-05]
	Learning Rate: 7.61494e-05
	LOSS [training: 0.058874466703961986 | validation: 0.04714512429410522]
	TIME [epoch: 40.8 sec]
EPOCH 369/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05832626545585516		[learning rate: 7.4989e-05]
	Learning Rate: 7.49894e-05
	LOSS [training: 0.05832626545585516 | validation: 0.04800633365538315]
	TIME [epoch: 40.8 sec]
EPOCH 370/500:
	Training over batches...
		[batch 4/4] avg loss: 0.058347731654665294		[learning rate: 7.3847e-05]
	Learning Rate: 7.38471e-05
	LOSS [training: 0.058347731654665294 | validation: 0.04779251450202543]
	TIME [epoch: 40.8 sec]
EPOCH 371/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05888216173873995		[learning rate: 7.2722e-05]
	Learning Rate: 7.27221e-05
	LOSS [training: 0.05888216173873995 | validation: 0.04788309059515685]
	TIME [epoch: 40.8 sec]
EPOCH 372/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05949238227729284		[learning rate: 7.1614e-05]
	Learning Rate: 7.16143e-05
	LOSS [training: 0.05949238227729284 | validation: 0.050530813282436846]
	TIME [epoch: 40.8 sec]
EPOCH 373/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05850662043272514		[learning rate: 7.0523e-05]
	Learning Rate: 7.05234e-05
	LOSS [training: 0.05850662043272514 | validation: 0.04856788177206387]
	TIME [epoch: 40.8 sec]
EPOCH 374/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05966340566831262		[learning rate: 6.9449e-05]
	Learning Rate: 6.94491e-05
	LOSS [training: 0.05966340566831262 | validation: 0.04986239890521032]
	TIME [epoch: 40.8 sec]
EPOCH 375/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05890684423863225		[learning rate: 6.8391e-05]
	Learning Rate: 6.83912e-05
	LOSS [training: 0.05890684423863225 | validation: 0.04811503445247867]
	TIME [epoch: 40.8 sec]
EPOCH 376/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05894968925618729		[learning rate: 6.7349e-05]
	Learning Rate: 6.73493e-05
	LOSS [training: 0.05894968925618729 | validation: 0.04912163699013755]
	TIME [epoch: 40.8 sec]
EPOCH 377/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05877154259690383		[learning rate: 6.6323e-05]
	Learning Rate: 6.63234e-05
	LOSS [training: 0.05877154259690383 | validation: 0.04827184809266713]
	TIME [epoch: 40.8 sec]
EPOCH 378/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05852473831007896		[learning rate: 6.5313e-05]
	Learning Rate: 6.5313e-05
	LOSS [training: 0.05852473831007896 | validation: 0.05017837355580333]
	TIME [epoch: 40.8 sec]
EPOCH 379/500:
	Training over batches...
		[batch 4/4] avg loss: 0.058120900283288784		[learning rate: 6.4318e-05]
	Learning Rate: 6.43181e-05
	LOSS [training: 0.058120900283288784 | validation: 0.04611954536720654]
	TIME [epoch: 40.8 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_379.pth
	Model improved!!!
EPOCH 380/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0583323342007354		[learning rate: 6.3338e-05]
	Learning Rate: 6.33383e-05
	LOSS [training: 0.0583323342007354 | validation: 0.04749775191607026]
	TIME [epoch: 40.7 sec]
EPOCH 381/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05895593156235907		[learning rate: 6.2373e-05]
	Learning Rate: 6.23735e-05
	LOSS [training: 0.05895593156235907 | validation: 0.04897183956857147]
	TIME [epoch: 40.7 sec]
EPOCH 382/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05826326277453814		[learning rate: 6.1423e-05]
	Learning Rate: 6.14233e-05
	LOSS [training: 0.05826326277453814 | validation: 0.048938970444055936]
	TIME [epoch: 40.7 sec]
EPOCH 383/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05798251291776285		[learning rate: 6.0488e-05]
	Learning Rate: 6.04876e-05
	LOSS [training: 0.05798251291776285 | validation: 0.04951385668921179]
	TIME [epoch: 40.7 sec]
EPOCH 384/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05905436372852576		[learning rate: 5.9566e-05]
	Learning Rate: 5.95662e-05
	LOSS [training: 0.05905436372852576 | validation: 0.046384059886109955]
	TIME [epoch: 40.7 sec]
EPOCH 385/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05799126140496451		[learning rate: 5.8659e-05]
	Learning Rate: 5.86588e-05
	LOSS [training: 0.05799126140496451 | validation: 0.04670032386702503]
	TIME [epoch: 40.7 sec]
EPOCH 386/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05866305610569446		[learning rate: 5.7765e-05]
	Learning Rate: 5.77652e-05
	LOSS [training: 0.05866305610569446 | validation: 0.04747280324083682]
	TIME [epoch: 40.7 sec]
EPOCH 387/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05968176539174388		[learning rate: 5.6885e-05]
	Learning Rate: 5.68853e-05
	LOSS [training: 0.05968176539174388 | validation: 0.04907182397180387]
	TIME [epoch: 40.7 sec]
EPOCH 388/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05850811011375376		[learning rate: 5.6019e-05]
	Learning Rate: 5.60187e-05
	LOSS [training: 0.05850811011375376 | validation: 0.04851472880222635]
	TIME [epoch: 40.7 sec]
EPOCH 389/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05707209888550188		[learning rate: 5.5165e-05]
	Learning Rate: 5.51654e-05
	LOSS [training: 0.05707209888550188 | validation: 0.04823005440423152]
	TIME [epoch: 40.7 sec]
EPOCH 390/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05736959139631431		[learning rate: 5.4325e-05]
	Learning Rate: 5.4325e-05
	LOSS [training: 0.05736959139631431 | validation: 0.04912977120710192]
	TIME [epoch: 40.7 sec]
EPOCH 391/500:
	Training over batches...
		[batch 4/4] avg loss: 0.058643995333613495		[learning rate: 5.3497e-05]
	Learning Rate: 5.34975e-05
	LOSS [training: 0.058643995333613495 | validation: 0.04929240059504525]
	TIME [epoch: 40.7 sec]
EPOCH 392/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05763863647009609		[learning rate: 5.2683e-05]
	Learning Rate: 5.26825e-05
	LOSS [training: 0.05763863647009609 | validation: 0.048476010361742136]
	TIME [epoch: 40.7 sec]
EPOCH 393/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05847514687796339		[learning rate: 5.188e-05]
	Learning Rate: 5.188e-05
	LOSS [training: 0.05847514687796339 | validation: 0.049040763736906884]
	TIME [epoch: 40.7 sec]
EPOCH 394/500:
	Training over batches...
		[batch 4/4] avg loss: 0.056840103957053245		[learning rate: 5.109e-05]
	Learning Rate: 5.10897e-05
	LOSS [training: 0.056840103957053245 | validation: 0.04965816931439891]
	TIME [epoch: 40.7 sec]
EPOCH 395/500:
	Training over batches...
		[batch 4/4] avg loss: 0.057241459500750234		[learning rate: 5.0311e-05]
	Learning Rate: 5.03114e-05
	LOSS [training: 0.057241459500750234 | validation: 0.048405891807382376]
	TIME [epoch: 40.7 sec]
EPOCH 396/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05801006502342089		[learning rate: 4.9545e-05]
	Learning Rate: 4.9545e-05
	LOSS [training: 0.05801006502342089 | validation: 0.04649552379157887]
	TIME [epoch: 40.7 sec]
EPOCH 397/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05759354241953335		[learning rate: 4.879e-05]
	Learning Rate: 4.87903e-05
	LOSS [training: 0.05759354241953335 | validation: 0.04971085112034801]
	TIME [epoch: 40.8 sec]
EPOCH 398/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05709382061527547		[learning rate: 4.8047e-05]
	Learning Rate: 4.8047e-05
	LOSS [training: 0.05709382061527547 | validation: 0.04926968092511838]
	TIME [epoch: 40.7 sec]
EPOCH 399/500:
	Training over batches...
		[batch 4/4] avg loss: 0.058481830826786076		[learning rate: 4.7315e-05]
	Learning Rate: 4.73151e-05
	LOSS [training: 0.058481830826786076 | validation: 0.04981258804040951]
	TIME [epoch: 40.7 sec]
EPOCH 400/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05759460373536018		[learning rate: 4.6594e-05]
	Learning Rate: 4.65944e-05
	LOSS [training: 0.05759460373536018 | validation: 0.05100261429525633]
	TIME [epoch: 40.7 sec]
EPOCH 401/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05761383560298786		[learning rate: 4.5885e-05]
	Learning Rate: 4.58846e-05
	LOSS [training: 0.05761383560298786 | validation: 0.04692216644314928]
	TIME [epoch: 40.7 sec]
EPOCH 402/500:
	Training over batches...
		[batch 4/4] avg loss: 0.057037820686918254		[learning rate: 4.5186e-05]
	Learning Rate: 4.51856e-05
	LOSS [training: 0.057037820686918254 | validation: 0.048603818969718354]
	TIME [epoch: 40.7 sec]
EPOCH 403/500:
	Training over batches...
		[batch 4/4] avg loss: 0.058353882768855704		[learning rate: 4.4497e-05]
	Learning Rate: 4.44973e-05
	LOSS [training: 0.058353882768855704 | validation: 0.04707861351309558]
	TIME [epoch: 40.7 sec]
EPOCH 404/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05755218539953148		[learning rate: 4.3819e-05]
	Learning Rate: 4.38194e-05
	LOSS [training: 0.05755218539953148 | validation: 0.04530100062730466]
	TIME [epoch: 40.7 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_404.pth
	Model improved!!!
EPOCH 405/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05835432760235213		[learning rate: 4.3152e-05]
	Learning Rate: 4.31519e-05
	LOSS [training: 0.05835432760235213 | validation: 0.045671932324708925]
	TIME [epoch: 40.7 sec]
EPOCH 406/500:
	Training over batches...
		[batch 4/4] avg loss: 0.057522935173844034		[learning rate: 4.2495e-05]
	Learning Rate: 4.24946e-05
	LOSS [training: 0.057522935173844034 | validation: 0.04716426395423545]
	TIME [epoch: 40.7 sec]
EPOCH 407/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05693005107875288		[learning rate: 4.1847e-05]
	Learning Rate: 4.18472e-05
	LOSS [training: 0.05693005107875288 | validation: 0.04858770286232826]
	TIME [epoch: 40.7 sec]
EPOCH 408/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05781691189834874		[learning rate: 4.121e-05]
	Learning Rate: 4.12098e-05
	LOSS [training: 0.05781691189834874 | validation: 0.04721681583806961]
	TIME [epoch: 40.7 sec]
EPOCH 409/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0580383911903774		[learning rate: 4.0582e-05]
	Learning Rate: 4.0582e-05
	LOSS [training: 0.0580383911903774 | validation: 0.04922467239920089]
	TIME [epoch: 40.7 sec]
EPOCH 410/500:
	Training over batches...
		[batch 4/4] avg loss: 0.057873029154982304		[learning rate: 3.9964e-05]
	Learning Rate: 3.99638e-05
	LOSS [training: 0.057873029154982304 | validation: 0.04797141938450811]
	TIME [epoch: 40.8 sec]
EPOCH 411/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05716445357831562		[learning rate: 3.9355e-05]
	Learning Rate: 3.9355e-05
	LOSS [training: 0.05716445357831562 | validation: 0.048841965799446045]
	TIME [epoch: 40.7 sec]
EPOCH 412/500:
	Training over batches...
		[batch 4/4] avg loss: 0.056241139030494845		[learning rate: 3.8755e-05]
	Learning Rate: 3.87555e-05
	LOSS [training: 0.056241139030494845 | validation: 0.05102000919796103]
	TIME [epoch: 40.7 sec]
EPOCH 413/500:
	Training over batches...
		[batch 4/4] avg loss: 0.057742001472263944		[learning rate: 3.8165e-05]
	Learning Rate: 3.81651e-05
	LOSS [training: 0.057742001472263944 | validation: 0.04873055267264151]
	TIME [epoch: 40.7 sec]
EPOCH 414/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05685053178188003		[learning rate: 3.7584e-05]
	Learning Rate: 3.75837e-05
	LOSS [training: 0.05685053178188003 | validation: 0.048898682284621395]
	TIME [epoch: 40.7 sec]
EPOCH 415/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0575041154563447		[learning rate: 3.7011e-05]
	Learning Rate: 3.70112e-05
	LOSS [training: 0.0575041154563447 | validation: 0.050058149819582426]
	TIME [epoch: 40.7 sec]
EPOCH 416/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05736528058238368		[learning rate: 3.6447e-05]
	Learning Rate: 3.64474e-05
	LOSS [training: 0.05736528058238368 | validation: 0.04667477092065195]
	TIME [epoch: 40.8 sec]
EPOCH 417/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05747096317760184		[learning rate: 3.5892e-05]
	Learning Rate: 3.58922e-05
	LOSS [training: 0.05747096317760184 | validation: 0.04774067717657151]
	TIME [epoch: 40.8 sec]
EPOCH 418/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05794065207792973		[learning rate: 3.5345e-05]
	Learning Rate: 3.53454e-05
	LOSS [training: 0.05794065207792973 | validation: 0.04657372644846771]
	TIME [epoch: 40.8 sec]
EPOCH 419/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05676570564836078		[learning rate: 3.4807e-05]
	Learning Rate: 3.4807e-05
	LOSS [training: 0.05676570564836078 | validation: 0.04780665841248879]
	TIME [epoch: 40.7 sec]
EPOCH 420/500:
	Training over batches...
		[batch 4/4] avg loss: 0.057203337188799164		[learning rate: 3.4277e-05]
	Learning Rate: 3.42768e-05
	LOSS [training: 0.057203337188799164 | validation: 0.04847886667176228]
	TIME [epoch: 40.7 sec]
EPOCH 421/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05813709038129445		[learning rate: 3.3755e-05]
	Learning Rate: 3.37546e-05
	LOSS [training: 0.05813709038129445 | validation: 0.04504734069893507]
	TIME [epoch: 40.8 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_421.pth
	Model improved!!!
EPOCH 422/500:
	Training over batches...
		[batch 4/4] avg loss: 0.057261585441028426		[learning rate: 3.324e-05]
	Learning Rate: 3.32404e-05
	LOSS [training: 0.057261585441028426 | validation: 0.04994067764112228]
	TIME [epoch: 40.8 sec]
EPOCH 423/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05724112306730805		[learning rate: 3.2734e-05]
	Learning Rate: 3.27341e-05
	LOSS [training: 0.05724112306730805 | validation: 0.04880827232315478]
	TIME [epoch: 40.8 sec]
EPOCH 424/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05738777731352754		[learning rate: 3.2235e-05]
	Learning Rate: 3.22354e-05
	LOSS [training: 0.05738777731352754 | validation: 0.04912369655257975]
	TIME [epoch: 40.7 sec]
EPOCH 425/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05788381762927984		[learning rate: 3.1744e-05]
	Learning Rate: 3.17444e-05
	LOSS [training: 0.05788381762927984 | validation: 0.047313883873977974]
	TIME [epoch: 40.7 sec]
EPOCH 426/500:
	Training over batches...
		[batch 4/4] avg loss: 0.057794174218270336		[learning rate: 3.1261e-05]
	Learning Rate: 3.12608e-05
	LOSS [training: 0.057794174218270336 | validation: 0.04655005145955053]
	TIME [epoch: 40.8 sec]
EPOCH 427/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05644322983578392		[learning rate: 3.0785e-05]
	Learning Rate: 3.07846e-05
	LOSS [training: 0.05644322983578392 | validation: 0.04787380595342326]
	TIME [epoch: 40.7 sec]
EPOCH 428/500:
	Training over batches...
		[batch 4/4] avg loss: 0.057519216235934714		[learning rate: 3.0316e-05]
	Learning Rate: 3.03156e-05
	LOSS [training: 0.057519216235934714 | validation: 0.046660149838736245]
	TIME [epoch: 40.8 sec]
EPOCH 429/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05700574225045979		[learning rate: 2.9854e-05]
	Learning Rate: 2.98538e-05
	LOSS [training: 0.05700574225045979 | validation: 0.04663763831569444]
	TIME [epoch: 40.8 sec]
EPOCH 430/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05739138720558247		[learning rate: 2.9399e-05]
	Learning Rate: 2.9399e-05
	LOSS [training: 0.05739138720558247 | validation: 0.048333596750614105]
	TIME [epoch: 40.7 sec]
EPOCH 431/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05681576056653442		[learning rate: 2.8951e-05]
	Learning Rate: 2.89512e-05
	LOSS [training: 0.05681576056653442 | validation: 0.0486815639521303]
	TIME [epoch: 40.7 sec]
EPOCH 432/500:
	Training over batches...
		[batch 4/4] avg loss: 0.057200249167530456		[learning rate: 2.851e-05]
	Learning Rate: 2.85102e-05
	LOSS [training: 0.057200249167530456 | validation: 0.04844038738317872]
	TIME [epoch: 40.7 sec]
EPOCH 433/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05700434886553673		[learning rate: 2.8076e-05]
	Learning Rate: 2.80759e-05
	LOSS [training: 0.05700434886553673 | validation: 0.045884934415322924]
	TIME [epoch: 40.7 sec]
EPOCH 434/500:
	Training over batches...
		[batch 4/4] avg loss: 0.056612341726782804		[learning rate: 2.7648e-05]
	Learning Rate: 2.76482e-05
	LOSS [training: 0.056612341726782804 | validation: 0.04773648158246229]
	TIME [epoch: 40.7 sec]
EPOCH 435/500:
	Training over batches...
		[batch 4/4] avg loss: 0.056047460966523494		[learning rate: 2.7227e-05]
	Learning Rate: 2.7227e-05
	LOSS [training: 0.056047460966523494 | validation: 0.0465215548440171]
	TIME [epoch: 40.7 sec]
EPOCH 436/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0568726103798735		[learning rate: 2.6812e-05]
	Learning Rate: 2.68122e-05
	LOSS [training: 0.0568726103798735 | validation: 0.04817636388122749]
	TIME [epoch: 40.7 sec]
EPOCH 437/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05760110982720312		[learning rate: 2.6404e-05]
	Learning Rate: 2.64038e-05
	LOSS [training: 0.05760110982720312 | validation: 0.04720769923360468]
	TIME [epoch: 40.7 sec]
EPOCH 438/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05728698179567682		[learning rate: 2.6002e-05]
	Learning Rate: 2.60016e-05
	LOSS [training: 0.05728698179567682 | validation: 0.04588043149612385]
	TIME [epoch: 40.7 sec]
EPOCH 439/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05793726061347906		[learning rate: 2.5605e-05]
	Learning Rate: 2.56055e-05
	LOSS [training: 0.05793726061347906 | validation: 0.04726595509562686]
	TIME [epoch: 40.7 sec]
EPOCH 440/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05662915703777112		[learning rate: 2.5215e-05]
	Learning Rate: 2.52154e-05
	LOSS [training: 0.05662915703777112 | validation: 0.04744014859630524]
	TIME [epoch: 40.7 sec]
EPOCH 441/500:
	Training over batches...
		[batch 4/4] avg loss: 0.056302929670932		[learning rate: 2.4831e-05]
	Learning Rate: 2.48313e-05
	LOSS [training: 0.056302929670932 | validation: 0.04844473253782035]
	TIME [epoch: 40.7 sec]
EPOCH 442/500:
	Training over batches...
		[batch 4/4] avg loss: 0.057448219483675095		[learning rate: 2.4453e-05]
	Learning Rate: 2.44531e-05
	LOSS [training: 0.057448219483675095 | validation: 0.04735298442850575]
	TIME [epoch: 40.7 sec]
EPOCH 443/500:
	Training over batches...
		[batch 4/4] avg loss: 0.056549583446218576		[learning rate: 2.4081e-05]
	Learning Rate: 2.40806e-05
	LOSS [training: 0.056549583446218576 | validation: 0.04634129180423001]
	TIME [epoch: 40.7 sec]
EPOCH 444/500:
	Training over batches...
		[batch 4/4] avg loss: 0.056565059258775294		[learning rate: 2.3714e-05]
	Learning Rate: 2.37137e-05
	LOSS [training: 0.056565059258775294 | validation: 0.04859515902275373]
	TIME [epoch: 40.7 sec]
EPOCH 445/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05635323451733314		[learning rate: 2.3352e-05]
	Learning Rate: 2.33525e-05
	LOSS [training: 0.05635323451733314 | validation: 0.046619678979468726]
	TIME [epoch: 40.7 sec]
EPOCH 446/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05659037586974534		[learning rate: 2.2997e-05]
	Learning Rate: 2.29968e-05
	LOSS [training: 0.05659037586974534 | validation: 0.04592659537596537]
	TIME [epoch: 40.7 sec]
EPOCH 447/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05718096166039778		[learning rate: 2.2646e-05]
	Learning Rate: 2.26464e-05
	LOSS [training: 0.05718096166039778 | validation: 0.045138800414765354]
	TIME [epoch: 40.7 sec]
EPOCH 448/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05715936074521985		[learning rate: 2.2301e-05]
	Learning Rate: 2.23015e-05
	LOSS [training: 0.05715936074521985 | validation: 0.048463392598093236]
	TIME [epoch: 40.7 sec]
EPOCH 449/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05684416774230182		[learning rate: 2.1962e-05]
	Learning Rate: 2.19617e-05
	LOSS [training: 0.05684416774230182 | validation: 0.04505367069092428]
	TIME [epoch: 40.7 sec]
EPOCH 450/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05684895144088273		[learning rate: 2.1627e-05]
	Learning Rate: 2.16272e-05
	LOSS [training: 0.05684895144088273 | validation: 0.049303203355105185]
	TIME [epoch: 40.7 sec]
EPOCH 451/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05625963171482986		[learning rate: 2.1298e-05]
	Learning Rate: 2.12977e-05
	LOSS [training: 0.05625963171482986 | validation: 0.047531371664024435]
	TIME [epoch: 40.7 sec]
EPOCH 452/500:
	Training over batches...
		[batch 4/4] avg loss: 0.056547935952364466		[learning rate: 2.0973e-05]
	Learning Rate: 2.09733e-05
	LOSS [training: 0.056547935952364466 | validation: 0.046005881752466886]
	TIME [epoch: 40.7 sec]
EPOCH 453/500:
	Training over batches...
		[batch 4/4] avg loss: 0.056803138614997924		[learning rate: 2.0654e-05]
	Learning Rate: 2.06538e-05
	LOSS [training: 0.056803138614997924 | validation: 0.045557497815632036]
	TIME [epoch: 40.7 sec]
EPOCH 454/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0565442653672416		[learning rate: 2.0339e-05]
	Learning Rate: 2.03392e-05
	LOSS [training: 0.0565442653672416 | validation: 0.04408945557268283]
	TIME [epoch: 40.7 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd3_20240711_013336/states/model_algphiq_1a_v_mmd3_454.pth
	Model improved!!!
EPOCH 455/500:
	Training over batches...
		[batch 4/4] avg loss: 0.056292126084242916		[learning rate: 2.0029e-05]
	Learning Rate: 2.00293e-05
	LOSS [training: 0.056292126084242916 | validation: 0.04513352723760841]
	TIME [epoch: 40.7 sec]
EPOCH 456/500:
	Training over batches...
		[batch 4/4] avg loss: 0.055827328067139456		[learning rate: 1.9724e-05]
	Learning Rate: 1.97242e-05
	LOSS [training: 0.055827328067139456 | validation: 0.046020610175442525]
	TIME [epoch: 40.7 sec]
EPOCH 457/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05650202383966109		[learning rate: 1.9424e-05]
	Learning Rate: 1.94238e-05
	LOSS [training: 0.05650202383966109 | validation: 0.045787334099711544]
	TIME [epoch: 40.7 sec]
EPOCH 458/500:
	Training over batches...
		[batch 4/4] avg loss: 0.055492894913559354		[learning rate: 1.9128e-05]
	Learning Rate: 1.91279e-05
	LOSS [training: 0.055492894913559354 | validation: 0.04585126892607147]
	TIME [epoch: 40.7 sec]
EPOCH 459/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05584971580691269		[learning rate: 1.8836e-05]
	Learning Rate: 1.88365e-05
	LOSS [training: 0.05584971580691269 | validation: 0.044103357491804156]
	TIME [epoch: 40.7 sec]
EPOCH 460/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05656111774121969		[learning rate: 1.855e-05]
	Learning Rate: 1.85495e-05
	LOSS [training: 0.05656111774121969 | validation: 0.04811324884632115]
	TIME [epoch: 40.7 sec]
EPOCH 461/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05687207852967238		[learning rate: 1.8267e-05]
	Learning Rate: 1.8267e-05
	LOSS [training: 0.05687207852967238 | validation: 0.04799894305093747]
	TIME [epoch: 40.7 sec]
EPOCH 462/500:
	Training over batches...
		[batch 4/4] avg loss: 0.056810827637273645		[learning rate: 1.7989e-05]
	Learning Rate: 1.79887e-05
	LOSS [training: 0.056810827637273645 | validation: 0.048402840377745004]
	TIME [epoch: 40.7 sec]
EPOCH 463/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0562092248268465		[learning rate: 1.7715e-05]
	Learning Rate: 1.77147e-05
	LOSS [training: 0.0562092248268465 | validation: 0.04781742648147741]
	TIME [epoch: 40.7 sec]
EPOCH 464/500:
	Training over batches...
		[batch 4/4] avg loss: 0.057042233188155184		[learning rate: 1.7445e-05]
	Learning Rate: 1.74448e-05
	LOSS [training: 0.057042233188155184 | validation: 0.04728850860014956]
	TIME [epoch: 40.7 sec]
EPOCH 465/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05742275260685315		[learning rate: 1.7179e-05]
	Learning Rate: 1.71791e-05
	LOSS [training: 0.05742275260685315 | validation: 0.045539143931984785]
	TIME [epoch: 40.7 sec]
EPOCH 466/500:
	Training over batches...
		[batch 4/4] avg loss: 0.056420646311229776		[learning rate: 1.6917e-05]
	Learning Rate: 1.69174e-05
	LOSS [training: 0.056420646311229776 | validation: 0.04787863014508732]
	TIME [epoch: 40.7 sec]
EPOCH 467/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05702861524606832		[learning rate: 1.666e-05]
	Learning Rate: 1.66597e-05
	LOSS [training: 0.05702861524606832 | validation: 0.04789516860093532]
	TIME [epoch: 40.7 sec]
EPOCH 468/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05627736088953447		[learning rate: 1.6406e-05]
	Learning Rate: 1.64059e-05
	LOSS [training: 0.05627736088953447 | validation: 0.04523397085111841]
	TIME [epoch: 40.7 sec]
EPOCH 469/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05571687623659621		[learning rate: 1.6156e-05]
	Learning Rate: 1.6156e-05
	LOSS [training: 0.05571687623659621 | validation: 0.04839359087274746]
	TIME [epoch: 40.7 sec]
EPOCH 470/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0565480387692435		[learning rate: 1.591e-05]
	Learning Rate: 1.59099e-05
	LOSS [training: 0.0565480387692435 | validation: 0.04709407967592537]
	TIME [epoch: 40.7 sec]
EPOCH 471/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05633003899345208		[learning rate: 1.5668e-05]
	Learning Rate: 1.56675e-05
	LOSS [training: 0.05633003899345208 | validation: 0.04859285653528851]
	TIME [epoch: 40.7 sec]
EPOCH 472/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0566386322597327		[learning rate: 1.5429e-05]
	Learning Rate: 1.54288e-05
	LOSS [training: 0.0566386322597327 | validation: 0.04696662398782289]
	TIME [epoch: 40.7 sec]
EPOCH 473/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05662623663389816		[learning rate: 1.5194e-05]
	Learning Rate: 1.51938e-05
	LOSS [training: 0.05662623663389816 | validation: 0.045422659744115856]
	TIME [epoch: 40.7 sec]
EPOCH 474/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05603043830098903		[learning rate: 1.4962e-05]
	Learning Rate: 1.49624e-05
	LOSS [training: 0.05603043830098903 | validation: 0.04688535764614139]
	TIME [epoch: 40.7 sec]
EPOCH 475/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05711693572303994		[learning rate: 1.4734e-05]
	Learning Rate: 1.47344e-05
	LOSS [training: 0.05711693572303994 | validation: 0.045818986641121405]
	TIME [epoch: 40.7 sec]
EPOCH 476/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05611450778058565		[learning rate: 1.451e-05]
	Learning Rate: 1.451e-05
	LOSS [training: 0.05611450778058565 | validation: 0.04683087325197291]
	TIME [epoch: 40.7 sec]
EPOCH 477/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05588340359332345		[learning rate: 1.4289e-05]
	Learning Rate: 1.42889e-05
	LOSS [training: 0.05588340359332345 | validation: 0.0475269211149639]
	TIME [epoch: 40.7 sec]
EPOCH 478/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05623825135019829		[learning rate: 1.4071e-05]
	Learning Rate: 1.40713e-05
	LOSS [training: 0.05623825135019829 | validation: 0.045625806753126275]
	TIME [epoch: 40.8 sec]
EPOCH 479/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05634161104133366		[learning rate: 1.3857e-05]
	Learning Rate: 1.38569e-05
	LOSS [training: 0.05634161104133366 | validation: 0.044140918420703085]
	TIME [epoch: 40.8 sec]
EPOCH 480/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0561966581657505		[learning rate: 1.3646e-05]
	Learning Rate: 1.36458e-05
	LOSS [training: 0.0561966581657505 | validation: 0.046365945191178023]
	TIME [epoch: 40.8 sec]
EPOCH 481/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0564765946325563		[learning rate: 1.3438e-05]
	Learning Rate: 1.3438e-05
	LOSS [training: 0.0564765946325563 | validation: 0.047202809683807606]
	TIME [epoch: 40.8 sec]
EPOCH 482/500:
	Training over batches...
		[batch 4/4] avg loss: 0.056389678633472065		[learning rate: 1.3233e-05]
	Learning Rate: 1.32333e-05
	LOSS [training: 0.056389678633472065 | validation: 0.04653222678547765]
	TIME [epoch: 40.7 sec]
EPOCH 483/500:
	Training over batches...
		[batch 4/4] avg loss: 0.056465812288896466		[learning rate: 1.3032e-05]
	Learning Rate: 1.30317e-05
	LOSS [training: 0.056465812288896466 | validation: 0.04647270501841024]
	TIME [epoch: 40.8 sec]
EPOCH 484/500:
	Training over batches...
		[batch 4/4] avg loss: 0.056391771504221935		[learning rate: 1.2833e-05]
	Learning Rate: 1.28332e-05
	LOSS [training: 0.056391771504221935 | validation: 0.04744065587617455]
	TIME [epoch: 40.8 sec]
EPOCH 485/500:
	Training over batches...
		[batch 4/4] avg loss: 0.056114109529335814		[learning rate: 1.2638e-05]
	Learning Rate: 1.26377e-05
	LOSS [training: 0.056114109529335814 | validation: 0.0452909162306142]
	TIME [epoch: 40.8 sec]
EPOCH 486/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05604009914717468		[learning rate: 1.2445e-05]
	Learning Rate: 1.24451e-05
	LOSS [training: 0.05604009914717468 | validation: 0.04629739723039649]
	TIME [epoch: 40.7 sec]
EPOCH 487/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05659817929467673		[learning rate: 1.2256e-05]
	Learning Rate: 1.22556e-05
	LOSS [training: 0.05659817929467673 | validation: 0.045753751946691915]
	TIME [epoch: 40.8 sec]
EPOCH 488/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05563392049888239		[learning rate: 1.2069e-05]
	Learning Rate: 1.20689e-05
	LOSS [training: 0.05563392049888239 | validation: 0.046884300704404976]
	TIME [epoch: 40.8 sec]
EPOCH 489/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05553474591187018		[learning rate: 1.1885e-05]
	Learning Rate: 1.1885e-05
	LOSS [training: 0.05553474591187018 | validation: 0.04691549931471914]
	TIME [epoch: 40.8 sec]
EPOCH 490/500:
	Training over batches...
		[batch 4/4] avg loss: 0.055692348245545586		[learning rate: 1.1704e-05]
	Learning Rate: 1.1704e-05
	LOSS [training: 0.055692348245545586 | validation: 0.045838731054248474]
	TIME [epoch: 40.8 sec]
EPOCH 491/500:
	Training over batches...
		[batch 4/4] avg loss: 0.057436417275500404		[learning rate: 1.1526e-05]
	Learning Rate: 1.15257e-05
	LOSS [training: 0.057436417275500404 | validation: 0.04705141924191475]
	TIME [epoch: 40.8 sec]
EPOCH 492/500:
	Training over batches...
		[batch 4/4] avg loss: 0.055945713041813165		[learning rate: 1.135e-05]
	Learning Rate: 1.13501e-05
	LOSS [training: 0.055945713041813165 | validation: 0.04728157677019693]
	TIME [epoch: 40.8 sec]
EPOCH 493/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05725878547540342		[learning rate: 1.1177e-05]
	Learning Rate: 1.11772e-05
	LOSS [training: 0.05725878547540342 | validation: 0.046581348775275644]
	TIME [epoch: 40.8 sec]
EPOCH 494/500:
	Training over batches...
		[batch 4/4] avg loss: 0.056656513905149565		[learning rate: 1.1007e-05]
	Learning Rate: 1.10069e-05
	LOSS [training: 0.056656513905149565 | validation: 0.046879628461228444]
	TIME [epoch: 40.8 sec]
EPOCH 495/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05557791189139391		[learning rate: 1.0839e-05]
	Learning Rate: 1.08393e-05
	LOSS [training: 0.05557791189139391 | validation: 0.046091844036225516]
	TIME [epoch: 40.7 sec]
EPOCH 496/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05592876784363843		[learning rate: 1.0674e-05]
	Learning Rate: 1.06741e-05
	LOSS [training: 0.05592876784363843 | validation: 0.045168754973276645]
	TIME [epoch: 40.7 sec]
EPOCH 497/500:
	Training over batches...
		[batch 4/4] avg loss: 0.055741335759438015		[learning rate: 1.0512e-05]
	Learning Rate: 1.05115e-05
	LOSS [training: 0.055741335759438015 | validation: 0.04411744000279719]
	TIME [epoch: 40.8 sec]
EPOCH 498/500:
	Training over batches...
		[batch 4/4] avg loss: 0.056167921530423076		[learning rate: 1.0351e-05]
	Learning Rate: 1.03514e-05
	LOSS [training: 0.056167921530423076 | validation: 0.04861944018759075]
	TIME [epoch: 40.8 sec]
EPOCH 499/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05652642827256535		[learning rate: 1.0194e-05]
	Learning Rate: 1.01937e-05
	LOSS [training: 0.05652642827256535 | validation: 0.04592345459445463]
	TIME [epoch: 40.8 sec]
EPOCH 500/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05609387026249335		[learning rate: 1.0038e-05]
	Learning Rate: 1.00384e-05
	LOSS [training: 0.05609387026249335 | validation: 0.044806970073888196]
	TIME [epoch: 40.7 sec]
Finished training in 14054.854 seconds.
