Args:
Namespace(name='model_algphiq_1a_v_klv21', outdir='out/model_training/model_algphiq_1a_v_klv21', training_data='data/training_data/data_phiq_1a/training', validation_data='data/training_data/data_phiq_1a/validation', model_type='quadratic', nsims_training=None, nsims_validation=None, num_epochs=500, passes_per_epoch=1, batch_size=250, patience=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=False, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 250], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=False, confinement_factor=1.0, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], phi_final_act='softplus', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=0.0, init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='klv2', kernel='multiscale', bw_range=None, optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 911569280

Training model...

Saving initial model state to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 4/4] avg loss: 8.65468145206152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.65468145206152 | validation: 8.719218127576143]
	TIME [epoch: 108 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 4/4] avg loss: 8.542774653660238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.542774653660238 | validation: 8.590099509154204]
	TIME [epoch: 4.27 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 4/4] avg loss: 8.39550482720028		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.39550482720028 | validation: 8.404887689700658]
	TIME [epoch: 4.21 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_3.pth
	Model improved!!!
EPOCH 4/500:
	Training over batches...
		[batch 4/4] avg loss: 8.164207634260162		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.164207634260162 | validation: 8.098675638851729]
	TIME [epoch: 4.23 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 4/4] avg loss: 7.761062571789172		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.761062571789172 | validation: 7.52682587664755]
	TIME [epoch: 4.26 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_5.pth
	Model improved!!!
EPOCH 6/500:
	Training over batches...
		[batch 4/4] avg loss: 6.952470657455409		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.952470657455409 | validation: 6.357220752167743]
	TIME [epoch: 4.23 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_6.pth
	Model improved!!!
EPOCH 7/500:
	Training over batches...
		[batch 4/4] avg loss: 6.153463774630769		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.153463774630769 | validation: 5.964630931164731]
	TIME [epoch: 4.23 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_7.pth
	Model improved!!!
EPOCH 8/500:
	Training over batches...
		[batch 4/4] avg loss: 5.612927813602829		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.612927813602829 | validation: 5.262955575013641]
	TIME [epoch: 4.21 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_8.pth
	Model improved!!!
EPOCH 9/500:
	Training over batches...
		[batch 4/4] avg loss: 4.606272681756851		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.606272681756851 | validation: 3.8102961941400246]
	TIME [epoch: 4.23 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_9.pth
	Model improved!!!
EPOCH 10/500:
	Training over batches...
		[batch 4/4] avg loss: 2.885063393405681		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.885063393405681 | validation: 2.134375830808601]
	TIME [epoch: 4.24 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_10.pth
	Model improved!!!
EPOCH 11/500:
	Training over batches...
		[batch 4/4] avg loss: 1.9931365103215277		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9931365103215277 | validation: 1.7948817645787511]
	TIME [epoch: 4.23 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_11.pth
	Model improved!!!
EPOCH 12/500:
	Training over batches...
		[batch 4/4] avg loss: 1.848663315651367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.848663315651367 | validation: 1.5656087385172204]
	TIME [epoch: 4.24 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_12.pth
	Model improved!!!
EPOCH 13/500:
	Training over batches...
		[batch 4/4] avg loss: 1.624186335737459		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.624186335737459 | validation: 1.3747249273368134]
	TIME [epoch: 4.26 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_13.pth
	Model improved!!!
EPOCH 14/500:
	Training over batches...
		[batch 4/4] avg loss: 1.4299277540763442		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4299277540763442 | validation: 1.2143614334623178]
	TIME [epoch: 4.24 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_14.pth
	Model improved!!!
EPOCH 15/500:
	Training over batches...
		[batch 4/4] avg loss: 1.24424202131358		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.24424202131358 | validation: 1.049706735614341]
	TIME [epoch: 4.21 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_15.pth
	Model improved!!!
EPOCH 16/500:
	Training over batches...
		[batch 4/4] avg loss: 1.0885791122971307		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0885791122971307 | validation: 0.8938154421787888]
	TIME [epoch: 4.22 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_16.pth
	Model improved!!!
EPOCH 17/500:
	Training over batches...
		[batch 4/4] avg loss: 0.929909809478165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.929909809478165 | validation: 0.9235471633735158]
	TIME [epoch: 4.24 sec]
EPOCH 18/500:
	Training over batches...
		[batch 4/4] avg loss: 0.9028009829277049		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9028009829277049 | validation: 0.7477129543464927]
	TIME [epoch: 4.23 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_18.pth
	Model improved!!!
EPOCH 19/500:
	Training over batches...
		[batch 4/4] avg loss: 0.7322636142549952		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7322636142549952 | validation: 0.7269903445435741]
	TIME [epoch: 4.23 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_19.pth
	Model improved!!!
EPOCH 20/500:
	Training over batches...
		[batch 4/4] avg loss: 0.6429737082980493		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6429737082980493 | validation: 0.6312705000985384]
	TIME [epoch: 4.28 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_20.pth
	Model improved!!!
EPOCH 21/500:
	Training over batches...
		[batch 4/4] avg loss: 0.5470595465887705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5470595465887705 | validation: 0.5724685285311448]
	TIME [epoch: 4.24 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_21.pth
	Model improved!!!
EPOCH 22/500:
	Training over batches...
		[batch 4/4] avg loss: 0.4839911529770647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4839911529770647 | validation: 0.37638760345298583]
	TIME [epoch: 4.23 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_22.pth
	Model improved!!!
EPOCH 23/500:
	Training over batches...
		[batch 4/4] avg loss: 0.4845806541471456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4845806541471456 | validation: 0.30264002051620453]
	TIME [epoch: 4.21 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_23.pth
	Model improved!!!
EPOCH 24/500:
	Training over batches...
		[batch 4/4] avg loss: 0.45407163836254827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45407163836254827 | validation: 0.2992273308143816]
	TIME [epoch: 4.22 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_24.pth
	Model improved!!!
EPOCH 25/500:
	Training over batches...
		[batch 4/4] avg loss: 0.35253320929923015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35253320929923015 | validation: 0.27776125584186984]
	TIME [epoch: 4.23 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_25.pth
	Model improved!!!
EPOCH 26/500:
	Training over batches...
		[batch 4/4] avg loss: 0.4797778337536657		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4797778337536657 | validation: 0.7092355552317882]
	TIME [epoch: 4.24 sec]
EPOCH 27/500:
	Training over batches...
		[batch 4/4] avg loss: 0.6018641408453937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6018641408453937 | validation: 0.5229644939926332]
	TIME [epoch: 4.27 sec]
EPOCH 28/500:
	Training over batches...
		[batch 4/4] avg loss: 0.3988858376166514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3988858376166514 | validation: 0.27012095929422547]
	TIME [epoch: 4.25 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_28.pth
	Model improved!!!
EPOCH 29/500:
	Training over batches...
		[batch 4/4] avg loss: 0.3907143748776385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3907143748776385 | validation: 0.4421332441218814]
	TIME [epoch: 4.22 sec]
EPOCH 30/500:
	Training over batches...
		[batch 4/4] avg loss: 0.3681837873109652		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3681837873109652 | validation: 0.2922075615071955]
	TIME [epoch: 4.21 sec]
EPOCH 31/500:
	Training over batches...
		[batch 4/4] avg loss: 0.4111628559250072		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4111628559250072 | validation: 0.28071975730798515]
	TIME [epoch: 4.23 sec]
EPOCH 32/500:
	Training over batches...
		[batch 4/4] avg loss: 0.3404020776623628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3404020776623628 | validation: 0.26851317698718136]
	TIME [epoch: 4.24 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_32.pth
	Model improved!!!
EPOCH 33/500:
	Training over batches...
		[batch 4/4] avg loss: 0.3308652655721289		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3308652655721289 | validation: 0.3456465242668184]
	TIME [epoch: 4.24 sec]
EPOCH 34/500:
	Training over batches...
		[batch 4/4] avg loss: 0.3568575394027235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3568575394027235 | validation: 0.3465413279533316]
	TIME [epoch: 4.23 sec]
EPOCH 35/500:
	Training over batches...
		[batch 4/4] avg loss: 0.41825430146114084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41825430146114084 | validation: 0.27711040222563255]
	TIME [epoch: 4.27 sec]
EPOCH 36/500:
	Training over batches...
		[batch 4/4] avg loss: 0.39114438118204903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39114438118204903 | validation: 0.3224258117517974]
	TIME [epoch: 4.22 sec]
EPOCH 37/500:
	Training over batches...
		[batch 4/4] avg loss: 0.34296833608652944		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34296833608652944 | validation: 0.31436482392065185]
	TIME [epoch: 4.22 sec]
EPOCH 38/500:
	Training over batches...
		[batch 4/4] avg loss: 0.3605922698741594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3605922698741594 | validation: 0.3715388480580114]
	TIME [epoch: 4.24 sec]
EPOCH 39/500:
	Training over batches...
		[batch 4/4] avg loss: 0.37758533699181646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37758533699181646 | validation: 0.3925632078167081]
	TIME [epoch: 4.22 sec]
EPOCH 40/500:
	Training over batches...
		[batch 4/4] avg loss: 0.3549902283709432		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3549902283709432 | validation: 0.39121890444703494]
	TIME [epoch: 4.49 sec]
EPOCH 41/500:
	Training over batches...
		[batch 4/4] avg loss: 0.34282067217435663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34282067217435663 | validation: 0.33317702579522046]
	TIME [epoch: 4.22 sec]
EPOCH 42/500:
	Training over batches...
		[batch 4/4] avg loss: 0.4069362382989388		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4069362382989388 | validation: 0.4715578686097013]
	TIME [epoch: 4.22 sec]
EPOCH 43/500:
	Training over batches...
		[batch 4/4] avg loss: 0.37035342222760137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37035342222760137 | validation: 0.3477431473005138]
	TIME [epoch: 4.25 sec]
EPOCH 44/500:
	Training over batches...
		[batch 4/4] avg loss: 0.3289382709521199		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3289382709521199 | validation: 0.3040380497569276]
	TIME [epoch: 4.22 sec]
EPOCH 45/500:
	Training over batches...
		[batch 4/4] avg loss: 0.3872375337996985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3872375337996985 | validation: 0.2750273235664274]
	TIME [epoch: 4.23 sec]
EPOCH 46/500:
	Training over batches...
		[batch 4/4] avg loss: 0.3396982610801456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3396982610801456 | validation: 0.29962157389515065]
	TIME [epoch: 4.23 sec]
EPOCH 47/500:
	Training over batches...
		[batch 4/4] avg loss: 0.31115409932545846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31115409932545846 | validation: 0.3418719423967437]
	TIME [epoch: 4.23 sec]
EPOCH 48/500:
	Training over batches...
		[batch 4/4] avg loss: 0.31563303832197487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31563303832197487 | validation: 0.3302441281306805]
	TIME [epoch: 4.24 sec]
EPOCH 49/500:
	Training over batches...
		[batch 4/4] avg loss: 0.31060472866513206		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31060472866513206 | validation: 0.3187824822420594]
	TIME [epoch: 4.29 sec]
EPOCH 50/500:
	Training over batches...
		[batch 4/4] avg loss: 0.30068675805533196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30068675805533196 | validation: 0.4229201798676405]
	TIME [epoch: 4.21 sec]
EPOCH 51/500:
	Training over batches...
		[batch 4/4] avg loss: 0.3282982552182676		[learning rate: 0.0098855]
	Learning Rate: 0.00988553
	LOSS [training: 0.3282982552182676 | validation: 0.3448851115732271]
	TIME [epoch: 112 sec]
EPOCH 52/500:
	Training over batches...
		[batch 4/4] avg loss: 0.32256566677858517		[learning rate: 0.0097349]
	Learning Rate: 0.00973494
	LOSS [training: 0.32256566677858517 | validation: 0.2745886005387379]
	TIME [epoch: 8.31 sec]
EPOCH 53/500:
	Training over batches...
		[batch 4/4] avg loss: 0.35859636491892655		[learning rate: 0.0095866]
	Learning Rate: 0.00958665
	LOSS [training: 0.35859636491892655 | validation: 0.32746340559663256]
	TIME [epoch: 8.27 sec]
EPOCH 54/500:
	Training over batches...
		[batch 4/4] avg loss: 0.3155940849990436		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.3155940849990436 | validation: 0.2573891131617756]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_54.pth
	Model improved!!!
EPOCH 55/500:
	Training over batches...
		[batch 4/4] avg loss: 0.28815101983185404		[learning rate: 0.0092968]
	Learning Rate: 0.0092968
	LOSS [training: 0.28815101983185404 | validation: 0.21673024256478043]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_55.pth
	Model improved!!!
EPOCH 56/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2887455096596514		[learning rate: 0.0091552]
	Learning Rate: 0.00915517
	LOSS [training: 0.2887455096596514 | validation: 0.20857549951454885]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_56.pth
	Model improved!!!
EPOCH 57/500:
	Training over batches...
		[batch 4/4] avg loss: 0.26547887149372323		[learning rate: 0.0090157]
	Learning Rate: 0.00901571
	LOSS [training: 0.26547887149372323 | validation: 0.21074862651870746]
	TIME [epoch: 8.33 sec]
EPOCH 58/500:
	Training over batches...
		[batch 4/4] avg loss: 0.26740838693219104		[learning rate: 0.0088784]
	Learning Rate: 0.00887837
	LOSS [training: 0.26740838693219104 | validation: 0.18108803537600632]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_58.pth
	Model improved!!!
EPOCH 59/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2566021064041226		[learning rate: 0.0087431]
	Learning Rate: 0.00874312
	LOSS [training: 0.2566021064041226 | validation: 0.19698159821283473]
	TIME [epoch: 8.33 sec]
EPOCH 60/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2725415178892962		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 0.2725415178892962 | validation: 0.19475616401950974]
	TIME [epoch: 8.38 sec]
EPOCH 61/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2569318160951652		[learning rate: 0.0084788]
	Learning Rate: 0.00847878
	LOSS [training: 0.2569318160951652 | validation: 0.19722145603978913]
	TIME [epoch: 8.35 sec]
EPOCH 62/500:
	Training over batches...
		[batch 4/4] avg loss: 0.21532630796404087		[learning rate: 0.0083496]
	Learning Rate: 0.00834962
	LOSS [training: 0.21532630796404087 | validation: 0.20164181132681241]
	TIME [epoch: 8.34 sec]
EPOCH 63/500:
	Training over batches...
		[batch 4/4] avg loss: 0.20287841573076423		[learning rate: 0.0082224]
	Learning Rate: 0.00822243
	LOSS [training: 0.20287841573076423 | validation: 0.17311077950401332]
	TIME [epoch: 8.35 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_63.pth
	Model improved!!!
EPOCH 64/500:
	Training over batches...
		[batch 4/4] avg loss: 0.19315854569889096		[learning rate: 0.0080972]
	Learning Rate: 0.00809717
	LOSS [training: 0.19315854569889096 | validation: 0.18510903654406824]
	TIME [epoch: 8.34 sec]
EPOCH 65/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2852199570006394		[learning rate: 0.0079738]
	Learning Rate: 0.00797382
	LOSS [training: 0.2852199570006394 | validation: 0.17007023602976354]
	TIME [epoch: 8.38 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_65.pth
	Model improved!!!
EPOCH 66/500:
	Training over batches...
		[batch 4/4] avg loss: 0.348770458256529		[learning rate: 0.0078524]
	Learning Rate: 0.00785236
	LOSS [training: 0.348770458256529 | validation: 0.21379936621280032]
	TIME [epoch: 8.34 sec]
EPOCH 67/500:
	Training over batches...
		[batch 4/4] avg loss: 0.20314089703091667		[learning rate: 0.0077327]
	Learning Rate: 0.00773274
	LOSS [training: 0.20314089703091667 | validation: 0.35277993417984727]
	TIME [epoch: 8.33 sec]
EPOCH 68/500:
	Training over batches...
		[batch 4/4] avg loss: 0.25294644779472486		[learning rate: 0.0076149]
	Learning Rate: 0.00761494
	LOSS [training: 0.25294644779472486 | validation: 0.25136721272088436]
	TIME [epoch: 8.34 sec]
EPOCH 69/500:
	Training over batches...
		[batch 4/4] avg loss: 0.45249904117670003		[learning rate: 0.0074989]
	Learning Rate: 0.00749894
	LOSS [training: 0.45249904117670003 | validation: 0.228933942674261]
	TIME [epoch: 8.37 sec]
EPOCH 70/500:
	Training over batches...
		[batch 4/4] avg loss: 0.21422579297458802		[learning rate: 0.0073847]
	Learning Rate: 0.00738471
	LOSS [training: 0.21422579297458802 | validation: 0.269148675552732]
	TIME [epoch: 8.35 sec]
EPOCH 71/500:
	Training over batches...
		[batch 4/4] avg loss: 0.23327102918815124		[learning rate: 0.0072722]
	Learning Rate: 0.00727221
	LOSS [training: 0.23327102918815124 | validation: 0.27554941844516034]
	TIME [epoch: 8.33 sec]
EPOCH 72/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2214451942418854		[learning rate: 0.0071614]
	Learning Rate: 0.00716143
	LOSS [training: 0.2214451942418854 | validation: 0.1384012162484485]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_72.pth
	Model improved!!!
EPOCH 73/500:
	Training over batches...
		[batch 4/4] avg loss: 0.25593174838643407		[learning rate: 0.0070523]
	Learning Rate: 0.00705234
	LOSS [training: 0.25593174838643407 | validation: 0.17129090392924423]
	TIME [epoch: 8.33 sec]
EPOCH 74/500:
	Training over batches...
		[batch 4/4] avg loss: 0.19531485508057267		[learning rate: 0.0069449]
	Learning Rate: 0.00694491
	LOSS [training: 0.19531485508057267 | validation: 0.1667250550754879]
	TIME [epoch: 8.34 sec]
EPOCH 75/500:
	Training over batches...
		[batch 4/4] avg loss: 0.18868593286801946		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.18868593286801946 | validation: 0.17020672353597482]
	TIME [epoch: 8.29 sec]
EPOCH 76/500:
	Training over batches...
		[batch 4/4] avg loss: 0.18797991190221958		[learning rate: 0.0067349]
	Learning Rate: 0.00673493
	LOSS [training: 0.18797991190221958 | validation: 0.15641681607255747]
	TIME [epoch: 8.31 sec]
EPOCH 77/500:
	Training over batches...
		[batch 4/4] avg loss: 0.22961607154847247		[learning rate: 0.0066323]
	Learning Rate: 0.00663234
	LOSS [training: 0.22961607154847247 | validation: 0.12803665239718975]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_77.pth
	Model improved!!!
EPOCH 78/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2003460527930302		[learning rate: 0.0065313]
	Learning Rate: 0.00653131
	LOSS [training: 0.2003460527930302 | validation: 0.15436348584674253]
	TIME [epoch: 8.3 sec]
EPOCH 79/500:
	Training over batches...
		[batch 4/4] avg loss: 0.19492808407085008		[learning rate: 0.0064318]
	Learning Rate: 0.00643181
	LOSS [training: 0.19492808407085008 | validation: 0.16324675061275218]
	TIME [epoch: 8.35 sec]
EPOCH 80/500:
	Training over batches...
		[batch 4/4] avg loss: 0.20300549127541878		[learning rate: 0.0063338]
	Learning Rate: 0.00633383
	LOSS [training: 0.20300549127541878 | validation: 0.14865795051956673]
	TIME [epoch: 8.32 sec]
EPOCH 81/500:
	Training over batches...
		[batch 4/4] avg loss: 0.17778477762731854		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.17778477762731854 | validation: 0.11676491156432214]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_81.pth
	Model improved!!!
EPOCH 82/500:
	Training over batches...
		[batch 4/4] avg loss: 0.16951998270496432		[learning rate: 0.0061423]
	Learning Rate: 0.00614233
	LOSS [training: 0.16951998270496432 | validation: 0.23912248831114918]
	TIME [epoch: 8.28 sec]
EPOCH 83/500:
	Training over batches...
		[batch 4/4] avg loss: 0.18555989898817335		[learning rate: 0.0060488]
	Learning Rate: 0.00604876
	LOSS [training: 0.18555989898817335 | validation: 0.2605311230505714]
	TIME [epoch: 8.31 sec]
EPOCH 84/500:
	Training over batches...
		[batch 4/4] avg loss: 0.20142982583998742		[learning rate: 0.0059566]
	Learning Rate: 0.00595662
	LOSS [training: 0.20142982583998742 | validation: 0.14270770891564602]
	TIME [epoch: 8.33 sec]
EPOCH 85/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15369686182186193		[learning rate: 0.0058659]
	Learning Rate: 0.00586588
	LOSS [training: 0.15369686182186193 | validation: 0.1120751945408835]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_85.pth
	Model improved!!!
EPOCH 86/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14979123111177872		[learning rate: 0.0057765]
	Learning Rate: 0.00577653
	LOSS [training: 0.14979123111177872 | validation: 0.30994470106947025]
	TIME [epoch: 8.35 sec]
EPOCH 87/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2241533050823709		[learning rate: 0.0056885]
	Learning Rate: 0.00568853
	LOSS [training: 0.2241533050823709 | validation: 0.13263769609680492]
	TIME [epoch: 8.35 sec]
EPOCH 88/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14881048789675724		[learning rate: 0.0056019]
	Learning Rate: 0.00560187
	LOSS [training: 0.14881048789675724 | validation: 0.13252775956896384]
	TIME [epoch: 8.34 sec]
EPOCH 89/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15961220323082057		[learning rate: 0.0055165]
	Learning Rate: 0.00551654
	LOSS [training: 0.15961220323082057 | validation: 0.12663182308477905]
	TIME [epoch: 8.36 sec]
EPOCH 90/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14979863670089427		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.14979863670089427 | validation: 0.11873506866923836]
	TIME [epoch: 8.33 sec]
EPOCH 91/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15882059733287687		[learning rate: 0.0053497]
	Learning Rate: 0.00534975
	LOSS [training: 0.15882059733287687 | validation: 0.14674187896220778]
	TIME [epoch: 8.32 sec]
EPOCH 92/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2781221513506655		[learning rate: 0.0052683]
	Learning Rate: 0.00526825
	LOSS [training: 0.2781221513506655 | validation: 0.13784248280041217]
	TIME [epoch: 8.35 sec]
EPOCH 93/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15078127851294718		[learning rate: 0.005188]
	Learning Rate: 0.005188
	LOSS [training: 0.15078127851294718 | validation: 0.14424421557347222]
	TIME [epoch: 8.34 sec]
EPOCH 94/500:
	Training over batches...
		[batch 4/4] avg loss: 0.165575989989317		[learning rate: 0.005109]
	Learning Rate: 0.00510897
	LOSS [training: 0.165575989989317 | validation: 0.11999536714065588]
	TIME [epoch: 8.32 sec]
EPOCH 95/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12949102146930086		[learning rate: 0.0050311]
	Learning Rate: 0.00503114
	LOSS [training: 0.12949102146930086 | validation: 0.12407180648367687]
	TIME [epoch: 8.32 sec]
EPOCH 96/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15856597460787436		[learning rate: 0.0049545]
	Learning Rate: 0.0049545
	LOSS [training: 0.15856597460787436 | validation: 0.11989745395165849]
	TIME [epoch: 8.33 sec]
EPOCH 97/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13903196578547738		[learning rate: 0.004879]
	Learning Rate: 0.00487903
	LOSS [training: 0.13903196578547738 | validation: 0.2183205902880368]
	TIME [epoch: 8.31 sec]
EPOCH 98/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1711988219924223		[learning rate: 0.0048047]
	Learning Rate: 0.0048047
	LOSS [training: 0.1711988219924223 | validation: 0.23453570739301743]
	TIME [epoch: 8.33 sec]
EPOCH 99/500:
	Training over batches...
		[batch 4/4] avg loss: 0.16597977504443373		[learning rate: 0.0047315]
	Learning Rate: 0.00473151
	LOSS [training: 0.16597977504443373 | validation: 0.20222859883230115]
	TIME [epoch: 8.34 sec]
EPOCH 100/500:
	Training over batches...
		[batch 4/4] avg loss: 0.18849352163944694		[learning rate: 0.0046594]
	Learning Rate: 0.00465944
	LOSS [training: 0.18849352163944694 | validation: 0.2038879501548492]
	TIME [epoch: 8.32 sec]
EPOCH 101/500:
	Training over batches...
		[batch 4/4] avg loss: 0.17528045712484425		[learning rate: 0.0045885]
	Learning Rate: 0.00458846
	LOSS [training: 0.17528045712484425 | validation: 0.15490449528745334]
	TIME [epoch: 123 sec]
EPOCH 102/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1965597581827223		[learning rate: 0.0045186]
	Learning Rate: 0.00451856
	LOSS [training: 0.1965597581827223 | validation: 0.1190974326722521]
	TIME [epoch: 18.8 sec]
EPOCH 103/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13742316857224185		[learning rate: 0.0044497]
	Learning Rate: 0.00444973
	LOSS [training: 0.13742316857224185 | validation: 0.1126529984058796]
	TIME [epoch: 18.9 sec]
EPOCH 104/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12617559897067332		[learning rate: 0.0043819]
	Learning Rate: 0.00438194
	LOSS [training: 0.12617559897067332 | validation: 0.12495526096196656]
	TIME [epoch: 18.9 sec]
EPOCH 105/500:
	Training over batches...
		[batch 4/4] avg loss: 0.139185804029543		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 0.139185804029543 | validation: 0.11927418656545098]
	TIME [epoch: 18.9 sec]
EPOCH 106/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12853951615639492		[learning rate: 0.0042495]
	Learning Rate: 0.00424946
	LOSS [training: 0.12853951615639492 | validation: 0.10153888961861889]
	TIME [epoch: 18.9 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_106.pth
	Model improved!!!
EPOCH 107/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12968833839692256		[learning rate: 0.0041847]
	Learning Rate: 0.00418472
	LOSS [training: 0.12968833839692256 | validation: 0.10350642651841716]
	TIME [epoch: 18.9 sec]
EPOCH 108/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13069540215504166		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.13069540215504166 | validation: 0.09918089270877586]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_108.pth
	Model improved!!!
EPOCH 109/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12880040483196398		[learning rate: 0.0040582]
	Learning Rate: 0.0040582
	LOSS [training: 0.12880040483196398 | validation: 0.08994952305408249]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_109.pth
	Model improved!!!
EPOCH 110/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1260875957824462		[learning rate: 0.0039964]
	Learning Rate: 0.00399638
	LOSS [training: 0.1260875957824462 | validation: 0.10483319795354262]
	TIME [epoch: 18.7 sec]
EPOCH 111/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13251614021858557		[learning rate: 0.0039355]
	Learning Rate: 0.0039355
	LOSS [training: 0.13251614021858557 | validation: 0.10850783021520666]
	TIME [epoch: 18.8 sec]
EPOCH 112/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13085106872479618		[learning rate: 0.0038755]
	Learning Rate: 0.00387555
	LOSS [training: 0.13085106872479618 | validation: 0.23742927539991904]
	TIME [epoch: 18.8 sec]
EPOCH 113/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1791658581319578		[learning rate: 0.0038165]
	Learning Rate: 0.00381651
	LOSS [training: 0.1791658581319578 | validation: 0.10915292872696528]
	TIME [epoch: 18.8 sec]
EPOCH 114/500:
	Training over batches...
		[batch 4/4] avg loss: 0.11956228566344806		[learning rate: 0.0037584]
	Learning Rate: 0.00375837
	LOSS [training: 0.11956228566344806 | validation: 0.09001269582882171]
	TIME [epoch: 18.8 sec]
EPOCH 115/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1148854160788839		[learning rate: 0.0037011]
	Learning Rate: 0.00370112
	LOSS [training: 0.1148854160788839 | validation: 0.10048065134419362]
	TIME [epoch: 18.8 sec]
EPOCH 116/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12264397275110661		[learning rate: 0.0036447]
	Learning Rate: 0.00364474
	LOSS [training: 0.12264397275110661 | validation: 0.09242153229421127]
	TIME [epoch: 18.8 sec]
EPOCH 117/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12103509938679438		[learning rate: 0.0035892]
	Learning Rate: 0.00358922
	LOSS [training: 0.12103509938679438 | validation: 0.09127259930271917]
	TIME [epoch: 18.8 sec]
EPOCH 118/500:
	Training over batches...
		[batch 4/4] avg loss: 0.11288561585299435		[learning rate: 0.0035345]
	Learning Rate: 0.00353454
	LOSS [training: 0.11288561585299435 | validation: 0.0910571747110451]
	TIME [epoch: 18.8 sec]
EPOCH 119/500:
	Training over batches...
		[batch 4/4] avg loss: 0.11603547522267423		[learning rate: 0.0034807]
	Learning Rate: 0.0034807
	LOSS [training: 0.11603547522267423 | validation: 0.08027134955916006]
	TIME [epoch: 18.7 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_119.pth
	Model improved!!!
EPOCH 120/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12099179327759338		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 0.12099179327759338 | validation: 0.08339259253677891]
	TIME [epoch: 18.9 sec]
EPOCH 121/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12162888706681446		[learning rate: 0.0033755]
	Learning Rate: 0.00337546
	LOSS [training: 0.12162888706681446 | validation: 0.18788880698681307]
	TIME [epoch: 18.9 sec]
EPOCH 122/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14805012576160703		[learning rate: 0.003324]
	Learning Rate: 0.00332404
	LOSS [training: 0.14805012576160703 | validation: 0.10080878731321465]
	TIME [epoch: 18.9 sec]
EPOCH 123/500:
	Training over batches...
		[batch 4/4] avg loss: 0.09954611133946009		[learning rate: 0.0032734]
	Learning Rate: 0.00327341
	LOSS [training: 0.09954611133946009 | validation: 0.13074365598714524]
	TIME [epoch: 18.9 sec]
EPOCH 124/500:
	Training over batches...
		[batch 4/4] avg loss: 0.11496693264132068		[learning rate: 0.0032235]
	Learning Rate: 0.00322354
	LOSS [training: 0.11496693264132068 | validation: 0.09237144729544017]
	TIME [epoch: 18.9 sec]
EPOCH 125/500:
	Training over batches...
		[batch 4/4] avg loss: 0.10648788500781572		[learning rate: 0.0031744]
	Learning Rate: 0.00317444
	LOSS [training: 0.10648788500781572 | validation: 0.11121109519500676]
	TIME [epoch: 18.9 sec]
EPOCH 126/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12854545907301293		[learning rate: 0.0031261]
	Learning Rate: 0.00312608
	LOSS [training: 0.12854545907301293 | validation: 0.1434977395377814]
	TIME [epoch: 18.9 sec]
EPOCH 127/500:
	Training over batches...
		[batch 4/4] avg loss: 0.11609095901855253		[learning rate: 0.0030785]
	Learning Rate: 0.00307846
	LOSS [training: 0.11609095901855253 | validation: 0.0770476937481227]
	TIME [epoch: 18.9 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_127.pth
	Model improved!!!
EPOCH 128/500:
	Training over batches...
		[batch 4/4] avg loss: 0.10335316444403056		[learning rate: 0.0030316]
	Learning Rate: 0.00303156
	LOSS [training: 0.10335316444403056 | validation: 0.07219296740992272]
	TIME [epoch: 18.9 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_128.pth
	Model improved!!!
EPOCH 129/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1103107625335463		[learning rate: 0.0029854]
	Learning Rate: 0.00298538
	LOSS [training: 0.1103107625335463 | validation: 0.10362430606889754]
	TIME [epoch: 18.9 sec]
EPOCH 130/500:
	Training over batches...
		[batch 4/4] avg loss: 0.11439673958659513		[learning rate: 0.0029399]
	Learning Rate: 0.0029399
	LOSS [training: 0.11439673958659513 | validation: 0.11221126918058283]
	TIME [epoch: 19 sec]
EPOCH 131/500:
	Training over batches...
		[batch 4/4] avg loss: 0.11833050142624943		[learning rate: 0.0028951]
	Learning Rate: 0.00289512
	LOSS [training: 0.11833050142624943 | validation: 0.1464221626113022]
	TIME [epoch: 18.9 sec]
EPOCH 132/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12515247975078259		[learning rate: 0.002851]
	Learning Rate: 0.00285102
	LOSS [training: 0.12515247975078259 | validation: 0.08581416665968696]
	TIME [epoch: 19 sec]
EPOCH 133/500:
	Training over batches...
		[batch 4/4] avg loss: 0.10080594091166835		[learning rate: 0.0028076]
	Learning Rate: 0.00280759
	LOSS [training: 0.10080594091166835 | validation: 0.08779790527669744]
	TIME [epoch: 18.9 sec]
EPOCH 134/500:
	Training over batches...
		[batch 4/4] avg loss: 0.09822865705464698		[learning rate: 0.0027648]
	Learning Rate: 0.00276482
	LOSS [training: 0.09822865705464698 | validation: 0.0847314859287579]
	TIME [epoch: 19 sec]
EPOCH 135/500:
	Training over batches...
		[batch 4/4] avg loss: 0.10802368322369284		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.10802368322369284 | validation: 0.06319794799057701]
	TIME [epoch: 18.9 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_135.pth
	Model improved!!!
EPOCH 136/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08049234146608174		[learning rate: 0.0026812]
	Learning Rate: 0.00268123
	LOSS [training: 0.08049234146608174 | validation: 0.17580040661387952]
	TIME [epoch: 19 sec]
EPOCH 137/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14109572291179293		[learning rate: 0.0026404]
	Learning Rate: 0.00264038
	LOSS [training: 0.14109572291179293 | validation: 0.07265125762278168]
	TIME [epoch: 18.9 sec]
EPOCH 138/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07905054577202444		[learning rate: 0.0026002]
	Learning Rate: 0.00260016
	LOSS [training: 0.07905054577202444 | validation: 0.06586560461607066]
	TIME [epoch: 18.9 sec]
EPOCH 139/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08168809953625056		[learning rate: 0.0025606]
	Learning Rate: 0.00256055
	LOSS [training: 0.08168809953625056 | validation: 0.06910660439015921]
	TIME [epoch: 18.9 sec]
EPOCH 140/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08806757044083541		[learning rate: 0.0025215]
	Learning Rate: 0.00252154
	LOSS [training: 0.08806757044083541 | validation: 0.08655478034696874]
	TIME [epoch: 18.9 sec]
EPOCH 141/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08164902148617512		[learning rate: 0.0024831]
	Learning Rate: 0.00248313
	LOSS [training: 0.08164902148617512 | validation: 0.06395493650462797]
	TIME [epoch: 19 sec]
EPOCH 142/500:
	Training over batches...
		[batch 4/4] avg loss: 0.09076124470238224		[learning rate: 0.0024453]
	Learning Rate: 0.00244531
	LOSS [training: 0.09076124470238224 | validation: 0.06327203395889426]
	TIME [epoch: 18.9 sec]
EPOCH 143/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08289537760693665		[learning rate: 0.0024081]
	Learning Rate: 0.00240806
	LOSS [training: 0.08289537760693665 | validation: 0.1023735251349267]
	TIME [epoch: 19 sec]
EPOCH 144/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08310081477375618		[learning rate: 0.0023714]
	Learning Rate: 0.00237137
	LOSS [training: 0.08310081477375618 | validation: 0.09018147114390487]
	TIME [epoch: 18.9 sec]
EPOCH 145/500:
	Training over batches...
		[batch 4/4] avg loss: 0.09074828805638277		[learning rate: 0.0023352]
	Learning Rate: 0.00233525
	LOSS [training: 0.09074828805638277 | validation: 0.07636955467739821]
	TIME [epoch: 19 sec]
EPOCH 146/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08264093960413446		[learning rate: 0.0022997]
	Learning Rate: 0.00229968
	LOSS [training: 0.08264093960413446 | validation: 0.06209456358559608]
	TIME [epoch: 18.9 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_146.pth
	Model improved!!!
EPOCH 147/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0802706598975154		[learning rate: 0.0022646]
	Learning Rate: 0.00226464
	LOSS [training: 0.0802706598975154 | validation: 0.06649592722432317]
	TIME [epoch: 19.1 sec]
EPOCH 148/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07458348827856598		[learning rate: 0.0022301]
	Learning Rate: 0.00223015
	LOSS [training: 0.07458348827856598 | validation: 0.05062769198334097]
	TIME [epoch: 19 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_148.pth
	Model improved!!!
EPOCH 149/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07248477435568326		[learning rate: 0.0021962]
	Learning Rate: 0.00219617
	LOSS [training: 0.07248477435568326 | validation: 0.0651133774640966]
	TIME [epoch: 19 sec]
EPOCH 150/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07176984082027259		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: 0.07176984082027259 | validation: 0.065173973318563]
	TIME [epoch: 18.9 sec]
EPOCH 151/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08861655749823692		[learning rate: 0.0021298]
	Learning Rate: 0.00212977
	LOSS [training: 0.08861655749823692 | validation: 0.06129300629592775]
	TIME [epoch: 19 sec]
EPOCH 152/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07092555607858593		[learning rate: 0.0020973]
	Learning Rate: 0.00209733
	LOSS [training: 0.07092555607858593 | validation: 0.13720003868283204]
	TIME [epoch: 19 sec]
EPOCH 153/500:
	Training over batches...
		[batch 4/4] avg loss: 0.10278394067315547		[learning rate: 0.0020654]
	Learning Rate: 0.00206538
	LOSS [training: 0.10278394067315547 | validation: 0.06133917335287152]
	TIME [epoch: 19 sec]
EPOCH 154/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07710313975443747		[learning rate: 0.0020339]
	Learning Rate: 0.00203392
	LOSS [training: 0.07710313975443747 | validation: 0.06288239364585249]
	TIME [epoch: 19 sec]
EPOCH 155/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08502909749571075		[learning rate: 0.0020029]
	Learning Rate: 0.00200293
	LOSS [training: 0.08502909749571075 | validation: 0.06834390446674185]
	TIME [epoch: 19 sec]
EPOCH 156/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06454663975252353		[learning rate: 0.0019724]
	Learning Rate: 0.00197242
	LOSS [training: 0.06454663975252353 | validation: 0.10089778906977478]
	TIME [epoch: 19 sec]
EPOCH 157/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08903602892207763		[learning rate: 0.0019424]
	Learning Rate: 0.00194238
	LOSS [training: 0.08903602892207763 | validation: 0.08061946911902507]
	TIME [epoch: 19 sec]
EPOCH 158/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06807508525510998		[learning rate: 0.0019128]
	Learning Rate: 0.00191279
	LOSS [training: 0.06807508525510998 | validation: 0.048962909485160425]
	TIME [epoch: 19 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_158.pth
	Model improved!!!
EPOCH 159/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07004760995495275		[learning rate: 0.0018836]
	Learning Rate: 0.00188365
	LOSS [training: 0.07004760995495275 | validation: 0.05045486046705035]
	TIME [epoch: 19 sec]
EPOCH 160/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06629923846212656		[learning rate: 0.001855]
	Learning Rate: 0.00185495
	LOSS [training: 0.06629923846212656 | validation: 0.12290996374949296]
	TIME [epoch: 19 sec]
EPOCH 161/500:
	Training over batches...
		[batch 4/4] avg loss: 0.09625005591204698		[learning rate: 0.0018267]
	Learning Rate: 0.0018267
	LOSS [training: 0.09625005591204698 | validation: 0.05837863298822853]
	TIME [epoch: 18.9 sec]
EPOCH 162/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07280566387264206		[learning rate: 0.0017989]
	Learning Rate: 0.00179887
	LOSS [training: 0.07280566387264206 | validation: 0.06076415459141091]
	TIME [epoch: 19 sec]
EPOCH 163/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06339097523992622		[learning rate: 0.0017715]
	Learning Rate: 0.00177147
	LOSS [training: 0.06339097523992622 | validation: 0.08126109765516126]
	TIME [epoch: 18.9 sec]
EPOCH 164/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0698359938213729		[learning rate: 0.0017445]
	Learning Rate: 0.00174448
	LOSS [training: 0.0698359938213729 | validation: 0.050825449654199814]
	TIME [epoch: 19 sec]
EPOCH 165/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06538519446630975		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: 0.06538519446630975 | validation: 0.05674362366147836]
	TIME [epoch: 18.9 sec]
EPOCH 166/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06040506609657466		[learning rate: 0.0016917]
	Learning Rate: 0.00169174
	LOSS [training: 0.06040506609657466 | validation: 0.06152339088986543]
	TIME [epoch: 19 sec]
EPOCH 167/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06361891717422585		[learning rate: 0.001666]
	Learning Rate: 0.00166597
	LOSS [training: 0.06361891717422585 | validation: 0.05471690330362824]
	TIME [epoch: 18.9 sec]
EPOCH 168/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06819128388880502		[learning rate: 0.0016406]
	Learning Rate: 0.00164059
	LOSS [training: 0.06819128388880502 | validation: 0.05886141305487434]
	TIME [epoch: 19 sec]
EPOCH 169/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07277972109185857		[learning rate: 0.0016156]
	Learning Rate: 0.0016156
	LOSS [training: 0.07277972109185857 | validation: 0.06886577063048796]
	TIME [epoch: 19 sec]
EPOCH 170/500:
	Training over batches...
		[batch 4/4] avg loss: 0.058852934798047624		[learning rate: 0.001591]
	Learning Rate: 0.00159099
	LOSS [training: 0.058852934798047624 | validation: 0.09039659030911124]
	TIME [epoch: 19 sec]
EPOCH 171/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08103133935381465		[learning rate: 0.0015668]
	Learning Rate: 0.00156675
	LOSS [training: 0.08103133935381465 | validation: 0.05473911645941281]
	TIME [epoch: 19 sec]
EPOCH 172/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06814291592506798		[learning rate: 0.0015429]
	Learning Rate: 0.00154288
	LOSS [training: 0.06814291592506798 | validation: 0.0506827947668143]
	TIME [epoch: 19 sec]
EPOCH 173/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06333905233367901		[learning rate: 0.0015194]
	Learning Rate: 0.00151938
	LOSS [training: 0.06333905233367901 | validation: 0.06684981086075936]
	TIME [epoch: 19 sec]
EPOCH 174/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06395357236744931		[learning rate: 0.0014962]
	Learning Rate: 0.00149624
	LOSS [training: 0.06395357236744931 | validation: 0.07565484944057739]
	TIME [epoch: 19 sec]
EPOCH 175/500:
	Training over batches...
		[batch 4/4] avg loss: 0.065732211836421		[learning rate: 0.0014734]
	Learning Rate: 0.00147344
	LOSS [training: 0.065732211836421 | validation: 0.0686255171803894]
	TIME [epoch: 19 sec]
EPOCH 176/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06754673211608805		[learning rate: 0.001451]
	Learning Rate: 0.001451
	LOSS [training: 0.06754673211608805 | validation: 0.05625123871803647]
	TIME [epoch: 18.9 sec]
EPOCH 177/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05900909618157905		[learning rate: 0.0014289]
	Learning Rate: 0.00142889
	LOSS [training: 0.05900909618157905 | validation: 0.07126326035727037]
	TIME [epoch: 19.1 sec]
EPOCH 178/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06026512773636847		[learning rate: 0.0014071]
	Learning Rate: 0.00140713
	LOSS [training: 0.06026512773636847 | validation: 0.0880866673941769]
	TIME [epoch: 18.9 sec]
EPOCH 179/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0730300818234604		[learning rate: 0.0013857]
	Learning Rate: 0.00138569
	LOSS [training: 0.0730300818234604 | validation: 0.051357147856892604]
	TIME [epoch: 19 sec]
EPOCH 180/500:
	Training over batches...
		[batch 4/4] avg loss: 0.053843103889908484		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: 0.053843103889908484 | validation: 0.051642547126446975]
	TIME [epoch: 18.9 sec]
EPOCH 181/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0711058545775035		[learning rate: 0.0013438]
	Learning Rate: 0.0013438
	LOSS [training: 0.0711058545775035 | validation: 0.06053950821206755]
	TIME [epoch: 19 sec]
EPOCH 182/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05595750240979419		[learning rate: 0.0013233]
	Learning Rate: 0.00132333
	LOSS [training: 0.05595750240979419 | validation: 0.05330006704633697]
	TIME [epoch: 18.9 sec]
EPOCH 183/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05465940184259448		[learning rate: 0.0013032]
	Learning Rate: 0.00130317
	LOSS [training: 0.05465940184259448 | validation: 0.041197168425239294]
	TIME [epoch: 19 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_183.pth
	Model improved!!!
EPOCH 184/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05494021485808086		[learning rate: 0.0012833]
	Learning Rate: 0.00128332
	LOSS [training: 0.05494021485808086 | validation: 0.05302511468639046]
	TIME [epoch: 19 sec]
EPOCH 185/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06102603499402052		[learning rate: 0.0012638]
	Learning Rate: 0.00126377
	LOSS [training: 0.06102603499402052 | validation: 0.044339440178873826]
	TIME [epoch: 19 sec]
EPOCH 186/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05452964305740503		[learning rate: 0.0012445]
	Learning Rate: 0.00124451
	LOSS [training: 0.05452964305740503 | validation: 0.03891427286804642]
	TIME [epoch: 19 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_186.pth
	Model improved!!!
EPOCH 187/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05078028149575382		[learning rate: 0.0012256]
	Learning Rate: 0.00122556
	LOSS [training: 0.05078028149575382 | validation: 0.04111398195283899]
	TIME [epoch: 19 sec]
EPOCH 188/500:
	Training over batches...
		[batch 4/4] avg loss: 0.049402607178170105		[learning rate: 0.0012069]
	Learning Rate: 0.00120689
	LOSS [training: 0.049402607178170105 | validation: 0.046494337227731525]
	TIME [epoch: 18.9 sec]
EPOCH 189/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04709859271225844		[learning rate: 0.0011885]
	Learning Rate: 0.0011885
	LOSS [training: 0.04709859271225844 | validation: 0.03735215963940286]
	TIME [epoch: 19 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_189.pth
	Model improved!!!
EPOCH 190/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05640934176555473		[learning rate: 0.0011704]
	Learning Rate: 0.0011704
	LOSS [training: 0.05640934176555473 | validation: 0.039708976399614605]
	TIME [epoch: 19 sec]
EPOCH 191/500:
	Training over batches...
		[batch 4/4] avg loss: 0.046615970558131756		[learning rate: 0.0011526]
	Learning Rate: 0.00115257
	LOSS [training: 0.046615970558131756 | validation: 0.043095681203449004]
	TIME [epoch: 19 sec]
EPOCH 192/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0464419500161295		[learning rate: 0.001135]
	Learning Rate: 0.00113501
	LOSS [training: 0.0464419500161295 | validation: 0.04413463698339604]
	TIME [epoch: 19 sec]
EPOCH 193/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05295335700560951		[learning rate: 0.0011177]
	Learning Rate: 0.00111772
	LOSS [training: 0.05295335700560951 | validation: 0.0512531367870833]
	TIME [epoch: 19 sec]
EPOCH 194/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06190776343325842		[learning rate: 0.0011007]
	Learning Rate: 0.00110069
	LOSS [training: 0.06190776343325842 | validation: 0.05733266708396914]
	TIME [epoch: 19.1 sec]
EPOCH 195/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05181658604910228		[learning rate: 0.0010839]
	Learning Rate: 0.00108393
	LOSS [training: 0.05181658604910228 | validation: 0.04399087828408644]
	TIME [epoch: 19 sec]
EPOCH 196/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04665015387927031		[learning rate: 0.0010674]
	Learning Rate: 0.00106741
	LOSS [training: 0.04665015387927031 | validation: 0.042884076724500175]
	TIME [epoch: 19.1 sec]
EPOCH 197/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04755038736316175		[learning rate: 0.0010512]
	Learning Rate: 0.00105115
	LOSS [training: 0.04755038736316175 | validation: 0.03946137864068006]
	TIME [epoch: 19 sec]
EPOCH 198/500:
	Training over batches...
		[batch 4/4] avg loss: 0.054033833177058246		[learning rate: 0.0010351]
	Learning Rate: 0.00103514
	LOSS [training: 0.054033833177058246 | validation: 0.048743418114328085]
	TIME [epoch: 19.1 sec]
EPOCH 199/500:
	Training over batches...
		[batch 4/4] avg loss: 0.054907171447267436		[learning rate: 0.0010194]
	Learning Rate: 0.00101937
	LOSS [training: 0.054907171447267436 | validation: 0.041058460949988204]
	TIME [epoch: 19 sec]
EPOCH 200/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07687031485294485		[learning rate: 0.0010038]
	Learning Rate: 0.00100384
	LOSS [training: 0.07687031485294485 | validation: 0.06908762932372414]
	TIME [epoch: 19.1 sec]
EPOCH 201/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05800992965813057		[learning rate: 0.00098855]
	Learning Rate: 0.000988553
	LOSS [training: 0.05800992965813057 | validation: 0.05242697298045455]
	TIME [epoch: 19.1 sec]
EPOCH 202/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06087546705719475		[learning rate: 0.00097349]
	Learning Rate: 0.000973494
	LOSS [training: 0.06087546705719475 | validation: 0.055317131509304944]
	TIME [epoch: 19.1 sec]
EPOCH 203/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05065158521400964		[learning rate: 0.00095866]
	Learning Rate: 0.000958664
	LOSS [training: 0.05065158521400964 | validation: 0.037460609882823015]
	TIME [epoch: 19 sec]
EPOCH 204/500:
	Training over batches...
		[batch 4/4] avg loss: 0.042510193464687464		[learning rate: 0.00094406]
	Learning Rate: 0.000944061
	LOSS [training: 0.042510193464687464 | validation: 0.03820064064017015]
	TIME [epoch: 19.1 sec]
EPOCH 205/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04579403527792774		[learning rate: 0.00092968]
	Learning Rate: 0.00092968
	LOSS [training: 0.04579403527792774 | validation: 0.04442199980426524]
	TIME [epoch: 19.1 sec]
EPOCH 206/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0437014797815945		[learning rate: 0.00091552]
	Learning Rate: 0.000915518
	LOSS [training: 0.0437014797815945 | validation: 0.04919214380603157]
	TIME [epoch: 19.1 sec]
EPOCH 207/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04835521751702894		[learning rate: 0.00090157]
	Learning Rate: 0.000901571
	LOSS [training: 0.04835521751702894 | validation: 0.05517934742206518]
	TIME [epoch: 19.1 sec]
EPOCH 208/500:
	Training over batches...
		[batch 4/4] avg loss: 0.051914945209767915		[learning rate: 0.00088784]
	Learning Rate: 0.000887837
	LOSS [training: 0.051914945209767915 | validation: 0.05658522160903138]
	TIME [epoch: 19.1 sec]
EPOCH 209/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05122053634326808		[learning rate: 0.00087431]
	Learning Rate: 0.000874312
	LOSS [training: 0.05122053634326808 | validation: 0.034565551258515737]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_209.pth
	Model improved!!!
EPOCH 210/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04269208236400465		[learning rate: 0.00086099]
	Learning Rate: 0.000860994
	LOSS [training: 0.04269208236400465 | validation: 0.05118564306385209]
	TIME [epoch: 19.1 sec]
EPOCH 211/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04712043577671663		[learning rate: 0.00084788]
	Learning Rate: 0.000847878
	LOSS [training: 0.04712043577671663 | validation: 0.046896701413718954]
	TIME [epoch: 19.1 sec]
EPOCH 212/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04571328672245082		[learning rate: 0.00083496]
	Learning Rate: 0.000834962
	LOSS [training: 0.04571328672245082 | validation: 0.025229585015837327]
	TIME [epoch: 19 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_212.pth
	Model improved!!!
EPOCH 213/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04527335047934737		[learning rate: 0.00082224]
	Learning Rate: 0.000822243
	LOSS [training: 0.04527335047934737 | validation: 0.04379809428779652]
	TIME [epoch: 19.1 sec]
EPOCH 214/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04412206309264334		[learning rate: 0.00080972]
	Learning Rate: 0.000809717
	LOSS [training: 0.04412206309264334 | validation: 0.03679498745383716]
	TIME [epoch: 19.1 sec]
EPOCH 215/500:
	Training over batches...
		[batch 4/4] avg loss: 0.048314076066861854		[learning rate: 0.00079738]
	Learning Rate: 0.000797382
	LOSS [training: 0.048314076066861854 | validation: 0.0456000251050847]
	TIME [epoch: 19.1 sec]
EPOCH 216/500:
	Training over batches...
		[batch 4/4] avg loss: 0.042882934046350546		[learning rate: 0.00078524]
	Learning Rate: 0.000785236
	LOSS [training: 0.042882934046350546 | validation: 0.04307221381583607]
	TIME [epoch: 19.1 sec]
EPOCH 217/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04706813713204449		[learning rate: 0.00077327]
	Learning Rate: 0.000773274
	LOSS [training: 0.04706813713204449 | validation: 0.0554100321419648]
	TIME [epoch: 19.1 sec]
EPOCH 218/500:
	Training over batches...
		[batch 4/4] avg loss: 0.046351301367439326		[learning rate: 0.00076149]
	Learning Rate: 0.000761494
	LOSS [training: 0.046351301367439326 | validation: 0.06051687721032292]
	TIME [epoch: 19.1 sec]
EPOCH 219/500:
	Training over batches...
		[batch 4/4] avg loss: 0.042503954098139625		[learning rate: 0.00074989]
	Learning Rate: 0.000749894
	LOSS [training: 0.042503954098139625 | validation: 0.032802530074149364]
	TIME [epoch: 19.1 sec]
EPOCH 220/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03986132672741129		[learning rate: 0.00073847]
	Learning Rate: 0.000738471
	LOSS [training: 0.03986132672741129 | validation: 0.04722287531852834]
	TIME [epoch: 19 sec]
EPOCH 221/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04673304873344606		[learning rate: 0.00072722]
	Learning Rate: 0.000727221
	LOSS [training: 0.04673304873344606 | validation: 0.04378113132405168]
	TIME [epoch: 19.1 sec]
EPOCH 222/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04401794294853406		[learning rate: 0.00071614]
	Learning Rate: 0.000716143
	LOSS [training: 0.04401794294853406 | validation: 0.03906347668839455]
	TIME [epoch: 19.1 sec]
EPOCH 223/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0401352580299801		[learning rate: 0.00070523]
	Learning Rate: 0.000705234
	LOSS [training: 0.0401352580299801 | validation: 0.03507015130402741]
	TIME [epoch: 19.1 sec]
EPOCH 224/500:
	Training over batches...
		[batch 4/4] avg loss: 0.038112995818262156		[learning rate: 0.00069449]
	Learning Rate: 0.000694491
	LOSS [training: 0.038112995818262156 | validation: 0.03487593214179663]
	TIME [epoch: 19.1 sec]
EPOCH 225/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03935680674644727		[learning rate: 0.00068391]
	Learning Rate: 0.000683912
	LOSS [training: 0.03935680674644727 | validation: 0.043212817874062046]
	TIME [epoch: 19.1 sec]
EPOCH 226/500:
	Training over batches...
		[batch 4/4] avg loss: 0.039306389268763016		[learning rate: 0.00067349]
	Learning Rate: 0.000673493
	LOSS [training: 0.039306389268763016 | validation: 0.029471447721418315]
	TIME [epoch: 19.1 sec]
EPOCH 227/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03832341225203906		[learning rate: 0.00066323]
	Learning Rate: 0.000663234
	LOSS [training: 0.03832341225203906 | validation: 0.045988949095421464]
	TIME [epoch: 19.1 sec]
EPOCH 228/500:
	Training over batches...
		[batch 4/4] avg loss: 0.035317943629367035		[learning rate: 0.00065313]
	Learning Rate: 0.00065313
	LOSS [training: 0.035317943629367035 | validation: 0.040319780426853566]
	TIME [epoch: 19.1 sec]
EPOCH 229/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03808710673813561		[learning rate: 0.00064318]
	Learning Rate: 0.000643181
	LOSS [training: 0.03808710673813561 | validation: 0.033154713484013096]
	TIME [epoch: 19.1 sec]
EPOCH 230/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03563452539147949		[learning rate: 0.00063338]
	Learning Rate: 0.000633383
	LOSS [training: 0.03563452539147949 | validation: 0.03603160135942611]
	TIME [epoch: 19.1 sec]
EPOCH 231/500:
	Training over batches...
		[batch 4/4] avg loss: 0.031000414561691683		[learning rate: 0.00062373]
	Learning Rate: 0.000623735
	LOSS [training: 0.031000414561691683 | validation: 0.030350955431562514]
	TIME [epoch: 19 sec]
EPOCH 232/500:
	Training over batches...
		[batch 4/4] avg loss: 0.037939379030781914		[learning rate: 0.00061423]
	Learning Rate: 0.000614233
	LOSS [training: 0.037939379030781914 | validation: 0.035692219548377535]
	TIME [epoch: 19.1 sec]
EPOCH 233/500:
	Training over batches...
		[batch 4/4] avg loss: 0.031074929998212642		[learning rate: 0.00060488]
	Learning Rate: 0.000604876
	LOSS [training: 0.031074929998212642 | validation: 0.03293571831916472]
	TIME [epoch: 19 sec]
EPOCH 234/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03519962483666934		[learning rate: 0.00059566]
	Learning Rate: 0.000595662
	LOSS [training: 0.03519962483666934 | validation: 0.02679203894523578]
	TIME [epoch: 19 sec]
EPOCH 235/500:
	Training over batches...
		[batch 4/4] avg loss: 0.038034604384535126		[learning rate: 0.00058659]
	Learning Rate: 0.000586588
	LOSS [training: 0.038034604384535126 | validation: 0.03872169051847807]
	TIME [epoch: 19.1 sec]
EPOCH 236/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03564397901341116		[learning rate: 0.00057765]
	Learning Rate: 0.000577652
	LOSS [training: 0.03564397901341116 | validation: 0.02987312291142039]
	TIME [epoch: 19.1 sec]
EPOCH 237/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03585554406047578		[learning rate: 0.00056885]
	Learning Rate: 0.000568853
	LOSS [training: 0.03585554406047578 | validation: 0.03599994448941882]
	TIME [epoch: 19 sec]
EPOCH 238/500:
	Training over batches...
		[batch 4/4] avg loss: 0.034575552319971906		[learning rate: 0.00056019]
	Learning Rate: 0.000560187
	LOSS [training: 0.034575552319971906 | validation: 0.034919378156323615]
	TIME [epoch: 19.1 sec]
EPOCH 239/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03455336404526926		[learning rate: 0.00055165]
	Learning Rate: 0.000551654
	LOSS [training: 0.03455336404526926 | validation: 0.025667425667371346]
	TIME [epoch: 19 sec]
EPOCH 240/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03400473380023974		[learning rate: 0.00054325]
	Learning Rate: 0.00054325
	LOSS [training: 0.03400473380023974 | validation: 0.02540780977177298]
	TIME [epoch: 19.1 sec]
EPOCH 241/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03193758086067714		[learning rate: 0.00053497]
	Learning Rate: 0.000534975
	LOSS [training: 0.03193758086067714 | validation: 0.02727212423113627]
	TIME [epoch: 19 sec]
EPOCH 242/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03351839573026017		[learning rate: 0.00052683]
	Learning Rate: 0.000526825
	LOSS [training: 0.03351839573026017 | validation: 0.028863702957396986]
	TIME [epoch: 19.1 sec]
EPOCH 243/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03348208373651117		[learning rate: 0.0005188]
	Learning Rate: 0.0005188
	LOSS [training: 0.03348208373651117 | validation: 0.030162330427627504]
	TIME [epoch: 19.1 sec]
EPOCH 244/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029679120578976197		[learning rate: 0.0005109]
	Learning Rate: 0.000510897
	LOSS [training: 0.029679120578976197 | validation: 0.03300655234486054]
	TIME [epoch: 19.1 sec]
EPOCH 245/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04169761417341454		[learning rate: 0.00050311]
	Learning Rate: 0.000503114
	LOSS [training: 0.04169761417341454 | validation: 0.02028091143342884]
	TIME [epoch: 19 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_245.pth
	Model improved!!!
EPOCH 246/500:
	Training over batches...
		[batch 4/4] avg loss: 0.032869312643615686		[learning rate: 0.00049545]
	Learning Rate: 0.00049545
	LOSS [training: 0.032869312643615686 | validation: 0.04139472974736272]
	TIME [epoch: 19.1 sec]
EPOCH 247/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03344150373404209		[learning rate: 0.0004879]
	Learning Rate: 0.000487903
	LOSS [training: 0.03344150373404209 | validation: 0.02692442156128714]
	TIME [epoch: 19.1 sec]
EPOCH 248/500:
	Training over batches...
		[batch 4/4] avg loss: 0.035268544534458914		[learning rate: 0.00048047]
	Learning Rate: 0.00048047
	LOSS [training: 0.035268544534458914 | validation: 0.027027178467466127]
	TIME [epoch: 19.1 sec]
EPOCH 249/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03371400164395825		[learning rate: 0.00047315]
	Learning Rate: 0.000473151
	LOSS [training: 0.03371400164395825 | validation: 0.036151830110625824]
	TIME [epoch: 19.1 sec]
EPOCH 250/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029090933044995323		[learning rate: 0.00046594]
	Learning Rate: 0.000465944
	LOSS [training: 0.029090933044995323 | validation: 0.025155862576761456]
	TIME [epoch: 19.1 sec]
EPOCH 251/500:
	Training over batches...
		[batch 4/4] avg loss: 0.032117712405111035		[learning rate: 0.00045885]
	Learning Rate: 0.000458846
	LOSS [training: 0.032117712405111035 | validation: 0.033800873393626696]
	TIME [epoch: 145 sec]
EPOCH 252/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03220804359355259		[learning rate: 0.00045186]
	Learning Rate: 0.000451856
	LOSS [training: 0.03220804359355259 | validation: 0.03012543999911991]
	TIME [epoch: 42.2 sec]
EPOCH 253/500:
	Training over batches...
		[batch 4/4] avg loss: 0.028325064094713158		[learning rate: 0.00044497]
	Learning Rate: 0.000444973
	LOSS [training: 0.028325064094713158 | validation: 0.03930444850036089]
	TIME [epoch: 42.2 sec]
EPOCH 254/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0301697436068816		[learning rate: 0.00043819]
	Learning Rate: 0.000438194
	LOSS [training: 0.0301697436068816 | validation: 0.04347048046689158]
	TIME [epoch: 42.3 sec]
EPOCH 255/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04316467060040415		[learning rate: 0.00043152]
	Learning Rate: 0.000431519
	LOSS [training: 0.04316467060040415 | validation: 0.05449433589564217]
	TIME [epoch: 42.2 sec]
EPOCH 256/500:
	Training over batches...
		[batch 4/4] avg loss: 0.037290507216952616		[learning rate: 0.00042495]
	Learning Rate: 0.000424946
	LOSS [training: 0.037290507216952616 | validation: 0.03562296450233816]
	TIME [epoch: 42.3 sec]
EPOCH 257/500:
	Training over batches...
		[batch 4/4] avg loss: 0.030529345048469426		[learning rate: 0.00041847]
	Learning Rate: 0.000418472
	LOSS [training: 0.030529345048469426 | validation: 0.035631196306265156]
	TIME [epoch: 42.3 sec]
EPOCH 258/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03932759585119412		[learning rate: 0.0004121]
	Learning Rate: 0.000412098
	LOSS [training: 0.03932759585119412 | validation: 0.039484820896543246]
	TIME [epoch: 42.3 sec]
EPOCH 259/500:
	Training over batches...
		[batch 4/4] avg loss: 0.030622352431195196		[learning rate: 0.00040582]
	Learning Rate: 0.00040582
	LOSS [training: 0.030622352431195196 | validation: 0.032044119885381396]
	TIME [epoch: 42.3 sec]
EPOCH 260/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03007884016597119		[learning rate: 0.00039964]
	Learning Rate: 0.000399638
	LOSS [training: 0.03007884016597119 | validation: 0.03177870819754225]
	TIME [epoch: 42.3 sec]
EPOCH 261/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03239541850673022		[learning rate: 0.00039355]
	Learning Rate: 0.00039355
	LOSS [training: 0.03239541850673022 | validation: 0.02852652390219635]
	TIME [epoch: 42.3 sec]
EPOCH 262/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03811266231711846		[learning rate: 0.00038755]
	Learning Rate: 0.000387555
	LOSS [training: 0.03811266231711846 | validation: 0.027894121899986413]
	TIME [epoch: 42.3 sec]
EPOCH 263/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029636136991598224		[learning rate: 0.00038165]
	Learning Rate: 0.000381651
	LOSS [training: 0.029636136991598224 | validation: 0.038660602128761684]
	TIME [epoch: 42.3 sec]
EPOCH 264/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03978643345323446		[learning rate: 0.00037584]
	Learning Rate: 0.000375837
	LOSS [training: 0.03978643345323446 | validation: 0.036490252204335605]
	TIME [epoch: 42.3 sec]
EPOCH 265/500:
	Training over batches...
		[batch 4/4] avg loss: 0.030403681559030477		[learning rate: 0.00037011]
	Learning Rate: 0.000370112
	LOSS [training: 0.030403681559030477 | validation: 0.024643595658642357]
	TIME [epoch: 42.3 sec]
EPOCH 266/500:
	Training over batches...
		[batch 4/4] avg loss: 0.028217136680372255		[learning rate: 0.00036447]
	Learning Rate: 0.000364474
	LOSS [training: 0.028217136680372255 | validation: 0.032220655800226476]
	TIME [epoch: 42.3 sec]
EPOCH 267/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02528745356522727		[learning rate: 0.00035892]
	Learning Rate: 0.000358922
	LOSS [training: 0.02528745356522727 | validation: 0.029430005848635553]
	TIME [epoch: 42.3 sec]
EPOCH 268/500:
	Training over batches...
		[batch 4/4] avg loss: 0.030233890464656663		[learning rate: 0.00035345]
	Learning Rate: 0.000353454
	LOSS [training: 0.030233890464656663 | validation: 0.028409277687352665]
	TIME [epoch: 42.3 sec]
EPOCH 269/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025983235883546105		[learning rate: 0.00034807]
	Learning Rate: 0.00034807
	LOSS [training: 0.025983235883546105 | validation: 0.0191364721895595]
	TIME [epoch: 42.3 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_269.pth
	Model improved!!!
EPOCH 270/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0320923399287299		[learning rate: 0.00034277]
	Learning Rate: 0.000342768
	LOSS [training: 0.0320923399287299 | validation: 0.019876842007855895]
	TIME [epoch: 42.3 sec]
EPOCH 271/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027824127887273755		[learning rate: 0.00033755]
	Learning Rate: 0.000337546
	LOSS [training: 0.027824127887273755 | validation: 0.024256851168940337]
	TIME [epoch: 42.3 sec]
EPOCH 272/500:
	Training over batches...
		[batch 4/4] avg loss: 0.030983464083609434		[learning rate: 0.0003324]
	Learning Rate: 0.000332404
	LOSS [training: 0.030983464083609434 | validation: 0.029474946176162066]
	TIME [epoch: 42.2 sec]
EPOCH 273/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02889602664941304		[learning rate: 0.00032734]
	Learning Rate: 0.000327341
	LOSS [training: 0.02889602664941304 | validation: 0.0341479038697943]
	TIME [epoch: 42.3 sec]
EPOCH 274/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03213107720372295		[learning rate: 0.00032235]
	Learning Rate: 0.000322354
	LOSS [training: 0.03213107720372295 | validation: 0.02540125737719877]
	TIME [epoch: 42.3 sec]
EPOCH 275/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029788304529342603		[learning rate: 0.00031744]
	Learning Rate: 0.000317444
	LOSS [training: 0.029788304529342603 | validation: 0.028488841568342395]
	TIME [epoch: 42.2 sec]
EPOCH 276/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02659926749869369		[learning rate: 0.00031261]
	Learning Rate: 0.000312608
	LOSS [training: 0.02659926749869369 | validation: 0.025455124615896628]
	TIME [epoch: 42.3 sec]
EPOCH 277/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02644980445920805		[learning rate: 0.00030785]
	Learning Rate: 0.000307846
	LOSS [training: 0.02644980445920805 | validation: 0.0250473396978858]
	TIME [epoch: 42.3 sec]
EPOCH 278/500:
	Training over batches...
		[batch 4/4] avg loss: 0.039889097348394104		[learning rate: 0.00030316]
	Learning Rate: 0.000303156
	LOSS [training: 0.039889097348394104 | validation: 0.04231950194559608]
	TIME [epoch: 42.3 sec]
EPOCH 279/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03128065620903608		[learning rate: 0.00029854]
	Learning Rate: 0.000298538
	LOSS [training: 0.03128065620903608 | validation: 0.024117094013321107]
	TIME [epoch: 42.3 sec]
EPOCH 280/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026311035707869523		[learning rate: 0.00029399]
	Learning Rate: 0.000293991
	LOSS [training: 0.026311035707869523 | validation: 0.02494006341889487]
	TIME [epoch: 42.3 sec]
EPOCH 281/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02819044750248821		[learning rate: 0.00028951]
	Learning Rate: 0.000289512
	LOSS [training: 0.02819044750248821 | validation: 0.017879609788472115]
	TIME [epoch: 42.3 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_281.pth
	Model improved!!!
EPOCH 282/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027264741740777927		[learning rate: 0.0002851]
	Learning Rate: 0.000285102
	LOSS [training: 0.027264741740777927 | validation: 0.027450862316393022]
	TIME [epoch: 42.4 sec]
EPOCH 283/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027689960762759137		[learning rate: 0.00028076]
	Learning Rate: 0.000280759
	LOSS [training: 0.027689960762759137 | validation: 0.026608828720256723]
	TIME [epoch: 42.3 sec]
EPOCH 284/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02782796623704284		[learning rate: 0.00027648]
	Learning Rate: 0.000276482
	LOSS [training: 0.02782796623704284 | validation: 0.017169313792670657]
	TIME [epoch: 42.4 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_284.pth
	Model improved!!!
EPOCH 285/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025145837392708918		[learning rate: 0.00027227]
	Learning Rate: 0.00027227
	LOSS [training: 0.025145837392708918 | validation: 0.02570784351005128]
	TIME [epoch: 42.3 sec]
EPOCH 286/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026860163495755072		[learning rate: 0.00026812]
	Learning Rate: 0.000268123
	LOSS [training: 0.026860163495755072 | validation: 0.03170324023318238]
	TIME [epoch: 42.3 sec]
EPOCH 287/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027470782442625727		[learning rate: 0.00026404]
	Learning Rate: 0.000264038
	LOSS [training: 0.027470782442625727 | validation: 0.02571285113028562]
	TIME [epoch: 42.3 sec]
EPOCH 288/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02437196358614233		[learning rate: 0.00026002]
	Learning Rate: 0.000260016
	LOSS [training: 0.02437196358614233 | validation: 0.01609222235667838]
	TIME [epoch: 42.4 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_288.pth
	Model improved!!!
EPOCH 289/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02129533853097654		[learning rate: 0.00025606]
	Learning Rate: 0.000256055
	LOSS [training: 0.02129533853097654 | validation: 0.0216012847073628]
	TIME [epoch: 42.3 sec]
EPOCH 290/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025727644259542534		[learning rate: 0.00025215]
	Learning Rate: 0.000252154
	LOSS [training: 0.025727644259542534 | validation: 0.01614565893913735]
	TIME [epoch: 42.3 sec]
EPOCH 291/500:
	Training over batches...
		[batch 4/4] avg loss: 0.024152461948983097		[learning rate: 0.00024831]
	Learning Rate: 0.000248313
	LOSS [training: 0.024152461948983097 | validation: 0.024339978641008245]
	TIME [epoch: 42.3 sec]
EPOCH 292/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025157656305818423		[learning rate: 0.00024453]
	Learning Rate: 0.000244531
	LOSS [training: 0.025157656305818423 | validation: 0.03162583783838434]
	TIME [epoch: 42.3 sec]
EPOCH 293/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023459060101850046		[learning rate: 0.00024081]
	Learning Rate: 0.000240806
	LOSS [training: 0.023459060101850046 | validation: 0.01722110523306124]
	TIME [epoch: 42.3 sec]
EPOCH 294/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02325220554386359		[learning rate: 0.00023714]
	Learning Rate: 0.000237137
	LOSS [training: 0.02325220554386359 | validation: 0.025207881539903186]
	TIME [epoch: 42.3 sec]
EPOCH 295/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025906239747934864		[learning rate: 0.00023352]
	Learning Rate: 0.000233525
	LOSS [training: 0.025906239747934864 | validation: 0.025893506444054068]
	TIME [epoch: 42.3 sec]
EPOCH 296/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023714184005811247		[learning rate: 0.00022997]
	Learning Rate: 0.000229968
	LOSS [training: 0.023714184005811247 | validation: 0.02845555474277138]
	TIME [epoch: 42.3 sec]
EPOCH 297/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02194087218436811		[learning rate: 0.00022646]
	Learning Rate: 0.000226464
	LOSS [training: 0.02194087218436811 | validation: 0.024414315945261802]
	TIME [epoch: 42.3 sec]
EPOCH 298/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027697563548876116		[learning rate: 0.00022301]
	Learning Rate: 0.000223015
	LOSS [training: 0.027697563548876116 | validation: 0.011816540180372603]
	TIME [epoch: 42.3 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_298.pth
	Model improved!!!
EPOCH 299/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020172902293486946		[learning rate: 0.00021962]
	Learning Rate: 0.000219617
	LOSS [training: 0.020172902293486946 | validation: 0.017160634290216255]
	TIME [epoch: 42.3 sec]
EPOCH 300/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02105342068996446		[learning rate: 0.00021627]
	Learning Rate: 0.000216272
	LOSS [training: 0.02105342068996446 | validation: 0.02572944766611437]
	TIME [epoch: 42.3 sec]
EPOCH 301/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02505859870310155		[learning rate: 0.00021298]
	Learning Rate: 0.000212977
	LOSS [training: 0.02505859870310155 | validation: 0.02824474118554631]
	TIME [epoch: 42.3 sec]
EPOCH 302/500:
	Training over batches...
		[batch 4/4] avg loss: 0.021111216124214495		[learning rate: 0.00020973]
	Learning Rate: 0.000209733
	LOSS [training: 0.021111216124214495 | validation: 0.018407611054384373]
	TIME [epoch: 42.3 sec]
EPOCH 303/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025276982424626802		[learning rate: 0.00020654]
	Learning Rate: 0.000206538
	LOSS [training: 0.025276982424626802 | validation: 0.022183819253702518]
	TIME [epoch: 42.3 sec]
EPOCH 304/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02698448567988663		[learning rate: 0.00020339]
	Learning Rate: 0.000203392
	LOSS [training: 0.02698448567988663 | validation: 0.022274719953144825]
	TIME [epoch: 42.3 sec]
EPOCH 305/500:
	Training over batches...
		[batch 4/4] avg loss: 0.022278111485669272		[learning rate: 0.00020029]
	Learning Rate: 0.000200293
	LOSS [training: 0.022278111485669272 | validation: 0.022500426334749087]
	TIME [epoch: 42.3 sec]
EPOCH 306/500:
	Training over batches...
		[batch 4/4] avg loss: 0.024763952446765915		[learning rate: 0.00019724]
	Learning Rate: 0.000197242
	LOSS [training: 0.024763952446765915 | validation: 0.023677702764957037]
	TIME [epoch: 42.3 sec]
EPOCH 307/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02141010017032892		[learning rate: 0.00019424]
	Learning Rate: 0.000194238
	LOSS [training: 0.02141010017032892 | validation: 0.0310677173828025]
	TIME [epoch: 42.3 sec]
EPOCH 308/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026646439500130965		[learning rate: 0.00019128]
	Learning Rate: 0.000191279
	LOSS [training: 0.026646439500130965 | validation: 0.024449369617681113]
	TIME [epoch: 42.4 sec]
EPOCH 309/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02683053254235546		[learning rate: 0.00018836]
	Learning Rate: 0.000188365
	LOSS [training: 0.02683053254235546 | validation: 0.022983320759133574]
	TIME [epoch: 42.3 sec]
EPOCH 310/500:
	Training over batches...
		[batch 4/4] avg loss: 0.022092386552204975		[learning rate: 0.0001855]
	Learning Rate: 0.000185495
	LOSS [training: 0.022092386552204975 | validation: 0.020259219733996633]
	TIME [epoch: 42.3 sec]
EPOCH 311/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020278491320371368		[learning rate: 0.00018267]
	Learning Rate: 0.00018267
	LOSS [training: 0.020278491320371368 | validation: 0.025033199716276263]
	TIME [epoch: 42.3 sec]
EPOCH 312/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02413636921950306		[learning rate: 0.00017989]
	Learning Rate: 0.000179887
	LOSS [training: 0.02413636921950306 | validation: 0.02539392439257985]
	TIME [epoch: 42.3 sec]
EPOCH 313/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02157320333041995		[learning rate: 0.00017715]
	Learning Rate: 0.000177147
	LOSS [training: 0.02157320333041995 | validation: 0.021093040019577524]
	TIME [epoch: 42.3 sec]
EPOCH 314/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023147928808691695		[learning rate: 0.00017445]
	Learning Rate: 0.000174448
	LOSS [training: 0.023147928808691695 | validation: 0.029030633249481942]
	TIME [epoch: 42.3 sec]
EPOCH 315/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02406976926885629		[learning rate: 0.00017179]
	Learning Rate: 0.000171791
	LOSS [training: 0.02406976926885629 | validation: 0.01659223818860538]
	TIME [epoch: 42.3 sec]
EPOCH 316/500:
	Training over batches...
		[batch 4/4] avg loss: 0.022946379276208902		[learning rate: 0.00016917]
	Learning Rate: 0.000169174
	LOSS [training: 0.022946379276208902 | validation: 0.023779250848963436]
	TIME [epoch: 42.3 sec]
EPOCH 317/500:
	Training over batches...
		[batch 4/4] avg loss: 0.024053662415748755		[learning rate: 0.0001666]
	Learning Rate: 0.000166597
	LOSS [training: 0.024053662415748755 | validation: 0.024884673353270666]
	TIME [epoch: 42.3 sec]
EPOCH 318/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025754826727830176		[learning rate: 0.00016406]
	Learning Rate: 0.000164059
	LOSS [training: 0.025754826727830176 | validation: 0.019494908792699092]
	TIME [epoch: 42.3 sec]
EPOCH 319/500:
	Training over batches...
		[batch 4/4] avg loss: 0.024334672168122948		[learning rate: 0.00016156]
	Learning Rate: 0.00016156
	LOSS [training: 0.024334672168122948 | validation: 0.025740173380445118]
	TIME [epoch: 42.3 sec]
EPOCH 320/500:
	Training over batches...
		[batch 4/4] avg loss: 0.021922204716685618		[learning rate: 0.0001591]
	Learning Rate: 0.000159099
	LOSS [training: 0.021922204716685618 | validation: 0.024544816878489153]
	TIME [epoch: 42.3 sec]
EPOCH 321/500:
	Training over batches...
		[batch 4/4] avg loss: 0.021528691860425067		[learning rate: 0.00015668]
	Learning Rate: 0.000156675
	LOSS [training: 0.021528691860425067 | validation: 0.026376661970549636]
	TIME [epoch: 42.3 sec]
EPOCH 322/500:
	Training over batches...
		[batch 4/4] avg loss: 0.019740264207033432		[learning rate: 0.00015429]
	Learning Rate: 0.000154288
	LOSS [training: 0.019740264207033432 | validation: 0.02627706918576739]
	TIME [epoch: 42.3 sec]
EPOCH 323/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025511557076438554		[learning rate: 0.00015194]
	Learning Rate: 0.000151938
	LOSS [training: 0.025511557076438554 | validation: 0.02508866582632393]
	TIME [epoch: 42.3 sec]
EPOCH 324/500:
	Training over batches...
		[batch 4/4] avg loss: 0.024290325986344775		[learning rate: 0.00014962]
	Learning Rate: 0.000149624
	LOSS [training: 0.024290325986344775 | validation: 0.025272991491974303]
	TIME [epoch: 42.4 sec]
EPOCH 325/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020975733736267543		[learning rate: 0.00014734]
	Learning Rate: 0.000147344
	LOSS [training: 0.020975733736267543 | validation: 0.022435400209310112]
	TIME [epoch: 42.3 sec]
EPOCH 326/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023211057284260067		[learning rate: 0.0001451]
	Learning Rate: 0.0001451
	LOSS [training: 0.023211057284260067 | validation: 0.018266062097299546]
	TIME [epoch: 42.4 sec]
EPOCH 327/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025156078180994218		[learning rate: 0.00014289]
	Learning Rate: 0.000142889
	LOSS [training: 0.025156078180994218 | validation: 0.03343435611505152]
	TIME [epoch: 42.3 sec]
EPOCH 328/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023404330161046698		[learning rate: 0.00014071]
	Learning Rate: 0.000140713
	LOSS [training: 0.023404330161046698 | validation: 0.022432762414363816]
	TIME [epoch: 42.3 sec]
EPOCH 329/500:
	Training over batches...
		[batch 4/4] avg loss: 0.019753966703878724		[learning rate: 0.00013857]
	Learning Rate: 0.000138569
	LOSS [training: 0.019753966703878724 | validation: 0.02372297634615139]
	TIME [epoch: 42.3 sec]
EPOCH 330/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020514002540282295		[learning rate: 0.00013646]
	Learning Rate: 0.000136458
	LOSS [training: 0.020514002540282295 | validation: 0.01814539197953304]
	TIME [epoch: 42.4 sec]
EPOCH 331/500:
	Training over batches...
		[batch 4/4] avg loss: 0.024944036520820057		[learning rate: 0.00013438]
	Learning Rate: 0.00013438
	LOSS [training: 0.024944036520820057 | validation: 0.011626436437805771]
	TIME [epoch: 42.4 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_331.pth
	Model improved!!!
EPOCH 332/500:
	Training over batches...
		[batch 4/4] avg loss: 0.021750023151847445		[learning rate: 0.00013233]
	Learning Rate: 0.000132333
	LOSS [training: 0.021750023151847445 | validation: 0.020629577457451982]
	TIME [epoch: 42.3 sec]
EPOCH 333/500:
	Training over batches...
		[batch 4/4] avg loss: 0.017016692286236916		[learning rate: 0.00013032]
	Learning Rate: 0.000130317
	LOSS [training: 0.017016692286236916 | validation: 0.014300979422185384]
	TIME [epoch: 42.3 sec]
EPOCH 334/500:
	Training over batches...
		[batch 4/4] avg loss: 0.019441187398006064		[learning rate: 0.00012833]
	Learning Rate: 0.000128332
	LOSS [training: 0.019441187398006064 | validation: 0.026450494692224123]
	TIME [epoch: 42.3 sec]
EPOCH 335/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02075760690292436		[learning rate: 0.00012638]
	Learning Rate: 0.000126377
	LOSS [training: 0.02075760690292436 | validation: 0.02914236553704965]
	TIME [epoch: 42.3 sec]
EPOCH 336/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020263433640792188		[learning rate: 0.00012445]
	Learning Rate: 0.000124451
	LOSS [training: 0.020263433640792188 | validation: 0.019033504339430254]
	TIME [epoch: 42.3 sec]
EPOCH 337/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020980010221276258		[learning rate: 0.00012256]
	Learning Rate: 0.000122556
	LOSS [training: 0.020980010221276258 | validation: 0.023171437373559298]
	TIME [epoch: 42.3 sec]
EPOCH 338/500:
	Training over batches...
		[batch 4/4] avg loss: 0.024682706899184573		[learning rate: 0.00012069]
	Learning Rate: 0.000120689
	LOSS [training: 0.024682706899184573 | validation: 0.025001761848657416]
	TIME [epoch: 42.3 sec]
EPOCH 339/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02377682721464478		[learning rate: 0.00011885]
	Learning Rate: 0.00011885
	LOSS [training: 0.02377682721464478 | validation: 0.02386550860551536]
	TIME [epoch: 42.3 sec]
EPOCH 340/500:
	Training over batches...
		[batch 4/4] avg loss: 0.021580961489268496		[learning rate: 0.00011704]
	Learning Rate: 0.00011704
	LOSS [training: 0.021580961489268496 | validation: 0.021696410108252736]
	TIME [epoch: 42.3 sec]
EPOCH 341/500:
	Training over batches...
		[batch 4/4] avg loss: 0.018463557706200288		[learning rate: 0.00011526]
	Learning Rate: 0.000115257
	LOSS [training: 0.018463557706200288 | validation: 0.02186074753431532]
	TIME [epoch: 42.3 sec]
EPOCH 342/500:
	Training over batches...
		[batch 4/4] avg loss: 0.022441178686973963		[learning rate: 0.0001135]
	Learning Rate: 0.000113501
	LOSS [training: 0.022441178686973963 | validation: 0.009515558564996954]
	TIME [epoch: 42.3 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_342.pth
	Model improved!!!
EPOCH 343/500:
	Training over batches...
		[batch 4/4] avg loss: 0.017611728608008997		[learning rate: 0.00011177]
	Learning Rate: 0.000111772
	LOSS [training: 0.017611728608008997 | validation: 0.02509231375762865]
	TIME [epoch: 42.3 sec]
EPOCH 344/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02376138013029535		[learning rate: 0.00011007]
	Learning Rate: 0.000110069
	LOSS [training: 0.02376138013029535 | validation: 0.01315755074260698]
	TIME [epoch: 42.3 sec]
EPOCH 345/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02095415918273842		[learning rate: 0.00010839]
	Learning Rate: 0.000108393
	LOSS [training: 0.02095415918273842 | validation: 0.010696729080260037]
	TIME [epoch: 42.3 sec]
EPOCH 346/500:
	Training over batches...
		[batch 4/4] avg loss: 0.022969915757244528		[learning rate: 0.00010674]
	Learning Rate: 0.000106742
	LOSS [training: 0.022969915757244528 | validation: 0.03035937794648034]
	TIME [epoch: 42.3 sec]
EPOCH 347/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023119454166344762		[learning rate: 0.00010512]
	Learning Rate: 0.000105115
	LOSS [training: 0.023119454166344762 | validation: 0.01790386454315203]
	TIME [epoch: 42.3 sec]
EPOCH 348/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02361421424827078		[learning rate: 0.00010351]
	Learning Rate: 0.000103514
	LOSS [training: 0.02361421424827078 | validation: 0.027405099902204334]
	TIME [epoch: 42.3 sec]
EPOCH 349/500:
	Training over batches...
		[batch 4/4] avg loss: 0.017958528952832453		[learning rate: 0.00010194]
	Learning Rate: 0.000101937
	LOSS [training: 0.017958528952832453 | validation: 0.019967147085445083]
	TIME [epoch: 42.3 sec]
EPOCH 350/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020852335914561374		[learning rate: 0.00010038]
	Learning Rate: 0.000100385
	LOSS [training: 0.020852335914561374 | validation: 0.01864907754246657]
	TIME [epoch: 42.3 sec]
EPOCH 351/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01738371711572498		[learning rate: 9.8855e-05]
	Learning Rate: 9.88553e-05
	LOSS [training: 0.01738371711572498 | validation: 0.029378738867567294]
	TIME [epoch: 42.3 sec]
EPOCH 352/500:
	Training over batches...
		[batch 4/4] avg loss: 0.022369751486151515		[learning rate: 9.7349e-05]
	Learning Rate: 9.73494e-05
	LOSS [training: 0.022369751486151515 | validation: 0.020672312012358477]
	TIME [epoch: 42.3 sec]
EPOCH 353/500:
	Training over batches...
		[batch 4/4] avg loss: 0.021346995709706634		[learning rate: 9.5866e-05]
	Learning Rate: 9.58665e-05
	LOSS [training: 0.021346995709706634 | validation: 0.02686432529923101]
	TIME [epoch: 42.3 sec]
EPOCH 354/500:
	Training over batches...
		[batch 4/4] avg loss: 0.018326913740578373		[learning rate: 9.4406e-05]
	Learning Rate: 9.44061e-05
	LOSS [training: 0.018326913740578373 | validation: 0.02446886744103384]
	TIME [epoch: 42.3 sec]
EPOCH 355/500:
	Training over batches...
		[batch 4/4] avg loss: 0.018795682309250484		[learning rate: 9.2968e-05]
	Learning Rate: 9.2968e-05
	LOSS [training: 0.018795682309250484 | validation: 0.03133601765922315]
	TIME [epoch: 42.4 sec]
EPOCH 356/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025011109016081157		[learning rate: 9.1552e-05]
	Learning Rate: 9.15518e-05
	LOSS [training: 0.025011109016081157 | validation: 0.02105720106673837]
	TIME [epoch: 42.3 sec]
EPOCH 357/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02497547510951573		[learning rate: 9.0157e-05]
	Learning Rate: 9.01571e-05
	LOSS [training: 0.02497547510951573 | validation: 0.020153623098693705]
	TIME [epoch: 42.3 sec]
EPOCH 358/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020856488972149725		[learning rate: 8.8784e-05]
	Learning Rate: 8.87837e-05
	LOSS [training: 0.020856488972149725 | validation: 0.018942643884947964]
	TIME [epoch: 42.3 sec]
EPOCH 359/500:
	Training over batches...
		[batch 4/4] avg loss: 0.019290419306714227		[learning rate: 8.7431e-05]
	Learning Rate: 8.74312e-05
	LOSS [training: 0.019290419306714227 | validation: 0.029157999870970012]
	TIME [epoch: 42.3 sec]
EPOCH 360/500:
	Training over batches...
		[batch 4/4] avg loss: 0.022362285492036556		[learning rate: 8.6099e-05]
	Learning Rate: 8.60994e-05
	LOSS [training: 0.022362285492036556 | validation: 0.01693540519354192]
	TIME [epoch: 42.3 sec]
EPOCH 361/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020532181818456473		[learning rate: 8.4788e-05]
	Learning Rate: 8.47878e-05
	LOSS [training: 0.020532181818456473 | validation: 0.02045831098228484]
	TIME [epoch: 42.3 sec]
EPOCH 362/500:
	Training over batches...
		[batch 4/4] avg loss: 0.021852638190765643		[learning rate: 8.3496e-05]
	Learning Rate: 8.34962e-05
	LOSS [training: 0.021852638190765643 | validation: 0.024767863379831737]
	TIME [epoch: 42.4 sec]
EPOCH 363/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01733718222209081		[learning rate: 8.2224e-05]
	Learning Rate: 8.22243e-05
	LOSS [training: 0.01733718222209081 | validation: 0.01601485389801466]
	TIME [epoch: 42.3 sec]
EPOCH 364/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023906527749595563		[learning rate: 8.0972e-05]
	Learning Rate: 8.09717e-05
	LOSS [training: 0.023906527749595563 | validation: 0.01636073575835969]
	TIME [epoch: 42.3 sec]
EPOCH 365/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01705998435035258		[learning rate: 7.9738e-05]
	Learning Rate: 7.97382e-05
	LOSS [training: 0.01705998435035258 | validation: 0.025185909227877744]
	TIME [epoch: 42.3 sec]
EPOCH 366/500:
	Training over batches...
		[batch 4/4] avg loss: 0.018952570702220728		[learning rate: 7.8524e-05]
	Learning Rate: 7.85235e-05
	LOSS [training: 0.018952570702220728 | validation: 0.025329983744520165]
	TIME [epoch: 42.3 sec]
EPOCH 367/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0206139021864453		[learning rate: 7.7327e-05]
	Learning Rate: 7.73274e-05
	LOSS [training: 0.0206139021864453 | validation: 0.019786083187782553]
	TIME [epoch: 42.3 sec]
EPOCH 368/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02119511456345733		[learning rate: 7.6149e-05]
	Learning Rate: 7.61494e-05
	LOSS [training: 0.02119511456345733 | validation: 0.02369236519765499]
	TIME [epoch: 42.3 sec]
EPOCH 369/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020059517432339184		[learning rate: 7.4989e-05]
	Learning Rate: 7.49894e-05
	LOSS [training: 0.020059517432339184 | validation: 0.010987975712314576]
	TIME [epoch: 42.3 sec]
EPOCH 370/500:
	Training over batches...
		[batch 4/4] avg loss: 0.021080264642871098		[learning rate: 7.3847e-05]
	Learning Rate: 7.38471e-05
	LOSS [training: 0.021080264642871098 | validation: 0.02883220208168083]
	TIME [epoch: 42.3 sec]
EPOCH 371/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01926488015285805		[learning rate: 7.2722e-05]
	Learning Rate: 7.27221e-05
	LOSS [training: 0.01926488015285805 | validation: 0.009207053788123497]
	TIME [epoch: 42.4 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_371.pth
	Model improved!!!
EPOCH 372/500:
	Training over batches...
		[batch 4/4] avg loss: 0.015441199994018408		[learning rate: 7.1614e-05]
	Learning Rate: 7.16143e-05
	LOSS [training: 0.015441199994018408 | validation: 0.02309125070406936]
	TIME [epoch: 42.4 sec]
EPOCH 373/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01931456689435134		[learning rate: 7.0523e-05]
	Learning Rate: 7.05234e-05
	LOSS [training: 0.01931456689435134 | validation: 0.017282278667729974]
	TIME [epoch: 42.4 sec]
EPOCH 374/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020738588877094268		[learning rate: 6.9449e-05]
	Learning Rate: 6.94491e-05
	LOSS [training: 0.020738588877094268 | validation: 0.02108335037565331]
	TIME [epoch: 42.3 sec]
EPOCH 375/500:
	Training over batches...
		[batch 4/4] avg loss: 0.018026585517199545		[learning rate: 6.8391e-05]
	Learning Rate: 6.83912e-05
	LOSS [training: 0.018026585517199545 | validation: 0.019602589915585993]
	TIME [epoch: 42.3 sec]
EPOCH 376/500:
	Training over batches...
		[batch 4/4] avg loss: 0.018634010878030998		[learning rate: 6.7349e-05]
	Learning Rate: 6.73493e-05
	LOSS [training: 0.018634010878030998 | validation: 0.016722600768520286]
	TIME [epoch: 42.3 sec]
EPOCH 377/500:
	Training over batches...
		[batch 4/4] avg loss: 0.018462317228746097		[learning rate: 6.6323e-05]
	Learning Rate: 6.63234e-05
	LOSS [training: 0.018462317228746097 | validation: 0.019980175962384022]
	TIME [epoch: 42.3 sec]
EPOCH 378/500:
	Training over batches...
		[batch 4/4] avg loss: 0.021053813530065815		[learning rate: 6.5313e-05]
	Learning Rate: 6.5313e-05
	LOSS [training: 0.021053813530065815 | validation: 0.014748658805004441]
	TIME [epoch: 42.3 sec]
EPOCH 379/500:
	Training over batches...
		[batch 4/4] avg loss: 0.019182862388145292		[learning rate: 6.4318e-05]
	Learning Rate: 6.43181e-05
	LOSS [training: 0.019182862388145292 | validation: 0.016180771143211353]
	TIME [epoch: 42.3 sec]
EPOCH 380/500:
	Training over batches...
		[batch 4/4] avg loss: 0.021264555631795478		[learning rate: 6.3338e-05]
	Learning Rate: 6.33383e-05
	LOSS [training: 0.021264555631795478 | validation: 0.018629515080162824]
	TIME [epoch: 42.4 sec]
EPOCH 381/500:
	Training over batches...
		[batch 4/4] avg loss: 0.019964525065637444		[learning rate: 6.2373e-05]
	Learning Rate: 6.23735e-05
	LOSS [training: 0.019964525065637444 | validation: 0.026638467054542495]
	TIME [epoch: 42.4 sec]
EPOCH 382/500:
	Training over batches...
		[batch 4/4] avg loss: 0.019548711536098922		[learning rate: 6.1423e-05]
	Learning Rate: 6.14233e-05
	LOSS [training: 0.019548711536098922 | validation: 0.023964928879913625]
	TIME [epoch: 42.4 sec]
EPOCH 383/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01991563727465779		[learning rate: 6.0488e-05]
	Learning Rate: 6.04876e-05
	LOSS [training: 0.01991563727465779 | validation: 0.032024907128279954]
	TIME [epoch: 42.4 sec]
EPOCH 384/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01961155447574285		[learning rate: 5.9566e-05]
	Learning Rate: 5.95662e-05
	LOSS [training: 0.01961155447574285 | validation: 0.016591398201277148]
	TIME [epoch: 42.3 sec]
EPOCH 385/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020227208546814337		[learning rate: 5.8659e-05]
	Learning Rate: 5.86588e-05
	LOSS [training: 0.020227208546814337 | validation: 0.02925154603424903]
	TIME [epoch: 42.3 sec]
EPOCH 386/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020730009285623734		[learning rate: 5.7765e-05]
	Learning Rate: 5.77652e-05
	LOSS [training: 0.020730009285623734 | validation: 0.01861900122176651]
	TIME [epoch: 42.4 sec]
EPOCH 387/500:
	Training over batches...
		[batch 4/4] avg loss: 0.022245973522973136		[learning rate: 5.6885e-05]
	Learning Rate: 5.68853e-05
	LOSS [training: 0.022245973522973136 | validation: 0.02240640046458711]
	TIME [epoch: 42.4 sec]
EPOCH 388/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025358390825496395		[learning rate: 5.6019e-05]
	Learning Rate: 5.60187e-05
	LOSS [training: 0.025358390825496395 | validation: 0.020024437794054634]
	TIME [epoch: 42.3 sec]
EPOCH 389/500:
	Training over batches...
		[batch 4/4] avg loss: 0.018011979482091087		[learning rate: 5.5165e-05]
	Learning Rate: 5.51654e-05
	LOSS [training: 0.018011979482091087 | validation: 0.01921372810739637]
	TIME [epoch: 42.3 sec]
EPOCH 390/500:
	Training over batches...
		[batch 4/4] avg loss: 0.019874567015835218		[learning rate: 5.4325e-05]
	Learning Rate: 5.4325e-05
	LOSS [training: 0.019874567015835218 | validation: 0.016556413967091135]
	TIME [epoch: 42.3 sec]
EPOCH 391/500:
	Training over batches...
		[batch 4/4] avg loss: 0.014981144087702902		[learning rate: 5.3497e-05]
	Learning Rate: 5.34975e-05
	LOSS [training: 0.014981144087702902 | validation: 0.02149074389933594]
	TIME [epoch: 42.3 sec]
EPOCH 392/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0133168925664604		[learning rate: 5.2683e-05]
	Learning Rate: 5.26825e-05
	LOSS [training: 0.0133168925664604 | validation: 0.015788516924065646]
	TIME [epoch: 42.4 sec]
EPOCH 393/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02128913164736966		[learning rate: 5.188e-05]
	Learning Rate: 5.188e-05
	LOSS [training: 0.02128913164736966 | validation: 0.01704244018682665]
	TIME [epoch: 42.3 sec]
EPOCH 394/500:
	Training over batches...
		[batch 4/4] avg loss: 0.019469687738869042		[learning rate: 5.109e-05]
	Learning Rate: 5.10897e-05
	LOSS [training: 0.019469687738869042 | validation: 0.018443966214170625]
	TIME [epoch: 42.3 sec]
EPOCH 395/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02009151285015786		[learning rate: 5.0311e-05]
	Learning Rate: 5.03114e-05
	LOSS [training: 0.02009151285015786 | validation: 0.01500162472235925]
	TIME [epoch: 42.3 sec]
EPOCH 396/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023186035428314905		[learning rate: 4.9545e-05]
	Learning Rate: 4.9545e-05
	LOSS [training: 0.023186035428314905 | validation: 0.021016880156371643]
	TIME [epoch: 42.3 sec]
EPOCH 397/500:
	Training over batches...
		[batch 4/4] avg loss: 0.017393565024999925		[learning rate: 4.879e-05]
	Learning Rate: 4.87903e-05
	LOSS [training: 0.017393565024999925 | validation: 0.029343559685302945]
	TIME [epoch: 42.3 sec]
EPOCH 398/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023549807156006332		[learning rate: 4.8047e-05]
	Learning Rate: 4.8047e-05
	LOSS [training: 0.023549807156006332 | validation: 0.018385787980073613]
	TIME [epoch: 42.3 sec]
EPOCH 399/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01957359398194836		[learning rate: 4.7315e-05]
	Learning Rate: 4.73151e-05
	LOSS [training: 0.01957359398194836 | validation: 0.02051527262361521]
	TIME [epoch: 42.3 sec]
EPOCH 400/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020234329041874763		[learning rate: 4.6594e-05]
	Learning Rate: 4.65944e-05
	LOSS [training: 0.020234329041874763 | validation: 0.029125972771928355]
	TIME [epoch: 42.3 sec]
EPOCH 401/500:
	Training over batches...
		[batch 4/4] avg loss: 0.019483651363589365		[learning rate: 4.5885e-05]
	Learning Rate: 4.58846e-05
	LOSS [training: 0.019483651363589365 | validation: 0.013667122054402164]
	TIME [epoch: 42.2 sec]
EPOCH 402/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02274708695477575		[learning rate: 4.5186e-05]
	Learning Rate: 4.51856e-05
	LOSS [training: 0.02274708695477575 | validation: 0.016446535009050328]
	TIME [epoch: 42.3 sec]
EPOCH 403/500:
	Training over batches...
		[batch 4/4] avg loss: 0.019189208149610892		[learning rate: 4.4497e-05]
	Learning Rate: 4.44973e-05
	LOSS [training: 0.019189208149610892 | validation: 0.017446747264778642]
	TIME [epoch: 42.3 sec]
EPOCH 404/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023782282855545116		[learning rate: 4.3819e-05]
	Learning Rate: 4.38194e-05
	LOSS [training: 0.023782282855545116 | validation: 0.010103874233625807]
	TIME [epoch: 42.2 sec]
EPOCH 405/500:
	Training over batches...
		[batch 4/4] avg loss: 0.021926565858640355		[learning rate: 4.3152e-05]
	Learning Rate: 4.31519e-05
	LOSS [training: 0.021926565858640355 | validation: 0.020238511557114224]
	TIME [epoch: 42.2 sec]
EPOCH 406/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02118045822805118		[learning rate: 4.2495e-05]
	Learning Rate: 4.24946e-05
	LOSS [training: 0.02118045822805118 | validation: 0.02869339800660598]
	TIME [epoch: 42.3 sec]
EPOCH 407/500:
	Training over batches...
		[batch 4/4] avg loss: 0.018668185253707205		[learning rate: 4.1847e-05]
	Learning Rate: 4.18472e-05
	LOSS [training: 0.018668185253707205 | validation: 0.020301609329901604]
	TIME [epoch: 42.2 sec]
EPOCH 408/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020946104311188003		[learning rate: 4.121e-05]
	Learning Rate: 4.12098e-05
	LOSS [training: 0.020946104311188003 | validation: 0.018729754600321363]
	TIME [epoch: 42.2 sec]
EPOCH 409/500:
	Training over batches...
		[batch 4/4] avg loss: 0.017105296307210374		[learning rate: 4.0582e-05]
	Learning Rate: 4.0582e-05
	LOSS [training: 0.017105296307210374 | validation: 0.022096335234316672]
	TIME [epoch: 42.3 sec]
EPOCH 410/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0214182226570853		[learning rate: 3.9964e-05]
	Learning Rate: 3.99638e-05
	LOSS [training: 0.0214182226570853 | validation: 0.01881056060714823]
	TIME [epoch: 42.2 sec]
EPOCH 411/500:
	Training over batches...
		[batch 4/4] avg loss: 0.013451407320504673		[learning rate: 3.9355e-05]
	Learning Rate: 3.9355e-05
	LOSS [training: 0.013451407320504673 | validation: 0.0219864949858763]
	TIME [epoch: 42.3 sec]
EPOCH 412/500:
	Training over batches...
		[batch 4/4] avg loss: 0.014700779362714642		[learning rate: 3.8755e-05]
	Learning Rate: 3.87555e-05
	LOSS [training: 0.014700779362714642 | validation: 0.025634804910030097]
	TIME [epoch: 42.3 sec]
EPOCH 413/500:
	Training over batches...
		[batch 4/4] avg loss: 0.018734442428431444		[learning rate: 3.8165e-05]
	Learning Rate: 3.81651e-05
	LOSS [training: 0.018734442428431444 | validation: 0.022431303467524612]
	TIME [epoch: 42.2 sec]
EPOCH 414/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01830213500246707		[learning rate: 3.7584e-05]
	Learning Rate: 3.75837e-05
	LOSS [training: 0.01830213500246707 | validation: 0.017281168457037227]
	TIME [epoch: 42.2 sec]
EPOCH 415/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01890184738441405		[learning rate: 3.7011e-05]
	Learning Rate: 3.70112e-05
	LOSS [training: 0.01890184738441405 | validation: 0.018497768637085448]
	TIME [epoch: 42.3 sec]
EPOCH 416/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01812090463608053		[learning rate: 3.6447e-05]
	Learning Rate: 3.64474e-05
	LOSS [training: 0.01812090463608053 | validation: 0.03056688304092412]
	TIME [epoch: 42.3 sec]
EPOCH 417/500:
	Training over batches...
		[batch 4/4] avg loss: 0.022429405008462053		[learning rate: 3.5892e-05]
	Learning Rate: 3.58922e-05
	LOSS [training: 0.022429405008462053 | validation: 0.020530509134444146]
	TIME [epoch: 42.2 sec]
EPOCH 418/500:
	Training over batches...
		[batch 4/4] avg loss: 0.018491558672237843		[learning rate: 3.5345e-05]
	Learning Rate: 3.53454e-05
	LOSS [training: 0.018491558672237843 | validation: 0.018545767838676917]
	TIME [epoch: 42.3 sec]
EPOCH 419/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020963138632617246		[learning rate: 3.4807e-05]
	Learning Rate: 3.4807e-05
	LOSS [training: 0.020963138632617246 | validation: 0.017407551704053087]
	TIME [epoch: 42.2 sec]
EPOCH 420/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01976754493917287		[learning rate: 3.4277e-05]
	Learning Rate: 3.42768e-05
	LOSS [training: 0.01976754493917287 | validation: 0.01896521748509643]
	TIME [epoch: 42.3 sec]
EPOCH 421/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01784934629941523		[learning rate: 3.3755e-05]
	Learning Rate: 3.37546e-05
	LOSS [training: 0.01784934629941523 | validation: 0.018364669114255917]
	TIME [epoch: 42.2 sec]
EPOCH 422/500:
	Training over batches...
		[batch 4/4] avg loss: 0.019533745522706553		[learning rate: 3.324e-05]
	Learning Rate: 3.32404e-05
	LOSS [training: 0.019533745522706553 | validation: 0.01694640130372114]
	TIME [epoch: 42.3 sec]
EPOCH 423/500:
	Training over batches...
		[batch 4/4] avg loss: 0.018961303378469976		[learning rate: 3.2734e-05]
	Learning Rate: 3.27341e-05
	LOSS [training: 0.018961303378469976 | validation: 0.021514269949720013]
	TIME [epoch: 42.3 sec]
EPOCH 424/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01921658507676107		[learning rate: 3.2235e-05]
	Learning Rate: 3.22354e-05
	LOSS [training: 0.01921658507676107 | validation: 0.01573278717911048]
	TIME [epoch: 42.3 sec]
EPOCH 425/500:
	Training over batches...
		[batch 4/4] avg loss: 0.017919572339982648		[learning rate: 3.1744e-05]
	Learning Rate: 3.17444e-05
	LOSS [training: 0.017919572339982648 | validation: 0.024514461528485167]
	TIME [epoch: 42.3 sec]
EPOCH 426/500:
	Training over batches...
		[batch 4/4] avg loss: 0.018910005547274615		[learning rate: 3.1261e-05]
	Learning Rate: 3.12608e-05
	LOSS [training: 0.018910005547274615 | validation: 0.027729862707339778]
	TIME [epoch: 42.2 sec]
EPOCH 427/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02100981896566417		[learning rate: 3.0785e-05]
	Learning Rate: 3.07846e-05
	LOSS [training: 0.02100981896566417 | validation: 0.014777545339978378]
	TIME [epoch: 42.3 sec]
EPOCH 428/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020452279204399813		[learning rate: 3.0316e-05]
	Learning Rate: 3.03156e-05
	LOSS [training: 0.020452279204399813 | validation: 0.02665688042093222]
	TIME [epoch: 42.2 sec]
EPOCH 429/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02036787556301893		[learning rate: 2.9854e-05]
	Learning Rate: 2.98538e-05
	LOSS [training: 0.02036787556301893 | validation: 0.0227381731107976]
	TIME [epoch: 42.3 sec]
EPOCH 430/500:
	Training over batches...
		[batch 4/4] avg loss: 0.019364269067301928		[learning rate: 2.9399e-05]
	Learning Rate: 2.9399e-05
	LOSS [training: 0.019364269067301928 | validation: 0.013845555484040806]
	TIME [epoch: 42.2 sec]
EPOCH 431/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02051077933677596		[learning rate: 2.8951e-05]
	Learning Rate: 2.89512e-05
	LOSS [training: 0.02051077933677596 | validation: 0.020781688439644518]
	TIME [epoch: 42.2 sec]
EPOCH 432/500:
	Training over batches...
		[batch 4/4] avg loss: 0.018276303342488576		[learning rate: 2.851e-05]
	Learning Rate: 2.85102e-05
	LOSS [training: 0.018276303342488576 | validation: 0.030057757263316207]
	TIME [epoch: 42.2 sec]
EPOCH 433/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020951891284889158		[learning rate: 2.8076e-05]
	Learning Rate: 2.80759e-05
	LOSS [training: 0.020951891284889158 | validation: 0.01917631163782118]
	TIME [epoch: 42.2 sec]
EPOCH 434/500:
	Training over batches...
		[batch 4/4] avg loss: 0.019925133677053886		[learning rate: 2.7648e-05]
	Learning Rate: 2.76482e-05
	LOSS [training: 0.019925133677053886 | validation: 0.020912142956951048]
	TIME [epoch: 42.3 sec]
EPOCH 435/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0187105460031112		[learning rate: 2.7227e-05]
	Learning Rate: 2.7227e-05
	LOSS [training: 0.0187105460031112 | validation: 0.02695096601881652]
	TIME [epoch: 42.2 sec]
EPOCH 436/500:
	Training over batches...
		[batch 4/4] avg loss: 0.019118892110525084		[learning rate: 2.6812e-05]
	Learning Rate: 2.68122e-05
	LOSS [training: 0.019118892110525084 | validation: 0.024492888679622467]
	TIME [epoch: 42.2 sec]
EPOCH 437/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020027593263940466		[learning rate: 2.6404e-05]
	Learning Rate: 2.64038e-05
	LOSS [training: 0.020027593263940466 | validation: 0.021359368334569015]
	TIME [epoch: 42.2 sec]
EPOCH 438/500:
	Training over batches...
		[batch 4/4] avg loss: 0.021732725971094914		[learning rate: 2.6002e-05]
	Learning Rate: 2.60016e-05
	LOSS [training: 0.021732725971094914 | validation: 0.022528737196695008]
	TIME [epoch: 42.2 sec]
EPOCH 439/500:
	Training over batches...
		[batch 4/4] avg loss: 0.018714875249419737		[learning rate: 2.5605e-05]
	Learning Rate: 2.56055e-05
	LOSS [training: 0.018714875249419737 | validation: 0.02535207003452021]
	TIME [epoch: 42.3 sec]
EPOCH 440/500:
	Training over batches...
		[batch 4/4] avg loss: 0.017296327707246		[learning rate: 2.5215e-05]
	Learning Rate: 2.52154e-05
	LOSS [training: 0.017296327707246 | validation: 0.026473603851815002]
	TIME [epoch: 42.2 sec]
EPOCH 441/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01670878443339784		[learning rate: 2.4831e-05]
	Learning Rate: 2.48313e-05
	LOSS [training: 0.01670878443339784 | validation: 0.024448629053044638]
	TIME [epoch: 42.3 sec]
EPOCH 442/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01754023770259651		[learning rate: 2.4453e-05]
	Learning Rate: 2.44531e-05
	LOSS [training: 0.01754023770259651 | validation: 0.013257480872707124]
	TIME [epoch: 42.2 sec]
EPOCH 443/500:
	Training over batches...
		[batch 4/4] avg loss: 0.018790226271768427		[learning rate: 2.4081e-05]
	Learning Rate: 2.40806e-05
	LOSS [training: 0.018790226271768427 | validation: 0.02283017169580704]
	TIME [epoch: 42.2 sec]
EPOCH 444/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02099737367203253		[learning rate: 2.3714e-05]
	Learning Rate: 2.37137e-05
	LOSS [training: 0.02099737367203253 | validation: 0.02608789659521013]
	TIME [epoch: 42.3 sec]
EPOCH 445/500:
	Training over batches...
		[batch 4/4] avg loss: 0.014666076732300255		[learning rate: 2.3352e-05]
	Learning Rate: 2.33525e-05
	LOSS [training: 0.014666076732300255 | validation: 0.017397220730714535]
	TIME [epoch: 42.3 sec]
EPOCH 446/500:
	Training over batches...
		[batch 4/4] avg loss: 0.019769807912023648		[learning rate: 2.2997e-05]
	Learning Rate: 2.29968e-05
	LOSS [training: 0.019769807912023648 | validation: 0.01905989325190416]
	TIME [epoch: 42.2 sec]
EPOCH 447/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01790133212763211		[learning rate: 2.2646e-05]
	Learning Rate: 2.26464e-05
	LOSS [training: 0.01790133212763211 | validation: 0.010209691850367644]
	TIME [epoch: 42.2 sec]
EPOCH 448/500:
	Training over batches...
		[batch 4/4] avg loss: 0.015511667529549415		[learning rate: 2.2301e-05]
	Learning Rate: 2.23015e-05
	LOSS [training: 0.015511667529549415 | validation: 0.018816063972302344]
	TIME [epoch: 42.2 sec]
EPOCH 449/500:
	Training over batches...
		[batch 4/4] avg loss: 0.013602141544956498		[learning rate: 2.1962e-05]
	Learning Rate: 2.19617e-05
	LOSS [training: 0.013602141544956498 | validation: 0.01132638323372262]
	TIME [epoch: 42.3 sec]
EPOCH 450/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023285217005415644		[learning rate: 2.1627e-05]
	Learning Rate: 2.16272e-05
	LOSS [training: 0.023285217005415644 | validation: 0.015068049647301896]
	TIME [epoch: 42.2 sec]
EPOCH 451/500:
	Training over batches...
		[batch 4/4] avg loss: 0.018380624911595117		[learning rate: 2.1298e-05]
	Learning Rate: 2.12977e-05
	LOSS [training: 0.018380624911595117 | validation: 0.022616912154394354]
	TIME [epoch: 42.3 sec]
EPOCH 452/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020028137980163816		[learning rate: 2.0973e-05]
	Learning Rate: 2.09733e-05
	LOSS [training: 0.020028137980163816 | validation: 0.0188317290442336]
	TIME [epoch: 42.3 sec]
EPOCH 453/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0195291668353492		[learning rate: 2.0654e-05]
	Learning Rate: 2.06538e-05
	LOSS [training: 0.0195291668353492 | validation: 0.026229015593277817]
	TIME [epoch: 42.3 sec]
EPOCH 454/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020362241155301834		[learning rate: 2.0339e-05]
	Learning Rate: 2.03392e-05
	LOSS [training: 0.020362241155301834 | validation: 0.02248062819778032]
	TIME [epoch: 42.3 sec]
EPOCH 455/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01836729935833988		[learning rate: 2.0029e-05]
	Learning Rate: 2.00293e-05
	LOSS [training: 0.01836729935833988 | validation: 0.018301768645998827]
	TIME [epoch: 42.3 sec]
EPOCH 456/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020433919018409314		[learning rate: 1.9724e-05]
	Learning Rate: 1.97242e-05
	LOSS [training: 0.020433919018409314 | validation: 0.016694250172548244]
	TIME [epoch: 42.3 sec]
EPOCH 457/500:
	Training over batches...
		[batch 4/4] avg loss: 0.013155903875702625		[learning rate: 1.9424e-05]
	Learning Rate: 1.94238e-05
	LOSS [training: 0.013155903875702625 | validation: 0.022515474425461486]
	TIME [epoch: 42.4 sec]
EPOCH 458/500:
	Training over batches...
		[batch 4/4] avg loss: 0.019071000119452706		[learning rate: 1.9128e-05]
	Learning Rate: 1.91279e-05
	LOSS [training: 0.019071000119452706 | validation: 0.02229048102019937]
	TIME [epoch: 42.4 sec]
EPOCH 459/500:
	Training over batches...
		[batch 4/4] avg loss: 0.015336201192911045		[learning rate: 1.8836e-05]
	Learning Rate: 1.88365e-05
	LOSS [training: 0.015336201192911045 | validation: 0.026846753942585545]
	TIME [epoch: 42.4 sec]
EPOCH 460/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01711795276235991		[learning rate: 1.855e-05]
	Learning Rate: 1.85495e-05
	LOSS [training: 0.01711795276235991 | validation: 0.024496005271219347]
	TIME [epoch: 42.4 sec]
EPOCH 461/500:
	Training over batches...
		[batch 4/4] avg loss: 0.016826737226672515		[learning rate: 1.8267e-05]
	Learning Rate: 1.8267e-05
	LOSS [training: 0.016826737226672515 | validation: 0.014616967024137244]
	TIME [epoch: 42.4 sec]
EPOCH 462/500:
	Training over batches...
		[batch 4/4] avg loss: 0.021191348623521344		[learning rate: 1.7989e-05]
	Learning Rate: 1.79887e-05
	LOSS [training: 0.021191348623521344 | validation: 0.014637171826346152]
	TIME [epoch: 42.4 sec]
EPOCH 463/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01464541623069773		[learning rate: 1.7715e-05]
	Learning Rate: 1.77147e-05
	LOSS [training: 0.01464541623069773 | validation: 0.020576788222552073]
	TIME [epoch: 42.3 sec]
EPOCH 464/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02052788234278294		[learning rate: 1.7445e-05]
	Learning Rate: 1.74448e-05
	LOSS [training: 0.02052788234278294 | validation: 0.01834674647600575]
	TIME [epoch: 42.4 sec]
EPOCH 465/500:
	Training over batches...
		[batch 4/4] avg loss: 0.016915895258279558		[learning rate: 1.7179e-05]
	Learning Rate: 1.71791e-05
	LOSS [training: 0.016915895258279558 | validation: 0.02218001266211292]
	TIME [epoch: 42.4 sec]
EPOCH 466/500:
	Training over batches...
		[batch 4/4] avg loss: 0.018971781773129023		[learning rate: 1.6917e-05]
	Learning Rate: 1.69174e-05
	LOSS [training: 0.018971781773129023 | validation: 0.011822571872041065]
	TIME [epoch: 42.4 sec]
EPOCH 467/500:
	Training over batches...
		[batch 4/4] avg loss: 0.021368549092293798		[learning rate: 1.666e-05]
	Learning Rate: 1.66597e-05
	LOSS [training: 0.021368549092293798 | validation: 0.024843524603094174]
	TIME [epoch: 42.4 sec]
EPOCH 468/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01828374576538607		[learning rate: 1.6406e-05]
	Learning Rate: 1.64059e-05
	LOSS [training: 0.01828374576538607 | validation: 0.01650681439832578]
	TIME [epoch: 42.3 sec]
EPOCH 469/500:
	Training over batches...
		[batch 4/4] avg loss: 0.018503919265902898		[learning rate: 1.6156e-05]
	Learning Rate: 1.6156e-05
	LOSS [training: 0.018503919265902898 | validation: 0.016633288252635985]
	TIME [epoch: 42.3 sec]
EPOCH 470/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01935746189006581		[learning rate: 1.591e-05]
	Learning Rate: 1.59099e-05
	LOSS [training: 0.01935746189006581 | validation: 0.017920779069538095]
	TIME [epoch: 42.4 sec]
EPOCH 471/500:
	Training over batches...
		[batch 4/4] avg loss: 0.018499867133762973		[learning rate: 1.5668e-05]
	Learning Rate: 1.56675e-05
	LOSS [training: 0.018499867133762973 | validation: 0.017271874360541284]
	TIME [epoch: 42.4 sec]
EPOCH 472/500:
	Training over batches...
		[batch 4/4] avg loss: 0.018532139631183824		[learning rate: 1.5429e-05]
	Learning Rate: 1.54288e-05
	LOSS [training: 0.018532139631183824 | validation: 0.014324922774158685]
	TIME [epoch: 42.3 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20240711_015952/states/model_algphiq_1a_v_klv21_472.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 13345.636 seconds.
