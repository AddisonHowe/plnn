Args:
Namespace(name='model_phi1_1a_v1_64', outdir='out/model_training/model_phi1_1a_v1_64', training_data='data/training_data/data_phi1_1a/training', validation_data='data/training_data/data_phi1_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=500, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 888351133

Training model...

Saving initial model state to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 10/10] avg loss: 11.064941880279298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.064941880279298 | validation: 11.369255552385972]
	TIME [epoch: 47.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 10/10] avg loss: 10.041989762304208		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.041989762304208 | validation: 11.178814485882768]
	TIME [epoch: 9.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 10/10] avg loss: 8.640137790563132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.640137790563132 | validation: 9.057847392461918]
	TIME [epoch: 9.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_3.pth
	Model improved!!!
EPOCH 4/500:
	Training over batches...
		[batch 10/10] avg loss: 7.780183302679416		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.780183302679416 | validation: 8.34038367622705]
	TIME [epoch: 9.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 10/10] avg loss: 6.888709903065761		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.888709903065761 | validation: 8.123370597760333]
	TIME [epoch: 9.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_5.pth
	Model improved!!!
EPOCH 6/500:
	Training over batches...
		[batch 10/10] avg loss: 6.519496665999772		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.519496665999772 | validation: 7.206470365076612]
	TIME [epoch: 9.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_6.pth
	Model improved!!!
EPOCH 7/500:
	Training over batches...
		[batch 10/10] avg loss: 6.220331647748257		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.220331647748257 | validation: 6.810698163464029]
	TIME [epoch: 9.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_7.pth
	Model improved!!!
EPOCH 8/500:
	Training over batches...
		[batch 10/10] avg loss: 5.416792484426277		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.416792484426277 | validation: 7.9663020085337335]
	TIME [epoch: 9.27 sec]
EPOCH 9/500:
	Training over batches...
		[batch 10/10] avg loss: 5.335174023470531		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.335174023470531 | validation: 6.215189793239755]
	TIME [epoch: 9.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_9.pth
	Model improved!!!
EPOCH 10/500:
	Training over batches...
		[batch 10/10] avg loss: 5.051418835052449		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.051418835052449 | validation: 6.308546544632411]
	TIME [epoch: 9.27 sec]
EPOCH 11/500:
	Training over batches...
		[batch 10/10] avg loss: 4.769678539596731		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.769678539596731 | validation: 5.770400425864177]
	TIME [epoch: 9.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_11.pth
	Model improved!!!
EPOCH 12/500:
	Training over batches...
		[batch 10/10] avg loss: 4.5461303723372675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.5461303723372675 | validation: 5.89938962711287]
	TIME [epoch: 9.27 sec]
EPOCH 13/500:
	Training over batches...
		[batch 10/10] avg loss: 4.61117222891065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.61117222891065 | validation: 5.317993714870005]
	TIME [epoch: 9.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_13.pth
	Model improved!!!
EPOCH 14/500:
	Training over batches...
		[batch 10/10] avg loss: 4.341949699927268		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.341949699927268 | validation: 5.344914058229598]
	TIME [epoch: 9.29 sec]
EPOCH 15/500:
	Training over batches...
		[batch 10/10] avg loss: 4.382347805975198		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.382347805975198 | validation: 5.187662528248274]
	TIME [epoch: 9.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_15.pth
	Model improved!!!
EPOCH 16/500:
	Training over batches...
		[batch 10/10] avg loss: 4.175431867104318		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.175431867104318 | validation: 5.4678196016597385]
	TIME [epoch: 9.28 sec]
EPOCH 17/500:
	Training over batches...
		[batch 10/10] avg loss: 4.510409462152399		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.510409462152399 | validation: 4.883583830876147]
	TIME [epoch: 9.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_17.pth
	Model improved!!!
EPOCH 18/500:
	Training over batches...
		[batch 10/10] avg loss: 3.8289932643451414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8289932643451414 | validation: 4.703921498555576]
	TIME [epoch: 9.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_18.pth
	Model improved!!!
EPOCH 19/500:
	Training over batches...
		[batch 10/10] avg loss: 3.722284771788879		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.722284771788879 | validation: 4.9165163818964155]
	TIME [epoch: 9.28 sec]
EPOCH 20/500:
	Training over batches...
		[batch 10/10] avg loss: 3.6537058725589304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6537058725589304 | validation: 6.4919458862486445]
	TIME [epoch: 9.27 sec]
EPOCH 21/500:
	Training over batches...
		[batch 10/10] avg loss: 3.481192657699507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.481192657699507 | validation: 3.6665146321333872]
	TIME [epoch: 9.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_21.pth
	Model improved!!!
EPOCH 22/500:
	Training over batches...
		[batch 10/10] avg loss: 3.1132424617445262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1132424617445262 | validation: 3.0221284891414846]
	TIME [epoch: 9.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_22.pth
	Model improved!!!
EPOCH 23/500:
	Training over batches...
		[batch 10/10] avg loss: 2.791727580454503		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.791727580454503 | validation: 2.2457279909822043]
	TIME [epoch: 9.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_23.pth
	Model improved!!!
EPOCH 24/500:
	Training over batches...
		[batch 10/10] avg loss: 2.2132093760358322		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2132093760358322 | validation: 3.0660244557861414]
	TIME [epoch: 9.29 sec]
EPOCH 25/500:
	Training over batches...
		[batch 10/10] avg loss: 2.524143390431122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.524143390431122 | validation: 2.024017426254493]
	TIME [epoch: 9.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_25.pth
	Model improved!!!
EPOCH 26/500:
	Training over batches...
		[batch 10/10] avg loss: 2.4677060590444393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4677060590444393 | validation: 2.191909366409524]
	TIME [epoch: 9.29 sec]
EPOCH 27/500:
	Training over batches...
		[batch 10/10] avg loss: 2.3744182098826156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3744182098826156 | validation: 1.99469237626095]
	TIME [epoch: 9.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_27.pth
	Model improved!!!
EPOCH 28/500:
	Training over batches...
		[batch 10/10] avg loss: 2.0140533432266694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0140533432266694 | validation: 1.8974911563085015]
	TIME [epoch: 9.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_28.pth
	Model improved!!!
EPOCH 29/500:
	Training over batches...
		[batch 10/10] avg loss: 2.239986467262969		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.239986467262969 | validation: 3.880019031743597]
	TIME [epoch: 9.29 sec]
EPOCH 30/500:
	Training over batches...
		[batch 10/10] avg loss: 2.5932241469327115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5932241469327115 | validation: 1.975045625372923]
	TIME [epoch: 9.29 sec]
EPOCH 31/500:
	Training over batches...
		[batch 10/10] avg loss: 1.7518444638860644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7518444638860644 | validation: 2.653583133018474]
	TIME [epoch: 9.27 sec]
EPOCH 32/500:
	Training over batches...
		[batch 10/10] avg loss: 2.0017575387836652		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0017575387836652 | validation: 1.5624707078747575]
	TIME [epoch: 9.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_32.pth
	Model improved!!!
EPOCH 33/500:
	Training over batches...
		[batch 10/10] avg loss: 1.7433295594908078		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7433295594908078 | validation: 1.5734614209683553]
	TIME [epoch: 9.3 sec]
EPOCH 34/500:
	Training over batches...
		[batch 10/10] avg loss: 1.7848148085378326		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7848148085378326 | validation: 4.330596087451956]
	TIME [epoch: 9.28 sec]
EPOCH 35/500:
	Training over batches...
		[batch 10/10] avg loss: 2.5866464106357916		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5866464106357916 | validation: 2.0721961194193894]
	TIME [epoch: 9.28 sec]
EPOCH 36/500:
	Training over batches...
		[batch 10/10] avg loss: 1.8378791767955627		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8378791767955627 | validation: 2.0740804099518844]
	TIME [epoch: 9.28 sec]
EPOCH 37/500:
	Training over batches...
		[batch 10/10] avg loss: 2.004736147895968		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.004736147895968 | validation: 1.6299879975173297]
	TIME [epoch: 9.29 sec]
EPOCH 38/500:
	Training over batches...
		[batch 10/10] avg loss: 1.9329061818996174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9329061818996174 | validation: 3.052126136072298]
	TIME [epoch: 9.28 sec]
EPOCH 39/500:
	Training over batches...
		[batch 10/10] avg loss: 2.3894528442562706		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3894528442562706 | validation: 1.8720293710306395]
	TIME [epoch: 9.26 sec]
EPOCH 40/500:
	Training over batches...
		[batch 10/10] avg loss: 1.6146232346952498		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6146232346952498 | validation: 2.163466811024692]
	TIME [epoch: 9.27 sec]
EPOCH 41/500:
	Training over batches...
		[batch 10/10] avg loss: 1.6610125757602083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6610125757602083 | validation: 1.4461593744514427]
	TIME [epoch: 9.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_41.pth
	Model improved!!!
EPOCH 42/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4594009667710703		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4594009667710703 | validation: 3.701990230091754]
	TIME [epoch: 9.28 sec]
EPOCH 43/500:
	Training over batches...
		[batch 10/10] avg loss: 1.799871639122026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.799871639122026 | validation: 1.6495343185898073]
	TIME [epoch: 9.27 sec]
EPOCH 44/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3302885683679517		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3302885683679517 | validation: 2.162041921008493]
	TIME [epoch: 9.26 sec]
EPOCH 45/500:
	Training over batches...
		[batch 10/10] avg loss: 1.6395418817250487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6395418817250487 | validation: 3.330219530308057]
	TIME [epoch: 9.27 sec]
EPOCH 46/500:
	Training over batches...
		[batch 10/10] avg loss: 2.0557743449163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0557743449163 | validation: 1.6024408216791983]
	TIME [epoch: 9.28 sec]
EPOCH 47/500:
	Training over batches...
		[batch 10/10] avg loss: 1.454828237260499		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.454828237260499 | validation: 1.6222615399463105]
	TIME [epoch: 9.27 sec]
EPOCH 48/500:
	Training over batches...
		[batch 10/10] avg loss: 1.347945474373588		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.347945474373588 | validation: 1.7322262820898082]
	TIME [epoch: 9.27 sec]
EPOCH 49/500:
	Training over batches...
		[batch 10/10] avg loss: 1.309420661562627		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.309420661562627 | validation: 1.1429463379727622]
	TIME [epoch: 9.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_49.pth
	Model improved!!!
EPOCH 50/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2838644287088783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2838644287088783 | validation: 1.5663440321638857]
	TIME [epoch: 9.29 sec]
EPOCH 51/500:
	Training over batches...
		[batch 10/10] avg loss: 1.8823615647326832		[learning rate: 0.0099541]
	Learning Rate: 0.00995405
	LOSS [training: 1.8823615647326832 | validation: 2.2927907023456346]
	TIME [epoch: 9.26 sec]
EPOCH 52/500:
	Training over batches...
		[batch 10/10] avg loss: 1.532990788240647		[learning rate: 0.0099033]
	Learning Rate: 0.00990325
	LOSS [training: 1.532990788240647 | validation: 0.8947403592681834]
	TIME [epoch: 9.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_52.pth
	Model improved!!!
EPOCH 53/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3960803660007086		[learning rate: 0.0098527]
	Learning Rate: 0.00985271
	LOSS [training: 1.3960803660007086 | validation: 1.206918561041923]
	TIME [epoch: 9.27 sec]
EPOCH 54/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1785172787289222		[learning rate: 0.0098024]
	Learning Rate: 0.00980242
	LOSS [training: 1.1785172787289222 | validation: 3.428262789601542]
	TIME [epoch: 9.29 sec]
EPOCH 55/500:
	Training over batches...
		[batch 10/10] avg loss: 1.9653578632216824		[learning rate: 0.0097524]
	Learning Rate: 0.00975239
	LOSS [training: 1.9653578632216824 | validation: 1.0761303026258768]
	TIME [epoch: 9.26 sec]
EPOCH 56/500:
	Training over batches...
		[batch 10/10] avg loss: 1.410623841505573		[learning rate: 0.0097026]
	Learning Rate: 0.00970262
	LOSS [training: 1.410623841505573 | validation: 1.120389562990265]
	TIME [epoch: 9.27 sec]
EPOCH 57/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2335071656614705		[learning rate: 0.0096531]
	Learning Rate: 0.0096531
	LOSS [training: 1.2335071656614705 | validation: 1.9366347370333505]
	TIME [epoch: 9.26 sec]
EPOCH 58/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4646895978889316		[learning rate: 0.0096038]
	Learning Rate: 0.00960383
	LOSS [training: 1.4646895978889316 | validation: 1.2694511778490398]
	TIME [epoch: 9.28 sec]
EPOCH 59/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1565314658857502		[learning rate: 0.0095548]
	Learning Rate: 0.00955481
	LOSS [training: 1.1565314658857502 | validation: 1.409419406503724]
	TIME [epoch: 9.26 sec]
EPOCH 60/500:
	Training over batches...
		[batch 10/10] avg loss: 1.254354857869513		[learning rate: 0.009506]
	Learning Rate: 0.00950605
	LOSS [training: 1.254354857869513 | validation: 1.13779572235324]
	TIME [epoch: 9.26 sec]
EPOCH 61/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2007377761048263		[learning rate: 0.0094575]
	Learning Rate: 0.00945753
	LOSS [training: 1.2007377761048263 | validation: 2.0200869798568637]
	TIME [epoch: 9.27 sec]
EPOCH 62/500:
	Training over batches...
		[batch 10/10] avg loss: 1.5453234658129946		[learning rate: 0.0094093]
	Learning Rate: 0.00940926
	LOSS [training: 1.5453234658129946 | validation: 1.0445175715161898]
	TIME [epoch: 9.29 sec]
EPOCH 63/500:
	Training over batches...
		[batch 10/10] avg loss: 1.41406585543108		[learning rate: 0.0093612]
	Learning Rate: 0.00936124
	LOSS [training: 1.41406585543108 | validation: 1.2411538863773952]
	TIME [epoch: 9.26 sec]
EPOCH 64/500:
	Training over batches...
		[batch 10/10] avg loss: 2.6075028816620702		[learning rate: 0.0093135]
	Learning Rate: 0.00931346
	LOSS [training: 2.6075028816620702 | validation: 1.6960659607763722]
	TIME [epoch: 9.26 sec]
EPOCH 65/500:
	Training over batches...
		[batch 10/10] avg loss: 1.456524748640053		[learning rate: 0.0092659]
	Learning Rate: 0.00926593
	LOSS [training: 1.456524748640053 | validation: 1.8556523664949907]
	TIME [epoch: 9.25 sec]
EPOCH 66/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2578194931190079		[learning rate: 0.0092186]
	Learning Rate: 0.00921864
	LOSS [training: 1.2578194931190079 | validation: 1.3684756684972872]
	TIME [epoch: 9.28 sec]
EPOCH 67/500:
	Training over batches...
		[batch 10/10] avg loss: 1.214133926337535		[learning rate: 0.0091716]
	Learning Rate: 0.00917159
	LOSS [training: 1.214133926337535 | validation: 0.9404186206148678]
	TIME [epoch: 9.26 sec]
EPOCH 68/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2665430173766477		[learning rate: 0.0091248]
	Learning Rate: 0.00912478
	LOSS [training: 1.2665430173766477 | validation: 1.6101162894940906]
	TIME [epoch: 9.26 sec]
EPOCH 69/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3046466545389734		[learning rate: 0.0090782]
	Learning Rate: 0.0090782
	LOSS [training: 1.3046466545389734 | validation: 1.9560585913252515]
	TIME [epoch: 9.26 sec]
EPOCH 70/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1648877894436107		[learning rate: 0.0090319]
	Learning Rate: 0.00903187
	LOSS [training: 1.1648877894436107 | validation: 0.9056924127884459]
	TIME [epoch: 9.28 sec]
EPOCH 71/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1330553636312135		[learning rate: 0.0089858]
	Learning Rate: 0.00898577
	LOSS [training: 1.1330553636312135 | validation: 1.0085288499249916]
	TIME [epoch: 9.26 sec]
EPOCH 72/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1853917140176304		[learning rate: 0.0089399]
	Learning Rate: 0.00893991
	LOSS [training: 1.1853917140176304 | validation: 1.6917261597039486]
	TIME [epoch: 9.27 sec]
EPOCH 73/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3787378246054733		[learning rate: 0.0088943]
	Learning Rate: 0.00889429
	LOSS [training: 1.3787378246054733 | validation: 0.982827863536305]
	TIME [epoch: 9.25 sec]
EPOCH 74/500:
	Training over batches...
		[batch 10/10] avg loss: 1.052290063651816		[learning rate: 0.0088489]
	Learning Rate: 0.00884889
	LOSS [training: 1.052290063651816 | validation: 0.7617677061984405]
	TIME [epoch: 9.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_74.pth
	Model improved!!!
EPOCH 75/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4080112248549805		[learning rate: 0.0088037]
	Learning Rate: 0.00880373
	LOSS [training: 1.4080112248549805 | validation: 1.0487338456622872]
	TIME [epoch: 9.28 sec]
EPOCH 76/500:
	Training over batches...
		[batch 10/10] avg loss: 1.261807469305114		[learning rate: 0.0087588]
	Learning Rate: 0.0087588
	LOSS [training: 1.261807469305114 | validation: 0.9602050445262806]
	TIME [epoch: 9.27 sec]
EPOCH 77/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9382832520515357		[learning rate: 0.0087141]
	Learning Rate: 0.00871409
	LOSS [training: 0.9382832520515357 | validation: 1.8381669541236434]
	TIME [epoch: 9.27 sec]
EPOCH 78/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2980014727520655		[learning rate: 0.0086696]
	Learning Rate: 0.00866962
	LOSS [training: 1.2980014727520655 | validation: 1.1209967888561563]
	TIME [epoch: 9.27 sec]
EPOCH 79/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1214164596425396		[learning rate: 0.0086254]
	Learning Rate: 0.00862537
	LOSS [training: 1.1214164596425396 | validation: 1.3081521517929222]
	TIME [epoch: 9.27 sec]
EPOCH 80/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1496792933291577		[learning rate: 0.0085813]
	Learning Rate: 0.00858135
	LOSS [training: 1.1496792933291577 | validation: 1.5110745869280429]
	TIME [epoch: 9.26 sec]
EPOCH 81/500:
	Training over batches...
		[batch 10/10] avg loss: 0.987804461414781		[learning rate: 0.0085376]
	Learning Rate: 0.00853755
	LOSS [training: 0.987804461414781 | validation: 1.058278247577219]
	TIME [epoch: 9.25 sec]
EPOCH 82/500:
	Training over batches...
		[batch 10/10] avg loss: 1.011355974502876		[learning rate: 0.008494]
	Learning Rate: 0.00849398
	LOSS [training: 1.011355974502876 | validation: 1.1521209057297734]
	TIME [epoch: 9.27 sec]
EPOCH 83/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0292553494357626		[learning rate: 0.0084506]
	Learning Rate: 0.00845063
	LOSS [training: 1.0292553494357626 | validation: 1.5749570568874935]
	TIME [epoch: 9.27 sec]
EPOCH 84/500:
	Training over batches...
		[batch 10/10] avg loss: 1.158120158292418		[learning rate: 0.0084075]
	Learning Rate: 0.00840749
	LOSS [training: 1.158120158292418 | validation: 1.1449699793280603]
	TIME [epoch: 9.25 sec]
EPOCH 85/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3119422330001793		[learning rate: 0.0083646]
	Learning Rate: 0.00836459
	LOSS [training: 1.3119422330001793 | validation: 0.7750620322790617]
	TIME [epoch: 9.27 sec]
EPOCH 86/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0883996047199573		[learning rate: 0.0083219]
	Learning Rate: 0.00832189
	LOSS [training: 1.0883996047199573 | validation: 0.9593522066447283]
	TIME [epoch: 9.28 sec]
EPOCH 87/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9610362292147163		[learning rate: 0.0082794]
	Learning Rate: 0.00827942
	LOSS [training: 0.9610362292147163 | validation: 1.277794698091112]
	TIME [epoch: 9.29 sec]
EPOCH 88/500:
	Training over batches...
		[batch 10/10] avg loss: 1.109696053426435		[learning rate: 0.0082372]
	Learning Rate: 0.00823716
	LOSS [training: 1.109696053426435 | validation: 1.183356095945223]
	TIME [epoch: 9.28 sec]
EPOCH 89/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0625503151509963		[learning rate: 0.0081951]
	Learning Rate: 0.00819512
	LOSS [training: 1.0625503151509963 | validation: 0.8158854209830477]
	TIME [epoch: 9.26 sec]
EPOCH 90/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8611068678987085		[learning rate: 0.0081533]
	Learning Rate: 0.0081533
	LOSS [training: 0.8611068678987085 | validation: 1.4312907510723114]
	TIME [epoch: 9.27 sec]
EPOCH 91/500:
	Training over batches...
		[batch 10/10] avg loss: 1.16223689931031		[learning rate: 0.0081117]
	Learning Rate: 0.00811169
	LOSS [training: 1.16223689931031 | validation: 1.0260046852875844]
	TIME [epoch: 9.27 sec]
EPOCH 92/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9744412718430215		[learning rate: 0.0080703]
	Learning Rate: 0.00807028
	LOSS [training: 0.9744412718430215 | validation: 0.7128101010279332]
	TIME [epoch: 9.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_92.pth
	Model improved!!!
EPOCH 93/500:
	Training over batches...
		[batch 10/10] avg loss: 1.4581860970298073		[learning rate: 0.0080291]
	Learning Rate: 0.0080291
	LOSS [training: 1.4581860970298073 | validation: 2.5301800126908724]
	TIME [epoch: 9.27 sec]
EPOCH 94/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0861268624246112		[learning rate: 0.0079881]
	Learning Rate: 0.00798812
	LOSS [training: 1.0861268624246112 | validation: 1.0377706651626097]
	TIME [epoch: 9.26 sec]
EPOCH 95/500:
	Training over batches...
		[batch 10/10] avg loss: 1.076015604248246		[learning rate: 0.0079473]
	Learning Rate: 0.00794735
	LOSS [training: 1.076015604248246 | validation: 1.6471947555546171]
	TIME [epoch: 9.28 sec]
EPOCH 96/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3537005310822625		[learning rate: 0.0079068]
	Learning Rate: 0.00790679
	LOSS [training: 1.3537005310822625 | validation: 1.4063622349531038]
	TIME [epoch: 9.26 sec]
EPOCH 97/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1058146854550492		[learning rate: 0.0078664]
	Learning Rate: 0.00786643
	LOSS [training: 1.1058146854550492 | validation: 1.2900529768207807]
	TIME [epoch: 9.25 sec]
EPOCH 98/500:
	Training over batches...
		[batch 10/10] avg loss: 1.096801732447286		[learning rate: 0.0078263]
	Learning Rate: 0.00782628
	LOSS [training: 1.096801732447286 | validation: 0.8699566196403943]
	TIME [epoch: 9.26 sec]
EPOCH 99/500:
	Training over batches...
		[batch 10/10] avg loss: 0.992592636149235		[learning rate: 0.0077863]
	Learning Rate: 0.00778634
	LOSS [training: 0.992592636149235 | validation: 0.6274550275943199]
	TIME [epoch: 9.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_99.pth
	Model improved!!!
EPOCH 100/500:
	Training over batches...
		[batch 10/10] avg loss: 1.151862656202575		[learning rate: 0.0077466]
	Learning Rate: 0.0077466
	LOSS [training: 1.151862656202575 | validation: 1.059872439927218]
	TIME [epoch: 9.26 sec]
EPOCH 101/500:
	Training over batches...
		[batch 10/10] avg loss: 1.050469618633555		[learning rate: 0.0077071]
	Learning Rate: 0.00770706
	LOSS [training: 1.050469618633555 | validation: 1.1273568087074441]
	TIME [epoch: 9.26 sec]
EPOCH 102/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8916387913651027		[learning rate: 0.0076677]
	Learning Rate: 0.00766773
	LOSS [training: 0.8916387913651027 | validation: 0.7076987577801854]
	TIME [epoch: 9.25 sec]
EPOCH 103/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8296351907318961		[learning rate: 0.0076286]
	Learning Rate: 0.00762859
	LOSS [training: 0.8296351907318961 | validation: 0.9576331500990486]
	TIME [epoch: 9.28 sec]
EPOCH 104/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8040222618066503		[learning rate: 0.0075897]
	Learning Rate: 0.00758966
	LOSS [training: 0.8040222618066503 | validation: 1.6434138622544079]
	TIME [epoch: 9.26 sec]
EPOCH 105/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1239296522247835		[learning rate: 0.0075509]
	Learning Rate: 0.00755092
	LOSS [training: 1.1239296522247835 | validation: 0.8979168058839043]
	TIME [epoch: 9.26 sec]
EPOCH 106/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9009877535746262		[learning rate: 0.0075124]
	Learning Rate: 0.00751238
	LOSS [training: 0.9009877535746262 | validation: 0.7408861585631586]
	TIME [epoch: 9.27 sec]
EPOCH 107/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8408489647660033		[learning rate: 0.007474]
	Learning Rate: 0.00747404
	LOSS [training: 0.8408489647660033 | validation: 1.1722830847185222]
	TIME [epoch: 9.29 sec]
EPOCH 108/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9758433710259269		[learning rate: 0.0074359]
	Learning Rate: 0.0074359
	LOSS [training: 0.9758433710259269 | validation: 0.7189472685452575]
	TIME [epoch: 9.27 sec]
EPOCH 109/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8301417344270758		[learning rate: 0.0073979]
	Learning Rate: 0.00739794
	LOSS [training: 0.8301417344270758 | validation: 0.8862913961299679]
	TIME [epoch: 9.26 sec]
EPOCH 110/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9298495224333463		[learning rate: 0.0073602]
	Learning Rate: 0.00736019
	LOSS [training: 0.9298495224333463 | validation: 0.6129570148252669]
	TIME [epoch: 9.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_110.pth
	Model improved!!!
EPOCH 111/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7891227798982643		[learning rate: 0.0073226]
	Learning Rate: 0.00732262
	LOSS [training: 0.7891227798982643 | validation: 1.1052613141052736]
	TIME [epoch: 9.3 sec]
EPOCH 112/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8251376321942205		[learning rate: 0.0072852]
	Learning Rate: 0.00728525
	LOSS [training: 0.8251376321942205 | validation: 0.87386567101391]
	TIME [epoch: 9.27 sec]
EPOCH 113/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1090504178033507		[learning rate: 0.0072481]
	Learning Rate: 0.00724807
	LOSS [training: 1.1090504178033507 | validation: 1.720606256228603]
	TIME [epoch: 9.26 sec]
EPOCH 114/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0491503723821305		[learning rate: 0.0072111]
	Learning Rate: 0.00721107
	LOSS [training: 1.0491503723821305 | validation: 0.5924798365362123]
	TIME [epoch: 9.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_114.pth
	Model improved!!!
EPOCH 115/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0903620234239682		[learning rate: 0.0071743]
	Learning Rate: 0.00717427
	LOSS [training: 1.0903620234239682 | validation: 1.32721930947338]
	TIME [epoch: 9.27 sec]
EPOCH 116/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3089136521381703		[learning rate: 0.0071377]
	Learning Rate: 0.00713765
	LOSS [training: 1.3089136521381703 | validation: 1.2991619206557712]
	TIME [epoch: 9.25 sec]
EPOCH 117/500:
	Training over batches...
		[batch 10/10] avg loss: 1.2562519442389173		[learning rate: 0.0071012]
	Learning Rate: 0.00710123
	LOSS [training: 1.2562519442389173 | validation: 1.4371314746021289]
	TIME [epoch: 9.24 sec]
EPOCH 118/500:
	Training over batches...
		[batch 10/10] avg loss: 1.101560586737469		[learning rate: 0.007065]
	Learning Rate: 0.00706498
	LOSS [training: 1.101560586737469 | validation: 1.0269667256922814]
	TIME [epoch: 9.25 sec]
EPOCH 119/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1612470707460036		[learning rate: 0.0070289]
	Learning Rate: 0.00702892
	LOSS [training: 1.1612470707460036 | validation: 0.8576844220698994]
	TIME [epoch: 9.27 sec]
EPOCH 120/500:
	Training over batches...
		[batch 10/10] avg loss: 1.322659187258721		[learning rate: 0.006993]
	Learning Rate: 0.00699305
	LOSS [training: 1.322659187258721 | validation: 1.1390662318450178]
	TIME [epoch: 9.26 sec]
EPOCH 121/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0242429973452558		[learning rate: 0.0069574]
	Learning Rate: 0.00695736
	LOSS [training: 1.0242429973452558 | validation: 1.294232563127972]
	TIME [epoch: 9.25 sec]
EPOCH 122/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9582293848292978		[learning rate: 0.0069219]
	Learning Rate: 0.00692185
	LOSS [training: 0.9582293848292978 | validation: 0.8146355718751335]
	TIME [epoch: 9.25 sec]
EPOCH 123/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1147022431052385		[learning rate: 0.0068865]
	Learning Rate: 0.00688652
	LOSS [training: 1.1147022431052385 | validation: 1.1004678466634987]
	TIME [epoch: 9.26 sec]
EPOCH 124/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8757972718857907		[learning rate: 0.0068514]
	Learning Rate: 0.00685138
	LOSS [training: 0.8757972718857907 | validation: 0.7244653212119226]
	TIME [epoch: 9.26 sec]
EPOCH 125/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9109491042166825		[learning rate: 0.0068164]
	Learning Rate: 0.00681641
	LOSS [training: 0.9109491042166825 | validation: 0.6922218398278028]
	TIME [epoch: 9.26 sec]
EPOCH 126/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9834271762948396		[learning rate: 0.0067816]
	Learning Rate: 0.00678162
	LOSS [training: 0.9834271762948396 | validation: 1.871866808201198]
	TIME [epoch: 9.25 sec]
EPOCH 127/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3680400052154154		[learning rate: 0.006747]
	Learning Rate: 0.00674701
	LOSS [training: 1.3680400052154154 | validation: 0.7133160284185257]
	TIME [epoch: 9.34 sec]
EPOCH 128/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8795754367578489		[learning rate: 0.0067126]
	Learning Rate: 0.00671257
	LOSS [training: 0.8795754367578489 | validation: 1.0495214864397655]
	TIME [epoch: 9.26 sec]
EPOCH 129/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8199040118539408		[learning rate: 0.0066783]
	Learning Rate: 0.00667831
	LOSS [training: 0.8199040118539408 | validation: 0.9857702967210912]
	TIME [epoch: 9.25 sec]
EPOCH 130/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9512854683150922		[learning rate: 0.0066442]
	Learning Rate: 0.00664423
	LOSS [training: 0.9512854683150922 | validation: 1.2951644870168153]
	TIME [epoch: 9.25 sec]
EPOCH 131/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9241165515163072		[learning rate: 0.0066103]
	Learning Rate: 0.00661032
	LOSS [training: 0.9241165515163072 | validation: 0.7136237919325717]
	TIME [epoch: 9.26 sec]
EPOCH 132/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9454972462528278		[learning rate: 0.0065766]
	Learning Rate: 0.00657658
	LOSS [training: 0.9454972462528278 | validation: 0.8367940541927542]
	TIME [epoch: 9.27 sec]
EPOCH 133/500:
	Training over batches...
		[batch 10/10] avg loss: 1.04882677096317		[learning rate: 0.006543]
	Learning Rate: 0.00654301
	LOSS [training: 1.04882677096317 | validation: 0.8180960111835663]
	TIME [epoch: 9.25 sec]
EPOCH 134/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7978075422967055		[learning rate: 0.0065096]
	Learning Rate: 0.00650962
	LOSS [training: 0.7978075422967055 | validation: 0.6808547180507464]
	TIME [epoch: 9.25 sec]
EPOCH 135/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9225119832428865		[learning rate: 0.0064764]
	Learning Rate: 0.00647639
	LOSS [training: 0.9225119832428865 | validation: 2.0232691107938714]
	TIME [epoch: 9.26 sec]
EPOCH 136/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9192626069387864		[learning rate: 0.0064433]
	Learning Rate: 0.00644334
	LOSS [training: 0.9192626069387864 | validation: 1.0369525603594238]
	TIME [epoch: 9.27 sec]
EPOCH 137/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8531683252993302		[learning rate: 0.0064105]
	Learning Rate: 0.00641046
	LOSS [training: 0.8531683252993302 | validation: 0.6198502198316725]
	TIME [epoch: 9.25 sec]
EPOCH 138/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8801962558866796		[learning rate: 0.0063777]
	Learning Rate: 0.00637774
	LOSS [training: 0.8801962558866796 | validation: 0.7037814784452938]
	TIME [epoch: 9.26 sec]
EPOCH 139/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8229815325767659		[learning rate: 0.0063452]
	Learning Rate: 0.00634519
	LOSS [training: 0.8229815325767659 | validation: 1.0374863151273752]
	TIME [epoch: 9.26 sec]
EPOCH 140/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9401284927173339		[learning rate: 0.0063128]
	Learning Rate: 0.0063128
	LOSS [training: 0.9401284927173339 | validation: 1.0411801335413333]
	TIME [epoch: 9.28 sec]
EPOCH 141/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8645506137678656		[learning rate: 0.0062806]
	Learning Rate: 0.00628058
	LOSS [training: 0.8645506137678656 | validation: 0.824773369789107]
	TIME [epoch: 9.25 sec]
EPOCH 142/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7667674815954505		[learning rate: 0.0062485]
	Learning Rate: 0.00624853
	LOSS [training: 0.7667674815954505 | validation: 0.9597947378595174]
	TIME [epoch: 9.25 sec]
EPOCH 143/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9398614416468958		[learning rate: 0.0062166]
	Learning Rate: 0.00621664
	LOSS [training: 0.9398614416468958 | validation: 2.405768796101337]
	TIME [epoch: 9.26 sec]
EPOCH 144/500:
	Training over batches...
		[batch 10/10] avg loss: 1.1862041357395026		[learning rate: 0.0061849]
	Learning Rate: 0.00618491
	LOSS [training: 1.1862041357395026 | validation: 0.8149453735322593]
	TIME [epoch: 9.28 sec]
EPOCH 145/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8205222938846836		[learning rate: 0.0061533]
	Learning Rate: 0.00615334
	LOSS [training: 0.8205222938846836 | validation: 0.6939309484005411]
	TIME [epoch: 9.27 sec]
EPOCH 146/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9037508598478705		[learning rate: 0.0061219]
	Learning Rate: 0.00612194
	LOSS [training: 0.9037508598478705 | validation: 0.7519317057031317]
	TIME [epoch: 9.26 sec]
EPOCH 147/500:
	Training over batches...
		[batch 10/10] avg loss: 1.0234904820385946		[learning rate: 0.0060907]
	Learning Rate: 0.00609069
	LOSS [training: 1.0234904820385946 | validation: 0.6522367741378532]
	TIME [epoch: 9.25 sec]
EPOCH 148/500:
	Training over batches...
		[batch 10/10] avg loss: 0.684776741726618		[learning rate: 0.0060596]
	Learning Rate: 0.00605961
	LOSS [training: 0.684776741726618 | validation: 0.6573196773546227]
	TIME [epoch: 9.28 sec]
EPOCH 149/500:
	Training over batches...
		[batch 10/10] avg loss: 0.863676966146366		[learning rate: 0.0060287]
	Learning Rate: 0.00602868
	LOSS [training: 0.863676966146366 | validation: 0.8895265202267219]
	TIME [epoch: 9.25 sec]
EPOCH 150/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7325554990204575		[learning rate: 0.0059979]
	Learning Rate: 0.00599791
	LOSS [training: 0.7325554990204575 | validation: 0.5944838984955337]
	TIME [epoch: 9.26 sec]
EPOCH 151/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7999073141265207		[learning rate: 0.0059673]
	Learning Rate: 0.0059673
	LOSS [training: 0.7999073141265207 | validation: 0.785704972651759]
	TIME [epoch: 9.26 sec]
EPOCH 152/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6169545039640824		[learning rate: 0.0059368]
	Learning Rate: 0.00593684
	LOSS [training: 0.6169545039640824 | validation: 0.751829058615896]
	TIME [epoch: 9.29 sec]
EPOCH 153/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7865680690073186		[learning rate: 0.0059065]
	Learning Rate: 0.00590654
	LOSS [training: 0.7865680690073186 | validation: 0.7824938009576847]
	TIME [epoch: 9.28 sec]
EPOCH 154/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8486999443870976		[learning rate: 0.0058764]
	Learning Rate: 0.0058764
	LOSS [training: 0.8486999443870976 | validation: 0.6702523615677185]
	TIME [epoch: 9.26 sec]
EPOCH 155/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6709156766204186		[learning rate: 0.0058464]
	Learning Rate: 0.0058464
	LOSS [training: 0.6709156766204186 | validation: 1.3773005719488516]
	TIME [epoch: 9.25 sec]
EPOCH 156/500:
	Training over batches...
		[batch 10/10] avg loss: 1.3296144259464893		[learning rate: 0.0058166]
	Learning Rate: 0.00581657
	LOSS [training: 1.3296144259464893 | validation: 0.7794832834410359]
	TIME [epoch: 9.27 sec]
EPOCH 157/500:
	Training over batches...
		[batch 10/10] avg loss: 0.91193801301815		[learning rate: 0.0057869]
	Learning Rate: 0.00578688
	LOSS [training: 0.91193801301815 | validation: 0.7250762951903363]
	TIME [epoch: 9.26 sec]
EPOCH 158/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7723289476267923		[learning rate: 0.0057573]
	Learning Rate: 0.00575734
	LOSS [training: 0.7723289476267923 | validation: 0.7484559879129642]
	TIME [epoch: 9.25 sec]
EPOCH 159/500:
	Training over batches...
		[batch 10/10] avg loss: 0.761191131735		[learning rate: 0.005728]
	Learning Rate: 0.00572796
	LOSS [training: 0.761191131735 | validation: 0.6188941156542801]
	TIME [epoch: 9.25 sec]
EPOCH 160/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6670574594287487		[learning rate: 0.0056987]
	Learning Rate: 0.00569873
	LOSS [training: 0.6670574594287487 | validation: 0.6115451291780903]
	TIME [epoch: 9.27 sec]
EPOCH 161/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7913301305982968		[learning rate: 0.0056696]
	Learning Rate: 0.00566964
	LOSS [training: 0.7913301305982968 | validation: 0.5198974963763469]
	TIME [epoch: 9.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_161.pth
	Model improved!!!
EPOCH 162/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7083748622605656		[learning rate: 0.0056407]
	Learning Rate: 0.0056407
	LOSS [training: 0.7083748622605656 | validation: 1.0122170368679921]
	TIME [epoch: 9.24 sec]
EPOCH 163/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8187861592354733		[learning rate: 0.0056119]
	Learning Rate: 0.00561191
	LOSS [training: 0.8187861592354733 | validation: 0.6125454612202325]
	TIME [epoch: 9.24 sec]
EPOCH 164/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6493578256181806		[learning rate: 0.0055833]
	Learning Rate: 0.00558327
	LOSS [training: 0.6493578256181806 | validation: 0.5857598889028414]
	TIME [epoch: 9.28 sec]
EPOCH 165/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8737248796353633		[learning rate: 0.0055548]
	Learning Rate: 0.00555478
	LOSS [training: 0.8737248796353633 | validation: 0.7988071281851296]
	TIME [epoch: 9.26 sec]
EPOCH 166/500:
	Training over batches...
		[batch 10/10] avg loss: 0.738717936587561		[learning rate: 0.0055264]
	Learning Rate: 0.00552643
	LOSS [training: 0.738717936587561 | validation: 0.7247108540669739]
	TIME [epoch: 9.26 sec]
EPOCH 167/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6951157051114039		[learning rate: 0.0054982]
	Learning Rate: 0.00549822
	LOSS [training: 0.6951157051114039 | validation: 0.9243207135968358]
	TIME [epoch: 9.25 sec]
EPOCH 168/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8221227084878882		[learning rate: 0.0054702]
	Learning Rate: 0.00547016
	LOSS [training: 0.8221227084878882 | validation: 1.3992589005864342]
	TIME [epoch: 9.26 sec]
EPOCH 169/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6619073283712615		[learning rate: 0.0054422]
	Learning Rate: 0.00544224
	LOSS [training: 0.6619073283712615 | validation: 0.573843204762939]
	TIME [epoch: 9.25 sec]
EPOCH 170/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5892220453147601		[learning rate: 0.0054145]
	Learning Rate: 0.00541446
	LOSS [training: 0.5892220453147601 | validation: 1.0643499726912535]
	TIME [epoch: 9.25 sec]
EPOCH 171/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8352758357769148		[learning rate: 0.0053868]
	Learning Rate: 0.00538683
	LOSS [training: 0.8352758357769148 | validation: 0.7229184795499467]
	TIME [epoch: 9.25 sec]
EPOCH 172/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6903257975800329		[learning rate: 0.0053593]
	Learning Rate: 0.00535934
	LOSS [training: 0.6903257975800329 | validation: 1.4845949561321412]
	TIME [epoch: 9.26 sec]
EPOCH 173/500:
	Training over batches...
		[batch 10/10] avg loss: 0.94365369216952		[learning rate: 0.005332]
	Learning Rate: 0.00533198
	LOSS [training: 0.94365369216952 | validation: 0.5420547595000786]
	TIME [epoch: 9.26 sec]
EPOCH 174/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8384669978939735		[learning rate: 0.0053048]
	Learning Rate: 0.00530477
	LOSS [training: 0.8384669978939735 | validation: 0.6066062658562178]
	TIME [epoch: 9.25 sec]
EPOCH 175/500:
	Training over batches...
		[batch 10/10] avg loss: 0.9688111367925227		[learning rate: 0.0052777]
	Learning Rate: 0.0052777
	LOSS [training: 0.9688111367925227 | validation: 0.7016640426526651]
	TIME [epoch: 9.25 sec]
EPOCH 176/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8736658112045121		[learning rate: 0.0052508]
	Learning Rate: 0.00525076
	LOSS [training: 0.8736658112045121 | validation: 0.906090911184997]
	TIME [epoch: 9.26 sec]
EPOCH 177/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8256192156949309		[learning rate: 0.005224]
	Learning Rate: 0.00522396
	LOSS [training: 0.8256192156949309 | validation: 0.701980460138389]
	TIME [epoch: 9.27 sec]
EPOCH 178/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5512046891776238		[learning rate: 0.0051973]
	Learning Rate: 0.0051973
	LOSS [training: 0.5512046891776238 | validation: 0.8197221821443336]
	TIME [epoch: 9.25 sec]
EPOCH 179/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7691552109749664		[learning rate: 0.0051708]
	Learning Rate: 0.00517077
	LOSS [training: 0.7691552109749664 | validation: 0.8024101147443506]
	TIME [epoch: 9.25 sec]
EPOCH 180/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7540944299862566		[learning rate: 0.0051444]
	Learning Rate: 0.00514438
	LOSS [training: 0.7540944299862566 | validation: 0.5900244757854239]
	TIME [epoch: 9.26 sec]
EPOCH 181/500:
	Training over batches...
		[batch 10/10] avg loss: 0.645195780761477		[learning rate: 0.0051181]
	Learning Rate: 0.00511813
	LOSS [training: 0.645195780761477 | validation: 0.5713002943185593]
	TIME [epoch: 9.26 sec]
EPOCH 182/500:
	Training over batches...
		[batch 10/10] avg loss: 0.577577358376223		[learning rate: 0.005092]
	Learning Rate: 0.00509201
	LOSS [training: 0.577577358376223 | validation: 0.919332375475363]
	TIME [epoch: 9.24 sec]
EPOCH 183/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5884745280117627		[learning rate: 0.005066]
	Learning Rate: 0.00506602
	LOSS [training: 0.5884745280117627 | validation: 0.5489956057816096]
	TIME [epoch: 9.24 sec]
EPOCH 184/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6227948457463255		[learning rate: 0.0050402]
	Learning Rate: 0.00504016
	LOSS [training: 0.6227948457463255 | validation: 0.6293874355566772]
	TIME [epoch: 9.24 sec]
EPOCH 185/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6802030649761681		[learning rate: 0.0050144]
	Learning Rate: 0.00501444
	LOSS [training: 0.6802030649761681 | validation: 0.6077286605402143]
	TIME [epoch: 9.27 sec]
EPOCH 186/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6560671969365862		[learning rate: 0.0049888]
	Learning Rate: 0.00498884
	LOSS [training: 0.6560671969365862 | validation: 0.905924514170557]
	TIME [epoch: 9.24 sec]
EPOCH 187/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8033462578462405		[learning rate: 0.0049634]
	Learning Rate: 0.00496338
	LOSS [training: 0.8033462578462405 | validation: 0.683217701852337]
	TIME [epoch: 9.24 sec]
EPOCH 188/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6077214437236158		[learning rate: 0.0049381]
	Learning Rate: 0.00493805
	LOSS [training: 0.6077214437236158 | validation: 0.7917281842208368]
	TIME [epoch: 9.23 sec]
EPOCH 189/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5924275792083356		[learning rate: 0.0049128]
	Learning Rate: 0.00491285
	LOSS [training: 0.5924275792083356 | validation: 0.4083051202785306]
	TIME [epoch: 9.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_189.pth
	Model improved!!!
EPOCH 190/500:
	Training over batches...
		[batch 10/10] avg loss: 0.608935053684944		[learning rate: 0.0048878]
	Learning Rate: 0.00488777
	LOSS [training: 0.608935053684944 | validation: 0.6225060587903949]
	TIME [epoch: 9.26 sec]
EPOCH 191/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6860463709430225		[learning rate: 0.0048628]
	Learning Rate: 0.00486283
	LOSS [training: 0.6860463709430225 | validation: 0.7766641607206842]
	TIME [epoch: 9.25 sec]
EPOCH 192/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6092530609017817		[learning rate: 0.004838]
	Learning Rate: 0.00483801
	LOSS [training: 0.6092530609017817 | validation: 0.6382926410776506]
	TIME [epoch: 9.25 sec]
EPOCH 193/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6054474099262712		[learning rate: 0.0048133]
	Learning Rate: 0.00481332
	LOSS [training: 0.6054474099262712 | validation: 0.5829566151176452]
	TIME [epoch: 9.27 sec]
EPOCH 194/500:
	Training over batches...
		[batch 10/10] avg loss: 0.545899984370376		[learning rate: 0.0047888]
	Learning Rate: 0.00478875
	LOSS [training: 0.545899984370376 | validation: 0.55418988306959]
	TIME [epoch: 9.23 sec]
EPOCH 195/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6225964064403562		[learning rate: 0.0047643]
	Learning Rate: 0.00476431
	LOSS [training: 0.6225964064403562 | validation: 0.9999997901424879]
	TIME [epoch: 9.25 sec]
EPOCH 196/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6469197781300391		[learning rate: 0.00474]
	Learning Rate: 0.00473999
	LOSS [training: 0.6469197781300391 | validation: 0.6906032900178118]
	TIME [epoch: 9.24 sec]
EPOCH 197/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5707758563681014		[learning rate: 0.0047158]
	Learning Rate: 0.0047158
	LOSS [training: 0.5707758563681014 | validation: 0.4834266773003157]
	TIME [epoch: 9.27 sec]
EPOCH 198/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6175679559215437		[learning rate: 0.0046917]
	Learning Rate: 0.00469173
	LOSS [training: 0.6175679559215437 | validation: 0.8301685345787945]
	TIME [epoch: 9.26 sec]
EPOCH 199/500:
	Training over batches...
		[batch 10/10] avg loss: 0.684602012046945		[learning rate: 0.0046678]
	Learning Rate: 0.00466779
	LOSS [training: 0.684602012046945 | validation: 0.5116082732391778]
	TIME [epoch: 9.26 sec]
EPOCH 200/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5835012774675681		[learning rate: 0.004644]
	Learning Rate: 0.00464396
	LOSS [training: 0.5835012774675681 | validation: 0.5109663057841888]
	TIME [epoch: 9.26 sec]
EPOCH 201/500:
	Training over batches...
		[batch 10/10] avg loss: 0.634379215627703		[learning rate: 0.0046203]
	Learning Rate: 0.00462026
	LOSS [training: 0.634379215627703 | validation: 0.5117310184848841]
	TIME [epoch: 9.27 sec]
EPOCH 202/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5067172502358037		[learning rate: 0.0045967]
	Learning Rate: 0.00459668
	LOSS [training: 0.5067172502358037 | validation: 0.6768522521763245]
	TIME [epoch: 9.27 sec]
EPOCH 203/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7609410727580581		[learning rate: 0.0045732]
	Learning Rate: 0.00457322
	LOSS [training: 0.7609410727580581 | validation: 1.344819738975229]
	TIME [epoch: 9.27 sec]
EPOCH 204/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8171646424210305		[learning rate: 0.0045499]
	Learning Rate: 0.00454988
	LOSS [training: 0.8171646424210305 | validation: 0.7999214152608572]
	TIME [epoch: 9.26 sec]
EPOCH 205/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6503295063936404		[learning rate: 0.0045267]
	Learning Rate: 0.00452666
	LOSS [training: 0.6503295063936404 | validation: 1.0018493579460999]
	TIME [epoch: 9.26 sec]
EPOCH 206/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5774165659505888		[learning rate: 0.0045036]
	Learning Rate: 0.00450356
	LOSS [training: 0.5774165659505888 | validation: 0.837595309626467]
	TIME [epoch: 9.25 sec]
EPOCH 207/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5467880311483493		[learning rate: 0.0044806]
	Learning Rate: 0.00448057
	LOSS [training: 0.5467880311483493 | validation: 0.7441911357457253]
	TIME [epoch: 9.24 sec]
EPOCH 208/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5424341368249885		[learning rate: 0.0044577]
	Learning Rate: 0.0044577
	LOSS [training: 0.5424341368249885 | validation: 0.7853841295298473]
	TIME [epoch: 9.25 sec]
EPOCH 209/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5643340435975367		[learning rate: 0.004435]
	Learning Rate: 0.00443495
	LOSS [training: 0.5643340435975367 | validation: 0.5828226328855627]
	TIME [epoch: 9.27 sec]
EPOCH 210/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6948728667486281		[learning rate: 0.0044123]
	Learning Rate: 0.00441232
	LOSS [training: 0.6948728667486281 | validation: 0.5029868307476524]
	TIME [epoch: 9.25 sec]
EPOCH 211/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6663111235509149		[learning rate: 0.0043898]
	Learning Rate: 0.0043898
	LOSS [training: 0.6663111235509149 | validation: 0.9256341584692634]
	TIME [epoch: 9.25 sec]
EPOCH 212/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5322192716756361		[learning rate: 0.0043674]
	Learning Rate: 0.00436739
	LOSS [training: 0.5322192716756361 | validation: 0.7151547569318945]
	TIME [epoch: 9.25 sec]
EPOCH 213/500:
	Training over batches...
		[batch 10/10] avg loss: 0.48332233637436345		[learning rate: 0.0043451]
	Learning Rate: 0.0043451
	LOSS [training: 0.48332233637436345 | validation: 0.4454846083790462]
	TIME [epoch: 9.26 sec]
EPOCH 214/500:
	Training over batches...
		[batch 10/10] avg loss: 0.47200146482800126		[learning rate: 0.0043229]
	Learning Rate: 0.00432293
	LOSS [training: 0.47200146482800126 | validation: 0.44378636894770435]
	TIME [epoch: 9.26 sec]
EPOCH 215/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4857809993476381		[learning rate: 0.0043009]
	Learning Rate: 0.00430086
	LOSS [training: 0.4857809993476381 | validation: 0.8531367437085158]
	TIME [epoch: 9.26 sec]
EPOCH 216/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6195445508134234		[learning rate: 0.0042789]
	Learning Rate: 0.00427891
	LOSS [training: 0.6195445508134234 | validation: 0.964381228724403]
	TIME [epoch: 9.26 sec]
EPOCH 217/500:
	Training over batches...
		[batch 10/10] avg loss: 0.7275154714803513		[learning rate: 0.0042571]
	Learning Rate: 0.00425707
	LOSS [training: 0.7275154714803513 | validation: 0.9174602617703416]
	TIME [epoch: 9.27 sec]
EPOCH 218/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6698669612521931		[learning rate: 0.0042353]
	Learning Rate: 0.00423535
	LOSS [training: 0.6698669612521931 | validation: 0.5334633123156604]
	TIME [epoch: 9.26 sec]
EPOCH 219/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5540457520821318		[learning rate: 0.0042137]
	Learning Rate: 0.00421373
	LOSS [training: 0.5540457520821318 | validation: 0.45643287960950424]
	TIME [epoch: 9.25 sec]
EPOCH 220/500:
	Training over batches...
		[batch 10/10] avg loss: 0.47156897241003604		[learning rate: 0.0041922]
	Learning Rate: 0.00419222
	LOSS [training: 0.47156897241003604 | validation: 0.3001592098840671]
	TIME [epoch: 9.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_220.pth
	Model improved!!!
EPOCH 221/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5467529530601087		[learning rate: 0.0041708]
	Learning Rate: 0.00417083
	LOSS [training: 0.5467529530601087 | validation: 0.3572907696708875]
	TIME [epoch: 9.26 sec]
EPOCH 222/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5874491149859404		[learning rate: 0.0041495]
	Learning Rate: 0.00414954
	LOSS [training: 0.5874491149859404 | validation: 0.36041977364269323]
	TIME [epoch: 9.27 sec]
EPOCH 223/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5233456476956799		[learning rate: 0.0041284]
	Learning Rate: 0.00412836
	LOSS [training: 0.5233456476956799 | validation: 0.4766050910281539]
	TIME [epoch: 9.26 sec]
EPOCH 224/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4880959799590312		[learning rate: 0.0041073]
	Learning Rate: 0.00410729
	LOSS [training: 0.4880959799590312 | validation: 0.48831091518460595]
	TIME [epoch: 9.26 sec]
EPOCH 225/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5266813312183568		[learning rate: 0.0040863]
	Learning Rate: 0.00408633
	LOSS [training: 0.5266813312183568 | validation: 0.5701429372431944]
	TIME [epoch: 9.25 sec]
EPOCH 226/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5204655981963968		[learning rate: 0.0040655]
	Learning Rate: 0.00406547
	LOSS [training: 0.5204655981963968 | validation: 0.5229942627982309]
	TIME [epoch: 9.28 sec]
EPOCH 227/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5667162377954824		[learning rate: 0.0040447]
	Learning Rate: 0.00404472
	LOSS [training: 0.5667162377954824 | validation: 0.4752298567428313]
	TIME [epoch: 9.25 sec]
EPOCH 228/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5007738005861924		[learning rate: 0.0040241]
	Learning Rate: 0.00402408
	LOSS [training: 0.5007738005861924 | validation: 0.674752558504241]
	TIME [epoch: 9.25 sec]
EPOCH 229/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5290520786577831		[learning rate: 0.0040035]
	Learning Rate: 0.00400354
	LOSS [training: 0.5290520786577831 | validation: 0.53454541050158]
	TIME [epoch: 9.26 sec]
EPOCH 230/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4815029084754502		[learning rate: 0.0039831]
	Learning Rate: 0.00398311
	LOSS [training: 0.4815029084754502 | validation: 0.4152956178280151]
	TIME [epoch: 9.29 sec]
EPOCH 231/500:
	Training over batches...
		[batch 10/10] avg loss: 0.49510465201241793		[learning rate: 0.0039628]
	Learning Rate: 0.00396278
	LOSS [training: 0.49510465201241793 | validation: 0.5272205111284546]
	TIME [epoch: 9.26 sec]
EPOCH 232/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4582067466362324		[learning rate: 0.0039426]
	Learning Rate: 0.00394256
	LOSS [training: 0.4582067466362324 | validation: 0.5913047940634266]
	TIME [epoch: 9.26 sec]
EPOCH 233/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6610130939381772		[learning rate: 0.0039224]
	Learning Rate: 0.00392243
	LOSS [training: 0.6610130939381772 | validation: 0.6638521557868396]
	TIME [epoch: 9.25 sec]
EPOCH 234/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6649984857222333		[learning rate: 0.0039024]
	Learning Rate: 0.00390241
	LOSS [training: 0.6649984857222333 | validation: 0.38920349893172473]
	TIME [epoch: 9.27 sec]
EPOCH 235/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5091607740731602		[learning rate: 0.0038825]
	Learning Rate: 0.0038825
	LOSS [training: 0.5091607740731602 | validation: 0.6213465068070793]
	TIME [epoch: 9.26 sec]
EPOCH 236/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5561951084746309		[learning rate: 0.0038627]
	Learning Rate: 0.00386268
	LOSS [training: 0.5561951084746309 | validation: 0.9642246735017652]
	TIME [epoch: 9.25 sec]
EPOCH 237/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5868944600100143		[learning rate: 0.003843]
	Learning Rate: 0.00384297
	LOSS [training: 0.5868944600100143 | validation: 0.7532593983290011]
	TIME [epoch: 9.25 sec]
EPOCH 238/500:
	Training over batches...
		[batch 10/10] avg loss: 0.45266100860284963		[learning rate: 0.0038234]
	Learning Rate: 0.00382335
	LOSS [training: 0.45266100860284963 | validation: 0.526009589717397]
	TIME [epoch: 9.28 sec]
EPOCH 239/500:
	Training over batches...
		[batch 10/10] avg loss: 0.8362700303701814		[learning rate: 0.0038038]
	Learning Rate: 0.00380384
	LOSS [training: 0.8362700303701814 | validation: 1.619545370882063]
	TIME [epoch: 9.25 sec]
EPOCH 240/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5906023782087334		[learning rate: 0.0037844]
	Learning Rate: 0.00378443
	LOSS [training: 0.5906023782087334 | validation: 0.5802352975440414]
	TIME [epoch: 9.26 sec]
EPOCH 241/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6271335680759581		[learning rate: 0.0037651]
	Learning Rate: 0.00376511
	LOSS [training: 0.6271335680759581 | validation: 0.5471988818953234]
	TIME [epoch: 9.26 sec]
EPOCH 242/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5613498695988277		[learning rate: 0.0037459]
	Learning Rate: 0.00374589
	LOSS [training: 0.5613498695988277 | validation: 0.5378728480336114]
	TIME [epoch: 9.29 sec]
EPOCH 243/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6220747680033274		[learning rate: 0.0037268]
	Learning Rate: 0.00372678
	LOSS [training: 0.6220747680033274 | validation: 0.6139678992096879]
	TIME [epoch: 9.27 sec]
EPOCH 244/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5895467979629604		[learning rate: 0.0037078]
	Learning Rate: 0.00370776
	LOSS [training: 0.5895467979629604 | validation: 0.6227689770500439]
	TIME [epoch: 9.25 sec]
EPOCH 245/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4764262220494519		[learning rate: 0.0036888]
	Learning Rate: 0.00368883
	LOSS [training: 0.4764262220494519 | validation: 0.4124169800793538]
	TIME [epoch: 9.25 sec]
EPOCH 246/500:
	Training over batches...
		[batch 10/10] avg loss: 0.41765383423162633		[learning rate: 0.00367]
	Learning Rate: 0.00367
	LOSS [training: 0.41765383423162633 | validation: 0.4647078409935535]
	TIME [epoch: 9.27 sec]
EPOCH 247/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5273991655885519		[learning rate: 0.0036513]
	Learning Rate: 0.00365127
	LOSS [training: 0.5273991655885519 | validation: 0.5153973033640654]
	TIME [epoch: 9.25 sec]
EPOCH 248/500:
	Training over batches...
		[batch 10/10] avg loss: 0.41594657394672174		[learning rate: 0.0036326]
	Learning Rate: 0.00363264
	LOSS [training: 0.41594657394672174 | validation: 0.4017799559927669]
	TIME [epoch: 9.25 sec]
EPOCH 249/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5256631050712488		[learning rate: 0.0036141]
	Learning Rate: 0.0036141
	LOSS [training: 0.5256631050712488 | validation: 0.46043378548767455]
	TIME [epoch: 9.24 sec]
EPOCH 250/500:
	Training over batches...
		[batch 10/10] avg loss: 0.39641143726801215		[learning rate: 0.0035957]
	Learning Rate: 0.00359565
	LOSS [training: 0.39641143726801215 | validation: 0.46928198372598057]
	TIME [epoch: 9.27 sec]
EPOCH 251/500:
	Training over batches...
		[batch 10/10] avg loss: 0.469910731814113		[learning rate: 0.0035773]
	Learning Rate: 0.0035773
	LOSS [training: 0.469910731814113 | validation: 1.2518166935910937]
	TIME [epoch: 9.25 sec]
EPOCH 252/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4887097706278986		[learning rate: 0.003559]
	Learning Rate: 0.00355904
	LOSS [training: 0.4887097706278986 | validation: 0.34565930998016253]
	TIME [epoch: 9.25 sec]
EPOCH 253/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4236506832943953		[learning rate: 0.0035409]
	Learning Rate: 0.00354088
	LOSS [training: 0.4236506832943953 | validation: 0.6113249910827125]
	TIME [epoch: 9.25 sec]
EPOCH 254/500:
	Training over batches...
		[batch 10/10] avg loss: 0.46405054453148387		[learning rate: 0.0035228]
	Learning Rate: 0.00352281
	LOSS [training: 0.46405054453148387 | validation: 0.2896149090103925]
	TIME [epoch: 9.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_254.pth
	Model improved!!!
EPOCH 255/500:
	Training over batches...
		[batch 10/10] avg loss: 0.46683035445562115		[learning rate: 0.0035048]
	Learning Rate: 0.00350483
	LOSS [training: 0.46683035445562115 | validation: 0.6238216864642422]
	TIME [epoch: 9.26 sec]
EPOCH 256/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4826566620777456		[learning rate: 0.0034869]
	Learning Rate: 0.00348694
	LOSS [training: 0.4826566620777456 | validation: 0.5031128316001979]
	TIME [epoch: 9.24 sec]
EPOCH 257/500:
	Training over batches...
		[batch 10/10] avg loss: 0.40629163426084985		[learning rate: 0.0034691]
	Learning Rate: 0.00346914
	LOSS [training: 0.40629163426084985 | validation: 1.1300324189551347]
	TIME [epoch: 9.24 sec]
EPOCH 258/500:
	Training over batches...
		[batch 10/10] avg loss: 0.44335743969459696		[learning rate: 0.0034514]
	Learning Rate: 0.00345144
	LOSS [training: 0.44335743969459696 | validation: 0.3527537965985325]
	TIME [epoch: 9.24 sec]
EPOCH 259/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5285122437024931		[learning rate: 0.0034338]
	Learning Rate: 0.00343382
	LOSS [training: 0.5285122437024931 | validation: 0.38644275166464365]
	TIME [epoch: 9.25 sec]
EPOCH 260/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5434507878683574		[learning rate: 0.0034163]
	Learning Rate: 0.0034163
	LOSS [training: 0.5434507878683574 | validation: 0.6503090089958922]
	TIME [epoch: 9.23 sec]
EPOCH 261/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6109364995979215		[learning rate: 0.0033989]
	Learning Rate: 0.00339886
	LOSS [training: 0.6109364995979215 | validation: 0.7496354696556797]
	TIME [epoch: 9.23 sec]
EPOCH 262/500:
	Training over batches...
		[batch 10/10] avg loss: 0.6767298149105141		[learning rate: 0.0033815]
	Learning Rate: 0.00338151
	LOSS [training: 0.6767298149105141 | validation: 0.46929020447166314]
	TIME [epoch: 9.24 sec]
EPOCH 263/500:
	Training over batches...
		[batch 10/10] avg loss: 0.41405930192590656		[learning rate: 0.0033643]
	Learning Rate: 0.00336425
	LOSS [training: 0.41405930192590656 | validation: 0.7960055480376079]
	TIME [epoch: 9.26 sec]
EPOCH 264/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5293646174923067		[learning rate: 0.0033471]
	Learning Rate: 0.00334708
	LOSS [training: 0.5293646174923067 | validation: 0.5915223904628295]
	TIME [epoch: 9.24 sec]
EPOCH 265/500:
	Training over batches...
		[batch 10/10] avg loss: 0.44721855893900814		[learning rate: 0.00333]
	Learning Rate: 0.00333
	LOSS [training: 0.44721855893900814 | validation: 0.9301361550299014]
	TIME [epoch: 9.23 sec]
EPOCH 266/500:
	Training over batches...
		[batch 10/10] avg loss: 0.38736178230576723		[learning rate: 0.003313]
	Learning Rate: 0.00331301
	LOSS [training: 0.38736178230576723 | validation: 0.3754916807111635]
	TIME [epoch: 9.27 sec]
EPOCH 267/500:
	Training over batches...
		[batch 10/10] avg loss: 0.42492001789352063		[learning rate: 0.0032961]
	Learning Rate: 0.0032961
	LOSS [training: 0.42492001789352063 | validation: 0.6744235450307053]
	TIME [epoch: 9.25 sec]
EPOCH 268/500:
	Training over batches...
		[batch 10/10] avg loss: 0.47290110813245567		[learning rate: 0.0032793]
	Learning Rate: 0.00327927
	LOSS [training: 0.47290110813245567 | validation: 0.6219257534793347]
	TIME [epoch: 9.24 sec]
EPOCH 269/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5659601809846103		[learning rate: 0.0032625]
	Learning Rate: 0.00326254
	LOSS [training: 0.5659601809846103 | validation: 0.36949260471737855]
	TIME [epoch: 9.24 sec]
EPOCH 270/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4597580734287992		[learning rate: 0.0032459]
	Learning Rate: 0.00324589
	LOSS [training: 0.4597580734287992 | validation: 0.643744907092477]
	TIME [epoch: 9.23 sec]
EPOCH 271/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3596521293328844		[learning rate: 0.0032293]
	Learning Rate: 0.00322932
	LOSS [training: 0.3596521293328844 | validation: 1.1800007953916412]
	TIME [epoch: 9.25 sec]
EPOCH 272/500:
	Training over batches...
		[batch 10/10] avg loss: 0.788429246058079		[learning rate: 0.0032128]
	Learning Rate: 0.00321284
	LOSS [training: 0.788429246058079 | validation: 0.3963410850587931]
	TIME [epoch: 9.24 sec]
EPOCH 273/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4175507423247584		[learning rate: 0.0031964]
	Learning Rate: 0.00319644
	LOSS [training: 0.4175507423247584 | validation: 0.7457997739108699]
	TIME [epoch: 9.24 sec]
EPOCH 274/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3580371773506591		[learning rate: 0.0031801]
	Learning Rate: 0.00318013
	LOSS [training: 0.3580371773506591 | validation: 0.5044180068196473]
	TIME [epoch: 9.24 sec]
EPOCH 275/500:
	Training over batches...
		[batch 10/10] avg loss: 0.38262869601392435		[learning rate: 0.0031639]
	Learning Rate: 0.0031639
	LOSS [training: 0.38262869601392435 | validation: 0.7734052153414922]
	TIME [epoch: 9.25 sec]
EPOCH 276/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4734119399686286		[learning rate: 0.0031477]
	Learning Rate: 0.00314775
	LOSS [training: 0.4734119399686286 | validation: 0.8665334346646077]
	TIME [epoch: 9.23 sec]
EPOCH 277/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5292406325880921		[learning rate: 0.0031317]
	Learning Rate: 0.00313168
	LOSS [training: 0.5292406325880921 | validation: 0.5123819740686084]
	TIME [epoch: 9.23 sec]
EPOCH 278/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4107483446036576		[learning rate: 0.0031157]
	Learning Rate: 0.0031157
	LOSS [training: 0.4107483446036576 | validation: 0.5471254482943495]
	TIME [epoch: 9.23 sec]
EPOCH 279/500:
	Training over batches...
		[batch 10/10] avg loss: 0.40396331044716327		[learning rate: 0.0030998]
	Learning Rate: 0.0030998
	LOSS [training: 0.40396331044716327 | validation: 0.7140139299226792]
	TIME [epoch: 9.25 sec]
EPOCH 280/500:
	Training over batches...
		[batch 10/10] avg loss: 0.37547093786096775		[learning rate: 0.003084]
	Learning Rate: 0.00308398
	LOSS [training: 0.37547093786096775 | validation: 0.6473716653006506]
	TIME [epoch: 9.25 sec]
EPOCH 281/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3785683786629902		[learning rate: 0.0030682]
	Learning Rate: 0.00306824
	LOSS [training: 0.3785683786629902 | validation: 0.5093629817191802]
	TIME [epoch: 9.24 sec]
EPOCH 282/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4354231175958246		[learning rate: 0.0030526]
	Learning Rate: 0.00305258
	LOSS [training: 0.4354231175958246 | validation: 0.5326990929189247]
	TIME [epoch: 9.25 sec]
EPOCH 283/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5565727870645909		[learning rate: 0.003037]
	Learning Rate: 0.003037
	LOSS [training: 0.5565727870645909 | validation: 0.28961128215044285]
	TIME [epoch: 9.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_283.pth
	Model improved!!!
EPOCH 284/500:
	Training over batches...
		[batch 10/10] avg loss: 0.33622726625653243		[learning rate: 0.0030215]
	Learning Rate: 0.0030215
	LOSS [training: 0.33622726625653243 | validation: 1.0908523012598874]
	TIME [epoch: 9.24 sec]
EPOCH 285/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5704829255727842		[learning rate: 0.0030061]
	Learning Rate: 0.00300608
	LOSS [training: 0.5704829255727842 | validation: 0.3480948318878896]
	TIME [epoch: 9.23 sec]
EPOCH 286/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5233765120636957		[learning rate: 0.0029907]
	Learning Rate: 0.00299073
	LOSS [training: 0.5233765120636957 | validation: 0.26785494421621153]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_286.pth
	Model improved!!!
EPOCH 287/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4269710210532658		[learning rate: 0.0029755]
	Learning Rate: 0.00297547
	LOSS [training: 0.4269710210532658 | validation: 0.368781324675936]
	TIME [epoch: 9.28 sec]
EPOCH 288/500:
	Training over batches...
		[batch 10/10] avg loss: 0.37210680258699413		[learning rate: 0.0029603]
	Learning Rate: 0.00296028
	LOSS [training: 0.37210680258699413 | validation: 0.39823135236559626]
	TIME [epoch: 9.26 sec]
EPOCH 289/500:
	Training over batches...
		[batch 10/10] avg loss: 0.306975441866396		[learning rate: 0.0029452]
	Learning Rate: 0.00294517
	LOSS [training: 0.306975441866396 | validation: 0.3840553071409269]
	TIME [epoch: 9.25 sec]
EPOCH 290/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3920904811948239		[learning rate: 0.0029301]
	Learning Rate: 0.00293014
	LOSS [training: 0.3920904811948239 | validation: 0.40766045715369104]
	TIME [epoch: 9.25 sec]
EPOCH 291/500:
	Training over batches...
		[batch 10/10] avg loss: 0.36401802993197374		[learning rate: 0.0029152]
	Learning Rate: 0.00291519
	LOSS [training: 0.36401802993197374 | validation: 0.8136163789249582]
	TIME [epoch: 9.26 sec]
EPOCH 292/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4947959628462302		[learning rate: 0.0029003]
	Learning Rate: 0.00290031
	LOSS [training: 0.4947959628462302 | validation: 0.7194230532089586]
	TIME [epoch: 9.27 sec]
EPOCH 293/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5066718404968042		[learning rate: 0.0028855]
	Learning Rate: 0.00288551
	LOSS [training: 0.5066718404968042 | validation: 0.4252702452393586]
	TIME [epoch: 9.27 sec]
EPOCH 294/500:
	Training over batches...
		[batch 10/10] avg loss: 0.407095285063021		[learning rate: 0.0028708]
	Learning Rate: 0.00287078
	LOSS [training: 0.407095285063021 | validation: 0.5125282432097624]
	TIME [epoch: 9.26 sec]
EPOCH 295/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3749930221781169		[learning rate: 0.0028561]
	Learning Rate: 0.00285613
	LOSS [training: 0.3749930221781169 | validation: 0.48974027545363014]
	TIME [epoch: 9.27 sec]
EPOCH 296/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4116840319214187		[learning rate: 0.0028416]
	Learning Rate: 0.00284155
	LOSS [training: 0.4116840319214187 | validation: 0.8779796970169483]
	TIME [epoch: 9.27 sec]
EPOCH 297/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4138585994625307		[learning rate: 0.002827]
	Learning Rate: 0.00282705
	LOSS [training: 0.4138585994625307 | validation: 0.5185048577659588]
	TIME [epoch: 9.25 sec]
EPOCH 298/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3069917443193936		[learning rate: 0.0028126]
	Learning Rate: 0.00281262
	LOSS [training: 0.3069917443193936 | validation: 0.44638484523266553]
	TIME [epoch: 9.25 sec]
EPOCH 299/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5042692398553746		[learning rate: 0.0027983]
	Learning Rate: 0.00279827
	LOSS [training: 0.5042692398553746 | validation: 1.0251164769281482]
	TIME [epoch: 9.25 sec]
EPOCH 300/500:
	Training over batches...
		[batch 10/10] avg loss: 0.46887817706695306		[learning rate: 0.002784]
	Learning Rate: 0.00278398
	LOSS [training: 0.46887817706695306 | validation: 0.2896985874745133]
	TIME [epoch: 9.27 sec]
EPOCH 301/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3444432109179786		[learning rate: 0.0027698]
	Learning Rate: 0.00276977
	LOSS [training: 0.3444432109179786 | validation: 0.44275544637915704]
	TIME [epoch: 9.25 sec]
EPOCH 302/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3633700970447288		[learning rate: 0.0027556]
	Learning Rate: 0.00275564
	LOSS [training: 0.3633700970447288 | validation: 0.6785031322602055]
	TIME [epoch: 9.25 sec]
EPOCH 303/500:
	Training over batches...
		[batch 10/10] avg loss: 0.40655493033345136		[learning rate: 0.0027416]
	Learning Rate: 0.00274157
	LOSS [training: 0.40655493033345136 | validation: 0.5673846211527195]
	TIME [epoch: 9.25 sec]
EPOCH 304/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4510897489768568		[learning rate: 0.0027276]
	Learning Rate: 0.00272758
	LOSS [training: 0.4510897489768568 | validation: 0.2894536510752202]
	TIME [epoch: 9.27 sec]
EPOCH 305/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3221219066085882		[learning rate: 0.0027137]
	Learning Rate: 0.00271366
	LOSS [training: 0.3221219066085882 | validation: 0.5583104775319141]
	TIME [epoch: 9.25 sec]
EPOCH 306/500:
	Training over batches...
		[batch 10/10] avg loss: 0.40130804642051576		[learning rate: 0.0026998]
	Learning Rate: 0.00269981
	LOSS [training: 0.40130804642051576 | validation: 0.3998994623649186]
	TIME [epoch: 9.26 sec]
EPOCH 307/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2717684156456214		[learning rate: 0.002686]
	Learning Rate: 0.00268603
	LOSS [training: 0.2717684156456214 | validation: 0.33708893593467676]
	TIME [epoch: 9.26 sec]
EPOCH 308/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4017464033508852		[learning rate: 0.0026723]
	Learning Rate: 0.00267232
	LOSS [training: 0.4017464033508852 | validation: 0.3586399566866448]
	TIME [epoch: 9.29 sec]
EPOCH 309/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2998030823217571		[learning rate: 0.0026587]
	Learning Rate: 0.00265868
	LOSS [training: 0.2998030823217571 | validation: 0.2337738305254281]
	TIME [epoch: 9.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_309.pth
	Model improved!!!
EPOCH 310/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3208780514267555		[learning rate: 0.0026451]
	Learning Rate: 0.00264511
	LOSS [training: 0.3208780514267555 | validation: 0.38606408126369707]
	TIME [epoch: 9.26 sec]
EPOCH 311/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4304124828813082		[learning rate: 0.0026316]
	Learning Rate: 0.00263161
	LOSS [training: 0.4304124828813082 | validation: 0.3271553912499857]
	TIME [epoch: 9.25 sec]
EPOCH 312/500:
	Training over batches...
		[batch 10/10] avg loss: 0.38197742485167613		[learning rate: 0.0026182]
	Learning Rate: 0.00261818
	LOSS [training: 0.38197742485167613 | validation: 0.5365510986790613]
	TIME [epoch: 9.27 sec]
EPOCH 313/500:
	Training over batches...
		[batch 10/10] avg loss: 0.31984489631833013		[learning rate: 0.0026048]
	Learning Rate: 0.00260482
	LOSS [training: 0.31984489631833013 | validation: 0.33075130525478097]
	TIME [epoch: 9.25 sec]
EPOCH 314/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3074535162725825		[learning rate: 0.0025915]
	Learning Rate: 0.00259153
	LOSS [training: 0.3074535162725825 | validation: 0.22606768023308996]
	TIME [epoch: 9.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_314.pth
	Model improved!!!
EPOCH 315/500:
	Training over batches...
		[batch 10/10] avg loss: 0.36768031375631566		[learning rate: 0.0025783]
	Learning Rate: 0.0025783
	LOSS [training: 0.36768031375631566 | validation: 0.32076142050808887]
	TIME [epoch: 9.25 sec]
EPOCH 316/500:
	Training over batches...
		[batch 10/10] avg loss: 0.34126134026593324		[learning rate: 0.0025651]
	Learning Rate: 0.00256514
	LOSS [training: 0.34126134026593324 | validation: 0.367408421287354]
	TIME [epoch: 9.28 sec]
EPOCH 317/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2810956809404878		[learning rate: 0.002552]
	Learning Rate: 0.00255205
	LOSS [training: 0.2810956809404878 | validation: 0.3601103089260846]
	TIME [epoch: 9.25 sec]
EPOCH 318/500:
	Training over batches...
		[batch 10/10] avg loss: 0.5592930787837405		[learning rate: 0.002539]
	Learning Rate: 0.00253902
	LOSS [training: 0.5592930787837405 | validation: 0.3047467578171105]
	TIME [epoch: 9.25 sec]
EPOCH 319/500:
	Training over batches...
		[batch 10/10] avg loss: 0.34983511186086563		[learning rate: 0.0025261]
	Learning Rate: 0.00252606
	LOSS [training: 0.34983511186086563 | validation: 0.4516936234628263]
	TIME [epoch: 9.26 sec]
EPOCH 320/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3312422484054596		[learning rate: 0.0025132]
	Learning Rate: 0.00251317
	LOSS [training: 0.3312422484054596 | validation: 0.37846086033166615]
	TIME [epoch: 9.28 sec]
EPOCH 321/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3257049157516501		[learning rate: 0.0025003]
	Learning Rate: 0.00250035
	LOSS [training: 0.3257049157516501 | validation: 0.5309471174177967]
	TIME [epoch: 9.26 sec]
EPOCH 322/500:
	Training over batches...
		[batch 10/10] avg loss: 0.35669003069175825		[learning rate: 0.0024876]
	Learning Rate: 0.00248758
	LOSS [training: 0.35669003069175825 | validation: 0.6238509569601904]
	TIME [epoch: 9.25 sec]
EPOCH 323/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3017766920235082		[learning rate: 0.0024749]
	Learning Rate: 0.00247489
	LOSS [training: 0.3017766920235082 | validation: 0.4383773423650186]
	TIME [epoch: 9.25 sec]
EPOCH 324/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3421771254584573		[learning rate: 0.0024623]
	Learning Rate: 0.00246226
	LOSS [training: 0.3421771254584573 | validation: 0.34374924688922803]
	TIME [epoch: 9.27 sec]
EPOCH 325/500:
	Training over batches...
		[batch 10/10] avg loss: 0.34350028914770875		[learning rate: 0.0024497]
	Learning Rate: 0.00244969
	LOSS [training: 0.34350028914770875 | validation: 0.3570442324180845]
	TIME [epoch: 9.25 sec]
EPOCH 326/500:
	Training over batches...
		[batch 10/10] avg loss: 0.345766963764623		[learning rate: 0.0024372]
	Learning Rate: 0.00243719
	LOSS [training: 0.345766963764623 | validation: 0.3780084020332519]
	TIME [epoch: 9.26 sec]
EPOCH 327/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4371114795484699		[learning rate: 0.0024247]
	Learning Rate: 0.00242475
	LOSS [training: 0.4371114795484699 | validation: 0.8395758059839071]
	TIME [epoch: 9.25 sec]
EPOCH 328/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3617962448157576		[learning rate: 0.0024124]
	Learning Rate: 0.00241237
	LOSS [training: 0.3617962448157576 | validation: 0.3441521378725519]
	TIME [epoch: 9.27 sec]
EPOCH 329/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3526430209797244		[learning rate: 0.0024001]
	Learning Rate: 0.00240006
	LOSS [training: 0.3526430209797244 | validation: 0.3730202950989407]
	TIME [epoch: 9.26 sec]
EPOCH 330/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3232107849401119		[learning rate: 0.0023878]
	Learning Rate: 0.00238781
	LOSS [training: 0.3232107849401119 | validation: 0.7254469256310151]
	TIME [epoch: 9.25 sec]
EPOCH 331/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3940913703090771		[learning rate: 0.0023756]
	Learning Rate: 0.00237562
	LOSS [training: 0.3940913703090771 | validation: 0.5336144096356309]
	TIME [epoch: 9.26 sec]
EPOCH 332/500:
	Training over batches...
		[batch 10/10] avg loss: 0.34572075314250716		[learning rate: 0.0023635]
	Learning Rate: 0.0023635
	LOSS [training: 0.34572075314250716 | validation: 0.4156729266095989]
	TIME [epoch: 9.27 sec]
EPOCH 333/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3189968466468084		[learning rate: 0.0023514]
	Learning Rate: 0.00235144
	LOSS [training: 0.3189968466468084 | validation: 0.294755689565243]
	TIME [epoch: 9.27 sec]
EPOCH 334/500:
	Training over batches...
		[batch 10/10] avg loss: 0.32325993236555295		[learning rate: 0.0023394]
	Learning Rate: 0.00233944
	LOSS [training: 0.32325993236555295 | validation: 0.5201024968794533]
	TIME [epoch: 9.26 sec]
EPOCH 335/500:
	Training over batches...
		[batch 10/10] avg loss: 0.42300444831289036		[learning rate: 0.0023275]
	Learning Rate: 0.0023275
	LOSS [training: 0.42300444831289036 | validation: 0.5838073691845276]
	TIME [epoch: 9.25 sec]
EPOCH 336/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3727969695415989		[learning rate: 0.0023156]
	Learning Rate: 0.00231562
	LOSS [training: 0.3727969695415989 | validation: 0.39107528392314567]
	TIME [epoch: 9.25 sec]
EPOCH 337/500:
	Training over batches...
		[batch 10/10] avg loss: 0.35056920921765516		[learning rate: 0.0023038]
	Learning Rate: 0.0023038
	LOSS [training: 0.35056920921765516 | validation: 0.26517748727963136]
	TIME [epoch: 9.26 sec]
EPOCH 338/500:
	Training over batches...
		[batch 10/10] avg loss: 0.36616201372049995		[learning rate: 0.002292]
	Learning Rate: 0.00229204
	LOSS [training: 0.36616201372049995 | validation: 0.5154078877025494]
	TIME [epoch: 9.25 sec]
EPOCH 339/500:
	Training over batches...
		[batch 10/10] avg loss: 0.4273690646031696		[learning rate: 0.0022803]
	Learning Rate: 0.00228034
	LOSS [training: 0.4273690646031696 | validation: 0.3969637963999845]
	TIME [epoch: 9.25 sec]
EPOCH 340/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3542197240048543		[learning rate: 0.0022687]
	Learning Rate: 0.0022687
	LOSS [training: 0.3542197240048543 | validation: 0.35954040946155036]
	TIME [epoch: 9.25 sec]
EPOCH 341/500:
	Training over batches...
		[batch 10/10] avg loss: 0.319874963633047		[learning rate: 0.0022571]
	Learning Rate: 0.00225712
	LOSS [training: 0.319874963633047 | validation: 0.3540139755616823]
	TIME [epoch: 9.27 sec]
EPOCH 342/500:
	Training over batches...
		[batch 10/10] avg loss: 0.304570164976467		[learning rate: 0.0022456]
	Learning Rate: 0.0022456
	LOSS [training: 0.304570164976467 | validation: 0.38427839195856067]
	TIME [epoch: 9.25 sec]
EPOCH 343/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2989136241810966		[learning rate: 0.0022341]
	Learning Rate: 0.00223414
	LOSS [training: 0.2989136241810966 | validation: 0.28824512956197373]
	TIME [epoch: 9.24 sec]
EPOCH 344/500:
	Training over batches...
		[batch 10/10] avg loss: 0.34157014735356006		[learning rate: 0.0022227]
	Learning Rate: 0.00222274
	LOSS [training: 0.34157014735356006 | validation: 0.5107179311283749]
	TIME [epoch: 9.26 sec]
EPOCH 345/500:
	Training over batches...
		[batch 10/10] avg loss: 0.38146239950659694		[learning rate: 0.0022114]
	Learning Rate: 0.0022114
	LOSS [training: 0.38146239950659694 | validation: 0.33063162281008074]
	TIME [epoch: 9.28 sec]
EPOCH 346/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2887110475249835		[learning rate: 0.0022001]
	Learning Rate: 0.00220011
	LOSS [training: 0.2887110475249835 | validation: 0.43200855243179026]
	TIME [epoch: 9.26 sec]
EPOCH 347/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3338694878321572		[learning rate: 0.0021889]
	Learning Rate: 0.00218888
	LOSS [training: 0.3338694878321572 | validation: 0.36656019687883384]
	TIME [epoch: 9.26 sec]
EPOCH 348/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3160725745824541		[learning rate: 0.0021777]
	Learning Rate: 0.00217771
	LOSS [training: 0.3160725745824541 | validation: 0.47582686478321684]
	TIME [epoch: 9.25 sec]
EPOCH 349/500:
	Training over batches...
		[batch 10/10] avg loss: 0.28711919960785953		[learning rate: 0.0021666]
	Learning Rate: 0.0021666
	LOSS [training: 0.28711919960785953 | validation: 1.0879286692853956]
	TIME [epoch: 9.27 sec]
EPOCH 350/500:
	Training over batches...
		[batch 10/10] avg loss: 0.413485219953423		[learning rate: 0.0021555]
	Learning Rate: 0.00215554
	LOSS [training: 0.413485219953423 | validation: 0.23122426030569754]
	TIME [epoch: 9.25 sec]
EPOCH 351/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2656952513260786		[learning rate: 0.0021445]
	Learning Rate: 0.00214454
	LOSS [training: 0.2656952513260786 | validation: 0.518300297072855]
	TIME [epoch: 9.26 sec]
EPOCH 352/500:
	Training over batches...
		[batch 10/10] avg loss: 0.29048499271085615		[learning rate: 0.0021336]
	Learning Rate: 0.00213359
	LOSS [training: 0.29048499271085615 | validation: 0.29398247695093843]
	TIME [epoch: 9.3 sec]
EPOCH 353/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3588743342490314		[learning rate: 0.0021227]
	Learning Rate: 0.0021227
	LOSS [training: 0.3588743342490314 | validation: 0.473804067577226]
	TIME [epoch: 9.3 sec]
EPOCH 354/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2747597976426193		[learning rate: 0.0021119]
	Learning Rate: 0.00211187
	LOSS [training: 0.2747597976426193 | validation: 0.2588453314502031]
	TIME [epoch: 9.29 sec]
EPOCH 355/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23805317700544318		[learning rate: 0.0021011]
	Learning Rate: 0.00210109
	LOSS [training: 0.23805317700544318 | validation: 0.36524614197894195]
	TIME [epoch: 9.28 sec]
EPOCH 356/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3572661400683993		[learning rate: 0.0020904]
	Learning Rate: 0.00209037
	LOSS [training: 0.3572661400683993 | validation: 0.3916298606715279]
	TIME [epoch: 9.28 sec]
EPOCH 357/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25060010409815325		[learning rate: 0.0020797]
	Learning Rate: 0.0020797
	LOSS [training: 0.25060010409815325 | validation: 0.3818827095257184]
	TIME [epoch: 9.3 sec]
EPOCH 358/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2782712636826398		[learning rate: 0.0020691]
	Learning Rate: 0.00206908
	LOSS [training: 0.2782712636826398 | validation: 0.7440746732143304]
	TIME [epoch: 9.29 sec]
EPOCH 359/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3360021910499473		[learning rate: 0.0020585]
	Learning Rate: 0.00205852
	LOSS [training: 0.3360021910499473 | validation: 0.42045848767889654]
	TIME [epoch: 9.28 sec]
EPOCH 360/500:
	Training over batches...
		[batch 10/10] avg loss: 0.40939320903385773		[learning rate: 0.002048]
	Learning Rate: 0.00204802
	LOSS [training: 0.40939320903385773 | validation: 0.41267047165862597]
	TIME [epoch: 9.29 sec]
EPOCH 361/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2830846193442137		[learning rate: 0.0020376]
	Learning Rate: 0.00203756
	LOSS [training: 0.2830846193442137 | validation: 0.4222798829507153]
	TIME [epoch: 9.3 sec]
EPOCH 362/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3058288687099982		[learning rate: 0.0020272]
	Learning Rate: 0.00202716
	LOSS [training: 0.3058288687099982 | validation: 0.353480442817232]
	TIME [epoch: 9.29 sec]
EPOCH 363/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3317621432458458		[learning rate: 0.0020168]
	Learning Rate: 0.00201682
	LOSS [training: 0.3317621432458458 | validation: 0.3665965117191901]
	TIME [epoch: 9.28 sec]
EPOCH 364/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2908141572424313		[learning rate: 0.0020065]
	Learning Rate: 0.00200652
	LOSS [training: 0.2908141572424313 | validation: 0.24282127651999588]
	TIME [epoch: 9.28 sec]
EPOCH 365/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2834595004476129		[learning rate: 0.0019963]
	Learning Rate: 0.00199628
	LOSS [training: 0.2834595004476129 | validation: 0.4664946767266609]
	TIME [epoch: 9.31 sec]
EPOCH 366/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24056879314185275		[learning rate: 0.0019861]
	Learning Rate: 0.00198609
	LOSS [training: 0.24056879314185275 | validation: 0.23386443979775393]
	TIME [epoch: 9.29 sec]
EPOCH 367/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2460274709408686		[learning rate: 0.001976]
	Learning Rate: 0.00197596
	LOSS [training: 0.2460274709408686 | validation: 0.3521438885587002]
	TIME [epoch: 9.28 sec]
EPOCH 368/500:
	Training over batches...
		[batch 10/10] avg loss: 0.293833996827903		[learning rate: 0.0019659]
	Learning Rate: 0.00196587
	LOSS [training: 0.293833996827903 | validation: 0.24575034543763383]
	TIME [epoch: 9.28 sec]
EPOCH 369/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21817216577000895		[learning rate: 0.0019558]
	Learning Rate: 0.00195584
	LOSS [training: 0.21817216577000895 | validation: 0.18295975761538705]
	TIME [epoch: 9.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_369.pth
	Model improved!!!
EPOCH 370/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2827159169296924		[learning rate: 0.0019459]
	Learning Rate: 0.00194586
	LOSS [training: 0.2827159169296924 | validation: 0.23663721310301955]
	TIME [epoch: 9.29 sec]
EPOCH 371/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2873191935995657		[learning rate: 0.0019359]
	Learning Rate: 0.00193593
	LOSS [training: 0.2873191935995657 | validation: 0.2399578921939595]
	TIME [epoch: 9.29 sec]
EPOCH 372/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2575854974345694		[learning rate: 0.001926]
	Learning Rate: 0.00192605
	LOSS [training: 0.2575854974345694 | validation: 0.27791725193242495]
	TIME [epoch: 9.28 sec]
EPOCH 373/500:
	Training over batches...
		[batch 10/10] avg loss: 0.35728087389717156		[learning rate: 0.0019162]
	Learning Rate: 0.00191622
	LOSS [training: 0.35728087389717156 | validation: 0.39919677011732696]
	TIME [epoch: 9.3 sec]
EPOCH 374/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2764850861185681		[learning rate: 0.0019064]
	Learning Rate: 0.00190644
	LOSS [training: 0.2764850861185681 | validation: 0.4423023484875889]
	TIME [epoch: 9.29 sec]
EPOCH 375/500:
	Training over batches...
		[batch 10/10] avg loss: 0.29063703443002814		[learning rate: 0.0018967]
	Learning Rate: 0.00189671
	LOSS [training: 0.29063703443002814 | validation: 0.5057050879183702]
	TIME [epoch: 9.28 sec]
EPOCH 376/500:
	Training over batches...
		[batch 10/10] avg loss: 0.30305459632933035		[learning rate: 0.001887]
	Learning Rate: 0.00188703
	LOSS [training: 0.30305459632933035 | validation: 0.3791002403561989]
	TIME [epoch: 9.28 sec]
EPOCH 377/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3376619127063975		[learning rate: 0.0018774]
	Learning Rate: 0.00187739
	LOSS [training: 0.3376619127063975 | validation: 0.30438657820445214]
	TIME [epoch: 9.29 sec]
EPOCH 378/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3079677990810997		[learning rate: 0.0018678]
	Learning Rate: 0.00186781
	LOSS [training: 0.3079677990810997 | validation: 0.25635783787522964]
	TIME [epoch: 9.29 sec]
EPOCH 379/500:
	Training over batches...
		[batch 10/10] avg loss: 0.35242568567842797		[learning rate: 0.0018583]
	Learning Rate: 0.00185828
	LOSS [training: 0.35242568567842797 | validation: 0.35307569940527245]
	TIME [epoch: 9.28 sec]
EPOCH 380/500:
	Training over batches...
		[batch 10/10] avg loss: 0.31187814014168913		[learning rate: 0.0018488]
	Learning Rate: 0.0018488
	LOSS [training: 0.31187814014168913 | validation: 0.22530424264327867]
	TIME [epoch: 9.28 sec]
EPOCH 381/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3234367630683036		[learning rate: 0.0018394]
	Learning Rate: 0.00183936
	LOSS [training: 0.3234367630683036 | validation: 0.26758783873245434]
	TIME [epoch: 9.29 sec]
EPOCH 382/500:
	Training over batches...
		[batch 10/10] avg loss: 0.28693544410565086		[learning rate: 0.00183]
	Learning Rate: 0.00182997
	LOSS [training: 0.28693544410565086 | validation: 0.24994005277472567]
	TIME [epoch: 9.29 sec]
EPOCH 383/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2951708127258464		[learning rate: 0.0018206]
	Learning Rate: 0.00182063
	LOSS [training: 0.2951708127258464 | validation: 0.33348908035568264]
	TIME [epoch: 9.28 sec]
EPOCH 384/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3848458973664341		[learning rate: 0.0018113]
	Learning Rate: 0.00181134
	LOSS [training: 0.3848458973664341 | validation: 0.21489387550438122]
	TIME [epoch: 9.29 sec]
EPOCH 385/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2667410874325725		[learning rate: 0.0018021]
	Learning Rate: 0.0018021
	LOSS [training: 0.2667410874325725 | validation: 0.2184891066441481]
	TIME [epoch: 9.29 sec]
EPOCH 386/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2643571142627209		[learning rate: 0.0017929]
	Learning Rate: 0.0017929
	LOSS [training: 0.2643571142627209 | validation: 0.3020287398032398]
	TIME [epoch: 9.3 sec]
EPOCH 387/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25366627124305047		[learning rate: 0.0017837]
	Learning Rate: 0.00178375
	LOSS [training: 0.25366627124305047 | validation: 0.6298304017245755]
	TIME [epoch: 9.29 sec]
EPOCH 388/500:
	Training over batches...
		[batch 10/10] avg loss: 0.3404437323757831		[learning rate: 0.0017746]
	Learning Rate: 0.00177464
	LOSS [training: 0.3404437323757831 | validation: 0.1944993722370469]
	TIME [epoch: 9.27 sec]
EPOCH 389/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2280367608390091		[learning rate: 0.0017656]
	Learning Rate: 0.00176559
	LOSS [training: 0.2280367608390091 | validation: 0.2581047685627878]
	TIME [epoch: 9.29 sec]
EPOCH 390/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23286223820967256		[learning rate: 0.0017566]
	Learning Rate: 0.00175657
	LOSS [training: 0.23286223820967256 | validation: 0.3292249631804118]
	TIME [epoch: 9.29 sec]
EPOCH 391/500:
	Training over batches...
		[batch 10/10] avg loss: 0.26692214423719796		[learning rate: 0.0017476]
	Learning Rate: 0.00174761
	LOSS [training: 0.26692214423719796 | validation: 0.326795688734491]
	TIME [epoch: 9.28 sec]
EPOCH 392/500:
	Training over batches...
		[batch 10/10] avg loss: 0.29584526335084654		[learning rate: 0.0017387]
	Learning Rate: 0.00173869
	LOSS [training: 0.29584526335084654 | validation: 0.49525907876927083]
	TIME [epoch: 9.28 sec]
EPOCH 393/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2978442827120043		[learning rate: 0.0017298]
	Learning Rate: 0.00172982
	LOSS [training: 0.2978442827120043 | validation: 0.2458409193318083]
	TIME [epoch: 9.28 sec]
EPOCH 394/500:
	Training over batches...
		[batch 10/10] avg loss: 0.30885141576626407		[learning rate: 0.001721]
	Learning Rate: 0.00172099
	LOSS [training: 0.30885141576626407 | validation: 0.35104175910329943]
	TIME [epoch: 9.3 sec]
EPOCH 395/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2660829679372728		[learning rate: 0.0017122]
	Learning Rate: 0.0017122
	LOSS [training: 0.2660829679372728 | validation: 0.32219577481398415]
	TIME [epoch: 9.29 sec]
EPOCH 396/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24344709908601847		[learning rate: 0.0017035]
	Learning Rate: 0.00170347
	LOSS [training: 0.24344709908601847 | validation: 0.25367522318648655]
	TIME [epoch: 9.27 sec]
EPOCH 397/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2700243689650662		[learning rate: 0.0016948]
	Learning Rate: 0.00169477
	LOSS [training: 0.2700243689650662 | validation: 0.27897898658160575]
	TIME [epoch: 9.28 sec]
EPOCH 398/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2208162572694934		[learning rate: 0.0016861]
	Learning Rate: 0.00168612
	LOSS [training: 0.2208162572694934 | validation: 0.24100800255386798]
	TIME [epoch: 9.3 sec]
EPOCH 399/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2512440937884329		[learning rate: 0.0016775]
	Learning Rate: 0.00167752
	LOSS [training: 0.2512440937884329 | validation: 0.32134238757286404]
	TIME [epoch: 9.28 sec]
EPOCH 400/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20856665323271617		[learning rate: 0.001669]
	Learning Rate: 0.00166895
	LOSS [training: 0.20856665323271617 | validation: 0.18524916582305193]
	TIME [epoch: 9.29 sec]
EPOCH 401/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25790247201891353		[learning rate: 0.0016604]
	Learning Rate: 0.00166044
	LOSS [training: 0.25790247201891353 | validation: 0.4907119048950159]
	TIME [epoch: 9.28 sec]
EPOCH 402/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2411970793173714		[learning rate: 0.001652]
	Learning Rate: 0.00165196
	LOSS [training: 0.2411970793173714 | validation: 0.4358953847930245]
	TIME [epoch: 9.3 sec]
EPOCH 403/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2685567012394112		[learning rate: 0.0016435]
	Learning Rate: 0.00164353
	LOSS [training: 0.2685567012394112 | validation: 0.21115430676740432]
	TIME [epoch: 9.28 sec]
EPOCH 404/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2983045987446535		[learning rate: 0.0016351]
	Learning Rate: 0.00163514
	LOSS [training: 0.2983045987446535 | validation: 0.33008620548748496]
	TIME [epoch: 9.28 sec]
EPOCH 405/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2630623272542444		[learning rate: 0.0016268]
	Learning Rate: 0.0016268
	LOSS [training: 0.2630623272542444 | validation: 0.35554170253577894]
	TIME [epoch: 9.28 sec]
EPOCH 406/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2369385992711172		[learning rate: 0.0016185]
	Learning Rate: 0.00161849
	LOSS [training: 0.2369385992711172 | validation: 0.3168583895802983]
	TIME [epoch: 9.3 sec]
EPOCH 407/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25678645107682574		[learning rate: 0.0016102]
	Learning Rate: 0.00161023
	LOSS [training: 0.25678645107682574 | validation: 0.24049264037702367]
	TIME [epoch: 9.28 sec]
EPOCH 408/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2921489727673242		[learning rate: 0.001602]
	Learning Rate: 0.00160202
	LOSS [training: 0.2921489727673242 | validation: 0.43167242854056465]
	TIME [epoch: 9.28 sec]
EPOCH 409/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22968285672965133		[learning rate: 0.0015938]
	Learning Rate: 0.00159384
	LOSS [training: 0.22968285672965133 | validation: 0.2358400868368438]
	TIME [epoch: 9.29 sec]
EPOCH 410/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23305685502705442		[learning rate: 0.0015857]
	Learning Rate: 0.0015857
	LOSS [training: 0.23305685502705442 | validation: 0.3836395420827586]
	TIME [epoch: 9.3 sec]
EPOCH 411/500:
	Training over batches...
		[batch 10/10] avg loss: 0.27038464569498155		[learning rate: 0.0015776]
	Learning Rate: 0.00157761
	LOSS [training: 0.27038464569498155 | validation: 0.1942917371884457]
	TIME [epoch: 9.29 sec]
EPOCH 412/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2468344200177416		[learning rate: 0.0015696]
	Learning Rate: 0.00156956
	LOSS [training: 0.2468344200177416 | validation: 0.2438544655699324]
	TIME [epoch: 9.28 sec]
EPOCH 413/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22365515071114586		[learning rate: 0.0015615]
	Learning Rate: 0.00156155
	LOSS [training: 0.22365515071114586 | validation: 0.2547882891637628]
	TIME [epoch: 9.28 sec]
EPOCH 414/500:
	Training over batches...
		[batch 10/10] avg loss: 0.26645029846731705		[learning rate: 0.0015536]
	Learning Rate: 0.00155358
	LOSS [training: 0.26645029846731705 | validation: 0.23400975524524623]
	TIME [epoch: 9.29 sec]
EPOCH 415/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23602516351417924		[learning rate: 0.0015456]
	Learning Rate: 0.00154565
	LOSS [training: 0.23602516351417924 | validation: 0.30470047744859446]
	TIME [epoch: 9.28 sec]
EPOCH 416/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2745235121459768		[learning rate: 0.0015378]
	Learning Rate: 0.00153776
	LOSS [training: 0.2745235121459768 | validation: 0.27694273154807864]
	TIME [epoch: 9.28 sec]
EPOCH 417/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2251584652073555		[learning rate: 0.0015299]
	Learning Rate: 0.00152991
	LOSS [training: 0.2251584652073555 | validation: 0.2547071493882925]
	TIME [epoch: 9.28 sec]
EPOCH 418/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18488855497160941		[learning rate: 0.0015221]
	Learning Rate: 0.0015221
	LOSS [training: 0.18488855497160941 | validation: 0.2139431914287294]
	TIME [epoch: 9.3 sec]
EPOCH 419/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25125896122848407		[learning rate: 0.0015143]
	Learning Rate: 0.00151434
	LOSS [training: 0.25125896122848407 | validation: 0.25635882513718067]
	TIME [epoch: 9.28 sec]
EPOCH 420/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21784380222818894		[learning rate: 0.0015066]
	Learning Rate: 0.00150661
	LOSS [training: 0.21784380222818894 | validation: 0.2264667669757999]
	TIME [epoch: 9.28 sec]
EPOCH 421/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23100000819038374		[learning rate: 0.0014989]
	Learning Rate: 0.00149892
	LOSS [training: 0.23100000819038374 | validation: 0.3047600455757004]
	TIME [epoch: 9.28 sec]
EPOCH 422/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2652746902104314		[learning rate: 0.0014913]
	Learning Rate: 0.00149127
	LOSS [training: 0.2652746902104314 | validation: 0.5994938943840623]
	TIME [epoch: 9.3 sec]
EPOCH 423/500:
	Training over batches...
		[batch 10/10] avg loss: 0.28905065943968766		[learning rate: 0.0014837]
	Learning Rate: 0.00148366
	LOSS [training: 0.28905065943968766 | validation: 0.16851120516434615]
	TIME [epoch: 9.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_423.pth
	Model improved!!!
EPOCH 424/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2617075080596464		[learning rate: 0.0014761]
	Learning Rate: 0.00147608
	LOSS [training: 0.2617075080596464 | validation: 0.1734447262554983]
	TIME [epoch: 9.29 sec]
EPOCH 425/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19965583935736425		[learning rate: 0.0014686]
	Learning Rate: 0.00146855
	LOSS [training: 0.19965583935736425 | validation: 0.23606059199121857]
	TIME [epoch: 9.27 sec]
EPOCH 426/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2334696296523378		[learning rate: 0.0014611]
	Learning Rate: 0.00146106
	LOSS [training: 0.2334696296523378 | validation: 0.21877064237620772]
	TIME [epoch: 9.29 sec]
EPOCH 427/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23866057427296275		[learning rate: 0.0014536]
	Learning Rate: 0.0014536
	LOSS [training: 0.23866057427296275 | validation: 0.38537942505055983]
	TIME [epoch: 9.28 sec]
EPOCH 428/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20598363065097897		[learning rate: 0.0014462]
	Learning Rate: 0.00144618
	LOSS [training: 0.20598363065097897 | validation: 0.19491430755774783]
	TIME [epoch: 9.27 sec]
EPOCH 429/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20083329303601918		[learning rate: 0.0014388]
	Learning Rate: 0.0014388
	LOSS [training: 0.20083329303601918 | validation: 0.19918671802079504]
	TIME [epoch: 9.27 sec]
EPOCH 430/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18453371361722654		[learning rate: 0.0014315]
	Learning Rate: 0.00143146
	LOSS [training: 0.18453371361722654 | validation: 0.3237881615230247]
	TIME [epoch: 9.28 sec]
EPOCH 431/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2377646214416786		[learning rate: 0.0014241]
	Learning Rate: 0.00142415
	LOSS [training: 0.2377646214416786 | validation: 0.4197710011456928]
	TIME [epoch: 9.29 sec]
EPOCH 432/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23547428403398846		[learning rate: 0.0014169]
	Learning Rate: 0.00141688
	LOSS [training: 0.23547428403398846 | validation: 0.39013124871328736]
	TIME [epoch: 9.27 sec]
EPOCH 433/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17899951006827697		[learning rate: 0.0014096]
	Learning Rate: 0.00140965
	LOSS [training: 0.17899951006827697 | validation: 0.2919936326229513]
	TIME [epoch: 9.27 sec]
EPOCH 434/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2028054003905543		[learning rate: 0.0014025]
	Learning Rate: 0.00140245
	LOSS [training: 0.2028054003905543 | validation: 0.4003335045729228]
	TIME [epoch: 9.28 sec]
EPOCH 435/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2042310085396005		[learning rate: 0.0013953]
	Learning Rate: 0.0013953
	LOSS [training: 0.2042310085396005 | validation: 0.297230906842939]
	TIME [epoch: 9.29 sec]
EPOCH 436/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21408024965107025		[learning rate: 0.0013882]
	Learning Rate: 0.00138818
	LOSS [training: 0.21408024965107025 | validation: 0.275726487531621]
	TIME [epoch: 9.27 sec]
EPOCH 437/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25306211939185685		[learning rate: 0.0013811]
	Learning Rate: 0.00138109
	LOSS [training: 0.25306211939185685 | validation: 0.2535606960137102]
	TIME [epoch: 9.28 sec]
EPOCH 438/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24249358790532272		[learning rate: 0.001374]
	Learning Rate: 0.00137404
	LOSS [training: 0.24249358790532272 | validation: 0.4715628067702749]
	TIME [epoch: 9.28 sec]
EPOCH 439/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2193776359883158		[learning rate: 0.001367]
	Learning Rate: 0.00136703
	LOSS [training: 0.2193776359883158 | validation: 0.2571549958181674]
	TIME [epoch: 9.28 sec]
EPOCH 440/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19088640475209429		[learning rate: 0.0013601]
	Learning Rate: 0.00136005
	LOSS [training: 0.19088640475209429 | validation: 0.19305981459088403]
	TIME [epoch: 9.28 sec]
EPOCH 441/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20111925325331045		[learning rate: 0.0013531]
	Learning Rate: 0.00135311
	LOSS [training: 0.20111925325331045 | validation: 0.25903999944109496]
	TIME [epoch: 9.27 sec]
EPOCH 442/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22473565009102797		[learning rate: 0.0013462]
	Learning Rate: 0.0013462
	LOSS [training: 0.22473565009102797 | validation: 0.3941712771497656]
	TIME [epoch: 9.28 sec]
EPOCH 443/500:
	Training over batches...
		[batch 10/10] avg loss: 0.27990229012346407		[learning rate: 0.0013393]
	Learning Rate: 0.00133933
	LOSS [training: 0.27990229012346407 | validation: 0.2500276624654574]
	TIME [epoch: 9.29 sec]
EPOCH 444/500:
	Training over batches...
		[batch 10/10] avg loss: 0.227124664086049		[learning rate: 0.0013325]
	Learning Rate: 0.0013325
	LOSS [training: 0.227124664086049 | validation: 0.19738846228752713]
	TIME [epoch: 9.33 sec]
EPOCH 445/500:
	Training over batches...
		[batch 10/10] avg loss: 0.218059765095641		[learning rate: 0.0013257]
	Learning Rate: 0.0013257
	LOSS [training: 0.218059765095641 | validation: 0.46116317881219054]
	TIME [epoch: 9.27 sec]
EPOCH 446/500:
	Training over batches...
		[batch 10/10] avg loss: 0.29813626901883333		[learning rate: 0.0013189]
	Learning Rate: 0.00131893
	LOSS [training: 0.29813626901883333 | validation: 0.6354660709217417]
	TIME [epoch: 9.27 sec]
EPOCH 447/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24613881080096017		[learning rate: 0.0013122]
	Learning Rate: 0.0013122
	LOSS [training: 0.24613881080096017 | validation: 0.20030652792652834]
	TIME [epoch: 9.3 sec]
EPOCH 448/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22261390548607318		[learning rate: 0.0013055]
	Learning Rate: 0.0013055
	LOSS [training: 0.22261390548607318 | validation: 0.19493509602272574]
	TIME [epoch: 9.29 sec]
EPOCH 449/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23268736901430015		[learning rate: 0.0012988]
	Learning Rate: 0.00129884
	LOSS [training: 0.23268736901430015 | validation: 0.7420694390605456]
	TIME [epoch: 9.28 sec]
EPOCH 450/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2878750662450013		[learning rate: 0.0012922]
	Learning Rate: 0.00129221
	LOSS [training: 0.2878750662450013 | validation: 0.31843263282862905]
	TIME [epoch: 9.26 sec]
EPOCH 451/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23477645731295632		[learning rate: 0.0012856]
	Learning Rate: 0.00128562
	LOSS [training: 0.23477645731295632 | validation: 0.21859567320955606]
	TIME [epoch: 9.26 sec]
EPOCH 452/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20249654605089945		[learning rate: 0.0012791]
	Learning Rate: 0.00127905
	LOSS [training: 0.20249654605089945 | validation: 0.30235245013990597]
	TIME [epoch: 9.24 sec]
EPOCH 453/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24163751597722602		[learning rate: 0.0012725]
	Learning Rate: 0.00127253
	LOSS [training: 0.24163751597722602 | validation: 0.43562658906661644]
	TIME [epoch: 9.24 sec]
EPOCH 454/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18293843277302174		[learning rate: 0.001266]
	Learning Rate: 0.00126603
	LOSS [training: 0.18293843277302174 | validation: 0.3179628083258046]
	TIME [epoch: 9.23 sec]
EPOCH 455/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2189438988260622		[learning rate: 0.0012596]
	Learning Rate: 0.00125957
	LOSS [training: 0.2189438988260622 | validation: 0.23722311537279372]
	TIME [epoch: 9.28 sec]
EPOCH 456/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21537582827551308		[learning rate: 0.0012531]
	Learning Rate: 0.00125314
	LOSS [training: 0.21537582827551308 | validation: 0.16594892158444402]
	TIME [epoch: 9.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_456.pth
	Model improved!!!
EPOCH 457/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20189427139019206		[learning rate: 0.0012467]
	Learning Rate: 0.00124675
	LOSS [training: 0.20189427139019206 | validation: 0.21284384091747835]
	TIME [epoch: 9.27 sec]
EPOCH 458/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20629482525588022		[learning rate: 0.0012404]
	Learning Rate: 0.00124038
	LOSS [training: 0.20629482525588022 | validation: 0.2320990540243868]
	TIME [epoch: 9.27 sec]
EPOCH 459/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17024433670826955		[learning rate: 0.0012341]
	Learning Rate: 0.00123405
	LOSS [training: 0.17024433670826955 | validation: 0.25781466855190377]
	TIME [epoch: 9.28 sec]
EPOCH 460/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2775718360826154		[learning rate: 0.0012278]
	Learning Rate: 0.00122775
	LOSS [training: 0.2775718360826154 | validation: 0.3132483940668262]
	TIME [epoch: 9.26 sec]
EPOCH 461/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2331846702636502		[learning rate: 0.0012215]
	Learning Rate: 0.00122149
	LOSS [training: 0.2331846702636502 | validation: 0.30205700559325904]
	TIME [epoch: 9.27 sec]
EPOCH 462/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2804460474532785		[learning rate: 0.0012153]
	Learning Rate: 0.00121525
	LOSS [training: 0.2804460474532785 | validation: 0.3122016332120813]
	TIME [epoch: 9.24 sec]
EPOCH 463/500:
	Training over batches...
		[batch 10/10] avg loss: 0.24596974701578986		[learning rate: 0.0012091]
	Learning Rate: 0.00120905
	LOSS [training: 0.24596974701578986 | validation: 0.33732237554997724]
	TIME [epoch: 9.26 sec]
EPOCH 464/500:
	Training over batches...
		[batch 10/10] avg loss: 0.25392499636855137		[learning rate: 0.0012029]
	Learning Rate: 0.00120288
	LOSS [training: 0.25392499636855137 | validation: 0.15846248654197795]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v1_64_20240215_143932/states/model_phi1_1a_v1_64_464.pth
	Model improved!!!
EPOCH 465/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1706033858640328		[learning rate: 0.0011967]
	Learning Rate: 0.00119674
	LOSS [training: 0.1706033858640328 | validation: 0.23866077225697072]
	TIME [epoch: 9.23 sec]
EPOCH 466/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20299167477528127		[learning rate: 0.0011906]
	Learning Rate: 0.00119063
	LOSS [training: 0.20299167477528127 | validation: 0.2565137346267193]
	TIME [epoch: 9.23 sec]
EPOCH 467/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2434546586676626		[learning rate: 0.0011846]
	Learning Rate: 0.00118456
	LOSS [training: 0.2434546586676626 | validation: 0.3979882225358258]
	TIME [epoch: 9.24 sec]
EPOCH 468/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2304864108135755		[learning rate: 0.0011785]
	Learning Rate: 0.00117851
	LOSS [training: 0.2304864108135755 | validation: 0.19982982776967625]
	TIME [epoch: 9.23 sec]
EPOCH 469/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22830448683173862		[learning rate: 0.0011725]
	Learning Rate: 0.0011725
	LOSS [training: 0.22830448683173862 | validation: 0.1924249061366614]
	TIME [epoch: 9.23 sec]
EPOCH 470/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18218548664703682		[learning rate: 0.0011665]
	Learning Rate: 0.00116651
	LOSS [training: 0.18218548664703682 | validation: 0.2050816568785994]
	TIME [epoch: 9.23 sec]
EPOCH 471/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21108516600634147		[learning rate: 0.0011606]
	Learning Rate: 0.00116056
	LOSS [training: 0.21108516600634147 | validation: 0.32153332329559564]
	TIME [epoch: 9.24 sec]
EPOCH 472/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18066552708965855		[learning rate: 0.0011546]
	Learning Rate: 0.00115463
	LOSS [training: 0.18066552708965855 | validation: 0.23563306287731467]
	TIME [epoch: 9.23 sec]
EPOCH 473/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23464314825454302		[learning rate: 0.0011487]
	Learning Rate: 0.00114874
	LOSS [training: 0.23464314825454302 | validation: 0.23851126971787404]
	TIME [epoch: 9.23 sec]
EPOCH 474/500:
	Training over batches...
		[batch 10/10] avg loss: 0.20688486950310558		[learning rate: 0.0011429]
	Learning Rate: 0.00114288
	LOSS [training: 0.20688486950310558 | validation: 0.34104489489574813]
	TIME [epoch: 9.24 sec]
EPOCH 475/500:
	Training over batches...
		[batch 10/10] avg loss: 0.21627536712191162		[learning rate: 0.001137]
	Learning Rate: 0.00113705
	LOSS [training: 0.21627536712191162 | validation: 0.18334746270141525]
	TIME [epoch: 9.24 sec]
EPOCH 476/500:
	Training over batches...
		[batch 10/10] avg loss: 0.241037942911698		[learning rate: 0.0011312]
	Learning Rate: 0.00113124
	LOSS [training: 0.241037942911698 | validation: 0.17452628582417526]
	TIME [epoch: 9.26 sec]
EPOCH 477/500:
	Training over batches...
		[batch 10/10] avg loss: 0.19129082173301817		[learning rate: 0.0011255]
	Learning Rate: 0.00112547
	LOSS [training: 0.19129082173301817 | validation: 0.24553436702268516]
	TIME [epoch: 9.23 sec]
EPOCH 478/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18878830885615897		[learning rate: 0.0011197]
	Learning Rate: 0.00111972
	LOSS [training: 0.18878830885615897 | validation: 0.23387487908639062]
	TIME [epoch: 9.23 sec]
EPOCH 479/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18346956805611211		[learning rate: 0.001114]
	Learning Rate: 0.00111401
	LOSS [training: 0.18346956805611211 | validation: 0.2297954208138876]
	TIME [epoch: 9.24 sec]
EPOCH 480/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18796305100962368		[learning rate: 0.0011083]
	Learning Rate: 0.00110832
	LOSS [training: 0.18796305100962368 | validation: 0.22804346214922666]
	TIME [epoch: 9.24 sec]
EPOCH 481/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18579284630467546		[learning rate: 0.0011027]
	Learning Rate: 0.00110267
	LOSS [training: 0.18579284630467546 | validation: 0.19792438202340534]
	TIME [epoch: 9.23 sec]
EPOCH 482/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17368051028364168		[learning rate: 0.001097]
	Learning Rate: 0.00109704
	LOSS [training: 0.17368051028364168 | validation: 0.22756717970809134]
	TIME [epoch: 9.24 sec]
EPOCH 483/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1703245389290772		[learning rate: 0.0010914]
	Learning Rate: 0.00109144
	LOSS [training: 0.1703245389290772 | validation: 0.26800873815804666]
	TIME [epoch: 9.37 sec]
EPOCH 484/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18141447518647966		[learning rate: 0.0010859]
	Learning Rate: 0.00108587
	LOSS [training: 0.18141447518647966 | validation: 0.1742697678678999]
	TIME [epoch: 9.24 sec]
EPOCH 485/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16952992603884942		[learning rate: 0.0010803]
	Learning Rate: 0.00108033
	LOSS [training: 0.16952992603884942 | validation: 0.22171631613864617]
	TIME [epoch: 9.23 sec]
EPOCH 486/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1998107940690433		[learning rate: 0.0010748]
	Learning Rate: 0.00107481
	LOSS [training: 0.1998107940690433 | validation: 0.21967534356196752]
	TIME [epoch: 9.24 sec]
EPOCH 487/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1732349991855917		[learning rate: 0.0010693]
	Learning Rate: 0.00106933
	LOSS [training: 0.1732349991855917 | validation: 0.28860663267314085]
	TIME [epoch: 9.25 sec]
EPOCH 488/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22090332979221522		[learning rate: 0.0010639]
	Learning Rate: 0.00106387
	LOSS [training: 0.22090332979221522 | validation: 0.1832810886972914]
	TIME [epoch: 9.26 sec]
EPOCH 489/500:
	Training over batches...
		[batch 10/10] avg loss: 0.17563517950037713		[learning rate: 0.0010584]
	Learning Rate: 0.00105844
	LOSS [training: 0.17563517950037713 | validation: 0.16922243206152263]
	TIME [epoch: 9.25 sec]
EPOCH 490/500:
	Training over batches...
		[batch 10/10] avg loss: 0.16765267337283535		[learning rate: 0.001053]
	Learning Rate: 0.00105304
	LOSS [training: 0.16765267337283535 | validation: 0.19252832125037234]
	TIME [epoch: 9.24 sec]
EPOCH 491/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1911593346361909		[learning rate: 0.0010477]
	Learning Rate: 0.00104766
	LOSS [training: 0.1911593346361909 | validation: 0.16154892552294872]
	TIME [epoch: 9.23 sec]
EPOCH 492/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1923044072993445		[learning rate: 0.0010423]
	Learning Rate: 0.00104232
	LOSS [training: 0.1923044072993445 | validation: 0.20917810634747927]
	TIME [epoch: 9.25 sec]
EPOCH 493/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18404716402783539		[learning rate: 0.001037]
	Learning Rate: 0.001037
	LOSS [training: 0.18404716402783539 | validation: 0.19212135493515095]
	TIME [epoch: 9.22 sec]
EPOCH 494/500:
	Training over batches...
		[batch 10/10] avg loss: 0.1709890250762392		[learning rate: 0.0010317]
	Learning Rate: 0.0010317
	LOSS [training: 0.1709890250762392 | validation: 0.16435919020222034]
	TIME [epoch: 9.24 sec]
EPOCH 495/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18560343435015345		[learning rate: 0.0010264]
	Learning Rate: 0.00102644
	LOSS [training: 0.18560343435015345 | validation: 0.3543782155098027]
	TIME [epoch: 9.23 sec]
EPOCH 496/500:
	Training over batches...
		[batch 10/10] avg loss: 0.18047996548765155		[learning rate: 0.0010212]
	Learning Rate: 0.0010212
	LOSS [training: 0.18047996548765155 | validation: 0.22160524328584544]
	TIME [epoch: 9.3 sec]
EPOCH 497/500:
	Training over batches...
		[batch 10/10] avg loss: 0.2070203347923767		[learning rate: 0.001016]
	Learning Rate: 0.00101599
	LOSS [training: 0.2070203347923767 | validation: 0.27964818113477485]
	TIME [epoch: 9.23 sec]
EPOCH 498/500:
	Training over batches...
		[batch 10/10] avg loss: 0.22650563102388346		[learning rate: 0.0010108]
	Learning Rate: 0.0010108
	LOSS [training: 0.22650563102388346 | validation: 0.440572676684879]
	TIME [epoch: 9.23 sec]
EPOCH 499/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23261652209615574		[learning rate: 0.0010056]
	Learning Rate: 0.00100564
	LOSS [training: 0.23261652209615574 | validation: 0.2578567548745297]
	TIME [epoch: 9.24 sec]
EPOCH 500/500:
	Training over batches...
		[batch 10/10] avg loss: 0.23314888074309503		[learning rate: 0.0010005]
	Learning Rate: 0.00100051
	LOSS [training: 0.23314888074309503 | validation: 0.24328935312323594]
	TIME [epoch: 9.27 sec]
Finished training in 4692.132 seconds.
