Args:
Namespace(name='model_algphi2_1a_v_klv2', outdir='out/model_training/model_algphi2_1a_v_klv2', training_data='data/training_data/data_phi2_1a/training', validation_data='data/training_data/data_phi2_1a/validation', model_type='binary_flip', nsims_training=None, nsims_validation=None, num_epochs=500, passes_per_epoch=1, batch_size=250, patience=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=False, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 250], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=False, confinement_factor=1.0, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], phi_final_act='softplus', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=0.0, init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='klv2', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 771150947

Training model...

Saving initial model state to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 4/4] avg loss: 8.631222859824828		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.631222859824828 | validation: 8.044062457803342]
	TIME [epoch: 94.3 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 4/4] avg loss: 8.03044172038999		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.03044172038999 | validation: 7.731486936706034]
	TIME [epoch: 4.23 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 4/4] avg loss: 7.819743110095422		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.819743110095422 | validation: 7.525022127345023]
	TIME [epoch: 4.16 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_3.pth
	Model improved!!!
EPOCH 4/500:
	Training over batches...
		[batch 4/4] avg loss: 7.67398512475293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.67398512475293 | validation: 7.342917350721873]
	TIME [epoch: 4.15 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 4/4] avg loss: 7.531280353455685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.531280353455685 | validation: 7.160344246270988]
	TIME [epoch: 4.17 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_5.pth
	Model improved!!!
EPOCH 6/500:
	Training over batches...
		[batch 4/4] avg loss: 7.387360157702682		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.387360157702682 | validation: 6.985732852222112]
	TIME [epoch: 4.18 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_6.pth
	Model improved!!!
EPOCH 7/500:
	Training over batches...
		[batch 4/4] avg loss: 7.221391085918082		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.221391085918082 | validation: 6.79178689941242]
	TIME [epoch: 4.19 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_7.pth
	Model improved!!!
EPOCH 8/500:
	Training over batches...
		[batch 4/4] avg loss: 7.054745835981692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.054745835981692 | validation: 6.50601544386442]
	TIME [epoch: 4.15 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_8.pth
	Model improved!!!
EPOCH 9/500:
	Training over batches...
		[batch 4/4] avg loss: 6.42062713777959		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.42062713777959 | validation: 5.150812788019671]
	TIME [epoch: 4.15 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_9.pth
	Model improved!!!
EPOCH 10/500:
	Training over batches...
		[batch 4/4] avg loss: 5.216016055264312		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.216016055264312 | validation: 4.2808313598632886]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_10.pth
	Model improved!!!
EPOCH 11/500:
	Training over batches...
		[batch 4/4] avg loss: 4.325002921885228		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.325002921885228 | validation: 3.7456622905748143]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_11.pth
	Model improved!!!
EPOCH 12/500:
	Training over batches...
		[batch 4/4] avg loss: 3.8864137352760504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8864137352760504 | validation: 3.3358312999503914]
	TIME [epoch: 4.15 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_12.pth
	Model improved!!!
EPOCH 13/500:
	Training over batches...
		[batch 4/4] avg loss: 3.4002214412430654		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4002214412430654 | validation: 2.8666687703634004]
	TIME [epoch: 4.16 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_13.pth
	Model improved!!!
EPOCH 14/500:
	Training over batches...
		[batch 4/4] avg loss: 2.8898128842230157		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8898128842230157 | validation: 2.432179410065262]
	TIME [epoch: 4.19 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_14.pth
	Model improved!!!
EPOCH 15/500:
	Training over batches...
		[batch 4/4] avg loss: 2.4268294079249007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4268294079249007 | validation: 2.0785091558473914]
	TIME [epoch: 4.17 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_15.pth
	Model improved!!!
EPOCH 16/500:
	Training over batches...
		[batch 4/4] avg loss: 2.1211663358039217		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1211663358039217 | validation: 1.819791742263416]
	TIME [epoch: 4.15 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_16.pth
	Model improved!!!
EPOCH 17/500:
	Training over batches...
		[batch 4/4] avg loss: 1.7602965133876947		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7602965133876947 | validation: 1.4521278243049838]
	TIME [epoch: 4.15 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_17.pth
	Model improved!!!
EPOCH 18/500:
	Training over batches...
		[batch 4/4] avg loss: 1.4029672287479698		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4029672287479698 | validation: 1.1142864330786186]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_18.pth
	Model improved!!!
EPOCH 19/500:
	Training over batches...
		[batch 4/4] avg loss: 1.0737317552222756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0737317552222756 | validation: 0.9166437633454526]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_19.pth
	Model improved!!!
EPOCH 20/500:
	Training over batches...
		[batch 4/4] avg loss: 0.8841908247739083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8841908247739083 | validation: 0.6194212360415174]
	TIME [epoch: 4.15 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_20.pth
	Model improved!!!
EPOCH 21/500:
	Training over batches...
		[batch 4/4] avg loss: 0.676924149603927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.676924149603927 | validation: 0.5282181033070892]
	TIME [epoch: 4.16 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_21.pth
	Model improved!!!
EPOCH 22/500:
	Training over batches...
		[batch 4/4] avg loss: 0.5552276211947579		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5552276211947579 | validation: 0.4610209941756023]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_22.pth
	Model improved!!!
EPOCH 23/500:
	Training over batches...
		[batch 4/4] avg loss: 0.4873009181095634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4873009181095634 | validation: 0.4577834896322338]
	TIME [epoch: 4.17 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_23.pth
	Model improved!!!
EPOCH 24/500:
	Training over batches...
		[batch 4/4] avg loss: 0.5088595106058496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5088595106058496 | validation: 0.3918578314586725]
	TIME [epoch: 4.17 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_24.pth
	Model improved!!!
EPOCH 25/500:
	Training over batches...
		[batch 4/4] avg loss: 0.42793567173982566		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42793567173982566 | validation: 0.3249001792809333]
	TIME [epoch: 4.15 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_25.pth
	Model improved!!!
EPOCH 26/500:
	Training over batches...
		[batch 4/4] avg loss: 0.35925361203735057		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35925361203735057 | validation: 0.309086458791631]
	TIME [epoch: 4.15 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_26.pth
	Model improved!!!
EPOCH 27/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2936415898562686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2936415898562686 | validation: 0.21089660024521117]
	TIME [epoch: 4.15 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_27.pth
	Model improved!!!
EPOCH 28/500:
	Training over batches...
		[batch 4/4] avg loss: 0.23308208729884805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23308208729884805 | validation: 0.190922964739309]
	TIME [epoch: 4.15 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_28.pth
	Model improved!!!
EPOCH 29/500:
	Training over batches...
		[batch 4/4] avg loss: 0.21806662139083244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21806662139083244 | validation: 0.1981865369957595]
	TIME [epoch: 4.15 sec]
EPOCH 30/500:
	Training over batches...
		[batch 4/4] avg loss: 0.21492474952628018		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21492474952628018 | validation: 0.18733001772148417]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_30.pth
	Model improved!!!
EPOCH 31/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2333154400279898		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2333154400279898 | validation: 0.21555927953929405]
	TIME [epoch: 4.14 sec]
EPOCH 32/500:
	Training over batches...
		[batch 4/4] avg loss: 0.24698637169813742		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24698637169813742 | validation: 0.22146012142470828]
	TIME [epoch: 4.15 sec]
EPOCH 33/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2687143841547964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2687143841547964 | validation: 0.21495093044084673]
	TIME [epoch: 4.18 sec]
EPOCH 34/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2347377102114921		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2347377102114921 | validation: 0.1667068127578894]
	TIME [epoch: 4.15 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_34.pth
	Model improved!!!
EPOCH 35/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2062211187627045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2062211187627045 | validation: 0.16324349753958084]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_35.pth
	Model improved!!!
EPOCH 36/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1876539006567201		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1876539006567201 | validation: 0.13635787712989092]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_36.pth
	Model improved!!!
EPOCH 37/500:
	Training over batches...
		[batch 4/4] avg loss: 0.16894401853854785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16894401853854785 | validation: 0.1447590973616597]
	TIME [epoch: 4.14 sec]
EPOCH 38/500:
	Training over batches...
		[batch 4/4] avg loss: 0.17052853094493045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17052853094493045 | validation: 0.1343901413866653]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_38.pth
	Model improved!!!
EPOCH 39/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15993287451193555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15993287451193555 | validation: 0.14019373331243787]
	TIME [epoch: 4.16 sec]
EPOCH 40/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1736627507076631		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1736627507076631 | validation: 0.17872228940268825]
	TIME [epoch: 4.15 sec]
EPOCH 41/500:
	Training over batches...
		[batch 4/4] avg loss: 0.21850535595940723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21850535595940723 | validation: 0.20785186371843384]
	TIME [epoch: 4.16 sec]
EPOCH 42/500:
	Training over batches...
		[batch 4/4] avg loss: 0.21973779550609426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21973779550609426 | validation: 0.17112260588079065]
	TIME [epoch: 4.17 sec]
EPOCH 43/500:
	Training over batches...
		[batch 4/4] avg loss: 0.22170848316568476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22170848316568476 | validation: 0.2356653590927845]
	TIME [epoch: 4.18 sec]
EPOCH 44/500:
	Training over batches...
		[batch 4/4] avg loss: 0.24343548163697112		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24343548163697112 | validation: 0.21710114419056784]
	TIME [epoch: 4.16 sec]
EPOCH 45/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2354384752797486		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2354384752797486 | validation: 0.20894441690806254]
	TIME [epoch: 4.16 sec]
EPOCH 46/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2165600086830552		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2165600086830552 | validation: 0.21028678587973984]
	TIME [epoch: 4.15 sec]
EPOCH 47/500:
	Training over batches...
		[batch 4/4] avg loss: 0.24549371360487765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24549371360487765 | validation: 0.2262355864234853]
	TIME [epoch: 4.15 sec]
EPOCH 48/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2453100673054605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2453100673054605 | validation: 0.1796197958883201]
	TIME [epoch: 4.15 sec]
EPOCH 49/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1825618308392806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1825618308392806 | validation: 0.12590678498301552]
	TIME [epoch: 4.15 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_49.pth
	Model improved!!!
EPOCH 50/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14804173561393724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14804173561393724 | validation: 0.13237171205517118]
	TIME [epoch: 4.16 sec]
EPOCH 51/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06039721020327503		[learning rate: 0.0098855]
	Learning Rate: 0.00988553
	LOSS [training: 0.06039721020327503 | validation: 0.04776716065421198]
	TIME [epoch: 98.6 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_51.pth
	Model improved!!!
EPOCH 52/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07696864578763492		[learning rate: 0.0097349]
	Learning Rate: 0.00973494
	LOSS [training: 0.07696864578763492 | validation: 0.04402523136518251]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_52.pth
	Model improved!!!
EPOCH 53/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07448878301956999		[learning rate: 0.0095866]
	Learning Rate: 0.00958665
	LOSS [training: 0.07448878301956999 | validation: 0.05669231609827223]
	TIME [epoch: 8.14 sec]
EPOCH 54/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06012759238664493		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.06012759238664493 | validation: 0.0343656861285439]
	TIME [epoch: 8.12 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_54.pth
	Model improved!!!
EPOCH 55/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07330456333775241		[learning rate: 0.0092968]
	Learning Rate: 0.0092968
	LOSS [training: 0.07330456333775241 | validation: 0.06238780127141824]
	TIME [epoch: 8.2 sec]
EPOCH 56/500:
	Training over batches...
		[batch 4/4] avg loss: 0.10137606237983667		[learning rate: 0.0091552]
	Learning Rate: 0.00915517
	LOSS [training: 0.10137606237983667 | validation: 0.09007699894056426]
	TIME [epoch: 8.13 sec]
EPOCH 57/500:
	Training over batches...
		[batch 4/4] avg loss: 0.10842759099022137		[learning rate: 0.0090157]
	Learning Rate: 0.00901571
	LOSS [training: 0.10842759099022137 | validation: 0.07288308769920426]
	TIME [epoch: 8.11 sec]
EPOCH 58/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06763785180119004		[learning rate: 0.0088784]
	Learning Rate: 0.00887837
	LOSS [training: 0.06763785180119004 | validation: 0.027779592189345885]
	TIME [epoch: 8.11 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_58.pth
	Model improved!!!
EPOCH 59/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03380917662697869		[learning rate: 0.0087431]
	Learning Rate: 0.00874312
	LOSS [training: 0.03380917662697869 | validation: 0.013149831310429565]
	TIME [epoch: 8.12 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_59.pth
	Model improved!!!
EPOCH 60/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02517838921590389		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 0.02517838921590389 | validation: 0.035723187013347035]
	TIME [epoch: 8.14 sec]
EPOCH 61/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029051564044610918		[learning rate: 0.0084788]
	Learning Rate: 0.00847878
	LOSS [training: 0.029051564044610918 | validation: 0.018261685266642097]
	TIME [epoch: 8.14 sec]
EPOCH 62/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02677309581781246		[learning rate: 0.0083496]
	Learning Rate: 0.00834962
	LOSS [training: 0.02677309581781246 | validation: 0.023206556719779527]
	TIME [epoch: 8.11 sec]
EPOCH 63/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06580664104185342		[learning rate: 0.0082224]
	Learning Rate: 0.00822243
	LOSS [training: 0.06580664104185342 | validation: 0.09771049831955252]
	TIME [epoch: 8.11 sec]
EPOCH 64/500:
	Training over batches...
		[batch 4/4] avg loss: 0.11395304533229564		[learning rate: 0.0080972]
	Learning Rate: 0.00809717
	LOSS [training: 0.11395304533229564 | validation: 0.06845837053360469]
	TIME [epoch: 8.1 sec]
EPOCH 65/500:
	Training over batches...
		[batch 4/4] avg loss: 0.09601204466618647		[learning rate: 0.0079738]
	Learning Rate: 0.00797382
	LOSS [training: 0.09601204466618647 | validation: 0.11142430847078588]
	TIME [epoch: 8.11 sec]
EPOCH 66/500:
	Training over batches...
		[batch 4/4] avg loss: 0.11767552281261628		[learning rate: 0.0078524]
	Learning Rate: 0.00785236
	LOSS [training: 0.11767552281261628 | validation: 0.07726212329240492]
	TIME [epoch: 8.13 sec]
EPOCH 67/500:
	Training over batches...
		[batch 4/4] avg loss: 0.10599719165137308		[learning rate: 0.0077327]
	Learning Rate: 0.00773274
	LOSS [training: 0.10599719165137308 | validation: 0.0614483041694698]
	TIME [epoch: 8.14 sec]
EPOCH 68/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05917221126149457		[learning rate: 0.0076149]
	Learning Rate: 0.00761494
	LOSS [training: 0.05917221126149457 | validation: 0.019299421707453662]
	TIME [epoch: 8.11 sec]
EPOCH 69/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0402095147794912		[learning rate: 0.0074989]
	Learning Rate: 0.00749894
	LOSS [training: 0.0402095147794912 | validation: 0.03300065650136268]
	TIME [epoch: 8.11 sec]
EPOCH 70/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05053001879990952		[learning rate: 0.0073847]
	Learning Rate: 0.00738471
	LOSS [training: 0.05053001879990952 | validation: 0.026526731307205523]
	TIME [epoch: 8.11 sec]
EPOCH 71/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0239903255563311		[learning rate: 0.0072722]
	Learning Rate: 0.00727221
	LOSS [training: 0.0239903255563311 | validation: 0.008619894828384881]
	TIME [epoch: 8.11 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_71.pth
	Model improved!!!
EPOCH 72/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0182527431298751		[learning rate: 0.0071614]
	Learning Rate: 0.00716143
	LOSS [training: 0.0182527431298751 | validation: -0.0001997224439860639]
	TIME [epoch: 8.18 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_72.pth
	Model improved!!!
EPOCH 73/500:
	Training over batches...
		[batch 4/4] avg loss: 0.014997876217168055		[learning rate: 0.0070523]
	Learning Rate: 0.00705234
	LOSS [training: 0.014997876217168055 | validation: 0.005942150088424036]
	TIME [epoch: 8.14 sec]
EPOCH 74/500:
	Training over batches...
		[batch 4/4] avg loss: 0.002019727884596867		[learning rate: 0.0069449]
	Learning Rate: 0.00694491
	LOSS [training: 0.002019727884596867 | validation: 0.0030030347536550376]
	TIME [epoch: 8.13 sec]
EPOCH 75/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006415984280798657		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.006415984280798657 | validation: -0.00878373591263368]
	TIME [epoch: 8.12 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_75.pth
	Model improved!!!
EPOCH 76/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007980351704874655		[learning rate: 0.0067349]
	Learning Rate: 0.00673493
	LOSS [training: 0.007980351704874655 | validation: -0.007397595847626916]
	TIME [epoch: 8.14 sec]
EPOCH 77/500:
	Training over batches...
		[batch 4/4] avg loss: 0.002192792653659985		[learning rate: 0.0066323]
	Learning Rate: 0.00663234
	LOSS [training: 0.002192792653659985 | validation: -0.011324437670571343]
	TIME [epoch: 8.16 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_77.pth
	Model improved!!!
EPOCH 78/500:
	Training over batches...
		[batch 4/4] avg loss: 0.005265220630576651		[learning rate: 0.0065313]
	Learning Rate: 0.00653131
	LOSS [training: 0.005265220630576651 | validation: 0.0002696817726172197]
	TIME [epoch: 8.14 sec]
EPOCH 79/500:
	Training over batches...
		[batch 4/4] avg loss: 0.010141075774900539		[learning rate: 0.0064318]
	Learning Rate: 0.00643181
	LOSS [training: 0.010141075774900539 | validation: 0.004680448383086628]
	TIME [epoch: 8.1 sec]
EPOCH 80/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029402334882662147		[learning rate: 0.0063338]
	Learning Rate: 0.00633383
	LOSS [training: 0.029402334882662147 | validation: 0.05485876195599454]
	TIME [epoch: 8.1 sec]
EPOCH 81/500:
	Training over batches...
		[batch 4/4] avg loss: 0.058722858277987844		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.058722858277987844 | validation: 0.03796876707029484]
	TIME [epoch: 8.1 sec]
EPOCH 82/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027442595913026974		[learning rate: 0.0061423]
	Learning Rate: 0.00614233
	LOSS [training: 0.027442595913026974 | validation: 0.014130092314458121]
	TIME [epoch: 8.12 sec]
EPOCH 83/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03985679748876089		[learning rate: 0.0060488]
	Learning Rate: 0.00604876
	LOSS [training: 0.03985679748876089 | validation: 0.0405841966994282]
	TIME [epoch: 8.15 sec]
EPOCH 84/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07118570356501945		[learning rate: 0.0059566]
	Learning Rate: 0.00595662
	LOSS [training: 0.07118570356501945 | validation: 0.04425002172482867]
	TIME [epoch: 8.1 sec]
EPOCH 85/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06228159235476729		[learning rate: 0.0058659]
	Learning Rate: 0.00586588
	LOSS [training: 0.06228159235476729 | validation: 0.041406961391319067]
	TIME [epoch: 8.1 sec]
EPOCH 86/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06003812811498102		[learning rate: 0.0057765]
	Learning Rate: 0.00577653
	LOSS [training: 0.06003812811498102 | validation: 0.0541122863240852]
	TIME [epoch: 8.1 sec]
EPOCH 87/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07066895106576446		[learning rate: 0.0056885]
	Learning Rate: 0.00568853
	LOSS [training: 0.07066895106576446 | validation: 0.05817469034174741]
	TIME [epoch: 8.11 sec]
EPOCH 88/500:
	Training over batches...
		[batch 4/4] avg loss: 0.10110738685030353		[learning rate: 0.0056019]
	Learning Rate: 0.00560187
	LOSS [training: 0.10110738685030353 | validation: 0.10177588604651665]
	TIME [epoch: 8.14 sec]
EPOCH 89/500:
	Training over batches...
		[batch 4/4] avg loss: 0.10025029924617818		[learning rate: 0.0055165]
	Learning Rate: 0.00551654
	LOSS [training: 0.10025029924617818 | validation: 0.043717062833509825]
	TIME [epoch: 8.11 sec]
EPOCH 90/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05316269161360446		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.05316269161360446 | validation: 0.03502750311845027]
	TIME [epoch: 8.1 sec]
EPOCH 91/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05367745693784418		[learning rate: 0.0053497]
	Learning Rate: 0.00534975
	LOSS [training: 0.05367745693784418 | validation: 0.02231840743603543]
	TIME [epoch: 8.1 sec]
EPOCH 92/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03907668413088663		[learning rate: 0.0052683]
	Learning Rate: 0.00526825
	LOSS [training: 0.03907668413088663 | validation: 0.0014399560380560991]
	TIME [epoch: 8.1 sec]
EPOCH 93/500:
	Training over batches...
		[batch 4/4] avg loss: 0.019817532825888915		[learning rate: 0.005188]
	Learning Rate: 0.005188
	LOSS [training: 0.019817532825888915 | validation: 0.005454231580565621]
	TIME [epoch: 8.11 sec]
EPOCH 94/500:
	Training over batches...
		[batch 4/4] avg loss: 0.034754471007835436		[learning rate: 0.005109]
	Learning Rate: 0.00510897
	LOSS [training: 0.034754471007835436 | validation: 0.029254182960107494]
	TIME [epoch: 8.14 sec]
EPOCH 95/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0552348647540964		[learning rate: 0.0050311]
	Learning Rate: 0.00503114
	LOSS [training: 0.0552348647540964 | validation: 0.053873815918626056]
	TIME [epoch: 8.1 sec]
EPOCH 96/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07530053973717231		[learning rate: 0.0049545]
	Learning Rate: 0.0049545
	LOSS [training: 0.07530053973717231 | validation: 0.06944979832479477]
	TIME [epoch: 8.1 sec]
EPOCH 97/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07449738124335618		[learning rate: 0.004879]
	Learning Rate: 0.00487903
	LOSS [training: 0.07449738124335618 | validation: 0.056255235181814606]
	TIME [epoch: 8.1 sec]
EPOCH 98/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05483072111800702		[learning rate: 0.0048047]
	Learning Rate: 0.0048047
	LOSS [training: 0.05483072111800702 | validation: 0.024773456751171964]
	TIME [epoch: 8.11 sec]
EPOCH 99/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03952030972801742		[learning rate: 0.0047315]
	Learning Rate: 0.00473151
	LOSS [training: 0.03952030972801742 | validation: 0.020830564693669604]
	TIME [epoch: 8.14 sec]
EPOCH 100/500:
	Training over batches...
		[batch 4/4] avg loss: 0.046740745441958796		[learning rate: 0.0046594]
	Learning Rate: 0.00465944
	LOSS [training: 0.046740745441958796 | validation: 0.04398516580398817]
	TIME [epoch: 8.11 sec]
EPOCH 101/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04452491749174143		[learning rate: 0.0045885]
	Learning Rate: 0.00458846
	LOSS [training: 0.04452491749174143 | validation: 0.01778496053002794]
	TIME [epoch: 111 sec]
EPOCH 102/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023538309472500483		[learning rate: 0.0045186]
	Learning Rate: 0.00451856
	LOSS [training: 0.023538309472500483 | validation: 0.007359179770824419]
	TIME [epoch: 18.6 sec]
EPOCH 103/500:
	Training over batches...
		[batch 4/4] avg loss: 0.019099412973241546		[learning rate: 0.0044497]
	Learning Rate: 0.00444973
	LOSS [training: 0.019099412973241546 | validation: 0.008036411785358277]
	TIME [epoch: 18.6 sec]
EPOCH 104/500:
	Training over batches...
		[batch 4/4] avg loss: 0.017025123030020337		[learning rate: 0.0043819]
	Learning Rate: 0.00438194
	LOSS [training: 0.017025123030020337 | validation: 0.009067578776820698]
	TIME [epoch: 18.6 sec]
EPOCH 105/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02613866396170792		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 0.02613866396170792 | validation: 0.027983934644294522]
	TIME [epoch: 18.6 sec]
EPOCH 106/500:
	Training over batches...
		[batch 4/4] avg loss: 0.035711632266724594		[learning rate: 0.0042495]
	Learning Rate: 0.00424946
	LOSS [training: 0.035711632266724594 | validation: 0.01986903154771041]
	TIME [epoch: 18.5 sec]
EPOCH 107/500:
	Training over batches...
		[batch 4/4] avg loss: 0.019123525221179417		[learning rate: 0.0041847]
	Learning Rate: 0.00418472
	LOSS [training: 0.019123525221179417 | validation: 0.011509792124483874]
	TIME [epoch: 18.6 sec]
EPOCH 108/500:
	Training over batches...
		[batch 4/4] avg loss: 0.019843337063909595		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.019843337063909595 | validation: -0.0003643011717467974]
	TIME [epoch: 18.5 sec]
EPOCH 109/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006179388593381723		[learning rate: 0.0040582]
	Learning Rate: 0.0040582
	LOSS [training: 0.006179388593381723 | validation: -0.007736982738331306]
	TIME [epoch: 18.7 sec]
EPOCH 110/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01036207727614317		[learning rate: 0.0039964]
	Learning Rate: 0.00399638
	LOSS [training: 0.01036207727614317 | validation: 0.015202153886081768]
	TIME [epoch: 18.6 sec]
EPOCH 111/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023705629769512		[learning rate: 0.0039355]
	Learning Rate: 0.0039355
	LOSS [training: 0.023705629769512 | validation: 0.01527739135819385]
	TIME [epoch: 18.6 sec]
EPOCH 112/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02447298836852291		[learning rate: 0.0038755]
	Learning Rate: 0.00387555
	LOSS [training: 0.02447298836852291 | validation: 0.00965159364081225]
	TIME [epoch: 18.6 sec]
EPOCH 113/500:
	Training over batches...
		[batch 4/4] avg loss: 0.028447687281794677		[learning rate: 0.0038165]
	Learning Rate: 0.00381651
	LOSS [training: 0.028447687281794677 | validation: 0.014884492207438725]
	TIME [epoch: 18.6 sec]
EPOCH 114/500:
	Training over batches...
		[batch 4/4] avg loss: 0.022284066734028912		[learning rate: 0.0037584]
	Learning Rate: 0.00375837
	LOSS [training: 0.022284066734028912 | validation: -0.002641484294575825]
	TIME [epoch: 18.6 sec]
EPOCH 115/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01803069396209122		[learning rate: 0.0037011]
	Learning Rate: 0.00370112
	LOSS [training: 0.01803069396209122 | validation: -0.004310169725907422]
	TIME [epoch: 18.6 sec]
EPOCH 116/500:
	Training over batches...
		[batch 4/4] avg loss: 0.011716022601804021		[learning rate: 0.0036447]
	Learning Rate: 0.00364474
	LOSS [training: 0.011716022601804021 | validation: 0.002868159254759582]
	TIME [epoch: 18.7 sec]
EPOCH 117/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007739468599439627		[learning rate: 0.0035892]
	Learning Rate: 0.00358922
	LOSS [training: 0.007739468599439627 | validation: 0.005107530516599326]
	TIME [epoch: 18.6 sec]
EPOCH 118/500:
	Training over batches...
		[batch 4/4] avg loss: 0.015538392427874033		[learning rate: 0.0035345]
	Learning Rate: 0.00353454
	LOSS [training: 0.015538392427874033 | validation: -0.0011932032730669617]
	TIME [epoch: 18.7 sec]
EPOCH 119/500:
	Training over batches...
		[batch 4/4] avg loss: 0.017380985401772818		[learning rate: 0.0034807]
	Learning Rate: 0.0034807
	LOSS [training: 0.017380985401772818 | validation: -0.006350057614404753]
	TIME [epoch: 18.6 sec]
EPOCH 120/500:
	Training over batches...
		[batch 4/4] avg loss: 0.013405664762515031		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 0.013405664762515031 | validation: 0.003779451595459722]
	TIME [epoch: 18.6 sec]
EPOCH 121/500:
	Training over batches...
		[batch 4/4] avg loss: 0.013378037369591544		[learning rate: 0.0033755]
	Learning Rate: 0.00337546
	LOSS [training: 0.013378037369591544 | validation: 0.0012501416189459554]
	TIME [epoch: 18.6 sec]
EPOCH 122/500:
	Training over batches...
		[batch 4/4] avg loss: 0.012320313052777214		[learning rate: 0.003324]
	Learning Rate: 0.00332404
	LOSS [training: 0.012320313052777214 | validation: -0.004369386070702823]
	TIME [epoch: 18.6 sec]
EPOCH 123/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006935823579337251		[learning rate: 0.0032734]
	Learning Rate: 0.00327341
	LOSS [training: 0.006935823579337251 | validation: -0.016313102242331966]
	TIME [epoch: 18.5 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_123.pth
	Model improved!!!
EPOCH 124/500:
	Training over batches...
		[batch 4/4] avg loss: 0.002127890926376415		[learning rate: 0.0032235]
	Learning Rate: 0.00322354
	LOSS [training: 0.002127890926376415 | validation: -0.008681015293705886]
	TIME [epoch: 18.5 sec]
EPOCH 125/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0022977042408538987		[learning rate: 0.0031744]
	Learning Rate: 0.00317444
	LOSS [training: 0.0022977042408538987 | validation: 0.005145922632137362]
	TIME [epoch: 18.5 sec]
EPOCH 126/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008736315326030055		[learning rate: 0.0031261]
	Learning Rate: 0.00312608
	LOSS [training: 0.008736315326030055 | validation: -0.011313055630580446]
	TIME [epoch: 18.6 sec]
EPOCH 127/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0023008116018058272		[learning rate: 0.0030785]
	Learning Rate: 0.00307846
	LOSS [training: 0.0023008116018058272 | validation: -0.002214147974336832]
	TIME [epoch: 18.5 sec]
EPOCH 128/500:
	Training over batches...
		[batch 4/4] avg loss: 0.010974167128141615		[learning rate: 0.0030316]
	Learning Rate: 0.00303156
	LOSS [training: 0.010974167128141615 | validation: 0.016777062141658444]
	TIME [epoch: 18.5 sec]
EPOCH 129/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01679185132181634		[learning rate: 0.0029854]
	Learning Rate: 0.00298538
	LOSS [training: 0.01679185132181634 | validation: 0.006988658923382749]
	TIME [epoch: 18.5 sec]
EPOCH 130/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0049151977516935065		[learning rate: 0.0029399]
	Learning Rate: 0.0029399
	LOSS [training: 0.0049151977516935065 | validation: 0.005512585945259196]
	TIME [epoch: 18.5 sec]
EPOCH 131/500:
	Training over batches...
		[batch 4/4] avg loss: -0.003784009229465511		[learning rate: 0.0028951]
	Learning Rate: 0.00289512
	LOSS [training: -0.003784009229465511 | validation: -0.0140481928102264]
	TIME [epoch: 18.5 sec]
EPOCH 132/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0007140595104082951		[learning rate: 0.002851]
	Learning Rate: 0.00285102
	LOSS [training: -0.0007140595104082951 | validation: -0.018756521120303914]
	TIME [epoch: 18.5 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_132.pth
	Model improved!!!
EPOCH 133/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0025884305684648326		[learning rate: 0.0028076]
	Learning Rate: 0.00280759
	LOSS [training: -0.0025884305684648326 | validation: -0.014606578502628647]
	TIME [epoch: 18.5 sec]
EPOCH 134/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0016933040160241138		[learning rate: 0.0027648]
	Learning Rate: 0.00276482
	LOSS [training: -0.0016933040160241138 | validation: -0.011663958251162393]
	TIME [epoch: 18.5 sec]
EPOCH 135/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0036082984725961556		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.0036082984725961556 | validation: -0.007389887223011756]
	TIME [epoch: 18.5 sec]
EPOCH 136/500:
	Training over batches...
		[batch 4/4] avg loss: 0.002719822391730277		[learning rate: 0.0026812]
	Learning Rate: 0.00268123
	LOSS [training: 0.002719822391730277 | validation: -0.016827249072113026]
	TIME [epoch: 18.5 sec]
EPOCH 137/500:
	Training over batches...
		[batch 4/4] avg loss: -0.003203905352906445		[learning rate: 0.0026404]
	Learning Rate: 0.00264038
	LOSS [training: -0.003203905352906445 | validation: -0.014847220003678593]
	TIME [epoch: 18.5 sec]
EPOCH 138/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0014226357460519698		[learning rate: 0.0026002]
	Learning Rate: 0.00260016
	LOSS [training: 0.0014226357460519698 | validation: -0.01796034186472059]
	TIME [epoch: 18.5 sec]
EPOCH 139/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005297381514522854		[learning rate: 0.0025606]
	Learning Rate: 0.00256055
	LOSS [training: -0.005297381514522854 | validation: -0.017518447993611196]
	TIME [epoch: 18.5 sec]
EPOCH 140/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0037661948520209456		[learning rate: 0.0025215]
	Learning Rate: 0.00252154
	LOSS [training: -0.0037661948520209456 | validation: -0.009686062935084361]
	TIME [epoch: 18.6 sec]
EPOCH 141/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004850158889319985		[learning rate: 0.0024831]
	Learning Rate: 0.00248313
	LOSS [training: -0.004850158889319985 | validation: -0.023948255152062996]
	TIME [epoch: 18.5 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_141.pth
	Model improved!!!
EPOCH 142/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010511097864937528		[learning rate: 0.0024453]
	Learning Rate: 0.00244531
	LOSS [training: -0.010511097864937528 | validation: -0.019310594476557943]
	TIME [epoch: 18.5 sec]
EPOCH 143/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0071049095225483245		[learning rate: 0.0024081]
	Learning Rate: 0.00240806
	LOSS [training: -0.0071049095225483245 | validation: -0.011672702096199302]
	TIME [epoch: 18.6 sec]
EPOCH 144/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0107218358270985		[learning rate: 0.0023714]
	Learning Rate: 0.00237137
	LOSS [training: -0.0107218358270985 | validation: -0.01832331247805944]
	TIME [epoch: 18.5 sec]
EPOCH 145/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007338708597720603		[learning rate: 0.0023352]
	Learning Rate: 0.00233525
	LOSS [training: -0.007338708597720603 | validation: -0.015987129336810173]
	TIME [epoch: 18.5 sec]
EPOCH 146/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0031523457160337453		[learning rate: 0.0022997]
	Learning Rate: 0.00229968
	LOSS [training: -0.0031523457160337453 | validation: -0.015319049571502527]
	TIME [epoch: 18.5 sec]
EPOCH 147/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0034684851339555857		[learning rate: 0.0022646]
	Learning Rate: 0.00226464
	LOSS [training: -0.0034684851339555857 | validation: -0.020982786442106077]
	TIME [epoch: 18.5 sec]
EPOCH 148/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006764579524801687		[learning rate: 0.0022301]
	Learning Rate: 0.00223015
	LOSS [training: -0.006764579524801687 | validation: -0.01751743969344583]
	TIME [epoch: 18.5 sec]
EPOCH 149/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011033434301085564		[learning rate: 0.0021962]
	Learning Rate: 0.00219617
	LOSS [training: -0.011033434301085564 | validation: -0.02169057339164842]
	TIME [epoch: 18.5 sec]
EPOCH 150/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009453900914099329		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: -0.009453900914099329 | validation: -0.021136408739140643]
	TIME [epoch: 18.5 sec]
EPOCH 151/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007785684657734566		[learning rate: 0.0021298]
	Learning Rate: 0.00212977
	LOSS [training: -0.007785684657734566 | validation: -0.011437612076465938]
	TIME [epoch: 18.5 sec]
EPOCH 152/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007220985249183037		[learning rate: 0.0020973]
	Learning Rate: 0.00209733
	LOSS [training: -0.007220985249183037 | validation: -0.014522382829282756]
	TIME [epoch: 18.5 sec]
EPOCH 153/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008704007081186096		[learning rate: 0.0020654]
	Learning Rate: 0.00206538
	LOSS [training: -0.008704007081186096 | validation: -0.014007086281837194]
	TIME [epoch: 18.4 sec]
EPOCH 154/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01104281209677763		[learning rate: 0.0020339]
	Learning Rate: 0.00203392
	LOSS [training: -0.01104281209677763 | validation: -0.004179483328843867]
	TIME [epoch: 18.5 sec]
EPOCH 155/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005039447969506566		[learning rate: 0.0020029]
	Learning Rate: 0.00200293
	LOSS [training: -0.005039447969506566 | validation: -0.010402195667619438]
	TIME [epoch: 18.4 sec]
EPOCH 156/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005322983057862494		[learning rate: 0.0019724]
	Learning Rate: 0.00197242
	LOSS [training: -0.005322983057862494 | validation: -0.009557384086108182]
	TIME [epoch: 18.5 sec]
EPOCH 157/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0038892393162926597		[learning rate: 0.0019424]
	Learning Rate: 0.00194238
	LOSS [training: -0.0038892393162926597 | validation: -0.0007212265141619549]
	TIME [epoch: 18.5 sec]
EPOCH 158/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021744598171379963		[learning rate: 0.0019128]
	Learning Rate: 0.00191279
	LOSS [training: -0.0021744598171379963 | validation: -0.010652880589076999]
	TIME [epoch: 18.5 sec]
EPOCH 159/500:
	Training over batches...
		[batch 4/4] avg loss: 0.005591843809324704		[learning rate: 0.0018836]
	Learning Rate: 0.00188365
	LOSS [training: 0.005591843809324704 | validation: 0.0010235398650019242]
	TIME [epoch: 18.5 sec]
EPOCH 160/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00014281326225201946		[learning rate: 0.001855]
	Learning Rate: 0.00185495
	LOSS [training: -0.00014281326225201946 | validation: 0.003666850704738616]
	TIME [epoch: 18.4 sec]
EPOCH 161/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006823210378897223		[learning rate: 0.0018267]
	Learning Rate: 0.0018267
	LOSS [training: 0.006823210378897223 | validation: 0.006430040049977776]
	TIME [epoch: 18.5 sec]
EPOCH 162/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008276527084759936		[learning rate: 0.0017989]
	Learning Rate: 0.00179887
	LOSS [training: 0.008276527084759936 | validation: -0.0024221003671509524]
	TIME [epoch: 18.5 sec]
EPOCH 163/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008891450245494908		[learning rate: 0.0017715]
	Learning Rate: 0.00177147
	LOSS [training: 0.008891450245494908 | validation: -0.005611671714604928]
	TIME [epoch: 18.5 sec]
EPOCH 164/500:
	Training over batches...
		[batch 4/4] avg loss: 0.005322320128748141		[learning rate: 0.0017445]
	Learning Rate: 0.00174448
	LOSS [training: 0.005322320128748141 | validation: -0.004968142012325415]
	TIME [epoch: 18.5 sec]
EPOCH 165/500:
	Training over batches...
		[batch 4/4] avg loss: 0.011221577023361162		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: 0.011221577023361162 | validation: 0.0007594730894409526]
	TIME [epoch: 18.5 sec]
EPOCH 166/500:
	Training over batches...
		[batch 4/4] avg loss: 0.011530377764585622		[learning rate: 0.0016917]
	Learning Rate: 0.00169174
	LOSS [training: 0.011530377764585622 | validation: 0.004340706711062848]
	TIME [epoch: 18.5 sec]
EPOCH 167/500:
	Training over batches...
		[batch 4/4] avg loss: 0.010148800185768365		[learning rate: 0.001666]
	Learning Rate: 0.00166597
	LOSS [training: 0.010148800185768365 | validation: 0.0087192003326622]
	TIME [epoch: 18.5 sec]
EPOCH 168/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01608206343006847		[learning rate: 0.0016406]
	Learning Rate: 0.00164059
	LOSS [training: 0.01608206343006847 | validation: 0.0005730392448549831]
	TIME [epoch: 18.5 sec]
EPOCH 169/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01952453309067654		[learning rate: 0.0016156]
	Learning Rate: 0.0016156
	LOSS [training: 0.01952453309067654 | validation: 0.015257627122092679]
	TIME [epoch: 18.4 sec]
EPOCH 170/500:
	Training over batches...
		[batch 4/4] avg loss: 0.013675263015231628		[learning rate: 0.001591]
	Learning Rate: 0.00159099
	LOSS [training: 0.013675263015231628 | validation: -0.006390093333755234]
	TIME [epoch: 18.5 sec]
EPOCH 171/500:
	Training over batches...
		[batch 4/4] avg loss: 0.013224977134264512		[learning rate: 0.0015668]
	Learning Rate: 0.00156675
	LOSS [training: 0.013224977134264512 | validation: 0.0038077058587445943]
	TIME [epoch: 18.5 sec]
EPOCH 172/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01271987905527083		[learning rate: 0.0015429]
	Learning Rate: 0.00154288
	LOSS [training: 0.01271987905527083 | validation: 0.00561469144525837]
	TIME [epoch: 18.5 sec]
EPOCH 173/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01175014864553873		[learning rate: 0.0015194]
	Learning Rate: 0.00151938
	LOSS [training: 0.01175014864553873 | validation: 0.007995733349230622]
	TIME [epoch: 18.5 sec]
EPOCH 174/500:
	Training over batches...
		[batch 4/4] avg loss: 0.012115409397751402		[learning rate: 0.0014962]
	Learning Rate: 0.00149624
	LOSS [training: 0.012115409397751402 | validation: 0.0004513906701631538]
	TIME [epoch: 18.5 sec]
EPOCH 175/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006011478689692063		[learning rate: 0.0014734]
	Learning Rate: 0.00147344
	LOSS [training: 0.006011478689692063 | validation: -0.002084168833654122]
	TIME [epoch: 18.5 sec]
EPOCH 176/500:
	Training over batches...
		[batch 4/4] avg loss: 0.002285317662468171		[learning rate: 0.001451]
	Learning Rate: 0.001451
	LOSS [training: 0.002285317662468171 | validation: -0.003227207784337317]
	TIME [epoch: 18.5 sec]
EPOCH 177/500:
	Training over batches...
		[batch 4/4] avg loss: 0.005706575919812532		[learning rate: 0.0014289]
	Learning Rate: 0.00142889
	LOSS [training: 0.005706575919812532 | validation: -0.015386043610866288]
	TIME [epoch: 18.5 sec]
EPOCH 178/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0029084120503190362		[learning rate: 0.0014071]
	Learning Rate: 0.00140713
	LOSS [training: 0.0029084120503190362 | validation: -0.003414147383202435]
	TIME [epoch: 18.4 sec]
EPOCH 179/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0006777489749550999		[learning rate: 0.0013857]
	Learning Rate: 0.00138569
	LOSS [training: 0.0006777489749550999 | validation: -0.0054180727928063496]
	TIME [epoch: 18.5 sec]
EPOCH 180/500:
	Training over batches...
		[batch 4/4] avg loss: 0.004817520408612777		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: 0.004817520408612777 | validation: 0.008003991031487781]
	TIME [epoch: 18.5 sec]
EPOCH 181/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0092096371607587		[learning rate: 0.0013438]
	Learning Rate: 0.0013438
	LOSS [training: 0.0092096371607587 | validation: 0.0017939529634978895]
	TIME [epoch: 18.5 sec]
EPOCH 182/500:
	Training over batches...
		[batch 4/4] avg loss: 0.004623095179499075		[learning rate: 0.0013233]
	Learning Rate: 0.00132333
	LOSS [training: 0.004623095179499075 | validation: -0.00881101422362772]
	TIME [epoch: 18.5 sec]
EPOCH 183/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0016127194203413248		[learning rate: 0.0013032]
	Learning Rate: 0.00130317
	LOSS [training: 0.0016127194203413248 | validation: -0.0018546351808359542]
	TIME [epoch: 18.5 sec]
EPOCH 184/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006404554175121531		[learning rate: 0.0012833]
	Learning Rate: 0.00128332
	LOSS [training: -0.006404554175121531 | validation: -0.007861236460922658]
	TIME [epoch: 18.5 sec]
EPOCH 185/500:
	Training over batches...
		[batch 4/4] avg loss: -0.003181896433801526		[learning rate: 0.0012638]
	Learning Rate: 0.00126377
	LOSS [training: -0.003181896433801526 | validation: -0.00943094003828232]
	TIME [epoch: 18.4 sec]
EPOCH 186/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005255773333214413		[learning rate: 0.0012445]
	Learning Rate: 0.00124451
	LOSS [training: -0.005255773333214413 | validation: -0.01014339667095029]
	TIME [epoch: 18.5 sec]
EPOCH 187/500:
	Training over batches...
		[batch 4/4] avg loss: -0.003781480110631605		[learning rate: 0.0012256]
	Learning Rate: 0.00122556
	LOSS [training: -0.003781480110631605 | validation: -0.02199516367005206]
	TIME [epoch: 18.5 sec]
EPOCH 188/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009304501004679559		[learning rate: 0.0012069]
	Learning Rate: 0.00120689
	LOSS [training: -0.009304501004679559 | validation: -0.009745600363009588]
	TIME [epoch: 18.5 sec]
EPOCH 189/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004255344218224058		[learning rate: 0.0011885]
	Learning Rate: 0.0011885
	LOSS [training: -0.004255344218224058 | validation: -0.01505482779588273]
	TIME [epoch: 18.5 sec]
EPOCH 190/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0047459986645522695		[learning rate: 0.0011704]
	Learning Rate: 0.0011704
	LOSS [training: -0.0047459986645522695 | validation: -0.01705129421523859]
	TIME [epoch: 18.5 sec]
EPOCH 191/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005549901291433083		[learning rate: 0.0011526]
	Learning Rate: 0.00115257
	LOSS [training: -0.005549901291433083 | validation: -0.011759057841642231]
	TIME [epoch: 18.5 sec]
EPOCH 192/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00657469095454968		[learning rate: 0.001135]
	Learning Rate: 0.00113501
	LOSS [training: -0.00657469095454968 | validation: -0.0071026756123023895]
	TIME [epoch: 18.5 sec]
EPOCH 193/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008494456750237066		[learning rate: 0.0011177]
	Learning Rate: 0.00111772
	LOSS [training: -0.008494456750237066 | validation: -0.016674620230456766]
	TIME [epoch: 18.5 sec]
EPOCH 194/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005670209642229515		[learning rate: 0.0011007]
	Learning Rate: 0.00110069
	LOSS [training: -0.005670209642229515 | validation: -0.01661495488066453]
	TIME [epoch: 18.5 sec]
EPOCH 195/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00592401473017466		[learning rate: 0.0010839]
	Learning Rate: 0.00108393
	LOSS [training: -0.00592401473017466 | validation: -0.012027909716150212]
	TIME [epoch: 18.5 sec]
EPOCH 196/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007702873478950392		[learning rate: 0.0010674]
	Learning Rate: 0.00106741
	LOSS [training: -0.007702873478950392 | validation: -0.012922496774284767]
	TIME [epoch: 18.4 sec]
EPOCH 197/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008236630366881374		[learning rate: 0.0010512]
	Learning Rate: 0.00105115
	LOSS [training: -0.008236630366881374 | validation: -0.009772325905876632]
	TIME [epoch: 18.5 sec]
EPOCH 198/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0017777779652288328		[learning rate: 0.0010351]
	Learning Rate: 0.00103514
	LOSS [training: -0.0017777779652288328 | validation: -0.014336434875228711]
	TIME [epoch: 18.6 sec]
EPOCH 199/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0032939650774495696		[learning rate: 0.0010194]
	Learning Rate: 0.00101937
	LOSS [training: -0.0032939650774495696 | validation: -0.011755970037996371]
	TIME [epoch: 18.5 sec]
EPOCH 200/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007270179632189058		[learning rate: 0.0010038]
	Learning Rate: 0.00100384
	LOSS [training: -0.007270179632189058 | validation: -0.020071485347048397]
	TIME [epoch: 18.6 sec]
EPOCH 201/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010975878575023447		[learning rate: 0.00098855]
	Learning Rate: 0.000988553
	LOSS [training: -0.010975878575023447 | validation: -0.014851194108150077]
	TIME [epoch: 18.5 sec]
EPOCH 202/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010831166355195506		[learning rate: 0.00097349]
	Learning Rate: 0.000973494
	LOSS [training: -0.010831166355195506 | validation: -0.011188185160548685]
	TIME [epoch: 18.6 sec]
EPOCH 203/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00704103586494758		[learning rate: 0.00095866]
	Learning Rate: 0.000958664
	LOSS [training: -0.00704103586494758 | validation: -0.01293572703442723]
	TIME [epoch: 18.5 sec]
EPOCH 204/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011065518943445821		[learning rate: 0.00094406]
	Learning Rate: 0.000944061
	LOSS [training: -0.011065518943445821 | validation: -0.01601153847359993]
	TIME [epoch: 18.5 sec]
EPOCH 205/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010410338360549994		[learning rate: 0.00092968]
	Learning Rate: 0.00092968
	LOSS [training: -0.010410338360549994 | validation: -0.015783133364073675]
	TIME [epoch: 18.5 sec]
EPOCH 206/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008909276683601395		[learning rate: 0.00091552]
	Learning Rate: 0.000915518
	LOSS [training: -0.008909276683601395 | validation: -0.003338500947779319]
	TIME [epoch: 18.5 sec]
EPOCH 207/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0057740109531895225		[learning rate: 0.00090157]
	Learning Rate: 0.000901571
	LOSS [training: -0.0057740109531895225 | validation: -0.013383404937843206]
	TIME [epoch: 18.5 sec]
EPOCH 208/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00829333696222435		[learning rate: 0.00088784]
	Learning Rate: 0.000887837
	LOSS [training: -0.00829333696222435 | validation: 0.00047523239317945765]
	TIME [epoch: 18.4 sec]
EPOCH 209/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010626155908172022		[learning rate: 0.00087431]
	Learning Rate: 0.000874312
	LOSS [training: -0.010626155908172022 | validation: -0.013419402519419536]
	TIME [epoch: 18.5 sec]
EPOCH 210/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011313828649945245		[learning rate: 0.00086099]
	Learning Rate: 0.000860994
	LOSS [training: -0.011313828649945245 | validation: -0.013113018131024137]
	TIME [epoch: 18.4 sec]
EPOCH 211/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008367160353184607		[learning rate: 0.00084788]
	Learning Rate: 0.000847878
	LOSS [training: -0.008367160353184607 | validation: -0.025157644858505857]
	TIME [epoch: 18.5 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_211.pth
	Model improved!!!
EPOCH 212/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007416053646831797		[learning rate: 0.00083496]
	Learning Rate: 0.000834962
	LOSS [training: -0.007416053646831797 | validation: -0.003261096954492]
	TIME [epoch: 18.4 sec]
EPOCH 213/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00970536167201676		[learning rate: 0.00082224]
	Learning Rate: 0.000822243
	LOSS [training: -0.00970536167201676 | validation: -0.00536159562378867]
	TIME [epoch: 18.4 sec]
EPOCH 214/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011248691972718616		[learning rate: 0.00080972]
	Learning Rate: 0.000809717
	LOSS [training: -0.011248691972718616 | validation: -0.010540935717482908]
	TIME [epoch: 18.5 sec]
EPOCH 215/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005117699639859686		[learning rate: 0.00079738]
	Learning Rate: 0.000797382
	LOSS [training: -0.005117699639859686 | validation: -0.007785523945207662]
	TIME [epoch: 18.4 sec]
EPOCH 216/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0058052360959634786		[learning rate: 0.00078524]
	Learning Rate: 0.000785236
	LOSS [training: -0.0058052360959634786 | validation: -0.0003796973173519798]
	TIME [epoch: 18.5 sec]
EPOCH 217/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006717674518138622		[learning rate: 0.00077327]
	Learning Rate: 0.000773274
	LOSS [training: -0.006717674518138622 | validation: -0.014883576513919125]
	TIME [epoch: 18.4 sec]
EPOCH 218/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009041157803954097		[learning rate: 0.00076149]
	Learning Rate: 0.000761494
	LOSS [training: -0.009041157803954097 | validation: -0.009722147852150406]
	TIME [epoch: 18.5 sec]
EPOCH 219/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008946077334079806		[learning rate: 0.00074989]
	Learning Rate: 0.000749894
	LOSS [training: -0.008946077334079806 | validation: -0.01623583914805699]
	TIME [epoch: 18.4 sec]
EPOCH 220/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010178063174293822		[learning rate: 0.00073847]
	Learning Rate: 0.000738471
	LOSS [training: -0.010178063174293822 | validation: -0.006615941623533395]
	TIME [epoch: 18.5 sec]
EPOCH 221/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008661624064330995		[learning rate: 0.00072722]
	Learning Rate: 0.000727221
	LOSS [training: -0.008661624064330995 | validation: -0.00665847637288509]
	TIME [epoch: 18.5 sec]
EPOCH 222/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008936628377867387		[learning rate: 0.00071614]
	Learning Rate: 0.000716143
	LOSS [training: -0.008936628377867387 | validation: -0.00917004966537785]
	TIME [epoch: 18.4 sec]
EPOCH 223/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006344277415940441		[learning rate: 0.00070523]
	Learning Rate: 0.000705234
	LOSS [training: -0.006344277415940441 | validation: -0.01487556885274729]
	TIME [epoch: 18.5 sec]
EPOCH 224/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005698604146781928		[learning rate: 0.00069449]
	Learning Rate: 0.000694491
	LOSS [training: -0.005698604146781928 | validation: -0.00895930636244572]
	TIME [epoch: 18.5 sec]
EPOCH 225/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007840622623298935		[learning rate: 0.00068391]
	Learning Rate: 0.000683912
	LOSS [training: -0.007840622623298935 | validation: -0.014675672738159777]
	TIME [epoch: 18.5 sec]
EPOCH 226/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007189173998826733		[learning rate: 0.00067349]
	Learning Rate: 0.000673493
	LOSS [training: -0.007189173998826733 | validation: -0.011246802913458472]
	TIME [epoch: 18.4 sec]
EPOCH 227/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0072481319946183865		[learning rate: 0.00066323]
	Learning Rate: 0.000663234
	LOSS [training: -0.0072481319946183865 | validation: -0.0025340044140860878]
	TIME [epoch: 18.5 sec]
EPOCH 228/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007412238786162288		[learning rate: 0.00065313]
	Learning Rate: 0.00065313
	LOSS [training: -0.007412238786162288 | validation: -0.016942514928978636]
	TIME [epoch: 18.5 sec]
EPOCH 229/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010615577434066851		[learning rate: 0.00064318]
	Learning Rate: 0.000643181
	LOSS [training: -0.010615577434066851 | validation: -0.01654314531784986]
	TIME [epoch: 18.4 sec]
EPOCH 230/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011890498243965517		[learning rate: 0.00063338]
	Learning Rate: 0.000633383
	LOSS [training: -0.011890498243965517 | validation: -0.012245994529688269]
	TIME [epoch: 18.5 sec]
EPOCH 231/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009828485685336834		[learning rate: 0.00062373]
	Learning Rate: 0.000623735
	LOSS [training: -0.009828485685336834 | validation: -0.024302437191737074]
	TIME [epoch: 18.4 sec]
EPOCH 232/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011373230504917849		[learning rate: 0.00061423]
	Learning Rate: 0.000614233
	LOSS [training: -0.011373230504917849 | validation: -0.02310242894276962]
	TIME [epoch: 18.5 sec]
EPOCH 233/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00996121706683466		[learning rate: 0.00060488]
	Learning Rate: 0.000604876
	LOSS [training: -0.00996121706683466 | validation: -0.011486103502251798]
	TIME [epoch: 18.4 sec]
EPOCH 234/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009054350280220788		[learning rate: 0.00059566]
	Learning Rate: 0.000595662
	LOSS [training: -0.009054350280220788 | validation: -0.01740533283444744]
	TIME [epoch: 18.5 sec]
EPOCH 235/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0063851893591961315		[learning rate: 0.00058659]
	Learning Rate: 0.000586588
	LOSS [training: -0.0063851893591961315 | validation: -0.009521368046968959]
	TIME [epoch: 18.4 sec]
EPOCH 236/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008466064048415338		[learning rate: 0.00057765]
	Learning Rate: 0.000577652
	LOSS [training: -0.008466064048415338 | validation: -0.01742249377654631]
	TIME [epoch: 18.4 sec]
EPOCH 237/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010159597840112356		[learning rate: 0.00056885]
	Learning Rate: 0.000568853
	LOSS [training: -0.010159597840112356 | validation: -0.011990334207650933]
	TIME [epoch: 18.5 sec]
EPOCH 238/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0077615641337522995		[learning rate: 0.00056019]
	Learning Rate: 0.000560187
	LOSS [training: -0.0077615641337522995 | validation: -0.02238011070120168]
	TIME [epoch: 18.4 sec]
EPOCH 239/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009529242040096782		[learning rate: 0.00055165]
	Learning Rate: 0.000551654
	LOSS [training: -0.009529242040096782 | validation: -0.0075419468795142825]
	TIME [epoch: 18.5 sec]
EPOCH 240/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009054801706861026		[learning rate: 0.00054325]
	Learning Rate: 0.00054325
	LOSS [training: -0.009054801706861026 | validation: -0.010652564780776606]
	TIME [epoch: 18.4 sec]
EPOCH 241/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00781035434426368		[learning rate: 0.00053497]
	Learning Rate: 0.000534975
	LOSS [training: -0.00781035434426368 | validation: -0.01265219248658261]
	TIME [epoch: 18.5 sec]
EPOCH 242/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008463543961724421		[learning rate: 0.00052683]
	Learning Rate: 0.000526825
	LOSS [training: -0.008463543961724421 | validation: -0.0038820060035667757]
	TIME [epoch: 18.4 sec]
EPOCH 243/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0045193288567779875		[learning rate: 0.0005188]
	Learning Rate: 0.0005188
	LOSS [training: -0.0045193288567779875 | validation: -0.013207013332246454]
	TIME [epoch: 18.5 sec]
EPOCH 244/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01027714116106394		[learning rate: 0.0005109]
	Learning Rate: 0.000510897
	LOSS [training: -0.01027714116106394 | validation: -0.020557627097835453]
	TIME [epoch: 18.5 sec]
EPOCH 245/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008981664780001963		[learning rate: 0.00050311]
	Learning Rate: 0.000503114
	LOSS [training: -0.008981664780001963 | validation: -0.024275517749130684]
	TIME [epoch: 18.4 sec]
EPOCH 246/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006966139003808177		[learning rate: 0.00049545]
	Learning Rate: 0.00049545
	LOSS [training: -0.006966139003808177 | validation: -0.012513968959984781]
	TIME [epoch: 18.5 sec]
EPOCH 247/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007820706995509841		[learning rate: 0.0004879]
	Learning Rate: 0.000487903
	LOSS [training: -0.007820706995509841 | validation: -0.012283474534442028]
	TIME [epoch: 18.4 sec]
EPOCH 248/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007080139310041008		[learning rate: 0.00048047]
	Learning Rate: 0.00048047
	LOSS [training: -0.007080139310041008 | validation: -0.01847548804804409]
	TIME [epoch: 18.5 sec]
EPOCH 249/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010371536370336278		[learning rate: 0.00047315]
	Learning Rate: 0.000473151
	LOSS [training: -0.010371536370336278 | validation: -0.012650055160900888]
	TIME [epoch: 18.4 sec]
EPOCH 250/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008832130261632935		[learning rate: 0.00046594]
	Learning Rate: 0.000465944
	LOSS [training: -0.008832130261632935 | validation: -0.01686069264569992]
	TIME [epoch: 18.5 sec]
EPOCH 251/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010838843896129883		[learning rate: 0.00045885]
	Learning Rate: 0.000458846
	LOSS [training: -0.010838843896129883 | validation: -0.015319875648866176]
	TIME [epoch: 133 sec]
EPOCH 252/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0065802941524266065		[learning rate: 0.00045186]
	Learning Rate: 0.000451856
	LOSS [training: -0.0065802941524266065 | validation: -0.017214202768289825]
	TIME [epoch: 41.2 sec]
EPOCH 253/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009342132324302498		[learning rate: 0.00044497]
	Learning Rate: 0.000444973
	LOSS [training: -0.009342132324302498 | validation: -0.01631247604802482]
	TIME [epoch: 41 sec]
EPOCH 254/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009846396605128937		[learning rate: 0.00043819]
	Learning Rate: 0.000438194
	LOSS [training: -0.009846396605128937 | validation: 0.0017203193982151005]
	TIME [epoch: 41 sec]
EPOCH 255/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005531492495273679		[learning rate: 0.00043152]
	Learning Rate: 0.000431519
	LOSS [training: -0.005531492495273679 | validation: -0.0015203259413796495]
	TIME [epoch: 41 sec]
EPOCH 256/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0073925952120978125		[learning rate: 0.00042495]
	Learning Rate: 0.000424946
	LOSS [training: -0.0073925952120978125 | validation: -0.011697975893971728]
	TIME [epoch: 41 sec]
EPOCH 257/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007474514201667034		[learning rate: 0.00041847]
	Learning Rate: 0.000418472
	LOSS [training: -0.007474514201667034 | validation: -0.016131844909787026]
	TIME [epoch: 41 sec]
EPOCH 258/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010701790713978036		[learning rate: 0.0004121]
	Learning Rate: 0.000412098
	LOSS [training: -0.010701790713978036 | validation: -0.02348875793727117]
	TIME [epoch: 41 sec]
EPOCH 259/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007073744370176385		[learning rate: 0.00040582]
	Learning Rate: 0.00040582
	LOSS [training: -0.007073744370176385 | validation: -0.015544133422446978]
	TIME [epoch: 41 sec]
EPOCH 260/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007695797076187026		[learning rate: 0.00039964]
	Learning Rate: 0.000399638
	LOSS [training: -0.007695797076187026 | validation: -0.010741408609256911]
	TIME [epoch: 41 sec]
EPOCH 261/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007190843165616849		[learning rate: 0.00039355]
	Learning Rate: 0.00039355
	LOSS [training: -0.007190843165616849 | validation: -0.0074245614382094]
	TIME [epoch: 41 sec]
EPOCH 262/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009374855594415218		[learning rate: 0.00038755]
	Learning Rate: 0.000387555
	LOSS [training: -0.009374855594415218 | validation: -0.018526580987321423]
	TIME [epoch: 41 sec]
EPOCH 263/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007739270867443792		[learning rate: 0.00038165]
	Learning Rate: 0.000381651
	LOSS [training: -0.007739270867443792 | validation: -0.009492051447575622]
	TIME [epoch: 41 sec]
EPOCH 264/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00779836930515341		[learning rate: 0.00037584]
	Learning Rate: 0.000375837
	LOSS [training: -0.00779836930515341 | validation: -0.026730032887945496]
	TIME [epoch: 41 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_264.pth
	Model improved!!!
EPOCH 265/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004128351289415793		[learning rate: 0.00037011]
	Learning Rate: 0.000370112
	LOSS [training: -0.004128351289415793 | validation: -0.023991031228914925]
	TIME [epoch: 41.1 sec]
EPOCH 266/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0052503515729178845		[learning rate: 0.00036447]
	Learning Rate: 0.000364474
	LOSS [training: -0.0052503515729178845 | validation: -0.02172014923865151]
	TIME [epoch: 41 sec]
EPOCH 267/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0072854042133818145		[learning rate: 0.00035892]
	Learning Rate: 0.000358922
	LOSS [training: -0.0072854042133818145 | validation: -0.027922574708362107]
	TIME [epoch: 41.1 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_267.pth
	Model improved!!!
EPOCH 268/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007847575470391433		[learning rate: 0.00035345]
	Learning Rate: 0.000353454
	LOSS [training: -0.007847575470391433 | validation: -0.01662605495422152]
	TIME [epoch: 41.1 sec]
EPOCH 269/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010704960368444745		[learning rate: 0.00034807]
	Learning Rate: 0.00034807
	LOSS [training: -0.010704960368444745 | validation: -0.009842743563569942]
	TIME [epoch: 41.1 sec]
EPOCH 270/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007996380550246112		[learning rate: 0.00034277]
	Learning Rate: 0.000342768
	LOSS [training: -0.007996380550246112 | validation: -0.017225443673894218]
	TIME [epoch: 41 sec]
EPOCH 271/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012557386863845285		[learning rate: 0.00033755]
	Learning Rate: 0.000337546
	LOSS [training: -0.012557386863845285 | validation: -0.0022736877387955923]
	TIME [epoch: 41 sec]
EPOCH 272/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009395908501588725		[learning rate: 0.0003324]
	Learning Rate: 0.000332404
	LOSS [training: -0.009395908501588725 | validation: -0.02425627398639121]
	TIME [epoch: 41.2 sec]
EPOCH 273/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01011532901031584		[learning rate: 0.00032734]
	Learning Rate: 0.000327341
	LOSS [training: -0.01011532901031584 | validation: -0.015061383932260988]
	TIME [epoch: 41.3 sec]
EPOCH 274/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005080525617040811		[learning rate: 0.00032235]
	Learning Rate: 0.000322354
	LOSS [training: -0.005080525617040811 | validation: -0.016788763870304018]
	TIME [epoch: 41.3 sec]
EPOCH 275/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00971024044768494		[learning rate: 0.00031744]
	Learning Rate: 0.000317444
	LOSS [training: -0.00971024044768494 | validation: -0.014112404994586393]
	TIME [epoch: 41.2 sec]
EPOCH 276/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011300701831447418		[learning rate: 0.00031261]
	Learning Rate: 0.000312608
	LOSS [training: -0.011300701831447418 | validation: -0.015433784982796947]
	TIME [epoch: 41.1 sec]
EPOCH 277/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009439623323682953		[learning rate: 0.00030785]
	Learning Rate: 0.000307846
	LOSS [training: -0.009439623323682953 | validation: -0.01677311384228387]
	TIME [epoch: 41.1 sec]
EPOCH 278/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012501224493780863		[learning rate: 0.00030316]
	Learning Rate: 0.000303156
	LOSS [training: -0.012501224493780863 | validation: -0.017877313803024292]
	TIME [epoch: 41.1 sec]
EPOCH 279/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008997112363892345		[learning rate: 0.00029854]
	Learning Rate: 0.000298538
	LOSS [training: -0.008997112363892345 | validation: -0.011945966626594445]
	TIME [epoch: 41 sec]
EPOCH 280/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009661838205277138		[learning rate: 0.00029399]
	Learning Rate: 0.000293991
	LOSS [training: -0.009661838205277138 | validation: -0.017506743767802223]
	TIME [epoch: 41.1 sec]
EPOCH 281/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010745631319479856		[learning rate: 0.00028951]
	Learning Rate: 0.000289512
	LOSS [training: -0.010745631319479856 | validation: -0.016974001711499712]
	TIME [epoch: 41.1 sec]
EPOCH 282/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009412100300151688		[learning rate: 0.0002851]
	Learning Rate: 0.000285102
	LOSS [training: -0.009412100300151688 | validation: -0.015886169149705785]
	TIME [epoch: 41 sec]
EPOCH 283/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010747562701259608		[learning rate: 0.00028076]
	Learning Rate: 0.000280759
	LOSS [training: -0.010747562701259608 | validation: -0.012799420032966866]
	TIME [epoch: 41.1 sec]
EPOCH 284/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012007495281841432		[learning rate: 0.00027648]
	Learning Rate: 0.000276482
	LOSS [training: -0.012007495281841432 | validation: -0.0201496447635085]
	TIME [epoch: 41.1 sec]
EPOCH 285/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011075190975718734		[learning rate: 0.00027227]
	Learning Rate: 0.00027227
	LOSS [training: -0.011075190975718734 | validation: -0.011716354233434853]
	TIME [epoch: 41.1 sec]
EPOCH 286/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010662078651951581		[learning rate: 0.00026812]
	Learning Rate: 0.000268123
	LOSS [training: -0.010662078651951581 | validation: -0.018250900467746155]
	TIME [epoch: 41.1 sec]
EPOCH 287/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01028930619790143		[learning rate: 0.00026404]
	Learning Rate: 0.000264038
	LOSS [training: -0.01028930619790143 | validation: -0.014813597786823864]
	TIME [epoch: 41.2 sec]
EPOCH 288/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009589210547059402		[learning rate: 0.00026002]
	Learning Rate: 0.000260016
	LOSS [training: -0.009589210547059402 | validation: -0.018997140487424385]
	TIME [epoch: 41.2 sec]
EPOCH 289/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011816030354241813		[learning rate: 0.00025606]
	Learning Rate: 0.000256055
	LOSS [training: -0.011816030354241813 | validation: -0.010222791796917746]
	TIME [epoch: 41.2 sec]
EPOCH 290/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013612792632612912		[learning rate: 0.00025215]
	Learning Rate: 0.000252154
	LOSS [training: -0.013612792632612912 | validation: -0.01757581046927977]
	TIME [epoch: 41.2 sec]
EPOCH 291/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008176808714502014		[learning rate: 0.00024831]
	Learning Rate: 0.000248313
	LOSS [training: -0.008176808714502014 | validation: -0.016556527364842165]
	TIME [epoch: 41.1 sec]
EPOCH 292/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008282594868928093		[learning rate: 0.00024453]
	Learning Rate: 0.000244531
	LOSS [training: -0.008282594868928093 | validation: -0.018024556268714385]
	TIME [epoch: 41.2 sec]
EPOCH 293/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010536249700843197		[learning rate: 0.00024081]
	Learning Rate: 0.000240806
	LOSS [training: -0.010536249700843197 | validation: -0.018738579894700562]
	TIME [epoch: 41.2 sec]
EPOCH 294/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009833104772359285		[learning rate: 0.00023714]
	Learning Rate: 0.000237137
	LOSS [training: -0.009833104772359285 | validation: -0.013375365205853171]
	TIME [epoch: 41.2 sec]
EPOCH 295/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006967191060654735		[learning rate: 0.00023352]
	Learning Rate: 0.000233525
	LOSS [training: -0.006967191060654735 | validation: -0.012218766591543417]
	TIME [epoch: 41.1 sec]
EPOCH 296/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006336282471806547		[learning rate: 0.00022997]
	Learning Rate: 0.000229968
	LOSS [training: -0.006336282471806547 | validation: -0.01993058149851449]
	TIME [epoch: 41 sec]
EPOCH 297/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012258334631362984		[learning rate: 0.00022646]
	Learning Rate: 0.000226464
	LOSS [training: -0.012258334631362984 | validation: -0.01721964481923596]
	TIME [epoch: 41.2 sec]
EPOCH 298/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014924527813188305		[learning rate: 0.00022301]
	Learning Rate: 0.000223015
	LOSS [training: -0.014924527813188305 | validation: -0.013457977789238955]
	TIME [epoch: 41.1 sec]
EPOCH 299/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013676073664249527		[learning rate: 0.00021962]
	Learning Rate: 0.000219617
	LOSS [training: -0.013676073664249527 | validation: -0.01785304329990918]
	TIME [epoch: 41.1 sec]
EPOCH 300/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01472414366955032		[learning rate: 0.00021627]
	Learning Rate: 0.000216272
	LOSS [training: -0.01472414366955032 | validation: -0.02279763927435191]
	TIME [epoch: 41.2 sec]
EPOCH 301/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011322360571052889		[learning rate: 0.00021298]
	Learning Rate: 0.000212977
	LOSS [training: -0.011322360571052889 | validation: -0.023756827457659856]
	TIME [epoch: 41 sec]
EPOCH 302/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013737976764522973		[learning rate: 0.00020973]
	Learning Rate: 0.000209733
	LOSS [training: -0.013737976764522973 | validation: -0.023056816579569823]
	TIME [epoch: 41 sec]
EPOCH 303/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00558809293357293		[learning rate: 0.00020654]
	Learning Rate: 0.000206538
	LOSS [training: -0.00558809293357293 | validation: -0.02214394610386128]
	TIME [epoch: 41 sec]
EPOCH 304/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011423274212753638		[learning rate: 0.00020339]
	Learning Rate: 0.000203392
	LOSS [training: -0.011423274212753638 | validation: -0.01944379451872537]
	TIME [epoch: 41 sec]
EPOCH 305/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010937551974348366		[learning rate: 0.00020029]
	Learning Rate: 0.000200293
	LOSS [training: -0.010937551974348366 | validation: -0.019848503431872225]
	TIME [epoch: 41 sec]
EPOCH 306/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011335485132376463		[learning rate: 0.00019724]
	Learning Rate: 0.000197242
	LOSS [training: -0.011335485132376463 | validation: -0.01577514197622355]
	TIME [epoch: 41 sec]
EPOCH 307/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009015186343964077		[learning rate: 0.00019424]
	Learning Rate: 0.000194238
	LOSS [training: -0.009015186343964077 | validation: -0.01110142489841998]
	TIME [epoch: 41 sec]
EPOCH 308/500:
	Training over batches...
		[batch 4/4] avg loss: -0.015844129039493216		[learning rate: 0.00019128]
	Learning Rate: 0.000191279
	LOSS [training: -0.015844129039493216 | validation: -0.0023255647513148953]
	TIME [epoch: 41 sec]
EPOCH 309/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010437207155980874		[learning rate: 0.00018836]
	Learning Rate: 0.000188365
	LOSS [training: -0.010437207155980874 | validation: -0.01981894830280192]
	TIME [epoch: 41 sec]
EPOCH 310/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008185768277160959		[learning rate: 0.0001855]
	Learning Rate: 0.000185495
	LOSS [training: -0.008185768277160959 | validation: -0.016837692400125788]
	TIME [epoch: 41 sec]
EPOCH 311/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012986465706270073		[learning rate: 0.00018267]
	Learning Rate: 0.00018267
	LOSS [training: -0.012986465706270073 | validation: -0.026693994940547194]
	TIME [epoch: 41 sec]
EPOCH 312/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01066742381058287		[learning rate: 0.00017989]
	Learning Rate: 0.000179887
	LOSS [training: -0.01066742381058287 | validation: -0.013877687200308152]
	TIME [epoch: 41 sec]
EPOCH 313/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011089459424521577		[learning rate: 0.00017715]
	Learning Rate: 0.000177147
	LOSS [training: -0.011089459424521577 | validation: -0.016671151764739732]
	TIME [epoch: 41 sec]
EPOCH 314/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005610374150808149		[learning rate: 0.00017445]
	Learning Rate: 0.000174448
	LOSS [training: -0.005610374150808149 | validation: -0.01743167342567404]
	TIME [epoch: 41 sec]
EPOCH 315/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01488961232212041		[learning rate: 0.00017179]
	Learning Rate: 0.000171791
	LOSS [training: -0.01488961232212041 | validation: -0.012746767243617375]
	TIME [epoch: 41 sec]
EPOCH 316/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010977761853205027		[learning rate: 0.00016917]
	Learning Rate: 0.000169174
	LOSS [training: -0.010977761853205027 | validation: -0.014711002220658947]
	TIME [epoch: 41 sec]
EPOCH 317/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010761775799527196		[learning rate: 0.0001666]
	Learning Rate: 0.000166597
	LOSS [training: -0.010761775799527196 | validation: -0.02583427034292376]
	TIME [epoch: 41 sec]
EPOCH 318/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010288721406187624		[learning rate: 0.00016406]
	Learning Rate: 0.000164059
	LOSS [training: -0.010288721406187624 | validation: -0.02762260650556303]
	TIME [epoch: 41 sec]
EPOCH 319/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01124395867191091		[learning rate: 0.00016156]
	Learning Rate: 0.00016156
	LOSS [training: -0.01124395867191091 | validation: -0.019566997020468387]
	TIME [epoch: 41 sec]
EPOCH 320/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011891626789242379		[learning rate: 0.0001591]
	Learning Rate: 0.000159099
	LOSS [training: -0.011891626789242379 | validation: -0.014725560998935617]
	TIME [epoch: 41 sec]
EPOCH 321/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009332288710315748		[learning rate: 0.00015668]
	Learning Rate: 0.000156675
	LOSS [training: -0.009332288710315748 | validation: -0.02158084078162241]
	TIME [epoch: 41 sec]
EPOCH 322/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011166545692366225		[learning rate: 0.00015429]
	Learning Rate: 0.000154288
	LOSS [training: -0.011166545692366225 | validation: -0.01765393686935016]
	TIME [epoch: 41 sec]
EPOCH 323/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014864397316087807		[learning rate: 0.00015194]
	Learning Rate: 0.000151938
	LOSS [training: -0.014864397316087807 | validation: -0.01108484998918675]
	TIME [epoch: 41 sec]
EPOCH 324/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007288044879905182		[learning rate: 0.00014962]
	Learning Rate: 0.000149624
	LOSS [training: -0.007288044879905182 | validation: -0.02388757113453504]
	TIME [epoch: 41 sec]
EPOCH 325/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00840471003438363		[learning rate: 0.00014734]
	Learning Rate: 0.000147344
	LOSS [training: -0.00840471003438363 | validation: -0.01947731551769594]
	TIME [epoch: 41 sec]
EPOCH 326/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009895388437014086		[learning rate: 0.0001451]
	Learning Rate: 0.0001451
	LOSS [training: -0.009895388437014086 | validation: -0.009827199509817896]
	TIME [epoch: 41 sec]
EPOCH 327/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01282709163516528		[learning rate: 0.00014289]
	Learning Rate: 0.000142889
	LOSS [training: -0.01282709163516528 | validation: -0.01688764242196543]
	TIME [epoch: 41 sec]
EPOCH 328/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006636313375518043		[learning rate: 0.00014071]
	Learning Rate: 0.000140713
	LOSS [training: -0.006636313375518043 | validation: -0.01267957191877538]
	TIME [epoch: 41 sec]
EPOCH 329/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00948557139909999		[learning rate: 0.00013857]
	Learning Rate: 0.000138569
	LOSS [training: -0.00948557139909999 | validation: -0.009182069541471483]
	TIME [epoch: 41 sec]
EPOCH 330/500:
	Training over batches...
		[batch 4/4] avg loss: -0.015179004474015231		[learning rate: 0.00013646]
	Learning Rate: 0.000136458
	LOSS [training: -0.015179004474015231 | validation: -0.017115318351523575]
	TIME [epoch: 41.1 sec]
EPOCH 331/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012246341855291835		[learning rate: 0.00013438]
	Learning Rate: 0.00013438
	LOSS [training: -0.012246341855291835 | validation: -0.014610122452940227]
	TIME [epoch: 41 sec]
EPOCH 332/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007479974058609737		[learning rate: 0.00013233]
	Learning Rate: 0.000132333
	LOSS [training: -0.007479974058609737 | validation: -0.025725489088047254]
	TIME [epoch: 41 sec]
EPOCH 333/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010314476805365996		[learning rate: 0.00013032]
	Learning Rate: 0.000130317
	LOSS [training: -0.010314476805365996 | validation: -0.02117345883892034]
	TIME [epoch: 41 sec]
EPOCH 334/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014804816309978472		[learning rate: 0.00012833]
	Learning Rate: 0.000128332
	LOSS [training: -0.014804816309978472 | validation: -0.024532346641330985]
	TIME [epoch: 41.1 sec]
EPOCH 335/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010290398612063986		[learning rate: 0.00012638]
	Learning Rate: 0.000126377
	LOSS [training: -0.010290398612063986 | validation: -0.01756488669322364]
	TIME [epoch: 41 sec]
EPOCH 336/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01173000148074334		[learning rate: 0.00012445]
	Learning Rate: 0.000124451
	LOSS [training: -0.01173000148074334 | validation: -0.01924890725535318]
	TIME [epoch: 41 sec]
EPOCH 337/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009223830335181111		[learning rate: 0.00012256]
	Learning Rate: 0.000122556
	LOSS [training: -0.009223830335181111 | validation: -0.011066358200727417]
	TIME [epoch: 41 sec]
EPOCH 338/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011182853814975337		[learning rate: 0.00012069]
	Learning Rate: 0.000120689
	LOSS [training: -0.011182853814975337 | validation: -0.015019720369550987]
	TIME [epoch: 41 sec]
EPOCH 339/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0106412902265636		[learning rate: 0.00011885]
	Learning Rate: 0.00011885
	LOSS [training: -0.0106412902265636 | validation: -0.013022275619877776]
	TIME [epoch: 41 sec]
EPOCH 340/500:
	Training over batches...
		[batch 4/4] avg loss: -0.016161775032310127		[learning rate: 0.00011704]
	Learning Rate: 0.00011704
	LOSS [training: -0.016161775032310127 | validation: -0.028094156362833272]
	TIME [epoch: 41 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_340.pth
	Model improved!!!
EPOCH 341/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01609174720165369		[learning rate: 0.00011526]
	Learning Rate: 0.000115257
	LOSS [training: -0.01609174720165369 | validation: -0.02074676440109101]
	TIME [epoch: 41 sec]
EPOCH 342/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009006094000706765		[learning rate: 0.0001135]
	Learning Rate: 0.000113501
	LOSS [training: -0.009006094000706765 | validation: -0.013836014103033794]
	TIME [epoch: 41 sec]
EPOCH 343/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010468274214952923		[learning rate: 0.00011177]
	Learning Rate: 0.000111772
	LOSS [training: -0.010468274214952923 | validation: -0.018413199140871684]
	TIME [epoch: 41 sec]
EPOCH 344/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010330421266826068		[learning rate: 0.00011007]
	Learning Rate: 0.000110069
	LOSS [training: -0.010330421266826068 | validation: -0.02374991239457847]
	TIME [epoch: 41 sec]
EPOCH 345/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010354190382967275		[learning rate: 0.00010839]
	Learning Rate: 0.000108393
	LOSS [training: -0.010354190382967275 | validation: -0.019091347246224334]
	TIME [epoch: 41 sec]
EPOCH 346/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011991681573774591		[learning rate: 0.00010674]
	Learning Rate: 0.000106742
	LOSS [training: -0.011991681573774591 | validation: -0.01738452106919094]
	TIME [epoch: 41 sec]
EPOCH 347/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013700116198102236		[learning rate: 0.00010512]
	Learning Rate: 0.000105115
	LOSS [training: -0.013700116198102236 | validation: -0.012435125286518385]
	TIME [epoch: 41 sec]
EPOCH 348/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010332360006482619		[learning rate: 0.00010351]
	Learning Rate: 0.000103514
	LOSS [training: -0.010332360006482619 | validation: -0.020696008326769724]
	TIME [epoch: 41.1 sec]
EPOCH 349/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009810601366074131		[learning rate: 0.00010194]
	Learning Rate: 0.000101937
	LOSS [training: -0.009810601366074131 | validation: -0.012067100101928418]
	TIME [epoch: 41 sec]
EPOCH 350/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011517938080895207		[learning rate: 0.00010038]
	Learning Rate: 0.000100385
	LOSS [training: -0.011517938080895207 | validation: -0.021691521957536986]
	TIME [epoch: 41 sec]
EPOCH 351/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009335186856450342		[learning rate: 9.8855e-05]
	Learning Rate: 9.88553e-05
	LOSS [training: -0.009335186856450342 | validation: -0.010395203624687604]
	TIME [epoch: 41 sec]
EPOCH 352/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013638320320620454		[learning rate: 9.7349e-05]
	Learning Rate: 9.73494e-05
	LOSS [training: -0.013638320320620454 | validation: -0.016529898596539697]
	TIME [epoch: 41.1 sec]
EPOCH 353/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009149432214401707		[learning rate: 9.5866e-05]
	Learning Rate: 9.58665e-05
	LOSS [training: -0.009149432214401707 | validation: -0.01776798594128517]
	TIME [epoch: 41 sec]
EPOCH 354/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011921203789585734		[learning rate: 9.4406e-05]
	Learning Rate: 9.44061e-05
	LOSS [training: -0.011921203789585734 | validation: -0.016533985417578438]
	TIME [epoch: 41 sec]
EPOCH 355/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010977190030204911		[learning rate: 9.2968e-05]
	Learning Rate: 9.2968e-05
	LOSS [training: -0.010977190030204911 | validation: -0.012311563329938902]
	TIME [epoch: 41 sec]
EPOCH 356/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012034317692197781		[learning rate: 9.1552e-05]
	Learning Rate: 9.15518e-05
	LOSS [training: -0.012034317692197781 | validation: -0.01043142869577168]
	TIME [epoch: 41 sec]
EPOCH 357/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012132221725334746		[learning rate: 9.0157e-05]
	Learning Rate: 9.01571e-05
	LOSS [training: -0.012132221725334746 | validation: -0.02309288083333745]
	TIME [epoch: 40.9 sec]
EPOCH 358/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011323012045559853		[learning rate: 8.8784e-05]
	Learning Rate: 8.87837e-05
	LOSS [training: -0.011323012045559853 | validation: -0.007954738716792987]
	TIME [epoch: 40.9 sec]
EPOCH 359/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010734891015604597		[learning rate: 8.7431e-05]
	Learning Rate: 8.74312e-05
	LOSS [training: -0.010734891015604597 | validation: -0.01978339712817428]
	TIME [epoch: 41 sec]
EPOCH 360/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012160849419696558		[learning rate: 8.6099e-05]
	Learning Rate: 8.60994e-05
	LOSS [training: -0.012160849419696558 | validation: -0.021554231519060944]
	TIME [epoch: 41 sec]
EPOCH 361/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0121871551092948		[learning rate: 8.4788e-05]
	Learning Rate: 8.47878e-05
	LOSS [training: -0.0121871551092948 | validation: -0.021391763678563883]
	TIME [epoch: 41 sec]
EPOCH 362/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012447118935020826		[learning rate: 8.3496e-05]
	Learning Rate: 8.34962e-05
	LOSS [training: -0.012447118935020826 | validation: -0.011442362933687595]
	TIME [epoch: 41 sec]
EPOCH 363/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01020093035525146		[learning rate: 8.2224e-05]
	Learning Rate: 8.22243e-05
	LOSS [training: -0.01020093035525146 | validation: -0.01340550509675479]
	TIME [epoch: 41 sec]
EPOCH 364/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011663938790822323		[learning rate: 8.0972e-05]
	Learning Rate: 8.09717e-05
	LOSS [training: -0.011663938790822323 | validation: -0.014141583687617244]
	TIME [epoch: 41 sec]
EPOCH 365/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012121154272144627		[learning rate: 7.9738e-05]
	Learning Rate: 7.97382e-05
	LOSS [training: -0.012121154272144627 | validation: -0.01842538942846713]
	TIME [epoch: 41 sec]
EPOCH 366/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011314693477130806		[learning rate: 7.8524e-05]
	Learning Rate: 7.85235e-05
	LOSS [training: -0.011314693477130806 | validation: -0.014412501251760116]
	TIME [epoch: 41 sec]
EPOCH 367/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00974742189916811		[learning rate: 7.7327e-05]
	Learning Rate: 7.73274e-05
	LOSS [training: -0.00974742189916811 | validation: -0.023875042231167303]
	TIME [epoch: 41 sec]
EPOCH 368/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009302994553837962		[learning rate: 7.6149e-05]
	Learning Rate: 7.61494e-05
	LOSS [training: -0.009302994553837962 | validation: -0.02410180757968431]
	TIME [epoch: 41 sec]
EPOCH 369/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00955005324460026		[learning rate: 7.4989e-05]
	Learning Rate: 7.49894e-05
	LOSS [training: -0.00955005324460026 | validation: -0.024927607993744702]
	TIME [epoch: 40.9 sec]
EPOCH 370/500:
	Training over batches...
		[batch 4/4] avg loss: -0.016075188590933036		[learning rate: 7.3847e-05]
	Learning Rate: 7.38471e-05
	LOSS [training: -0.016075188590933036 | validation: -0.018033266213689086]
	TIME [epoch: 41 sec]
EPOCH 371/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013012017459004646		[learning rate: 7.2722e-05]
	Learning Rate: 7.27221e-05
	LOSS [training: -0.013012017459004646 | validation: -0.010917474351914664]
	TIME [epoch: 41 sec]
EPOCH 372/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010997931430137681		[learning rate: 7.1614e-05]
	Learning Rate: 7.16143e-05
	LOSS [training: -0.010997931430137681 | validation: -0.009780464758012237]
	TIME [epoch: 41 sec]
EPOCH 373/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014405110324882607		[learning rate: 7.0523e-05]
	Learning Rate: 7.05234e-05
	LOSS [training: -0.014405110324882607 | validation: -0.013174892750873034]
	TIME [epoch: 41 sec]
EPOCH 374/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014097957823950305		[learning rate: 6.9449e-05]
	Learning Rate: 6.94491e-05
	LOSS [training: -0.014097957823950305 | validation: -0.023199112520517286]
	TIME [epoch: 41 sec]
EPOCH 375/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010562182903199515		[learning rate: 6.8391e-05]
	Learning Rate: 6.83912e-05
	LOSS [training: -0.010562182903199515 | validation: -0.01748298239381918]
	TIME [epoch: 41 sec]
EPOCH 376/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012201395792909254		[learning rate: 6.7349e-05]
	Learning Rate: 6.73493e-05
	LOSS [training: -0.012201395792909254 | validation: -0.012814758847269112]
	TIME [epoch: 41 sec]
EPOCH 377/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01043542012653856		[learning rate: 6.6323e-05]
	Learning Rate: 6.63234e-05
	LOSS [training: -0.01043542012653856 | validation: -0.021368211488689545]
	TIME [epoch: 41 sec]
EPOCH 378/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01306682231157152		[learning rate: 6.5313e-05]
	Learning Rate: 6.5313e-05
	LOSS [training: -0.01306682231157152 | validation: -0.02031435260561866]
	TIME [epoch: 41 sec]
EPOCH 379/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013240851410977843		[learning rate: 6.4318e-05]
	Learning Rate: 6.43181e-05
	LOSS [training: -0.013240851410977843 | validation: -0.01494146372333562]
	TIME [epoch: 41.2 sec]
EPOCH 380/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01230911955441472		[learning rate: 6.3338e-05]
	Learning Rate: 6.33383e-05
	LOSS [training: -0.01230911955441472 | validation: -0.0195871255149472]
	TIME [epoch: 41.1 sec]
EPOCH 381/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010687361618457222		[learning rate: 6.2373e-05]
	Learning Rate: 6.23735e-05
	LOSS [training: -0.010687361618457222 | validation: -0.029110923768596655]
	TIME [epoch: 41.1 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_381.pth
	Model improved!!!
EPOCH 382/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01258711365458327		[learning rate: 6.1423e-05]
	Learning Rate: 6.14233e-05
	LOSS [training: -0.01258711365458327 | validation: -0.02565271636517167]
	TIME [epoch: 41 sec]
EPOCH 383/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013147625068785772		[learning rate: 6.0488e-05]
	Learning Rate: 6.04876e-05
	LOSS [training: -0.013147625068785772 | validation: -0.030688630089552735]
	TIME [epoch: 41 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_383.pth
	Model improved!!!
EPOCH 384/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011755364016919331		[learning rate: 5.9566e-05]
	Learning Rate: 5.95662e-05
	LOSS [training: -0.011755364016919331 | validation: -0.01998822926800946]
	TIME [epoch: 41 sec]
EPOCH 385/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011516693494091552		[learning rate: 5.8659e-05]
	Learning Rate: 5.86588e-05
	LOSS [training: -0.011516693494091552 | validation: -0.014049455792750775]
	TIME [epoch: 40.9 sec]
EPOCH 386/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012608740470852425		[learning rate: 5.7765e-05]
	Learning Rate: 5.77652e-05
	LOSS [training: -0.012608740470852425 | validation: -0.021844030020543026]
	TIME [epoch: 41 sec]
EPOCH 387/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011811740170272133		[learning rate: 5.6885e-05]
	Learning Rate: 5.68853e-05
	LOSS [training: -0.011811740170272133 | validation: -0.017613897125684563]
	TIME [epoch: 40.9 sec]
EPOCH 388/500:
	Training over batches...
		[batch 4/4] avg loss: -0.016192843292262733		[learning rate: 5.6019e-05]
	Learning Rate: 5.60187e-05
	LOSS [training: -0.016192843292262733 | validation: -0.020774246189023356]
	TIME [epoch: 41 sec]
EPOCH 389/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012321903638036789		[learning rate: 5.5165e-05]
	Learning Rate: 5.51654e-05
	LOSS [training: -0.012321903638036789 | validation: -0.01660400649863895]
	TIME [epoch: 41 sec]
EPOCH 390/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012263105159713308		[learning rate: 5.4325e-05]
	Learning Rate: 5.4325e-05
	LOSS [training: -0.012263105159713308 | validation: -0.016972334778309412]
	TIME [epoch: 41 sec]
EPOCH 391/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00955075510799086		[learning rate: 5.3497e-05]
	Learning Rate: 5.34975e-05
	LOSS [training: -0.00955075510799086 | validation: -0.015939767763243108]
	TIME [epoch: 41 sec]
EPOCH 392/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012562392196790317		[learning rate: 5.2683e-05]
	Learning Rate: 5.26825e-05
	LOSS [training: -0.012562392196790317 | validation: -0.015146536524403282]
	TIME [epoch: 41 sec]
EPOCH 393/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010716651217571904		[learning rate: 5.188e-05]
	Learning Rate: 5.188e-05
	LOSS [training: -0.010716651217571904 | validation: -0.01403025125816093]
	TIME [epoch: 41 sec]
EPOCH 394/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014377844373323737		[learning rate: 5.109e-05]
	Learning Rate: 5.10897e-05
	LOSS [training: -0.014377844373323737 | validation: -0.015518538546934132]
	TIME [epoch: 41 sec]
EPOCH 395/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014338043246567579		[learning rate: 5.0311e-05]
	Learning Rate: 5.03114e-05
	LOSS [training: -0.014338043246567579 | validation: -0.023049661100173695]
	TIME [epoch: 41 sec]
EPOCH 396/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012129968459768664		[learning rate: 4.9545e-05]
	Learning Rate: 4.9545e-05
	LOSS [training: -0.012129968459768664 | validation: -0.02109388463583037]
	TIME [epoch: 41 sec]
EPOCH 397/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01467288491041007		[learning rate: 4.879e-05]
	Learning Rate: 4.87903e-05
	LOSS [training: -0.01467288491041007 | validation: -0.017037382901193925]
	TIME [epoch: 41 sec]
EPOCH 398/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012464731807494602		[learning rate: 4.8047e-05]
	Learning Rate: 4.8047e-05
	LOSS [training: -0.012464731807494602 | validation: -0.01824723893181636]
	TIME [epoch: 41 sec]
EPOCH 399/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011054618325483151		[learning rate: 4.7315e-05]
	Learning Rate: 4.73151e-05
	LOSS [training: -0.011054618325483151 | validation: -0.023947090953063892]
	TIME [epoch: 40.9 sec]
EPOCH 400/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013494761378502198		[learning rate: 4.6594e-05]
	Learning Rate: 4.65944e-05
	LOSS [training: -0.013494761378502198 | validation: -0.013055054395233426]
	TIME [epoch: 40.9 sec]
EPOCH 401/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010679755638840072		[learning rate: 4.5885e-05]
	Learning Rate: 4.58846e-05
	LOSS [training: -0.010679755638840072 | validation: -0.021072370804098246]
	TIME [epoch: 41 sec]
EPOCH 402/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00931414823542233		[learning rate: 4.5186e-05]
	Learning Rate: 4.51856e-05
	LOSS [training: -0.00931414823542233 | validation: -0.021325120295892522]
	TIME [epoch: 41 sec]
EPOCH 403/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012296310971527207		[learning rate: 4.4497e-05]
	Learning Rate: 4.44973e-05
	LOSS [training: -0.012296310971527207 | validation: -0.015407507690853672]
	TIME [epoch: 41 sec]
EPOCH 404/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014122903993765415		[learning rate: 4.3819e-05]
	Learning Rate: 4.38194e-05
	LOSS [training: -0.014122903993765415 | validation: -0.025827544363290454]
	TIME [epoch: 41 sec]
EPOCH 405/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012601341139491712		[learning rate: 4.3152e-05]
	Learning Rate: 4.31519e-05
	LOSS [training: -0.012601341139491712 | validation: -0.015294194595227116]
	TIME [epoch: 41 sec]
EPOCH 406/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013388799728150848		[learning rate: 4.2495e-05]
	Learning Rate: 4.24946e-05
	LOSS [training: -0.013388799728150848 | validation: -0.011778210129937527]
	TIME [epoch: 41 sec]
EPOCH 407/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010373983666355		[learning rate: 4.1847e-05]
	Learning Rate: 4.18472e-05
	LOSS [training: -0.010373983666355 | validation: -0.01367803072166656]
	TIME [epoch: 41 sec]
EPOCH 408/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0117972785202134		[learning rate: 4.121e-05]
	Learning Rate: 4.12098e-05
	LOSS [training: -0.0117972785202134 | validation: -0.014250702580054403]
	TIME [epoch: 41 sec]
EPOCH 409/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009611091617002068		[learning rate: 4.0582e-05]
	Learning Rate: 4.0582e-05
	LOSS [training: -0.009611091617002068 | validation: -0.018119671406642404]
	TIME [epoch: 41 sec]
EPOCH 410/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008729179775184106		[learning rate: 3.9964e-05]
	Learning Rate: 3.99638e-05
	LOSS [training: -0.008729179775184106 | validation: -0.016724513948966242]
	TIME [epoch: 40.9 sec]
EPOCH 411/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013348869583175408		[learning rate: 3.9355e-05]
	Learning Rate: 3.9355e-05
	LOSS [training: -0.013348869583175408 | validation: -0.01357152505934684]
	TIME [epoch: 40.9 sec]
EPOCH 412/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012270924479768488		[learning rate: 3.8755e-05]
	Learning Rate: 3.87555e-05
	LOSS [training: -0.012270924479768488 | validation: -0.019839577658847696]
	TIME [epoch: 41 sec]
EPOCH 413/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013010898106215089		[learning rate: 3.8165e-05]
	Learning Rate: 3.81651e-05
	LOSS [training: -0.013010898106215089 | validation: -0.010132707300802745]
	TIME [epoch: 41 sec]
EPOCH 414/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010245465415769353		[learning rate: 3.7584e-05]
	Learning Rate: 3.75837e-05
	LOSS [training: -0.010245465415769353 | validation: -0.023112377566348596]
	TIME [epoch: 40.9 sec]
EPOCH 415/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01286193920284244		[learning rate: 3.7011e-05]
	Learning Rate: 3.70112e-05
	LOSS [training: -0.01286193920284244 | validation: -0.03143084152086882]
	TIME [epoch: 44.9 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20240705_015512/states/model_algphi2_1a_v_klv2_415.pth
	Model improved!!!
EPOCH 416/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011801483236404111		[learning rate: 3.6447e-05]
	Learning Rate: 3.64474e-05
	LOSS [training: -0.011801483236404111 | validation: -0.015547633950531981]
	TIME [epoch: 41 sec]
EPOCH 417/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013259020822892988		[learning rate: 3.5892e-05]
	Learning Rate: 3.58922e-05
	LOSS [training: -0.013259020822892988 | validation: -0.02060000531648907]
	TIME [epoch: 41 sec]
EPOCH 418/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010280989132419184		[learning rate: 3.5345e-05]
	Learning Rate: 3.53454e-05
	LOSS [training: -0.010280989132419184 | validation: -0.023177798650886254]
	TIME [epoch: 41 sec]
EPOCH 419/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013934231058524166		[learning rate: 3.4807e-05]
	Learning Rate: 3.4807e-05
	LOSS [training: -0.013934231058524166 | validation: -0.021486506388442107]
	TIME [epoch: 41 sec]
EPOCH 420/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013285715463845521		[learning rate: 3.4277e-05]
	Learning Rate: 3.42768e-05
	LOSS [training: -0.013285715463845521 | validation: -0.01613862013621132]
	TIME [epoch: 41 sec]
EPOCH 421/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014095203182090316		[learning rate: 3.3755e-05]
	Learning Rate: 3.37546e-05
	LOSS [training: -0.014095203182090316 | validation: -0.0246362955584797]
	TIME [epoch: 41 sec]
EPOCH 422/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014301256839484126		[learning rate: 3.324e-05]
	Learning Rate: 3.32404e-05
	LOSS [training: -0.014301256839484126 | validation: -0.021664446877433154]
	TIME [epoch: 41 sec]
EPOCH 423/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014429047282181652		[learning rate: 3.2734e-05]
	Learning Rate: 3.27341e-05
	LOSS [training: -0.014429047282181652 | validation: -0.022333792954322956]
	TIME [epoch: 41 sec]
EPOCH 424/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012571802278328222		[learning rate: 3.2235e-05]
	Learning Rate: 3.22354e-05
	LOSS [training: -0.012571802278328222 | validation: -0.010553324338891508]
	TIME [epoch: 41 sec]
EPOCH 425/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014021263718980308		[learning rate: 3.1744e-05]
	Learning Rate: 3.17444e-05
	LOSS [training: -0.014021263718980308 | validation: -0.008084765746885866]
	TIME [epoch: 41 sec]
EPOCH 426/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013168399522178728		[learning rate: 3.1261e-05]
	Learning Rate: 3.12608e-05
	LOSS [training: -0.013168399522178728 | validation: -0.016040691689955727]
	TIME [epoch: 41 sec]
EPOCH 427/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013655691669020264		[learning rate: 3.0785e-05]
	Learning Rate: 3.07846e-05
	LOSS [training: -0.013655691669020264 | validation: -0.01949768101693086]
	TIME [epoch: 41 sec]
EPOCH 428/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01290817315187683		[learning rate: 3.0316e-05]
	Learning Rate: 3.03156e-05
	LOSS [training: -0.01290817315187683 | validation: -0.02021485167303068]
	TIME [epoch: 40.9 sec]
EPOCH 429/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01410332111757682		[learning rate: 2.9854e-05]
	Learning Rate: 2.98538e-05
	LOSS [training: -0.01410332111757682 | validation: -0.01488842271207811]
	TIME [epoch: 40.9 sec]
EPOCH 430/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010929565510789987		[learning rate: 2.9399e-05]
	Learning Rate: 2.9399e-05
	LOSS [training: -0.010929565510789987 | validation: -0.021156633867686965]
	TIME [epoch: 40.9 sec]
EPOCH 431/500:
	Training over batches...
		[batch 4/4] avg loss: -0.015907227583655988		[learning rate: 2.8951e-05]
	Learning Rate: 2.89512e-05
	LOSS [training: -0.015907227583655988 | validation: -0.022059309235866922]
	TIME [epoch: 41 sec]
EPOCH 432/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010938252336797964		[learning rate: 2.851e-05]
	Learning Rate: 2.85102e-05
	LOSS [training: -0.010938252336797964 | validation: -0.016205326160336257]
	TIME [epoch: 41 sec]
EPOCH 433/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011510056129844699		[learning rate: 2.8076e-05]
	Learning Rate: 2.80759e-05
	LOSS [training: -0.011510056129844699 | validation: -0.010658172205500046]
	TIME [epoch: 40.9 sec]
EPOCH 434/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010662045648482435		[learning rate: 2.7648e-05]
	Learning Rate: 2.76482e-05
	LOSS [training: -0.010662045648482435 | validation: -0.015078090689202258]
	TIME [epoch: 40.9 sec]
EPOCH 435/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009954814200015842		[learning rate: 2.7227e-05]
	Learning Rate: 2.7227e-05
	LOSS [training: -0.009954814200015842 | validation: -0.014426257178999691]
	TIME [epoch: 41 sec]
EPOCH 436/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010261730061952237		[learning rate: 2.6812e-05]
	Learning Rate: 2.68122e-05
	LOSS [training: -0.010261730061952237 | validation: -0.018818169416011686]
	TIME [epoch: 41 sec]
EPOCH 437/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01461876054612581		[learning rate: 2.6404e-05]
	Learning Rate: 2.64038e-05
	LOSS [training: -0.01461876054612581 | validation: -0.014664505557902538]
	TIME [epoch: 41 sec]
EPOCH 438/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011960002173362603		[learning rate: 2.6002e-05]
	Learning Rate: 2.60016e-05
	LOSS [training: -0.011960002173362603 | validation: -0.015439949450773417]
	TIME [epoch: 41 sec]
EPOCH 439/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013976694816074005		[learning rate: 2.5605e-05]
	Learning Rate: 2.56055e-05
	LOSS [training: -0.013976694816074005 | validation: -0.015428703971674097]
	TIME [epoch: 41 sec]
EPOCH 440/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013321805176817077		[learning rate: 2.5215e-05]
	Learning Rate: 2.52154e-05
	LOSS [training: -0.013321805176817077 | validation: -0.019495151622855734]
	TIME [epoch: 41.1 sec]
EPOCH 441/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012746186637575319		[learning rate: 2.4831e-05]
	Learning Rate: 2.48313e-05
	LOSS [training: -0.012746186637575319 | validation: -0.020777289878623154]
	TIME [epoch: 41 sec]
EPOCH 442/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012362205175758305		[learning rate: 2.4453e-05]
	Learning Rate: 2.44531e-05
	LOSS [training: -0.012362205175758305 | validation: -0.020713764832609137]
	TIME [epoch: 41 sec]
EPOCH 443/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014223074932068104		[learning rate: 2.4081e-05]
	Learning Rate: 2.40806e-05
	LOSS [training: -0.014223074932068104 | validation: -0.015606496645627577]
	TIME [epoch: 41 sec]
EPOCH 444/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01213950417925628		[learning rate: 2.3714e-05]
	Learning Rate: 2.37137e-05
	LOSS [training: -0.01213950417925628 | validation: -0.02049302457682836]
	TIME [epoch: 41 sec]
EPOCH 445/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012218955693536766		[learning rate: 2.3352e-05]
	Learning Rate: 2.33525e-05
	LOSS [training: -0.012218955693536766 | validation: -0.01627919957156369]
	TIME [epoch: 40.9 sec]
EPOCH 446/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01183349473603125		[learning rate: 2.2997e-05]
	Learning Rate: 2.29968e-05
	LOSS [training: -0.01183349473603125 | validation: -0.023428037686366397]
	TIME [epoch: 41 sec]
EPOCH 447/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007954700948023759		[learning rate: 2.2646e-05]
	Learning Rate: 2.26464e-05
	LOSS [training: -0.007954700948023759 | validation: -0.011803301359472421]
	TIME [epoch: 41 sec]
EPOCH 448/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012207555839089492		[learning rate: 2.2301e-05]
	Learning Rate: 2.23015e-05
	LOSS [training: -0.012207555839089492 | validation: -0.016507673521519772]
	TIME [epoch: 41 sec]
EPOCH 449/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0134182065883404		[learning rate: 2.1962e-05]
	Learning Rate: 2.19617e-05
	LOSS [training: -0.0134182065883404 | validation: -0.02158690459977846]
	TIME [epoch: 40.9 sec]
EPOCH 450/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013052862650275662		[learning rate: 2.1627e-05]
	Learning Rate: 2.16272e-05
	LOSS [training: -0.013052862650275662 | validation: -0.019554364130190606]
	TIME [epoch: 41 sec]
EPOCH 451/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009499683808968084		[learning rate: 2.1298e-05]
	Learning Rate: 2.12977e-05
	LOSS [training: -0.009499683808968084 | validation: -0.01475967736859933]
	TIME [epoch: 41 sec]
EPOCH 452/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012438763260130183		[learning rate: 2.0973e-05]
	Learning Rate: 2.09733e-05
	LOSS [training: -0.012438763260130183 | validation: -0.023365532852671546]
	TIME [epoch: 41 sec]
EPOCH 453/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012900176887135725		[learning rate: 2.0654e-05]
	Learning Rate: 2.06538e-05
	LOSS [training: -0.012900176887135725 | validation: -0.0186117540731495]
	TIME [epoch: 41 sec]
EPOCH 454/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01453768975560194		[learning rate: 2.0339e-05]
	Learning Rate: 2.03392e-05
	LOSS [training: -0.01453768975560194 | validation: -0.01912952486271382]
	TIME [epoch: 41 sec]
EPOCH 455/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013397422669782118		[learning rate: 2.0029e-05]
	Learning Rate: 2.00293e-05
	LOSS [training: -0.013397422669782118 | validation: -0.02546111428252]
	TIME [epoch: 41 sec]
EPOCH 456/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008078035193556193		[learning rate: 1.9724e-05]
	Learning Rate: 1.97242e-05
	LOSS [training: -0.008078035193556193 | validation: -0.021438597094511413]
	TIME [epoch: 40.9 sec]
EPOCH 457/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01615281240797389		[learning rate: 1.9424e-05]
	Learning Rate: 1.94238e-05
	LOSS [training: -0.01615281240797389 | validation: -0.018364794372397387]
	TIME [epoch: 41 sec]
EPOCH 458/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013139703362267992		[learning rate: 1.9128e-05]
	Learning Rate: 1.91279e-05
	LOSS [training: -0.013139703362267992 | validation: -0.01608161351167816]
	TIME [epoch: 41 sec]
EPOCH 459/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010617202939304774		[learning rate: 1.8836e-05]
	Learning Rate: 1.88365e-05
	LOSS [training: -0.010617202939304774 | validation: -0.008681518651592826]
	TIME [epoch: 41 sec]
EPOCH 460/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010390811594566826		[learning rate: 1.855e-05]
	Learning Rate: 1.85495e-05
	LOSS [training: -0.010390811594566826 | validation: -0.01871343694458214]
	TIME [epoch: 40.9 sec]
EPOCH 461/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01161373432237502		[learning rate: 1.8267e-05]
	Learning Rate: 1.8267e-05
	LOSS [training: -0.01161373432237502 | validation: -0.029156231851171097]
	TIME [epoch: 41 sec]
EPOCH 462/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014285502067280628		[learning rate: 1.7989e-05]
	Learning Rate: 1.79887e-05
	LOSS [training: -0.014285502067280628 | validation: -0.015112969879150114]
	TIME [epoch: 41.1 sec]
EPOCH 463/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00859056011763792		[learning rate: 1.7715e-05]
	Learning Rate: 1.77147e-05
	LOSS [training: -0.00859056011763792 | validation: -0.018947207300752694]
	TIME [epoch: 41 sec]
EPOCH 464/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013065361845365477		[learning rate: 1.7445e-05]
	Learning Rate: 1.74448e-05
	LOSS [training: -0.013065361845365477 | validation: -0.02002086566512131]
	TIME [epoch: 41 sec]
EPOCH 465/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011451881519467938		[learning rate: 1.7179e-05]
	Learning Rate: 1.71791e-05
	LOSS [training: -0.011451881519467938 | validation: -0.01270496268928383]
	TIME [epoch: 41 sec]
EPOCH 466/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009824061851910846		[learning rate: 1.6917e-05]
	Learning Rate: 1.69174e-05
	LOSS [training: -0.009824061851910846 | validation: -0.024757953688510092]
	TIME [epoch: 41 sec]
EPOCH 467/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011389228682483179		[learning rate: 1.666e-05]
	Learning Rate: 1.66597e-05
	LOSS [training: -0.011389228682483179 | validation: -0.012077668933016136]
	TIME [epoch: 41.1 sec]
EPOCH 468/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014625658616077631		[learning rate: 1.6406e-05]
	Learning Rate: 1.64059e-05
	LOSS [training: -0.014625658616077631 | validation: -0.021206536121580292]
	TIME [epoch: 41 sec]
EPOCH 469/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01356324585721808		[learning rate: 1.6156e-05]
	Learning Rate: 1.6156e-05
	LOSS [training: -0.01356324585721808 | validation: -0.01446612552922751]
	TIME [epoch: 41 sec]
EPOCH 470/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01542353210065545		[learning rate: 1.591e-05]
	Learning Rate: 1.59099e-05
	LOSS [training: -0.01542353210065545 | validation: -0.023574737621575616]
	TIME [epoch: 41 sec]
EPOCH 471/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010752779077106105		[learning rate: 1.5668e-05]
	Learning Rate: 1.56675e-05
	LOSS [training: -0.010752779077106105 | validation: -0.014160879387814315]
	TIME [epoch: 41 sec]
EPOCH 472/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009626582310201484		[learning rate: 1.5429e-05]
	Learning Rate: 1.54288e-05
	LOSS [training: -0.009626582310201484 | validation: -0.015901783082339332]
	TIME [epoch: 41 sec]
EPOCH 473/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008723888848487828		[learning rate: 1.5194e-05]
	Learning Rate: 1.51938e-05
	LOSS [training: -0.008723888848487828 | validation: -0.01741143247976068]
	TIME [epoch: 41 sec]
EPOCH 474/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009163900107792299		[learning rate: 1.4962e-05]
	Learning Rate: 1.49624e-05
	LOSS [training: -0.009163900107792299 | validation: -0.02477119183413294]
	TIME [epoch: 41 sec]
EPOCH 475/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010704794051966903		[learning rate: 1.4734e-05]
	Learning Rate: 1.47344e-05
	LOSS [training: -0.010704794051966903 | validation: -0.019613290349934642]
	TIME [epoch: 41 sec]
EPOCH 476/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013114148666372737		[learning rate: 1.451e-05]
	Learning Rate: 1.451e-05
	LOSS [training: -0.013114148666372737 | validation: -0.015112098446240976]
	TIME [epoch: 40.9 sec]
EPOCH 477/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014562254984008156		[learning rate: 1.4289e-05]
	Learning Rate: 1.42889e-05
	LOSS [training: -0.014562254984008156 | validation: -0.012723811779889056]
	TIME [epoch: 40.9 sec]
EPOCH 478/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01268675845134716		[learning rate: 1.4071e-05]
	Learning Rate: 1.40713e-05
	LOSS [training: -0.01268675845134716 | validation: -0.022748013483344362]
	TIME [epoch: 41 sec]
EPOCH 479/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008983404535905008		[learning rate: 1.3857e-05]
	Learning Rate: 1.38569e-05
	LOSS [training: -0.008983404535905008 | validation: -0.01737971562926005]
	TIME [epoch: 41 sec]
EPOCH 480/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009371638678853492		[learning rate: 1.3646e-05]
	Learning Rate: 1.36458e-05
	LOSS [training: -0.009371638678853492 | validation: -0.016734093262282233]
	TIME [epoch: 41 sec]
EPOCH 481/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011882158195678963		[learning rate: 1.3438e-05]
	Learning Rate: 1.3438e-05
	LOSS [training: -0.011882158195678963 | validation: -0.021925390736713228]
	TIME [epoch: 40.9 sec]
EPOCH 482/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007185064045866644		[learning rate: 1.3233e-05]
	Learning Rate: 1.32333e-05
	LOSS [training: -0.007185064045866644 | validation: -0.016331875251260015]
	TIME [epoch: 41 sec]
EPOCH 483/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010220327995709245		[learning rate: 1.3032e-05]
	Learning Rate: 1.30317e-05
	LOSS [training: -0.010220327995709245 | validation: -0.01624092300697595]
	TIME [epoch: 41 sec]
EPOCH 484/500:
	Training over batches...
		[batch 4/4] avg loss: -0.016601746786489666		[learning rate: 1.2833e-05]
	Learning Rate: 1.28332e-05
	LOSS [training: -0.016601746786489666 | validation: -0.010063068356303087]
	TIME [epoch: 41 sec]
EPOCH 485/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01272369396512486		[learning rate: 1.2638e-05]
	Learning Rate: 1.26377e-05
	LOSS [training: -0.01272369396512486 | validation: -0.013067770081215365]
	TIME [epoch: 40.9 sec]
EPOCH 486/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01143486926367411		[learning rate: 1.2445e-05]
	Learning Rate: 1.24451e-05
	LOSS [training: -0.01143486926367411 | validation: -0.01865463978605658]
	TIME [epoch: 41 sec]
EPOCH 487/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008500602861906294		[learning rate: 1.2256e-05]
	Learning Rate: 1.22556e-05
	LOSS [training: -0.008500602861906294 | validation: -0.01952609889154095]
	TIME [epoch: 40.9 sec]
EPOCH 488/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010800111166432915		[learning rate: 1.2069e-05]
	Learning Rate: 1.20689e-05
	LOSS [training: -0.010800111166432915 | validation: -0.012446264160977974]
	TIME [epoch: 40.9 sec]
EPOCH 489/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011803601356646234		[learning rate: 1.1885e-05]
	Learning Rate: 1.1885e-05
	LOSS [training: -0.011803601356646234 | validation: -0.0151657751268569]
	TIME [epoch: 40.9 sec]
EPOCH 490/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01442696662048762		[learning rate: 1.1704e-05]
	Learning Rate: 1.1704e-05
	LOSS [training: -0.01442696662048762 | validation: -0.02205767673235157]
	TIME [epoch: 41 sec]
EPOCH 491/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008945451912005825		[learning rate: 1.1526e-05]
	Learning Rate: 1.15257e-05
	LOSS [training: -0.008945451912005825 | validation: -0.019472049861251204]
	TIME [epoch: 41 sec]
EPOCH 492/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013580755642411957		[learning rate: 1.135e-05]
	Learning Rate: 1.13501e-05
	LOSS [training: -0.013580755642411957 | validation: -0.01666764404247201]
	TIME [epoch: 40.9 sec]
EPOCH 493/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01219972403407189		[learning rate: 1.1177e-05]
	Learning Rate: 1.11772e-05
	LOSS [training: -0.01219972403407189 | validation: -0.019233460172369016]
	TIME [epoch: 40.9 sec]
EPOCH 494/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012214530879473141		[learning rate: 1.1007e-05]
	Learning Rate: 1.10069e-05
	LOSS [training: -0.012214530879473141 | validation: -0.01960403984187287]
	TIME [epoch: 41 sec]
EPOCH 495/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010667393372330438		[learning rate: 1.0839e-05]
	Learning Rate: 1.08393e-05
	LOSS [training: -0.010667393372330438 | validation: -0.0205429614612304]
	TIME [epoch: 41 sec]
EPOCH 496/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014487568217109911		[learning rate: 1.0674e-05]
	Learning Rate: 1.06741e-05
	LOSS [training: -0.014487568217109911 | validation: -0.01859066522236809]
	TIME [epoch: 40.9 sec]
EPOCH 497/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01004270383993391		[learning rate: 1.0512e-05]
	Learning Rate: 1.05115e-05
	LOSS [training: -0.01004270383993391 | validation: -0.005473822708268615]
	TIME [epoch: 40.9 sec]
EPOCH 498/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011877304424915518		[learning rate: 1.0351e-05]
	Learning Rate: 1.03514e-05
	LOSS [training: -0.011877304424915518 | validation: -0.020304242245430343]
	TIME [epoch: 41 sec]
EPOCH 499/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012280974672048764		[learning rate: 1.0194e-05]
	Learning Rate: 1.01937e-05
	LOSS [training: -0.012280974672048764 | validation: -0.01652123676724817]
	TIME [epoch: 41 sec]
EPOCH 500/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009487094315822172		[learning rate: 1.0038e-05]
	Learning Rate: 1.00384e-05
	LOSS [training: -0.009487094315822172 | validation: -0.013618881566750084]
	TIME [epoch: 40.9 sec]
Finished training in 14058.649 seconds.
