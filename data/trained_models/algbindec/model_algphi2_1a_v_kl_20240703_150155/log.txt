Args:
Namespace(name='model_algphi2_1a_v_kl', outdir='out/model_training/model_algphi2_1a_v_kl', training_data='data/training_data/data_phi2_1a/training', validation_data='data/training_data/data_phi2_1a/validation', model_type='binary_flip', nsims_training=None, nsims_validation=None, num_epochs=500, passes_per_epoch=1, batch_size=250, patience=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=False, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, signal_function='sigmoid', solver='heun', confine=False, confinement_factor=1.0, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], phi_final_act='softplus', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=0.0, init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2122866441

Training model...

Saving initial model state to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 4/4] avg loss: 5.313036408556201		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.313036408556201 | validation: 4.757055245340215]
	TIME [epoch: 95.2 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 4/4] avg loss: 4.744264237511169		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.744264237511169 | validation: 4.324356800270551]
	TIME [epoch: 4.37 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 4/4] avg loss: 4.417662377298379		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.417662377298379 | validation: 3.998915303796748]
	TIME [epoch: 4.32 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_3.pth
	Model improved!!!
EPOCH 4/500:
	Training over batches...
		[batch 4/4] avg loss: 4.1246914223459665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.1246914223459665 | validation: 3.734418312329545]
	TIME [epoch: 4.32 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 4/4] avg loss: 3.8436462710061994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8436462710061994 | validation: 3.467301907633045]
	TIME [epoch: 4.34 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_5.pth
	Model improved!!!
EPOCH 6/500:
	Training over batches...
		[batch 4/4] avg loss: 3.601736463618958		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.601736463618958 | validation: 3.3423585413875863]
	TIME [epoch: 4.32 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_6.pth
	Model improved!!!
EPOCH 7/500:
	Training over batches...
		[batch 4/4] avg loss: 3.366157685961015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.366157685961015 | validation: 3.137486431964814]
	TIME [epoch: 4.42 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_7.pth
	Model improved!!!
EPOCH 8/500:
	Training over batches...
		[batch 4/4] avg loss: 3.1343547090968054		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1343547090968054 | validation: 2.806315967042993]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_8.pth
	Model improved!!!
EPOCH 9/500:
	Training over batches...
		[batch 4/4] avg loss: 2.86944276250905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.86944276250905 | validation: 2.5163068292989994]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_9.pth
	Model improved!!!
EPOCH 10/500:
	Training over batches...
		[batch 4/4] avg loss: 2.5969736031971244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5969736031971244 | validation: 2.292794188913007]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_10.pth
	Model improved!!!
EPOCH 11/500:
	Training over batches...
		[batch 4/4] avg loss: 2.401203212510799		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.401203212510799 | validation: 2.104349074409735]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_11.pth
	Model improved!!!
EPOCH 12/500:
	Training over batches...
		[batch 4/4] avg loss: 2.123339074510838		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.123339074510838 | validation: 1.8291576534134277]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_12.pth
	Model improved!!!
EPOCH 13/500:
	Training over batches...
		[batch 4/4] avg loss: 1.8260454587277717		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8260454587277717 | validation: 1.5977238629790285]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_13.pth
	Model improved!!!
EPOCH 14/500:
	Training over batches...
		[batch 4/4] avg loss: 1.5704053016812378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5704053016812378 | validation: 1.342431479430221]
	TIME [epoch: 4.35 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_14.pth
	Model improved!!!
EPOCH 15/500:
	Training over batches...
		[batch 4/4] avg loss: 1.3595369225845833		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3595369225845833 | validation: 1.106185597609711]
	TIME [epoch: 4.34 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_15.pth
	Model improved!!!
EPOCH 16/500:
	Training over batches...
		[batch 4/4] avg loss: 1.143400300391784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.143400300391784 | validation: 1.0520990859328399]
	TIME [epoch: 4.31 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_16.pth
	Model improved!!!
EPOCH 17/500:
	Training over batches...
		[batch 4/4] avg loss: 1.0340275265782288		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0340275265782288 | validation: 0.8663317104063917]
	TIME [epoch: 4.31 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_17.pth
	Model improved!!!
EPOCH 18/500:
	Training over batches...
		[batch 4/4] avg loss: 0.8888418999115045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8888418999115045 | validation: 0.7113375854317814]
	TIME [epoch: 4.31 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_18.pth
	Model improved!!!
EPOCH 19/500:
	Training over batches...
		[batch 4/4] avg loss: 0.6929686185557042		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6929686185557042 | validation: 0.5395340520898066]
	TIME [epoch: 4.31 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_19.pth
	Model improved!!!
EPOCH 20/500:
	Training over batches...
		[batch 4/4] avg loss: 0.5710870174983238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5710870174983238 | validation: 0.4803098384708874]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_20.pth
	Model improved!!!
EPOCH 21/500:
	Training over batches...
		[batch 4/4] avg loss: 0.47763221243381626		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47763221243381626 | validation: 0.3891826703664948]
	TIME [epoch: 4.31 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_21.pth
	Model improved!!!
EPOCH 22/500:
	Training over batches...
		[batch 4/4] avg loss: 0.4112270758518082		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4112270758518082 | validation: 0.3261624514089396]
	TIME [epoch: 4.32 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_22.pth
	Model improved!!!
EPOCH 23/500:
	Training over batches...
		[batch 4/4] avg loss: 0.36161784221216736		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36161784221216736 | validation: 0.3119898091033707]
	TIME [epoch: 4.35 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_23.pth
	Model improved!!!
EPOCH 24/500:
	Training over batches...
		[batch 4/4] avg loss: 0.3401357723151799		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3401357723151799 | validation: 0.32138688930998216]
	TIME [epoch: 4.32 sec]
EPOCH 25/500:
	Training over batches...
		[batch 4/4] avg loss: 0.34035149360772055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34035149360772055 | validation: 0.2848358884065612]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_25.pth
	Model improved!!!
EPOCH 26/500:
	Training over batches...
		[batch 4/4] avg loss: 0.27019784976202343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27019784976202343 | validation: 0.22962179353889356]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_26.pth
	Model improved!!!
EPOCH 27/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2731448957032727		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2731448957032727 | validation: 0.22776189235526184]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_27.pth
	Model improved!!!
EPOCH 28/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2620335656827737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2620335656827737 | validation: 0.22498037912272006]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_28.pth
	Model improved!!!
EPOCH 29/500:
	Training over batches...
		[batch 4/4] avg loss: 0.24409254896384153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24409254896384153 | validation: 0.19201855120222602]
	TIME [epoch: 4.31 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_29.pth
	Model improved!!!
EPOCH 30/500:
	Training over batches...
		[batch 4/4] avg loss: 0.21136239332166276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21136239332166276 | validation: 0.17078467560216876]
	TIME [epoch: 4.32 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_30.pth
	Model improved!!!
EPOCH 31/500:
	Training over batches...
		[batch 4/4] avg loss: 0.18230087443180304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18230087443180304 | validation: 0.16093139062517947]
	TIME [epoch: 4.31 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_31.pth
	Model improved!!!
EPOCH 32/500:
	Training over batches...
		[batch 4/4] avg loss: 0.19955251618702197		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19955251618702197 | validation: 0.16768278277353194]
	TIME [epoch: 4.35 sec]
EPOCH 33/500:
	Training over batches...
		[batch 4/4] avg loss: 0.21014159453133097		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21014159453133097 | validation: 0.17011946058060023]
	TIME [epoch: 4.3 sec]
EPOCH 34/500:
	Training over batches...
		[batch 4/4] avg loss: 0.20762120302973475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20762120302973475 | validation: 0.17216913198672532]
	TIME [epoch: 4.3 sec]
EPOCH 35/500:
	Training over batches...
		[batch 4/4] avg loss: 0.22400089123447936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22400089123447936 | validation: 0.23303811670283442]
	TIME [epoch: 4.31 sec]
EPOCH 36/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2801034451822942		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2801034451822942 | validation: 0.17967319320119224]
	TIME [epoch: 4.3 sec]
EPOCH 37/500:
	Training over batches...
		[batch 4/4] avg loss: 0.20268106682779544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20268106682779544 | validation: 0.1563892510370273]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_37.pth
	Model improved!!!
EPOCH 38/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1875079789615505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1875079789615505 | validation: 0.1426126453804282]
	TIME [epoch: 4.31 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_38.pth
	Model improved!!!
EPOCH 39/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1460287237871381		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1460287237871381 | validation: 0.11457354069558309]
	TIME [epoch: 4.31 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_39.pth
	Model improved!!!
EPOCH 40/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1508710721782534		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1508710721782534 | validation: 0.12708988313381764]
	TIME [epoch: 4.3 sec]
EPOCH 41/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1619759163258721		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1619759163258721 | validation: 0.1454461306885159]
	TIME [epoch: 4.31 sec]
EPOCH 42/500:
	Training over batches...
		[batch 4/4] avg loss: 0.16074553222319776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16074553222319776 | validation: 0.1201008056230134]
	TIME [epoch: 4.34 sec]
EPOCH 43/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13343244238566815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13343244238566815 | validation: 0.12225569074385458]
	TIME [epoch: 4.31 sec]
EPOCH 44/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14705568650372156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14705568650372156 | validation: 0.15070569563704186]
	TIME [epoch: 4.41 sec]
EPOCH 45/500:
	Training over batches...
		[batch 4/4] avg loss: 0.17387859543887096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17387859543887096 | validation: 0.17799140436131305]
	TIME [epoch: 4.3 sec]
EPOCH 46/500:
	Training over batches...
		[batch 4/4] avg loss: 0.20918119311785804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20918119311785804 | validation: 0.15748034971065042]
	TIME [epoch: 4.3 sec]
EPOCH 47/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15786135106247182		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15786135106247182 | validation: 0.14441627261532122]
	TIME [epoch: 4.3 sec]
EPOCH 48/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15511333625924748		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15511333625924748 | validation: 0.14447188992547044]
	TIME [epoch: 4.3 sec]
EPOCH 49/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15120021254694502		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15120021254694502 | validation: 0.1562820823615606]
	TIME [epoch: 4.31 sec]
EPOCH 50/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1718087371251733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1718087371251733 | validation: 0.1682933116060732]
	TIME [epoch: 4.3 sec]
EPOCH 51/500:
	Training over batches...
		[batch 4/4] avg loss: 0.17485563903627		[learning rate: 0.0098855]
	Learning Rate: 0.00988553
	LOSS [training: 0.17485563903627 | validation: 0.18774388057209151]
	TIME [epoch: 4.31 sec]
EPOCH 52/500:
	Training over batches...
		[batch 4/4] avg loss: 0.18558435745221263		[learning rate: 0.0097349]
	Learning Rate: 0.00973494
	LOSS [training: 0.18558435745221263 | validation: 0.17198644737815005]
	TIME [epoch: 4.33 sec]
EPOCH 53/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15353035091451178		[learning rate: 0.0095866]
	Learning Rate: 0.00958665
	LOSS [training: 0.15353035091451178 | validation: 0.13870070214872582]
	TIME [epoch: 4.3 sec]
EPOCH 54/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15695174369320303		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.15695174369320303 | validation: 0.166649521585508]
	TIME [epoch: 4.3 sec]
EPOCH 55/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15502737353559293		[learning rate: 0.0092968]
	Learning Rate: 0.0092968
	LOSS [training: 0.15502737353559293 | validation: 0.15043929160734051]
	TIME [epoch: 4.3 sec]
EPOCH 56/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15527761541211416		[learning rate: 0.0091552]
	Learning Rate: 0.00915517
	LOSS [training: 0.15527761541211416 | validation: 0.15515580741552124]
	TIME [epoch: 4.3 sec]
EPOCH 57/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1578317404716451		[learning rate: 0.0090157]
	Learning Rate: 0.00901571
	LOSS [training: 0.1578317404716451 | validation: 0.11758017467541682]
	TIME [epoch: 4.3 sec]
EPOCH 58/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1457040415450818		[learning rate: 0.0088784]
	Learning Rate: 0.00887837
	LOSS [training: 0.1457040415450818 | validation: 0.12413404300256309]
	TIME [epoch: 4.3 sec]
EPOCH 59/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14239816295511507		[learning rate: 0.0087431]
	Learning Rate: 0.00874312
	LOSS [training: 0.14239816295511507 | validation: 0.12770606386585467]
	TIME [epoch: 4.3 sec]
EPOCH 60/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14849782159015137		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 0.14849782159015137 | validation: 0.14469226539419916]
	TIME [epoch: 4.3 sec]
EPOCH 61/500:
	Training over batches...
		[batch 4/4] avg loss: 0.16912023350171887		[learning rate: 0.0084788]
	Learning Rate: 0.00847878
	LOSS [training: 0.16912023350171887 | validation: 0.15705060360078574]
	TIME [epoch: 4.31 sec]
EPOCH 62/500:
	Training over batches...
		[batch 4/4] avg loss: 0.16716062434009735		[learning rate: 0.0083496]
	Learning Rate: 0.00834962
	LOSS [training: 0.16716062434009735 | validation: 0.14431846677368096]
	TIME [epoch: 4.33 sec]
EPOCH 63/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1583963104214438		[learning rate: 0.0082224]
	Learning Rate: 0.00822243
	LOSS [training: 0.1583963104214438 | validation: 0.15205869432421196]
	TIME [epoch: 4.3 sec]
EPOCH 64/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1514206736599153		[learning rate: 0.0080972]
	Learning Rate: 0.00809717
	LOSS [training: 0.1514206736599153 | validation: 0.14078993160838144]
	TIME [epoch: 4.29 sec]
EPOCH 65/500:
	Training over batches...
		[batch 4/4] avg loss: 0.16594083596500067		[learning rate: 0.0079738]
	Learning Rate: 0.00797382
	LOSS [training: 0.16594083596500067 | validation: 0.13573119836926997]
	TIME [epoch: 4.3 sec]
EPOCH 66/500:
	Training over batches...
		[batch 4/4] avg loss: 0.16622151882052238		[learning rate: 0.0078524]
	Learning Rate: 0.00785236
	LOSS [training: 0.16622151882052238 | validation: 0.13038088459631414]
	TIME [epoch: 4.3 sec]
EPOCH 67/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14644614309663717		[learning rate: 0.0077327]
	Learning Rate: 0.00773274
	LOSS [training: 0.14644614309663717 | validation: 0.11730851663408037]
	TIME [epoch: 4.3 sec]
EPOCH 68/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1309744588917652		[learning rate: 0.0076149]
	Learning Rate: 0.00761494
	LOSS [training: 0.1309744588917652 | validation: 0.1287156838018968]
	TIME [epoch: 4.29 sec]
EPOCH 69/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13911776817375862		[learning rate: 0.0074989]
	Learning Rate: 0.00749894
	LOSS [training: 0.13911776817375862 | validation: 0.13711072752583545]
	TIME [epoch: 4.29 sec]
EPOCH 70/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14324150357246168		[learning rate: 0.0073847]
	Learning Rate: 0.00738471
	LOSS [training: 0.14324150357246168 | validation: 0.13442870588286304]
	TIME [epoch: 4.29 sec]
EPOCH 71/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1443806902823951		[learning rate: 0.0072722]
	Learning Rate: 0.00727221
	LOSS [training: 0.1443806902823951 | validation: 0.13773128895702982]
	TIME [epoch: 4.31 sec]
EPOCH 72/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1677740811988598		[learning rate: 0.0071614]
	Learning Rate: 0.00716143
	LOSS [training: 0.1677740811988598 | validation: 0.1586229940360794]
	TIME [epoch: 4.33 sec]
EPOCH 73/500:
	Training over batches...
		[batch 4/4] avg loss: 0.164042997063445		[learning rate: 0.0070523]
	Learning Rate: 0.00705234
	LOSS [training: 0.164042997063445 | validation: 0.1428950788382774]
	TIME [epoch: 4.3 sec]
EPOCH 74/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15782238291299847		[learning rate: 0.0069449]
	Learning Rate: 0.00694491
	LOSS [training: 0.15782238291299847 | validation: 0.144798945127665]
	TIME [epoch: 4.3 sec]
EPOCH 75/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15742096912174258		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.15742096912174258 | validation: 0.13873394386635238]
	TIME [epoch: 4.3 sec]
EPOCH 76/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14947232807621452		[learning rate: 0.0067349]
	Learning Rate: 0.00673493
	LOSS [training: 0.14947232807621452 | validation: 0.14678289005072703]
	TIME [epoch: 4.29 sec]
EPOCH 77/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14402940878005988		[learning rate: 0.0066323]
	Learning Rate: 0.00663234
	LOSS [training: 0.14402940878005988 | validation: 0.13338332144634799]
	TIME [epoch: 4.3 sec]
EPOCH 78/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1343914223504417		[learning rate: 0.0065313]
	Learning Rate: 0.00653131
	LOSS [training: 0.1343914223504417 | validation: 0.12307384663732296]
	TIME [epoch: 4.3 sec]
EPOCH 79/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1323442672403041		[learning rate: 0.0064318]
	Learning Rate: 0.00643181
	LOSS [training: 0.1323442672403041 | validation: 0.11628748146479786]
	TIME [epoch: 4.3 sec]
EPOCH 80/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13579310356011376		[learning rate: 0.0063338]
	Learning Rate: 0.00633383
	LOSS [training: 0.13579310356011376 | validation: 0.12552639175847635]
	TIME [epoch: 4.29 sec]
EPOCH 81/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14398430685962268		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.14398430685962268 | validation: 0.14441414701800165]
	TIME [epoch: 4.32 sec]
EPOCH 82/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14936178726482263		[learning rate: 0.0061423]
	Learning Rate: 0.00614233
	LOSS [training: 0.14936178726482263 | validation: 0.13673323561330325]
	TIME [epoch: 4.34 sec]
EPOCH 83/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14587001280544973		[learning rate: 0.0060488]
	Learning Rate: 0.00604876
	LOSS [training: 0.14587001280544973 | validation: 0.14013222363812605]
	TIME [epoch: 4.3 sec]
EPOCH 84/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15219944816386008		[learning rate: 0.0059566]
	Learning Rate: 0.00595662
	LOSS [training: 0.15219944816386008 | validation: 0.15291748392396556]
	TIME [epoch: 4.3 sec]
EPOCH 85/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14613189675596971		[learning rate: 0.0058659]
	Learning Rate: 0.00586588
	LOSS [training: 0.14613189675596971 | validation: 0.1503371784417893]
	TIME [epoch: 4.32 sec]
EPOCH 86/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14423459857765597		[learning rate: 0.0057765]
	Learning Rate: 0.00577653
	LOSS [training: 0.14423459857765597 | validation: 0.1433189772810318]
	TIME [epoch: 4.29 sec]
EPOCH 87/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13528273732475476		[learning rate: 0.0056885]
	Learning Rate: 0.00568853
	LOSS [training: 0.13528273732475476 | validation: 0.11754692591883592]
	TIME [epoch: 4.29 sec]
EPOCH 88/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13259308854783697		[learning rate: 0.0056019]
	Learning Rate: 0.00560187
	LOSS [training: 0.13259308854783697 | validation: 0.10771157399397327]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_88.pth
	Model improved!!!
EPOCH 89/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12957026798513724		[learning rate: 0.0055165]
	Learning Rate: 0.00551654
	LOSS [training: 0.12957026798513724 | validation: 0.12654696781642205]
	TIME [epoch: 4.31 sec]
EPOCH 90/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12910711308588213		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.12910711308588213 | validation: 0.12059021597772251]
	TIME [epoch: 4.32 sec]
EPOCH 91/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1349606750965675		[learning rate: 0.0053497]
	Learning Rate: 0.00534975
	LOSS [training: 0.1349606750965675 | validation: 0.12379353470437152]
	TIME [epoch: 4.34 sec]
EPOCH 92/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13632740397833654		[learning rate: 0.0052683]
	Learning Rate: 0.00526825
	LOSS [training: 0.13632740397833654 | validation: 0.12886759095627287]
	TIME [epoch: 4.32 sec]
EPOCH 93/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1409744784119209		[learning rate: 0.005188]
	Learning Rate: 0.005188
	LOSS [training: 0.1409744784119209 | validation: 0.13472180719878515]
	TIME [epoch: 4.3 sec]
EPOCH 94/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1426996598456073		[learning rate: 0.005109]
	Learning Rate: 0.00510897
	LOSS [training: 0.1426996598456073 | validation: 0.12393827249176133]
	TIME [epoch: 4.3 sec]
EPOCH 95/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13810067357377456		[learning rate: 0.0050311]
	Learning Rate: 0.00503114
	LOSS [training: 0.13810067357377456 | validation: 0.1215262967013207]
	TIME [epoch: 4.31 sec]
EPOCH 96/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13257857198338296		[learning rate: 0.0049545]
	Learning Rate: 0.0049545
	LOSS [training: 0.13257857198338296 | validation: 0.12189087280528771]
	TIME [epoch: 4.3 sec]
EPOCH 97/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13437498660257324		[learning rate: 0.004879]
	Learning Rate: 0.00487903
	LOSS [training: 0.13437498660257324 | validation: 0.12183626526394817]
	TIME [epoch: 4.3 sec]
EPOCH 98/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13925501680040275		[learning rate: 0.0048047]
	Learning Rate: 0.0048047
	LOSS [training: 0.13925501680040275 | validation: 0.12891594473994383]
	TIME [epoch: 4.3 sec]
EPOCH 99/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15878113338438055		[learning rate: 0.0047315]
	Learning Rate: 0.00473151
	LOSS [training: 0.15878113338438055 | validation: 0.12236719600033835]
	TIME [epoch: 4.3 sec]
EPOCH 100/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14220583110555907		[learning rate: 0.0046594]
	Learning Rate: 0.00465944
	LOSS [training: 0.14220583110555907 | validation: 0.11092246773071074]
	TIME [epoch: 4.3 sec]
EPOCH 101/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13751753228396532		[learning rate: 0.0045885]
	Learning Rate: 0.00458846
	LOSS [training: 0.13751753228396532 | validation: 0.12085646243925396]
	TIME [epoch: 4.35 sec]
EPOCH 102/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14128476522715025		[learning rate: 0.0045186]
	Learning Rate: 0.00451856
	LOSS [training: 0.14128476522715025 | validation: 0.10346321122377818]
	TIME [epoch: 4.33 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_102.pth
	Model improved!!!
EPOCH 103/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13775021035403906		[learning rate: 0.0044497]
	Learning Rate: 0.00444973
	LOSS [training: 0.13775021035403906 | validation: 0.11698087705507515]
	TIME [epoch: 4.31 sec]
EPOCH 104/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14540360933849755		[learning rate: 0.0043819]
	Learning Rate: 0.00438194
	LOSS [training: 0.14540360933849755 | validation: 0.13059593969915173]
	TIME [epoch: 4.31 sec]
EPOCH 105/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15041522416766218		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 0.15041522416766218 | validation: 0.1286280663656133]
	TIME [epoch: 4.3 sec]
EPOCH 106/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14839475509034517		[learning rate: 0.0042495]
	Learning Rate: 0.00424946
	LOSS [training: 0.14839475509034517 | validation: 0.12499256027700417]
	TIME [epoch: 4.3 sec]
EPOCH 107/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14977143206145319		[learning rate: 0.0041847]
	Learning Rate: 0.00418472
	LOSS [training: 0.14977143206145319 | validation: 0.12561277245042135]
	TIME [epoch: 4.3 sec]
EPOCH 108/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15253630900265677		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.15253630900265677 | validation: 0.12528842519736397]
	TIME [epoch: 4.3 sec]
EPOCH 109/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14290141825205177		[learning rate: 0.0040582]
	Learning Rate: 0.0040582
	LOSS [training: 0.14290141825205177 | validation: 0.11826573789455244]
	TIME [epoch: 4.3 sec]
EPOCH 110/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1459734944619988		[learning rate: 0.0039964]
	Learning Rate: 0.00399638
	LOSS [training: 0.1459734944619988 | validation: 0.11881260071503633]
	TIME [epoch: 4.3 sec]
EPOCH 111/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15979966204341184		[learning rate: 0.0039355]
	Learning Rate: 0.0039355
	LOSS [training: 0.15979966204341184 | validation: 0.12296900373624228]
	TIME [epoch: 4.34 sec]
EPOCH 112/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1583036625856497		[learning rate: 0.0038755]
	Learning Rate: 0.00387555
	LOSS [training: 0.1583036625856497 | validation: 0.12581491886824303]
	TIME [epoch: 4.31 sec]
EPOCH 113/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15424807844794414		[learning rate: 0.0038165]
	Learning Rate: 0.00381651
	LOSS [training: 0.15424807844794414 | validation: 0.13360877038646995]
	TIME [epoch: 4.3 sec]
EPOCH 114/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1621551066403229		[learning rate: 0.0037584]
	Learning Rate: 0.00375837
	LOSS [training: 0.1621551066403229 | validation: 0.15001807538456924]
	TIME [epoch: 4.3 sec]
EPOCH 115/500:
	Training over batches...
		[batch 4/4] avg loss: 0.16221591121895138		[learning rate: 0.0037011]
	Learning Rate: 0.00370112
	LOSS [training: 0.16221591121895138 | validation: 0.1394075280343821]
	TIME [epoch: 4.3 sec]
EPOCH 116/500:
	Training over batches...
		[batch 4/4] avg loss: 0.16813468570365547		[learning rate: 0.0036447]
	Learning Rate: 0.00364474
	LOSS [training: 0.16813468570365547 | validation: 0.13577618909588424]
	TIME [epoch: 4.3 sec]
EPOCH 117/500:
	Training over batches...
		[batch 4/4] avg loss: 0.16331616505344035		[learning rate: 0.0035892]
	Learning Rate: 0.00358922
	LOSS [training: 0.16331616505344035 | validation: 0.11537547297596037]
	TIME [epoch: 4.3 sec]
EPOCH 118/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15389583184178607		[learning rate: 0.0035345]
	Learning Rate: 0.00353454
	LOSS [training: 0.15389583184178607 | validation: 0.12980461916705727]
	TIME [epoch: 4.3 sec]
EPOCH 119/500:
	Training over batches...
		[batch 4/4] avg loss: 0.16582422586692555		[learning rate: 0.0034807]
	Learning Rate: 0.0034807
	LOSS [training: 0.16582422586692555 | validation: 0.1305906542839167]
	TIME [epoch: 4.3 sec]
EPOCH 120/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1715633483643351		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 0.1715633483643351 | validation: 0.1571444848679481]
	TIME [epoch: 4.3 sec]
EPOCH 121/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1979970992117298		[learning rate: 0.0033755]
	Learning Rate: 0.00337546
	LOSS [training: 0.1979970992117298 | validation: 0.16753278515254583]
	TIME [epoch: 4.34 sec]
EPOCH 122/500:
	Training over batches...
		[batch 4/4] avg loss: 0.23914636068742803		[learning rate: 0.003324]
	Learning Rate: 0.00332404
	LOSS [training: 0.23914636068742803 | validation: 0.19534669893999507]
	TIME [epoch: 4.31 sec]
EPOCH 123/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2589634557876384		[learning rate: 0.0032734]
	Learning Rate: 0.00327341
	LOSS [training: 0.2589634557876384 | validation: 0.20354108800921208]
	TIME [epoch: 4.3 sec]
EPOCH 124/500:
	Training over batches...
		[batch 4/4] avg loss: 0.28554359846161603		[learning rate: 0.0032235]
	Learning Rate: 0.00322354
	LOSS [training: 0.28554359846161603 | validation: 0.21024488342280123]
	TIME [epoch: 4.3 sec]
EPOCH 125/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2739879720573058		[learning rate: 0.0031744]
	Learning Rate: 0.00317444
	LOSS [training: 0.2739879720573058 | validation: 0.18829416497276663]
	TIME [epoch: 4.3 sec]
EPOCH 126/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2552943794973069		[learning rate: 0.0031261]
	Learning Rate: 0.00312608
	LOSS [training: 0.2552943794973069 | validation: 0.19676738948992228]
	TIME [epoch: 4.3 sec]
EPOCH 127/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2617804125000572		[learning rate: 0.0030785]
	Learning Rate: 0.00307846
	LOSS [training: 0.2617804125000572 | validation: 0.19882771391947884]
	TIME [epoch: 4.3 sec]
EPOCH 128/500:
	Training over batches...
		[batch 4/4] avg loss: 0.23943961375436415		[learning rate: 0.0030316]
	Learning Rate: 0.00303156
	LOSS [training: 0.23943961375436415 | validation: 0.17176163713442827]
	TIME [epoch: 4.3 sec]
EPOCH 129/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2112043822255627		[learning rate: 0.0029854]
	Learning Rate: 0.00298538
	LOSS [training: 0.2112043822255627 | validation: 0.151962914871068]
	TIME [epoch: 4.3 sec]
EPOCH 130/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1893186455472582		[learning rate: 0.0029399]
	Learning Rate: 0.0029399
	LOSS [training: 0.1893186455472582 | validation: 0.14026937244864393]
	TIME [epoch: 4.3 sec]
EPOCH 131/500:
	Training over batches...
		[batch 4/4] avg loss: 0.18037668867316753		[learning rate: 0.0028951]
	Learning Rate: 0.00289512
	LOSS [training: 0.18037668867316753 | validation: 0.14888392485722046]
	TIME [epoch: 4.34 sec]
EPOCH 132/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1722326188847982		[learning rate: 0.002851]
	Learning Rate: 0.00285102
	LOSS [training: 0.1722326188847982 | validation: 0.1354852813891051]
	TIME [epoch: 4.31 sec]
EPOCH 133/500:
	Training over batches...
		[batch 4/4] avg loss: 0.17265689656402672		[learning rate: 0.0028076]
	Learning Rate: 0.00280759
	LOSS [training: 0.17265689656402672 | validation: 0.14819912243652453]
	TIME [epoch: 4.3 sec]
EPOCH 134/500:
	Training over batches...
		[batch 4/4] avg loss: 0.18381557020458675		[learning rate: 0.0027648]
	Learning Rate: 0.00276482
	LOSS [training: 0.18381557020458675 | validation: 0.15843994537839134]
	TIME [epoch: 4.3 sec]
EPOCH 135/500:
	Training over batches...
		[batch 4/4] avg loss: 0.18049522570902266		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.18049522570902266 | validation: 0.15202316964231588]
	TIME [epoch: 4.3 sec]
EPOCH 136/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1803408513627298		[learning rate: 0.0026812]
	Learning Rate: 0.00268123
	LOSS [training: 0.1803408513627298 | validation: 0.1403249825363594]
	TIME [epoch: 4.29 sec]
EPOCH 137/500:
	Training over batches...
		[batch 4/4] avg loss: 0.17777041473154429		[learning rate: 0.0026404]
	Learning Rate: 0.00264038
	LOSS [training: 0.17777041473154429 | validation: 0.14725773221145627]
	TIME [epoch: 4.3 sec]
EPOCH 138/500:
	Training over batches...
		[batch 4/4] avg loss: 0.17383443285450786		[learning rate: 0.0026002]
	Learning Rate: 0.00260016
	LOSS [training: 0.17383443285450786 | validation: 0.12795047829110778]
	TIME [epoch: 4.3 sec]
EPOCH 139/500:
	Training over batches...
		[batch 4/4] avg loss: 0.17223777354992575		[learning rate: 0.0025606]
	Learning Rate: 0.00256055
	LOSS [training: 0.17223777354992575 | validation: 0.13982110997628372]
	TIME [epoch: 4.3 sec]
EPOCH 140/500:
	Training over batches...
		[batch 4/4] avg loss: 0.17288736048764464		[learning rate: 0.0025215]
	Learning Rate: 0.00252154
	LOSS [training: 0.17288736048764464 | validation: 0.12864142344735807]
	TIME [epoch: 4.3 sec]
EPOCH 141/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14884166278199396		[learning rate: 0.0024831]
	Learning Rate: 0.00248313
	LOSS [training: 0.14884166278199396 | validation: 0.12016781303843846]
	TIME [epoch: 4.33 sec]
EPOCH 142/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14050937790252413		[learning rate: 0.0024453]
	Learning Rate: 0.00244531
	LOSS [training: 0.14050937790252413 | validation: 0.11151172408035405]
	TIME [epoch: 4.31 sec]
EPOCH 143/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13559398378158966		[learning rate: 0.0024081]
	Learning Rate: 0.00240806
	LOSS [training: 0.13559398378158966 | validation: 0.1188657535041836]
	TIME [epoch: 4.3 sec]
EPOCH 144/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13400862488968734		[learning rate: 0.0023714]
	Learning Rate: 0.00237137
	LOSS [training: 0.13400862488968734 | validation: 0.12403802671651261]
	TIME [epoch: 4.3 sec]
EPOCH 145/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14057593812260707		[learning rate: 0.0023352]
	Learning Rate: 0.00233525
	LOSS [training: 0.14057593812260707 | validation: 0.11952632374739786]
	TIME [epoch: 4.3 sec]
EPOCH 146/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14816997074671578		[learning rate: 0.0022997]
	Learning Rate: 0.00229968
	LOSS [training: 0.14816997074671578 | validation: 0.12105316521639642]
	TIME [epoch: 4.3 sec]
EPOCH 147/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14679412549897985		[learning rate: 0.0022646]
	Learning Rate: 0.00226464
	LOSS [training: 0.14679412549897985 | validation: 0.11300862063221037]
	TIME [epoch: 4.3 sec]
EPOCH 148/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13572484045234517		[learning rate: 0.0022301]
	Learning Rate: 0.00223015
	LOSS [training: 0.13572484045234517 | validation: 0.11045688601222325]
	TIME [epoch: 4.3 sec]
EPOCH 149/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13477167822885977		[learning rate: 0.0021962]
	Learning Rate: 0.00219617
	LOSS [training: 0.13477167822885977 | validation: 0.1130084507935766]
	TIME [epoch: 4.31 sec]
EPOCH 150/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13463368373846546		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: 0.13463368373846546 | validation: 0.12168860390470629]
	TIME [epoch: 4.3 sec]
EPOCH 151/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13234074124423217		[learning rate: 0.0021298]
	Learning Rate: 0.00212977
	LOSS [training: 0.13234074124423217 | validation: 0.11864020722634305]
	TIME [epoch: 4.34 sec]
EPOCH 152/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1320519137533282		[learning rate: 0.0020973]
	Learning Rate: 0.00209733
	LOSS [training: 0.1320519137533282 | validation: 0.11313815872839732]
	TIME [epoch: 4.31 sec]
EPOCH 153/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13653795002795444		[learning rate: 0.0020654]
	Learning Rate: 0.00206538
	LOSS [training: 0.13653795002795444 | validation: 0.11923515244958557]
	TIME [epoch: 4.3 sec]
EPOCH 154/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14115173380947027		[learning rate: 0.0020339]
	Learning Rate: 0.00203392
	LOSS [training: 0.14115173380947027 | validation: 0.11303171497156778]
	TIME [epoch: 4.3 sec]
EPOCH 155/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13158744276413414		[learning rate: 0.0020029]
	Learning Rate: 0.00200293
	LOSS [training: 0.13158744276413414 | validation: 0.116449224483305]
	TIME [epoch: 4.3 sec]
EPOCH 156/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13890653629816713		[learning rate: 0.0019724]
	Learning Rate: 0.00197242
	LOSS [training: 0.13890653629816713 | validation: 0.11556815777593105]
	TIME [epoch: 4.3 sec]
EPOCH 157/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1339166410805513		[learning rate: 0.0019424]
	Learning Rate: 0.00194238
	LOSS [training: 0.1339166410805513 | validation: 0.1249826295121999]
	TIME [epoch: 4.3 sec]
EPOCH 158/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13823546559175492		[learning rate: 0.0019128]
	Learning Rate: 0.00191279
	LOSS [training: 0.13823546559175492 | validation: 0.12828300445525131]
	TIME [epoch: 4.3 sec]
EPOCH 159/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14467979698058686		[learning rate: 0.0018836]
	Learning Rate: 0.00188365
	LOSS [training: 0.14467979698058686 | validation: 0.12584080875413062]
	TIME [epoch: 4.3 sec]
EPOCH 160/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14315950602272495		[learning rate: 0.001855]
	Learning Rate: 0.00185495
	LOSS [training: 0.14315950602272495 | validation: 0.12555995772805295]
	TIME [epoch: 4.3 sec]
EPOCH 161/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14544657605122716		[learning rate: 0.0018267]
	Learning Rate: 0.0018267
	LOSS [training: 0.14544657605122716 | validation: 0.1165690499611694]
	TIME [epoch: 4.34 sec]
EPOCH 162/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1327726944657334		[learning rate: 0.0017989]
	Learning Rate: 0.00179887
	LOSS [training: 0.1327726944657334 | validation: 0.11653575837909369]
	TIME [epoch: 4.31 sec]
EPOCH 163/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1275785201332213		[learning rate: 0.0017715]
	Learning Rate: 0.00177147
	LOSS [training: 0.1275785201332213 | validation: 0.09814774238333415]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_163.pth
	Model improved!!!
EPOCH 164/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13184663394787377		[learning rate: 0.0017445]
	Learning Rate: 0.00174448
	LOSS [training: 0.13184663394787377 | validation: 0.11760575833848314]
	TIME [epoch: 4.3 sec]
EPOCH 165/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13679613052363138		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: 0.13679613052363138 | validation: 0.11779778970549441]
	TIME [epoch: 4.3 sec]
EPOCH 166/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13937507878419164		[learning rate: 0.0016917]
	Learning Rate: 0.00169174
	LOSS [training: 0.13937507878419164 | validation: 0.11528747439473269]
	TIME [epoch: 4.3 sec]
EPOCH 167/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1363389672866756		[learning rate: 0.001666]
	Learning Rate: 0.00166597
	LOSS [training: 0.1363389672866756 | validation: 0.11698420551817532]
	TIME [epoch: 4.3 sec]
EPOCH 168/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1370779294219351		[learning rate: 0.0016406]
	Learning Rate: 0.00164059
	LOSS [training: 0.1370779294219351 | validation: 0.11642587991748549]
	TIME [epoch: 4.3 sec]
EPOCH 169/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13225361599267735		[learning rate: 0.0016156]
	Learning Rate: 0.0016156
	LOSS [training: 0.13225361599267735 | validation: 0.11269130253480314]
	TIME [epoch: 4.3 sec]
EPOCH 170/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12741662120749922		[learning rate: 0.001591]
	Learning Rate: 0.00159099
	LOSS [training: 0.12741662120749922 | validation: 0.1149092400010353]
	TIME [epoch: 4.31 sec]
EPOCH 171/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1357985617958999		[learning rate: 0.0015668]
	Learning Rate: 0.00156675
	LOSS [training: 0.1357985617958999 | validation: 0.1135678842809658]
	TIME [epoch: 4.33 sec]
EPOCH 172/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13317218908853456		[learning rate: 0.0015429]
	Learning Rate: 0.00154288
	LOSS [training: 0.13317218908853456 | validation: 0.09842522036669218]
	TIME [epoch: 4.31 sec]
EPOCH 173/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12865693677320125		[learning rate: 0.0015194]
	Learning Rate: 0.00151938
	LOSS [training: 0.12865693677320125 | validation: 0.11290099125070002]
	TIME [epoch: 4.3 sec]
EPOCH 174/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12731158968804923		[learning rate: 0.0014962]
	Learning Rate: 0.00149624
	LOSS [training: 0.12731158968804923 | validation: 0.10505112913359758]
	TIME [epoch: 4.3 sec]
EPOCH 175/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12651910071248867		[learning rate: 0.0014734]
	Learning Rate: 0.00147344
	LOSS [training: 0.12651910071248867 | validation: 0.10069916462796782]
	TIME [epoch: 4.3 sec]
EPOCH 176/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12979878833519265		[learning rate: 0.001451]
	Learning Rate: 0.001451
	LOSS [training: 0.12979878833519265 | validation: 0.110219353417337]
	TIME [epoch: 4.29 sec]
EPOCH 177/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1258140586937342		[learning rate: 0.0014289]
	Learning Rate: 0.00142889
	LOSS [training: 0.1258140586937342 | validation: 0.10227576842674167]
	TIME [epoch: 4.3 sec]
EPOCH 178/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13495366419002683		[learning rate: 0.0014071]
	Learning Rate: 0.00140713
	LOSS [training: 0.13495366419002683 | validation: 0.09975858913445755]
	TIME [epoch: 4.3 sec]
EPOCH 179/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12583241593459701		[learning rate: 0.0013857]
	Learning Rate: 0.00138569
	LOSS [training: 0.12583241593459701 | validation: 0.1128382434620085]
	TIME [epoch: 4.29 sec]
EPOCH 180/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12637044921885748		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: 0.12637044921885748 | validation: 0.10693838463687022]
	TIME [epoch: 4.31 sec]
EPOCH 181/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1255336317501759		[learning rate: 0.0013438]
	Learning Rate: 0.0013438
	LOSS [training: 0.1255336317501759 | validation: 0.10879796767621691]
	TIME [epoch: 4.32 sec]
EPOCH 182/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12591214875571424		[learning rate: 0.0013233]
	Learning Rate: 0.00132333
	LOSS [training: 0.12591214875571424 | validation: 0.10034290047004163]
	TIME [epoch: 4.31 sec]
EPOCH 183/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12711509729911566		[learning rate: 0.0013032]
	Learning Rate: 0.00130317
	LOSS [training: 0.12711509729911566 | validation: 0.11422637494547529]
	TIME [epoch: 4.3 sec]
EPOCH 184/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1280002384884395		[learning rate: 0.0012833]
	Learning Rate: 0.00128332
	LOSS [training: 0.1280002384884395 | validation: 0.12359809655040574]
	TIME [epoch: 4.31 sec]
EPOCH 185/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12808219124475706		[learning rate: 0.0012638]
	Learning Rate: 0.00126377
	LOSS [training: 0.12808219124475706 | validation: 0.12487548128839818]
	TIME [epoch: 4.3 sec]
EPOCH 186/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1323041599739681		[learning rate: 0.0012445]
	Learning Rate: 0.00124451
	LOSS [training: 0.1323041599739681 | validation: 0.10809383790874183]
	TIME [epoch: 4.3 sec]
EPOCH 187/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1318622793859311		[learning rate: 0.0012256]
	Learning Rate: 0.00122556
	LOSS [training: 0.1318622793859311 | validation: 0.11410591473585976]
	TIME [epoch: 4.3 sec]
EPOCH 188/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1321359807950898		[learning rate: 0.0012069]
	Learning Rate: 0.00120689
	LOSS [training: 0.1321359807950898 | validation: 0.11956373458299827]
	TIME [epoch: 4.3 sec]
EPOCH 189/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13755094659218142		[learning rate: 0.0011885]
	Learning Rate: 0.0011885
	LOSS [training: 0.13755094659218142 | validation: 0.11646085853012907]
	TIME [epoch: 4.3 sec]
EPOCH 190/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13139665891272437		[learning rate: 0.0011704]
	Learning Rate: 0.0011704
	LOSS [training: 0.13139665891272437 | validation: 0.11011148957993519]
	TIME [epoch: 4.31 sec]
EPOCH 191/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13414143266868286		[learning rate: 0.0011526]
	Learning Rate: 0.00115257
	LOSS [training: 0.13414143266868286 | validation: 0.11175691027384492]
	TIME [epoch: 4.39 sec]
EPOCH 192/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12763977028465234		[learning rate: 0.001135]
	Learning Rate: 0.00113501
	LOSS [training: 0.12763977028465234 | validation: 0.11004949655581717]
	TIME [epoch: 4.31 sec]
EPOCH 193/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12979331534410526		[learning rate: 0.0011177]
	Learning Rate: 0.00111772
	LOSS [training: 0.12979331534410526 | validation: 0.1154858270358308]
	TIME [epoch: 4.3 sec]
EPOCH 194/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13603121309418417		[learning rate: 0.0011007]
	Learning Rate: 0.00110069
	LOSS [training: 0.13603121309418417 | validation: 0.11706950275063524]
	TIME [epoch: 4.3 sec]
EPOCH 195/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13697388474506242		[learning rate: 0.0010839]
	Learning Rate: 0.00108393
	LOSS [training: 0.13697388474506242 | validation: 0.11021305169201312]
	TIME [epoch: 4.3 sec]
EPOCH 196/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1426171679911776		[learning rate: 0.0010674]
	Learning Rate: 0.00106741
	LOSS [training: 0.1426171679911776 | validation: 0.11550126732799082]
	TIME [epoch: 4.3 sec]
EPOCH 197/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14361928920408681		[learning rate: 0.0010512]
	Learning Rate: 0.00105115
	LOSS [training: 0.14361928920408681 | validation: 0.12190766349748562]
	TIME [epoch: 4.3 sec]
EPOCH 198/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1439689173147119		[learning rate: 0.0010351]
	Learning Rate: 0.00103514
	LOSS [training: 0.1439689173147119 | validation: 0.12631755674739997]
	TIME [epoch: 4.3 sec]
EPOCH 199/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1419830326474539		[learning rate: 0.0010194]
	Learning Rate: 0.00101937
	LOSS [training: 0.1419830326474539 | validation: 0.12559208788321877]
	TIME [epoch: 4.3 sec]
EPOCH 200/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13733296670492243		[learning rate: 0.0010038]
	Learning Rate: 0.00100384
	LOSS [training: 0.13733296670492243 | validation: 0.1319541057482237]
	TIME [epoch: 4.31 sec]
EPOCH 201/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13670740884269894		[learning rate: 0.00098855]
	Learning Rate: 0.000988553
	LOSS [training: 0.13670740884269894 | validation: 0.11945688467880297]
	TIME [epoch: 4.33 sec]
EPOCH 202/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13704513041529334		[learning rate: 0.00097349]
	Learning Rate: 0.000973494
	LOSS [training: 0.13704513041529334 | validation: 0.10490098782974946]
	TIME [epoch: 4.31 sec]
EPOCH 203/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1409132367181741		[learning rate: 0.00095866]
	Learning Rate: 0.000958664
	LOSS [training: 0.1409132367181741 | validation: 0.1284246170357997]
	TIME [epoch: 4.29 sec]
EPOCH 204/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14440759915242746		[learning rate: 0.00094406]
	Learning Rate: 0.000944061
	LOSS [training: 0.14440759915242746 | validation: 0.11621179757283132]
	TIME [epoch: 4.3 sec]
EPOCH 205/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14386160742873538		[learning rate: 0.00092968]
	Learning Rate: 0.00092968
	LOSS [training: 0.14386160742873538 | validation: 0.12734885779490018]
	TIME [epoch: 4.34 sec]
EPOCH 206/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1409557519134788		[learning rate: 0.00091552]
	Learning Rate: 0.000915518
	LOSS [training: 0.1409557519134788 | validation: 0.11997068362122804]
	TIME [epoch: 4.3 sec]
EPOCH 207/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14043807099543995		[learning rate: 0.00090157]
	Learning Rate: 0.000901571
	LOSS [training: 0.14043807099543995 | validation: 0.11174192705035929]
	TIME [epoch: 4.3 sec]
EPOCH 208/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14173223176069874		[learning rate: 0.00088784]
	Learning Rate: 0.000887837
	LOSS [training: 0.14173223176069874 | validation: 0.12259572999423934]
	TIME [epoch: 4.29 sec]
EPOCH 209/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13943333403995373		[learning rate: 0.00087431]
	Learning Rate: 0.000874312
	LOSS [training: 0.13943333403995373 | validation: 0.12467407993894977]
	TIME [epoch: 4.29 sec]
EPOCH 210/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14008363314946676		[learning rate: 0.00086099]
	Learning Rate: 0.000860994
	LOSS [training: 0.14008363314946676 | validation: 0.11835666936758842]
	TIME [epoch: 4.31 sec]
EPOCH 211/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13820671351766406		[learning rate: 0.00084788]
	Learning Rate: 0.000847878
	LOSS [training: 0.13820671351766406 | validation: 0.11767895476010368]
	TIME [epoch: 4.32 sec]
EPOCH 212/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13720176212543905		[learning rate: 0.00083496]
	Learning Rate: 0.000834962
	LOSS [training: 0.13720176212543905 | validation: 0.11447200129815746]
	TIME [epoch: 4.3 sec]
EPOCH 213/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13516975841213422		[learning rate: 0.00082224]
	Learning Rate: 0.000822243
	LOSS [training: 0.13516975841213422 | validation: 0.11404679846835433]
	TIME [epoch: 4.29 sec]
EPOCH 214/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13568692015359973		[learning rate: 0.00080972]
	Learning Rate: 0.000809717
	LOSS [training: 0.13568692015359973 | validation: 0.11952168503227845]
	TIME [epoch: 4.3 sec]
EPOCH 215/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13487317214061223		[learning rate: 0.00079738]
	Learning Rate: 0.000797382
	LOSS [training: 0.13487317214061223 | validation: 0.12144370504918992]
	TIME [epoch: 4.29 sec]
EPOCH 216/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13495058888674735		[learning rate: 0.00078524]
	Learning Rate: 0.000785236
	LOSS [training: 0.13495058888674735 | validation: 0.11769460755492686]
	TIME [epoch: 4.29 sec]
EPOCH 217/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13695815319096158		[learning rate: 0.00077327]
	Learning Rate: 0.000773274
	LOSS [training: 0.13695815319096158 | validation: 0.11573721722527418]
	TIME [epoch: 4.3 sec]
EPOCH 218/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13662971994250886		[learning rate: 0.00076149]
	Learning Rate: 0.000761494
	LOSS [training: 0.13662971994250886 | validation: 0.1133548725880888]
	TIME [epoch: 4.3 sec]
EPOCH 219/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13087756189837108		[learning rate: 0.00074989]
	Learning Rate: 0.000749894
	LOSS [training: 0.13087756189837108 | validation: 0.1128034006362579]
	TIME [epoch: 4.29 sec]
EPOCH 220/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1326399808888955		[learning rate: 0.00073847]
	Learning Rate: 0.000738471
	LOSS [training: 0.1326399808888955 | validation: 0.11196558298463372]
	TIME [epoch: 4.31 sec]
EPOCH 221/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13327469461463373		[learning rate: 0.00072722]
	Learning Rate: 0.000727221
	LOSS [training: 0.13327469461463373 | validation: 0.1143910602969173]
	TIME [epoch: 4.32 sec]
EPOCH 222/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13288115668898418		[learning rate: 0.00071614]
	Learning Rate: 0.000716143
	LOSS [training: 0.13288115668898418 | validation: 0.1109315308433918]
	TIME [epoch: 4.31 sec]
EPOCH 223/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12904803024633782		[learning rate: 0.00070523]
	Learning Rate: 0.000705234
	LOSS [training: 0.12904803024633782 | validation: 0.10640472467525111]
	TIME [epoch: 4.3 sec]
EPOCH 224/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13221176013425995		[learning rate: 0.00069449]
	Learning Rate: 0.000694491
	LOSS [training: 0.13221176013425995 | validation: 0.11253117565172621]
	TIME [epoch: 4.3 sec]
EPOCH 225/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13567162376751293		[learning rate: 0.00068391]
	Learning Rate: 0.000683912
	LOSS [training: 0.13567162376751293 | validation: 0.1072283347775589]
	TIME [epoch: 4.3 sec]
EPOCH 226/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13670767093460245		[learning rate: 0.00067349]
	Learning Rate: 0.000673493
	LOSS [training: 0.13670767093460245 | validation: 0.11519936744489212]
	TIME [epoch: 4.3 sec]
EPOCH 227/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1380440006154699		[learning rate: 0.00066323]
	Learning Rate: 0.000663234
	LOSS [training: 0.1380440006154699 | validation: 0.11379800511855251]
	TIME [epoch: 4.3 sec]
EPOCH 228/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1311817065216007		[learning rate: 0.00065313]
	Learning Rate: 0.00065313
	LOSS [training: 0.1311817065216007 | validation: 0.10769971321494812]
	TIME [epoch: 4.29 sec]
EPOCH 229/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13113887671592073		[learning rate: 0.00064318]
	Learning Rate: 0.000643181
	LOSS [training: 0.13113887671592073 | validation: 0.11328275256068748]
	TIME [epoch: 4.3 sec]
EPOCH 230/500:
	Training over batches...
		[batch 4/4] avg loss: 0.130933149346815		[learning rate: 0.00063338]
	Learning Rate: 0.000633383
	LOSS [training: 0.130933149346815 | validation: 0.1185037829675715]
	TIME [epoch: 4.31 sec]
EPOCH 231/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12786061257502704		[learning rate: 0.00062373]
	Learning Rate: 0.000623735
	LOSS [training: 0.12786061257502704 | validation: 0.11351052358299309]
	TIME [epoch: 4.32 sec]
EPOCH 232/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13178465983671706		[learning rate: 0.00061423]
	Learning Rate: 0.000614233
	LOSS [training: 0.13178465983671706 | validation: 0.101229987576314]
	TIME [epoch: 4.3 sec]
EPOCH 233/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1302392761523349		[learning rate: 0.00060488]
	Learning Rate: 0.000604876
	LOSS [training: 0.1302392761523349 | validation: 0.11121344687823959]
	TIME [epoch: 4.3 sec]
EPOCH 234/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1292162298299409		[learning rate: 0.00059566]
	Learning Rate: 0.000595662
	LOSS [training: 0.1292162298299409 | validation: 0.11115469544227422]
	TIME [epoch: 4.3 sec]
EPOCH 235/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12733296424293172		[learning rate: 0.00058659]
	Learning Rate: 0.000586588
	LOSS [training: 0.12733296424293172 | validation: 0.11108462058693172]
	TIME [epoch: 4.29 sec]
EPOCH 236/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13097096759597612		[learning rate: 0.00057765]
	Learning Rate: 0.000577652
	LOSS [training: 0.13097096759597612 | validation: 0.10913352582730909]
	TIME [epoch: 4.3 sec]
EPOCH 237/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12634987342640175		[learning rate: 0.00056885]
	Learning Rate: 0.000568853
	LOSS [training: 0.12634987342640175 | validation: 0.11092739648177688]
	TIME [epoch: 4.3 sec]
EPOCH 238/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12491188549213592		[learning rate: 0.00056019]
	Learning Rate: 0.000560187
	LOSS [training: 0.12491188549213592 | validation: 0.11573029745634769]
	TIME [epoch: 4.3 sec]
EPOCH 239/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1256529963412668		[learning rate: 0.00055165]
	Learning Rate: 0.000551654
	LOSS [training: 0.1256529963412668 | validation: 0.10521791636968511]
	TIME [epoch: 4.29 sec]
EPOCH 240/500:
	Training over batches...
		[batch 4/4] avg loss: 0.125754580105412		[learning rate: 0.00054325]
	Learning Rate: 0.00054325
	LOSS [training: 0.125754580105412 | validation: 0.11389135385401405]
	TIME [epoch: 4.31 sec]
EPOCH 241/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12981302572653142		[learning rate: 0.00053497]
	Learning Rate: 0.000534975
	LOSS [training: 0.12981302572653142 | validation: 0.10709361398422329]
	TIME [epoch: 4.32 sec]
EPOCH 242/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12550077944353447		[learning rate: 0.00052683]
	Learning Rate: 0.000526825
	LOSS [training: 0.12550077944353447 | validation: 0.10339857771680692]
	TIME [epoch: 4.31 sec]
EPOCH 243/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1244328803157489		[learning rate: 0.0005188]
	Learning Rate: 0.0005188
	LOSS [training: 0.1244328803157489 | validation: 0.11073997483558697]
	TIME [epoch: 4.3 sec]
EPOCH 244/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12583784271965576		[learning rate: 0.0005109]
	Learning Rate: 0.000510897
	LOSS [training: 0.12583784271965576 | validation: 0.11301217625202023]
	TIME [epoch: 4.3 sec]
EPOCH 245/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1237317389658897		[learning rate: 0.00050311]
	Learning Rate: 0.000503114
	LOSS [training: 0.1237317389658897 | validation: 0.11549494406815547]
	TIME [epoch: 4.3 sec]
EPOCH 246/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1204687508700849		[learning rate: 0.00049545]
	Learning Rate: 0.00049545
	LOSS [training: 0.1204687508700849 | validation: 0.1154314023084003]
	TIME [epoch: 4.3 sec]
EPOCH 247/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12403156488458664		[learning rate: 0.0004879]
	Learning Rate: 0.000487903
	LOSS [training: 0.12403156488458664 | validation: 0.10170565718610955]
	TIME [epoch: 4.29 sec]
EPOCH 248/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12303481569623757		[learning rate: 0.00048047]
	Learning Rate: 0.00048047
	LOSS [training: 0.12303481569623757 | validation: 0.10281403798768673]
	TIME [epoch: 4.29 sec]
EPOCH 249/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12609122922334004		[learning rate: 0.00047315]
	Learning Rate: 0.000473151
	LOSS [training: 0.12609122922334004 | validation: 0.11312265320834688]
	TIME [epoch: 4.3 sec]
EPOCH 250/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12408117448456983		[learning rate: 0.00046594]
	Learning Rate: 0.000465944
	LOSS [training: 0.12408117448456983 | validation: 0.10624365216415328]
	TIME [epoch: 4.31 sec]
EPOCH 251/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12214096841278277		[learning rate: 0.00045885]
	Learning Rate: 0.000458846
	LOSS [training: 0.12214096841278277 | validation: 0.11436914894392147]
	TIME [epoch: 4.32 sec]
EPOCH 252/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12566688440931156		[learning rate: 0.00045186]
	Learning Rate: 0.000451856
	LOSS [training: 0.12566688440931156 | validation: 0.10686330521145321]
	TIME [epoch: 4.3 sec]
EPOCH 253/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12407025281074197		[learning rate: 0.00044497]
	Learning Rate: 0.000444973
	LOSS [training: 0.12407025281074197 | validation: 0.11452463613753337]
	TIME [epoch: 4.3 sec]
EPOCH 254/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12331361220961679		[learning rate: 0.00043819]
	Learning Rate: 0.000438194
	LOSS [training: 0.12331361220961679 | validation: 0.10477836671702513]
	TIME [epoch: 4.31 sec]
EPOCH 255/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12629185779692972		[learning rate: 0.00043152]
	Learning Rate: 0.000431519
	LOSS [training: 0.12629185779692972 | validation: 0.11928551046414751]
	TIME [epoch: 4.3 sec]
EPOCH 256/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12602100711951295		[learning rate: 0.00042495]
	Learning Rate: 0.000424946
	LOSS [training: 0.12602100711951295 | validation: 0.11251579363170683]
	TIME [epoch: 4.3 sec]
EPOCH 257/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12872036777632745		[learning rate: 0.00041847]
	Learning Rate: 0.000418472
	LOSS [training: 0.12872036777632745 | validation: 0.11849365690737262]
	TIME [epoch: 4.3 sec]
EPOCH 258/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12638463234706257		[learning rate: 0.0004121]
	Learning Rate: 0.000412098
	LOSS [training: 0.12638463234706257 | validation: 0.10522676002639353]
	TIME [epoch: 4.3 sec]
EPOCH 259/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12468715550651299		[learning rate: 0.00040582]
	Learning Rate: 0.00040582
	LOSS [training: 0.12468715550651299 | validation: 0.0988215111225099]
	TIME [epoch: 4.3 sec]
EPOCH 260/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12606405707920326		[learning rate: 0.00039964]
	Learning Rate: 0.000399638
	LOSS [training: 0.12606405707920326 | validation: 0.10793864491454273]
	TIME [epoch: 4.31 sec]
EPOCH 261/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12212911563399939		[learning rate: 0.00039355]
	Learning Rate: 0.00039355
	LOSS [training: 0.12212911563399939 | validation: 0.11656274999512994]
	TIME [epoch: 4.33 sec]
EPOCH 262/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12522172292460992		[learning rate: 0.00038755]
	Learning Rate: 0.000387555
	LOSS [training: 0.12522172292460992 | validation: 0.1117786683367171]
	TIME [epoch: 4.31 sec]
EPOCH 263/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12508015119342433		[learning rate: 0.00038165]
	Learning Rate: 0.000381651
	LOSS [training: 0.12508015119342433 | validation: 0.10745189948143131]
	TIME [epoch: 4.29 sec]
EPOCH 264/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12793370856344016		[learning rate: 0.00037584]
	Learning Rate: 0.000375837
	LOSS [training: 0.12793370856344016 | validation: 0.10711124392914789]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240703_150155/states/model_algphi2_1a_v_kl_264.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 1256.497 seconds.
