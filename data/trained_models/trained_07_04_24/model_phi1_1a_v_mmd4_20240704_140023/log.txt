Args:
Namespace(name='model_phi1_1a_v_mmd4', outdir='out/model_training/model_phi1_1a_v_mmd4', training_data='data/training_data/data_phi1_1a/training', validation_data='data/training_data/data_phi1_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.1, weight_decay=0.9, clip=1.0, lr_schedule='warmup_cosine_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1358891164

Training model...

Saving initial model state to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.677164968608965		[learning rate: 0.01015]
	Learning Rate: 0.01015
	LOSS [training: 4.677164968608965 | validation: 4.929642031203235]
	TIME [epoch: 121 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.433061543756716		[learning rate: 0.01035]
	Learning Rate: 0.01035
	LOSS [training: 4.433061543756716 | validation: 4.842878457426041]
	TIME [epoch: 7.68 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.302360101745766		[learning rate: 0.01055]
	Learning Rate: 0.01055
	LOSS [training: 4.302360101745766 | validation: 4.7736868913937265]
	TIME [epoch: 7.55 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.164760668309681		[learning rate: 0.01075]
	Learning Rate: 0.01075
	LOSS [training: 4.164760668309681 | validation: 4.689126371701422]
	TIME [epoch: 7.58 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0349706468012485		[learning rate: 0.01095]
	Learning Rate: 0.01095
	LOSS [training: 4.0349706468012485 | validation: 4.3844803421120195]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.900137354042526		[learning rate: 0.01115]
	Learning Rate: 0.01115
	LOSS [training: 3.900137354042526 | validation: 4.0952289392853345]
	TIME [epoch: 7.55 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.664089020728923		[learning rate: 0.01135]
	Learning Rate: 0.01135
	LOSS [training: 3.664089020728923 | validation: 3.9025925066669336]
	TIME [epoch: 7.59 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.432403618999368		[learning rate: 0.01155]
	Learning Rate: 0.01155
	LOSS [training: 3.432403618999368 | validation: 3.78173976173443]
	TIME [epoch: 7.59 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3434134553133825		[learning rate: 0.01175]
	Learning Rate: 0.01175
	LOSS [training: 3.3434134553133825 | validation: 3.4549074840003424]
	TIME [epoch: 7.59 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1021660812504246		[learning rate: 0.01195]
	Learning Rate: 0.01195
	LOSS [training: 3.1021660812504246 | validation: 3.6362144578818443]
	TIME [epoch: 7.65 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.939675941406776		[learning rate: 0.01215]
	Learning Rate: 0.01215
	LOSS [training: 2.939675941406776 | validation: 3.4434834724395227]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.878132670803422		[learning rate: 0.01235]
	Learning Rate: 0.01235
	LOSS [training: 2.878132670803422 | validation: 3.007604982076296]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.567165538192971		[learning rate: 0.01255]
	Learning Rate: 0.01255
	LOSS [training: 2.567165538192971 | validation: 3.256975926837412]
	TIME [epoch: 7.59 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5755075264325464		[learning rate: 0.01275]
	Learning Rate: 0.01275
	LOSS [training: 2.5755075264325464 | validation: 2.914587754861577]
	TIME [epoch: 7.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3977698630979614		[learning rate: 0.01295]
	Learning Rate: 0.01295
	LOSS [training: 2.3977698630979614 | validation: 2.436410363082537]
	TIME [epoch: 7.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2674333787812118		[learning rate: 0.01315]
	Learning Rate: 0.01315
	LOSS [training: 2.2674333787812118 | validation: 2.8271683523081927]
	TIME [epoch: 7.54 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9845000682022813		[learning rate: 0.01335]
	Learning Rate: 0.01335
	LOSS [training: 1.9845000682022813 | validation: 2.364628068699103]
	TIME [epoch: 7.53 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0229971866380994		[learning rate: 0.01355]
	Learning Rate: 0.01355
	LOSS [training: 2.0229971866380994 | validation: 2.1711503450624408]
	TIME [epoch: 7.57 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5471810114001423		[learning rate: 0.01375]
	Learning Rate: 0.01375
	LOSS [training: 1.5471810114001423 | validation: 2.0225195127786466]
	TIME [epoch: 7.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1012884838802472		[learning rate: 0.01395]
	Learning Rate: 0.01395
	LOSS [training: 2.1012884838802472 | validation: 2.1435613231414448]
	TIME [epoch: 7.58 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4696067930359946		[learning rate: 0.01415]
	Learning Rate: 0.01415
	LOSS [training: 1.4696067930359946 | validation: 2.1304117160057583]
	TIME [epoch: 7.58 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8934813705688125		[learning rate: 0.01435]
	Learning Rate: 0.01435
	LOSS [training: 1.8934813705688125 | validation: 2.267287100637867]
	TIME [epoch: 7.57 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7597861011264673		[learning rate: 0.01455]
	Learning Rate: 0.01455
	LOSS [training: 1.7597861011264673 | validation: 1.9088153474955638]
	TIME [epoch: 7.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4792896462423364		[learning rate: 0.01475]
	Learning Rate: 0.01475
	LOSS [training: 1.4792896462423364 | validation: 1.9429192313584105]
	TIME [epoch: 7.63 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3771837338393254		[learning rate: 0.01495]
	Learning Rate: 0.01495
	LOSS [training: 1.3771837338393254 | validation: 1.8943982748321684]
	TIME [epoch: 7.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4115530118209625		[learning rate: 0.01515]
	Learning Rate: 0.01515
	LOSS [training: 1.4115530118209625 | validation: 1.8059999587728313]
	TIME [epoch: 7.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.851586230272229		[learning rate: 0.01535]
	Learning Rate: 0.01535
	LOSS [training: 1.851586230272229 | validation: 1.9475179529636213]
	TIME [epoch: 7.58 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5552021948097017		[learning rate: 0.01555]
	Learning Rate: 0.01555
	LOSS [training: 1.5552021948097017 | validation: 1.8786881112501088]
	TIME [epoch: 7.58 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3636462602340789		[learning rate: 0.01575]
	Learning Rate: 0.01575
	LOSS [training: 1.3636462602340789 | validation: 1.8929977307867896]
	TIME [epoch: 7.64 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3589851826494954		[learning rate: 0.01595]
	Learning Rate: 0.01595
	LOSS [training: 1.3589851826494954 | validation: 1.994554173641187]
	TIME [epoch: 7.59 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7156189026744109		[learning rate: 0.01615]
	Learning Rate: 0.01615
	LOSS [training: 1.7156189026744109 | validation: 2.361064822480077]
	TIME [epoch: 7.58 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5890847343008478		[learning rate: 0.01635]
	Learning Rate: 0.01635
	LOSS [training: 1.5890847343008478 | validation: 1.9037590727229545]
	TIME [epoch: 7.58 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3644542397593264		[learning rate: 0.01655]
	Learning Rate: 0.01655
	LOSS [training: 1.3644542397593264 | validation: 1.8141228656308455]
	TIME [epoch: 7.58 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3503531613378459		[learning rate: 0.01675]
	Learning Rate: 0.01675
	LOSS [training: 1.3503531613378459 | validation: 1.7747545558223963]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.399280373135459		[learning rate: 0.01695]
	Learning Rate: 0.01695
	LOSS [training: 1.399280373135459 | validation: 1.838327519599312]
	TIME [epoch: 7.63 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2471650006594945		[learning rate: 0.01715]
	Learning Rate: 0.01715
	LOSS [training: 1.2471650006594945 | validation: 2.233061073512487]
	TIME [epoch: 7.6 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.710077419470912		[learning rate: 0.01735]
	Learning Rate: 0.01735
	LOSS [training: 1.710077419470912 | validation: 1.7280180260182272]
	TIME [epoch: 7.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3430303964467227		[learning rate: 0.01755]
	Learning Rate: 0.01755
	LOSS [training: 1.3430303964467227 | validation: 1.7837650087510477]
	TIME [epoch: 7.54 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3219771278312225		[learning rate: 0.01775]
	Learning Rate: 0.01775
	LOSS [training: 1.3219771278312225 | validation: 1.7539451166671431]
	TIME [epoch: 7.58 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3367307867273621		[learning rate: 0.01795]
	Learning Rate: 0.01795
	LOSS [training: 1.3367307867273621 | validation: 1.7413509898804962]
	TIME [epoch: 7.55 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5131274581526732		[learning rate: 0.01815]
	Learning Rate: 0.01815
	LOSS [training: 1.5131274581526732 | validation: 1.7979808667655188]
	TIME [epoch: 7.55 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4134939446395234		[learning rate: 0.01835]
	Learning Rate: 0.01835
	LOSS [training: 1.4134939446395234 | validation: 1.8408628103238822]
	TIME [epoch: 7.53 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2928513663763876		[learning rate: 0.01855]
	Learning Rate: 0.01855
	LOSS [training: 1.2928513663763876 | validation: 1.8049235508927257]
	TIME [epoch: 7.54 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4771766498721446		[learning rate: 0.01875]
	Learning Rate: 0.01875
	LOSS [training: 1.4771766498721446 | validation: 1.7262439022586875]
	TIME [epoch: 7.58 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2669168605981076		[learning rate: 0.01895]
	Learning Rate: 0.01895
	LOSS [training: 1.2669168605981076 | validation: 1.5216123952653777]
	TIME [epoch: 7.57 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6777671215313998		[learning rate: 0.01915]
	Learning Rate: 0.01915
	LOSS [training: 1.6777671215313998 | validation: 2.0537609324395323]
	TIME [epoch: 7.59 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.703817395174966		[learning rate: 0.01935]
	Learning Rate: 0.01935
	LOSS [training: 1.703817395174966 | validation: 1.845715635495706]
	TIME [epoch: 7.56 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2232536384182784		[learning rate: 0.01955]
	Learning Rate: 0.01955
	LOSS [training: 1.2232536384182784 | validation: 1.7301851122644165]
	TIME [epoch: 7.59 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1467796939555666		[learning rate: 0.01975]
	Learning Rate: 0.01975
	LOSS [training: 1.1467796939555666 | validation: 1.9622333380270627]
	TIME [epoch: 7.62 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3118310916313236		[learning rate: 0.01995]
	Learning Rate: 0.01995
	LOSS [training: 1.3118310916313236 | validation: 1.434805009050051]
	TIME [epoch: 7.57 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5587283895459714		[learning rate: 0.02]
	Learning Rate: 0.02
	LOSS [training: 1.5587283895459714 | validation: 1.8890573724752135]
	TIME [epoch: 7.59 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2217093857087997		[learning rate: 0.02]
	Learning Rate: 0.02
	LOSS [training: 1.2217093857087997 | validation: 1.8312284434611132]
	TIME [epoch: 7.61 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2949444119043845		[learning rate: 0.02]
	Learning Rate: 0.0199999
	LOSS [training: 1.2949444119043845 | validation: 1.5727244941000977]
	TIME [epoch: 7.59 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0419051881637014		[learning rate: 0.02]
	Learning Rate: 0.0199998
	LOSS [training: 1.0419051881637014 | validation: 1.8471093715342863]
	TIME [epoch: 7.63 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1393553826830694		[learning rate: 0.02]
	Learning Rate: 0.0199997
	LOSS [training: 1.1393553826830694 | validation: 1.4634393107908608]
	TIME [epoch: 7.6 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.102386202858012		[learning rate: 0.02]
	Learning Rate: 0.0199995
	LOSS [training: 1.102386202858012 | validation: 1.4054284452709531]
	TIME [epoch: 7.59 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9867835154314868		[learning rate: 0.019999]
	Learning Rate: 0.0199994
	LOSS [training: 0.9867835154314868 | validation: 1.2913210250648086]
	TIME [epoch: 7.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.930082096089932		[learning rate: 0.019999]
	Learning Rate: 0.0199992
	LOSS [training: 0.930082096089932 | validation: 1.3049496934580813]
	TIME [epoch: 7.64 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2201601477928339		[learning rate: 0.019999]
	Learning Rate: 0.019999
	LOSS [training: 1.2201601477928339 | validation: 1.4553529816443327]
	TIME [epoch: 7.61 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2982750369049478		[learning rate: 0.019999]
	Learning Rate: 0.0199987
	LOSS [training: 1.2982750369049478 | validation: 1.218599877945144]
	TIME [epoch: 7.59 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8465271480242802		[learning rate: 0.019998]
	Learning Rate: 0.0199984
	LOSS [training: 0.8465271480242802 | validation: 1.1424881159572045]
	TIME [epoch: 7.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8721806592150398		[learning rate: 0.019998]
	Learning Rate: 0.0199981
	LOSS [training: 0.8721806592150398 | validation: 1.0467237494181272]
	TIME [epoch: 7.88 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.734471574538375		[learning rate: 0.019998]
	Learning Rate: 0.0199978
	LOSS [training: 0.734471574538375 | validation: 1.0521284625588303]
	TIME [epoch: 7.62 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8948743354441745		[learning rate: 0.019997]
	Learning Rate: 0.0199974
	LOSS [training: 0.8948743354441745 | validation: 1.019823060188693]
	TIME [epoch: 7.58 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6215831737450281		[learning rate: 0.019997]
	Learning Rate: 0.019997
	LOSS [training: 0.6215831737450281 | validation: 0.835618084524846]
	TIME [epoch: 7.54 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7252094292424744		[learning rate: 0.019997]
	Learning Rate: 0.0199966
	LOSS [training: 0.7252094292424744 | validation: 1.049980543428699]
	TIME [epoch: 7.6 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9359446117043905		[learning rate: 0.019996]
	Learning Rate: 0.0199962
	LOSS [training: 0.9359446117043905 | validation: 0.9005604188875922]
	TIME [epoch: 7.58 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5942095662453567		[learning rate: 0.019996]
	Learning Rate: 0.0199957
	LOSS [training: 0.5942095662453567 | validation: 0.5930775626283902]
	TIME [epoch: 7.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6850893321461945		[learning rate: 0.019995]
	Learning Rate: 0.0199952
	LOSS [training: 0.6850893321461945 | validation: 0.993267974235905]
	TIME [epoch: 7.63 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5768196059178069		[learning rate: 0.019995]
	Learning Rate: 0.0199947
	LOSS [training: 0.5768196059178069 | validation: 0.7346948580110599]
	TIME [epoch: 7.59 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5892890995833818		[learning rate: 0.019994]
	Learning Rate: 0.0199941
	LOSS [training: 0.5892890995833818 | validation: 0.857990985645321]
	TIME [epoch: 7.58 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5641473784225162		[learning rate: 0.019994]
	Learning Rate: 0.0199935
	LOSS [training: 0.5641473784225162 | validation: 0.9104782563370103]
	TIME [epoch: 7.59 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5289633893331062		[learning rate: 0.019993]
	Learning Rate: 0.0199929
	LOSS [training: 0.5289633893331062 | validation: 0.4618265320769956]
	TIME [epoch: 7.65 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5036369940650178		[learning rate: 0.019992]
	Learning Rate: 0.0199923
	LOSS [training: 0.5036369940650178 | validation: 0.5952360033436412]
	TIME [epoch: 7.61 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5283104841983544		[learning rate: 0.019992]
	Learning Rate: 0.0199916
	LOSS [training: 0.5283104841983544 | validation: 0.6760766912591459]
	TIME [epoch: 7.61 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6099946934672013		[learning rate: 0.019991]
	Learning Rate: 0.0199909
	LOSS [training: 0.6099946934672013 | validation: 0.4635497809179394]
	TIME [epoch: 7.6 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.439597405007887		[learning rate: 0.01999]
	Learning Rate: 0.0199902
	LOSS [training: 0.439597405007887 | validation: 0.6727302381156143]
	TIME [epoch: 7.61 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4542748612838601		[learning rate: 0.019989]
	Learning Rate: 0.0199895
	LOSS [training: 0.4542748612838601 | validation: 0.6673232071490864]
	TIME [epoch: 7.65 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4597145861246679		[learning rate: 0.019989]
	Learning Rate: 0.0199887
	LOSS [training: 0.4597145861246679 | validation: 0.5184337708793656]
	TIME [epoch: 7.63 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3599997263233593		[learning rate: 0.019988]
	Learning Rate: 0.0199879
	LOSS [training: 0.3599997263233593 | validation: 0.6640057731716302]
	TIME [epoch: 7.61 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4325625388552523		[learning rate: 0.019987]
	Learning Rate: 0.0199871
	LOSS [training: 0.4325625388552523 | validation: 1.0081873253719127]
	TIME [epoch: 7.63 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5963616126280993		[learning rate: 0.019986]
	Learning Rate: 0.0199862
	LOSS [training: 0.5963616126280993 | validation: 0.5142457199018132]
	TIME [epoch: 7.63 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4001657042363442		[learning rate: 0.019985]
	Learning Rate: 0.0199853
	LOSS [training: 0.4001657042363442 | validation: 0.37868532850182124]
	TIME [epoch: 7.66 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3704637840752245		[learning rate: 0.019984]
	Learning Rate: 0.0199844
	LOSS [training: 0.3704637840752245 | validation: 0.5380459914037699]
	TIME [epoch: 7.62 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4459685004378061		[learning rate: 0.019984]
	Learning Rate: 0.0199835
	LOSS [training: 0.4459685004378061 | validation: 0.8654418648243731]
	TIME [epoch: 7.62 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46618819577088133		[learning rate: 0.019983]
	Learning Rate: 0.0199825
	LOSS [training: 0.46618819577088133 | validation: 0.40459214690170153]
	TIME [epoch: 7.64 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40815700706034086		[learning rate: 0.019982]
	Learning Rate: 0.0199816
	LOSS [training: 0.40815700706034086 | validation: 0.5839749401922039]
	TIME [epoch: 7.64 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43422247400714065		[learning rate: 0.019981]
	Learning Rate: 0.0199805
	LOSS [training: 0.43422247400714065 | validation: 0.5379436452742561]
	TIME [epoch: 7.67 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4060576653167201		[learning rate: 0.019979]
	Learning Rate: 0.0199795
	LOSS [training: 0.4060576653167201 | validation: 0.6294164703125429]
	TIME [epoch: 7.64 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3838566678928555		[learning rate: 0.019978]
	Learning Rate: 0.0199784
	LOSS [training: 0.3838566678928555 | validation: 0.4984308789555708]
	TIME [epoch: 7.63 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43148369556852756		[learning rate: 0.019977]
	Learning Rate: 0.0199773
	LOSS [training: 0.43148369556852756 | validation: 0.4571303060240245]
	TIME [epoch: 7.63 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3751441000173227		[learning rate: 0.019976]
	Learning Rate: 0.0199762
	LOSS [training: 0.3751441000173227 | validation: 0.5786667234309046]
	TIME [epoch: 7.65 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4037220713352765		[learning rate: 0.019975]
	Learning Rate: 0.019975
	LOSS [training: 0.4037220713352765 | validation: 0.4438616479741676]
	TIME [epoch: 7.67 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3603214127164135		[learning rate: 0.019974]
	Learning Rate: 0.0199739
	LOSS [training: 0.3603214127164135 | validation: 0.4921338094231831]
	TIME [epoch: 7.65 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4089375421669468		[learning rate: 0.019973]
	Learning Rate: 0.0199727
	LOSS [training: 0.4089375421669468 | validation: 0.41890763752947824]
	TIME [epoch: 7.63 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3859247510463463		[learning rate: 0.019971]
	Learning Rate: 0.0199714
	LOSS [training: 0.3859247510463463 | validation: 0.45515173188231073]
	TIME [epoch: 7.64 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3500733565830818		[learning rate: 0.01997]
	Learning Rate: 0.0199702
	LOSS [training: 0.3500733565830818 | validation: 0.39447860641386456]
	TIME [epoch: 7.65 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4419051171992705		[learning rate: 0.019969]
	Learning Rate: 0.0199689
	LOSS [training: 0.4419051171992705 | validation: 0.5946244654688133]
	TIME [epoch: 7.7 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3872275493815765		[learning rate: 0.019968]
	Learning Rate: 0.0199675
	LOSS [training: 0.3872275493815765 | validation: 0.5824847326534525]
	TIME [epoch: 7.64 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46797086529251053		[learning rate: 0.019966]
	Learning Rate: 0.0199662
	LOSS [training: 0.46797086529251053 | validation: 0.4163209304659664]
	TIME [epoch: 7.63 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31432720876187104		[learning rate: 0.019965]
	Learning Rate: 0.0199648
	LOSS [training: 0.31432720876187104 | validation: 0.3173776851275985]
	TIME [epoch: 7.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36111554928583023		[learning rate: 0.019963]
	Learning Rate: 0.0199634
	LOSS [training: 0.36111554928583023 | validation: 0.35633169643981466]
	TIME [epoch: 7.59 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34630117652420783		[learning rate: 0.019962]
	Learning Rate: 0.019962
	LOSS [training: 0.34630117652420783 | validation: 0.3865923779495186]
	TIME [epoch: 7.57 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3942466370765104		[learning rate: 0.019961]
	Learning Rate: 0.0199606
	LOSS [training: 0.3942466370765104 | validation: 0.31678230189418677]
	TIME [epoch: 7.58 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3260417516670591		[learning rate: 0.019959]
	Learning Rate: 0.0199591
	LOSS [training: 0.3260417516670591 | validation: 0.4203953993047491]
	TIME [epoch: 7.58 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3669058644418665		[learning rate: 0.019958]
	Learning Rate: 0.0199576
	LOSS [training: 0.3669058644418665 | validation: 0.37100496277900996]
	TIME [epoch: 7.57 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3341147916813084		[learning rate: 0.019956]
	Learning Rate: 0.019956
	LOSS [training: 0.3341147916813084 | validation: 0.34640564489467973]
	TIME [epoch: 7.62 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3676862057851995		[learning rate: 0.019954]
	Learning Rate: 0.0199545
	LOSS [training: 0.3676862057851995 | validation: 0.29042326514431027]
	TIME [epoch: 7.58 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4513031120776118		[learning rate: 0.019953]
	Learning Rate: 0.0199529
	LOSS [training: 0.4513031120776118 | validation: 0.5240257809014242]
	TIME [epoch: 7.6 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3118781337233074		[learning rate: 0.019951]
	Learning Rate: 0.0199513
	LOSS [training: 0.3118781337233074 | validation: 0.3388597661644417]
	TIME [epoch: 7.6 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3312606442545306		[learning rate: 0.01995]
	Learning Rate: 0.0199496
	LOSS [training: 0.3312606442545306 | validation: 0.4402872293476663]
	TIME [epoch: 7.58 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4323640705025055		[learning rate: 0.019948]
	Learning Rate: 0.0199479
	LOSS [training: 0.4323640705025055 | validation: 0.3833614106588452]
	TIME [epoch: 7.63 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3349625043818424		[learning rate: 0.019946]
	Learning Rate: 0.0199462
	LOSS [training: 0.3349625043818424 | validation: 0.4757437999497446]
	TIME [epoch: 7.59 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35471789212034244		[learning rate: 0.019945]
	Learning Rate: 0.0199445
	LOSS [training: 0.35471789212034244 | validation: 0.6956005615058138]
	TIME [epoch: 7.59 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36029259604318625		[learning rate: 0.019943]
	Learning Rate: 0.0199428
	LOSS [training: 0.36029259604318625 | validation: 0.3801592737308842]
	TIME [epoch: 7.6 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.310600736407715		[learning rate: 0.019941]
	Learning Rate: 0.019941
	LOSS [training: 0.310600736407715 | validation: 0.6313292112315019]
	TIME [epoch: 7.59 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0021635492760756		[learning rate: 0.019939]
	Learning Rate: 0.0199392
	LOSS [training: 1.0021635492760756 | validation: 3.9591074524013505]
	TIME [epoch: 7.62 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.035619922034192		[learning rate: 0.019937]
	Learning Rate: 0.0199374
	LOSS [training: 4.035619922034192 | validation: 4.026991822081633]
	TIME [epoch: 7.6 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.019992837790771		[learning rate: 0.019935]
	Learning Rate: 0.0199355
	LOSS [training: 4.019992837790771 | validation: 4.1899158442576505]
	TIME [epoch: 7.59 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.038095859329448		[learning rate: 0.019934]
	Learning Rate: 0.0199336
	LOSS [training: 4.038095859329448 | validation: 4.238703290479554]
	TIME [epoch: 7.58 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.946030146719739		[learning rate: 0.019932]
	Learning Rate: 0.0199317
	LOSS [training: 3.946030146719739 | validation: 4.11033697826055]
	TIME [epoch: 7.6 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5081493164595856		[learning rate: 0.01993]
	Learning Rate: 0.0199297
	LOSS [training: 3.5081493164595856 | validation: 3.0347621331264247]
	TIME [epoch: 7.66 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.462435904770933		[learning rate: 0.019928]
	Learning Rate: 0.0199278
	LOSS [training: 2.462435904770933 | validation: 2.388575093126391]
	TIME [epoch: 7.61 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5382510336307238		[learning rate: 0.019926]
	Learning Rate: 0.0199258
	LOSS [training: 1.5382510336307238 | validation: 2.2148183196056794]
	TIME [epoch: 7.59 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4365392195195716		[learning rate: 0.019924]
	Learning Rate: 0.0199238
	LOSS [training: 1.4365392195195716 | validation: 2.127767302041069]
	TIME [epoch: 7.58 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3880163501838443		[learning rate: 0.019922]
	Learning Rate: 0.0199217
	LOSS [training: 1.3880163501838443 | validation: 2.120557052962549]
	TIME [epoch: 7.6 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.381315324531264		[learning rate: 0.01992]
	Learning Rate: 0.0199196
	LOSS [training: 1.381315324531264 | validation: 2.1065621555519662]
	TIME [epoch: 7.65 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.312579669921515		[learning rate: 0.019918]
	Learning Rate: 0.0199175
	LOSS [training: 1.312579669921515 | validation: 2.096779097206387]
	TIME [epoch: 7.62 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.285477610271519		[learning rate: 0.019915]
	Learning Rate: 0.0199154
	LOSS [training: 1.285477610271519 | validation: 2.0604929735319213]
	TIME [epoch: 7.6 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3029400959052566		[learning rate: 0.019913]
	Learning Rate: 0.0199132
	LOSS [training: 1.3029400959052566 | validation: 1.9899771444497496]
	TIME [epoch: 7.59 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5650701425749385		[learning rate: 0.019911]
	Learning Rate: 0.019911
	LOSS [training: 1.5650701425749385 | validation: 1.7755549524633247]
	TIME [epoch: 7.59 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4030235048698634		[learning rate: 0.019909]
	Learning Rate: 0.0199088
	LOSS [training: 1.4030235048698634 | validation: 1.6689864357317865]
	TIME [epoch: 7.66 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0370005103176396		[learning rate: 0.019907]
	Learning Rate: 0.0199066
	LOSS [training: 1.0370005103176396 | validation: 1.2674234975446805]
	TIME [epoch: 7.63 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.211345634980279		[learning rate: 0.019904]
	Learning Rate: 0.0199043
	LOSS [training: 1.211345634980279 | validation: 1.249751186882303]
	TIME [epoch: 7.6 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7241526301621362		[learning rate: 0.019902]
	Learning Rate: 0.019902
	LOSS [training: 0.7241526301621362 | validation: 0.7451557541880846]
	TIME [epoch: 7.59 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5267173994337156		[learning rate: 0.0199]
	Learning Rate: 0.0198997
	LOSS [training: 0.5267173994337156 | validation: 0.5104432583162684]
	TIME [epoch: 7.61 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39795149552094955		[learning rate: 0.019897]
	Learning Rate: 0.0198974
	LOSS [training: 0.39795149552094955 | validation: 0.4952703763619496]
	TIME [epoch: 7.64 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4457823161552561		[learning rate: 0.019895]
	Learning Rate: 0.019895
	LOSS [training: 0.4457823161552561 | validation: 0.4288037403211322]
	TIME [epoch: 7.62 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40185712113357663		[learning rate: 0.019893]
	Learning Rate: 0.0198926
	LOSS [training: 0.40185712113357663 | validation: 0.4535053135794611]
	TIME [epoch: 7.65 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4054522121354927		[learning rate: 0.01989]
	Learning Rate: 0.0198901
	LOSS [training: 0.4054522121354927 | validation: 0.42784498695072615]
	TIME [epoch: 7.61 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5870069622359673		[learning rate: 0.019888]
	Learning Rate: 0.0198877
	LOSS [training: 0.5870069622359673 | validation: 0.4167829577535921]
	TIME [epoch: 7.6 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3249053227788153		[learning rate: 0.019885]
	Learning Rate: 0.0198852
	LOSS [training: 0.3249053227788153 | validation: 0.5075210513800477]
	TIME [epoch: 7.65 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47985279549847487		[learning rate: 0.019883]
	Learning Rate: 0.0198827
	LOSS [training: 0.47985279549847487 | validation: 0.3802504982834465]
	TIME [epoch: 7.61 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3760593168327118		[learning rate: 0.01988]
	Learning Rate: 0.0198802
	LOSS [training: 0.3760593168327118 | validation: 0.533757247857717]
	TIME [epoch: 7.61 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4931260678021339		[learning rate: 0.019878]
	Learning Rate: 0.0198776
	LOSS [training: 0.4931260678021339 | validation: 0.46192542158241073]
	TIME [epoch: 7.64 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4380694199622541		[learning rate: 0.019875]
	Learning Rate: 0.019875
	LOSS [training: 1.4380694199622541 | validation: 0.6581854477825391]
	TIME [epoch: 7.62 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42045408374718696		[learning rate: 0.019872]
	Learning Rate: 0.0198724
	LOSS [training: 0.42045408374718696 | validation: 0.5000977100810355]
	TIME [epoch: 7.66 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4201030577370901		[learning rate: 0.01987]
	Learning Rate: 0.0198697
	LOSS [training: 0.4201030577370901 | validation: 0.49301554218539534]
	TIME [epoch: 7.63 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3652373646322769		[learning rate: 0.019867]
	Learning Rate: 0.0198671
	LOSS [training: 0.3652373646322769 | validation: 0.6297607915732557]
	TIME [epoch: 7.61 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4232254768935627		[learning rate: 0.019864]
	Learning Rate: 0.0198644
	LOSS [training: 0.4232254768935627 | validation: 0.48153072454426993]
	TIME [epoch: 7.63 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45802613161277794		[learning rate: 0.019862]
	Learning Rate: 0.0198616
	LOSS [training: 0.45802613161277794 | validation: 0.3989557328123196]
	TIME [epoch: 7.63 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3252472215041159		[learning rate: 0.019859]
	Learning Rate: 0.0198589
	LOSS [training: 0.3252472215041159 | validation: 0.468482269737841]
	TIME [epoch: 7.67 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.379592887106735		[learning rate: 0.019856]
	Learning Rate: 0.0198561
	LOSS [training: 0.379592887106735 | validation: 0.3955415492975468]
	TIME [epoch: 7.62 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40280889855365704		[learning rate: 0.019853]
	Learning Rate: 0.0198533
	LOSS [training: 0.40280889855365704 | validation: 0.41681095162487114]
	TIME [epoch: 7.63 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3860634975867416		[learning rate: 0.01985]
	Learning Rate: 0.0198505
	LOSS [training: 0.3860634975867416 | validation: 0.38264108469388625]
	TIME [epoch: 7.62 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36712523418667575		[learning rate: 0.019848]
	Learning Rate: 0.0198476
	LOSS [training: 0.36712523418667575 | validation: 0.34338109240949616]
	TIME [epoch: 7.62 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41627053772388917		[learning rate: 0.019845]
	Learning Rate: 0.0198447
	LOSS [training: 0.41627053772388917 | validation: 0.6725968219425358]
	TIME [epoch: 7.69 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3971676090422413		[learning rate: 0.019842]
	Learning Rate: 0.0198418
	LOSS [training: 0.3971676090422413 | validation: 0.3811665726131245]
	TIME [epoch: 7.62 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37486633263678026		[learning rate: 0.019839]
	Learning Rate: 0.0198388
	LOSS [training: 0.37486633263678026 | validation: 0.3587252936753602]
	TIME [epoch: 7.64 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3137993854796036		[learning rate: 0.019836]
	Learning Rate: 0.0198359
	LOSS [training: 0.3137993854796036 | validation: 0.4668837755410308]
	TIME [epoch: 7.63 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.572933793089462		[learning rate: 0.019833]
	Learning Rate: 0.0198329
	LOSS [training: 0.572933793089462 | validation: 0.8853672319330573]
	TIME [epoch: 7.63 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5414111325807602		[learning rate: 0.01983]
	Learning Rate: 0.0198299
	LOSS [training: 0.5414111325807602 | validation: 0.5928290338022771]
	TIME [epoch: 7.67 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4202116897828642		[learning rate: 0.019827]
	Learning Rate: 0.0198268
	LOSS [training: 0.4202116897828642 | validation: 0.49622083882123835]
	TIME [epoch: 7.64 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3543622298213234		[learning rate: 0.019824]
	Learning Rate: 0.0198237
	LOSS [training: 0.3543622298213234 | validation: 0.43675472422023076]
	TIME [epoch: 7.64 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36358374485645145		[learning rate: 0.019821]
	Learning Rate: 0.0198206
	LOSS [training: 0.36358374485645145 | validation: 0.3859977076038904]
	TIME [epoch: 7.63 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30624028395073816		[learning rate: 0.019818]
	Learning Rate: 0.0198175
	LOSS [training: 0.30624028395073816 | validation: 0.3667270097240197]
	TIME [epoch: 7.63 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3305085558281602		[learning rate: 0.019814]
	Learning Rate: 0.0198143
	LOSS [training: 0.3305085558281602 | validation: 0.3816888326342647]
	TIME [epoch: 7.69 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33271606516121865		[learning rate: 0.019811]
	Learning Rate: 0.0198112
	LOSS [training: 0.33271606516121865 | validation: 0.4901629299442116]
	TIME [epoch: 7.65 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5216810791180284		[learning rate: 0.019808]
	Learning Rate: 0.0198079
	LOSS [training: 0.5216810791180284 | validation: 2.107545467849622]
	TIME [epoch: 7.64 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2961093500102063		[learning rate: 0.019805]
	Learning Rate: 0.0198047
	LOSS [training: 1.2961093500102063 | validation: 1.1601590532265011]
	TIME [epoch: 7.63 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7160099269410249		[learning rate: 0.019801]
	Learning Rate: 0.0198014
	LOSS [training: 0.7160099269410249 | validation: 0.8515135758145213]
	TIME [epoch: 7.62 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5281026552961804		[learning rate: 0.019798]
	Learning Rate: 0.0197982
	LOSS [training: 0.5281026552961804 | validation: 0.5675322605831348]
	TIME [epoch: 7.68 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.440578577883108		[learning rate: 0.019795]
	Learning Rate: 0.0197948
	LOSS [training: 0.440578577883108 | validation: 0.4913783150514957]
	TIME [epoch: 7.64 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3800059754258783		[learning rate: 0.019791]
	Learning Rate: 0.0197915
	LOSS [training: 0.3800059754258783 | validation: 0.4640359904761233]
	TIME [epoch: 7.63 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39689439817163785		[learning rate: 0.019788]
	Learning Rate: 0.0197881
	LOSS [training: 0.39689439817163785 | validation: 0.5067898155918622]
	TIME [epoch: 7.64 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9652741491070649		[learning rate: 0.019785]
	Learning Rate: 0.0197847
	LOSS [training: 0.9652741491070649 | validation: 6.225544137843985]
	TIME [epoch: 7.64 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.171443738447483		[learning rate: 0.019781]
	Learning Rate: 0.0197813
	LOSS [training: 6.171443738447483 | validation: 6.903926929612399]
	TIME [epoch: 7.67 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.663821348673823		[learning rate: 0.019778]
	Learning Rate: 0.0197778
	LOSS [training: 6.663821348673823 | validation: 6.884279137517032]
	TIME [epoch: 7.64 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.580501050532453		[learning rate: 0.019774]
	Learning Rate: 0.0197744
	LOSS [training: 6.580501050532453 | validation: 7.013880306147955]
	TIME [epoch: 7.63 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0441805517990455		[learning rate: 0.019771]
	Learning Rate: 0.0197709
	LOSS [training: 6.0441805517990455 | validation: 4.625962656716303]
	TIME [epoch: 7.64 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.795923152212934		[learning rate: 0.019767]
	Learning Rate: 0.0197673
	LOSS [training: 4.795923152212934 | validation: 3.824249371185109]
	TIME [epoch: 7.63 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.764735799175213		[learning rate: 0.019764]
	Learning Rate: 0.0197638
	LOSS [training: 4.764735799175213 | validation: 4.301079984129156]
	TIME [epoch: 7.69 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3977081485222		[learning rate: 0.01976]
	Learning Rate: 0.0197602
	LOSS [training: 4.3977081485222 | validation: 3.1624476597366113]
	TIME [epoch: 7.64 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0421726644085463		[learning rate: 0.019757]
	Learning Rate: 0.0197566
	LOSS [training: 2.0421726644085463 | validation: 0.7592841105105308]
	TIME [epoch: 7.65 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6255677908089232		[learning rate: 0.019753]
	Learning Rate: 0.0197529
	LOSS [training: 0.6255677908089232 | validation: 0.5354577561309345]
	TIME [epoch: 7.64 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4125079952088083		[learning rate: 0.019749]
	Learning Rate: 0.0197493
	LOSS [training: 0.4125079952088083 | validation: 0.37986746255461173]
	TIME [epoch: 7.65 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34316193014418667		[learning rate: 0.019746]
	Learning Rate: 0.0197456
	LOSS [training: 0.34316193014418667 | validation: 0.35833950743251497]
	TIME [epoch: 7.68 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3285323563066582		[learning rate: 0.019742]
	Learning Rate: 0.0197419
	LOSS [training: 0.3285323563066582 | validation: 0.34286570367864044]
	TIME [epoch: 7.62 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3495130072360816		[learning rate: 0.019738]
	Learning Rate: 0.0197381
	LOSS [training: 0.3495130072360816 | validation: 0.4101814430979328]
	TIME [epoch: 7.64 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.341843285249522		[learning rate: 0.019734]
	Learning Rate: 0.0197343
	LOSS [training: 0.341843285249522 | validation: 0.42345189913367876]
	TIME [epoch: 7.62 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43469313134566		[learning rate: 0.019731]
	Learning Rate: 0.0197305
	LOSS [training: 0.43469313134566 | validation: 0.5557342957474305]
	TIME [epoch: 7.63 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42880655564522074		[learning rate: 0.019727]
	Learning Rate: 0.0197267
	LOSS [training: 0.42880655564522074 | validation: 0.38693859979882206]
	TIME [epoch: 7.69 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41843632207820236		[learning rate: 0.019723]
	Learning Rate: 0.0197229
	LOSS [training: 0.41843632207820236 | validation: 0.4297649127884411]
	TIME [epoch: 7.65 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44077590511226905		[learning rate: 0.019719]
	Learning Rate: 0.019719
	LOSS [training: 0.44077590511226905 | validation: 0.49278025052010627]
	TIME [epoch: 7.62 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49583421620682294		[learning rate: 0.019715]
	Learning Rate: 0.0197151
	LOSS [training: 0.49583421620682294 | validation: 0.3366358340875043]
	TIME [epoch: 7.62 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4087572168588298		[learning rate: 0.019711]
	Learning Rate: 0.0197112
	LOSS [training: 0.4087572168588298 | validation: 0.36042244932878836]
	TIME [epoch: 7.64 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41531411401912216		[learning rate: 0.019707]
	Learning Rate: 0.0197072
	LOSS [training: 0.41531411401912216 | validation: 0.3134055814013643]
	TIME [epoch: 7.7 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3733921437252299		[learning rate: 0.019703]
	Learning Rate: 0.0197032
	LOSS [training: 0.3733921437252299 | validation: 0.3959226790325252]
	TIME [epoch: 7.65 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4388885528932007		[learning rate: 0.019699]
	Learning Rate: 0.0196992
	LOSS [training: 0.4388885528932007 | validation: 0.4559778103248361]
	TIME [epoch: 7.63 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4291334016607985		[learning rate: 0.019695]
	Learning Rate: 0.0196952
	LOSS [training: 0.4291334016607985 | validation: 0.5127691345248969]
	TIME [epoch: 7.62 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41846775727464414		[learning rate: 0.019691]
	Learning Rate: 0.0196911
	LOSS [training: 0.41846775727464414 | validation: 0.33155384395298526]
	TIME [epoch: 129 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4060955294941376		[learning rate: 0.019687]
	Learning Rate: 0.019687
	LOSS [training: 0.4060955294941376 | validation: 0.346931987104692]
	TIME [epoch: 14.9 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3839841536501796		[learning rate: 0.019683]
	Learning Rate: 0.0196829
	LOSS [training: 0.3839841536501796 | validation: 0.3341283180657998]
	TIME [epoch: 14.9 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5017742022962135		[learning rate: 0.019679]
	Learning Rate: 0.0196788
	LOSS [training: 0.5017742022962135 | validation: 0.3223209520914784]
	TIME [epoch: 14.9 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3890374050029598		[learning rate: 0.019675]
	Learning Rate: 0.0196746
	LOSS [training: 0.3890374050029598 | validation: 0.627988507570779]
	TIME [epoch: 14.9 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4415102657922564		[learning rate: 0.01967]
	Learning Rate: 0.0196704
	LOSS [training: 0.4415102657922564 | validation: 0.33237365477242553]
	TIME [epoch: 14.9 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3554115581713146		[learning rate: 0.019666]
	Learning Rate: 0.0196662
	LOSS [training: 0.3554115581713146 | validation: 0.3380105471540355]
	TIME [epoch: 14.9 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3596534546841106		[learning rate: 0.019662]
	Learning Rate: 0.0196619
	LOSS [training: 0.3596534546841106 | validation: 0.3371931373478503]
	TIME [epoch: 14.9 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3720746410533913		[learning rate: 0.019658]
	Learning Rate: 0.0196576
	LOSS [training: 0.3720746410533913 | validation: 0.34957722116034784]
	TIME [epoch: 14.9 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41344252467621023		[learning rate: 0.019653]
	Learning Rate: 0.0196533
	LOSS [training: 0.41344252467621023 | validation: 0.3378862238158574]
	TIME [epoch: 14.9 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.483439197390203		[learning rate: 0.019649]
	Learning Rate: 0.019649
	LOSS [training: 0.483439197390203 | validation: 0.3916863176172428]
	TIME [epoch: 14.9 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36794786429274196		[learning rate: 0.019645]
	Learning Rate: 0.0196447
	LOSS [training: 0.36794786429274196 | validation: 0.3647345259890499]
	TIME [epoch: 14.9 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3683697336231771		[learning rate: 0.01964]
	Learning Rate: 0.0196403
	LOSS [training: 0.3683697336231771 | validation: 0.35630749326455013]
	TIME [epoch: 14.9 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4190547590717685		[learning rate: 0.019636]
	Learning Rate: 0.0196359
	LOSS [training: 0.4190547590717685 | validation: 0.50342780177659]
	TIME [epoch: 14.9 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3975774813348677		[learning rate: 0.019631]
	Learning Rate: 0.0196314
	LOSS [training: 0.3975774813348677 | validation: 0.3430401971907553]
	TIME [epoch: 14.9 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37912834156023023		[learning rate: 0.019627]
	Learning Rate: 0.019627
	LOSS [training: 0.37912834156023023 | validation: 0.4488466814545148]
	TIME [epoch: 14.9 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.439972627443551		[learning rate: 0.019622]
	Learning Rate: 0.0196225
	LOSS [training: 0.439972627443551 | validation: 0.2849584567613823]
	TIME [epoch: 14.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_217.pth
	Model improved!!!
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36361314294166847		[learning rate: 0.019618]
	Learning Rate: 0.019618
	LOSS [training: 0.36361314294166847 | validation: 0.34969007150200626]
	TIME [epoch: 14.9 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3771315029574027		[learning rate: 0.019613]
	Learning Rate: 0.0196134
	LOSS [training: 0.3771315029574027 | validation: 0.3359138776405135]
	TIME [epoch: 14.9 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3809837082903721		[learning rate: 0.019609]
	Learning Rate: 0.0196089
	LOSS [training: 0.3809837082903721 | validation: 0.37830834304301353]
	TIME [epoch: 14.9 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37448450779975667		[learning rate: 0.019604]
	Learning Rate: 0.0196043
	LOSS [training: 0.37448450779975667 | validation: 0.36301261067915536]
	TIME [epoch: 14.9 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32663083255853986		[learning rate: 0.0196]
	Learning Rate: 0.0195997
	LOSS [training: 0.32663083255853986 | validation: 0.29289790254598624]
	TIME [epoch: 14.9 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35270234183180826		[learning rate: 0.019595]
	Learning Rate: 0.019595
	LOSS [training: 0.35270234183180826 | validation: 0.27561314976046114]
	TIME [epoch: 14.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_223.pth
	Model improved!!!
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38929615336669465		[learning rate: 0.01959]
	Learning Rate: 0.0195904
	LOSS [training: 0.38929615336669465 | validation: 0.2655244659421122]
	TIME [epoch: 14.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_224.pth
	Model improved!!!
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38519197853372156		[learning rate: 0.019586]
	Learning Rate: 0.0195857
	LOSS [training: 0.38519197853372156 | validation: 0.36494299442060707]
	TIME [epoch: 14.9 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3540056051250987		[learning rate: 0.019581]
	Learning Rate: 0.0195809
	LOSS [training: 0.3540056051250987 | validation: 0.25058159843301525]
	TIME [epoch: 15.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_226.pth
	Model improved!!!
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31442378112835523		[learning rate: 0.019576]
	Learning Rate: 0.0195762
	LOSS [training: 0.31442378112835523 | validation: 0.37228439392595397]
	TIME [epoch: 15.1 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3621584941781075		[learning rate: 0.019571]
	Learning Rate: 0.0195714
	LOSS [training: 0.3621584941781075 | validation: 0.4403988168143115]
	TIME [epoch: 15.1 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36879549411711743		[learning rate: 0.019567]
	Learning Rate: 0.0195666
	LOSS [training: 0.36879549411711743 | validation: 0.23024484482370972]
	TIME [epoch: 15.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_229.pth
	Model improved!!!
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3478664308638557		[learning rate: 0.019562]
	Learning Rate: 0.0195618
	LOSS [training: 0.3478664308638557 | validation: 0.2483277754662997]
	TIME [epoch: 15.1 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3582052616843607		[learning rate: 0.019557]
	Learning Rate: 0.0195569
	LOSS [training: 0.3582052616843607 | validation: 0.2541326026848342]
	TIME [epoch: 15.2 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3442566803411143		[learning rate: 0.019552]
	Learning Rate: 0.0195521
	LOSS [training: 0.3442566803411143 | validation: 0.3596983332284187]
	TIME [epoch: 15.1 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34109938494067205		[learning rate: 0.019547]
	Learning Rate: 0.0195472
	LOSS [training: 0.34109938494067205 | validation: 0.355218206977468]
	TIME [epoch: 15.1 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32447074925989017		[learning rate: 0.019542]
	Learning Rate: 0.0195422
	LOSS [training: 0.32447074925989017 | validation: 0.3189524515514657]
	TIME [epoch: 15.2 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3484452372343091		[learning rate: 0.019537]
	Learning Rate: 0.0195373
	LOSS [training: 0.3484452372343091 | validation: 0.4853741741601032]
	TIME [epoch: 15.1 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3724035707202097		[learning rate: 0.019532]
	Learning Rate: 0.0195323
	LOSS [training: 0.3724035707202097 | validation: 0.2660061606106048]
	TIME [epoch: 15 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2936111494604995		[learning rate: 0.019527]
	Learning Rate: 0.0195273
	LOSS [training: 0.2936111494604995 | validation: 0.45720795882765397]
	TIME [epoch: 15.2 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34745976509758847		[learning rate: 0.019522]
	Learning Rate: 0.0195222
	LOSS [training: 0.34745976509758847 | validation: 0.46685528930497233]
	TIME [epoch: 15.1 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3710669618059352		[learning rate: 0.019517]
	Learning Rate: 0.0195172
	LOSS [training: 0.3710669618059352 | validation: 0.2939480710876333]
	TIME [epoch: 15.1 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31961566469401964		[learning rate: 0.019512]
	Learning Rate: 0.0195121
	LOSS [training: 0.31961566469401964 | validation: 0.33240871639610103]
	TIME [epoch: 15.1 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30976694847040087		[learning rate: 0.019507]
	Learning Rate: 0.019507
	LOSS [training: 0.30976694847040087 | validation: 0.3640781127164001]
	TIME [epoch: 15 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33933663844788625		[learning rate: 0.019502]
	Learning Rate: 0.0195018
	LOSS [training: 0.33933663844788625 | validation: 0.25977445432105956]
	TIME [epoch: 15.1 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30385146544686625		[learning rate: 0.019497]
	Learning Rate: 0.0194967
	LOSS [training: 0.30385146544686625 | validation: 0.3045842977487083]
	TIME [epoch: 15.1 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32212369860930234		[learning rate: 0.019491]
	Learning Rate: 0.0194915
	LOSS [training: 0.32212369860930234 | validation: 0.28496150509472085]
	TIME [epoch: 15 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3518505531395134		[learning rate: 0.019486]
	Learning Rate: 0.0194863
	LOSS [training: 0.3518505531395134 | validation: 0.30883277072454296]
	TIME [epoch: 15.1 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.370492985630323		[learning rate: 0.019481]
	Learning Rate: 0.019481
	LOSS [training: 0.370492985630323 | validation: 0.2711622105870479]
	TIME [epoch: 15 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3254478495210866		[learning rate: 0.019476]
	Learning Rate: 0.0194757
	LOSS [training: 0.3254478495210866 | validation: 0.23637478163189263]
	TIME [epoch: 15.1 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2907325499205462		[learning rate: 0.01947]
	Learning Rate: 0.0194705
	LOSS [training: 0.2907325499205462 | validation: 0.25403891993402117]
	TIME [epoch: 15.2 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3174823025139285		[learning rate: 0.019465]
	Learning Rate: 0.0194651
	LOSS [training: 0.3174823025139285 | validation: 0.2386978929066987]
	TIME [epoch: 15.1 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3135564131372253		[learning rate: 0.01946]
	Learning Rate: 0.0194598
	LOSS [training: 0.3135564131372253 | validation: 0.322739580607318]
	TIME [epoch: 15.1 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32659855423594825		[learning rate: 0.019454]
	Learning Rate: 0.0194544
	LOSS [training: 0.32659855423594825 | validation: 0.3201289959257785]
	TIME [epoch: 15.2 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36284527608142475		[learning rate: 0.019449]
	Learning Rate: 0.019449
	LOSS [training: 0.36284527608142475 | validation: 0.2941904882125066]
	TIME [epoch: 15.1 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26202599151645645		[learning rate: 0.019444]
	Learning Rate: 0.0194436
	LOSS [training: 0.26202599151645645 | validation: 0.2179286059217058]
	TIME [epoch: 15.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_253.pth
	Model improved!!!
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31133027447706485		[learning rate: 0.019438]
	Learning Rate: 0.0194381
	LOSS [training: 0.31133027447706485 | validation: 0.2715327430268254]
	TIME [epoch: 15.1 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27388833338309304		[learning rate: 0.019433]
	Learning Rate: 0.0194327
	LOSS [training: 0.27388833338309304 | validation: 0.2629291120843249]
	TIME [epoch: 15.1 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3919023731721881		[learning rate: 0.019427]
	Learning Rate: 0.0194272
	LOSS [training: 0.3919023731721881 | validation: 1.1437331321279118]
	TIME [epoch: 15.2 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.257504717301861		[learning rate: 0.019422]
	Learning Rate: 0.0194216
	LOSS [training: 1.257504717301861 | validation: 1.686392866459404]
	TIME [epoch: 15.1 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1335782338812253		[learning rate: 0.019416]
	Learning Rate: 0.0194161
	LOSS [training: 1.1335782338812253 | validation: 1.5130626060826693]
	TIME [epoch: 15.1 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9280653838884967		[learning rate: 0.019411]
	Learning Rate: 0.0194105
	LOSS [training: 0.9280653838884967 | validation: 1.3805204860787077]
	TIME [epoch: 15.2 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8251881136073879		[learning rate: 0.019405]
	Learning Rate: 0.0194049
	LOSS [training: 0.8251881136073879 | validation: 1.2224420253392378]
	TIME [epoch: 15.1 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7426827964169787		[learning rate: 0.019399]
	Learning Rate: 0.0193993
	LOSS [training: 0.7426827964169787 | validation: 1.073695939424772]
	TIME [epoch: 15.1 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1976729825720613		[learning rate: 0.019394]
	Learning Rate: 0.0193936
	LOSS [training: 1.1976729825720613 | validation: 1.6083306272431503]
	TIME [epoch: 15.2 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9734274031818886		[learning rate: 0.019388]
	Learning Rate: 0.0193879
	LOSS [training: 0.9734274031818886 | validation: 1.2623760845238858]
	TIME [epoch: 15.1 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7830863270200583		[learning rate: 0.019382]
	Learning Rate: 0.0193822
	LOSS [training: 0.7830863270200583 | validation: 1.080054886692119]
	TIME [epoch: 15.2 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6062332651261692		[learning rate: 0.019376]
	Learning Rate: 0.0193765
	LOSS [training: 0.6062332651261692 | validation: 0.5611682050205296]
	TIME [epoch: 15.1 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.441101591057928		[learning rate: 0.019371]
	Learning Rate: 0.0193707
	LOSS [training: 0.441101591057928 | validation: 0.7159486533036051]
	TIME [epoch: 15.1 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0727894790542514		[learning rate: 0.019365]
	Learning Rate: 0.0193649
	LOSS [training: 1.0727894790542514 | validation: 1.5440892411925515]
	TIME [epoch: 15.2 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.79745756707364		[learning rate: 0.019359]
	Learning Rate: 0.0193591
	LOSS [training: 1.79745756707364 | validation: 1.5361911989988388]
	TIME [epoch: 15.1 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8693982724492733		[learning rate: 0.019353]
	Learning Rate: 0.0193533
	LOSS [training: 1.8693982724492733 | validation: 2.4606113138648356]
	TIME [epoch: 15.1 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.755007609785396		[learning rate: 0.019347]
	Learning Rate: 0.0193474
	LOSS [training: 2.755007609785396 | validation: 2.4304271264506867]
	TIME [epoch: 15.2 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0045792734735963		[learning rate: 0.019342]
	Learning Rate: 0.0193416
	LOSS [training: 3.0045792734735963 | validation: 3.7855161350599014]
	TIME [epoch: 15.1 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9865859766649177		[learning rate: 0.019336]
	Learning Rate: 0.0193356
	LOSS [training: 2.9865859766649177 | validation: 1.12890677298731]
	TIME [epoch: 15.1 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7672511439223828		[learning rate: 0.01933]
	Learning Rate: 0.0193297
	LOSS [training: 0.7672511439223828 | validation: 0.7108149285076055]
	TIME [epoch: 15.2 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.596606307392616		[learning rate: 0.019324]
	Learning Rate: 0.0193237
	LOSS [training: 0.596606307392616 | validation: 0.5593696029770591]
	TIME [epoch: 15.1 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.511539800232817		[learning rate: 0.019318]
	Learning Rate: 0.0193178
	LOSS [training: 0.511539800232817 | validation: 0.4970761255028471]
	TIME [epoch: 15.1 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43445596204641457		[learning rate: 0.019312]
	Learning Rate: 0.0193117
	LOSS [training: 0.43445596204641457 | validation: 0.6105845178756064]
	TIME [epoch: 15.2 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4936582504670891		[learning rate: 0.019306]
	Learning Rate: 0.0193057
	LOSS [training: 0.4936582504670891 | validation: 0.5040420368722069]
	TIME [epoch: 15.1 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4358263610591083		[learning rate: 0.0193]
	Learning Rate: 0.0192996
	LOSS [training: 0.4358263610591083 | validation: 0.4876223192673888]
	TIME [epoch: 15.2 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4285681028865574		[learning rate: 0.019294]
	Learning Rate: 0.0192935
	LOSS [training: 0.4285681028865574 | validation: 0.47280888873149274]
	TIME [epoch: 15.1 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3749247089806482		[learning rate: 0.019287]
	Learning Rate: 0.0192874
	LOSS [training: 0.3749247089806482 | validation: 0.4357457090624389]
	TIME [epoch: 15.1 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3688536283005262		[learning rate: 0.019281]
	Learning Rate: 0.0192813
	LOSS [training: 0.3688536283005262 | validation: 0.4189814740509864]
	TIME [epoch: 15.2 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35309901790062903		[learning rate: 0.019275]
	Learning Rate: 0.0192751
	LOSS [training: 0.35309901790062903 | validation: 0.3682115695247762]
	TIME [epoch: 15.1 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32583711310783037		[learning rate: 0.019269]
	Learning Rate: 0.0192689
	LOSS [training: 0.32583711310783037 | validation: 0.3953472262102011]
	TIME [epoch: 15.1 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38817888931549377		[learning rate: 0.019263]
	Learning Rate: 0.0192627
	LOSS [training: 0.38817888931549377 | validation: 0.5756318103086879]
	TIME [epoch: 15.2 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39809204217073313		[learning rate: 0.019256]
	Learning Rate: 0.0192565
	LOSS [training: 0.39809204217073313 | validation: 0.5086443997795753]
	TIME [epoch: 15.1 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8592944002149363		[learning rate: 0.01925]
	Learning Rate: 0.0192502
	LOSS [training: 1.8592944002149363 | validation: 1.1723045269325851]
	TIME [epoch: 15.1 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3562363663147414		[learning rate: 0.019244]
	Learning Rate: 0.0192439
	LOSS [training: 1.3562363663147414 | validation: 0.6393812169181236]
	TIME [epoch: 15 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5651176798242242		[learning rate: 0.019238]
	Learning Rate: 0.0192376
	LOSS [training: 0.5651176798242242 | validation: 0.3920857308108909]
	TIME [epoch: 14.9 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3439392661149873		[learning rate: 0.019231]
	Learning Rate: 0.0192313
	LOSS [training: 0.3439392661149873 | validation: 0.3951457946798551]
	TIME [epoch: 15 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35700628765989406		[learning rate: 0.019225]
	Learning Rate: 0.0192249
	LOSS [training: 0.35700628765989406 | validation: 0.34580995502456396]
	TIME [epoch: 15.1 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30156346382815596		[learning rate: 0.019218]
	Learning Rate: 0.0192185
	LOSS [training: 0.30156346382815596 | validation: 0.34442318916394965]
	TIME [epoch: 15.1 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31987026974493427		[learning rate: 0.019212]
	Learning Rate: 0.0192121
	LOSS [training: 0.31987026974493427 | validation: 0.38093040777517917]
	TIME [epoch: 15.2 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3262075309885659		[learning rate: 0.019206]
	Learning Rate: 0.0192056
	LOSS [training: 0.3262075309885659 | validation: 0.3311511289864182]
	TIME [epoch: 15.1 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3334928552925235		[learning rate: 0.019199]
	Learning Rate: 0.0191992
	LOSS [training: 0.3334928552925235 | validation: 0.4079081560158836]
	TIME [epoch: 15.1 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36915155883473816		[learning rate: 0.019193]
	Learning Rate: 0.0191927
	LOSS [training: 0.36915155883473816 | validation: 0.2966897241310591]
	TIME [epoch: 15.1 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31424919494258874		[learning rate: 0.019186]
	Learning Rate: 0.0191861
	LOSS [training: 0.31424919494258874 | validation: 0.36310289587332467]
	TIME [epoch: 15.1 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4658248026589241		[learning rate: 0.01918]
	Learning Rate: 0.0191796
	LOSS [training: 0.4658248026589241 | validation: 0.37484825888022866]
	TIME [epoch: 15.1 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3368489536259457		[learning rate: 0.019173]
	Learning Rate: 0.019173
	LOSS [training: 0.3368489536259457 | validation: 0.38496657272685]
	TIME [epoch: 15.2 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3446615064327005		[learning rate: 0.019166]
	Learning Rate: 0.0191664
	LOSS [training: 0.3446615064327005 | validation: 0.4003639000105115]
	TIME [epoch: 15.1 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3461632974641474		[learning rate: 0.01916]
	Learning Rate: 0.0191598
	LOSS [training: 0.3461632974641474 | validation: 0.3780359575695102]
	TIME [epoch: 15.2 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3422852684347899		[learning rate: 0.019153]
	Learning Rate: 0.0191532
	LOSS [training: 0.3422852684347899 | validation: 0.4268473588455256]
	TIME [epoch: 15.1 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35451539111949654		[learning rate: 0.019146]
	Learning Rate: 0.0191465
	LOSS [training: 0.35451539111949654 | validation: 0.33546466274044523]
	TIME [epoch: 15.1 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3175101255164565		[learning rate: 0.01914]
	Learning Rate: 0.0191398
	LOSS [training: 0.3175101255164565 | validation: 0.28441834267163957]
	TIME [epoch: 15.2 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3983658324465228		[learning rate: 0.019133]
	Learning Rate: 0.0191331
	LOSS [training: 0.3983658324465228 | validation: 0.39265971888939744]
	TIME [epoch: 15.1 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3300010096675059		[learning rate: 0.019126]
	Learning Rate: 0.0191263
	LOSS [training: 0.3300010096675059 | validation: 0.41299478777017407]
	TIME [epoch: 15.1 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3684068432553186		[learning rate: 0.01912]
	Learning Rate: 0.0191196
	LOSS [training: 0.3684068432553186 | validation: 0.33386861081480823]
	TIME [epoch: 15.2 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3466805075385341		[learning rate: 0.019113]
	Learning Rate: 0.0191128
	LOSS [training: 0.3466805075385341 | validation: 0.36634054647188163]
	TIME [epoch: 15.1 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3214567845448		[learning rate: 0.019106]
	Learning Rate: 0.019106
	LOSS [training: 0.3214567845448 | validation: 0.30909888313376677]
	TIME [epoch: 15.1 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35564809133260056		[learning rate: 0.019099]
	Learning Rate: 0.0190991
	LOSS [training: 0.35564809133260056 | validation: 0.3013078865009283]
	TIME [epoch: 15.2 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3444321026814394		[learning rate: 0.019092]
	Learning Rate: 0.0190922
	LOSS [training: 0.3444321026814394 | validation: 0.549012286641225]
	TIME [epoch: 15.1 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3889381538171996		[learning rate: 0.019085]
	Learning Rate: 0.0190853
	LOSS [training: 0.3889381538171996 | validation: 0.216997772333266]
	TIME [epoch: 15.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_311.pth
	Model improved!!!
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29536019978712624		[learning rate: 0.019078]
	Learning Rate: 0.0190784
	LOSS [training: 0.29536019978712624 | validation: 0.3347680155898083]
	TIME [epoch: 15.1 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32560436067117837		[learning rate: 0.019071]
	Learning Rate: 0.0190715
	LOSS [training: 0.32560436067117837 | validation: 0.3946907840056787]
	TIME [epoch: 15.1 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3371074980918601		[learning rate: 0.019065]
	Learning Rate: 0.0190645
	LOSS [training: 0.3371074980918601 | validation: 0.2601628300441051]
	TIME [epoch: 15.1 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33153683720352356		[learning rate: 0.019058]
	Learning Rate: 0.0190575
	LOSS [training: 0.33153683720352356 | validation: 0.34489514462529636]
	TIME [epoch: 15.1 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3956791906793422		[learning rate: 0.019051]
	Learning Rate: 0.0190505
	LOSS [training: 0.3956791906793422 | validation: 0.3584336235869718]
	TIME [epoch: 15.1 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3221295845305817		[learning rate: 0.019043]
	Learning Rate: 0.0190435
	LOSS [training: 0.3221295845305817 | validation: 0.2178635205645711]
	TIME [epoch: 15.1 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3245631346458339		[learning rate: 0.019036]
	Learning Rate: 0.0190364
	LOSS [training: 0.3245631346458339 | validation: 0.2735343628482808]
	TIME [epoch: 15.1 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3649698174813358		[learning rate: 0.019029]
	Learning Rate: 0.0190293
	LOSS [training: 1.3649698174813358 | validation: 3.0260918440187514]
	TIME [epoch: 15.1 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5305867449088122		[learning rate: 0.019022]
	Learning Rate: 0.0190222
	LOSS [training: 1.5305867449088122 | validation: 0.7389706790295013]
	TIME [epoch: 15.1 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49749583631561795		[learning rate: 0.019015]
	Learning Rate: 0.019015
	LOSS [training: 0.49749583631561795 | validation: 0.399651541878014]
	TIME [epoch: 15.1 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31906826732513194		[learning rate: 0.019008]
	Learning Rate: 0.0190079
	LOSS [training: 0.31906826732513194 | validation: 0.32503551057015845]
	TIME [epoch: 15.2 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29828639695054293		[learning rate: 0.019001]
	Learning Rate: 0.0190007
	LOSS [training: 0.29828639695054293 | validation: 0.3105955944893941]
	TIME [epoch: 15.1 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29800599942413925		[learning rate: 0.018993]
	Learning Rate: 0.0189935
	LOSS [training: 0.29800599942413925 | validation: 0.300225678052754]
	TIME [epoch: 15.1 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.298573378299161		[learning rate: 0.018986]
	Learning Rate: 0.0189862
	LOSS [training: 0.298573378299161 | validation: 0.3024331533614093]
	TIME [epoch: 15.2 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2890216328988506		[learning rate: 0.018979]
	Learning Rate: 0.018979
	LOSS [training: 0.2890216328988506 | validation: 0.29931927755862875]
	TIME [epoch: 15.1 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29773946635371007		[learning rate: 0.018972]
	Learning Rate: 0.0189717
	LOSS [training: 0.29773946635371007 | validation: 0.3003761128875607]
	TIME [epoch: 15.1 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2954079917668001		[learning rate: 0.018964]
	Learning Rate: 0.0189644
	LOSS [training: 0.2954079917668001 | validation: 0.37499782460027054]
	TIME [epoch: 15.1 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3236979813403724		[learning rate: 0.018957]
	Learning Rate: 0.018957
	LOSS [training: 0.3236979813403724 | validation: 0.32721061540268576]
	TIME [epoch: 15.1 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31391113160539735		[learning rate: 0.01895]
	Learning Rate: 0.0189497
	LOSS [training: 0.31391113160539735 | validation: 0.2988178069277809]
	TIME [epoch: 15.2 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29874946008249104		[learning rate: 0.018942]
	Learning Rate: 0.0189423
	LOSS [training: 0.29874946008249104 | validation: 0.39446071847962194]
	TIME [epoch: 15.1 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31146544144052113		[learning rate: 0.018935]
	Learning Rate: 0.0189349
	LOSS [training: 0.31146544144052113 | validation: 0.47177399658031777]
	TIME [epoch: 15.1 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32770245650135943		[learning rate: 0.018927]
	Learning Rate: 0.0189274
	LOSS [training: 0.32770245650135943 | validation: 0.3682874126243707]
	TIME [epoch: 15.2 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3301030634468817		[learning rate: 0.01892]
	Learning Rate: 0.01892
	LOSS [training: 0.3301030634468817 | validation: 0.3269084749611285]
	TIME [epoch: 15.1 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3249673054281682		[learning rate: 0.018912]
	Learning Rate: 0.0189125
	LOSS [training: 0.3249673054281682 | validation: 0.37560715422743784]
	TIME [epoch: 15.1 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3276286733239034		[learning rate: 0.018905]
	Learning Rate: 0.018905
	LOSS [training: 0.3276286733239034 | validation: 0.42507446048724706]
	TIME [epoch: 15.1 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29206504575662123		[learning rate: 0.018897]
	Learning Rate: 0.0188974
	LOSS [training: 0.29206504575662123 | validation: 0.3469955320543912]
	TIME [epoch: 15.1 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27670290960266397		[learning rate: 0.01889]
	Learning Rate: 0.0188899
	LOSS [training: 0.27670290960266397 | validation: 0.3567391610646776]
	TIME [epoch: 15.2 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3183656887103627		[learning rate: 0.018882]
	Learning Rate: 0.0188823
	LOSS [training: 0.3183656887103627 | validation: 0.2739607987386145]
	TIME [epoch: 15.1 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27765311429510126		[learning rate: 0.018875]
	Learning Rate: 0.0188747
	LOSS [training: 0.27765311429510126 | validation: 0.34648005306696633]
	TIME [epoch: 15.1 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2915862869097362		[learning rate: 0.018867]
	Learning Rate: 0.0188671
	LOSS [training: 0.2915862869097362 | validation: 0.5942473742250576]
	TIME [epoch: 15.2 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5445886824688995		[learning rate: 0.018859]
	Learning Rate: 0.0188594
	LOSS [training: 0.5445886824688995 | validation: 1.7407012010526985]
	TIME [epoch: 15.1 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7623623608094767		[learning rate: 0.018852]
	Learning Rate: 0.0188517
	LOSS [training: 1.7623623608094767 | validation: 2.7412819912904074]
	TIME [epoch: 15.2 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.582946414051553		[learning rate: 0.018844]
	Learning Rate: 0.018844
	LOSS [training: 2.582946414051553 | validation: 2.872102132116651]
	TIME [epoch: 15.1 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.713812980401653		[learning rate: 0.018836]
	Learning Rate: 0.0188363
	LOSS [training: 2.713812980401653 | validation: 3.1697331014458054]
	TIME [epoch: 15.1 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.578760493309449		[learning rate: 0.018829]
	Learning Rate: 0.0188286
	LOSS [training: 3.578760493309449 | validation: 5.43423355328102]
	TIME [epoch: 15.1 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.305900206739887		[learning rate: 0.018821]
	Learning Rate: 0.0188208
	LOSS [training: 4.305900206739887 | validation: 4.1790296248714505]
	TIME [epoch: 15.1 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.990666522009015		[learning rate: 0.018813]
	Learning Rate: 0.018813
	LOSS [training: 3.990666522009015 | validation: 4.466898294164457]
	TIME [epoch: 15.1 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.209083645591587		[learning rate: 0.018805]
	Learning Rate: 0.0188052
	LOSS [training: 4.209083645591587 | validation: 3.7459619353650133]
	TIME [epoch: 15.1 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4693138631133755		[learning rate: 0.018797]
	Learning Rate: 0.0187973
	LOSS [training: 3.4693138631133755 | validation: 3.478793466910097]
	TIME [epoch: 15.1 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465503070510782		[learning rate: 0.018789]
	Learning Rate: 0.0187894
	LOSS [training: 4.465503070510782 | validation: 6.985067951107703]
	TIME [epoch: 15.2 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.076939193079385		[learning rate: 0.018782]
	Learning Rate: 0.0187815
	LOSS [training: 7.076939193079385 | validation: 7.071791181098238]
	TIME [epoch: 15.1 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.1427337467508		[learning rate: 0.018774]
	Learning Rate: 0.0187736
	LOSS [training: 7.1427337467508 | validation: 7.114440185468348]
	TIME [epoch: 15.1 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.3834521588756035		[learning rate: 0.018766]
	Learning Rate: 0.0187657
	LOSS [training: 6.3834521588756035 | validation: 4.841499564729043]
	TIME [epoch: 15.2 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.314094859182342		[learning rate: 0.018758]
	Learning Rate: 0.0187577
	LOSS [training: 4.314094859182342 | validation: 3.758048358790799]
	TIME [epoch: 15.1 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3530756069234915		[learning rate: 0.01875]
	Learning Rate: 0.0187497
	LOSS [training: 4.3530756069234915 | validation: 6.544121457341074]
	TIME [epoch: 15.2 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.875632287385912		[learning rate: 0.018742]
	Learning Rate: 0.0187417
	LOSS [training: 6.875632287385912 | validation: 6.946277291782538]
	TIME [epoch: 15.1 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.067581674394113		[learning rate: 0.018734]
	Learning Rate: 0.0187337
	LOSS [training: 7.067581674394113 | validation: 6.801959025976883]
	TIME [epoch: 15.1 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.615136707889987		[learning rate: 0.018726]
	Learning Rate: 0.0187256
	LOSS [training: 6.615136707889987 | validation: 3.8849872203410407]
	TIME [epoch: 15.2 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6439694681318775		[learning rate: 0.018718]
	Learning Rate: 0.0187175
	LOSS [training: 3.6439694681318775 | validation: 2.7903529641713734]
	TIME [epoch: 15.1 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.225060605083727		[learning rate: 0.018709]
	Learning Rate: 0.0187094
	LOSS [training: 2.225060605083727 | validation: 2.5361278823570306]
	TIME [epoch: 15.1 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.415839993076472		[learning rate: 0.018701]
	Learning Rate: 0.0187013
	LOSS [training: 2.415839993076472 | validation: 3.357963163180419]
	TIME [epoch: 15.1 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0850795729549216		[learning rate: 0.018693]
	Learning Rate: 0.0186931
	LOSS [training: 3.0850795729549216 | validation: 3.464734997720538]
	TIME [epoch: 15.1 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.882263584961356		[learning rate: 0.018685]
	Learning Rate: 0.0186849
	LOSS [training: 2.882263584961356 | validation: 3.3282277200904424]
	TIME [epoch: 15.2 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.000894942309426		[learning rate: 0.018677]
	Learning Rate: 0.0186767
	LOSS [training: 3.000894942309426 | validation: 3.418016910223696]
	TIME [epoch: 15.1 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8053284166053647		[learning rate: 0.018668]
	Learning Rate: 0.0186685
	LOSS [training: 2.8053284166053647 | validation: 3.0164646618333952]
	TIME [epoch: 15.1 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.695182797308029		[learning rate: 0.01866]
	Learning Rate: 0.0186602
	LOSS [training: 2.695182797308029 | validation: 2.862723238062199]
	TIME [epoch: 15.2 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3931517151795574		[learning rate: 0.018652]
	Learning Rate: 0.018652
	LOSS [training: 2.3931517151795574 | validation: 2.7961291950359946]
	TIME [epoch: 15.9 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3645689459550456		[learning rate: 0.018644]
	Learning Rate: 0.0186437
	LOSS [training: 2.3645689459550456 | validation: 2.561446795974703]
	TIME [epoch: 15.1 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2944772273319978		[learning rate: 0.018635]
	Learning Rate: 0.0186353
	LOSS [training: 2.2944772273319978 | validation: 2.510841920927314]
	TIME [epoch: 15.1 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2410669072800005		[learning rate: 0.018627]
	Learning Rate: 0.018627
	LOSS [training: 2.2410669072800005 | validation: 2.4403764551005054]
	TIME [epoch: 15.1 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.280198759828555		[learning rate: 0.018619]
	Learning Rate: 0.0186186
	LOSS [training: 2.280198759828555 | validation: 2.0689293349921023]
	TIME [epoch: 15.2 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.622949366989713		[learning rate: 0.01861]
	Learning Rate: 0.0186102
	LOSS [training: 2.622949366989713 | validation: 4.690693321480862]
	TIME [epoch: 15.1 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3046540743608563		[learning rate: 0.018602]
	Learning Rate: 0.0186018
	LOSS [training: 3.3046540743608563 | validation: 2.5813160107169146]
	TIME [epoch: 15.1 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2413109418754855		[learning rate: 0.018593]
	Learning Rate: 0.0185934
	LOSS [training: 2.2413109418754855 | validation: 2.505842707855214]
	TIME [epoch: 15.2 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1731097105596557		[learning rate: 0.018585]
	Learning Rate: 0.0185849
	LOSS [training: 2.1731097105596557 | validation: 2.4521881063500173]
	TIME [epoch: 15.1 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1320994599560814		[learning rate: 0.018576]
	Learning Rate: 0.0185764
	LOSS [training: 2.1320994599560814 | validation: 2.402165460518442]
	TIME [epoch: 15.1 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0969246651950075		[learning rate: 0.018568]
	Learning Rate: 0.0185679
	LOSS [training: 2.0969246651950075 | validation: 2.3212900414025253]
	TIME [epoch: 15.2 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0587082889511934		[learning rate: 0.018559]
	Learning Rate: 0.0185594
	LOSS [training: 2.0587082889511934 | validation: 2.3188819500723272]
	TIME [epoch: 15.1 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.031913964718324		[learning rate: 0.018551]
	Learning Rate: 0.0185508
	LOSS [training: 2.031913964718324 | validation: 2.254186502381325]
	TIME [epoch: 15.2 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0039457446078437		[learning rate: 0.018542]
	Learning Rate: 0.0185422
	LOSS [training: 2.0039457446078437 | validation: 2.224265767788638]
	TIME [epoch: 15.1 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.95045231253504		[learning rate: 0.018534]
	Learning Rate: 0.0185336
	LOSS [training: 1.95045231253504 | validation: 2.0657420334647063]
	TIME [epoch: 15.1 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.55589918645235		[learning rate: 0.018525]
	Learning Rate: 0.018525
	LOSS [training: 1.55589918645235 | validation: 1.1376512397559182]
	TIME [epoch: 15.2 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2945915416108429		[learning rate: 0.018516]
	Learning Rate: 0.0185163
	LOSS [training: 1.2945915416108429 | validation: 1.045875388551754]
	TIME [epoch: 15.1 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2121132465695095		[learning rate: 0.018508]
	Learning Rate: 0.0185077
	LOSS [training: 1.2121132465695095 | validation: 1.1143206647510024]
	TIME [epoch: 15.1 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.26461335759074		[learning rate: 0.018499]
	Learning Rate: 0.018499
	LOSS [training: 1.26461335759074 | validation: 1.0027164351256446]
	TIME [epoch: 15.1 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2066419416283032		[learning rate: 0.01849]
	Learning Rate: 0.0184902
	LOSS [training: 1.2066419416283032 | validation: 0.9602132279773066]
	TIME [epoch: 15.1 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.454565521067689		[learning rate: 0.018481]
	Learning Rate: 0.0184815
	LOSS [training: 1.454565521067689 | validation: 1.907734815971195]
	TIME [epoch: 15.1 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.582002950968786		[learning rate: 0.018473]
	Learning Rate: 0.0184727
	LOSS [training: 1.582002950968786 | validation: 0.9964985645858017]
	TIME [epoch: 15.1 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6349455580885224		[learning rate: 0.018464]
	Learning Rate: 0.0184639
	LOSS [training: 1.6349455580885224 | validation: 2.099107539136342]
	TIME [epoch: 15.1 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3477596709269488		[learning rate: 0.018455]
	Learning Rate: 0.0184551
	LOSS [training: 1.3477596709269488 | validation: 1.0654805123668252]
	TIME [epoch: 15.2 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.084346447833216		[learning rate: 0.018446]
	Learning Rate: 0.0184463
	LOSS [training: 1.084346447833216 | validation: 0.9750715391285397]
	TIME [epoch: 15.1 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1441199463084035		[learning rate: 0.018437]
	Learning Rate: 0.0184374
	LOSS [training: 1.1441199463084035 | validation: 1.011496454898247]
	TIME [epoch: 15.2 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1014499226394519		[learning rate: 0.018429]
	Learning Rate: 0.0184285
	LOSS [training: 1.1014499226394519 | validation: 1.0047494557686352]
	TIME [epoch: 15.1 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0942555025800207		[learning rate: 0.01842]
	Learning Rate: 0.0184196
	LOSS [training: 1.0942555025800207 | validation: 1.029607141300735]
	TIME [epoch: 15.1 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0748770742424332		[learning rate: 0.018411]
	Learning Rate: 0.0184107
	LOSS [training: 1.0748770742424332 | validation: 1.0146991479162026]
	TIME [epoch: 15.2 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0485268032000183		[learning rate: 0.018402]
	Learning Rate: 0.0184017
	LOSS [training: 1.0485268032000183 | validation: 1.0013316487516666]
	TIME [epoch: 15.1 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0329096170233656		[learning rate: 0.018393]
	Learning Rate: 0.0183928
	LOSS [training: 1.0329096170233656 | validation: 0.9166473559438978]
	TIME [epoch: 15.1 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1097032460927476		[learning rate: 0.018384]
	Learning Rate: 0.0183838
	LOSS [training: 1.1097032460927476 | validation: 1.2934925420131913]
	TIME [epoch: 15.2 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.06685052527543		[learning rate: 0.018375]
	Learning Rate: 0.0183747
	LOSS [training: 1.06685052527543 | validation: 1.0394738633261924]
	TIME [epoch: 15.1 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0599859979070336		[learning rate: 0.018366]
	Learning Rate: 0.0183657
	LOSS [training: 1.0599859979070336 | validation: 0.9908586576975044]
	TIME [epoch: 15.2 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0276142374293586		[learning rate: 0.018357]
	Learning Rate: 0.0183566
	LOSS [training: 1.0276142374293586 | validation: 1.034730395535338]
	TIME [epoch: 15.1 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.179275911059997		[learning rate: 0.018348]
	Learning Rate: 0.0183475
	LOSS [training: 1.179275911059997 | validation: 0.9072392073607647]
	TIME [epoch: 15.1 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2972587442991568		[learning rate: 0.018338]
	Learning Rate: 0.0183384
	LOSS [training: 1.2972587442991568 | validation: 0.9407531428888174]
	TIME [epoch: 15.2 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9896639903366975		[learning rate: 0.018329]
	Learning Rate: 0.0183293
	LOSS [training: 0.9896639903366975 | validation: 0.98383215206967]
	TIME [epoch: 15.1 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9378070088660498		[learning rate: 0.01832]
	Learning Rate: 0.0183201
	LOSS [training: 0.9378070088660498 | validation: 0.9263326641277752]
	TIME [epoch: 15.1 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8954001163643894		[learning rate: 0.018311]
	Learning Rate: 0.0183109
	LOSS [training: 0.8954001163643894 | validation: 0.7553381801248746]
	TIME [epoch: 15.2 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7700270804408857		[learning rate: 0.018302]
	Learning Rate: 0.0183017
	LOSS [training: 0.7700270804408857 | validation: 0.6489565383028721]
	TIME [epoch: 15.1 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7098194949844296		[learning rate: 0.018293]
	Learning Rate: 0.0182925
	LOSS [training: 0.7098194949844296 | validation: 0.6023543074835955]
	TIME [epoch: 15.2 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.772886894990341		[learning rate: 0.018283]
	Learning Rate: 0.0182833
	LOSS [training: 0.772886894990341 | validation: 0.6070286887934904]
	TIME [epoch: 15.1 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6968453165767411		[learning rate: 0.018274]
	Learning Rate: 0.018274
	LOSS [training: 0.6968453165767411 | validation: 0.5711981213729955]
	TIME [epoch: 15.1 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6771872605255405		[learning rate: 0.018265]
	Learning Rate: 0.0182647
	LOSS [training: 0.6771872605255405 | validation: 0.5568050949583316]
	TIME [epoch: 15.2 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.693260256326131		[learning rate: 0.018255]
	Learning Rate: 0.0182554
	LOSS [training: 0.693260256326131 | validation: 0.6562729047823324]
	TIME [epoch: 15.1 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6594841967975187		[learning rate: 0.018246]
	Learning Rate: 0.018246
	LOSS [training: 0.6594841967975187 | validation: 0.6626603329810397]
	TIME [epoch: 15.1 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6589324490218109		[learning rate: 0.018237]
	Learning Rate: 0.0182367
	LOSS [training: 0.6589324490218109 | validation: 0.6200180590280588]
	TIME [epoch: 15.2 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6430611125891348		[learning rate: 0.018227]
	Learning Rate: 0.0182273
	LOSS [training: 0.6430611125891348 | validation: 0.5649304091635512]
	TIME [epoch: 15.1 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7279218803251141		[learning rate: 0.018218]
	Learning Rate: 0.0182179
	LOSS [training: 0.7279218803251141 | validation: 0.6473126264280313]
	TIME [epoch: 15.2 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.741790461672509		[learning rate: 0.018208]
	Learning Rate: 0.0182085
	LOSS [training: 0.741790461672509 | validation: 0.6474726176669339]
	TIME [epoch: 15.1 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6494975236314496		[learning rate: 0.018199]
	Learning Rate: 0.018199
	LOSS [training: 0.6494975236314496 | validation: 0.5434154124071211]
	TIME [epoch: 15.1 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5955471772347352		[learning rate: 0.01819]
	Learning Rate: 0.0181895
	LOSS [training: 0.5955471772347352 | validation: 0.585785292892967]
	TIME [epoch: 15.2 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5947439892416		[learning rate: 0.01818]
	Learning Rate: 0.01818
	LOSS [training: 0.5947439892416 | validation: 0.5777667157061498]
	TIME [epoch: 15.1 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6271487821783357		[learning rate: 0.018171]
	Learning Rate: 0.0181705
	LOSS [training: 0.6271487821783357 | validation: 0.6040180506548747]
	TIME [epoch: 15.2 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6254931409868036		[learning rate: 0.018161]
	Learning Rate: 0.018161
	LOSS [training: 0.6254931409868036 | validation: 0.5508346089897775]
	TIME [epoch: 15.1 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6278017653666548		[learning rate: 0.018151]
	Learning Rate: 0.0181514
	LOSS [training: 0.6278017653666548 | validation: 0.5788094288383911]
	TIME [epoch: 15 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6697353136217759		[learning rate: 0.018142]
	Learning Rate: 0.0181418
	LOSS [training: 0.6697353136217759 | validation: 0.669961517027319]
	TIME [epoch: 15.1 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6264013918602405		[learning rate: 0.018132]
	Learning Rate: 0.0181322
	LOSS [training: 0.6264013918602405 | validation: 0.5905205058732133]
	TIME [epoch: 15 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6534163255584826		[learning rate: 0.018123]
	Learning Rate: 0.0181226
	LOSS [training: 0.6534163255584826 | validation: 0.4994573182617834]
	TIME [epoch: 15.1 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5659728998445729		[learning rate: 0.018113]
	Learning Rate: 0.0181129
	LOSS [training: 0.5659728998445729 | validation: 0.5338430532097771]
	TIME [epoch: 15.1 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5777348849164853		[learning rate: 0.018103]
	Learning Rate: 0.0181032
	LOSS [training: 0.5777348849164853 | validation: 0.5262844726223079]
	TIME [epoch: 15.1 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5816328555191106		[learning rate: 0.018094]
	Learning Rate: 0.0180936
	LOSS [training: 0.5816328555191106 | validation: 0.5262861128109197]
	TIME [epoch: 15.1 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5856231250364491		[learning rate: 0.018084]
	Learning Rate: 0.0180838
	LOSS [training: 0.5856231250364491 | validation: 0.4794886433603914]
	TIME [epoch: 15.1 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5804662066166826		[learning rate: 0.018074]
	Learning Rate: 0.0180741
	LOSS [training: 0.5804662066166826 | validation: 0.6180738605522738]
	TIME [epoch: 15 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.203969441490746		[learning rate: 0.018064]
	Learning Rate: 0.0180643
	LOSS [training: 1.203969441490746 | validation: 0.665573475994286]
	TIME [epoch: 15.1 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6732401312333285		[learning rate: 0.018055]
	Learning Rate: 0.0180545
	LOSS [training: 0.6732401312333285 | validation: 0.5222097773244938]
	TIME [epoch: 15 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.568507473724344		[learning rate: 0.018045]
	Learning Rate: 0.0180447
	LOSS [training: 0.568507473724344 | validation: 0.4641564831708378]
	TIME [epoch: 15 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5600027611342502		[learning rate: 0.018035]
	Learning Rate: 0.0180349
	LOSS [training: 0.5600027611342502 | validation: 0.6438349653672676]
	TIME [epoch: 15.1 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7414962173165051		[learning rate: 0.018025]
	Learning Rate: 0.0180251
	LOSS [training: 0.7414962173165051 | validation: 0.8058757615353671]
	TIME [epoch: 15 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6870149844676152		[learning rate: 0.018015]
	Learning Rate: 0.0180152
	LOSS [training: 0.6870149844676152 | validation: 0.5627064101119044]
	TIME [epoch: 15.1 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6160875631271672		[learning rate: 0.018005]
	Learning Rate: 0.0180053
	LOSS [training: 0.6160875631271672 | validation: 0.518402201882109]
	TIME [epoch: 15.1 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5580700107448998		[learning rate: 0.017995]
	Learning Rate: 0.0179954
	LOSS [training: 0.5580700107448998 | validation: 0.5406223922409668]
	TIME [epoch: 15 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.591266642122282		[learning rate: 0.017985]
	Learning Rate: 0.0179854
	LOSS [training: 0.591266642122282 | validation: 0.5093208775789715]
	TIME [epoch: 15.1 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5769499577439049		[learning rate: 0.017975]
	Learning Rate: 0.0179755
	LOSS [training: 0.5769499577439049 | validation: 0.49104015833198444]
	TIME [epoch: 15 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5934375390462319		[learning rate: 0.017965]
	Learning Rate: 0.0179655
	LOSS [training: 0.5934375390462319 | validation: 0.4898720071583479]
	TIME [epoch: 15 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5848799589951014		[learning rate: 0.017955]
	Learning Rate: 0.0179555
	LOSS [training: 0.5848799589951014 | validation: 0.49994006604102476]
	TIME [epoch: 15.1 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6505000962226384		[learning rate: 0.017945]
	Learning Rate: 0.0179455
	LOSS [training: 0.6505000962226384 | validation: 0.4518580893514754]
	TIME [epoch: 15 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.672833148471498		[learning rate: 0.017935]
	Learning Rate: 0.0179354
	LOSS [training: 0.672833148471498 | validation: 0.48698537090538874]
	TIME [epoch: 15.1 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5346826536175526		[learning rate: 0.017925]
	Learning Rate: 0.0179253
	LOSS [training: 0.5346826536175526 | validation: 0.4626090105398134]
	TIME [epoch: 15 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5280700495752778		[learning rate: 0.017915]
	Learning Rate: 0.0179152
	LOSS [training: 0.5280700495752778 | validation: 0.4950975579665695]
	TIME [epoch: 15 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5655991282423349		[learning rate: 0.017905]
	Learning Rate: 0.0179051
	LOSS [training: 0.5655991282423349 | validation: 0.4989154251512047]
	TIME [epoch: 15.1 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5664575172919606		[learning rate: 0.017895]
	Learning Rate: 0.017895
	LOSS [training: 0.5664575172919606 | validation: 0.4268298224867558]
	TIME [epoch: 15.1 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.516284661327972		[learning rate: 0.017885]
	Learning Rate: 0.0178848
	LOSS [training: 0.516284661327972 | validation: 0.5570840625327818]
	TIME [epoch: 15 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5723089394411315		[learning rate: 0.017875]
	Learning Rate: 0.0178747
	LOSS [training: 0.5723089394411315 | validation: 0.5013735140282335]
	TIME [epoch: 15.1 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5424034030144362		[learning rate: 0.017864]
	Learning Rate: 0.0178645
	LOSS [training: 0.5424034030144362 | validation: 0.4965497874746738]
	TIME [epoch: 15 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5611616032596767		[learning rate: 0.017854]
	Learning Rate: 0.0178542
	LOSS [training: 0.5611616032596767 | validation: 0.4792843775066682]
	TIME [epoch: 15.1 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5554883383124076		[learning rate: 0.017844]
	Learning Rate: 0.017844
	LOSS [training: 0.5554883383124076 | validation: 0.6966214767159925]
	TIME [epoch: 15.1 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5562208719381809		[learning rate: 0.017834]
	Learning Rate: 0.0178337
	LOSS [training: 0.5562208719381809 | validation: 0.4195379095862144]
	TIME [epoch: 15 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5213918385947947		[learning rate: 0.017823]
	Learning Rate: 0.0178235
	LOSS [training: 0.5213918385947947 | validation: 0.45820135476045243]
	TIME [epoch: 15.1 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5429817914874935		[learning rate: 0.017813]
	Learning Rate: 0.0178131
	LOSS [training: 0.5429817914874935 | validation: 0.5362886557940039]
	TIME [epoch: 15 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5355572015863477		[learning rate: 0.017803]
	Learning Rate: 0.0178028
	LOSS [training: 0.5355572015863477 | validation: 0.533752498798913]
	TIME [epoch: 15.1 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.527898586725854		[learning rate: 0.017792]
	Learning Rate: 0.0177925
	LOSS [training: 0.527898586725854 | validation: 0.44365988850660537]
	TIME [epoch: 15.1 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.528875479458715		[learning rate: 0.017782]
	Learning Rate: 0.0177821
	LOSS [training: 0.528875479458715 | validation: 0.433938811045901]
	TIME [epoch: 15 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5064527494586895		[learning rate: 0.017772]
	Learning Rate: 0.0177717
	LOSS [training: 0.5064527494586895 | validation: 0.46166527899894405]
	TIME [epoch: 15.1 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5439842175523656		[learning rate: 0.017761]
	Learning Rate: 0.0177613
	LOSS [training: 0.5439842175523656 | validation: 0.48495661230415366]
	TIME [epoch: 15.1 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5149449312132772		[learning rate: 0.017751]
	Learning Rate: 0.0177509
	LOSS [training: 0.5149449312132772 | validation: 0.4326547464792403]
	TIME [epoch: 15 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4859699772874161		[learning rate: 0.01774]
	Learning Rate: 0.0177404
	LOSS [training: 0.4859699772874161 | validation: 0.47211815711949534]
	TIME [epoch: 15.1 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5260326138225673		[learning rate: 0.01773]
	Learning Rate: 0.0177299
	LOSS [training: 0.5260326138225673 | validation: 0.4330109709645344]
	TIME [epoch: 15 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5447557518849145		[learning rate: 0.017719]
	Learning Rate: 0.0177194
	LOSS [training: 0.5447557518849145 | validation: 0.37151986474133214]
	TIME [epoch: 15.1 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5070211105290939		[learning rate: 0.017709]
	Learning Rate: 0.0177089
	LOSS [training: 0.5070211105290939 | validation: 0.4095591383945063]
	TIME [epoch: 15.1 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5138415697170046		[learning rate: 0.017698]
	Learning Rate: 0.0176984
	LOSS [training: 0.5138415697170046 | validation: 0.43595413681171535]
	TIME [epoch: 15 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5245525039799788		[learning rate: 0.017688]
	Learning Rate: 0.0176878
	LOSS [training: 0.5245525039799788 | validation: 0.48698493151982536]
	TIME [epoch: 15.1 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5272446119059168		[learning rate: 0.017677]
	Learning Rate: 0.0176772
	LOSS [training: 0.5272446119059168 | validation: 0.4792939691507618]
	TIME [epoch: 15.1 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4828028848679211		[learning rate: 0.017667]
	Learning Rate: 0.0176666
	LOSS [training: 0.4828028848679211 | validation: 0.42137016066244987]
	TIME [epoch: 15 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48947792400555296		[learning rate: 0.017656]
	Learning Rate: 0.017656
	LOSS [training: 0.48947792400555296 | validation: 0.45780510540755615]
	TIME [epoch: 15.1 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49220985589560423		[learning rate: 0.017645]
	Learning Rate: 0.0176454
	LOSS [training: 0.49220985589560423 | validation: 0.46717014017616854]
	TIME [epoch: 15 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5242735039117011		[learning rate: 0.017635]
	Learning Rate: 0.0176347
	LOSS [training: 0.5242735039117011 | validation: 0.4149948436953949]
	TIME [epoch: 15.1 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5042840354047589		[learning rate: 0.017624]
	Learning Rate: 0.017624
	LOSS [training: 0.5042840354047589 | validation: 0.3892809290737286]
	TIME [epoch: 15 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4743152959961111		[learning rate: 0.017613]
	Learning Rate: 0.0176133
	LOSS [training: 0.4743152959961111 | validation: 0.39271998796838437]
	TIME [epoch: 15 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5051232468181187		[learning rate: 0.017603]
	Learning Rate: 0.0176026
	LOSS [training: 0.5051232468181187 | validation: 0.5341238431747235]
	TIME [epoch: 15.1 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5891724496096349		[learning rate: 0.017592]
	Learning Rate: 0.0175918
	LOSS [training: 0.5891724496096349 | validation: 0.4047689343098352]
	TIME [epoch: 15 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47415964812929445		[learning rate: 0.017581]
	Learning Rate: 0.0175811
	LOSS [training: 0.47415964812929445 | validation: 0.47069902957135856]
	TIME [epoch: 15 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4776206813437319		[learning rate: 0.01757]
	Learning Rate: 0.0175703
	LOSS [training: 0.4776206813437319 | validation: 0.4922213350405495]
	TIME [epoch: 15.1 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46153456029627915		[learning rate: 0.017559]
	Learning Rate: 0.0175595
	LOSS [training: 0.46153456029627915 | validation: 0.41523590953659084]
	TIME [epoch: 15.1 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4686991726844072		[learning rate: 0.017549]
	Learning Rate: 0.0175486
	LOSS [training: 0.4686991726844072 | validation: 0.5932148643417685]
	TIME [epoch: 15.1 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4924860503278501		[learning rate: 0.017538]
	Learning Rate: 0.0175378
	LOSS [training: 0.4924860503278501 | validation: 0.3767765421449024]
	TIME [epoch: 15.1 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5130385254508858		[learning rate: 0.017527]
	Learning Rate: 0.0175269
	LOSS [training: 0.5130385254508858 | validation: 0.5042380662100908]
	TIME [epoch: 15.1 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5247763784316725		[learning rate: 0.017516]
	Learning Rate: 0.017516
	LOSS [training: 0.5247763784316725 | validation: 0.4707103490372211]
	TIME [epoch: 15.2 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46881369638260006		[learning rate: 0.017505]
	Learning Rate: 0.0175051
	LOSS [training: 0.46881369638260006 | validation: 0.5064723616729716]
	TIME [epoch: 15.1 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47184329438168393		[learning rate: 0.017494]
	Learning Rate: 0.0174942
	LOSS [training: 0.47184329438168393 | validation: 0.3956968428261053]
	TIME [epoch: 15.1 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5105389082531808		[learning rate: 0.017483]
	Learning Rate: 0.0174832
	LOSS [training: 0.5105389082531808 | validation: 0.42678156028440506]
	TIME [epoch: 15.1 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49312422912788206		[learning rate: 0.017472]
	Learning Rate: 0.0174722
	LOSS [training: 0.49312422912788206 | validation: 0.3890378609379508]
	TIME [epoch: 15.1 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4865944273183845		[learning rate: 0.017461]
	Learning Rate: 0.0174612
	LOSS [training: 0.4865944273183845 | validation: 0.41358105328442396]
	TIME [epoch: 15.2 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5052922087337725		[learning rate: 0.01745]
	Learning Rate: 0.0174502
	LOSS [training: 0.5052922087337725 | validation: 0.41681566996004094]
	TIME [epoch: 15.1 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47469943986745256		[learning rate: 0.017439]
	Learning Rate: 0.0174392
	LOSS [training: 0.47469943986745256 | validation: 0.42410735535551647]
	TIME [epoch: 15.1 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.497748205434669		[learning rate: 0.017428]
	Learning Rate: 0.0174281
	LOSS [training: 0.497748205434669 | validation: 0.4745949621151102]
	TIME [epoch: 15.2 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5121110711607407		[learning rate: 0.017417]
	Learning Rate: 0.017417
	LOSS [training: 0.5121110711607407 | validation: 0.492010014245191]
	TIME [epoch: 15.1 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5154662298901056		[learning rate: 0.017406]
	Learning Rate: 0.0174059
	LOSS [training: 0.5154662298901056 | validation: 0.4826294320704971]
	TIME [epoch: 15.1 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4623308897052142		[learning rate: 0.017395]
	Learning Rate: 0.0173948
	LOSS [training: 0.4623308897052142 | validation: 0.40782758634996763]
	TIME [epoch: 15.2 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5006664888669284		[learning rate: 0.017384]
	Learning Rate: 0.0173837
	LOSS [training: 0.5006664888669284 | validation: 0.44898864921404724]
	TIME [epoch: 15.1 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.475634435203101		[learning rate: 0.017373]
	Learning Rate: 0.0173725
	LOSS [training: 0.475634435203101 | validation: 0.3857340252868986]
	TIME [epoch: 15.1 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4348511331673248		[learning rate: 0.017361]
	Learning Rate: 0.0173614
	LOSS [training: 0.4348511331673248 | validation: 0.3718667864302865]
	TIME [epoch: 15.1 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4731201827543525		[learning rate: 0.01735]
	Learning Rate: 0.0173502
	LOSS [training: 0.4731201827543525 | validation: 0.42032074240250095]
	TIME [epoch: 138 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5094959909037573		[learning rate: 0.017339]
	Learning Rate: 0.0173389
	LOSS [training: 0.5094959909037573 | validation: 0.42952897916985155]
	TIME [epoch: 32.8 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45415027223871673		[learning rate: 0.017328]
	Learning Rate: 0.0173277
	LOSS [training: 0.45415027223871673 | validation: 0.44739975617152516]
	TIME [epoch: 32.9 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44329915467644987		[learning rate: 0.017316]
	Learning Rate: 0.0173164
	LOSS [training: 0.44329915467644987 | validation: 0.4252867733307282]
	TIME [epoch: 32.8 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4924412353115377		[learning rate: 0.017305]
	Learning Rate: 0.0173052
	LOSS [training: 0.4924412353115377 | validation: 0.40322380768232163]
	TIME [epoch: 32.9 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4714457840159013		[learning rate: 0.017294]
	Learning Rate: 0.0172939
	LOSS [training: 0.4714457840159013 | validation: 0.3475689213963501]
	TIME [epoch: 32.8 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44167803560915486		[learning rate: 0.017283]
	Learning Rate: 0.0172826
	LOSS [training: 0.44167803560915486 | validation: 0.3815902272619931]
	TIME [epoch: 32.9 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4871773299637311		[learning rate: 0.017271]
	Learning Rate: 0.0172712
	LOSS [training: 0.4871773299637311 | validation: 0.45283542874082555]
	TIME [epoch: 32.8 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.522083356819229		[learning rate: 0.01726]
	Learning Rate: 0.0172599
	LOSS [training: 0.522083356819229 | validation: 0.4037222451426774]
	TIME [epoch: 32.9 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46904557004324665		[learning rate: 0.017248]
	Learning Rate: 0.0172485
	LOSS [training: 0.46904557004324665 | validation: 0.39619244466506154]
	TIME [epoch: 32.8 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4537311821186491		[learning rate: 0.017237]
	Learning Rate: 0.0172371
	LOSS [training: 0.4537311821186491 | validation: 0.3686140510519538]
	TIME [epoch: 32.9 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4762796562325722		[learning rate: 0.017226]
	Learning Rate: 0.0172257
	LOSS [training: 0.4762796562325722 | validation: 0.4213993215077677]
	TIME [epoch: 32.8 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4690456002927924		[learning rate: 0.017214]
	Learning Rate: 0.0172142
	LOSS [training: 0.4690456002927924 | validation: 0.4131450996401433]
	TIME [epoch: 32.9 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47325575442776147		[learning rate: 0.017203]
	Learning Rate: 0.0172028
	LOSS [training: 0.47325575442776147 | validation: 0.47696113203914814]
	TIME [epoch: 32.9 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4970011300544284		[learning rate: 0.017191]
	Learning Rate: 0.0171913
	LOSS [training: 0.4970011300544284 | validation: 0.3890768490431953]
	TIME [epoch: 32.9 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41661146901832724		[learning rate: 0.01718]
	Learning Rate: 0.0171798
	LOSS [training: 0.41661146901832724 | validation: 0.4017903159340056]
	TIME [epoch: 32.8 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4672669853746321		[learning rate: 0.017168]
	Learning Rate: 0.0171683
	LOSS [training: 0.4672669853746321 | validation: 0.3832885081810347]
	TIME [epoch: 32.9 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48202572583970726		[learning rate: 0.017157]
	Learning Rate: 0.0171567
	LOSS [training: 0.48202572583970726 | validation: 0.3582691807510019]
	TIME [epoch: 32.9 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.429532023510074		[learning rate: 0.017145]
	Learning Rate: 0.0171452
	LOSS [training: 0.429532023510074 | validation: 0.35638890465833384]
	TIME [epoch: 32.7 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49465920314798306		[learning rate: 0.017134]
	Learning Rate: 0.0171336
	LOSS [training: 0.49465920314798306 | validation: 0.4539826362090731]
	TIME [epoch: 32.8 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4413395504350667		[learning rate: 0.017122]
	Learning Rate: 0.017122
	LOSS [training: 0.4413395504350667 | validation: 0.4050609449562466]
	TIME [epoch: 32.8 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4486759698753413		[learning rate: 0.01711]
	Learning Rate: 0.0171104
	LOSS [training: 0.4486759698753413 | validation: 0.4049075186998402]
	TIME [epoch: 32.7 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43401685486588015		[learning rate: 0.017099]
	Learning Rate: 0.0170988
	LOSS [training: 0.43401685486588015 | validation: 0.3378405558756135]
	TIME [epoch: 32.6 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4509275586384428		[learning rate: 0.017087]
	Learning Rate: 0.0170871
	LOSS [training: 0.4509275586384428 | validation: 0.39575833826425655]
	TIME [epoch: 32.7 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4636558755840071		[learning rate: 0.017075]
	Learning Rate: 0.0170755
	LOSS [training: 0.4636558755840071 | validation: 0.43698280893139607]
	TIME [epoch: 32.7 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4900403179190864		[learning rate: 0.017064]
	Learning Rate: 0.0170638
	LOSS [training: 0.4900403179190864 | validation: 0.35433949206453563]
	TIME [epoch: 32.6 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44549731962100547		[learning rate: 0.017052]
	Learning Rate: 0.0170521
	LOSS [training: 0.44549731962100547 | validation: 0.3416499659863652]
	TIME [epoch: 32.9 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40030369870105786		[learning rate: 0.01704]
	Learning Rate: 0.0170403
	LOSS [training: 0.40030369870105786 | validation: 0.4274126773529069]
	TIME [epoch: 32.8 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4800666437665716		[learning rate: 0.017029]
	Learning Rate: 0.0170286
	LOSS [training: 0.4800666437665716 | validation: 0.3160854047861806]
	TIME [epoch: 32.8 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4301432312384062		[learning rate: 0.017017]
	Learning Rate: 0.0170168
	LOSS [training: 0.4301432312384062 | validation: 0.39401514129243637]
	TIME [epoch: 32.9 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4657747178468302		[learning rate: 0.017005]
	Learning Rate: 0.017005
	LOSS [training: 0.4657747178468302 | validation: 0.39594466430944086]
	TIME [epoch: 32.7 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45334793205363705		[learning rate: 0.016993]
	Learning Rate: 0.0169932
	LOSS [training: 0.45334793205363705 | validation: 0.37438703364523573]
	TIME [epoch: 32.8 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4449526392220116		[learning rate: 0.016981]
	Learning Rate: 0.0169814
	LOSS [training: 0.4449526392220116 | validation: 0.3308406338550197]
	TIME [epoch: 32.8 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4555470287230506		[learning rate: 0.01697]
	Learning Rate: 0.0169695
	LOSS [training: 0.4555470287230506 | validation: 0.40246127901179685]
	TIME [epoch: 32.9 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43858034182322336		[learning rate: 0.016958]
	Learning Rate: 0.0169577
	LOSS [training: 0.43858034182322336 | validation: 0.3763547434919462]
	TIME [epoch: 32.8 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3930065964283052		[learning rate: 0.016946]
	Learning Rate: 0.0169458
	LOSS [training: 0.3930065964283052 | validation: 0.37492778675885563]
	TIME [epoch: 32.9 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4455084055399694		[learning rate: 0.016934]
	Learning Rate: 0.0169339
	LOSS [training: 0.4455084055399694 | validation: 0.32087781450730757]
	TIME [epoch: 32.8 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41482482444141894		[learning rate: 0.016922]
	Learning Rate: 0.016922
	LOSS [training: 0.41482482444141894 | validation: 0.35882449950604456]
	TIME [epoch: 32.9 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4728895735383436		[learning rate: 0.01691]
	Learning Rate: 0.01691
	LOSS [training: 0.4728895735383436 | validation: 0.339624716813256]
	TIME [epoch: 32.8 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39845293311553714		[learning rate: 0.016898]
	Learning Rate: 0.0168981
	LOSS [training: 0.39845293311553714 | validation: 0.41098845098553666]
	TIME [epoch: 32.8 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4528669584875167		[learning rate: 0.016886]
	Learning Rate: 0.0168861
	LOSS [training: 0.4528669584875167 | validation: 0.33737056160150064]
	TIME [epoch: 32.8 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4173690909580245		[learning rate: 0.016874]
	Learning Rate: 0.0168741
	LOSS [training: 0.4173690909580245 | validation: 0.3108779292744207]
	TIME [epoch: 32.8 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38150137618989544		[learning rate: 0.016862]
	Learning Rate: 0.0168621
	LOSS [training: 0.38150137618989544 | validation: 0.4980712116161734]
	TIME [epoch: 32.9 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4202051553437266		[learning rate: 0.01685]
	Learning Rate: 0.0168501
	LOSS [training: 0.4202051553437266 | validation: 2.494365012504394]
	TIME [epoch: 32.8 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.15003642258965		[learning rate: 0.016838]
	Learning Rate: 0.016838
	LOSS [training: 1.15003642258965 | validation: 0.27145009540522624]
	TIME [epoch: 32.9 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33261279553709805		[learning rate: 0.016826]
	Learning Rate: 0.0168259
	LOSS [training: 0.33261279553709805 | validation: 0.2813598151081016]
	TIME [epoch: 32.8 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3547928979612004		[learning rate: 0.016814]
	Learning Rate: 0.0168138
	LOSS [training: 0.3547928979612004 | validation: 0.324814419513334]
	TIME [epoch: 32.9 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36182779549328276		[learning rate: 0.016802]
	Learning Rate: 0.0168017
	LOSS [training: 0.36182779549328276 | validation: 0.4024252180833181]
	TIME [epoch: 32.8 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.438710676383017		[learning rate: 0.01679]
	Learning Rate: 0.0167896
	LOSS [training: 0.438710676383017 | validation: 0.30001502781723133]
	TIME [epoch: 32.9 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3437778325799888		[learning rate: 0.016777]
	Learning Rate: 0.0167775
	LOSS [training: 0.3437778325799888 | validation: 0.3013656313404878]
	TIME [epoch: 32.8 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3635635316583677		[learning rate: 0.016765]
	Learning Rate: 0.0167653
	LOSS [training: 0.3635635316583677 | validation: 0.3375243546538045]
	TIME [epoch: 32.8 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3484828890816296		[learning rate: 0.016753]
	Learning Rate: 0.0167531
	LOSS [training: 0.3484828890816296 | validation: 0.3268095107777751]
	TIME [epoch: 32.8 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3471752431378573		[learning rate: 0.016741]
	Learning Rate: 0.0167409
	LOSS [training: 0.3471752431378573 | validation: 0.3029434220712871]
	TIME [epoch: 32.9 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3705222374068432		[learning rate: 0.016729]
	Learning Rate: 0.0167287
	LOSS [training: 0.3705222374068432 | validation: 0.3435056977502157]
	TIME [epoch: 32.9 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36362081520295864		[learning rate: 0.016716]
	Learning Rate: 0.0167165
	LOSS [training: 0.36362081520295864 | validation: 0.31812964304334]
	TIME [epoch: 32.9 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35772654570679097		[learning rate: 0.016704]
	Learning Rate: 0.0167042
	LOSS [training: 0.35772654570679097 | validation: 0.3442584586745822]
	TIME [epoch: 32.9 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40096500555427295		[learning rate: 0.016692]
	Learning Rate: 0.0166919
	LOSS [training: 0.40096500555427295 | validation: 0.2832901100486334]
	TIME [epoch: 32.8 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34338810045394275		[learning rate: 0.01668]
	Learning Rate: 0.0166796
	LOSS [training: 0.34338810045394275 | validation: 0.3963359956771747]
	TIME [epoch: 32.9 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4126883952591375		[learning rate: 0.016667]
	Learning Rate: 0.0166673
	LOSS [training: 0.4126883952591375 | validation: 0.29330256681840294]
	TIME [epoch: 32.9 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34297619672990853		[learning rate: 0.016655]
	Learning Rate: 0.016655
	LOSS [training: 0.34297619672990853 | validation: 0.2963553664673457]
	TIME [epoch: 32.9 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3386139708195705		[learning rate: 0.016643]
	Learning Rate: 0.0166427
	LOSS [training: 0.3386139708195705 | validation: 1.1907898307139453]
	TIME [epoch: 32.9 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6798469988652329		[learning rate: 0.01663]
	Learning Rate: 0.0166303
	LOSS [training: 0.6798469988652329 | validation: 0.34598121999730314]
	TIME [epoch: 32.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240704_140023/states/model_phi1_1a_v_mmd4_562.pth
Halted early. No improvement in validation loss for 250 epochs.
Finished training in 8482.738 seconds.
