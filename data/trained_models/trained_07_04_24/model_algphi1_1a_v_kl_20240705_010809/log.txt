Args:
Namespace(name='model_algphi1_1a_v_kl', outdir='out/model_training/model_algphi1_1a_v_kl', training_data='data/training_data/data_phi1_1a/training', validation_data='data/training_data/data_phi1_1a/validation', model_type='binary_choice', nsims_training=None, nsims_validation=None, num_epochs=500, passes_per_epoch=1, batch_size=250, patience=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=False, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 250], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=False, confinement_factor=1.0, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], phi_final_act='softplus', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=0.0, init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3226872486

Training model...

Saving initial model state to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 4/4] avg loss: 10.478876228019676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.478876228019676 | validation: 10.569713589306573]
	TIME [epoch: 105 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 4/4] avg loss: 10.353415772503		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.353415772503 | validation: 10.367653182045604]
	TIME [epoch: 4.35 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 4/4] avg loss: 10.000718361500777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.000718361500777 | validation: 9.797087701277452]
	TIME [epoch: 4.31 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_3.pth
	Model improved!!!
EPOCH 4/500:
	Training over batches...
		[batch 4/4] avg loss: 9.758005096750512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.758005096750512 | validation: 9.665960561322741]
	TIME [epoch: 4.28 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 4/4] avg loss: 9.585100286132004		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.585100286132004 | validation: 9.418005867796111]
	TIME [epoch: 4.27 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_5.pth
	Model improved!!!
EPOCH 6/500:
	Training over batches...
		[batch 4/4] avg loss: 9.34678627488933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.34678627488933 | validation: 9.275537308976254]
	TIME [epoch: 4.28 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_6.pth
	Model improved!!!
EPOCH 7/500:
	Training over batches...
		[batch 4/4] avg loss: 9.107624136280592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.107624136280592 | validation: 9.08662617287598]
	TIME [epoch: 4.27 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_7.pth
	Model improved!!!
EPOCH 8/500:
	Training over batches...
		[batch 4/4] avg loss: 8.965322366312282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.965322366312282 | validation: 9.029226249668627]
	TIME [epoch: 4.26 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_8.pth
	Model improved!!!
EPOCH 9/500:
	Training over batches...
		[batch 4/4] avg loss: 8.677952545640347		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.677952545640347 | validation: 8.525921954707691]
	TIME [epoch: 4.26 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_9.pth
	Model improved!!!
EPOCH 10/500:
	Training over batches...
		[batch 4/4] avg loss: 8.286842789636168		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.286842789636168 | validation: 8.198418761357846]
	TIME [epoch: 4.26 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_10.pth
	Model improved!!!
EPOCH 11/500:
	Training over batches...
		[batch 4/4] avg loss: 8.061643024977675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.061643024977675 | validation: 7.813708806231409]
	TIME [epoch: 4.27 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_11.pth
	Model improved!!!
EPOCH 12/500:
	Training over batches...
		[batch 4/4] avg loss: 7.552921010644263		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.552921010644263 | validation: 7.459743913810142]
	TIME [epoch: 4.29 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_12.pth
	Model improved!!!
EPOCH 13/500:
	Training over batches...
		[batch 4/4] avg loss: 7.241989100317635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.241989100317635 | validation: 7.0670725852065335]
	TIME [epoch: 4.28 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_13.pth
	Model improved!!!
EPOCH 14/500:
	Training over batches...
		[batch 4/4] avg loss: 6.878251781891868		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.878251781891868 | validation: 6.591525316228079]
	TIME [epoch: 4.26 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_14.pth
	Model improved!!!
EPOCH 15/500:
	Training over batches...
		[batch 4/4] avg loss: 6.3488883669895975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.3488883669895975 | validation: 6.196072960907584]
	TIME [epoch: 4.27 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_15.pth
	Model improved!!!
EPOCH 16/500:
	Training over batches...
		[batch 4/4] avg loss: 5.953792505411897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.953792505411897 | validation: 5.834990593554663]
	TIME [epoch: 4.27 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_16.pth
	Model improved!!!
EPOCH 17/500:
	Training over batches...
		[batch 4/4] avg loss: 5.603975684036227		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.603975684036227 | validation: 5.617341164918196]
	TIME [epoch: 4.26 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_17.pth
	Model improved!!!
EPOCH 18/500:
	Training over batches...
		[batch 4/4] avg loss: 5.344468582020206		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.344468582020206 | validation: 5.318530094352406]
	TIME [epoch: 4.27 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_18.pth
	Model improved!!!
EPOCH 19/500:
	Training over batches...
		[batch 4/4] avg loss: 5.087748269706028		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.087748269706028 | validation: 5.205425046616375]
	TIME [epoch: 4.27 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_19.pth
	Model improved!!!
EPOCH 20/500:
	Training over batches...
		[batch 4/4] avg loss: 5.008154533548828		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.008154533548828 | validation: 5.098014591947745]
	TIME [epoch: 4.26 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_20.pth
	Model improved!!!
EPOCH 21/500:
	Training over batches...
		[batch 4/4] avg loss: 4.82342444526382		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.82342444526382 | validation: 4.755036768368053]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_21.pth
	Model improved!!!
EPOCH 22/500:
	Training over batches...
		[batch 4/4] avg loss: 4.650948105240548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.650948105240548 | validation: 4.618675564407056]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_22.pth
	Model improved!!!
EPOCH 23/500:
	Training over batches...
		[batch 4/4] avg loss: 4.547519189203759		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.547519189203759 | validation: 4.571925449843954]
	TIME [epoch: 4.27 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_23.pth
	Model improved!!!
EPOCH 24/500:
	Training over batches...
		[batch 4/4] avg loss: 4.546538944618402		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.546538944618402 | validation: 4.56274714135405]
	TIME [epoch: 4.27 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_24.pth
	Model improved!!!
EPOCH 25/500:
	Training over batches...
		[batch 4/4] avg loss: 4.487753218589999		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.487753218589999 | validation: 4.689966543988202]
	TIME [epoch: 4.26 sec]
EPOCH 26/500:
	Training over batches...
		[batch 4/4] avg loss: 4.529743505680391		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.529743505680391 | validation: 4.611036696756429]
	TIME [epoch: 4.27 sec]
EPOCH 27/500:
	Training over batches...
		[batch 4/4] avg loss: 4.460448244268723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.460448244268723 | validation: 4.399472290630053]
	TIME [epoch: 4.26 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_27.pth
	Model improved!!!
EPOCH 28/500:
	Training over batches...
		[batch 4/4] avg loss: 4.3339002402013325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.3339002402013325 | validation: 4.312335758790498]
	TIME [epoch: 4.26 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_28.pth
	Model improved!!!
EPOCH 29/500:
	Training over batches...
		[batch 4/4] avg loss: 4.316677027371708		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.316677027371708 | validation: 4.333798558086986]
	TIME [epoch: 4.26 sec]
EPOCH 30/500:
	Training over batches...
		[batch 4/4] avg loss: 4.306946908280711		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.306946908280711 | validation: 4.335810157128131]
	TIME [epoch: 4.28 sec]
EPOCH 31/500:
	Training over batches...
		[batch 4/4] avg loss: 4.326649756541499		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.326649756541499 | validation: 4.3440811221504845]
	TIME [epoch: 4.28 sec]
EPOCH 32/500:
	Training over batches...
		[batch 4/4] avg loss: 4.332707540020369		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.332707540020369 | validation: 4.267337083816157]
	TIME [epoch: 4.26 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_32.pth
	Model improved!!!
EPOCH 33/500:
	Training over batches...
		[batch 4/4] avg loss: 4.193035223822217		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.193035223822217 | validation: 4.111883807203825]
	TIME [epoch: 4.27 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_33.pth
	Model improved!!!
EPOCH 34/500:
	Training over batches...
		[batch 4/4] avg loss: 4.107091372998304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.107091372998304 | validation: 4.173512744735564]
	TIME [epoch: 4.27 sec]
EPOCH 35/500:
	Training over batches...
		[batch 4/4] avg loss: 4.140487342950307		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.140487342950307 | validation: 4.1067684989902435]
	TIME [epoch: 4.27 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_35.pth
	Model improved!!!
EPOCH 36/500:
	Training over batches...
		[batch 4/4] avg loss: 4.170937044607703		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.170937044607703 | validation: 4.162363060165006]
	TIME [epoch: 4.27 sec]
EPOCH 37/500:
	Training over batches...
		[batch 4/4] avg loss: 4.081891589368578		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.081891589368578 | validation: 4.120846727643395]
	TIME [epoch: 4.26 sec]
EPOCH 38/500:
	Training over batches...
		[batch 4/4] avg loss: 4.15558029309029		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.15558029309029 | validation: 4.242145347973178]
	TIME [epoch: 4.26 sec]
EPOCH 39/500:
	Training over batches...
		[batch 4/4] avg loss: 4.241436908161419		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.241436908161419 | validation: 4.1610185765767245]
	TIME [epoch: 4.27 sec]
EPOCH 40/500:
	Training over batches...
		[batch 4/4] avg loss: 4.237028829133662		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.237028829133662 | validation: 4.209118846723584]
	TIME [epoch: 4.31 sec]
EPOCH 41/500:
	Training over batches...
		[batch 4/4] avg loss: 4.3155570593900165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.3155570593900165 | validation: 4.405575410987016]
	TIME [epoch: 4.28 sec]
EPOCH 42/500:
	Training over batches...
		[batch 4/4] avg loss: 4.711782438543733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.711782438543733 | validation: 4.786358660392647]
	TIME [epoch: 4.27 sec]
EPOCH 43/500:
	Training over batches...
		[batch 4/4] avg loss: 5.035722941994685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.035722941994685 | validation: 5.0598425464805965]
	TIME [epoch: 4.27 sec]
EPOCH 44/500:
	Training over batches...
		[batch 4/4] avg loss: 5.211913930422182		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.211913930422182 | validation: 4.864520642875118]
	TIME [epoch: 4.27 sec]
EPOCH 45/500:
	Training over batches...
		[batch 4/4] avg loss: 4.893620165481937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.893620165481937 | validation: 4.584960877796995]
	TIME [epoch: 4.27 sec]
EPOCH 46/500:
	Training over batches...
		[batch 4/4] avg loss: 4.6297263086410085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.6297263086410085 | validation: 4.352419569346198]
	TIME [epoch: 4.27 sec]
EPOCH 47/500:
	Training over batches...
		[batch 4/4] avg loss: 4.417738882427157		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.417738882427157 | validation: 4.260192539315124]
	TIME [epoch: 4.26 sec]
EPOCH 48/500:
	Training over batches...
		[batch 4/4] avg loss: 4.373564282262507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.373564282262507 | validation: 4.36251775963798]
	TIME [epoch: 4.26 sec]
EPOCH 49/500:
	Training over batches...
		[batch 4/4] avg loss: 4.5396009001745234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.5396009001745234 | validation: 4.376340949507535]
	TIME [epoch: 4.3 sec]
EPOCH 50/500:
	Training over batches...
		[batch 4/4] avg loss: 4.565402788402332		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.565402788402332 | validation: 4.238113381638317]
	TIME [epoch: 4.32 sec]
EPOCH 51/500:
	Training over batches...
		[batch 4/4] avg loss: 1.1805643120988907		[learning rate: 0.0098855]
	Learning Rate: 0.00988553
	LOSS [training: 1.1805643120988907 | validation: 0.9219510171339278]
	TIME [epoch: 108 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_51.pth
	Model improved!!!
EPOCH 52/500:
	Training over batches...
		[batch 4/4] avg loss: 0.8479861784557595		[learning rate: 0.0097349]
	Learning Rate: 0.00973494
	LOSS [training: 0.8479861784557595 | validation: 0.733435885227377]
	TIME [epoch: 8.43 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_52.pth
	Model improved!!!
EPOCH 53/500:
	Training over batches...
		[batch 4/4] avg loss: 0.6292321193683128		[learning rate: 0.0095866]
	Learning Rate: 0.00958665
	LOSS [training: 0.6292321193683128 | validation: 0.4901033959843233]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_53.pth
	Model improved!!!
EPOCH 54/500:
	Training over batches...
		[batch 4/4] avg loss: 0.4393921267580749		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.4393921267580749 | validation: 0.36127798744991846]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_54.pth
	Model improved!!!
EPOCH 55/500:
	Training over batches...
		[batch 4/4] avg loss: 0.3199567929363579		[learning rate: 0.0092968]
	Learning Rate: 0.0092968
	LOSS [training: 0.3199567929363579 | validation: 0.2755871271854861]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_55.pth
	Model improved!!!
EPOCH 56/500:
	Training over batches...
		[batch 4/4] avg loss: 0.25971584328376696		[learning rate: 0.0091552]
	Learning Rate: 0.00915517
	LOSS [training: 0.25971584328376696 | validation: 0.22601942838439135]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_56.pth
	Model improved!!!
EPOCH 57/500:
	Training over batches...
		[batch 4/4] avg loss: 0.203473768649468		[learning rate: 0.0090157]
	Learning Rate: 0.00901571
	LOSS [training: 0.203473768649468 | validation: 0.1786849088079998]
	TIME [epoch: 8.35 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_57.pth
	Model improved!!!
EPOCH 58/500:
	Training over batches...
		[batch 4/4] avg loss: 0.16712247159921195		[learning rate: 0.0088784]
	Learning Rate: 0.00887837
	LOSS [training: 0.16712247159921195 | validation: 0.16258413271422406]
	TIME [epoch: 8.35 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_58.pth
	Model improved!!!
EPOCH 59/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1252907807791832		[learning rate: 0.0087431]
	Learning Rate: 0.00874312
	LOSS [training: 0.1252907807791832 | validation: 0.11652266039591584]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_59.pth
	Model improved!!!
EPOCH 60/500:
	Training over batches...
		[batch 4/4] avg loss: 0.10606477744617789		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 0.10606477744617789 | validation: 0.13560102331623902]
	TIME [epoch: 8.31 sec]
EPOCH 61/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13268746268821005		[learning rate: 0.0084788]
	Learning Rate: 0.00847878
	LOSS [training: 0.13268746268821005 | validation: 0.11037045990867383]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_61.pth
	Model improved!!!
EPOCH 62/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08057021170329323		[learning rate: 0.0083496]
	Learning Rate: 0.00834962
	LOSS [training: 0.08057021170329323 | validation: 0.07605445389515611]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_62.pth
	Model improved!!!
EPOCH 63/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07413241035862479		[learning rate: 0.0082224]
	Learning Rate: 0.00822243
	LOSS [training: 0.07413241035862479 | validation: 0.09824387810240112]
	TIME [epoch: 8.34 sec]
EPOCH 64/500:
	Training over batches...
		[batch 4/4] avg loss: 0.09265943579982172		[learning rate: 0.0080972]
	Learning Rate: 0.00809717
	LOSS [training: 0.09265943579982172 | validation: 0.06166578621496177]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_64.pth
	Model improved!!!
EPOCH 65/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05276425482373297		[learning rate: 0.0079738]
	Learning Rate: 0.00797382
	LOSS [training: 0.05276425482373297 | validation: 0.06485982213749274]
	TIME [epoch: 8.3 sec]
EPOCH 66/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05229170867821194		[learning rate: 0.0078524]
	Learning Rate: 0.00785236
	LOSS [training: 0.05229170867821194 | validation: 0.06043099178259595]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_66.pth
	Model improved!!!
EPOCH 67/500:
	Training over batches...
		[batch 4/4] avg loss: 0.053388513915953666		[learning rate: 0.0077327]
	Learning Rate: 0.00773274
	LOSS [training: 0.053388513915953666 | validation: 0.04766930329601715]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_67.pth
	Model improved!!!
EPOCH 68/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06516480678975008		[learning rate: 0.0076149]
	Learning Rate: 0.00761494
	LOSS [training: 0.06516480678975008 | validation: 0.08768841897275964]
	TIME [epoch: 8.34 sec]
EPOCH 69/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07003022490426879		[learning rate: 0.0074989]
	Learning Rate: 0.00749894
	LOSS [training: 0.07003022490426879 | validation: 0.05329400967687856]
	TIME [epoch: 8.31 sec]
EPOCH 70/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06656832179170627		[learning rate: 0.0073847]
	Learning Rate: 0.00738471
	LOSS [training: 0.06656832179170627 | validation: 0.06559715278554323]
	TIME [epoch: 8.31 sec]
EPOCH 71/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0555533504398792		[learning rate: 0.0072722]
	Learning Rate: 0.00727221
	LOSS [training: 0.0555533504398792 | validation: 0.07215457713705967]
	TIME [epoch: 8.32 sec]
EPOCH 72/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06994389627003107		[learning rate: 0.0071614]
	Learning Rate: 0.00716143
	LOSS [training: 0.06994389627003107 | validation: 0.050679336036155834]
	TIME [epoch: 8.35 sec]
EPOCH 73/500:
	Training over batches...
		[batch 4/4] avg loss: 0.048900952437435696		[learning rate: 0.0070523]
	Learning Rate: 0.00705234
	LOSS [training: 0.048900952437435696 | validation: 0.05080262813056402]
	TIME [epoch: 8.34 sec]
EPOCH 74/500:
	Training over batches...
		[batch 4/4] avg loss: 0.054880127705018045		[learning rate: 0.0069449]
	Learning Rate: 0.00694491
	LOSS [training: 0.054880127705018045 | validation: 0.05427463520153204]
	TIME [epoch: 8.32 sec]
EPOCH 75/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06331667952613806		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.06331667952613806 | validation: 0.0702074239658124]
	TIME [epoch: 8.33 sec]
EPOCH 76/500:
	Training over batches...
		[batch 4/4] avg loss: 0.060596304556872385		[learning rate: 0.0067349]
	Learning Rate: 0.00673493
	LOSS [training: 0.060596304556872385 | validation: 0.051636312388392745]
	TIME [epoch: 8.31 sec]
EPOCH 77/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05351532819425471		[learning rate: 0.0066323]
	Learning Rate: 0.00663234
	LOSS [training: 0.05351532819425471 | validation: 0.054983421357995166]
	TIME [epoch: 8.35 sec]
EPOCH 78/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05011976261277906		[learning rate: 0.0065313]
	Learning Rate: 0.00653131
	LOSS [training: 0.05011976261277906 | validation: 0.04995255808217068]
	TIME [epoch: 8.35 sec]
EPOCH 79/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04864686083716587		[learning rate: 0.0064318]
	Learning Rate: 0.00643181
	LOSS [training: 0.04864686083716587 | validation: 0.054955345226009214]
	TIME [epoch: 8.31 sec]
EPOCH 80/500:
	Training over batches...
		[batch 4/4] avg loss: 0.061993112309464526		[learning rate: 0.0063338]
	Learning Rate: 0.00633383
	LOSS [training: 0.061993112309464526 | validation: 0.06244166196240566]
	TIME [epoch: 8.32 sec]
EPOCH 81/500:
	Training over batches...
		[batch 4/4] avg loss: 0.057020379706587083		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.057020379706587083 | validation: 0.05681393390492957]
	TIME [epoch: 8.32 sec]
EPOCH 82/500:
	Training over batches...
		[batch 4/4] avg loss: 0.047714016267128935		[learning rate: 0.0061423]
	Learning Rate: 0.00614233
	LOSS [training: 0.047714016267128935 | validation: 0.05353507292370091]
	TIME [epoch: 8.35 sec]
EPOCH 83/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05898393890136111		[learning rate: 0.0060488]
	Learning Rate: 0.00604876
	LOSS [training: 0.05898393890136111 | validation: 0.06344022486347027]
	TIME [epoch: 8.34 sec]
EPOCH 84/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0755134632063791		[learning rate: 0.0059566]
	Learning Rate: 0.00595662
	LOSS [training: 0.0755134632063791 | validation: 0.06524099728140603]
	TIME [epoch: 8.32 sec]
EPOCH 85/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06131261902671482		[learning rate: 0.0058659]
	Learning Rate: 0.00586588
	LOSS [training: 0.06131261902671482 | validation: 0.047406612969739484]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_85.pth
	Model improved!!!
EPOCH 86/500:
	Training over batches...
		[batch 4/4] avg loss: 0.045352357446472105		[learning rate: 0.0057765]
	Learning Rate: 0.00577653
	LOSS [training: 0.045352357446472105 | validation: 0.0503648491446531]
	TIME [epoch: 8.33 sec]
EPOCH 87/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05090676427194914		[learning rate: 0.0056885]
	Learning Rate: 0.00568853
	LOSS [training: 0.05090676427194914 | validation: 0.06974143331448462]
	TIME [epoch: 8.36 sec]
EPOCH 88/500:
	Training over batches...
		[batch 4/4] avg loss: 0.061179961975061696		[learning rate: 0.0056019]
	Learning Rate: 0.00560187
	LOSS [training: 0.061179961975061696 | validation: 0.05812722175682023]
	TIME [epoch: 8.33 sec]
EPOCH 89/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05225471971775474		[learning rate: 0.0055165]
	Learning Rate: 0.00551654
	LOSS [training: 0.05225471971775474 | validation: 0.051945414926153746]
	TIME [epoch: 8.31 sec]
EPOCH 90/500:
	Training over batches...
		[batch 4/4] avg loss: 0.053973048973929336		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.053973048973929336 | validation: 0.056737091064486544]
	TIME [epoch: 8.31 sec]
EPOCH 91/500:
	Training over batches...
		[batch 4/4] avg loss: 0.054619254711159894		[learning rate: 0.0053497]
	Learning Rate: 0.00534975
	LOSS [training: 0.054619254711159894 | validation: 0.06101494224512284]
	TIME [epoch: 8.32 sec]
EPOCH 92/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05519840509063974		[learning rate: 0.0052683]
	Learning Rate: 0.00526825
	LOSS [training: 0.05519840509063974 | validation: 0.05730552632275032]
	TIME [epoch: 8.35 sec]
EPOCH 93/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08405112205607379		[learning rate: 0.005188]
	Learning Rate: 0.005188
	LOSS [training: 0.08405112205607379 | validation: 0.09443668382989648]
	TIME [epoch: 8.34 sec]
EPOCH 94/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07673964778413858		[learning rate: 0.005109]
	Learning Rate: 0.00510897
	LOSS [training: 0.07673964778413858 | validation: 0.05619391233233408]
	TIME [epoch: 8.32 sec]
EPOCH 95/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0637146050125084		[learning rate: 0.0050311]
	Learning Rate: 0.00503114
	LOSS [training: 0.0637146050125084 | validation: 0.07162744554627018]
	TIME [epoch: 8.32 sec]
EPOCH 96/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06779080487012354		[learning rate: 0.0049545]
	Learning Rate: 0.0049545
	LOSS [training: 0.06779080487012354 | validation: 0.06026476014037477]
	TIME [epoch: 8.31 sec]
EPOCH 97/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05339668881121959		[learning rate: 0.004879]
	Learning Rate: 0.00487903
	LOSS [training: 0.05339668881121959 | validation: 0.05154692801981034]
	TIME [epoch: 8.36 sec]
EPOCH 98/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04655519613135229		[learning rate: 0.0048047]
	Learning Rate: 0.0048047
	LOSS [training: 0.04655519613135229 | validation: 0.05081768682321002]
	TIME [epoch: 8.34 sec]
EPOCH 99/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0500881529720318		[learning rate: 0.0047315]
	Learning Rate: 0.00473151
	LOSS [training: 0.0500881529720318 | validation: 0.05953188517757263]
	TIME [epoch: 8.35 sec]
EPOCH 100/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0494354106541581		[learning rate: 0.0046594]
	Learning Rate: 0.00465944
	LOSS [training: 0.0494354106541581 | validation: 0.0625626174104162]
	TIME [epoch: 8.35 sec]
EPOCH 101/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007869853677408525		[learning rate: 0.0045885]
	Learning Rate: 0.00458846
	LOSS [training: 0.007869853677408525 | validation: 0.0024811401359532163]
	TIME [epoch: 119 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_101.pth
	Model improved!!!
EPOCH 102/500:
	Training over batches...
		[batch 4/4] avg loss: 0.005489162059660371		[learning rate: 0.0045186]
	Learning Rate: 0.00451856
	LOSS [training: 0.005489162059660371 | validation: -0.0037686463338167716]
	TIME [epoch: 19 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_102.pth
	Model improved!!!
EPOCH 103/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004097918114326514		[learning rate: 0.0044497]
	Learning Rate: 0.00444973
	LOSS [training: -0.004097918114326514 | validation: 0.020592497105438996]
	TIME [epoch: 18.9 sec]
EPOCH 104/500:
	Training over batches...
		[batch 4/4] avg loss: 8.806383380228708e-05		[learning rate: 0.0043819]
	Learning Rate: 0.00438194
	LOSS [training: 8.806383380228708e-05 | validation: -0.010951735035869381]
	TIME [epoch: 18.9 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_104.pth
	Model improved!!!
EPOCH 105/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004518044496154592		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: -0.004518044496154592 | validation: 0.0025850662942720954]
	TIME [epoch: 18.9 sec]
EPOCH 106/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0023284540553723367		[learning rate: 0.0042495]
	Learning Rate: 0.00424946
	LOSS [training: -0.0023284540553723367 | validation: -0.006801949638385265]
	TIME [epoch: 18.8 sec]
EPOCH 107/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0014445393640753425		[learning rate: 0.0041847]
	Learning Rate: 0.00418472
	LOSS [training: -0.0014445393640753425 | validation: 0.00923433239522393]
	TIME [epoch: 18.9 sec]
EPOCH 108/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0004131511387439424		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: -0.0004131511387439424 | validation: 0.0051087395391414755]
	TIME [epoch: 18.8 sec]
EPOCH 109/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005704494406342179		[learning rate: 0.0040582]
	Learning Rate: 0.0040582
	LOSS [training: -0.005704494406342179 | validation: 0.0029140116041652176]
	TIME [epoch: 18.9 sec]
EPOCH 110/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007322037226616982		[learning rate: 0.0039964]
	Learning Rate: 0.00399638
	LOSS [training: -0.007322037226616982 | validation: -0.004291389990060698]
	TIME [epoch: 18.8 sec]
EPOCH 111/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0050123767367261235		[learning rate: 0.0039355]
	Learning Rate: 0.0039355
	LOSS [training: -0.0050123767367261235 | validation: -0.0016164891262982145]
	TIME [epoch: 18.9 sec]
EPOCH 112/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007556230675693727		[learning rate: 0.0038755]
	Learning Rate: 0.00387555
	LOSS [training: -0.007556230675693727 | validation: 0.0019999685772225982]
	TIME [epoch: 18.8 sec]
EPOCH 113/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00391075718127214		[learning rate: 0.0038165]
	Learning Rate: 0.00381651
	LOSS [training: -0.00391075718127214 | validation: -0.00594940402892602]
	TIME [epoch: 18.9 sec]
EPOCH 114/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007217550196409912		[learning rate: 0.0037584]
	Learning Rate: 0.00375837
	LOSS [training: -0.007217550196409912 | validation: -0.007186799323130918]
	TIME [epoch: 18.9 sec]
EPOCH 115/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002338966216923653		[learning rate: 0.0037011]
	Learning Rate: 0.00370112
	LOSS [training: -0.002338966216923653 | validation: -0.00460453884853011]
	TIME [epoch: 18.8 sec]
EPOCH 116/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0027329591822871776		[learning rate: 0.0036447]
	Learning Rate: 0.00364474
	LOSS [training: 0.0027329591822871776 | validation: 0.004941660665778707]
	TIME [epoch: 18.9 sec]
EPOCH 117/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0039125051709389975		[learning rate: 0.0035892]
	Learning Rate: 0.00358922
	LOSS [training: 0.0039125051709389975 | validation: 0.0031030212070163334]
	TIME [epoch: 18.8 sec]
EPOCH 118/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00045150722617165066		[learning rate: 0.0035345]
	Learning Rate: 0.00353454
	LOSS [training: -0.00045150722617165066 | validation: -0.0065947833665702445]
	TIME [epoch: 18.9 sec]
EPOCH 119/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00782424364089464		[learning rate: 0.0034807]
	Learning Rate: 0.0034807
	LOSS [training: -0.00782424364089464 | validation: 0.0016090846125909443]
	TIME [epoch: 18.8 sec]
EPOCH 120/500:
	Training over batches...
		[batch 4/4] avg loss: -0.003272309530260354		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: -0.003272309530260354 | validation: 0.010918393886501789]
	TIME [epoch: 18.9 sec]
EPOCH 121/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0063474508067517125		[learning rate: 0.0033755]
	Learning Rate: 0.00337546
	LOSS [training: 0.0063474508067517125 | validation: -0.005685544092057534]
	TIME [epoch: 18.8 sec]
EPOCH 122/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006595519838657568		[learning rate: 0.003324]
	Learning Rate: 0.00332404
	LOSS [training: -0.006595519838657568 | validation: -0.012913265000551153]
	TIME [epoch: 18.9 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_122.pth
	Model improved!!!
EPOCH 123/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007496119825231251		[learning rate: 0.0032734]
	Learning Rate: 0.00327341
	LOSS [training: -0.007496119825231251 | validation: -0.0017185245855901587]
	TIME [epoch: 18.9 sec]
EPOCH 124/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007749451237446652		[learning rate: 0.0032235]
	Learning Rate: 0.00322354
	LOSS [training: -0.007749451237446652 | validation: -0.006451096317299962]
	TIME [epoch: 18.9 sec]
EPOCH 125/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006494361177212616		[learning rate: 0.0031744]
	Learning Rate: 0.00317444
	LOSS [training: -0.006494361177212616 | validation: -0.0054153020233948]
	TIME [epoch: 18.9 sec]
EPOCH 126/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006614165686750905		[learning rate: 0.0031261]
	Learning Rate: 0.00312608
	LOSS [training: -0.006614165686750905 | validation: -0.0034098487472127344]
	TIME [epoch: 18.9 sec]
EPOCH 127/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00865508535570979		[learning rate: 0.0030785]
	Learning Rate: 0.00307846
	LOSS [training: -0.00865508535570979 | validation: -3.799174532881887e-05]
	TIME [epoch: 18.9 sec]
EPOCH 128/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007824079389509686		[learning rate: 0.0030316]
	Learning Rate: 0.00303156
	LOSS [training: -0.007824079389509686 | validation: -0.003351698833410287]
	TIME [epoch: 18.8 sec]
EPOCH 129/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007180774981810694		[learning rate: 0.0029854]
	Learning Rate: 0.00298538
	LOSS [training: -0.007180774981810694 | validation: -0.013484054407342148]
	TIME [epoch: 18.9 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_129.pth
	Model improved!!!
EPOCH 130/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00884964515276231		[learning rate: 0.0029399]
	Learning Rate: 0.0029399
	LOSS [training: -0.00884964515276231 | validation: -0.003707495216598001]
	TIME [epoch: 18.9 sec]
EPOCH 131/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010441599228714467		[learning rate: 0.0028951]
	Learning Rate: 0.00289512
	LOSS [training: -0.010441599228714467 | validation: -0.017856872163410607]
	TIME [epoch: 18.9 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_131.pth
	Model improved!!!
EPOCH 132/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009154185079260767		[learning rate: 0.002851]
	Learning Rate: 0.00285102
	LOSS [training: -0.009154185079260767 | validation: 0.006574832213876229]
	TIME [epoch: 18.9 sec]
EPOCH 133/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0012082292472789886		[learning rate: 0.0028076]
	Learning Rate: 0.00280759
	LOSS [training: -0.0012082292472789886 | validation: -0.007015971342803264]
	TIME [epoch: 18.9 sec]
EPOCH 134/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0023640877159799957		[learning rate: 0.0027648]
	Learning Rate: 0.00276482
	LOSS [training: -0.0023640877159799957 | validation: 0.0036402482233210444]
	TIME [epoch: 18.9 sec]
EPOCH 135/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00021302164276258343		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.00021302164276258343 | validation: 0.008416601905123161]
	TIME [epoch: 18.9 sec]
EPOCH 136/500:
	Training over batches...
		[batch 4/4] avg loss: 0.004883690635505136		[learning rate: 0.0026812]
	Learning Rate: 0.00268123
	LOSS [training: 0.004883690635505136 | validation: 0.002641411755732943]
	TIME [epoch: 18.9 sec]
EPOCH 137/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009772201559023749		[learning rate: 0.0026404]
	Learning Rate: 0.00264038
	LOSS [training: 0.009772201559023749 | validation: -0.0006997057975448783]
	TIME [epoch: 18.9 sec]
EPOCH 138/500:
	Training over batches...
		[batch 4/4] avg loss: 0.005349667477880262		[learning rate: 0.0026002]
	Learning Rate: 0.00260016
	LOSS [training: 0.005349667477880262 | validation: 0.01934281217791002]
	TIME [epoch: 18.9 sec]
EPOCH 139/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0062092163632466325		[learning rate: 0.0025606]
	Learning Rate: 0.00256055
	LOSS [training: 0.0062092163632466325 | validation: 0.004326603835240914]
	TIME [epoch: 18.9 sec]
EPOCH 140/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00011405828076429614		[learning rate: 0.0025215]
	Learning Rate: 0.00252154
	LOSS [training: 0.00011405828076429614 | validation: 0.0019284043047118069]
	TIME [epoch: 18.9 sec]
EPOCH 141/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0013100431935054923		[learning rate: 0.0024831]
	Learning Rate: 0.00248313
	LOSS [training: 0.0013100431935054923 | validation: -0.0006285591987772088]
	TIME [epoch: 18.9 sec]
EPOCH 142/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0006809102018169892		[learning rate: 0.0024453]
	Learning Rate: 0.00244531
	LOSS [training: 0.0006809102018169892 | validation: -0.017464877664776713]
	TIME [epoch: 18.9 sec]
EPOCH 143/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00569938140377308		[learning rate: 0.0024081]
	Learning Rate: 0.00240806
	LOSS [training: -0.00569938140377308 | validation: -0.006558477642341205]
	TIME [epoch: 18.9 sec]
EPOCH 144/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010903718552905891		[learning rate: 0.0023714]
	Learning Rate: 0.00237137
	LOSS [training: -0.010903718552905891 | validation: -0.002730781824153956]
	TIME [epoch: 18.9 sec]
EPOCH 145/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010409911521145376		[learning rate: 0.0023352]
	Learning Rate: 0.00233525
	LOSS [training: -0.010409911521145376 | validation: -0.009912226649472293]
	TIME [epoch: 18.9 sec]
EPOCH 146/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006816588710668311		[learning rate: 0.0022997]
	Learning Rate: 0.00229968
	LOSS [training: -0.006816588710668311 | validation: -0.0076015371717936715]
	TIME [epoch: 18.9 sec]
EPOCH 147/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009382515999318804		[learning rate: 0.0022646]
	Learning Rate: 0.00226464
	LOSS [training: -0.009382515999318804 | validation: -0.01158865314433889]
	TIME [epoch: 18.9 sec]
EPOCH 148/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007805001176929756		[learning rate: 0.0022301]
	Learning Rate: 0.00223015
	LOSS [training: -0.007805001176929756 | validation: 0.00016002163488535793]
	TIME [epoch: 18.9 sec]
EPOCH 149/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005378244908131526		[learning rate: 0.0021962]
	Learning Rate: 0.00219617
	LOSS [training: -0.005378244908131526 | validation: -0.0076293465397161975]
	TIME [epoch: 19 sec]
EPOCH 150/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011018179199722266		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: -0.011018179199722266 | validation: 0.0012986929634729119]
	TIME [epoch: 18.9 sec]
EPOCH 151/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00836669599345978		[learning rate: 0.0021298]
	Learning Rate: 0.00212977
	LOSS [training: -0.00836669599345978 | validation: 0.005531775896194651]
	TIME [epoch: 18.9 sec]
EPOCH 152/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01046497818427876		[learning rate: 0.0020973]
	Learning Rate: 0.00209733
	LOSS [training: -0.01046497818427876 | validation: -0.01125964790439684]
	TIME [epoch: 18.9 sec]
EPOCH 153/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012603538698938528		[learning rate: 0.0020654]
	Learning Rate: 0.00206538
	LOSS [training: -0.012603538698938528 | validation: 0.002287124246350321]
	TIME [epoch: 18.8 sec]
EPOCH 154/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004936553461332491		[learning rate: 0.0020339]
	Learning Rate: 0.00203392
	LOSS [training: -0.004936553461332491 | validation: -0.008860260380928575]
	TIME [epoch: 18.9 sec]
EPOCH 155/500:
	Training over batches...
		[batch 4/4] avg loss: -0.000831367806768775		[learning rate: 0.0020029]
	Learning Rate: 0.00200293
	LOSS [training: -0.000831367806768775 | validation: -0.0025987220599451976]
	TIME [epoch: 18.8 sec]
EPOCH 156/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004678883224604502		[learning rate: 0.0019724]
	Learning Rate: 0.00197242
	LOSS [training: -0.004678883224604502 | validation: 0.0008217483367483529]
	TIME [epoch: 18.9 sec]
EPOCH 157/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004586086152763203		[learning rate: 0.0019424]
	Learning Rate: 0.00194238
	LOSS [training: -0.004586086152763203 | validation: -0.009182412904320338]
	TIME [epoch: 18.8 sec]
EPOCH 158/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010018432796460171		[learning rate: 0.0019128]
	Learning Rate: 0.00191279
	LOSS [training: -0.010018432796460171 | validation: -0.013893756294116849]
	TIME [epoch: 18.9 sec]
EPOCH 159/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012090759558068185		[learning rate: 0.0018836]
	Learning Rate: 0.00188365
	LOSS [training: -0.012090759558068185 | validation: -0.005126914283909307]
	TIME [epoch: 18.9 sec]
EPOCH 160/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012963423710738995		[learning rate: 0.001855]
	Learning Rate: 0.00185495
	LOSS [training: -0.012963423710738995 | validation: -0.009760786875283332]
	TIME [epoch: 18.9 sec]
EPOCH 161/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011557494925645537		[learning rate: 0.0018267]
	Learning Rate: 0.0018267
	LOSS [training: -0.011557494925645537 | validation: -0.009638955467322859]
	TIME [epoch: 18.9 sec]
EPOCH 162/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014960469620812381		[learning rate: 0.0017989]
	Learning Rate: 0.00179887
	LOSS [training: -0.014960469620812381 | validation: -0.015630694683049947]
	TIME [epoch: 18.9 sec]
EPOCH 163/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006346124637479032		[learning rate: 0.0017715]
	Learning Rate: 0.00177147
	LOSS [training: -0.006346124637479032 | validation: -0.000387296402655112]
	TIME [epoch: 18.9 sec]
EPOCH 164/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00976119005413973		[learning rate: 0.0017445]
	Learning Rate: 0.00174448
	LOSS [training: -0.00976119005413973 | validation: -0.007848930996821]
	TIME [epoch: 18.9 sec]
EPOCH 165/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01417445086336307		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: -0.01417445086336307 | validation: -0.009777017456757728]
	TIME [epoch: 18.9 sec]
EPOCH 166/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007040327564752367		[learning rate: 0.0016917]
	Learning Rate: 0.00169174
	LOSS [training: -0.007040327564752367 | validation: -0.005177566611135169]
	TIME [epoch: 18.9 sec]
EPOCH 167/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014033995428363824		[learning rate: 0.001666]
	Learning Rate: 0.00166597
	LOSS [training: -0.014033995428363824 | validation: 0.0033109629720831733]
	TIME [epoch: 18.9 sec]
EPOCH 168/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00799821826311463		[learning rate: 0.0016406]
	Learning Rate: 0.00164059
	LOSS [training: -0.00799821826311463 | validation: -0.004792618257016773]
	TIME [epoch: 18.8 sec]
EPOCH 169/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00733717728168486		[learning rate: 0.0016156]
	Learning Rate: 0.0016156
	LOSS [training: -0.00733717728168486 | validation: 0.0017933999144924672]
	TIME [epoch: 18.9 sec]
EPOCH 170/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008461188625644375		[learning rate: 0.001591]
	Learning Rate: 0.00159099
	LOSS [training: -0.008461188625644375 | validation: -0.008442621685417965]
	TIME [epoch: 18.9 sec]
EPOCH 171/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014971451674544292		[learning rate: 0.0015668]
	Learning Rate: 0.00156675
	LOSS [training: -0.014971451674544292 | validation: -0.017750673013893957]
	TIME [epoch: 18.8 sec]
EPOCH 172/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009287699284478715		[learning rate: 0.0015429]
	Learning Rate: 0.00154288
	LOSS [training: -0.009287699284478715 | validation: -0.011074101865474804]
	TIME [epoch: 18.9 sec]
EPOCH 173/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007971299886021372		[learning rate: 0.0015194]
	Learning Rate: 0.00151938
	LOSS [training: -0.007971299886021372 | validation: -0.004829388451682241]
	TIME [epoch: 18.9 sec]
EPOCH 174/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009809465841539414		[learning rate: 0.0014962]
	Learning Rate: 0.00149624
	LOSS [training: -0.009809465841539414 | validation: -0.01850737412784432]
	TIME [epoch: 19 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_174.pth
	Model improved!!!
EPOCH 175/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0060840657615540755		[learning rate: 0.0014734]
	Learning Rate: 0.00147344
	LOSS [training: -0.0060840657615540755 | validation: -0.005984380851376668]
	TIME [epoch: 18.8 sec]
EPOCH 176/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008990998286269813		[learning rate: 0.001451]
	Learning Rate: 0.001451
	LOSS [training: -0.008990998286269813 | validation: -0.007649222730919282]
	TIME [epoch: 18.9 sec]
EPOCH 177/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008429516927831166		[learning rate: 0.0014289]
	Learning Rate: 0.00142889
	LOSS [training: -0.008429516927831166 | validation: -0.0038992373115638167]
	TIME [epoch: 18.9 sec]
EPOCH 178/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010261814159005381		[learning rate: 0.0014071]
	Learning Rate: 0.00140713
	LOSS [training: -0.010261814159005381 | validation: -0.01161448959574837]
	TIME [epoch: 18.9 sec]
EPOCH 179/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010061029910575087		[learning rate: 0.0013857]
	Learning Rate: 0.00138569
	LOSS [training: -0.010061029910575087 | validation: -0.005659823050685891]
	TIME [epoch: 18.9 sec]
EPOCH 180/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007436274552423339		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: -0.007436274552423339 | validation: -0.009634320284482441]
	TIME [epoch: 18.8 sec]
EPOCH 181/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008938792746189044		[learning rate: 0.0013438]
	Learning Rate: 0.0013438
	LOSS [training: -0.008938792746189044 | validation: -0.009233415087623011]
	TIME [epoch: 18.9 sec]
EPOCH 182/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009661866222963462		[learning rate: 0.0013233]
	Learning Rate: 0.00132333
	LOSS [training: -0.009661866222963462 | validation: -0.008275838720675789]
	TIME [epoch: 18.9 sec]
EPOCH 183/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009103117222639758		[learning rate: 0.0013032]
	Learning Rate: 0.00130317
	LOSS [training: -0.009103117222639758 | validation: -0.007463311378996808]
	TIME [epoch: 18.9 sec]
EPOCH 184/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010134623010331545		[learning rate: 0.0012833]
	Learning Rate: 0.00128332
	LOSS [training: -0.010134623010331545 | validation: 0.0018490764538648722]
	TIME [epoch: 18.8 sec]
EPOCH 185/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0035546058290127852		[learning rate: 0.0012638]
	Learning Rate: 0.00126377
	LOSS [training: -0.0035546058290127852 | validation: -0.007673517699777902]
	TIME [epoch: 18.9 sec]
EPOCH 186/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004963782904894659		[learning rate: 0.0012445]
	Learning Rate: 0.00124451
	LOSS [training: -0.004963782904894659 | validation: -0.015417246084884786]
	TIME [epoch: 18.8 sec]
EPOCH 187/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011932251976339753		[learning rate: 0.0012256]
	Learning Rate: 0.00122556
	LOSS [training: -0.011932251976339753 | validation: -0.015403940507142524]
	TIME [epoch: 18.9 sec]
EPOCH 188/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01410069635324063		[learning rate: 0.0012069]
	Learning Rate: 0.00120689
	LOSS [training: -0.01410069635324063 | validation: -0.012453476876122898]
	TIME [epoch: 18.8 sec]
EPOCH 189/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009551835342566367		[learning rate: 0.0011885]
	Learning Rate: 0.0011885
	LOSS [training: -0.009551835342566367 | validation: -0.0060366545154599775]
	TIME [epoch: 18.9 sec]
EPOCH 190/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009873580192074615		[learning rate: 0.0011704]
	Learning Rate: 0.0011704
	LOSS [training: -0.009873580192074615 | validation: -0.010963109992954528]
	TIME [epoch: 18.9 sec]
EPOCH 191/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007932895770347807		[learning rate: 0.0011526]
	Learning Rate: 0.00115257
	LOSS [training: -0.007932895770347807 | validation: -0.008839500434268623]
	TIME [epoch: 18.8 sec]
EPOCH 192/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010468895788040517		[learning rate: 0.001135]
	Learning Rate: 0.00113501
	LOSS [training: -0.010468895788040517 | validation: -0.006876424589721731]
	TIME [epoch: 18.9 sec]
EPOCH 193/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011556258644065582		[learning rate: 0.0011177]
	Learning Rate: 0.00111772
	LOSS [training: -0.011556258644065582 | validation: -0.007100839638505086]
	TIME [epoch: 18.9 sec]
EPOCH 194/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011062043843157732		[learning rate: 0.0011007]
	Learning Rate: 0.00110069
	LOSS [training: -0.011062043843157732 | validation: -0.010266412414504518]
	TIME [epoch: 18.9 sec]
EPOCH 195/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009458597604315699		[learning rate: 0.0010839]
	Learning Rate: 0.00108393
	LOSS [training: -0.009458597604315699 | validation: -0.008595995930631069]
	TIME [epoch: 18.9 sec]
EPOCH 196/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01435710475726841		[learning rate: 0.0010674]
	Learning Rate: 0.00106741
	LOSS [training: -0.01435710475726841 | validation: -0.0059108288905081715]
	TIME [epoch: 18.9 sec]
EPOCH 197/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00861648848833228		[learning rate: 0.0010512]
	Learning Rate: 0.00105115
	LOSS [training: -0.00861648848833228 | validation: -0.00735173224969186]
	TIME [epoch: 18.8 sec]
EPOCH 198/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012528407972448618		[learning rate: 0.0010351]
	Learning Rate: 0.00103514
	LOSS [training: -0.012528407972448618 | validation: -0.017945583173618287]
	TIME [epoch: 18.9 sec]
EPOCH 199/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011854952783454437		[learning rate: 0.0010194]
	Learning Rate: 0.00101937
	LOSS [training: -0.011854952783454437 | validation: -0.005453575891403715]
	TIME [epoch: 19 sec]
EPOCH 200/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012357421474870586		[learning rate: 0.0010038]
	Learning Rate: 0.00100384
	LOSS [training: -0.012357421474870586 | validation: -0.015078656175003785]
	TIME [epoch: 18.9 sec]
EPOCH 201/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007554537911774224		[learning rate: 0.00098855]
	Learning Rate: 0.000988553
	LOSS [training: -0.007554537911774224 | validation: 0.011729289195588006]
	TIME [epoch: 18.9 sec]
EPOCH 202/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004341362056601838		[learning rate: 0.00097349]
	Learning Rate: 0.000973494
	LOSS [training: -0.004341362056601838 | validation: -0.0023277641658111833]
	TIME [epoch: 18.9 sec]
EPOCH 203/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005858440605635875		[learning rate: 0.00095866]
	Learning Rate: 0.000958664
	LOSS [training: -0.005858440605635875 | validation: 0.0010896779373540302]
	TIME [epoch: 18.9 sec]
EPOCH 204/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011262328351436632		[learning rate: 0.00094406]
	Learning Rate: 0.000944061
	LOSS [training: -0.011262328351436632 | validation: -0.014917863177239182]
	TIME [epoch: 18.9 sec]
EPOCH 205/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010885316676560425		[learning rate: 0.00092968]
	Learning Rate: 0.00092968
	LOSS [training: -0.010885316676560425 | validation: -0.008483613078342174]
	TIME [epoch: 18.9 sec]
EPOCH 206/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005864504732959497		[learning rate: 0.00091552]
	Learning Rate: 0.000915518
	LOSS [training: -0.005864504732959497 | validation: -0.0052583883284855314]
	TIME [epoch: 18.8 sec]
EPOCH 207/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006969527727978564		[learning rate: 0.00090157]
	Learning Rate: 0.000901571
	LOSS [training: -0.006969527727978564 | validation: -0.003693286542044934]
	TIME [epoch: 18.9 sec]
EPOCH 208/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008780438169510102		[learning rate: 0.00088784]
	Learning Rate: 0.000887837
	LOSS [training: -0.008780438169510102 | validation: -0.016168199202244656]
	TIME [epoch: 18.9 sec]
EPOCH 209/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009156312873810846		[learning rate: 0.00087431]
	Learning Rate: 0.000874312
	LOSS [training: -0.009156312873810846 | validation: -0.012133074787243868]
	TIME [epoch: 18.8 sec]
EPOCH 210/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011581643529172856		[learning rate: 0.00086099]
	Learning Rate: 0.000860994
	LOSS [training: -0.011581643529172856 | validation: 0.0027646908193272573]
	TIME [epoch: 18.9 sec]
EPOCH 211/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008436455322810801		[learning rate: 0.00084788]
	Learning Rate: 0.000847878
	LOSS [training: -0.008436455322810801 | validation: -0.011759745597120345]
	TIME [epoch: 18.8 sec]
EPOCH 212/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007427779655793493		[learning rate: 0.00083496]
	Learning Rate: 0.000834962
	LOSS [training: -0.007427779655793493 | validation: -0.008368758375033723]
	TIME [epoch: 18.9 sec]
EPOCH 213/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007127718728688243		[learning rate: 0.00082224]
	Learning Rate: 0.000822243
	LOSS [training: -0.007127718728688243 | validation: -0.013242762032332277]
	TIME [epoch: 18.8 sec]
EPOCH 214/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011840043172791285		[learning rate: 0.00080972]
	Learning Rate: 0.000809717
	LOSS [training: -0.011840043172791285 | validation: -0.0056189175145972175]
	TIME [epoch: 18.9 sec]
EPOCH 215/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014325625191946273		[learning rate: 0.00079738]
	Learning Rate: 0.000797382
	LOSS [training: -0.014325625191946273 | validation: -0.0049396914082948384]
	TIME [epoch: 18.9 sec]
EPOCH 216/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009712675414889698		[learning rate: 0.00078524]
	Learning Rate: 0.000785236
	LOSS [training: -0.009712675414889698 | validation: -0.007273928932809554]
	TIME [epoch: 18.9 sec]
EPOCH 217/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010126570023121804		[learning rate: 0.00077327]
	Learning Rate: 0.000773274
	LOSS [training: -0.010126570023121804 | validation: -0.00647267654093138]
	TIME [epoch: 18.9 sec]
EPOCH 218/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009782211716191749		[learning rate: 0.00076149]
	Learning Rate: 0.000761494
	LOSS [training: -0.009782211716191749 | validation: -0.0014927040548959897]
	TIME [epoch: 18.8 sec]
EPOCH 219/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008588544115488945		[learning rate: 0.00074989]
	Learning Rate: 0.000749894
	LOSS [training: -0.008588544115488945 | validation: -0.006523588672277959]
	TIME [epoch: 19 sec]
EPOCH 220/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012970344118654838		[learning rate: 0.00073847]
	Learning Rate: 0.000738471
	LOSS [training: -0.012970344118654838 | validation: -0.005496218203674753]
	TIME [epoch: 18.8 sec]
EPOCH 221/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012994187150889881		[learning rate: 0.00072722]
	Learning Rate: 0.000727221
	LOSS [training: -0.012994187150889881 | validation: -0.00363867941466462]
	TIME [epoch: 18.9 sec]
EPOCH 222/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009979827822041681		[learning rate: 0.00071614]
	Learning Rate: 0.000716143
	LOSS [training: -0.009979827822041681 | validation: -0.007536378338833887]
	TIME [epoch: 18.8 sec]
EPOCH 223/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010636773420768157		[learning rate: 0.00070523]
	Learning Rate: 0.000705234
	LOSS [training: -0.010636773420768157 | validation: -0.008531049915591485]
	TIME [epoch: 18.9 sec]
EPOCH 224/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00878015906428797		[learning rate: 0.00069449]
	Learning Rate: 0.000694491
	LOSS [training: -0.00878015906428797 | validation: -0.0023238936121499068]
	TIME [epoch: 18.8 sec]
EPOCH 225/500:
	Training over batches...
		[batch 4/4] avg loss: -0.015390469215576033		[learning rate: 0.00068391]
	Learning Rate: 0.000683912
	LOSS [training: -0.015390469215576033 | validation: -0.008982607500302489]
	TIME [epoch: 18.9 sec]
EPOCH 226/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009777431248163932		[learning rate: 0.00067349]
	Learning Rate: 0.000673493
	LOSS [training: -0.009777431248163932 | validation: -0.008503548337240945]
	TIME [epoch: 18.9 sec]
EPOCH 227/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008841399349884493		[learning rate: 0.00066323]
	Learning Rate: 0.000663234
	LOSS [training: -0.008841399349884493 | validation: -0.009778406696062572]
	TIME [epoch: 18.9 sec]
EPOCH 228/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014563389496107393		[learning rate: 0.00065313]
	Learning Rate: 0.00065313
	LOSS [training: -0.014563389496107393 | validation: -0.008190565321488458]
	TIME [epoch: 18.9 sec]
EPOCH 229/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010946004116888158		[learning rate: 0.00064318]
	Learning Rate: 0.000643181
	LOSS [training: -0.010946004116888158 | validation: -0.011566965247907963]
	TIME [epoch: 18.8 sec]
EPOCH 230/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011369844112709752		[learning rate: 0.00063338]
	Learning Rate: 0.000633383
	LOSS [training: -0.011369844112709752 | validation: -0.006088033468718066]
	TIME [epoch: 18.9 sec]
EPOCH 231/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010571624596467245		[learning rate: 0.00062373]
	Learning Rate: 0.000623735
	LOSS [training: -0.010571624596467245 | validation: -0.006546498661539434]
	TIME [epoch: 18.9 sec]
EPOCH 232/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011400067925210783		[learning rate: 0.00061423]
	Learning Rate: 0.000614233
	LOSS [training: -0.011400067925210783 | validation: -6.61604117829567e-05]
	TIME [epoch: 18.9 sec]
EPOCH 233/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010576292315266052		[learning rate: 0.00060488]
	Learning Rate: 0.000604876
	LOSS [training: -0.010576292315266052 | validation: -0.010923328785776686]
	TIME [epoch: 18.8 sec]
EPOCH 234/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009087431648717996		[learning rate: 0.00059566]
	Learning Rate: 0.000595662
	LOSS [training: -0.009087431648717996 | validation: -0.01026280408052581]
	TIME [epoch: 18.9 sec]
EPOCH 235/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010794652829902678		[learning rate: 0.00058659]
	Learning Rate: 0.000586588
	LOSS [training: -0.010794652829902678 | validation: -0.006785645653801161]
	TIME [epoch: 18.9 sec]
EPOCH 236/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00834247473275149		[learning rate: 0.00057765]
	Learning Rate: 0.000577652
	LOSS [training: -0.00834247473275149 | validation: -0.014331413355889201]
	TIME [epoch: 18.9 sec]
EPOCH 237/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009716779780451427		[learning rate: 0.00056885]
	Learning Rate: 0.000568853
	LOSS [training: -0.009716779780451427 | validation: -0.009367792157936011]
	TIME [epoch: 18.9 sec]
EPOCH 238/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004410417050892875		[learning rate: 0.00056019]
	Learning Rate: 0.000560187
	LOSS [training: -0.004410417050892875 | validation: -0.003745908808288981]
	TIME [epoch: 18.8 sec]
EPOCH 239/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0054350248134507825		[learning rate: 0.00055165]
	Learning Rate: 0.000551654
	LOSS [training: -0.0054350248134507825 | validation: -0.008444218086903509]
	TIME [epoch: 18.9 sec]
EPOCH 240/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011517624469310978		[learning rate: 0.00054325]
	Learning Rate: 0.00054325
	LOSS [training: -0.011517624469310978 | validation: -0.008582094698588536]
	TIME [epoch: 18.8 sec]
EPOCH 241/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008063048646668099		[learning rate: 0.00053497]
	Learning Rate: 0.000534975
	LOSS [training: -0.008063048646668099 | validation: -0.013677742861414715]
	TIME [epoch: 18.9 sec]
EPOCH 242/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012235371412405143		[learning rate: 0.00052683]
	Learning Rate: 0.000526825
	LOSS [training: -0.012235371412405143 | validation: -0.010729559934554388]
	TIME [epoch: 18.8 sec]
EPOCH 243/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006766701609548048		[learning rate: 0.0005188]
	Learning Rate: 0.0005188
	LOSS [training: -0.006766701609548048 | validation: -0.011228398380826397]
	TIME [epoch: 19 sec]
EPOCH 244/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008466643687337568		[learning rate: 0.0005109]
	Learning Rate: 0.000510897
	LOSS [training: -0.008466643687337568 | validation: -0.008750256632558717]
	TIME [epoch: 19 sec]
EPOCH 245/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011574898254399987		[learning rate: 0.00050311]
	Learning Rate: 0.000503114
	LOSS [training: -0.011574898254399987 | validation: -0.008278080918617314]
	TIME [epoch: 18.9 sec]
EPOCH 246/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009112976093400607		[learning rate: 0.00049545]
	Learning Rate: 0.00049545
	LOSS [training: -0.009112976093400607 | validation: -0.011839266879855743]
	TIME [epoch: 19 sec]
EPOCH 247/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009534755924920969		[learning rate: 0.0004879]
	Learning Rate: 0.000487903
	LOSS [training: -0.009534755924920969 | validation: -0.010948920038265034]
	TIME [epoch: 19 sec]
EPOCH 248/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010210187331211816		[learning rate: 0.00048047]
	Learning Rate: 0.00048047
	LOSS [training: -0.010210187331211816 | validation: -0.0018766950648296849]
	TIME [epoch: 19 sec]
EPOCH 249/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008110385975007184		[learning rate: 0.00047315]
	Learning Rate: 0.000473151
	LOSS [training: -0.008110385975007184 | validation: -0.0019591981929855604]
	TIME [epoch: 18.8 sec]
EPOCH 250/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009839359005638103		[learning rate: 0.00046594]
	Learning Rate: 0.000465944
	LOSS [training: -0.009839359005638103 | validation: -0.009990098182807165]
	TIME [epoch: 19 sec]
EPOCH 251/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013704198980565324		[learning rate: 0.00045885]
	Learning Rate: 0.000458846
	LOSS [training: -0.013704198980565324 | validation: -0.01517078781750246]
	TIME [epoch: 139 sec]
EPOCH 252/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009188149444633715		[learning rate: 0.00045186]
	Learning Rate: 0.000451856
	LOSS [training: -0.009188149444633715 | validation: -0.008122987413006126]
	TIME [epoch: 42 sec]
EPOCH 253/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012176506330741896		[learning rate: 0.00044497]
	Learning Rate: 0.000444973
	LOSS [training: -0.012176506330741896 | validation: -0.012073076869709255]
	TIME [epoch: 42 sec]
EPOCH 254/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010564728635836677		[learning rate: 0.00043819]
	Learning Rate: 0.000438194
	LOSS [training: -0.010564728635836677 | validation: -0.005664143669123556]
	TIME [epoch: 41.9 sec]
EPOCH 255/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011635580234369024		[learning rate: 0.00043152]
	Learning Rate: 0.000431519
	LOSS [training: -0.011635580234369024 | validation: -0.008331294018814203]
	TIME [epoch: 41.9 sec]
EPOCH 256/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009660199395419126		[learning rate: 0.00042495]
	Learning Rate: 0.000424946
	LOSS [training: -0.009660199395419126 | validation: -0.0042886965237413964]
	TIME [epoch: 41.9 sec]
EPOCH 257/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010305932576640133		[learning rate: 0.00041847]
	Learning Rate: 0.000418472
	LOSS [training: -0.010305932576640133 | validation: -0.004733244362567339]
	TIME [epoch: 41.8 sec]
EPOCH 258/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00993466963471636		[learning rate: 0.0004121]
	Learning Rate: 0.000412098
	LOSS [training: -0.00993466963471636 | validation: -0.010517354455721464]
	TIME [epoch: 41.8 sec]
EPOCH 259/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006624577066852326		[learning rate: 0.00040582]
	Learning Rate: 0.00040582
	LOSS [training: -0.006624577066852326 | validation: -0.0050210125718812195]
	TIME [epoch: 41.8 sec]
EPOCH 260/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011928054120882197		[learning rate: 0.00039964]
	Learning Rate: 0.000399638
	LOSS [training: -0.011928054120882197 | validation: -0.01511464578782784]
	TIME [epoch: 41.8 sec]
EPOCH 261/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005424001231542981		[learning rate: 0.00039355]
	Learning Rate: 0.00039355
	LOSS [training: -0.005424001231542981 | validation: -0.01622081885485903]
	TIME [epoch: 41.8 sec]
EPOCH 262/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011618727649514637		[learning rate: 0.00038755]
	Learning Rate: 0.000387555
	LOSS [training: -0.011618727649514637 | validation: -0.0036185770183670913]
	TIME [epoch: 41.9 sec]
EPOCH 263/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009355529303255176		[learning rate: 0.00038165]
	Learning Rate: 0.000381651
	LOSS [training: -0.009355529303255176 | validation: -0.006990598663363119]
	TIME [epoch: 41.8 sec]
EPOCH 264/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0062067267524391		[learning rate: 0.00037584]
	Learning Rate: 0.000375837
	LOSS [training: -0.0062067267524391 | validation: -0.019884301764295762]
	TIME [epoch: 41.9 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_264.pth
	Model improved!!!
EPOCH 265/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012017401347346895		[learning rate: 0.00037011]
	Learning Rate: 0.000370112
	LOSS [training: -0.012017401347346895 | validation: -0.005542666147212082]
	TIME [epoch: 41.8 sec]
EPOCH 266/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009284711495099669		[learning rate: 0.00036447]
	Learning Rate: 0.000364474
	LOSS [training: -0.009284711495099669 | validation: -0.012378863550080702]
	TIME [epoch: 41.9 sec]
EPOCH 267/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009703971937244019		[learning rate: 0.00035892]
	Learning Rate: 0.000358922
	LOSS [training: -0.009703971937244019 | validation: -0.008560659053597944]
	TIME [epoch: 41.9 sec]
EPOCH 268/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010829655461900258		[learning rate: 0.00035345]
	Learning Rate: 0.000353454
	LOSS [training: -0.010829655461900258 | validation: 0.0020260742134340015]
	TIME [epoch: 41.8 sec]
EPOCH 269/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010855778909915327		[learning rate: 0.00034807]
	Learning Rate: 0.00034807
	LOSS [training: -0.010855778909915327 | validation: -0.012600333155465621]
	TIME [epoch: 41.8 sec]
EPOCH 270/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01147305558760703		[learning rate: 0.00034277]
	Learning Rate: 0.000342768
	LOSS [training: -0.01147305558760703 | validation: -0.008396777289050607]
	TIME [epoch: 41.8 sec]
EPOCH 271/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011182613933435495		[learning rate: 0.00033755]
	Learning Rate: 0.000337546
	LOSS [training: -0.011182613933435495 | validation: -0.007502730951309513]
	TIME [epoch: 41.8 sec]
EPOCH 272/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012697460968529426		[learning rate: 0.0003324]
	Learning Rate: 0.000332404
	LOSS [training: -0.012697460968529426 | validation: -0.004343388494082844]
	TIME [epoch: 41.8 sec]
EPOCH 273/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012627633541122379		[learning rate: 0.00032734]
	Learning Rate: 0.000327341
	LOSS [training: -0.012627633541122379 | validation: -0.010597529094887679]
	TIME [epoch: 41.8 sec]
EPOCH 274/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01037100821116681		[learning rate: 0.00032235]
	Learning Rate: 0.000322354
	LOSS [training: -0.01037100821116681 | validation: -0.01678228375517272]
	TIME [epoch: 41.9 sec]
EPOCH 275/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011160700220156364		[learning rate: 0.00031744]
	Learning Rate: 0.000317444
	LOSS [training: -0.011160700220156364 | validation: 0.0005826145357872578]
	TIME [epoch: 41.9 sec]
EPOCH 276/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011064027639381281		[learning rate: 0.00031261]
	Learning Rate: 0.000312608
	LOSS [training: -0.011064027639381281 | validation: -0.010227179988299532]
	TIME [epoch: 41.9 sec]
EPOCH 277/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01116166631865842		[learning rate: 0.00030785]
	Learning Rate: 0.000307846
	LOSS [training: -0.01116166631865842 | validation: -0.009099242399346293]
	TIME [epoch: 41.8 sec]
EPOCH 278/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009844662476495505		[learning rate: 0.00030316]
	Learning Rate: 0.000303156
	LOSS [training: -0.009844662476495505 | validation: -0.013324772560176532]
	TIME [epoch: 41.8 sec]
EPOCH 279/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013957866757719302		[learning rate: 0.00029854]
	Learning Rate: 0.000298538
	LOSS [training: -0.013957866757719302 | validation: -0.008322365063364309]
	TIME [epoch: 41.8 sec]
EPOCH 280/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009968107116902075		[learning rate: 0.00029399]
	Learning Rate: 0.000293991
	LOSS [training: -0.009968107116902075 | validation: -0.016222233456934184]
	TIME [epoch: 41.8 sec]
EPOCH 281/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00652889189502731		[learning rate: 0.00028951]
	Learning Rate: 0.000289512
	LOSS [training: -0.00652889189502731 | validation: -0.014321681059180594]
	TIME [epoch: 41.9 sec]
EPOCH 282/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010655146097950478		[learning rate: 0.0002851]
	Learning Rate: 0.000285102
	LOSS [training: -0.010655146097950478 | validation: -0.014286113490664918]
	TIME [epoch: 41.8 sec]
EPOCH 283/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01297693927854628		[learning rate: 0.00028076]
	Learning Rate: 0.000280759
	LOSS [training: -0.01297693927854628 | validation: -0.012014745345014566]
	TIME [epoch: 41.8 sec]
EPOCH 284/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013238054975151313		[learning rate: 0.00027648]
	Learning Rate: 0.000276482
	LOSS [training: -0.013238054975151313 | validation: -0.008161720701039038]
	TIME [epoch: 41.8 sec]
EPOCH 285/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009942523287234375		[learning rate: 0.00027227]
	Learning Rate: 0.00027227
	LOSS [training: -0.009942523287234375 | validation: -0.014975032107647052]
	TIME [epoch: 41.9 sec]
EPOCH 286/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009476258795076813		[learning rate: 0.00026812]
	Learning Rate: 0.000268123
	LOSS [training: -0.009476258795076813 | validation: -0.005380857258464999]
	TIME [epoch: 41.9 sec]
EPOCH 287/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011835026145796727		[learning rate: 0.00026404]
	Learning Rate: 0.000264038
	LOSS [training: -0.011835026145796727 | validation: -0.011807620714605024]
	TIME [epoch: 41.8 sec]
EPOCH 288/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011474347092830166		[learning rate: 0.00026002]
	Learning Rate: 0.000260016
	LOSS [training: -0.011474347092830166 | validation: 0.0037877747491787354]
	TIME [epoch: 41.9 sec]
EPOCH 289/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009879718853901114		[learning rate: 0.00025606]
	Learning Rate: 0.000256055
	LOSS [training: -0.009879718853901114 | validation: 0.000753810513405651]
	TIME [epoch: 41.9 sec]
EPOCH 290/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012124489845434728		[learning rate: 0.00025215]
	Learning Rate: 0.000252154
	LOSS [training: -0.012124489845434728 | validation: -0.01178319102927204]
	TIME [epoch: 42.1 sec]
EPOCH 291/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012596463934787598		[learning rate: 0.00024831]
	Learning Rate: 0.000248313
	LOSS [training: -0.012596463934787598 | validation: -0.01850027330639821]
	TIME [epoch: 42 sec]
EPOCH 292/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010675984376868935		[learning rate: 0.00024453]
	Learning Rate: 0.000244531
	LOSS [training: -0.010675984376868935 | validation: -0.0040797136001117194]
	TIME [epoch: 42 sec]
EPOCH 293/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013820590916578307		[learning rate: 0.00024081]
	Learning Rate: 0.000240806
	LOSS [training: -0.013820590916578307 | validation: -0.009528078969080044]
	TIME [epoch: 42 sec]
EPOCH 294/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013724305178852276		[learning rate: 0.00023714]
	Learning Rate: 0.000237137
	LOSS [training: -0.013724305178852276 | validation: -0.009896512530619926]
	TIME [epoch: 41.9 sec]
EPOCH 295/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00930000972837332		[learning rate: 0.00023352]
	Learning Rate: 0.000233525
	LOSS [training: -0.00930000972837332 | validation: -0.005520984459556818]
	TIME [epoch: 41.9 sec]
EPOCH 296/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009575021586597052		[learning rate: 0.00022997]
	Learning Rate: 0.000229968
	LOSS [training: -0.009575021586597052 | validation: -0.013714378843746364]
	TIME [epoch: 41.9 sec]
EPOCH 297/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012131659264841062		[learning rate: 0.00022646]
	Learning Rate: 0.000226464
	LOSS [training: -0.012131659264841062 | validation: -0.0028092815575073023]
	TIME [epoch: 41.9 sec]
EPOCH 298/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01524828082700684		[learning rate: 0.00022301]
	Learning Rate: 0.000223015
	LOSS [training: -0.01524828082700684 | validation: -0.008076268106652445]
	TIME [epoch: 41.9 sec]
EPOCH 299/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009004592075258087		[learning rate: 0.00021962]
	Learning Rate: 0.000219617
	LOSS [training: -0.009004592075258087 | validation: -0.006611599517466472]
	TIME [epoch: 41.9 sec]
EPOCH 300/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01192785281745454		[learning rate: 0.00021627]
	Learning Rate: 0.000216272
	LOSS [training: -0.01192785281745454 | validation: -0.003974186176181187]
	TIME [epoch: 41.9 sec]
EPOCH 301/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01371551639268744		[learning rate: 0.00021298]
	Learning Rate: 0.000212977
	LOSS [training: -0.01371551639268744 | validation: -0.007060539263424497]
	TIME [epoch: 41.9 sec]
EPOCH 302/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00742656877460675		[learning rate: 0.00020973]
	Learning Rate: 0.000209733
	LOSS [training: -0.00742656877460675 | validation: -0.007070477989555292]
	TIME [epoch: 41.8 sec]
EPOCH 303/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012132686954174961		[learning rate: 0.00020654]
	Learning Rate: 0.000206538
	LOSS [training: -0.012132686954174961 | validation: -0.0040272966773728025]
	TIME [epoch: 41.9 sec]
EPOCH 304/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012682119713469293		[learning rate: 0.00020339]
	Learning Rate: 0.000203392
	LOSS [training: -0.012682119713469293 | validation: -0.0003577748846851983]
	TIME [epoch: 41.9 sec]
EPOCH 305/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008450065586267635		[learning rate: 0.00020029]
	Learning Rate: 0.000200293
	LOSS [training: -0.008450065586267635 | validation: -0.013167517544821108]
	TIME [epoch: 41.9 sec]
EPOCH 306/500:
	Training over batches...
		[batch 4/4] avg loss: -0.017471989699253274		[learning rate: 0.00019724]
	Learning Rate: 0.000197242
	LOSS [training: -0.017471989699253274 | validation: -0.01703187745350765]
	TIME [epoch: 41.9 sec]
EPOCH 307/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012709191057486295		[learning rate: 0.00019424]
	Learning Rate: 0.000194238
	LOSS [training: -0.012709191057486295 | validation: -0.01326704686370709]
	TIME [epoch: 41.9 sec]
EPOCH 308/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01373722171474884		[learning rate: 0.00019128]
	Learning Rate: 0.000191279
	LOSS [training: -0.01373722171474884 | validation: -0.013129125109731278]
	TIME [epoch: 41.9 sec]
EPOCH 309/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00983295294857511		[learning rate: 0.00018836]
	Learning Rate: 0.000188365
	LOSS [training: -0.00983295294857511 | validation: -0.011347937948488832]
	TIME [epoch: 41.9 sec]
EPOCH 310/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013252981930002024		[learning rate: 0.0001855]
	Learning Rate: 0.000185495
	LOSS [training: -0.013252981930002024 | validation: -0.009346719750521579]
	TIME [epoch: 41.9 sec]
EPOCH 311/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012427165509868762		[learning rate: 0.00018267]
	Learning Rate: 0.00018267
	LOSS [training: -0.012427165509868762 | validation: -0.015046547349117912]
	TIME [epoch: 41.8 sec]
EPOCH 312/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010655846777996813		[learning rate: 0.00017989]
	Learning Rate: 0.000179887
	LOSS [training: -0.010655846777996813 | validation: -0.008255603415910683]
	TIME [epoch: 41.8 sec]
EPOCH 313/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006801658460492902		[learning rate: 0.00017715]
	Learning Rate: 0.000177147
	LOSS [training: -0.006801658460492902 | validation: -0.003834065515933704]
	TIME [epoch: 41.9 sec]
EPOCH 314/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012547956536865027		[learning rate: 0.00017445]
	Learning Rate: 0.000174448
	LOSS [training: -0.012547956536865027 | validation: -0.00800016624373583]
	TIME [epoch: 41.9 sec]
EPOCH 315/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009355383395502005		[learning rate: 0.00017179]
	Learning Rate: 0.000171791
	LOSS [training: -0.009355383395502005 | validation: -0.016906096766158504]
	TIME [epoch: 41.9 sec]
EPOCH 316/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010048773090577895		[learning rate: 0.00016917]
	Learning Rate: 0.000169174
	LOSS [training: -0.010048773090577895 | validation: -0.009941400109894217]
	TIME [epoch: 41.9 sec]
EPOCH 317/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013138697578071562		[learning rate: 0.0001666]
	Learning Rate: 0.000166597
	LOSS [training: -0.013138697578071562 | validation: -0.01659372822874755]
	TIME [epoch: 41.8 sec]
EPOCH 318/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010468978661278109		[learning rate: 0.00016406]
	Learning Rate: 0.000164059
	LOSS [training: -0.010468978661278109 | validation: 0.0018120426359886236]
	TIME [epoch: 41.8 sec]
EPOCH 319/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01117713889851135		[learning rate: 0.00016156]
	Learning Rate: 0.00016156
	LOSS [training: -0.01117713889851135 | validation: -0.00831523784297259]
	TIME [epoch: 41.8 sec]
EPOCH 320/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012083117504470133		[learning rate: 0.0001591]
	Learning Rate: 0.000159099
	LOSS [training: -0.012083117504470133 | validation: -0.00698388013106768]
	TIME [epoch: 41.9 sec]
EPOCH 321/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013836720148519919		[learning rate: 0.00015668]
	Learning Rate: 0.000156675
	LOSS [training: -0.013836720148519919 | validation: -0.009846380585334841]
	TIME [epoch: 41.9 sec]
EPOCH 322/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010751678318153214		[learning rate: 0.00015429]
	Learning Rate: 0.000154288
	LOSS [training: -0.010751678318153214 | validation: -0.01042187937969727]
	TIME [epoch: 41.9 sec]
EPOCH 323/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012649690983513378		[learning rate: 0.00015194]
	Learning Rate: 0.000151938
	LOSS [training: -0.012649690983513378 | validation: -0.009443619885987884]
	TIME [epoch: 41.8 sec]
EPOCH 324/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011148855941486615		[learning rate: 0.00014962]
	Learning Rate: 0.000149624
	LOSS [training: -0.011148855941486615 | validation: -0.0046383034790958315]
	TIME [epoch: 41.8 sec]
EPOCH 325/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005847796970326922		[learning rate: 0.00014734]
	Learning Rate: 0.000147344
	LOSS [training: -0.005847796970326922 | validation: -0.008805607835747234]
	TIME [epoch: 41.7 sec]
EPOCH 326/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014870469833555635		[learning rate: 0.0001451]
	Learning Rate: 0.0001451
	LOSS [training: -0.014870469833555635 | validation: -0.01655941812423923]
	TIME [epoch: 41.8 sec]
EPOCH 327/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012944260534802897		[learning rate: 0.00014289]
	Learning Rate: 0.000142889
	LOSS [training: -0.012944260534802897 | validation: -0.01581193234564437]
	TIME [epoch: 41.8 sec]
EPOCH 328/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01147704032819083		[learning rate: 0.00014071]
	Learning Rate: 0.000140713
	LOSS [training: -0.01147704032819083 | validation: -0.015509578758414667]
	TIME [epoch: 41.8 sec]
EPOCH 329/500:
	Training over batches...
		[batch 4/4] avg loss: -0.015638373905934994		[learning rate: 0.00013857]
	Learning Rate: 0.000138569
	LOSS [training: -0.015638373905934994 | validation: -0.01384215813679467]
	TIME [epoch: 41.8 sec]
EPOCH 330/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013338001814825471		[learning rate: 0.00013646]
	Learning Rate: 0.000136458
	LOSS [training: -0.013338001814825471 | validation: -0.0042313997885870145]
	TIME [epoch: 41.8 sec]
EPOCH 331/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011005130946170241		[learning rate: 0.00013438]
	Learning Rate: 0.00013438
	LOSS [training: -0.011005130946170241 | validation: -0.008683675334991526]
	TIME [epoch: 41.8 sec]
EPOCH 332/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014055269194527233		[learning rate: 0.00013233]
	Learning Rate: 0.000132333
	LOSS [training: -0.014055269194527233 | validation: -0.004762046467324951]
	TIME [epoch: 41.9 sec]
EPOCH 333/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010787322922185741		[learning rate: 0.00013032]
	Learning Rate: 0.000130317
	LOSS [training: -0.010787322922185741 | validation: -0.014249337116169332]
	TIME [epoch: 41.9 sec]
EPOCH 334/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01405441703711503		[learning rate: 0.00012833]
	Learning Rate: 0.000128332
	LOSS [training: -0.01405441703711503 | validation: -0.014177073386686376]
	TIME [epoch: 41.8 sec]
EPOCH 335/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0131691698052989		[learning rate: 0.00012638]
	Learning Rate: 0.000126377
	LOSS [training: -0.0131691698052989 | validation: -0.011239936692450308]
	TIME [epoch: 41.8 sec]
EPOCH 336/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013976256876915203		[learning rate: 0.00012445]
	Learning Rate: 0.000124451
	LOSS [training: -0.013976256876915203 | validation: -0.013998978732279094]
	TIME [epoch: 41.9 sec]
EPOCH 337/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009211675318969909		[learning rate: 0.00012256]
	Learning Rate: 0.000122556
	LOSS [training: -0.009211675318969909 | validation: -0.01998683529746765]
	TIME [epoch: 42 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_337.pth
	Model improved!!!
EPOCH 338/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01352595773565549		[learning rate: 0.00012069]
	Learning Rate: 0.000120689
	LOSS [training: -0.01352595773565549 | validation: -0.009969379460444919]
	TIME [epoch: 41.9 sec]
EPOCH 339/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01247683795934415		[learning rate: 0.00011885]
	Learning Rate: 0.00011885
	LOSS [training: -0.01247683795934415 | validation: -0.013231680187794562]
	TIME [epoch: 41.9 sec]
EPOCH 340/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010497156249321314		[learning rate: 0.00011704]
	Learning Rate: 0.00011704
	LOSS [training: -0.010497156249321314 | validation: -0.004982646656336357]
	TIME [epoch: 41.8 sec]
EPOCH 341/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011526769585243894		[learning rate: 0.00011526]
	Learning Rate: 0.000115257
	LOSS [training: -0.011526769585243894 | validation: -0.002656348653171635]
	TIME [epoch: 41.8 sec]
EPOCH 342/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012852571021146933		[learning rate: 0.0001135]
	Learning Rate: 0.000113501
	LOSS [training: -0.012852571021146933 | validation: -0.007436093718189055]
	TIME [epoch: 41.8 sec]
EPOCH 343/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009433236715584964		[learning rate: 0.00011177]
	Learning Rate: 0.000111772
	LOSS [training: -0.009433236715584964 | validation: -0.01831925189385384]
	TIME [epoch: 41.8 sec]
EPOCH 344/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01142891716406901		[learning rate: 0.00011007]
	Learning Rate: 0.000110069
	LOSS [training: -0.01142891716406901 | validation: -0.01541635768171282]
	TIME [epoch: 41.8 sec]
EPOCH 345/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014251826378065973		[learning rate: 0.00010839]
	Learning Rate: 0.000108393
	LOSS [training: -0.014251826378065973 | validation: -0.009045775381786721]
	TIME [epoch: 41.8 sec]
EPOCH 346/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014530612918222385		[learning rate: 0.00010674]
	Learning Rate: 0.000106742
	LOSS [training: -0.014530612918222385 | validation: -0.005847974889329204]
	TIME [epoch: 41.8 sec]
EPOCH 347/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013973360496740877		[learning rate: 0.00010512]
	Learning Rate: 0.000105115
	LOSS [training: -0.013973360496740877 | validation: -0.013135557012174157]
	TIME [epoch: 41.8 sec]
EPOCH 348/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010781163799034287		[learning rate: 0.00010351]
	Learning Rate: 0.000103514
	LOSS [training: -0.010781163799034287 | validation: -0.0051589130182440445]
	TIME [epoch: 41.8 sec]
EPOCH 349/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014875136858410607		[learning rate: 0.00010194]
	Learning Rate: 0.000101937
	LOSS [training: -0.014875136858410607 | validation: -0.008818996902877463]
	TIME [epoch: 41.8 sec]
EPOCH 350/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01550272927440834		[learning rate: 0.00010038]
	Learning Rate: 0.000100385
	LOSS [training: -0.01550272927440834 | validation: -0.011657916746387352]
	TIME [epoch: 41.8 sec]
EPOCH 351/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008701988614420885		[learning rate: 9.8855e-05]
	Learning Rate: 9.88553e-05
	LOSS [training: -0.008701988614420885 | validation: -0.009095969930831036]
	TIME [epoch: 41.9 sec]
EPOCH 352/500:
	Training over batches...
		[batch 4/4] avg loss: -0.018275333145024063		[learning rate: 9.7349e-05]
	Learning Rate: 9.73494e-05
	LOSS [training: -0.018275333145024063 | validation: -0.010972543209172726]
	TIME [epoch: 41.8 sec]
EPOCH 353/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010286058150318305		[learning rate: 9.5866e-05]
	Learning Rate: 9.58665e-05
	LOSS [training: -0.010286058150318305 | validation: -0.010427936368504975]
	TIME [epoch: 41.9 sec]
EPOCH 354/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01574502628953389		[learning rate: 9.4406e-05]
	Learning Rate: 9.44061e-05
	LOSS [training: -0.01574502628953389 | validation: -0.01199274106880743]
	TIME [epoch: 41.8 sec]
EPOCH 355/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014016410792187755		[learning rate: 9.2968e-05]
	Learning Rate: 9.2968e-05
	LOSS [training: -0.014016410792187755 | validation: -0.012445624560392912]
	TIME [epoch: 41.8 sec]
EPOCH 356/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009743907704392749		[learning rate: 9.1552e-05]
	Learning Rate: 9.15518e-05
	LOSS [training: -0.009743907704392749 | validation: -0.010422934296526255]
	TIME [epoch: 41.8 sec]
EPOCH 357/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014064864615917577		[learning rate: 9.0157e-05]
	Learning Rate: 9.01571e-05
	LOSS [training: -0.014064864615917577 | validation: -0.009408812388906049]
	TIME [epoch: 41.8 sec]
EPOCH 358/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01474864520801224		[learning rate: 8.8784e-05]
	Learning Rate: 8.87837e-05
	LOSS [training: -0.01474864520801224 | validation: -0.011882238851013052]
	TIME [epoch: 41.8 sec]
EPOCH 359/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012050428981553627		[learning rate: 8.7431e-05]
	Learning Rate: 8.74312e-05
	LOSS [training: -0.012050428981553627 | validation: -0.011009034903530028]
	TIME [epoch: 41.8 sec]
EPOCH 360/500:
	Training over batches...
		[batch 4/4] avg loss: -0.015246179261304556		[learning rate: 8.6099e-05]
	Learning Rate: 8.60994e-05
	LOSS [training: -0.015246179261304556 | validation: -0.0077914805996726145]
	TIME [epoch: 41.8 sec]
EPOCH 361/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013796238553857313		[learning rate: 8.4788e-05]
	Learning Rate: 8.47878e-05
	LOSS [training: -0.013796238553857313 | validation: -0.009021972262499536]
	TIME [epoch: 41.8 sec]
EPOCH 362/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01256622001453472		[learning rate: 8.3496e-05]
	Learning Rate: 8.34962e-05
	LOSS [training: -0.01256622001453472 | validation: -0.009001825128802775]
	TIME [epoch: 41.8 sec]
EPOCH 363/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012679693828917078		[learning rate: 8.2224e-05]
	Learning Rate: 8.22243e-05
	LOSS [training: -0.012679693828917078 | validation: -0.00014372375152481125]
	TIME [epoch: 41.8 sec]
EPOCH 364/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011015345592562033		[learning rate: 8.0972e-05]
	Learning Rate: 8.09717e-05
	LOSS [training: -0.011015345592562033 | validation: -0.017713806257268126]
	TIME [epoch: 41.8 sec]
EPOCH 365/500:
	Training over batches...
		[batch 4/4] avg loss: -0.015449763592036602		[learning rate: 7.9738e-05]
	Learning Rate: 7.97382e-05
	LOSS [training: -0.015449763592036602 | validation: -0.005637394232598313]
	TIME [epoch: 41.8 sec]
EPOCH 366/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01135261708119254		[learning rate: 7.8524e-05]
	Learning Rate: 7.85235e-05
	LOSS [training: -0.01135261708119254 | validation: -0.009478048178752111]
	TIME [epoch: 41.8 sec]
EPOCH 367/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014534754093091925		[learning rate: 7.7327e-05]
	Learning Rate: 7.73274e-05
	LOSS [training: -0.014534754093091925 | validation: -0.008447585620338757]
	TIME [epoch: 41.9 sec]
EPOCH 368/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010462149460814005		[learning rate: 7.6149e-05]
	Learning Rate: 7.61494e-05
	LOSS [training: -0.010462149460814005 | validation: -0.00887507680891613]
	TIME [epoch: 41.8 sec]
EPOCH 369/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012303650058583977		[learning rate: 7.4989e-05]
	Learning Rate: 7.49894e-05
	LOSS [training: -0.012303650058583977 | validation: -0.012271195260184635]
	TIME [epoch: 41.8 sec]
EPOCH 370/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012423967468349194		[learning rate: 7.3847e-05]
	Learning Rate: 7.38471e-05
	LOSS [training: -0.012423967468349194 | validation: -0.010410143248056728]
	TIME [epoch: 41.8 sec]
EPOCH 371/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014571490169301841		[learning rate: 7.2722e-05]
	Learning Rate: 7.27221e-05
	LOSS [training: -0.014571490169301841 | validation: -0.011727101806738627]
	TIME [epoch: 41.8 sec]
EPOCH 372/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012333434003369618		[learning rate: 7.1614e-05]
	Learning Rate: 7.16143e-05
	LOSS [training: -0.012333434003369618 | validation: -0.012806586476031008]
	TIME [epoch: 41.9 sec]
EPOCH 373/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014908995874067642		[learning rate: 7.0523e-05]
	Learning Rate: 7.05234e-05
	LOSS [training: -0.014908995874067642 | validation: -0.01703447027411238]
	TIME [epoch: 41.8 sec]
EPOCH 374/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012167173414844695		[learning rate: 6.9449e-05]
	Learning Rate: 6.94491e-05
	LOSS [training: -0.012167173414844695 | validation: -0.012205195171831443]
	TIME [epoch: 41.8 sec]
EPOCH 375/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012848818344141658		[learning rate: 6.8391e-05]
	Learning Rate: 6.83912e-05
	LOSS [training: -0.012848818344141658 | validation: -0.017075763935781925]
	TIME [epoch: 41.8 sec]
EPOCH 376/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010933214785678344		[learning rate: 6.7349e-05]
	Learning Rate: 6.73493e-05
	LOSS [training: -0.010933214785678344 | validation: -0.014235078462339125]
	TIME [epoch: 41.8 sec]
EPOCH 377/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014342665301588729		[learning rate: 6.6323e-05]
	Learning Rate: 6.63234e-05
	LOSS [training: -0.014342665301588729 | validation: -0.013564981279194869]
	TIME [epoch: 41.8 sec]
EPOCH 378/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012294868115726108		[learning rate: 6.5313e-05]
	Learning Rate: 6.5313e-05
	LOSS [training: -0.012294868115726108 | validation: -0.003367712205348353]
	TIME [epoch: 41.8 sec]
EPOCH 379/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010595992950615403		[learning rate: 6.4318e-05]
	Learning Rate: 6.43181e-05
	LOSS [training: -0.010595992950615403 | validation: -0.012664932728710731]
	TIME [epoch: 41.8 sec]
EPOCH 380/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010485010761942169		[learning rate: 6.3338e-05]
	Learning Rate: 6.33383e-05
	LOSS [training: -0.010485010761942169 | validation: -0.009539795393227976]
	TIME [epoch: 41.8 sec]
EPOCH 381/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014515806697820589		[learning rate: 6.2373e-05]
	Learning Rate: 6.23735e-05
	LOSS [training: -0.014515806697820589 | validation: -0.015965370569551364]
	TIME [epoch: 41.8 sec]
EPOCH 382/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012966115810172492		[learning rate: 6.1423e-05]
	Learning Rate: 6.14233e-05
	LOSS [training: -0.012966115810172492 | validation: -0.009620683196132719]
	TIME [epoch: 41.8 sec]
EPOCH 383/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012409208768970035		[learning rate: 6.0488e-05]
	Learning Rate: 6.04876e-05
	LOSS [training: -0.012409208768970035 | validation: -0.020290251977726093]
	TIME [epoch: 41.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_383.pth
	Model improved!!!
EPOCH 384/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006790758520077211		[learning rate: 5.9566e-05]
	Learning Rate: 5.95662e-05
	LOSS [training: -0.006790758520077211 | validation: -0.006850284717484541]
	TIME [epoch: 41.8 sec]
EPOCH 385/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014046029112006017		[learning rate: 5.8659e-05]
	Learning Rate: 5.86588e-05
	LOSS [training: -0.014046029112006017 | validation: -0.013149940380036211]
	TIME [epoch: 41.8 sec]
EPOCH 386/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014448134396776975		[learning rate: 5.7765e-05]
	Learning Rate: 5.77652e-05
	LOSS [training: -0.014448134396776975 | validation: -0.01848478580156124]
	TIME [epoch: 41.7 sec]
EPOCH 387/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014071535595148864		[learning rate: 5.6885e-05]
	Learning Rate: 5.68853e-05
	LOSS [training: -0.014071535595148864 | validation: -0.013167581936661902]
	TIME [epoch: 41.7 sec]
EPOCH 388/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011815645245312851		[learning rate: 5.6019e-05]
	Learning Rate: 5.60187e-05
	LOSS [training: -0.011815645245312851 | validation: -0.008682164962659722]
	TIME [epoch: 41.8 sec]
EPOCH 389/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014793230439330859		[learning rate: 5.5165e-05]
	Learning Rate: 5.51654e-05
	LOSS [training: -0.014793230439330859 | validation: -0.014237858063162943]
	TIME [epoch: 41.8 sec]
EPOCH 390/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010843127397442351		[learning rate: 5.4325e-05]
	Learning Rate: 5.4325e-05
	LOSS [training: -0.010843127397442351 | validation: -0.003932381394784377]
	TIME [epoch: 41.8 sec]
EPOCH 391/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008710247812867358		[learning rate: 5.3497e-05]
	Learning Rate: 5.34975e-05
	LOSS [training: -0.008710247812867358 | validation: -0.012467662415058887]
	TIME [epoch: 41.8 sec]
EPOCH 392/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013679826048984801		[learning rate: 5.2683e-05]
	Learning Rate: 5.26825e-05
	LOSS [training: -0.013679826048984801 | validation: -0.008907404346458456]
	TIME [epoch: 41.9 sec]
EPOCH 393/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01427575128612879		[learning rate: 5.188e-05]
	Learning Rate: 5.188e-05
	LOSS [training: -0.01427575128612879 | validation: -0.02141120528059478]
	TIME [epoch: 41.9 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_393.pth
	Model improved!!!
EPOCH 394/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011423673194246468		[learning rate: 5.109e-05]
	Learning Rate: 5.10897e-05
	LOSS [training: -0.011423673194246468 | validation: -0.010139945821310146]
	TIME [epoch: 41.8 sec]
EPOCH 395/500:
	Training over batches...
		[batch 4/4] avg loss: -0.015200940720887039		[learning rate: 5.0311e-05]
	Learning Rate: 5.03114e-05
	LOSS [training: -0.015200940720887039 | validation: -0.006210088928590513]
	TIME [epoch: 41.8 sec]
EPOCH 396/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013699023368728597		[learning rate: 4.9545e-05]
	Learning Rate: 4.9545e-05
	LOSS [training: -0.013699023368728597 | validation: -0.009714750459671078]
	TIME [epoch: 41.8 sec]
EPOCH 397/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011084276805109561		[learning rate: 4.879e-05]
	Learning Rate: 4.87903e-05
	LOSS [training: -0.011084276805109561 | validation: -0.010299645319698077]
	TIME [epoch: 41.8 sec]
EPOCH 398/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013717951142577862		[learning rate: 4.8047e-05]
	Learning Rate: 4.8047e-05
	LOSS [training: -0.013717951142577862 | validation: -0.009129617613792156]
	TIME [epoch: 41.8 sec]
EPOCH 399/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012361001708993192		[learning rate: 4.7315e-05]
	Learning Rate: 4.73151e-05
	LOSS [training: -0.012361001708993192 | validation: -0.019451052662891825]
	TIME [epoch: 41.8 sec]
EPOCH 400/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012188235535852462		[learning rate: 4.6594e-05]
	Learning Rate: 4.65944e-05
	LOSS [training: -0.012188235535852462 | validation: -0.012735026205700418]
	TIME [epoch: 41.8 sec]
EPOCH 401/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014077247640456978		[learning rate: 4.5885e-05]
	Learning Rate: 4.58846e-05
	LOSS [training: -0.014077247640456978 | validation: -0.012242061775478534]
	TIME [epoch: 41.7 sec]
EPOCH 402/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010480384761521279		[learning rate: 4.5186e-05]
	Learning Rate: 4.51856e-05
	LOSS [training: -0.010480384761521279 | validation: -0.016640556041382877]
	TIME [epoch: 41.7 sec]
EPOCH 403/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011528745289203357		[learning rate: 4.4497e-05]
	Learning Rate: 4.44973e-05
	LOSS [training: -0.011528745289203357 | validation: -0.0068373640623457235]
	TIME [epoch: 41.7 sec]
EPOCH 404/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006719052774873423		[learning rate: 4.3819e-05]
	Learning Rate: 4.38194e-05
	LOSS [training: -0.006719052774873423 | validation: -0.008687166328802525]
	TIME [epoch: 41.7 sec]
EPOCH 405/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008304263137005557		[learning rate: 4.3152e-05]
	Learning Rate: 4.31519e-05
	LOSS [training: -0.008304263137005557 | validation: -0.00538064060498815]
	TIME [epoch: 41.7 sec]
EPOCH 406/500:
	Training over batches...
		[batch 4/4] avg loss: -0.016244188753016156		[learning rate: 4.2495e-05]
	Learning Rate: 4.24946e-05
	LOSS [training: -0.016244188753016156 | validation: -0.017145209314134754]
	TIME [epoch: 41.7 sec]
EPOCH 407/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011835130723310931		[learning rate: 4.1847e-05]
	Learning Rate: 4.18472e-05
	LOSS [training: -0.011835130723310931 | validation: -0.009542101318360613]
	TIME [epoch: 41.7 sec]
EPOCH 408/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01217376397504982		[learning rate: 4.121e-05]
	Learning Rate: 4.12098e-05
	LOSS [training: -0.01217376397504982 | validation: -0.008715550330106162]
	TIME [epoch: 41.7 sec]
EPOCH 409/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011210946253817976		[learning rate: 4.0582e-05]
	Learning Rate: 4.0582e-05
	LOSS [training: -0.011210946253817976 | validation: -0.005312040569215652]
	TIME [epoch: 41.7 sec]
EPOCH 410/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012631065013790709		[learning rate: 3.9964e-05]
	Learning Rate: 3.99638e-05
	LOSS [training: -0.012631065013790709 | validation: -0.01557362563917]
	TIME [epoch: 41.7 sec]
EPOCH 411/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009518643696262633		[learning rate: 3.9355e-05]
	Learning Rate: 3.9355e-05
	LOSS [training: -0.009518643696262633 | validation: -0.01091195061857056]
	TIME [epoch: 41.7 sec]
EPOCH 412/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01135892504412669		[learning rate: 3.8755e-05]
	Learning Rate: 3.87555e-05
	LOSS [training: -0.01135892504412669 | validation: -0.023180501647435695]
	TIME [epoch: 41.6 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20240705_010809/states/model_algphi1_1a_v_kl_412.pth
	Model improved!!!
EPOCH 413/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01443687404748251		[learning rate: 3.8165e-05]
	Learning Rate: 3.81651e-05
	LOSS [training: -0.01443687404748251 | validation: -0.008649326330448221]
	TIME [epoch: 41.8 sec]
EPOCH 414/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01384843789878171		[learning rate: 3.7584e-05]
	Learning Rate: 3.75837e-05
	LOSS [training: -0.01384843789878171 | validation: -0.00852734984786649]
	TIME [epoch: 41.8 sec]
EPOCH 415/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012466815047715412		[learning rate: 3.7011e-05]
	Learning Rate: 3.70112e-05
	LOSS [training: -0.012466815047715412 | validation: -0.02012853037987665]
	TIME [epoch: 41.8 sec]
EPOCH 416/500:
	Training over batches...
		[batch 4/4] avg loss: -0.015749497839664346		[learning rate: 3.6447e-05]
	Learning Rate: 3.64474e-05
	LOSS [training: -0.015749497839664346 | validation: -0.0063987567085753115]
	TIME [epoch: 41.8 sec]
EPOCH 417/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01357455434165768		[learning rate: 3.5892e-05]
	Learning Rate: 3.58922e-05
	LOSS [training: -0.01357455434165768 | validation: -0.0072015208227113]
	TIME [epoch: 41.8 sec]
EPOCH 418/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012016739435459119		[learning rate: 3.5345e-05]
	Learning Rate: 3.53454e-05
	LOSS [training: -0.012016739435459119 | validation: -0.006689627622135306]
	TIME [epoch: 41.8 sec]
EPOCH 419/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014619701826533604		[learning rate: 3.4807e-05]
	Learning Rate: 3.4807e-05
	LOSS [training: -0.014619701826533604 | validation: -0.0074001899485178334]
	TIME [epoch: 41.8 sec]
EPOCH 420/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014050228631992498		[learning rate: 3.4277e-05]
	Learning Rate: 3.42768e-05
	LOSS [training: -0.014050228631992498 | validation: -0.014220673161061513]
	TIME [epoch: 41.7 sec]
EPOCH 421/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009079278519629697		[learning rate: 3.3755e-05]
	Learning Rate: 3.37546e-05
	LOSS [training: -0.009079278519629697 | validation: -0.007354575788476368]
	TIME [epoch: 41.7 sec]
EPOCH 422/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01391281735404912		[learning rate: 3.324e-05]
	Learning Rate: 3.32404e-05
	LOSS [training: -0.01391281735404912 | validation: -0.005581764506029438]
	TIME [epoch: 41.7 sec]
EPOCH 423/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01243183043478527		[learning rate: 3.2734e-05]
	Learning Rate: 3.27341e-05
	LOSS [training: -0.01243183043478527 | validation: -0.013067053865501456]
	TIME [epoch: 41.7 sec]
EPOCH 424/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012001238386401238		[learning rate: 3.2235e-05]
	Learning Rate: 3.22354e-05
	LOSS [training: -0.012001238386401238 | validation: -0.016706314406559834]
	TIME [epoch: 41.6 sec]
EPOCH 425/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011335797262351425		[learning rate: 3.1744e-05]
	Learning Rate: 3.17444e-05
	LOSS [training: -0.011335797262351425 | validation: 0.004184062818347777]
	TIME [epoch: 41.7 sec]
EPOCH 426/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010723661775301874		[learning rate: 3.1261e-05]
	Learning Rate: 3.12608e-05
	LOSS [training: -0.010723661775301874 | validation: -0.012193718348926779]
	TIME [epoch: 41.7 sec]
EPOCH 427/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00941251598929019		[learning rate: 3.0785e-05]
	Learning Rate: 3.07846e-05
	LOSS [training: -0.00941251598929019 | validation: -0.007768146034446068]
	TIME [epoch: 41.7 sec]
EPOCH 428/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014379455029853706		[learning rate: 3.0316e-05]
	Learning Rate: 3.03156e-05
	LOSS [training: -0.014379455029853706 | validation: -0.00872151060645882]
	TIME [epoch: 41.7 sec]
EPOCH 429/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01016230249398024		[learning rate: 2.9854e-05]
	Learning Rate: 2.98538e-05
	LOSS [training: -0.01016230249398024 | validation: -0.011554883713554797]
	TIME [epoch: 41.7 sec]
EPOCH 430/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012478569768435893		[learning rate: 2.9399e-05]
	Learning Rate: 2.9399e-05
	LOSS [training: -0.012478569768435893 | validation: -0.013204120878073631]
	TIME [epoch: 41.7 sec]
EPOCH 431/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012733466031129553		[learning rate: 2.8951e-05]
	Learning Rate: 2.89512e-05
	LOSS [training: -0.012733466031129553 | validation: -0.0115936468179542]
	TIME [epoch: 41.7 sec]
EPOCH 432/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014179004528341328		[learning rate: 2.851e-05]
	Learning Rate: 2.85102e-05
	LOSS [training: -0.014179004528341328 | validation: -0.007406550070067013]
	TIME [epoch: 41.7 sec]
EPOCH 433/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010897083649815256		[learning rate: 2.8076e-05]
	Learning Rate: 2.80759e-05
	LOSS [training: -0.010897083649815256 | validation: -0.006644840667741035]
	TIME [epoch: 41.7 sec]
EPOCH 434/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0167942074674452		[learning rate: 2.7648e-05]
	Learning Rate: 2.76482e-05
	LOSS [training: -0.0167942074674452 | validation: -0.0189064535846486]
	TIME [epoch: 41.7 sec]
EPOCH 435/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012714270434106547		[learning rate: 2.7227e-05]
	Learning Rate: 2.7227e-05
	LOSS [training: -0.012714270434106547 | validation: -0.011875911925155429]
	TIME [epoch: 41.7 sec]
EPOCH 436/500:
	Training over batches...
		[batch 4/4] avg loss: -0.015334316680119994		[learning rate: 2.6812e-05]
	Learning Rate: 2.68122e-05
	LOSS [training: -0.015334316680119994 | validation: -0.016862831339480654]
	TIME [epoch: 41.8 sec]
EPOCH 437/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011603767025785925		[learning rate: 2.6404e-05]
	Learning Rate: 2.64038e-05
	LOSS [training: -0.011603767025785925 | validation: -0.018198344390523223]
	TIME [epoch: 41.8 sec]
EPOCH 438/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012931815001040677		[learning rate: 2.6002e-05]
	Learning Rate: 2.60016e-05
	LOSS [training: -0.012931815001040677 | validation: -0.009184358915986856]
	TIME [epoch: 41.8 sec]
EPOCH 439/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009922891293985067		[learning rate: 2.5605e-05]
	Learning Rate: 2.56055e-05
	LOSS [training: -0.009922891293985067 | validation: -0.014719822189056438]
	TIME [epoch: 41.8 sec]
EPOCH 440/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014317187240024322		[learning rate: 2.5215e-05]
	Learning Rate: 2.52154e-05
	LOSS [training: -0.014317187240024322 | validation: -0.008267575545685284]
	TIME [epoch: 41.9 sec]
EPOCH 441/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011404866442916073		[learning rate: 2.4831e-05]
	Learning Rate: 2.48313e-05
	LOSS [training: -0.011404866442916073 | validation: -0.010396450421912652]
	TIME [epoch: 41.9 sec]
EPOCH 442/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009366850774977783		[learning rate: 2.4453e-05]
	Learning Rate: 2.44531e-05
	LOSS [training: -0.009366850774977783 | validation: -0.008114019110649304]
	TIME [epoch: 41.8 sec]
EPOCH 443/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011329947783517593		[learning rate: 2.4081e-05]
	Learning Rate: 2.40806e-05
	LOSS [training: -0.011329947783517593 | validation: -0.002137365159517915]
	TIME [epoch: 41.9 sec]
EPOCH 444/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0136396499631255		[learning rate: 2.3714e-05]
	Learning Rate: 2.37137e-05
	LOSS [training: -0.0136396499631255 | validation: -0.016415268642199776]
	TIME [epoch: 41.8 sec]
EPOCH 445/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01329224705868885		[learning rate: 2.3352e-05]
	Learning Rate: 2.33525e-05
	LOSS [training: -0.01329224705868885 | validation: -0.010206799413858221]
	TIME [epoch: 41.9 sec]
EPOCH 446/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00985117648703321		[learning rate: 2.2997e-05]
	Learning Rate: 2.29968e-05
	LOSS [training: -0.00985117648703321 | validation: -0.01866039973056348]
	TIME [epoch: 41.9 sec]
EPOCH 447/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011205678174638583		[learning rate: 2.2646e-05]
	Learning Rate: 2.26464e-05
	LOSS [training: -0.011205678174638583 | validation: -0.01335002820897481]
	TIME [epoch: 41.8 sec]
EPOCH 448/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01393929300097629		[learning rate: 2.2301e-05]
	Learning Rate: 2.23015e-05
	LOSS [training: -0.01393929300097629 | validation: -0.0042227537872964365]
	TIME [epoch: 41.9 sec]
EPOCH 449/500:
	Training over batches...
		[batch 4/4] avg loss: -0.015556160249161528		[learning rate: 2.1962e-05]
	Learning Rate: 2.19617e-05
	LOSS [training: -0.015556160249161528 | validation: -0.010320644353521355]
	TIME [epoch: 41.8 sec]
EPOCH 450/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013940838832699098		[learning rate: 2.1627e-05]
	Learning Rate: 2.16272e-05
	LOSS [training: -0.013940838832699098 | validation: -0.011478607537761615]
	TIME [epoch: 41.8 sec]
EPOCH 451/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011851506236944677		[learning rate: 2.1298e-05]
	Learning Rate: 2.12977e-05
	LOSS [training: -0.011851506236944677 | validation: -0.005823526274774653]
	TIME [epoch: 41.9 sec]
EPOCH 452/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008408249853468166		[learning rate: 2.0973e-05]
	Learning Rate: 2.09733e-05
	LOSS [training: -0.008408249853468166 | validation: -0.0045975707508697375]
	TIME [epoch: 41.9 sec]
EPOCH 453/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012958756350348502		[learning rate: 2.0654e-05]
	Learning Rate: 2.06538e-05
	LOSS [training: -0.012958756350348502 | validation: -0.017874358979017346]
	TIME [epoch: 41.8 sec]
EPOCH 454/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01042716940506174		[learning rate: 2.0339e-05]
	Learning Rate: 2.03392e-05
	LOSS [training: -0.01042716940506174 | validation: -0.012400848369907874]
	TIME [epoch: 41.8 sec]
EPOCH 455/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01671658949616993		[learning rate: 2.0029e-05]
	Learning Rate: 2.00293e-05
	LOSS [training: -0.01671658949616993 | validation: -0.003921991197608823]
	TIME [epoch: 41.8 sec]
EPOCH 456/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014492855472325004		[learning rate: 1.9724e-05]
	Learning Rate: 1.97242e-05
	LOSS [training: -0.014492855472325004 | validation: -0.02255806840689439]
	TIME [epoch: 41.8 sec]
EPOCH 457/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011897349047739841		[learning rate: 1.9424e-05]
	Learning Rate: 1.94238e-05
	LOSS [training: -0.011897349047739841 | validation: -0.01731219443120552]
	TIME [epoch: 41.8 sec]
EPOCH 458/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010782063221072613		[learning rate: 1.9128e-05]
	Learning Rate: 1.91279e-05
	LOSS [training: -0.010782063221072613 | validation: -0.008595550394143687]
	TIME [epoch: 41.8 sec]
EPOCH 459/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013834406932629446		[learning rate: 1.8836e-05]
	Learning Rate: 1.88365e-05
	LOSS [training: -0.013834406932629446 | validation: -0.012609777307157895]
	TIME [epoch: 41.8 sec]
EPOCH 460/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011582054253796995		[learning rate: 1.855e-05]
	Learning Rate: 1.85495e-05
	LOSS [training: -0.011582054253796995 | validation: -0.007673944870608519]
	TIME [epoch: 41.8 sec]
EPOCH 461/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011835783574611049		[learning rate: 1.8267e-05]
	Learning Rate: 1.8267e-05
	LOSS [training: -0.011835783574611049 | validation: -0.004657406913026397]
	TIME [epoch: 41.8 sec]
EPOCH 462/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01195651155555605		[learning rate: 1.7989e-05]
	Learning Rate: 1.79887e-05
	LOSS [training: -0.01195651155555605 | validation: 0.00012569854458356882]
	TIME [epoch: 41.9 sec]
EPOCH 463/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013128003565119142		[learning rate: 1.7715e-05]
	Learning Rate: 1.77147e-05
	LOSS [training: -0.013128003565119142 | validation: -0.015472814541059273]
	TIME [epoch: 41.9 sec]
EPOCH 464/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013299073565456046		[learning rate: 1.7445e-05]
	Learning Rate: 1.74448e-05
	LOSS [training: -0.013299073565456046 | validation: -0.0124514854865859]
	TIME [epoch: 41.8 sec]
EPOCH 465/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010471835081291327		[learning rate: 1.7179e-05]
	Learning Rate: 1.71791e-05
	LOSS [training: -0.010471835081291327 | validation: -0.011181416894932385]
	TIME [epoch: 41.9 sec]
EPOCH 466/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013904400473931083		[learning rate: 1.6917e-05]
	Learning Rate: 1.69174e-05
	LOSS [training: -0.013904400473931083 | validation: -0.01313081393580834]
	TIME [epoch: 41.8 sec]
EPOCH 467/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010499729580854352		[learning rate: 1.666e-05]
	Learning Rate: 1.66597e-05
	LOSS [training: -0.010499729580854352 | validation: -0.00931940662849583]
	TIME [epoch: 41.9 sec]
EPOCH 468/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011840075722991863		[learning rate: 1.6406e-05]
	Learning Rate: 1.64059e-05
	LOSS [training: -0.011840075722991863 | validation: 0.003131154107110108]
	TIME [epoch: 41.8 sec]
EPOCH 469/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014550667147991338		[learning rate: 1.6156e-05]
	Learning Rate: 1.6156e-05
	LOSS [training: -0.014550667147991338 | validation: -0.018810183684869326]
	TIME [epoch: 41.8 sec]
EPOCH 470/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014640086405726891		[learning rate: 1.591e-05]
	Learning Rate: 1.59099e-05
	LOSS [training: -0.014640086405726891 | validation: -0.013325680141938504]
	TIME [epoch: 41.8 sec]
EPOCH 471/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013705225642516108		[learning rate: 1.5668e-05]
	Learning Rate: 1.56675e-05
	LOSS [training: -0.013705225642516108 | validation: -0.007836043627635824]
	TIME [epoch: 41.8 sec]
EPOCH 472/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012181939751816733		[learning rate: 1.5429e-05]
	Learning Rate: 1.54288e-05
	LOSS [training: -0.012181939751816733 | validation: -0.014725675364174438]
	TIME [epoch: 41.8 sec]
EPOCH 473/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01042671100790119		[learning rate: 1.5194e-05]
	Learning Rate: 1.51938e-05
	LOSS [training: -0.01042671100790119 | validation: -0.008255044955811202]
	TIME [epoch: 41.8 sec]
EPOCH 474/500:
	Training over batches...
		[batch 4/4] avg loss: -0.015142430289706719		[learning rate: 1.4962e-05]
	Learning Rate: 1.49624e-05
	LOSS [training: -0.015142430289706719 | validation: -0.006161641929113504]
	TIME [epoch: 41.9 sec]
EPOCH 475/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01022369660748509		[learning rate: 1.4734e-05]
	Learning Rate: 1.47344e-05
	LOSS [training: -0.01022369660748509 | validation: -0.008690885392490397]
	TIME [epoch: 41.8 sec]
EPOCH 476/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013410849648242299		[learning rate: 1.451e-05]
	Learning Rate: 1.451e-05
	LOSS [training: -0.013410849648242299 | validation: -0.010698705051617963]
	TIME [epoch: 41.8 sec]
EPOCH 477/500:
	Training over batches...
		[batch 4/4] avg loss: -0.015052896197540539		[learning rate: 1.4289e-05]
	Learning Rate: 1.42889e-05
	LOSS [training: -0.015052896197540539 | validation: -0.01321370111258977]
	TIME [epoch: 41.8 sec]
EPOCH 478/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013320847074037055		[learning rate: 1.4071e-05]
	Learning Rate: 1.40713e-05
	LOSS [training: -0.013320847074037055 | validation: -0.012849160048580614]
	TIME [epoch: 41.9 sec]
EPOCH 479/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011482767661462643		[learning rate: 1.3857e-05]
	Learning Rate: 1.38569e-05
	LOSS [training: -0.011482767661462643 | validation: -0.011712798182800908]
	TIME [epoch: 41.8 sec]
EPOCH 480/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01264135289258982		[learning rate: 1.3646e-05]
	Learning Rate: 1.36458e-05
	LOSS [training: -0.01264135289258982 | validation: -0.006079120323440078]
	TIME [epoch: 41.8 sec]
EPOCH 481/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008320553930978242		[learning rate: 1.3438e-05]
	Learning Rate: 1.3438e-05
	LOSS [training: -0.008320553930978242 | validation: -0.011989488883318512]
	TIME [epoch: 41.9 sec]
EPOCH 482/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01204821517002905		[learning rate: 1.3233e-05]
	Learning Rate: 1.32333e-05
	LOSS [training: -0.01204821517002905 | validation: -0.0035759194375526164]
	TIME [epoch: 41.9 sec]
EPOCH 483/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01370945008572695		[learning rate: 1.3032e-05]
	Learning Rate: 1.30317e-05
	LOSS [training: -0.01370945008572695 | validation: -0.010786257561648742]
	TIME [epoch: 41.9 sec]
EPOCH 484/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012434395952845609		[learning rate: 1.2833e-05]
	Learning Rate: 1.28332e-05
	LOSS [training: -0.012434395952845609 | validation: -0.01014299447764572]
	TIME [epoch: 41.9 sec]
EPOCH 485/500:
	Training over batches...
		[batch 4/4] avg loss: -0.016275037797564618		[learning rate: 1.2638e-05]
	Learning Rate: 1.26377e-05
	LOSS [training: -0.016275037797564618 | validation: -0.012721088302985784]
	TIME [epoch: 41.9 sec]
EPOCH 486/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011647887591831059		[learning rate: 1.2445e-05]
	Learning Rate: 1.24451e-05
	LOSS [training: -0.011647887591831059 | validation: -0.009892595425480096]
	TIME [epoch: 41.8 sec]
EPOCH 487/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010208590792147466		[learning rate: 1.2256e-05]
	Learning Rate: 1.22556e-05
	LOSS [training: -0.010208590792147466 | validation: -0.01647648326899745]
	TIME [epoch: 41.8 sec]
EPOCH 488/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011998553488199677		[learning rate: 1.2069e-05]
	Learning Rate: 1.20689e-05
	LOSS [training: -0.011998553488199677 | validation: -0.01181474176491151]
	TIME [epoch: 41.8 sec]
EPOCH 489/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014008641743407269		[learning rate: 1.1885e-05]
	Learning Rate: 1.1885e-05
	LOSS [training: -0.014008641743407269 | validation: -0.011563971258534644]
	TIME [epoch: 41.7 sec]
EPOCH 490/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007114134749549559		[learning rate: 1.1704e-05]
	Learning Rate: 1.1704e-05
	LOSS [training: -0.007114134749549559 | validation: -0.010744731342280073]
	TIME [epoch: 41.8 sec]
EPOCH 491/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011655151055776058		[learning rate: 1.1526e-05]
	Learning Rate: 1.15257e-05
	LOSS [training: -0.011655151055776058 | validation: -0.0030995431170397275]
	TIME [epoch: 41.8 sec]
EPOCH 492/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009453588293202746		[learning rate: 1.135e-05]
	Learning Rate: 1.13501e-05
	LOSS [training: -0.009453588293202746 | validation: -0.00810439360096112]
	TIME [epoch: 41.8 sec]
EPOCH 493/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012231188219601688		[learning rate: 1.1177e-05]
	Learning Rate: 1.11772e-05
	LOSS [training: -0.012231188219601688 | validation: -0.009635809355847388]
	TIME [epoch: 41.8 sec]
EPOCH 494/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01196779927364494		[learning rate: 1.1007e-05]
	Learning Rate: 1.10069e-05
	LOSS [training: -0.01196779927364494 | validation: -0.010007912716412947]
	TIME [epoch: 41.8 sec]
EPOCH 495/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013228519602696337		[learning rate: 1.0839e-05]
	Learning Rate: 1.08393e-05
	LOSS [training: -0.013228519602696337 | validation: -0.00546618798110614]
	TIME [epoch: 41.8 sec]
EPOCH 496/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010997457820491567		[learning rate: 1.0674e-05]
	Learning Rate: 1.06741e-05
	LOSS [training: -0.010997457820491567 | validation: -0.00385661001372742]
	TIME [epoch: 41.8 sec]
EPOCH 497/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013817138321408684		[learning rate: 1.0512e-05]
	Learning Rate: 1.05115e-05
	LOSS [training: -0.013817138321408684 | validation: -0.004876295643665478]
	TIME [epoch: 41.9 sec]
EPOCH 498/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01737459836055946		[learning rate: 1.0351e-05]
	Learning Rate: 1.03514e-05
	LOSS [training: -0.01737459836055946 | validation: -0.008430529448500815]
	TIME [epoch: 41.8 sec]
EPOCH 499/500:
	Training over batches...
		[batch 4/4] avg loss: -0.015669047490027517		[learning rate: 1.0194e-05]
	Learning Rate: 1.01937e-05
	LOSS [training: -0.015669047490027517 | validation: -0.017169711047944874]
	TIME [epoch: 41.8 sec]
EPOCH 500/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014762655705675521		[learning rate: 1.0038e-05]
	Learning Rate: 1.00384e-05
	LOSS [training: -0.014762655705675521 | validation: -0.009794190332574369]
	TIME [epoch: 41.8 sec]
Finished training in 14375.564 seconds.
