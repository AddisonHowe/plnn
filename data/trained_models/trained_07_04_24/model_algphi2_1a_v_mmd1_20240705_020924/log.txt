Args:
Namespace(name='model_algphi2_1a_v_mmd1', outdir='out/model_training/model_algphi2_1a_v_mmd1', training_data='data/training_data/data_phi2_1a/training', validation_data='data/training_data/data_phi2_1a/validation', model_type='binary_flip', nsims_training=None, nsims_validation=None, num_epochs=500, passes_per_epoch=1, batch_size=250, patience=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=False, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 250], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=False, confinement_factor=1.0, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], phi_final_act='softplus', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=0.0, init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 652972350

Training model...

Saving initial model state to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 4/4] avg loss: 3.2543844764516217		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2543844764516217 | validation: 2.8091664867207475]
	TIME [epoch: 96.1 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 4/4] avg loss: 3.0233706969641703		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0233706969641703 | validation: 2.710041107905713]
	TIME [epoch: 4.38 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 4/4] avg loss: 2.9537548171345396		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9537548171345396 | validation: 2.7069384890046493]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_3.pth
	Model improved!!!
EPOCH 4/500:
	Training over batches...
		[batch 4/4] avg loss: 2.8885033306965298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8885033306965298 | validation: 2.684595758442935]
	TIME [epoch: 4.34 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 4/4] avg loss: 2.8392887133053657		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8392887133053657 | validation: 2.634442785793779]
	TIME [epoch: 4.33 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_5.pth
	Model improved!!!
EPOCH 6/500:
	Training over batches...
		[batch 4/4] avg loss: 2.7768552258815022		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7768552258815022 | validation: 2.569704448817248]
	TIME [epoch: 4.33 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_6.pth
	Model improved!!!
EPOCH 7/500:
	Training over batches...
		[batch 4/4] avg loss: 2.7108991330664454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7108991330664454 | validation: 2.503393503360484]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_7.pth
	Model improved!!!
EPOCH 8/500:
	Training over batches...
		[batch 4/4] avg loss: 2.4283399626051247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4283399626051247 | validation: 2.1341224995825794]
	TIME [epoch: 4.31 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_8.pth
	Model improved!!!
EPOCH 9/500:
	Training over batches...
		[batch 4/4] avg loss: 1.7399727861910366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7399727861910366 | validation: 1.6238789608750976]
	TIME [epoch: 4.32 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_9.pth
	Model improved!!!
EPOCH 10/500:
	Training over batches...
		[batch 4/4] avg loss: 1.3483674948853697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3483674948853697 | validation: 1.35313746900314]
	TIME [epoch: 4.32 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_10.pth
	Model improved!!!
EPOCH 11/500:
	Training over batches...
		[batch 4/4] avg loss: 1.0827726089472338		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0827726089472338 | validation: 1.0212272212760822]
	TIME [epoch: 4.33 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_11.pth
	Model improved!!!
EPOCH 12/500:
	Training over batches...
		[batch 4/4] avg loss: 0.8838676252975414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8838676252975414 | validation: 0.7838575449982672]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_12.pth
	Model improved!!!
EPOCH 13/500:
	Training over batches...
		[batch 4/4] avg loss: 0.6775225520289347		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6775225520289347 | validation: 0.664297293579498]
	TIME [epoch: 4.31 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_13.pth
	Model improved!!!
EPOCH 14/500:
	Training over batches...
		[batch 4/4] avg loss: 0.5721672317336306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5721672317336306 | validation: 0.6080261679530994]
	TIME [epoch: 4.33 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_14.pth
	Model improved!!!
EPOCH 15/500:
	Training over batches...
		[batch 4/4] avg loss: 0.5166050528472521		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5166050528472521 | validation: 0.561281802932293]
	TIME [epoch: 4.31 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_15.pth
	Model improved!!!
EPOCH 16/500:
	Training over batches...
		[batch 4/4] avg loss: 0.46730801945697964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46730801945697964 | validation: 0.518892461571907]
	TIME [epoch: 4.29 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_16.pth
	Model improved!!!
EPOCH 17/500:
	Training over batches...
		[batch 4/4] avg loss: 0.42733996623923465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42733996623923465 | validation: 0.47847916198637575]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_17.pth
	Model improved!!!
EPOCH 18/500:
	Training over batches...
		[batch 4/4] avg loss: 0.3889553369917978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3889553369917978 | validation: 0.4356519502539661]
	TIME [epoch: 4.28 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_18.pth
	Model improved!!!
EPOCH 19/500:
	Training over batches...
		[batch 4/4] avg loss: 0.3363412237172112		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3363412237172112 | validation: 0.31500131209635784]
	TIME [epoch: 4.29 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_19.pth
	Model improved!!!
EPOCH 20/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2348598318980945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2348598318980945 | validation: 0.1622248834587879]
	TIME [epoch: 4.32 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_20.pth
	Model improved!!!
EPOCH 21/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13107546808720327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13107546808720327 | validation: 0.06428019233526899]
	TIME [epoch: 4.34 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_21.pth
	Model improved!!!
EPOCH 22/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05959858244676056		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05959858244676056 | validation: 0.025379613306830903]
	TIME [epoch: 4.35 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_22.pth
	Model improved!!!
EPOCH 23/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02530236798936424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02530236798936424 | validation: 0.01337528624451854]
	TIME [epoch: 4.31 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_23.pth
	Model improved!!!
EPOCH 24/500:
	Training over batches...
		[batch 4/4] avg loss: 0.011880649102311859		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.011880649102311859 | validation: 0.00646097442954464]
	TIME [epoch: 4.29 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_24.pth
	Model improved!!!
EPOCH 25/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006971151515726692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.006971151515726692 | validation: 0.004108100994536042]
	TIME [epoch: 4.31 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_25.pth
	Model improved!!!
EPOCH 26/500:
	Training over batches...
		[batch 4/4] avg loss: 0.003873485240220404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.003873485240220404 | validation: 0.0028892236292076537]
	TIME [epoch: 4.32 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_26.pth
	Model improved!!!
EPOCH 27/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0023601037030297712		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0023601037030297712 | validation: 0.003540978772356042]
	TIME [epoch: 4.31 sec]
EPOCH 28/500:
	Training over batches...
		[batch 4/4] avg loss: 0.001868989696973982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.001868989696973982 | validation: 0.002305290427485753]
	TIME [epoch: 4.31 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_28.pth
	Model improved!!!
EPOCH 29/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0029339149504409618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0029339149504409618 | validation: 0.0024485157968835167]
	TIME [epoch: 4.32 sec]
EPOCH 30/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006460533109639089		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.006460533109639089 | validation: 0.012071577465627682]
	TIME [epoch: 4.31 sec]
EPOCH 31/500:
	Training over batches...
		[batch 4/4] avg loss: 0.012589822908195427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.012589822908195427 | validation: 0.0025427070879181076]
	TIME [epoch: 4.34 sec]
EPOCH 32/500:
	Training over batches...
		[batch 4/4] avg loss: 0.002179264122352808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.002179264122352808 | validation: 0.002670066048659307]
	TIME [epoch: 4.31 sec]
EPOCH 33/500:
	Training over batches...
		[batch 4/4] avg loss: 0.002736100247415869		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.002736100247415869 | validation: 0.003009168651464014]
	TIME [epoch: 4.31 sec]
EPOCH 34/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0023038524880912136		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0023038524880912136 | validation: 0.0038987834391360546]
	TIME [epoch: 4.3 sec]
EPOCH 35/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00596159676004273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.00596159676004273 | validation: 0.002829999986013078]
	TIME [epoch: 4.31 sec]
EPOCH 36/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00767919768491063		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.00767919768491063 | validation: 0.003059218664556583]
	TIME [epoch: 4.31 sec]
EPOCH 37/500:
	Training over batches...
		[batch 4/4] avg loss: 0.003769558061712826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.003769558061712826 | validation: 0.003127391095686218]
	TIME [epoch: 4.29 sec]
EPOCH 38/500:
	Training over batches...
		[batch 4/4] avg loss: 0.002645230189370724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.002645230189370724 | validation: 0.005095832194731172]
	TIME [epoch: 4.29 sec]
EPOCH 39/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00681451088867944		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.00681451088867944 | validation: 0.0032250591576694757]
	TIME [epoch: 4.29 sec]
EPOCH 40/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00251858422726796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.00251858422726796 | validation: 0.0018774155942945497]
	TIME [epoch: 4.29 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_40.pth
	Model improved!!!
EPOCH 41/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0026160462166806607		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0026160462166806607 | validation: 0.008778691009528217]
	TIME [epoch: 4.33 sec]
EPOCH 42/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006446050765111539		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.006446050765111539 | validation: 0.002078232632226594]
	TIME [epoch: 4.29 sec]
EPOCH 43/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0032603321115484796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0032603321115484796 | validation: 0.01104621604894419]
	TIME [epoch: 4.29 sec]
EPOCH 44/500:
	Training over batches...
		[batch 4/4] avg loss: 0.013586695616041998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.013586695616041998 | validation: 0.00781492621382382]
	TIME [epoch: 4.29 sec]
EPOCH 45/500:
	Training over batches...
		[batch 4/4] avg loss: 0.005430259741544768		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.005430259741544768 | validation: 0.004297285996515268]
	TIME [epoch: 4.29 sec]
EPOCH 46/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0037546594722971584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0037546594722971584 | validation: 0.0025672267062613685]
	TIME [epoch: 4.29 sec]
EPOCH 47/500:
	Training over batches...
		[batch 4/4] avg loss: 0.003091131828651306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.003091131828651306 | validation: 0.0034347334297126684]
	TIME [epoch: 4.29 sec]
EPOCH 48/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0024733852521266132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0024733852521266132 | validation: 0.0024587935557105487]
	TIME [epoch: 4.29 sec]
EPOCH 49/500:
	Training over batches...
		[batch 4/4] avg loss: 0.002096002009300345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.002096002009300345 | validation: 0.0018721902454142984]
	TIME [epoch: 4.29 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_49.pth
	Model improved!!!
EPOCH 50/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008032127369182306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.008032127369182306 | validation: 0.008021962929337849]
	TIME [epoch: 4.3 sec]
EPOCH 51/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0028086211422273188		[learning rate: 0.0098855]
	Learning Rate: 0.00988553
	LOSS [training: 0.0028086211422273188 | validation: 0.0013249432861319895]
	TIME [epoch: 99.4 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_51.pth
	Model improved!!!
EPOCH 52/500:
	Training over batches...
		[batch 4/4] avg loss: 0.003348209969923255		[learning rate: 0.0097349]
	Learning Rate: 0.00973494
	LOSS [training: 0.003348209969923255 | validation: 0.004268350637779494]
	TIME [epoch: 8.45 sec]
EPOCH 53/500:
	Training over batches...
		[batch 4/4] avg loss: 0.002905356638889342		[learning rate: 0.0095866]
	Learning Rate: 0.00958665
	LOSS [training: 0.002905356638889342 | validation: 0.00295345625871472]
	TIME [epoch: 8.39 sec]
EPOCH 54/500:
	Training over batches...
		[batch 4/4] avg loss: 0.002004839864830743		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.002004839864830743 | validation: 3.9090269893530464e-05]
	TIME [epoch: 8.41 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_54.pth
	Model improved!!!
EPOCH 55/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0011427760046945736		[learning rate: 0.0092968]
	Learning Rate: 0.0092968
	LOSS [training: 0.0011427760046945736 | validation: 2.779493147004431e-05]
	TIME [epoch: 8.42 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_55.pth
	Model improved!!!
EPOCH 56/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0005682368038419738		[learning rate: 0.0091552]
	Learning Rate: 0.00915517
	LOSS [training: -0.0005682368038419738 | validation: -0.00039151896585794613]
	TIME [epoch: 8.39 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_56.pth
	Model improved!!!
EPOCH 57/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0016991231118130491		[learning rate: 0.0090157]
	Learning Rate: 0.00901571
	LOSS [training: -0.0016991231118130491 | validation: -0.0017316052165014977]
	TIME [epoch: 8.4 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_57.pth
	Model improved!!!
EPOCH 58/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019363371403508711		[learning rate: 0.0088784]
	Learning Rate: 0.00887837
	LOSS [training: -0.0019363371403508711 | validation: -0.0017460614867687626]
	TIME [epoch: 8.38 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_58.pth
	Model improved!!!
EPOCH 59/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0013989387759945871		[learning rate: 0.0087431]
	Learning Rate: 0.00874312
	LOSS [training: -0.0013989387759945871 | validation: -0.000683776076409131]
	TIME [epoch: 8.39 sec]
EPOCH 60/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001033891672877525		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: -0.001033891672877525 | validation: -0.001290301332915998]
	TIME [epoch: 8.41 sec]
EPOCH 61/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0031474600613803205		[learning rate: 0.0084788]
	Learning Rate: 0.00847878
	LOSS [training: 0.0031474600613803205 | validation: 0.0033150094841972234]
	TIME [epoch: 8.39 sec]
EPOCH 62/500:
	Training over batches...
		[batch 4/4] avg loss: 0.010130375078769443		[learning rate: 0.0083496]
	Learning Rate: 0.00834962
	LOSS [training: 0.010130375078769443 | validation: 0.014371286363538153]
	TIME [epoch: 8.38 sec]
EPOCH 63/500:
	Training over batches...
		[batch 4/4] avg loss: 0.014541198540310258		[learning rate: 0.0082224]
	Learning Rate: 0.00822243
	LOSS [training: 0.014541198540310258 | validation: 0.00025218006096599453]
	TIME [epoch: 8.38 sec]
EPOCH 64/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00042549758480417714		[learning rate: 0.0080972]
	Learning Rate: 0.00809717
	LOSS [training: -0.00042549758480417714 | validation: 0.0003385100351505459]
	TIME [epoch: 8.38 sec]
EPOCH 65/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0007617614212354285		[learning rate: 0.0079738]
	Learning Rate: 0.00797382
	LOSS [training: -0.0007617614212354285 | validation: -0.0012348727887941525]
	TIME [epoch: 8.39 sec]
EPOCH 66/500:
	Training over batches...
		[batch 4/4] avg loss: 9.382934502495189e-05		[learning rate: 0.0078524]
	Learning Rate: 0.00785236
	LOSS [training: 9.382934502495189e-05 | validation: 0.005495375652990303]
	TIME [epoch: 8.42 sec]
EPOCH 67/500:
	Training over batches...
		[batch 4/4] avg loss: 0.005321872687878009		[learning rate: 0.0077327]
	Learning Rate: 0.00773274
	LOSS [training: 0.005321872687878009 | validation: 0.002308129814629494]
	TIME [epoch: 8.48 sec]
EPOCH 68/500:
	Training over batches...
		[batch 4/4] avg loss: 0.004012727388431255		[learning rate: 0.0076149]
	Learning Rate: 0.00761494
	LOSS [training: 0.004012727388431255 | validation: 0.0018506041740957544]
	TIME [epoch: 8.39 sec]
EPOCH 69/500:
	Training over batches...
		[batch 4/4] avg loss: 0.001287596068819537		[learning rate: 0.0074989]
	Learning Rate: 0.00749894
	LOSS [training: 0.001287596068819537 | validation: -0.00022759619821249058]
	TIME [epoch: 8.39 sec]
EPOCH 70/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0004283658412379905		[learning rate: 0.0073847]
	Learning Rate: 0.00738471
	LOSS [training: -0.0004283658412379905 | validation: -0.001390095749165547]
	TIME [epoch: 8.39 sec]
EPOCH 71/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0011152310797906406		[learning rate: 0.0072722]
	Learning Rate: 0.00727221
	LOSS [training: -0.0011152310797906406 | validation: -0.0003887100499618326]
	TIME [epoch: 8.39 sec]
EPOCH 72/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0016739666767370508		[learning rate: 0.0071614]
	Learning Rate: 0.00716143
	LOSS [training: -0.0016739666767370508 | validation: -0.001732371149502553]
	TIME [epoch: 8.44 sec]
EPOCH 73/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0013296278040406068		[learning rate: 0.0070523]
	Learning Rate: 0.00705234
	LOSS [training: -0.0013296278040406068 | validation: -0.0013350496111101421]
	TIME [epoch: 8.39 sec]
EPOCH 74/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00119061790091561		[learning rate: 0.0069449]
	Learning Rate: 0.00694491
	LOSS [training: -0.00119061790091561 | validation: -0.0014967973153754985]
	TIME [epoch: 8.39 sec]
EPOCH 75/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001905468346368961		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: -0.001905468346368961 | validation: -0.0019619387125717445]
	TIME [epoch: 8.38 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_75.pth
	Model improved!!!
EPOCH 76/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0006363621938926106		[learning rate: 0.0067349]
	Learning Rate: 0.00673493
	LOSS [training: -0.0006363621938926106 | validation: 0.002321712444310129]
	TIME [epoch: 8.38 sec]
EPOCH 77/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0010238321269099837		[learning rate: 0.0066323]
	Learning Rate: 0.00663234
	LOSS [training: 0.0010238321269099837 | validation: -0.0010556366412223955]
	TIME [epoch: 8.4 sec]
EPOCH 78/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001833462526407134		[learning rate: 0.0065313]
	Learning Rate: 0.00653131
	LOSS [training: -0.001833462526407134 | validation: -0.002091404433611657]
	TIME [epoch: 8.43 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_78.pth
	Model improved!!!
EPOCH 79/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001151861891419302		[learning rate: 0.0064318]
	Learning Rate: 0.00643181
	LOSS [training: -0.001151861891419302 | validation: 0.0009161789306655837]
	TIME [epoch: 8.38 sec]
EPOCH 80/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0024236638440042623		[learning rate: 0.0063338]
	Learning Rate: 0.00633383
	LOSS [training: 0.0024236638440042623 | validation: 0.002541063569347611]
	TIME [epoch: 8.38 sec]
EPOCH 81/500:
	Training over batches...
		[batch 4/4] avg loss: 0.001756537183768434		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.001756537183768434 | validation: 4.9975100290681855e-05]
	TIME [epoch: 8.38 sec]
EPOCH 82/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00041760320241719033		[learning rate: 0.0061423]
	Learning Rate: 0.00614233
	LOSS [training: -0.00041760320241719033 | validation: -0.0013236454659796442]
	TIME [epoch: 8.39 sec]
EPOCH 83/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001523136532476706		[learning rate: 0.0060488]
	Learning Rate: 0.00604876
	LOSS [training: -0.001523136532476706 | validation: -0.0014840426916763558]
	TIME [epoch: 8.41 sec]
EPOCH 84/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001770735891976917		[learning rate: 0.0059566]
	Learning Rate: 0.00595662
	LOSS [training: -0.001770735891976917 | validation: -0.0017941774394317012]
	TIME [epoch: 8.42 sec]
EPOCH 85/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0014843068995252467		[learning rate: 0.0058659]
	Learning Rate: 0.00586588
	LOSS [training: -0.0014843068995252467 | validation: -0.0014762926542460017]
	TIME [epoch: 8.38 sec]
EPOCH 86/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0009728728346804508		[learning rate: 0.0057765]
	Learning Rate: 0.00577653
	LOSS [training: -0.0009728728346804508 | validation: -0.0007170189918443924]
	TIME [epoch: 8.39 sec]
EPOCH 87/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0007003000962969008		[learning rate: 0.0056885]
	Learning Rate: 0.00568853
	LOSS [training: -0.0007003000962969008 | validation: 0.00037959584350147726]
	TIME [epoch: 8.39 sec]
EPOCH 88/500:
	Training over batches...
		[batch 4/4] avg loss: -1.7300197487694533e-05		[learning rate: 0.0056019]
	Learning Rate: 0.00560187
	LOSS [training: -1.7300197487694533e-05 | validation: 0.0048900880022361]
	TIME [epoch: 8.39 sec]
EPOCH 89/500:
	Training over batches...
		[batch 4/4] avg loss: 0.003729829162785674		[learning rate: 0.0055165]
	Learning Rate: 0.00551654
	LOSS [training: 0.003729829162785674 | validation: -0.0004194090643004968]
	TIME [epoch: 8.43 sec]
EPOCH 90/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001224830091952095		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: -0.001224830091952095 | validation: -0.001500353757581944]
	TIME [epoch: 8.39 sec]
EPOCH 91/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0017975126523150412		[learning rate: 0.0053497]
	Learning Rate: 0.00534975
	LOSS [training: -0.0017975126523150412 | validation: -0.0012830011726655632]
	TIME [epoch: 8.39 sec]
EPOCH 92/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0017383992836099756		[learning rate: 0.0052683]
	Learning Rate: 0.00526825
	LOSS [training: -0.0017383992836099756 | validation: -0.0021689467979990186]
	TIME [epoch: 8.39 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_92.pth
	Model improved!!!
EPOCH 93/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0018110686599156433		[learning rate: 0.005188]
	Learning Rate: 0.005188
	LOSS [training: -0.0018110686599156433 | validation: -0.0018132643351483563]
	TIME [epoch: 8.38 sec]
EPOCH 94/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019364164173069664		[learning rate: 0.005109]
	Learning Rate: 0.00510897
	LOSS [training: -0.0019364164173069664 | validation: -0.0011458205632362385]
	TIME [epoch: 8.39 sec]
EPOCH 95/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019204295607599055		[learning rate: 0.0050311]
	Learning Rate: 0.00503114
	LOSS [training: -0.0019204295607599055 | validation: -0.0018308099776476233]
	TIME [epoch: 8.42 sec]
EPOCH 96/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001262121724065926		[learning rate: 0.0049545]
	Learning Rate: 0.0049545
	LOSS [training: -0.001262121724065926 | validation: -0.0005604736917822905]
	TIME [epoch: 8.38 sec]
EPOCH 97/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00021452658888892874		[learning rate: 0.004879]
	Learning Rate: 0.00487903
	LOSS [training: -0.00021452658888892874 | validation: -0.0008145576025545384]
	TIME [epoch: 8.38 sec]
EPOCH 98/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0007828414925782829		[learning rate: 0.0048047]
	Learning Rate: 0.0048047
	LOSS [training: 0.0007828414925782829 | validation: -0.00012088852555101106]
	TIME [epoch: 8.38 sec]
EPOCH 99/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0012298441072175455		[learning rate: 0.0047315]
	Learning Rate: 0.00473151
	LOSS [training: -0.0012298441072175455 | validation: -0.0016828116769024724]
	TIME [epoch: 8.38 sec]
EPOCH 100/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0017112438172386234		[learning rate: 0.0046594]
	Learning Rate: 0.00465944
	LOSS [training: -0.0017112438172386234 | validation: -0.0020236586767317494]
	TIME [epoch: 8.41 sec]
EPOCH 101/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019501516714800413		[learning rate: 0.0045885]
	Learning Rate: 0.00458846
	LOSS [training: -0.0019501516714800413 | validation: -0.0018521068972341666]
	TIME [epoch: 111 sec]
EPOCH 102/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021219050642701087		[learning rate: 0.0045186]
	Learning Rate: 0.00451856
	LOSS [training: -0.0021219050642701087 | validation: -0.002206657647636096]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_102.pth
	Model improved!!!
EPOCH 103/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0016207826038067631		[learning rate: 0.0044497]
	Learning Rate: 0.00444973
	LOSS [training: -0.0016207826038067631 | validation: -0.0013865945232480969]
	TIME [epoch: 19.1 sec]
EPOCH 104/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021297813925211296		[learning rate: 0.0043819]
	Learning Rate: 0.00438194
	LOSS [training: -0.0021297813925211296 | validation: 0.0013335389693803434]
	TIME [epoch: 19.1 sec]
EPOCH 105/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00045537319892569885		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 0.00045537319892569885 | validation: -0.0009859632112252008]
	TIME [epoch: 19.1 sec]
EPOCH 106/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0006716491335406647		[learning rate: 0.0042495]
	Learning Rate: 0.00424946
	LOSS [training: -0.0006716491335406647 | validation: 0.00041769396122384126]
	TIME [epoch: 19.1 sec]
EPOCH 107/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0007685837666675608		[learning rate: 0.0041847]
	Learning Rate: 0.00418472
	LOSS [training: -0.0007685837666675608 | validation: -0.001297622691259805]
	TIME [epoch: 19.1 sec]
EPOCH 108/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0003530947196789727		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.0003530947196789727 | validation: -0.0014539214611020623]
	TIME [epoch: 19.1 sec]
EPOCH 109/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0013315823437781492		[learning rate: 0.0040582]
	Learning Rate: 0.0040582
	LOSS [training: -0.0013315823437781492 | validation: -0.0021035286764267153]
	TIME [epoch: 19.1 sec]
EPOCH 110/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0023908800600025417		[learning rate: 0.0039964]
	Learning Rate: 0.00399638
	LOSS [training: -0.0023908800600025417 | validation: -0.002030607846686571]
	TIME [epoch: 19.1 sec]
EPOCH 111/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0009664059193988119		[learning rate: 0.0039355]
	Learning Rate: 0.0039355
	LOSS [training: -0.0009664059193988119 | validation: 4.962265579146408e-05]
	TIME [epoch: 19 sec]
EPOCH 112/500:
	Training over batches...
		[batch 4/4] avg loss: 0.002068140300269064		[learning rate: 0.0038755]
	Learning Rate: 0.00387555
	LOSS [training: 0.002068140300269064 | validation: 9.502212094734128e-06]
	TIME [epoch: 19.1 sec]
EPOCH 113/500:
	Training over batches...
		[batch 4/4] avg loss: 9.455004237571263e-05		[learning rate: 0.0038165]
	Learning Rate: 0.00381651
	LOSS [training: 9.455004237571263e-05 | validation: -0.0009505336040139546]
	TIME [epoch: 19.1 sec]
EPOCH 114/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0011789832814962941		[learning rate: 0.0037584]
	Learning Rate: 0.00375837
	LOSS [training: -0.0011789832814962941 | validation: -0.0019634854221183095]
	TIME [epoch: 19.1 sec]
EPOCH 115/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0004698654216697287		[learning rate: 0.0037011]
	Learning Rate: 0.00370112
	LOSS [training: -0.0004698654216697287 | validation: 0.0018435402712249846]
	TIME [epoch: 19.1 sec]
EPOCH 116/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00011196671634757416		[learning rate: 0.0036447]
	Learning Rate: 0.00364474
	LOSS [training: 0.00011196671634757416 | validation: -0.0015269218016165029]
	TIME [epoch: 19.1 sec]
EPOCH 117/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020044410402495416		[learning rate: 0.0035892]
	Learning Rate: 0.00358922
	LOSS [training: -0.0020044410402495416 | validation: -0.0016908718871464163]
	TIME [epoch: 19.1 sec]
EPOCH 118/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020660150041339267		[learning rate: 0.0035345]
	Learning Rate: 0.00353454
	LOSS [training: -0.0020660150041339267 | validation: -0.001648000733847557]
	TIME [epoch: 19.1 sec]
EPOCH 119/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002240977948617685		[learning rate: 0.0034807]
	Learning Rate: 0.0034807
	LOSS [training: -0.002240977948617685 | validation: -0.0015682250119448016]
	TIME [epoch: 19.1 sec]
EPOCH 120/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0018340247409629811		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: -0.0018340247409629811 | validation: -0.0022057142601783412]
	TIME [epoch: 19.1 sec]
EPOCH 121/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002044652036305477		[learning rate: 0.0033755]
	Learning Rate: 0.00337546
	LOSS [training: -0.002044652036305477 | validation: -0.002028748495249014]
	TIME [epoch: 19.1 sec]
EPOCH 122/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0017791033106518556		[learning rate: 0.003324]
	Learning Rate: 0.00332404
	LOSS [training: -0.0017791033106518556 | validation: -0.001852318630970161]
	TIME [epoch: 19.1 sec]
EPOCH 123/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020820102996907644		[learning rate: 0.0032734]
	Learning Rate: 0.00327341
	LOSS [training: -0.0020820102996907644 | validation: -0.0016955598970431463]
	TIME [epoch: 19.1 sec]
EPOCH 124/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019297100186132373		[learning rate: 0.0032235]
	Learning Rate: 0.00322354
	LOSS [training: -0.0019297100186132373 | validation: -0.0004349042681474926]
	TIME [epoch: 19.1 sec]
EPOCH 125/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001090442765055531		[learning rate: 0.0031744]
	Learning Rate: 0.00317444
	LOSS [training: -0.001090442765055531 | validation: -0.0012407814997238546]
	TIME [epoch: 19.1 sec]
EPOCH 126/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002007008760619461		[learning rate: 0.0031261]
	Learning Rate: 0.00312608
	LOSS [training: -0.002007008760619461 | validation: -0.0013083214722259804]
	TIME [epoch: 19.1 sec]
EPOCH 127/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0004573518183296892		[learning rate: 0.0030785]
	Learning Rate: 0.00307846
	LOSS [training: -0.0004573518183296892 | validation: -0.0011986150050447982]
	TIME [epoch: 19.1 sec]
EPOCH 128/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0018924033747323356		[learning rate: 0.0030316]
	Learning Rate: 0.00303156
	LOSS [training: -0.0018924033747323356 | validation: -0.0018464930720436287]
	TIME [epoch: 19.1 sec]
EPOCH 129/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022359574346204627		[learning rate: 0.0029854]
	Learning Rate: 0.00298538
	LOSS [training: -0.0022359574346204627 | validation: -0.002026280858418455]
	TIME [epoch: 19 sec]
EPOCH 130/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0017011349495437275		[learning rate: 0.0029399]
	Learning Rate: 0.0029399
	LOSS [training: -0.0017011349495437275 | validation: -0.00206944399882961]
	TIME [epoch: 19.1 sec]
EPOCH 131/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002177297553337538		[learning rate: 0.0028951]
	Learning Rate: 0.00289512
	LOSS [training: -0.002177297553337538 | validation: -0.0024322092259540158]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_131.pth
	Model improved!!!
EPOCH 132/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002558977579140893		[learning rate: 0.002851]
	Learning Rate: 0.00285102
	LOSS [training: -0.002558977579140893 | validation: -0.0011250795651277182]
	TIME [epoch: 19.1 sec]
EPOCH 133/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001661189973852247		[learning rate: 0.0028076]
	Learning Rate: 0.00280759
	LOSS [training: -0.001661189973852247 | validation: -0.0016849432574580572]
	TIME [epoch: 19.1 sec]
EPOCH 134/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002104034982465193		[learning rate: 0.0027648]
	Learning Rate: 0.00276482
	LOSS [training: -0.002104034982465193 | validation: -0.0016588047101586643]
	TIME [epoch: 19.1 sec]
EPOCH 135/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0017224782768051504		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: -0.0017224782768051504 | validation: -0.002033397836425762]
	TIME [epoch: 19.1 sec]
EPOCH 136/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022589583200399413		[learning rate: 0.0026812]
	Learning Rate: 0.00268123
	LOSS [training: -0.0022589583200399413 | validation: -0.002528587097756535]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_136.pth
	Model improved!!!
EPOCH 137/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0023103835722949337		[learning rate: 0.0026404]
	Learning Rate: 0.00264038
	LOSS [training: -0.0023103835722949337 | validation: -0.0012021143985854704]
	TIME [epoch: 19.1 sec]
EPOCH 138/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019514797178590106		[learning rate: 0.0026002]
	Learning Rate: 0.00260016
	LOSS [training: -0.0019514797178590106 | validation: -0.0014486177078302305]
	TIME [epoch: 19.1 sec]
EPOCH 139/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0011269635795676872		[learning rate: 0.0025606]
	Learning Rate: 0.00256055
	LOSS [training: -0.0011269635795676872 | validation: -0.0019864704091218863]
	TIME [epoch: 19.1 sec]
EPOCH 140/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020651365105652875		[learning rate: 0.0025215]
	Learning Rate: 0.00252154
	LOSS [training: -0.0020651365105652875 | validation: -0.0021843402207614403]
	TIME [epoch: 19.1 sec]
EPOCH 141/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021735042507923575		[learning rate: 0.0024831]
	Learning Rate: 0.00248313
	LOSS [training: -0.0021735042507923575 | validation: -0.0014571006518443422]
	TIME [epoch: 19.1 sec]
EPOCH 142/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00134050714722578		[learning rate: 0.0024453]
	Learning Rate: 0.00244531
	LOSS [training: -0.00134050714722578 | validation: -0.0017351560384344083]
	TIME [epoch: 19.1 sec]
EPOCH 143/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0018144146695995547		[learning rate: 0.0024081]
	Learning Rate: 0.00240806
	LOSS [training: -0.0018144146695995547 | validation: -0.0014043956537224981]
	TIME [epoch: 19.1 sec]
EPOCH 144/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022359772746241018		[learning rate: 0.0023714]
	Learning Rate: 0.00237137
	LOSS [training: -0.0022359772746241018 | validation: -0.002040686156679871]
	TIME [epoch: 19.1 sec]
EPOCH 145/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001955762673647622		[learning rate: 0.0023352]
	Learning Rate: 0.00233525
	LOSS [training: -0.001955762673647622 | validation: -0.002080623894286013]
	TIME [epoch: 19.1 sec]
EPOCH 146/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0018931398819559179		[learning rate: 0.0022997]
	Learning Rate: 0.00229968
	LOSS [training: -0.0018931398819559179 | validation: -0.0012830604911551863]
	TIME [epoch: 19.1 sec]
EPOCH 147/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0013229515265891884		[learning rate: 0.0022646]
	Learning Rate: 0.00226464
	LOSS [training: -0.0013229515265891884 | validation: 0.0005655601987185386]
	TIME [epoch: 19.1 sec]
EPOCH 148/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001804815417618932		[learning rate: 0.0022301]
	Learning Rate: 0.00223015
	LOSS [training: -0.001804815417618932 | validation: -0.0011858000391987873]
	TIME [epoch: 19.1 sec]
EPOCH 149/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001536139105402035		[learning rate: 0.0021962]
	Learning Rate: 0.00219617
	LOSS [training: -0.001536139105402035 | validation: -0.0018109569901098097]
	TIME [epoch: 19.2 sec]
EPOCH 150/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0018800948299489305		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: -0.0018800948299489305 | validation: -0.002136904915869257]
	TIME [epoch: 19.2 sec]
EPOCH 151/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002044011613649627		[learning rate: 0.0021298]
	Learning Rate: 0.00212977
	LOSS [training: -0.002044011613649627 | validation: -0.0018405026299686447]
	TIME [epoch: 19.2 sec]
EPOCH 152/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020207916713549396		[learning rate: 0.0020973]
	Learning Rate: 0.00209733
	LOSS [training: -0.0020207916713549396 | validation: -0.00201222583925792]
	TIME [epoch: 19.1 sec]
EPOCH 153/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0018994874743636354		[learning rate: 0.0020654]
	Learning Rate: 0.00206538
	LOSS [training: -0.0018994874743636354 | validation: -0.0019610474708298374]
	TIME [epoch: 19.3 sec]
EPOCH 154/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0023763599501037402		[learning rate: 0.0020339]
	Learning Rate: 0.00203392
	LOSS [training: -0.0023763599501037402 | validation: -0.002244702830367774]
	TIME [epoch: 19.1 sec]
EPOCH 155/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020842688436437298		[learning rate: 0.0020029]
	Learning Rate: 0.00200293
	LOSS [training: -0.0020842688436437298 | validation: -0.0016334407939787195]
	TIME [epoch: 19.1 sec]
EPOCH 156/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0011384744860876196		[learning rate: 0.0019724]
	Learning Rate: 0.00197242
	LOSS [training: -0.0011384744860876196 | validation: -0.0018551062060180481]
	TIME [epoch: 19.1 sec]
EPOCH 157/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0018537091417730844		[learning rate: 0.0019424]
	Learning Rate: 0.00194238
	LOSS [training: -0.0018537091417730844 | validation: -0.0023356250124887193]
	TIME [epoch: 19 sec]
EPOCH 158/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002283465038928629		[learning rate: 0.0019128]
	Learning Rate: 0.00191279
	LOSS [training: -0.002283465038928629 | validation: -0.0012830310610045341]
	TIME [epoch: 19.1 sec]
EPOCH 159/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0015343749084495855		[learning rate: 0.0018836]
	Learning Rate: 0.00188365
	LOSS [training: -0.0015343749084495855 | validation: -0.0017778636031738526]
	TIME [epoch: 19 sec]
EPOCH 160/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0016206087754610298		[learning rate: 0.001855]
	Learning Rate: 0.00185495
	LOSS [training: -0.0016206087754610298 | validation: -0.001831354275867368]
	TIME [epoch: 19.1 sec]
EPOCH 161/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0011732578588286558		[learning rate: 0.0018267]
	Learning Rate: 0.0018267
	LOSS [training: -0.0011732578588286558 | validation: -0.0005651539493955258]
	TIME [epoch: 19.1 sec]
EPOCH 162/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0005766829248300867		[learning rate: 0.0017989]
	Learning Rate: 0.00179887
	LOSS [training: -0.0005766829248300867 | validation: -0.0014249692691711581]
	TIME [epoch: 19 sec]
EPOCH 163/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0013249531474300602		[learning rate: 0.0017715]
	Learning Rate: 0.00177147
	LOSS [training: -0.0013249531474300602 | validation: -0.001606064740058863]
	TIME [epoch: 19.1 sec]
EPOCH 164/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019998291115454693		[learning rate: 0.0017445]
	Learning Rate: 0.00174448
	LOSS [training: -0.0019998291115454693 | validation: -0.0021989782763154105]
	TIME [epoch: 19 sec]
EPOCH 165/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019019387041690362		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: -0.0019019387041690362 | validation: -0.0016362108112497648]
	TIME [epoch: 19.1 sec]
EPOCH 166/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0016614028286121366		[learning rate: 0.0016917]
	Learning Rate: 0.00169174
	LOSS [training: -0.0016614028286121366 | validation: -0.001315238064706582]
	TIME [epoch: 19.1 sec]
EPOCH 167/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0018816371096418974		[learning rate: 0.001666]
	Learning Rate: 0.00166597
	LOSS [training: -0.0018816371096418974 | validation: -0.002343263314605609]
	TIME [epoch: 19 sec]
EPOCH 168/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019650460596492645		[learning rate: 0.0016406]
	Learning Rate: 0.00164059
	LOSS [training: -0.0019650460596492645 | validation: -0.0019885325577209166]
	TIME [epoch: 19.1 sec]
EPOCH 169/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0017774626398012194		[learning rate: 0.0016156]
	Learning Rate: 0.0016156
	LOSS [training: -0.0017774626398012194 | validation: -0.002064998394455384]
	TIME [epoch: 19.1 sec]
EPOCH 170/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0016069722801231767		[learning rate: 0.001591]
	Learning Rate: 0.00159099
	LOSS [training: -0.0016069722801231767 | validation: -0.0010674782749280918]
	TIME [epoch: 19.1 sec]
EPOCH 171/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0014621807527879617		[learning rate: 0.0015668]
	Learning Rate: 0.00156675
	LOSS [training: -0.0014621807527879617 | validation: -0.0015862739219408392]
	TIME [epoch: 19.1 sec]
EPOCH 172/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001783367937780033		[learning rate: 0.0015429]
	Learning Rate: 0.00154288
	LOSS [training: -0.001783367937780033 | validation: -0.0013758039994245545]
	TIME [epoch: 19 sec]
EPOCH 173/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022196704857760843		[learning rate: 0.0015194]
	Learning Rate: 0.00151938
	LOSS [training: -0.0022196704857760843 | validation: -0.001487808913424444]
	TIME [epoch: 19.1 sec]
EPOCH 174/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0025894807611392063		[learning rate: 0.0014962]
	Learning Rate: 0.00149624
	LOSS [training: -0.0025894807611392063 | validation: -0.001212261275553407]
	TIME [epoch: 19.1 sec]
EPOCH 175/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021169894104587097		[learning rate: 0.0014734]
	Learning Rate: 0.00147344
	LOSS [training: -0.0021169894104587097 | validation: -0.001809344025000812]
	TIME [epoch: 19.1 sec]
EPOCH 176/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002216424423644567		[learning rate: 0.001451]
	Learning Rate: 0.001451
	LOSS [training: -0.002216424423644567 | validation: -0.002408878224122111]
	TIME [epoch: 19.1 sec]
EPOCH 177/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001980668992016075		[learning rate: 0.0014289]
	Learning Rate: 0.00142889
	LOSS [training: -0.001980668992016075 | validation: -0.002114713689974432]
	TIME [epoch: 19.1 sec]
EPOCH 178/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0024208717951950355		[learning rate: 0.0014071]
	Learning Rate: 0.00140713
	LOSS [training: -0.0024208717951950355 | validation: -0.0017602816454157563]
	TIME [epoch: 19.1 sec]
EPOCH 179/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021249198659994244		[learning rate: 0.0013857]
	Learning Rate: 0.00138569
	LOSS [training: -0.0021249198659994244 | validation: -0.0012552405285499995]
	TIME [epoch: 19.1 sec]
EPOCH 180/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001849370451498173		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: -0.001849370451498173 | validation: -0.0016793249248140373]
	TIME [epoch: 19 sec]
EPOCH 181/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0017828925781342444		[learning rate: 0.0013438]
	Learning Rate: 0.0013438
	LOSS [training: -0.0017828925781342444 | validation: -0.0018617673439084387]
	TIME [epoch: 19.1 sec]
EPOCH 182/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022731401555153934		[learning rate: 0.0013233]
	Learning Rate: 0.00132333
	LOSS [training: -0.0022731401555153934 | validation: -0.002042629330493105]
	TIME [epoch: 19 sec]
EPOCH 183/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021988515970529114		[learning rate: 0.0013032]
	Learning Rate: 0.00130317
	LOSS [training: -0.0021988515970529114 | validation: -0.0017199146897388582]
	TIME [epoch: 19.1 sec]
EPOCH 184/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0016524745486263428		[learning rate: 0.0012833]
	Learning Rate: 0.00128332
	LOSS [training: -0.0016524745486263428 | validation: -0.0020174104694140153]
	TIME [epoch: 19.1 sec]
EPOCH 185/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0017426679115795881		[learning rate: 0.0012638]
	Learning Rate: 0.00126377
	LOSS [training: -0.0017426679115795881 | validation: -0.0013005451053384651]
	TIME [epoch: 19 sec]
EPOCH 186/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022807974219835603		[learning rate: 0.0012445]
	Learning Rate: 0.00124451
	LOSS [training: -0.0022807974219835603 | validation: -0.0015207509933810905]
	TIME [epoch: 19.1 sec]
EPOCH 187/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022942164417481055		[learning rate: 0.0012256]
	Learning Rate: 0.00122556
	LOSS [training: -0.0022942164417481055 | validation: -0.0015720980944943725]
	TIME [epoch: 19 sec]
EPOCH 188/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020372943608509522		[learning rate: 0.0012069]
	Learning Rate: 0.00120689
	LOSS [training: -0.0020372943608509522 | validation: -0.0020764336286905345]
	TIME [epoch: 19.1 sec]
EPOCH 189/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020203577192634296		[learning rate: 0.0011885]
	Learning Rate: 0.0011885
	LOSS [training: -0.0020203577192634296 | validation: -0.002676913690287923]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_189.pth
	Model improved!!!
EPOCH 190/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019359030844933532		[learning rate: 0.0011704]
	Learning Rate: 0.0011704
	LOSS [training: -0.0019359030844933532 | validation: -0.002160559587230697]
	TIME [epoch: 19.1 sec]
EPOCH 191/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019269592114868376		[learning rate: 0.0011526]
	Learning Rate: 0.00115257
	LOSS [training: -0.0019269592114868376 | validation: -0.0018449809984327089]
	TIME [epoch: 19.1 sec]
EPOCH 192/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001953647155516115		[learning rate: 0.001135]
	Learning Rate: 0.00113501
	LOSS [training: -0.001953647155516115 | validation: -0.001442289905026635]
	TIME [epoch: 19.1 sec]
EPOCH 193/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002024896463062528		[learning rate: 0.0011177]
	Learning Rate: 0.00111772
	LOSS [training: -0.002024896463062528 | validation: -0.0022060836039901896]
	TIME [epoch: 19.1 sec]
EPOCH 194/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002007221070831346		[learning rate: 0.0011007]
	Learning Rate: 0.00110069
	LOSS [training: -0.002007221070831346 | validation: -0.0021812191696243717]
	TIME [epoch: 19.1 sec]
EPOCH 195/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020659181538537426		[learning rate: 0.0010839]
	Learning Rate: 0.00108393
	LOSS [training: -0.0020659181538537426 | validation: -0.002272761941269132]
	TIME [epoch: 19.1 sec]
EPOCH 196/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021971686065019435		[learning rate: 0.0010674]
	Learning Rate: 0.00106741
	LOSS [training: -0.0021971686065019435 | validation: -0.002246108630007996]
	TIME [epoch: 19.1 sec]
EPOCH 197/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021647755049601478		[learning rate: 0.0010512]
	Learning Rate: 0.00105115
	LOSS [training: -0.0021647755049601478 | validation: -0.002519396627828011]
	TIME [epoch: 19.1 sec]
EPOCH 198/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002010696186985568		[learning rate: 0.0010351]
	Learning Rate: 0.00103514
	LOSS [training: -0.002010696186985568 | validation: -0.002342508216742848]
	TIME [epoch: 19.1 sec]
EPOCH 199/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0018695423194943408		[learning rate: 0.0010194]
	Learning Rate: 0.00101937
	LOSS [training: -0.0018695423194943408 | validation: -0.002230794370207268]
	TIME [epoch: 19.1 sec]
EPOCH 200/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022315315037032754		[learning rate: 0.0010038]
	Learning Rate: 0.00100384
	LOSS [training: -0.0022315315037032754 | validation: -0.0018005407393187154]
	TIME [epoch: 19.1 sec]
EPOCH 201/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002271015638030933		[learning rate: 0.00098855]
	Learning Rate: 0.000988553
	LOSS [training: -0.002271015638030933 | validation: -0.0023113357474255445]
	TIME [epoch: 19.2 sec]
EPOCH 202/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00224288639238974		[learning rate: 0.00097349]
	Learning Rate: 0.000973494
	LOSS [training: -0.00224288639238974 | validation: -0.0021291717476000552]
	TIME [epoch: 19.1 sec]
EPOCH 203/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001737106874534244		[learning rate: 0.00095866]
	Learning Rate: 0.000958664
	LOSS [training: -0.001737106874534244 | validation: -0.0019794893914001186]
	TIME [epoch: 19.1 sec]
EPOCH 204/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00214686922848551		[learning rate: 0.00094406]
	Learning Rate: 0.000944061
	LOSS [training: -0.00214686922848551 | validation: -0.001346188391086434]
	TIME [epoch: 19.1 sec]
EPOCH 205/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0017039508136010486		[learning rate: 0.00092968]
	Learning Rate: 0.00092968
	LOSS [training: -0.0017039508136010486 | validation: -0.00140993470761787]
	TIME [epoch: 19.2 sec]
EPOCH 206/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0018215535014595406		[learning rate: 0.00091552]
	Learning Rate: 0.000915518
	LOSS [training: -0.0018215535014595406 | validation: -0.002031145101210341]
	TIME [epoch: 19.2 sec]
EPOCH 207/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002052451001504988		[learning rate: 0.00090157]
	Learning Rate: 0.000901571
	LOSS [training: -0.002052451001504988 | validation: -0.0017057027187502875]
	TIME [epoch: 19.1 sec]
EPOCH 208/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020856621172655387		[learning rate: 0.00088784]
	Learning Rate: 0.000887837
	LOSS [training: -0.0020856621172655387 | validation: -0.0021152467451219245]
	TIME [epoch: 19.1 sec]
EPOCH 209/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0016492687480981635		[learning rate: 0.00087431]
	Learning Rate: 0.000874312
	LOSS [training: -0.0016492687480981635 | validation: -0.001403855583171712]
	TIME [epoch: 19.1 sec]
EPOCH 210/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022444611669420983		[learning rate: 0.00086099]
	Learning Rate: 0.000860994
	LOSS [training: -0.0022444611669420983 | validation: -0.0016209843645394449]
	TIME [epoch: 19.1 sec]
EPOCH 211/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019495384727679912		[learning rate: 0.00084788]
	Learning Rate: 0.000847878
	LOSS [training: -0.0019495384727679912 | validation: -0.0012160133004621558]
	TIME [epoch: 19.1 sec]
EPOCH 212/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0023787556130265898		[learning rate: 0.00083496]
	Learning Rate: 0.000834962
	LOSS [training: -0.0023787556130265898 | validation: -0.001448689651547232]
	TIME [epoch: 19.1 sec]
EPOCH 213/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020953845979851883		[learning rate: 0.00082224]
	Learning Rate: 0.000822243
	LOSS [training: -0.0020953845979851883 | validation: -0.002150190012241492]
	TIME [epoch: 19.1 sec]
EPOCH 214/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022491107481472793		[learning rate: 0.00080972]
	Learning Rate: 0.000809717
	LOSS [training: -0.0022491107481472793 | validation: -0.0010451329331006528]
	TIME [epoch: 19.1 sec]
EPOCH 215/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022780506297634564		[learning rate: 0.00079738]
	Learning Rate: 0.000797382
	LOSS [training: -0.0022780506297634564 | validation: -0.0019924810151913976]
	TIME [epoch: 19.1 sec]
EPOCH 216/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022463740699790423		[learning rate: 0.00078524]
	Learning Rate: 0.000785236
	LOSS [training: -0.0022463740699790423 | validation: -0.0017642707361249159]
	TIME [epoch: 19.1 sec]
EPOCH 217/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020852301882729528		[learning rate: 0.00077327]
	Learning Rate: 0.000773274
	LOSS [training: -0.0020852301882729528 | validation: -0.0012905061103605825]
	TIME [epoch: 19.1 sec]
EPOCH 218/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0018258549614026042		[learning rate: 0.00076149]
	Learning Rate: 0.000761494
	LOSS [training: -0.0018258549614026042 | validation: -0.0007786895258798086]
	TIME [epoch: 19.1 sec]
EPOCH 219/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021492450699028675		[learning rate: 0.00074989]
	Learning Rate: 0.000749894
	LOSS [training: -0.0021492450699028675 | validation: -0.002318066249590434]
	TIME [epoch: 19.1 sec]
EPOCH 220/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002202830881902619		[learning rate: 0.00073847]
	Learning Rate: 0.000738471
	LOSS [training: -0.002202830881902619 | validation: -0.0021925883734307]
	TIME [epoch: 19 sec]
EPOCH 221/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002715259161439357		[learning rate: 0.00072722]
	Learning Rate: 0.000727221
	LOSS [training: -0.002715259161439357 | validation: -0.0024713492327616627]
	TIME [epoch: 19.1 sec]
EPOCH 222/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020749157427760855		[learning rate: 0.00071614]
	Learning Rate: 0.000716143
	LOSS [training: -0.0020749157427760855 | validation: -0.0024289091565705464]
	TIME [epoch: 19.1 sec]
EPOCH 223/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020265721428801885		[learning rate: 0.00070523]
	Learning Rate: 0.000705234
	LOSS [training: -0.0020265721428801885 | validation: -0.0023862672281312943]
	TIME [epoch: 19.1 sec]
EPOCH 224/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002123299611955665		[learning rate: 0.00069449]
	Learning Rate: 0.000694491
	LOSS [training: -0.002123299611955665 | validation: -0.0020683754003342236]
	TIME [epoch: 19.1 sec]
EPOCH 225/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021596532965729616		[learning rate: 0.00068391]
	Learning Rate: 0.000683912
	LOSS [training: -0.0021596532965729616 | validation: -0.002186420993483298]
	TIME [epoch: 19.1 sec]
EPOCH 226/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0018638844967291297		[learning rate: 0.00067349]
	Learning Rate: 0.000673493
	LOSS [training: -0.0018638844967291297 | validation: -0.0019404283498658695]
	TIME [epoch: 19.1 sec]
EPOCH 227/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0016981119067871555		[learning rate: 0.00066323]
	Learning Rate: 0.000663234
	LOSS [training: -0.0016981119067871555 | validation: -0.0020525408337488497]
	TIME [epoch: 19 sec]
EPOCH 228/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020929211994397774		[learning rate: 0.00065313]
	Learning Rate: 0.00065313
	LOSS [training: -0.0020929211994397774 | validation: -0.001689696968165827]
	TIME [epoch: 19.1 sec]
EPOCH 229/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021363896927112775		[learning rate: 0.00064318]
	Learning Rate: 0.000643181
	LOSS [training: -0.0021363896927112775 | validation: -0.0017988840582075754]
	TIME [epoch: 19.1 sec]
EPOCH 230/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020516462260280763		[learning rate: 0.00063338]
	Learning Rate: 0.000633383
	LOSS [training: -0.0020516462260280763 | validation: -0.0015150657552343784]
	TIME [epoch: 19 sec]
EPOCH 231/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021531753382407364		[learning rate: 0.00062373]
	Learning Rate: 0.000623735
	LOSS [training: -0.0021531753382407364 | validation: -0.0018321202729357161]
	TIME [epoch: 19.1 sec]
EPOCH 232/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0018485693812815935		[learning rate: 0.00061423]
	Learning Rate: 0.000614233
	LOSS [training: -0.0018485693812815935 | validation: -0.001991744044824914]
	TIME [epoch: 19.1 sec]
EPOCH 233/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002154680067747991		[learning rate: 0.00060488]
	Learning Rate: 0.000604876
	LOSS [training: -0.002154680067747991 | validation: -0.0005997478668940058]
	TIME [epoch: 19 sec]
EPOCH 234/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002297469805294363		[learning rate: 0.00059566]
	Learning Rate: 0.000595662
	LOSS [training: -0.002297469805294363 | validation: -0.002531255690340954]
	TIME [epoch: 19.1 sec]
EPOCH 235/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002090365040309815		[learning rate: 0.00058659]
	Learning Rate: 0.000586588
	LOSS [training: -0.002090365040309815 | validation: -0.002253983415018666]
	TIME [epoch: 19 sec]
EPOCH 236/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002201074465210498		[learning rate: 0.00057765]
	Learning Rate: 0.000577652
	LOSS [training: -0.002201074465210498 | validation: -0.002335269695606966]
	TIME [epoch: 19.1 sec]
EPOCH 237/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022588566959542474		[learning rate: 0.00056885]
	Learning Rate: 0.000568853
	LOSS [training: -0.0022588566959542474 | validation: -0.002214174533098258]
	TIME [epoch: 19.1 sec]
EPOCH 238/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0027527813807184066		[learning rate: 0.00056019]
	Learning Rate: 0.000560187
	LOSS [training: -0.0027527813807184066 | validation: -0.001955739539660217]
	TIME [epoch: 19.1 sec]
EPOCH 239/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002202293104260758		[learning rate: 0.00055165]
	Learning Rate: 0.000551654
	LOSS [training: -0.002202293104260758 | validation: -0.0018578881425625128]
	TIME [epoch: 19.1 sec]
EPOCH 240/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020646613664936095		[learning rate: 0.00054325]
	Learning Rate: 0.00054325
	LOSS [training: -0.0020646613664936095 | validation: -0.0014313967310360634]
	TIME [epoch: 19.1 sec]
EPOCH 241/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00201111712815455		[learning rate: 0.00053497]
	Learning Rate: 0.000534975
	LOSS [training: -0.00201111712815455 | validation: -0.002032606840547722]
	TIME [epoch: 19.2 sec]
EPOCH 242/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020142136379945616		[learning rate: 0.00052683]
	Learning Rate: 0.000526825
	LOSS [training: -0.0020142136379945616 | validation: -0.002340679214472273]
	TIME [epoch: 19.1 sec]
EPOCH 243/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021824562091893717		[learning rate: 0.0005188]
	Learning Rate: 0.0005188
	LOSS [training: -0.0021824562091893717 | validation: -0.0020487704721417446]
	TIME [epoch: 19.1 sec]
EPOCH 244/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0023563028563560787		[learning rate: 0.0005109]
	Learning Rate: 0.000510897
	LOSS [training: -0.0023563028563560787 | validation: -0.0025030050148487585]
	TIME [epoch: 19.2 sec]
EPOCH 245/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002424336673760075		[learning rate: 0.00050311]
	Learning Rate: 0.000503114
	LOSS [training: -0.002424336673760075 | validation: -0.001714670600731289]
	TIME [epoch: 19.1 sec]
EPOCH 246/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002526778649192344		[learning rate: 0.00049545]
	Learning Rate: 0.00049545
	LOSS [training: -0.002526778649192344 | validation: -0.0020100007338416767]
	TIME [epoch: 19.1 sec]
EPOCH 247/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021505335414125277		[learning rate: 0.0004879]
	Learning Rate: 0.000487903
	LOSS [training: -0.0021505335414125277 | validation: -0.0021085553731294824]
	TIME [epoch: 19.1 sec]
EPOCH 248/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021928572237388567		[learning rate: 0.00048047]
	Learning Rate: 0.00048047
	LOSS [training: -0.0021928572237388567 | validation: -0.0018205157891890552]
	TIME [epoch: 19 sec]
EPOCH 249/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002113477997407453		[learning rate: 0.00047315]
	Learning Rate: 0.000473151
	LOSS [training: -0.002113477997407453 | validation: -0.002062270966502892]
	TIME [epoch: 19.1 sec]
EPOCH 250/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020186126772745575		[learning rate: 0.00046594]
	Learning Rate: 0.000465944
	LOSS [training: -0.0020186126772745575 | validation: -0.0027575671732857124]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_250.pth
	Model improved!!!
EPOCH 251/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0026854204106195657		[learning rate: 0.00045885]
	Learning Rate: 0.000458846
	LOSS [training: -0.0026854204106195657 | validation: -0.0014644393545118345]
	TIME [epoch: 134 sec]
EPOCH 252/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002233718209975635		[learning rate: 0.00045186]
	Learning Rate: 0.000451856
	LOSS [training: -0.002233718209975635 | validation: -0.0011462681299286822]
	TIME [epoch: 42.4 sec]
EPOCH 253/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021850817816743903		[learning rate: 0.00044497]
	Learning Rate: 0.000444973
	LOSS [training: -0.0021850817816743903 | validation: -0.002432801055125491]
	TIME [epoch: 42.4 sec]
EPOCH 254/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020211130605847847		[learning rate: 0.00043819]
	Learning Rate: 0.000438194
	LOSS [training: -0.0020211130605847847 | validation: -0.0017918065348977454]
	TIME [epoch: 42.4 sec]
EPOCH 255/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00230851335936655		[learning rate: 0.00043152]
	Learning Rate: 0.000431519
	LOSS [training: -0.00230851335936655 | validation: -0.002254529074539403]
	TIME [epoch: 42.4 sec]
EPOCH 256/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0023431046171884457		[learning rate: 0.00042495]
	Learning Rate: 0.000424946
	LOSS [training: -0.0023431046171884457 | validation: -0.002462905204442838]
	TIME [epoch: 42.4 sec]
EPOCH 257/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002043752093427299		[learning rate: 0.00041847]
	Learning Rate: 0.000418472
	LOSS [training: -0.002043752093427299 | validation: -0.0008691893648841757]
	TIME [epoch: 42.5 sec]
EPOCH 258/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0017746012164050163		[learning rate: 0.0004121]
	Learning Rate: 0.000412098
	LOSS [training: -0.0017746012164050163 | validation: -0.0017952757937749315]
	TIME [epoch: 42.4 sec]
EPOCH 259/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002212810113436142		[learning rate: 0.00040582]
	Learning Rate: 0.00040582
	LOSS [training: -0.002212810113436142 | validation: -0.002248826948233953]
	TIME [epoch: 42.4 sec]
EPOCH 260/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019099502403831447		[learning rate: 0.00039964]
	Learning Rate: 0.000399638
	LOSS [training: -0.0019099502403831447 | validation: -0.0020672636773220072]
	TIME [epoch: 42.4 sec]
EPOCH 261/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002272704561306502		[learning rate: 0.00039355]
	Learning Rate: 0.00039355
	LOSS [training: -0.002272704561306502 | validation: -0.0017491147684226612]
	TIME [epoch: 42.4 sec]
EPOCH 262/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0023434065948486653		[learning rate: 0.00038755]
	Learning Rate: 0.000387555
	LOSS [training: -0.0023434065948486653 | validation: -0.0020339649201932732]
	TIME [epoch: 42.4 sec]
EPOCH 263/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002136032083735639		[learning rate: 0.00038165]
	Learning Rate: 0.000381651
	LOSS [training: -0.002136032083735639 | validation: -0.0020112605076631645]
	TIME [epoch: 42.4 sec]
EPOCH 264/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021622775256177167		[learning rate: 0.00037584]
	Learning Rate: 0.000375837
	LOSS [training: -0.0021622775256177167 | validation: -0.001337268122282903]
	TIME [epoch: 42.4 sec]
EPOCH 265/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021532475699699754		[learning rate: 0.00037011]
	Learning Rate: 0.000370112
	LOSS [training: -0.0021532475699699754 | validation: -0.0022651779071156865]
	TIME [epoch: 42.4 sec]
EPOCH 266/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0023628840009954468		[learning rate: 0.00036447]
	Learning Rate: 0.000364474
	LOSS [training: -0.0023628840009954468 | validation: -0.0018890467881050072]
	TIME [epoch: 42.4 sec]
EPOCH 267/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0023847585270003135		[learning rate: 0.00035892]
	Learning Rate: 0.000358922
	LOSS [training: -0.0023847585270003135 | validation: -0.0014423995987535255]
	TIME [epoch: 42.4 sec]
EPOCH 268/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020403670190301103		[learning rate: 0.00035345]
	Learning Rate: 0.000353454
	LOSS [training: -0.0020403670190301103 | validation: -0.002248343738912922]
	TIME [epoch: 42.4 sec]
EPOCH 269/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021980599519890957		[learning rate: 0.00034807]
	Learning Rate: 0.00034807
	LOSS [training: -0.0021980599519890957 | validation: -0.002329582089197368]
	TIME [epoch: 42.4 sec]
EPOCH 270/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0025670114673414083		[learning rate: 0.00034277]
	Learning Rate: 0.000342768
	LOSS [training: -0.0025670114673414083 | validation: -0.0021816747217191872]
	TIME [epoch: 42.4 sec]
EPOCH 271/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021102047049354382		[learning rate: 0.00033755]
	Learning Rate: 0.000337546
	LOSS [training: -0.0021102047049354382 | validation: -0.0019915600974337792]
	TIME [epoch: 42.4 sec]
EPOCH 272/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002300628303141877		[learning rate: 0.0003324]
	Learning Rate: 0.000332404
	LOSS [training: -0.002300628303141877 | validation: -0.0016281133629890694]
	TIME [epoch: 42.4 sec]
EPOCH 273/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001914438065636583		[learning rate: 0.00032734]
	Learning Rate: 0.000327341
	LOSS [training: -0.001914438065636583 | validation: -0.0025951136713820043]
	TIME [epoch: 42.4 sec]
EPOCH 274/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002222048592979171		[learning rate: 0.00032235]
	Learning Rate: 0.000322354
	LOSS [training: -0.002222048592979171 | validation: -0.0008694671070666922]
	TIME [epoch: 42.4 sec]
EPOCH 275/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0023370766086071287		[learning rate: 0.00031744]
	Learning Rate: 0.000317444
	LOSS [training: -0.0023370766086071287 | validation: -0.001461707728505333]
	TIME [epoch: 42.4 sec]
EPOCH 276/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021327100896078198		[learning rate: 0.00031261]
	Learning Rate: 0.000312608
	LOSS [training: -0.0021327100896078198 | validation: -0.0023600160436536405]
	TIME [epoch: 42.4 sec]
EPOCH 277/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0018130871819677745		[learning rate: 0.00030785]
	Learning Rate: 0.000307846
	LOSS [training: -0.0018130871819677745 | validation: -0.0018416122838483338]
	TIME [epoch: 42.4 sec]
EPOCH 278/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019624464106880015		[learning rate: 0.00030316]
	Learning Rate: 0.000303156
	LOSS [training: -0.0019624464106880015 | validation: -0.0019961612446888193]
	TIME [epoch: 42.4 sec]
EPOCH 279/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0025594183622797712		[learning rate: 0.00029854]
	Learning Rate: 0.000298538
	LOSS [training: -0.0025594183622797712 | validation: -0.0012146786134893972]
	TIME [epoch: 42.4 sec]
EPOCH 280/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019162598913556354		[learning rate: 0.00029399]
	Learning Rate: 0.000293991
	LOSS [training: -0.0019162598913556354 | validation: -0.0017856142009296018]
	TIME [epoch: 42.4 sec]
EPOCH 281/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021323289624777635		[learning rate: 0.00028951]
	Learning Rate: 0.000289512
	LOSS [training: -0.0021323289624777635 | validation: -0.002305893036883099]
	TIME [epoch: 42.4 sec]
EPOCH 282/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0023590420081440722		[learning rate: 0.0002851]
	Learning Rate: 0.000285102
	LOSS [training: -0.0023590420081440722 | validation: -0.0013694670775904743]
	TIME [epoch: 42.4 sec]
EPOCH 283/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021259465711249517		[learning rate: 0.00028076]
	Learning Rate: 0.000280759
	LOSS [training: -0.0021259465711249517 | validation: -0.0025392250305676916]
	TIME [epoch: 42.4 sec]
EPOCH 284/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00245242339091548		[learning rate: 0.00027648]
	Learning Rate: 0.000276482
	LOSS [training: -0.00245242339091548 | validation: -0.0018524071628161045]
	TIME [epoch: 42.4 sec]
EPOCH 285/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020906782808928015		[learning rate: 0.00027227]
	Learning Rate: 0.00027227
	LOSS [training: -0.0020906782808928015 | validation: -0.002060235678895822]
	TIME [epoch: 42.5 sec]
EPOCH 286/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002490974512291533		[learning rate: 0.00026812]
	Learning Rate: 0.000268123
	LOSS [training: -0.002490974512291533 | validation: -0.0023285490844043473]
	TIME [epoch: 42.4 sec]
EPOCH 287/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002313602510430959		[learning rate: 0.00026404]
	Learning Rate: 0.000264038
	LOSS [training: -0.002313602510430959 | validation: -0.0014556709157420955]
	TIME [epoch: 42.5 sec]
EPOCH 288/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002223619778709494		[learning rate: 0.00026002]
	Learning Rate: 0.000260016
	LOSS [training: -0.002223619778709494 | validation: -0.002263574683930171]
	TIME [epoch: 42.4 sec]
EPOCH 289/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0023546201015435964		[learning rate: 0.00025606]
	Learning Rate: 0.000256055
	LOSS [training: -0.0023546201015435964 | validation: -0.0020273482081670548]
	TIME [epoch: 42.4 sec]
EPOCH 290/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0023790407308963138		[learning rate: 0.00025215]
	Learning Rate: 0.000252154
	LOSS [training: -0.0023790407308963138 | validation: -0.002213528863953375]
	TIME [epoch: 42.4 sec]
EPOCH 291/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002246165465574385		[learning rate: 0.00024831]
	Learning Rate: 0.000248313
	LOSS [training: -0.002246165465574385 | validation: -0.0020549067383990862]
	TIME [epoch: 42.4 sec]
EPOCH 292/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022571187765258937		[learning rate: 0.00024453]
	Learning Rate: 0.000244531
	LOSS [training: -0.0022571187765258937 | validation: -0.0019900161177113917]
	TIME [epoch: 42.4 sec]
EPOCH 293/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020906839716595795		[learning rate: 0.00024081]
	Learning Rate: 0.000240806
	LOSS [training: -0.0020906839716595795 | validation: -0.002175239143759504]
	TIME [epoch: 42.4 sec]
EPOCH 294/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0023976722713392445		[learning rate: 0.00023714]
	Learning Rate: 0.000237137
	LOSS [training: -0.0023976722713392445 | validation: -0.0022005787020820873]
	TIME [epoch: 42.5 sec]
EPOCH 295/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0023895903105044304		[learning rate: 0.00023352]
	Learning Rate: 0.000233525
	LOSS [training: -0.0023895903105044304 | validation: -0.0016998667604181214]
	TIME [epoch: 42.5 sec]
EPOCH 296/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0023815819122489056		[learning rate: 0.00022997]
	Learning Rate: 0.000229968
	LOSS [training: -0.0023815819122489056 | validation: -0.0017419854982535297]
	TIME [epoch: 42.5 sec]
EPOCH 297/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002189942570670073		[learning rate: 0.00022646]
	Learning Rate: 0.000226464
	LOSS [training: -0.002189942570670073 | validation: -0.0016546544638349028]
	TIME [epoch: 42.4 sec]
EPOCH 298/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0026582518874700488		[learning rate: 0.00022301]
	Learning Rate: 0.000223015
	LOSS [training: -0.0026582518874700488 | validation: -0.0024791262506534137]
	TIME [epoch: 42.4 sec]
EPOCH 299/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0024632076146219135		[learning rate: 0.00021962]
	Learning Rate: 0.000219617
	LOSS [training: -0.0024632076146219135 | validation: -0.0023452087031391386]
	TIME [epoch: 42.4 sec]
EPOCH 300/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002341198891007858		[learning rate: 0.00021627]
	Learning Rate: 0.000216272
	LOSS [training: -0.002341198891007858 | validation: -0.001927721982275331]
	TIME [epoch: 42.4 sec]
EPOCH 301/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022412819376731582		[learning rate: 0.00021298]
	Learning Rate: 0.000212977
	LOSS [training: -0.0022412819376731582 | validation: -0.0008225242540219773]
	TIME [epoch: 42.4 sec]
EPOCH 302/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022158637061081773		[learning rate: 0.00020973]
	Learning Rate: 0.000209733
	LOSS [training: -0.0022158637061081773 | validation: -0.0014109253185630123]
	TIME [epoch: 42.4 sec]
EPOCH 303/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020909780331140474		[learning rate: 0.00020654]
	Learning Rate: 0.000206538
	LOSS [training: -0.0020909780331140474 | validation: -0.0015171109370838635]
	TIME [epoch: 42.4 sec]
EPOCH 304/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022150017362102307		[learning rate: 0.00020339]
	Learning Rate: 0.000203392
	LOSS [training: -0.0022150017362102307 | validation: -0.0018955754475305589]
	TIME [epoch: 42.3 sec]
EPOCH 305/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0023670931724931923		[learning rate: 0.00020029]
	Learning Rate: 0.000200293
	LOSS [training: -0.0023670931724931923 | validation: -0.001142558445926231]
	TIME [epoch: 42.3 sec]
EPOCH 306/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002436430658325457		[learning rate: 0.00019724]
	Learning Rate: 0.000197242
	LOSS [training: -0.002436430658325457 | validation: -0.0016908187724420957]
	TIME [epoch: 42.4 sec]
EPOCH 307/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020701294148685935		[learning rate: 0.00019424]
	Learning Rate: 0.000194238
	LOSS [training: -0.0020701294148685935 | validation: -0.0011609920307738655]
	TIME [epoch: 42.3 sec]
EPOCH 308/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002114278765906831		[learning rate: 0.00019128]
	Learning Rate: 0.000191279
	LOSS [training: -0.002114278765906831 | validation: -0.001620217325534576]
	TIME [epoch: 42.4 sec]
EPOCH 309/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019859177978158006		[learning rate: 0.00018836]
	Learning Rate: 0.000188365
	LOSS [training: -0.0019859177978158006 | validation: -0.0019705833947156783]
	TIME [epoch: 42.3 sec]
EPOCH 310/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002132233217199488		[learning rate: 0.0001855]
	Learning Rate: 0.000185495
	LOSS [training: -0.002132233217199488 | validation: -0.0015785945149880565]
	TIME [epoch: 42.4 sec]
EPOCH 311/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0024175332627762525		[learning rate: 0.00018267]
	Learning Rate: 0.00018267
	LOSS [training: -0.0024175332627762525 | validation: -0.0019780764493477106]
	TIME [epoch: 42.4 sec]
EPOCH 312/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0024197248917516507		[learning rate: 0.00017989]
	Learning Rate: 0.000179887
	LOSS [training: -0.0024197248917516507 | validation: -0.00214320339864805]
	TIME [epoch: 42.4 sec]
EPOCH 313/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0023498973553962013		[learning rate: 0.00017715]
	Learning Rate: 0.000177147
	LOSS [training: -0.0023498973553962013 | validation: -0.0022595625898213455]
	TIME [epoch: 42.4 sec]
EPOCH 314/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002285132592273191		[learning rate: 0.00017445]
	Learning Rate: 0.000174448
	LOSS [training: -0.002285132592273191 | validation: -0.00246207549674276]
	TIME [epoch: 42.4 sec]
EPOCH 315/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0023723101777238585		[learning rate: 0.00017179]
	Learning Rate: 0.000171791
	LOSS [training: -0.0023723101777238585 | validation: -0.0018521201424405442]
	TIME [epoch: 42.4 sec]
EPOCH 316/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0025604361751050213		[learning rate: 0.00016917]
	Learning Rate: 0.000169174
	LOSS [training: -0.0025604361751050213 | validation: -0.0022418111437277123]
	TIME [epoch: 42.4 sec]
EPOCH 317/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0023612822686048386		[learning rate: 0.0001666]
	Learning Rate: 0.000166597
	LOSS [training: -0.0023612822686048386 | validation: -0.001930667641696898]
	TIME [epoch: 42.4 sec]
EPOCH 318/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002111690382214347		[learning rate: 0.00016406]
	Learning Rate: 0.000164059
	LOSS [training: -0.002111690382214347 | validation: -0.0014820052693496838]
	TIME [epoch: 42.3 sec]
EPOCH 319/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002406528764140201		[learning rate: 0.00016156]
	Learning Rate: 0.00016156
	LOSS [training: -0.002406528764140201 | validation: -0.0020560136224295113]
	TIME [epoch: 42.3 sec]
EPOCH 320/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002700605633564627		[learning rate: 0.0001591]
	Learning Rate: 0.000159099
	LOSS [training: -0.002700605633564627 | validation: -0.0021075775587352883]
	TIME [epoch: 42.3 sec]
EPOCH 321/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0024805346253045195		[learning rate: 0.00015668]
	Learning Rate: 0.000156675
	LOSS [training: -0.0024805346253045195 | validation: -0.002600714642168286]
	TIME [epoch: 42.4 sec]
EPOCH 322/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021862858684496		[learning rate: 0.00015429]
	Learning Rate: 0.000154288
	LOSS [training: -0.0021862858684496 | validation: -0.00237854078480377]
	TIME [epoch: 42.4 sec]
EPOCH 323/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002157557375921066		[learning rate: 0.00015194]
	Learning Rate: 0.000151938
	LOSS [training: -0.002157557375921066 | validation: -0.0023920140194555297]
	TIME [epoch: 42.3 sec]
EPOCH 324/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019444688253555734		[learning rate: 0.00014962]
	Learning Rate: 0.000149624
	LOSS [training: -0.0019444688253555734 | validation: -0.0020611088171870427]
	TIME [epoch: 42.4 sec]
EPOCH 325/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021147776700580043		[learning rate: 0.00014734]
	Learning Rate: 0.000147344
	LOSS [training: -0.0021147776700580043 | validation: -0.0024423058715079956]
	TIME [epoch: 42.3 sec]
EPOCH 326/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0024232487422773084		[learning rate: 0.0001451]
	Learning Rate: 0.0001451
	LOSS [training: -0.0024232487422773084 | validation: -0.0021417657045743163]
	TIME [epoch: 42.3 sec]
EPOCH 327/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002103785564268054		[learning rate: 0.00014289]
	Learning Rate: 0.000142889
	LOSS [training: -0.002103785564268054 | validation: -0.0022478885133383605]
	TIME [epoch: 42.4 sec]
EPOCH 328/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002265561753145789		[learning rate: 0.00014071]
	Learning Rate: 0.000140713
	LOSS [training: -0.002265561753145789 | validation: -0.0017800627594374415]
	TIME [epoch: 42.4 sec]
EPOCH 329/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022808131958728783		[learning rate: 0.00013857]
	Learning Rate: 0.000138569
	LOSS [training: -0.0022808131958728783 | validation: -0.0021355427407403834]
	TIME [epoch: 42.4 sec]
EPOCH 330/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0018141244184876762		[learning rate: 0.00013646]
	Learning Rate: 0.000136458
	LOSS [training: -0.0018141244184876762 | validation: -0.001677057128460853]
	TIME [epoch: 42.4 sec]
EPOCH 331/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002118945678088342		[learning rate: 0.00013438]
	Learning Rate: 0.00013438
	LOSS [training: -0.002118945678088342 | validation: -0.001801016533359753]
	TIME [epoch: 42.4 sec]
EPOCH 332/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019733150911477424		[learning rate: 0.00013233]
	Learning Rate: 0.000132333
	LOSS [training: -0.0019733150911477424 | validation: -0.001482306845134633]
	TIME [epoch: 42.4 sec]
EPOCH 333/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021773437818456455		[learning rate: 0.00013032]
	Learning Rate: 0.000130317
	LOSS [training: -0.0021773437818456455 | validation: -0.0020221709177154204]
	TIME [epoch: 42.4 sec]
EPOCH 334/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0024119368005568655		[learning rate: 0.00012833]
	Learning Rate: 0.000128332
	LOSS [training: -0.0024119368005568655 | validation: -0.0025577487475731122]
	TIME [epoch: 42.4 sec]
EPOCH 335/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002248813022635044		[learning rate: 0.00012638]
	Learning Rate: 0.000126377
	LOSS [training: -0.002248813022635044 | validation: -0.0019909126371321405]
	TIME [epoch: 42.4 sec]
EPOCH 336/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021868407574192335		[learning rate: 0.00012445]
	Learning Rate: 0.000124451
	LOSS [training: -0.0021868407574192335 | validation: -0.0016427227224278373]
	TIME [epoch: 42.4 sec]
EPOCH 337/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0023604727024937842		[learning rate: 0.00012256]
	Learning Rate: 0.000122556
	LOSS [training: -0.0023604727024937842 | validation: -0.0018493956039924444]
	TIME [epoch: 42.4 sec]
EPOCH 338/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002219739607212813		[learning rate: 0.00012069]
	Learning Rate: 0.000120689
	LOSS [training: -0.002219739607212813 | validation: -0.001325005417538736]
	TIME [epoch: 42.4 sec]
EPOCH 339/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019260725183280322		[learning rate: 0.00011885]
	Learning Rate: 0.00011885
	LOSS [training: -0.0019260725183280322 | validation: -0.0008989200493582264]
	TIME [epoch: 42.3 sec]
EPOCH 340/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0024330895601218563		[learning rate: 0.00011704]
	Learning Rate: 0.00011704
	LOSS [training: -0.0024330895601218563 | validation: -0.00226360330933762]
	TIME [epoch: 42.3 sec]
EPOCH 341/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0023235835564172423		[learning rate: 0.00011526]
	Learning Rate: 0.000115257
	LOSS [training: -0.0023235835564172423 | validation: -0.0014707265230459283]
	TIME [epoch: 42.4 sec]
EPOCH 342/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021620092809656686		[learning rate: 0.0001135]
	Learning Rate: 0.000113501
	LOSS [training: -0.0021620092809656686 | validation: -0.002606058517839235]
	TIME [epoch: 42.4 sec]
EPOCH 343/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020569587073737653		[learning rate: 0.00011177]
	Learning Rate: 0.000111772
	LOSS [training: -0.0020569587073737653 | validation: -0.00164805082286033]
	TIME [epoch: 42.4 sec]
EPOCH 344/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002283943512068671		[learning rate: 0.00011007]
	Learning Rate: 0.000110069
	LOSS [training: -0.002283943512068671 | validation: -0.002332887139200535]
	TIME [epoch: 42.4 sec]
EPOCH 345/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002545389982438385		[learning rate: 0.00010839]
	Learning Rate: 0.000108393
	LOSS [training: -0.002545389982438385 | validation: -0.0012396774217266558]
	TIME [epoch: 42.4 sec]
EPOCH 346/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002540548151298009		[learning rate: 0.00010674]
	Learning Rate: 0.000106742
	LOSS [training: -0.002540548151298009 | validation: -0.0019035842773935708]
	TIME [epoch: 42.4 sec]
EPOCH 347/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002171107642082127		[learning rate: 0.00010512]
	Learning Rate: 0.000105115
	LOSS [training: -0.002171107642082127 | validation: -0.0019090442351261112]
	TIME [epoch: 42.3 sec]
EPOCH 348/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00236355302487274		[learning rate: 0.00010351]
	Learning Rate: 0.000103514
	LOSS [training: -0.00236355302487274 | validation: -0.0019865766309593216]
	TIME [epoch: 42.4 sec]
EPOCH 349/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002237596764346341		[learning rate: 0.00010194]
	Learning Rate: 0.000101937
	LOSS [training: -0.002237596764346341 | validation: -0.0022908044816686607]
	TIME [epoch: 42.4 sec]
EPOCH 350/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002499641829763926		[learning rate: 0.00010038]
	Learning Rate: 0.000100385
	LOSS [training: -0.002499641829763926 | validation: -0.0018901075900666425]
	TIME [epoch: 42.4 sec]
EPOCH 351/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022853707391139516		[learning rate: 9.8855e-05]
	Learning Rate: 9.88553e-05
	LOSS [training: -0.0022853707391139516 | validation: -0.0022059725576128045]
	TIME [epoch: 42.4 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20240705_020924/states/model_algphi2_1a_v_mmd1_351.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 8188.139 seconds.
