Args:
Namespace(name='model_algphi1_1a_v_klv2', outdir='out/model_training/model_algphi1_1a_v_klv2', training_data='data/training_data/data_phi1_1a/training', validation_data='data/training_data/data_phi1_1a/validation', model_type='binary_choice', nsims_training=None, nsims_validation=None, num_epochs=500, passes_per_epoch=1, batch_size=250, patience=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=False, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 250], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=False, confinement_factor=1.0, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], phi_final_act='softplus', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=0.0, init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='klv2', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3284547162

Training model...

Saving initial model state to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 4/4] avg loss: 10.696224113582613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.696224113582613 | validation: 10.644418091761851]
	TIME [epoch: 101 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 4/4] avg loss: 10.68794991444744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.68794991444744 | validation: 10.700596878997988]
	TIME [epoch: 4.36 sec]
EPOCH 3/500:
	Training over batches...
		[batch 4/4] avg loss: 10.667881165880631		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.667881165880631 | validation: 10.686253955445117]
	TIME [epoch: 4.31 sec]
EPOCH 4/500:
	Training over batches...
		[batch 4/4] avg loss: 10.646359838279537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.646359838279537 | validation: 10.595661923503902]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 4/4] avg loss: 10.652640945776847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.652640945776847 | validation: 10.602783558102136]
	TIME [epoch: 4.29 sec]
EPOCH 6/500:
	Training over batches...
		[batch 4/4] avg loss: 10.6410166809269		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.6410166809269 | validation: 10.620299815597363]
	TIME [epoch: 4.29 sec]
EPOCH 7/500:
	Training over batches...
		[batch 4/4] avg loss: 10.620579047709647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.620579047709647 | validation: 10.652402896515]
	TIME [epoch: 4.29 sec]
EPOCH 8/500:
	Training over batches...
		[batch 4/4] avg loss: 10.575619438308971		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.575619438308971 | validation: 10.615966467176136]
	TIME [epoch: 4.28 sec]
EPOCH 9/500:
	Training over batches...
		[batch 4/4] avg loss: 10.614956752939094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.614956752939094 | validation: 10.69310904709112]
	TIME [epoch: 4.28 sec]
EPOCH 10/500:
	Training over batches...
		[batch 4/4] avg loss: 10.621046567849941		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.621046567849941 | validation: 10.62813844178431]
	TIME [epoch: 4.29 sec]
EPOCH 11/500:
	Training over batches...
		[batch 4/4] avg loss: 10.635562948117222		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.635562948117222 | validation: 10.597855293877014]
	TIME [epoch: 4.28 sec]
EPOCH 12/500:
	Training over batches...
		[batch 4/4] avg loss: 10.602971340822595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.602971340822595 | validation: 10.587243338398064]
	TIME [epoch: 4.28 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_12.pth
	Model improved!!!
EPOCH 13/500:
	Training over batches...
		[batch 4/4] avg loss: 10.605388384070732		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.605388384070732 | validation: 10.570240510645132]
	TIME [epoch: 4.29 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_13.pth
	Model improved!!!
EPOCH 14/500:
	Training over batches...
		[batch 4/4] avg loss: 10.581723221934816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.581723221934816 | validation: 10.575861016176816]
	TIME [epoch: 4.32 sec]
EPOCH 15/500:
	Training over batches...
		[batch 4/4] avg loss: 10.505544176552148		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.505544176552148 | validation: 10.557331630622535]
	TIME [epoch: 4.28 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_15.pth
	Model improved!!!
EPOCH 16/500:
	Training over batches...
		[batch 4/4] avg loss: 10.49240740678957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.49240740678957 | validation: 10.549219149885381]
	TIME [epoch: 4.28 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_16.pth
	Model improved!!!
EPOCH 17/500:
	Training over batches...
		[batch 4/4] avg loss: 10.558813947755857		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.558813947755857 | validation: 10.522255873916524]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_17.pth
	Model improved!!!
EPOCH 18/500:
	Training over batches...
		[batch 4/4] avg loss: 10.569061780904024		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.569061780904024 | validation: 10.549894590355986]
	TIME [epoch: 4.29 sec]
EPOCH 19/500:
	Training over batches...
		[batch 4/4] avg loss: 10.586233094931522		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.586233094931522 | validation: 10.6079799221037]
	TIME [epoch: 4.28 sec]
EPOCH 20/500:
	Training over batches...
		[batch 4/4] avg loss: 10.60317635421784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.60317635421784 | validation: 10.631072205423763]
	TIME [epoch: 4.28 sec]
EPOCH 21/500:
	Training over batches...
		[batch 4/4] avg loss: 10.593143871855428		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.593143871855428 | validation: 10.660056744411762]
	TIME [epoch: 4.28 sec]
EPOCH 22/500:
	Training over batches...
		[batch 4/4] avg loss: 10.576824014560536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.576824014560536 | validation: 10.631497566690683]
	TIME [epoch: 4.31 sec]
EPOCH 23/500:
	Training over batches...
		[batch 4/4] avg loss: 10.571743918421713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.571743918421713 | validation: 10.588023309332504]
	TIME [epoch: 4.31 sec]
EPOCH 24/500:
	Training over batches...
		[batch 4/4] avg loss: 10.550075925975719		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.550075925975719 | validation: 10.58090374764159]
	TIME [epoch: 4.29 sec]
EPOCH 25/500:
	Training over batches...
		[batch 4/4] avg loss: 10.511192379397892		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.511192379397892 | validation: 10.594937838589239]
	TIME [epoch: 4.28 sec]
EPOCH 26/500:
	Training over batches...
		[batch 4/4] avg loss: 10.466470023268164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.466470023268164 | validation: 10.531493546771134]
	TIME [epoch: 4.28 sec]
EPOCH 27/500:
	Training over batches...
		[batch 4/4] avg loss: 10.437457024376318		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.437457024376318 | validation: 10.533584081156647]
	TIME [epoch: 4.28 sec]
EPOCH 28/500:
	Training over batches...
		[batch 4/4] avg loss: 10.422641127394728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.422641127394728 | validation: 10.539408769510135]
	TIME [epoch: 4.28 sec]
EPOCH 29/500:
	Training over batches...
		[batch 4/4] avg loss: 10.387309164164941		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.387309164164941 | validation: 10.482494048638788]
	TIME [epoch: 4.28 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_29.pth
	Model improved!!!
EPOCH 30/500:
	Training over batches...
		[batch 4/4] avg loss: 10.408346243984141		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.408346243984141 | validation: 10.408203090189296]
	TIME [epoch: 4.27 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_30.pth
	Model improved!!!
EPOCH 31/500:
	Training over batches...
		[batch 4/4] avg loss: 10.34815428218634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.34815428218634 | validation: 10.274573276973268]
	TIME [epoch: 4.28 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_31.pth
	Model improved!!!
EPOCH 32/500:
	Training over batches...
		[batch 4/4] avg loss: 10.22613217681098		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.22613217681098 | validation: 10.135310486324109]
	TIME [epoch: 4.32 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_32.pth
	Model improved!!!
EPOCH 33/500:
	Training over batches...
		[batch 4/4] avg loss: 10.098574729295976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.098574729295976 | validation: 9.964003484079829]
	TIME [epoch: 4.29 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_33.pth
	Model improved!!!
EPOCH 34/500:
	Training over batches...
		[batch 4/4] avg loss: 10.023121116312609		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.023121116312609 | validation: 9.885685569117804]
	TIME [epoch: 4.4 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_34.pth
	Model improved!!!
EPOCH 35/500:
	Training over batches...
		[batch 4/4] avg loss: 9.982235421175947		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.982235421175947 | validation: 9.811052843633655]
	TIME [epoch: 4.28 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_35.pth
	Model improved!!!
EPOCH 36/500:
	Training over batches...
		[batch 4/4] avg loss: 9.901504890958824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.901504890958824 | validation: 9.77233356806763]
	TIME [epoch: 4.29 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_36.pth
	Model improved!!!
EPOCH 37/500:
	Training over batches...
		[batch 4/4] avg loss: 9.829489629383694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.829489629383694 | validation: 9.66676426418309]
	TIME [epoch: 4.29 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_37.pth
	Model improved!!!
EPOCH 38/500:
	Training over batches...
		[batch 4/4] avg loss: 9.685896238321202		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.685896238321202 | validation: 9.559140642533123]
	TIME [epoch: 4.27 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_38.pth
	Model improved!!!
EPOCH 39/500:
	Training over batches...
		[batch 4/4] avg loss: 9.580932570417344		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.580932570417344 | validation: 9.492360266752215]
	TIME [epoch: 4.28 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_39.pth
	Model improved!!!
EPOCH 40/500:
	Training over batches...
		[batch 4/4] avg loss: 9.489348044561126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.489348044561126 | validation: 9.42119832957644]
	TIME [epoch: 4.29 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_40.pth
	Model improved!!!
EPOCH 41/500:
	Training over batches...
		[batch 4/4] avg loss: 9.345007066849483		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.345007066849483 | validation: 9.107727790392275]
	TIME [epoch: 4.31 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_41.pth
	Model improved!!!
EPOCH 42/500:
	Training over batches...
		[batch 4/4] avg loss: 9.174321519418948		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.174321519418948 | validation: 9.029396463129892]
	TIME [epoch: 4.29 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_42.pth
	Model improved!!!
EPOCH 43/500:
	Training over batches...
		[batch 4/4] avg loss: 9.122135925001688		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.122135925001688 | validation: 8.930271590838192]
	TIME [epoch: 4.28 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_43.pth
	Model improved!!!
EPOCH 44/500:
	Training over batches...
		[batch 4/4] avg loss: 9.028194047759703		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.028194047759703 | validation: 8.681175879435555]
	TIME [epoch: 4.29 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_44.pth
	Model improved!!!
EPOCH 45/500:
	Training over batches...
		[batch 4/4] avg loss: 8.735050174554281		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.735050174554281 | validation: 8.357933840042609]
	TIME [epoch: 4.28 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_45.pth
	Model improved!!!
EPOCH 46/500:
	Training over batches...
		[batch 4/4] avg loss: 8.51398235026573		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.51398235026573 | validation: 8.028588938342207]
	TIME [epoch: 4.28 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_46.pth
	Model improved!!!
EPOCH 47/500:
	Training over batches...
		[batch 4/4] avg loss: 8.028259314034184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.028259314034184 | validation: 7.515003949287253]
	TIME [epoch: 4.28 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_47.pth
	Model improved!!!
EPOCH 48/500:
	Training over batches...
		[batch 4/4] avg loss: 7.566641771847165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.566641771847165 | validation: 7.203311542463004]
	TIME [epoch: 4.28 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_48.pth
	Model improved!!!
EPOCH 49/500:
	Training over batches...
		[batch 4/4] avg loss: 7.27533676423528		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.27533676423528 | validation: 6.940598189979547]
	TIME [epoch: 4.32 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_49.pth
	Model improved!!!
EPOCH 50/500:
	Training over batches...
		[batch 4/4] avg loss: 6.892506805245495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.892506805245495 | validation: 6.5472446232694]
	TIME [epoch: 4.32 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_50.pth
	Model improved!!!
EPOCH 51/500:
	Training over batches...
		[batch 4/4] avg loss: 4.482736120221367		[learning rate: 0.0098855]
	Learning Rate: 0.00988553
	LOSS [training: 4.482736120221367 | validation: 3.7617473630406133]
	TIME [epoch: 104 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_51.pth
	Model improved!!!
EPOCH 52/500:
	Training over batches...
		[batch 4/4] avg loss: 3.877874483367242		[learning rate: 0.0097349]
	Learning Rate: 0.00973494
	LOSS [training: 3.877874483367242 | validation: 3.2713330004389705]
	TIME [epoch: 8.45 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_52.pth
	Model improved!!!
EPOCH 53/500:
	Training over batches...
		[batch 4/4] avg loss: 3.4136574141528557		[learning rate: 0.0095866]
	Learning Rate: 0.00958665
	LOSS [training: 3.4136574141528557 | validation: 2.8211890768186603]
	TIME [epoch: 8.42 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_53.pth
	Model improved!!!
EPOCH 54/500:
	Training over batches...
		[batch 4/4] avg loss: 3.0059740033025335		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 3.0059740033025335 | validation: 2.4099160266296358]
	TIME [epoch: 8.39 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_54.pth
	Model improved!!!
EPOCH 55/500:
	Training over batches...
		[batch 4/4] avg loss: 2.64387652979438		[learning rate: 0.0092968]
	Learning Rate: 0.0092968
	LOSS [training: 2.64387652979438 | validation: 2.1517930820738553]
	TIME [epoch: 8.38 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_55.pth
	Model improved!!!
EPOCH 56/500:
	Training over batches...
		[batch 4/4] avg loss: 2.356176309793825		[learning rate: 0.0091552]
	Learning Rate: 0.00915517
	LOSS [training: 2.356176309793825 | validation: 1.9529754098425887]
	TIME [epoch: 8.38 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_56.pth
	Model improved!!!
EPOCH 57/500:
	Training over batches...
		[batch 4/4] avg loss: 2.0591527679537194		[learning rate: 0.0090157]
	Learning Rate: 0.00901571
	LOSS [training: 2.0591527679537194 | validation: 1.7280484101410298]
	TIME [epoch: 8.37 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_57.pth
	Model improved!!!
EPOCH 58/500:
	Training over batches...
		[batch 4/4] avg loss: 1.8735767950453048		[learning rate: 0.0088784]
	Learning Rate: 0.00887837
	LOSS [training: 1.8735767950453048 | validation: 1.6134047245563845]
	TIME [epoch: 8.39 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_58.pth
	Model improved!!!
EPOCH 59/500:
	Training over batches...
		[batch 4/4] avg loss: 1.6847882200918576		[learning rate: 0.0087431]
	Learning Rate: 0.00874312
	LOSS [training: 1.6847882200918576 | validation: 1.46778210231404]
	TIME [epoch: 8.43 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_59.pth
	Model improved!!!
EPOCH 60/500:
	Training over batches...
		[batch 4/4] avg loss: 1.5337428336084646		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 1.5337428336084646 | validation: 1.343122268800347]
	TIME [epoch: 8.39 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_60.pth
	Model improved!!!
EPOCH 61/500:
	Training over batches...
		[batch 4/4] avg loss: 1.4225410525250752		[learning rate: 0.0084788]
	Learning Rate: 0.00847878
	LOSS [training: 1.4225410525250752 | validation: 1.2799339620287769]
	TIME [epoch: 8.38 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_61.pth
	Model improved!!!
EPOCH 62/500:
	Training over batches...
		[batch 4/4] avg loss: 1.3315053006770028		[learning rate: 0.0083496]
	Learning Rate: 0.00834962
	LOSS [training: 1.3315053006770028 | validation: 1.1799333197666249]
	TIME [epoch: 8.38 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_62.pth
	Model improved!!!
EPOCH 63/500:
	Training over batches...
		[batch 4/4] avg loss: 1.2291337674669922		[learning rate: 0.0082224]
	Learning Rate: 0.00822243
	LOSS [training: 1.2291337674669922 | validation: 1.0718589646425323]
	TIME [epoch: 8.37 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_63.pth
	Model improved!!!
EPOCH 64/500:
	Training over batches...
		[batch 4/4] avg loss: 1.0894261505391372		[learning rate: 0.0080972]
	Learning Rate: 0.00809717
	LOSS [training: 1.0894261505391372 | validation: 0.9457505461218018]
	TIME [epoch: 8.4 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_64.pth
	Model improved!!!
EPOCH 65/500:
	Training over batches...
		[batch 4/4] avg loss: 0.9778265129291657		[learning rate: 0.0079738]
	Learning Rate: 0.00797382
	LOSS [training: 0.9778265129291657 | validation: 0.8678250016408761]
	TIME [epoch: 8.4 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_65.pth
	Model improved!!!
EPOCH 66/500:
	Training over batches...
		[batch 4/4] avg loss: 0.8758055406680103		[learning rate: 0.0078524]
	Learning Rate: 0.00785236
	LOSS [training: 0.8758055406680103 | validation: 0.7617782413429701]
	TIME [epoch: 8.36 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_66.pth
	Model improved!!!
EPOCH 67/500:
	Training over batches...
		[batch 4/4] avg loss: 0.7888563524545888		[learning rate: 0.0077327]
	Learning Rate: 0.00773274
	LOSS [training: 0.7888563524545888 | validation: 0.7353777807773498]
	TIME [epoch: 8.36 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_67.pth
	Model improved!!!
EPOCH 68/500:
	Training over batches...
		[batch 4/4] avg loss: 0.7318947922386897		[learning rate: 0.0076149]
	Learning Rate: 0.00761494
	LOSS [training: 0.7318947922386897 | validation: 0.6718562016706429]
	TIME [epoch: 8.36 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_68.pth
	Model improved!!!
EPOCH 69/500:
	Training over batches...
		[batch 4/4] avg loss: 0.6765722814810057		[learning rate: 0.0074989]
	Learning Rate: 0.00749894
	LOSS [training: 0.6765722814810057 | validation: 0.5859700070647029]
	TIME [epoch: 8.39 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_69.pth
	Model improved!!!
EPOCH 70/500:
	Training over batches...
		[batch 4/4] avg loss: 0.5726052721129269		[learning rate: 0.0073847]
	Learning Rate: 0.00738471
	LOSS [training: 0.5726052721129269 | validation: 0.49763586911437496]
	TIME [epoch: 8.43 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_70.pth
	Model improved!!!
EPOCH 71/500:
	Training over batches...
		[batch 4/4] avg loss: 0.4820529594095295		[learning rate: 0.0072722]
	Learning Rate: 0.00727221
	LOSS [training: 0.4820529594095295 | validation: 0.4180782877965161]
	TIME [epoch: 8.41 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_71.pth
	Model improved!!!
EPOCH 72/500:
	Training over batches...
		[batch 4/4] avg loss: 0.3963642608513992		[learning rate: 0.0071614]
	Learning Rate: 0.00716143
	LOSS [training: 0.3963642608513992 | validation: 0.3159387438340366]
	TIME [epoch: 8.4 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_72.pth
	Model improved!!!
EPOCH 73/500:
	Training over batches...
		[batch 4/4] avg loss: 0.3091674345154698		[learning rate: 0.0070523]
	Learning Rate: 0.00705234
	LOSS [training: 0.3091674345154698 | validation: 0.254398210767657]
	TIME [epoch: 8.37 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_73.pth
	Model improved!!!
EPOCH 74/500:
	Training over batches...
		[batch 4/4] avg loss: 0.23824767321878249		[learning rate: 0.0069449]
	Learning Rate: 0.00694491
	LOSS [training: 0.23824767321878249 | validation: 0.19886424707078576]
	TIME [epoch: 8.39 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_74.pth
	Model improved!!!
EPOCH 75/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1786333315144862		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.1786333315144862 | validation: 0.14157915250238814]
	TIME [epoch: 8.42 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_75.pth
	Model improved!!!
EPOCH 76/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13719069359736677		[learning rate: 0.0067349]
	Learning Rate: 0.00673493
	LOSS [training: 0.13719069359736677 | validation: 0.13614942747572734]
	TIME [epoch: 8.37 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_76.pth
	Model improved!!!
EPOCH 77/500:
	Training over batches...
		[batch 4/4] avg loss: 0.11582840230572425		[learning rate: 0.0066323]
	Learning Rate: 0.00663234
	LOSS [training: 0.11582840230572425 | validation: 0.08512789757607982]
	TIME [epoch: 8.35 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_77.pth
	Model improved!!!
EPOCH 78/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08741391068465224		[learning rate: 0.0065313]
	Learning Rate: 0.00653131
	LOSS [training: 0.08741391068465224 | validation: 0.09341528645944072]
	TIME [epoch: 8.36 sec]
EPOCH 79/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07321247129270086		[learning rate: 0.0064318]
	Learning Rate: 0.00643181
	LOSS [training: 0.07321247129270086 | validation: 0.06783039708453666]
	TIME [epoch: 8.36 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_79.pth
	Model improved!!!
EPOCH 80/500:
	Training over batches...
		[batch 4/4] avg loss: 0.053403387569093824		[learning rate: 0.0063338]
	Learning Rate: 0.00633383
	LOSS [training: 0.053403387569093824 | validation: 0.052869257475630774]
	TIME [epoch: 8.42 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_80.pth
	Model improved!!!
EPOCH 81/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05782521657880625		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.05782521657880625 | validation: 0.05540796731010823]
	TIME [epoch: 8.4 sec]
EPOCH 82/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0506783860206879		[learning rate: 0.0061423]
	Learning Rate: 0.00614233
	LOSS [training: 0.0506783860206879 | validation: 0.07557294925710878]
	TIME [epoch: 8.4 sec]
EPOCH 83/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08371817804782848		[learning rate: 0.0060488]
	Learning Rate: 0.00604876
	LOSS [training: 0.08371817804782848 | validation: 0.07467387167966041]
	TIME [epoch: 8.38 sec]
EPOCH 84/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05909843838457077		[learning rate: 0.0059566]
	Learning Rate: 0.00595662
	LOSS [training: 0.05909843838457077 | validation: 0.059838082018798]
	TIME [epoch: 8.37 sec]
EPOCH 85/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05621935206899117		[learning rate: 0.0058659]
	Learning Rate: 0.00586588
	LOSS [training: 0.05621935206899117 | validation: 0.069195299278276]
	TIME [epoch: 8.4 sec]
EPOCH 86/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07844584191898454		[learning rate: 0.0057765]
	Learning Rate: 0.00577653
	LOSS [training: 0.07844584191898454 | validation: 0.09135744440813365]
	TIME [epoch: 8.4 sec]
EPOCH 87/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07830431972382346		[learning rate: 0.0056885]
	Learning Rate: 0.00568853
	LOSS [training: 0.07830431972382346 | validation: 0.062404427484984384]
	TIME [epoch: 8.38 sec]
EPOCH 88/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05859470069838024		[learning rate: 0.0056019]
	Learning Rate: 0.00560187
	LOSS [training: 0.05859470069838024 | validation: 0.04582221863988663]
	TIME [epoch: 8.37 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_88.pth
	Model improved!!!
EPOCH 89/500:
	Training over batches...
		[batch 4/4] avg loss: 0.050077497475093026		[learning rate: 0.0055165]
	Learning Rate: 0.00551654
	LOSS [training: 0.050077497475093026 | validation: 0.050426697076100285]
	TIME [epoch: 8.39 sec]
EPOCH 90/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04462451865930511		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.04462451865930511 | validation: 0.053544866195137535]
	TIME [epoch: 8.39 sec]
EPOCH 91/500:
	Training over batches...
		[batch 4/4] avg loss: 0.046694574091698485		[learning rate: 0.0053497]
	Learning Rate: 0.00534975
	LOSS [training: 0.046694574091698485 | validation: 0.04076850513823346]
	TIME [epoch: 8.43 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_91.pth
	Model improved!!!
EPOCH 92/500:
	Training over batches...
		[batch 4/4] avg loss: 0.046899055653422214		[learning rate: 0.0052683]
	Learning Rate: 0.00526825
	LOSS [training: 0.046899055653422214 | validation: 0.04972277227076427]
	TIME [epoch: 8.38 sec]
EPOCH 93/500:
	Training over batches...
		[batch 4/4] avg loss: 0.055539462278890214		[learning rate: 0.005188]
	Learning Rate: 0.005188
	LOSS [training: 0.055539462278890214 | validation: 0.08547065091407867]
	TIME [epoch: 8.37 sec]
EPOCH 94/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06144731640794203		[learning rate: 0.005109]
	Learning Rate: 0.00510897
	LOSS [training: 0.06144731640794203 | validation: 0.06896107283618866]
	TIME [epoch: 8.37 sec]
EPOCH 95/500:
	Training over batches...
		[batch 4/4] avg loss: 0.059266117649283426		[learning rate: 0.0050311]
	Learning Rate: 0.00503114
	LOSS [training: 0.059266117649283426 | validation: 0.057455302052706034]
	TIME [epoch: 8.37 sec]
EPOCH 96/500:
	Training over batches...
		[batch 4/4] avg loss: 0.052947808630746926		[learning rate: 0.0049545]
	Learning Rate: 0.0049545
	LOSS [training: 0.052947808630746926 | validation: 0.05788540441707972]
	TIME [epoch: 8.43 sec]
EPOCH 97/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05217684185275293		[learning rate: 0.004879]
	Learning Rate: 0.00487903
	LOSS [training: 0.05217684185275293 | validation: 0.04878075058770422]
	TIME [epoch: 8.4 sec]
EPOCH 98/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04989887946994279		[learning rate: 0.0048047]
	Learning Rate: 0.0048047
	LOSS [training: 0.04989887946994279 | validation: 0.03759503810800863]
	TIME [epoch: 8.41 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_98.pth
	Model improved!!!
EPOCH 99/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04957838203712963		[learning rate: 0.0047315]
	Learning Rate: 0.00473151
	LOSS [training: 0.04957838203712963 | validation: 0.057047353197238214]
	TIME [epoch: 8.42 sec]
EPOCH 100/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0610703001881622		[learning rate: 0.0046594]
	Learning Rate: 0.00465944
	LOSS [training: 0.0610703001881622 | validation: 0.07225757596158935]
	TIME [epoch: 8.41 sec]
EPOCH 101/500:
	Training over batches...
		[batch 4/4] avg loss: 0.022980532411671972		[learning rate: 0.0045885]
	Learning Rate: 0.00458846
	LOSS [training: 0.022980532411671972 | validation: 0.032080012355223717]
	TIME [epoch: 114 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_101.pth
	Model improved!!!
EPOCH 102/500:
	Training over batches...
		[batch 4/4] avg loss: 0.013799332905543471		[learning rate: 0.0045186]
	Learning Rate: 0.00451856
	LOSS [training: 0.013799332905543471 | validation: 0.0036632038945763118]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_102.pth
	Model improved!!!
EPOCH 103/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0003604163559432957		[learning rate: 0.0044497]
	Learning Rate: 0.00444973
	LOSS [training: -0.0003604163559432957 | validation: -0.007787766972172871]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_103.pth
	Model improved!!!
EPOCH 104/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008813550609235691		[learning rate: 0.0043819]
	Learning Rate: 0.00438194
	LOSS [training: -0.008813550609235691 | validation: 0.0010485138865474874]
	TIME [epoch: 19 sec]
EPOCH 105/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01002182500113336		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: -0.01002182500113336 | validation: 0.00036847783152666597]
	TIME [epoch: 19.1 sec]
EPOCH 106/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011750254639024394		[learning rate: 0.0042495]
	Learning Rate: 0.00424946
	LOSS [training: -0.011750254639024394 | validation: -0.0012453362281944708]
	TIME [epoch: 19 sec]
EPOCH 107/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011735501014230322		[learning rate: 0.0041847]
	Learning Rate: 0.00418472
	LOSS [training: -0.011735501014230322 | validation: -0.004384350352286203]
	TIME [epoch: 19 sec]
EPOCH 108/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008268063751289		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: -0.008268063751289 | validation: -0.007685936483004396]
	TIME [epoch: 19.1 sec]
EPOCH 109/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012643604907920287		[learning rate: 0.0040582]
	Learning Rate: 0.0040582
	LOSS [training: -0.012643604907920287 | validation: -0.004440441307298112]
	TIME [epoch: 19 sec]
EPOCH 110/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007453391097682743		[learning rate: 0.0039964]
	Learning Rate: 0.00399638
	LOSS [training: -0.007453391097682743 | validation: 0.0010457099418456762]
	TIME [epoch: 19.1 sec]
EPOCH 111/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00018795762967022405		[learning rate: 0.0039355]
	Learning Rate: 0.0039355
	LOSS [training: 0.00018795762967022405 | validation: 0.0010343357029545907]
	TIME [epoch: 19 sec]
EPOCH 112/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010639946435379884		[learning rate: 0.0038755]
	Learning Rate: 0.00387555
	LOSS [training: -0.010639946435379884 | validation: -0.0014126326382719627]
	TIME [epoch: 19.1 sec]
EPOCH 113/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007646325083620394		[learning rate: 0.0038165]
	Learning Rate: 0.00381651
	LOSS [training: -0.007646325083620394 | validation: -0.0054136930440870186]
	TIME [epoch: 19 sec]
EPOCH 114/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009511902571358942		[learning rate: 0.0037584]
	Learning Rate: 0.00375837
	LOSS [training: -0.009511902571358942 | validation: -0.0026532544058625322]
	TIME [epoch: 19 sec]
EPOCH 115/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009506026146612853		[learning rate: 0.0037011]
	Learning Rate: 0.00370112
	LOSS [training: -0.009506026146612853 | validation: 0.002655304965209421]
	TIME [epoch: 19.1 sec]
EPOCH 116/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007142709460795604		[learning rate: 0.0036447]
	Learning Rate: 0.00364474
	LOSS [training: -0.007142709460795604 | validation: -0.01766623846607818]
	TIME [epoch: 19 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_116.pth
	Model improved!!!
EPOCH 117/500:
	Training over batches...
		[batch 4/4] avg loss: -0.016370633070848607		[learning rate: 0.0035892]
	Learning Rate: 0.00358922
	LOSS [training: -0.016370633070848607 | validation: -0.007536866285225105]
	TIME [epoch: 19.1 sec]
EPOCH 118/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0075309589800216445		[learning rate: 0.0035345]
	Learning Rate: 0.00353454
	LOSS [training: -0.0075309589800216445 | validation: 0.004903752330805594]
	TIME [epoch: 19 sec]
EPOCH 119/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00564828520333924		[learning rate: 0.0034807]
	Learning Rate: 0.0034807
	LOSS [training: -0.00564828520333924 | validation: 0.002653964459774284]
	TIME [epoch: 19.1 sec]
EPOCH 120/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008687408761198888		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: -0.008687408761198888 | validation: -0.004131230782727311]
	TIME [epoch: 19 sec]
EPOCH 121/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008033492385999683		[learning rate: 0.0033755]
	Learning Rate: 0.00337546
	LOSS [training: -0.008033492385999683 | validation: -0.01126032254800229]
	TIME [epoch: 19 sec]
EPOCH 122/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008117096808210095		[learning rate: 0.003324]
	Learning Rate: 0.00332404
	LOSS [training: -0.008117096808210095 | validation: 0.002980200470323105]
	TIME [epoch: 19.1 sec]
EPOCH 123/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002981214078469284		[learning rate: 0.0032734]
	Learning Rate: 0.00327341
	LOSS [training: -0.002981214078469284 | validation: 0.0006810944675809359]
	TIME [epoch: 19 sec]
EPOCH 124/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0052745714090525085		[learning rate: 0.0032235]
	Learning Rate: 0.00322354
	LOSS [training: -0.0052745714090525085 | validation: -0.007569463731155887]
	TIME [epoch: 19.1 sec]
EPOCH 125/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005759904796861213		[learning rate: 0.0031744]
	Learning Rate: 0.00317444
	LOSS [training: -0.005759904796861213 | validation: -0.013825560101360103]
	TIME [epoch: 19.1 sec]
EPOCH 126/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008853179905466026		[learning rate: 0.0031261]
	Learning Rate: 0.00312608
	LOSS [training: -0.008853179905466026 | validation: -0.010258316290934783]
	TIME [epoch: 19.1 sec]
EPOCH 127/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0035013425381501566		[learning rate: 0.0030785]
	Learning Rate: 0.00307846
	LOSS [training: -0.0035013425381501566 | validation: -0.0012769464321211088]
	TIME [epoch: 19.1 sec]
EPOCH 128/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0012476012688804059		[learning rate: 0.0030316]
	Learning Rate: 0.00303156
	LOSS [training: -0.0012476012688804059 | validation: 0.004691621700797326]
	TIME [epoch: 19 sec]
EPOCH 129/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005374197450564024		[learning rate: 0.0029854]
	Learning Rate: 0.00298538
	LOSS [training: -0.005374197450564024 | validation: -0.010095206717920602]
	TIME [epoch: 19.1 sec]
EPOCH 130/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006675915671274711		[learning rate: 0.0029399]
	Learning Rate: 0.0029399
	LOSS [training: -0.006675915671274711 | validation: -0.01641441944749812]
	TIME [epoch: 19 sec]
EPOCH 131/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008543564039308515		[learning rate: 0.0028951]
	Learning Rate: 0.00289512
	LOSS [training: -0.008543564039308515 | validation: -0.004488979656972885]
	TIME [epoch: 19.1 sec]
EPOCH 132/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004998735606021002		[learning rate: 0.002851]
	Learning Rate: 0.00285102
	LOSS [training: -0.004998735606021002 | validation: -0.009743582665103948]
	TIME [epoch: 19 sec]
EPOCH 133/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009587437704649935		[learning rate: 0.0028076]
	Learning Rate: 0.00280759
	LOSS [training: -0.009587437704649935 | validation: -0.014417957694186918]
	TIME [epoch: 19 sec]
EPOCH 134/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005272197108797153		[learning rate: 0.0027648]
	Learning Rate: 0.00276482
	LOSS [training: -0.005272197108797153 | validation: -0.004517494559569602]
	TIME [epoch: 19.1 sec]
EPOCH 135/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008740122960959187		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: -0.008740122960959187 | validation: -0.006283672045498049]
	TIME [epoch: 19 sec]
EPOCH 136/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005744042337074415		[learning rate: 0.0026812]
	Learning Rate: 0.00268123
	LOSS [training: -0.005744042337074415 | validation: -0.007614069000320871]
	TIME [epoch: 19.1 sec]
EPOCH 137/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013314659256587182		[learning rate: 0.0026404]
	Learning Rate: 0.00264038
	LOSS [training: -0.013314659256587182 | validation: -0.005798604467729202]
	TIME [epoch: 19 sec]
EPOCH 138/500:
	Training over batches...
		[batch 4/4] avg loss: -0.015422476711841594		[learning rate: 0.0026002]
	Learning Rate: 0.00260016
	LOSS [training: -0.015422476711841594 | validation: -0.004110311015197131]
	TIME [epoch: 19.1 sec]
EPOCH 139/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007891255772511345		[learning rate: 0.0025606]
	Learning Rate: 0.00256055
	LOSS [training: -0.007891255772511345 | validation: -0.00715277324370882]
	TIME [epoch: 19.1 sec]
EPOCH 140/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013270974351909354		[learning rate: 0.0025215]
	Learning Rate: 0.00252154
	LOSS [training: -0.013270974351909354 | validation: -0.021049633117368564]
	TIME [epoch: 19 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_140.pth
	Model improved!!!
EPOCH 141/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005619100903397453		[learning rate: 0.0024831]
	Learning Rate: 0.00248313
	LOSS [training: -0.005619100903397453 | validation: -0.01803730260900232]
	TIME [epoch: 19.1 sec]
EPOCH 142/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0129956426795528		[learning rate: 0.0024453]
	Learning Rate: 0.00244531
	LOSS [training: -0.0129956426795528 | validation: 0.006752742849096103]
	TIME [epoch: 19 sec]
EPOCH 143/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0007557947634654835		[learning rate: 0.0024081]
	Learning Rate: 0.00240806
	LOSS [training: -0.0007557947634654835 | validation: -0.008227891898536859]
	TIME [epoch: 19.1 sec]
EPOCH 144/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005319530546500029		[learning rate: 0.0023714]
	Learning Rate: 0.00237137
	LOSS [training: -0.005319530546500029 | validation: -0.011663559442320294]
	TIME [epoch: 19 sec]
EPOCH 145/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005422481816276829		[learning rate: 0.0023352]
	Learning Rate: 0.00233525
	LOSS [training: -0.005422481816276829 | validation: -1.6330532873762207e-05]
	TIME [epoch: 19 sec]
EPOCH 146/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0033615348667629533		[learning rate: 0.0022997]
	Learning Rate: 0.00229968
	LOSS [training: 0.0033615348667629533 | validation: -0.0060342652559693104]
	TIME [epoch: 19 sec]
EPOCH 147/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0027611622546580097		[learning rate: 0.0022646]
	Learning Rate: 0.00226464
	LOSS [training: -0.0027611622546580097 | validation: 0.0020686146922320996]
	TIME [epoch: 19 sec]
EPOCH 148/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00697294334671116		[learning rate: 0.0022301]
	Learning Rate: 0.00223015
	LOSS [training: -0.00697294334671116 | validation: -0.008479938793460286]
	TIME [epoch: 19.1 sec]
EPOCH 149/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00855720913135151		[learning rate: 0.0021962]
	Learning Rate: 0.00219617
	LOSS [training: -0.00855720913135151 | validation: 0.002605833346784516]
	TIME [epoch: 19 sec]
EPOCH 150/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0015398575805261464		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: -0.0015398575805261464 | validation: -0.0067365664269417765]
	TIME [epoch: 19.1 sec]
EPOCH 151/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004596269887702388		[learning rate: 0.0021298]
	Learning Rate: 0.00212977
	LOSS [training: -0.004596269887702388 | validation: 0.0038869746990868584]
	TIME [epoch: 19 sec]
EPOCH 152/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00406611203580607		[learning rate: 0.0020973]
	Learning Rate: 0.00209733
	LOSS [training: 0.00406611203580607 | validation: 0.006494633887507366]
	TIME [epoch: 19 sec]
EPOCH 153/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0040939937644601495		[learning rate: 0.0020654]
	Learning Rate: 0.00206538
	LOSS [training: -0.0040939937644601495 | validation: -0.013333578756894105]
	TIME [epoch: 19.1 sec]
EPOCH 154/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006943087426816569		[learning rate: 0.0020339]
	Learning Rate: 0.00203392
	LOSS [training: -0.006943087426816569 | validation: 0.001685727007269893]
	TIME [epoch: 19 sec]
EPOCH 155/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021126050425919764		[learning rate: 0.0020029]
	Learning Rate: 0.00200293
	LOSS [training: -0.0021126050425919764 | validation: 0.002611611802192976]
	TIME [epoch: 19.1 sec]
EPOCH 156/500:
	Training over batches...
		[batch 4/4] avg loss: 0.005334441389258928		[learning rate: 0.0019724]
	Learning Rate: 0.00197242
	LOSS [training: 0.005334441389258928 | validation: 0.0030296070352110625]
	TIME [epoch: 19 sec]
EPOCH 157/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002007620180682539		[learning rate: 0.0019424]
	Learning Rate: 0.00194238
	LOSS [training: -0.002007620180682539 | validation: -0.0003977157634400184]
	TIME [epoch: 19 sec]
EPOCH 158/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019856547177734786		[learning rate: 0.0019128]
	Learning Rate: 0.00191279
	LOSS [training: -0.0019856547177734786 | validation: 0.00044915675977605504]
	TIME [epoch: 19 sec]
EPOCH 159/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005828269893280699		[learning rate: 0.0018836]
	Learning Rate: 0.00188365
	LOSS [training: -0.005828269893280699 | validation: -0.00789062725234435]
	TIME [epoch: 19 sec]
EPOCH 160/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00435703974746772		[learning rate: 0.001855]
	Learning Rate: 0.00185495
	LOSS [training: -0.00435703974746772 | validation: -0.004814233064717902]
	TIME [epoch: 19.1 sec]
EPOCH 161/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009661246255130184		[learning rate: 0.0018267]
	Learning Rate: 0.0018267
	LOSS [training: -0.009661246255130184 | validation: -0.003479194504266256]
	TIME [epoch: 19 sec]
EPOCH 162/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005828131575293495		[learning rate: 0.0017989]
	Learning Rate: 0.00179887
	LOSS [training: -0.005828131575293495 | validation: -0.008683783527203696]
	TIME [epoch: 19.1 sec]
EPOCH 163/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007942914794418542		[learning rate: 0.0017715]
	Learning Rate: 0.00177147
	LOSS [training: -0.007942914794418542 | validation: -0.014121053564306013]
	TIME [epoch: 19 sec]
EPOCH 164/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010559102552069943		[learning rate: 0.0017445]
	Learning Rate: 0.00174448
	LOSS [training: -0.010559102552069943 | validation: -0.008506188595029225]
	TIME [epoch: 19 sec]
EPOCH 165/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006893269956665362		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: -0.006893269956665362 | validation: -0.012520019679899838]
	TIME [epoch: 19 sec]
EPOCH 166/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009673241941640324		[learning rate: 0.0016917]
	Learning Rate: 0.00169174
	LOSS [training: -0.009673241941640324 | validation: -0.014854915302889245]
	TIME [epoch: 19 sec]
EPOCH 167/500:
	Training over batches...
		[batch 4/4] avg loss: -0.015084583175704436		[learning rate: 0.001666]
	Learning Rate: 0.00166597
	LOSS [training: -0.015084583175704436 | validation: -0.010555454189881226]
	TIME [epoch: 19.1 sec]
EPOCH 168/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009924272807599045		[learning rate: 0.0016406]
	Learning Rate: 0.00164059
	LOSS [training: -0.009924272807599045 | validation: -0.007035622704311702]
	TIME [epoch: 19 sec]
EPOCH 169/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001831565209704022		[learning rate: 0.0016156]
	Learning Rate: 0.0016156
	LOSS [training: -0.001831565209704022 | validation: -0.006330042031302174]
	TIME [epoch: 19.1 sec]
EPOCH 170/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007028513623021183		[learning rate: 0.001591]
	Learning Rate: 0.00159099
	LOSS [training: -0.007028513623021183 | validation: 0.0025892355633966935]
	TIME [epoch: 19 sec]
EPOCH 171/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0030238617588941794		[learning rate: 0.0015668]
	Learning Rate: 0.00156675
	LOSS [training: -0.0030238617588941794 | validation: -0.0005989092463413448]
	TIME [epoch: 19 sec]
EPOCH 172/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004311353237774221		[learning rate: 0.0015429]
	Learning Rate: 0.00154288
	LOSS [training: -0.004311353237774221 | validation: 0.0010640383198843046]
	TIME [epoch: 19.1 sec]
EPOCH 173/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007360720367734285		[learning rate: 0.0015194]
	Learning Rate: 0.00151938
	LOSS [training: -0.007360720367734285 | validation: -0.012369388539571915]
	TIME [epoch: 19 sec]
EPOCH 174/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00886631357534713		[learning rate: 0.0014962]
	Learning Rate: 0.00149624
	LOSS [training: -0.00886631357534713 | validation: -0.00347951510927273]
	TIME [epoch: 19.1 sec]
EPOCH 175/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00725334587823318		[learning rate: 0.0014734]
	Learning Rate: 0.00147344
	LOSS [training: -0.00725334587823318 | validation: -0.0038648586620411607]
	TIME [epoch: 19 sec]
EPOCH 176/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010009107512273182		[learning rate: 0.001451]
	Learning Rate: 0.001451
	LOSS [training: -0.010009107512273182 | validation: -0.009331161485174641]
	TIME [epoch: 19 sec]
EPOCH 177/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006549195854652022		[learning rate: 0.0014289]
	Learning Rate: 0.00142889
	LOSS [training: -0.006549195854652022 | validation: 0.011006058703201014]
	TIME [epoch: 19 sec]
EPOCH 178/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0009546109772251817		[learning rate: 0.0014071]
	Learning Rate: 0.00140713
	LOSS [training: 0.0009546109772251817 | validation: 0.015578412357917442]
	TIME [epoch: 19 sec]
EPOCH 179/500:
	Training over batches...
		[batch 4/4] avg loss: 0.001605396940361381		[learning rate: 0.0013857]
	Learning Rate: 0.00138569
	LOSS [training: 0.001605396940361381 | validation: -0.005673986100229211]
	TIME [epoch: 19.1 sec]
EPOCH 180/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005106402047517457		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: -0.005106402047517457 | validation: -0.003346264157355642]
	TIME [epoch: 19 sec]
EPOCH 181/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004759946476959225		[learning rate: 0.0013438]
	Learning Rate: 0.0013438
	LOSS [training: -0.004759946476959225 | validation: -0.00578358426692541]
	TIME [epoch: 19.1 sec]
EPOCH 182/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006760063401294957		[learning rate: 0.0013233]
	Learning Rate: 0.00132333
	LOSS [training: -0.006760063401294957 | validation: -0.005474438421080345]
	TIME [epoch: 19 sec]
EPOCH 183/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008792113319782913		[learning rate: 0.0013032]
	Learning Rate: 0.00130317
	LOSS [training: -0.008792113319782913 | validation: -0.00034003332128631917]
	TIME [epoch: 19 sec]
EPOCH 184/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010647183156663406		[learning rate: 0.0012833]
	Learning Rate: 0.00128332
	LOSS [training: -0.010647183156663406 | validation: -0.00533698884866393]
	TIME [epoch: 19.1 sec]
EPOCH 185/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008481497432715925		[learning rate: 0.0012638]
	Learning Rate: 0.00126377
	LOSS [training: -0.008481497432715925 | validation: -0.00925611241182585]
	TIME [epoch: 19 sec]
EPOCH 186/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009989129362847895		[learning rate: 0.0012445]
	Learning Rate: 0.00124451
	LOSS [training: -0.009989129362847895 | validation: -0.014031283637849275]
	TIME [epoch: 19.1 sec]
EPOCH 187/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01107774520482296		[learning rate: 0.0012256]
	Learning Rate: 0.00122556
	LOSS [training: -0.01107774520482296 | validation: -0.005083851701132006]
	TIME [epoch: 19 sec]
EPOCH 188/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011618366649490376		[learning rate: 0.0012069]
	Learning Rate: 0.00120689
	LOSS [training: -0.011618366649490376 | validation: -0.015289987748632959]
	TIME [epoch: 19.1 sec]
EPOCH 189/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009977674172136634		[learning rate: 0.0011885]
	Learning Rate: 0.0011885
	LOSS [training: -0.009977674172136634 | validation: -0.014629683623056177]
	TIME [epoch: 19 sec]
EPOCH 190/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011011133422032113		[learning rate: 0.0011704]
	Learning Rate: 0.0011704
	LOSS [training: -0.011011133422032113 | validation: -0.011959634165386576]
	TIME [epoch: 19 sec]
EPOCH 191/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014017892420533615		[learning rate: 0.0011526]
	Learning Rate: 0.00115257
	LOSS [training: -0.014017892420533615 | validation: -0.004851820388594707]
	TIME [epoch: 19.1 sec]
EPOCH 192/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013004999881617088		[learning rate: 0.001135]
	Learning Rate: 0.00113501
	LOSS [training: -0.013004999881617088 | validation: -0.00523412414404139]
	TIME [epoch: 19 sec]
EPOCH 193/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01156371033802643		[learning rate: 0.0011177]
	Learning Rate: 0.00111772
	LOSS [training: -0.01156371033802643 | validation: -0.008538347061030818]
	TIME [epoch: 19.1 sec]
EPOCH 194/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009312022742614268		[learning rate: 0.0011007]
	Learning Rate: 0.00110069
	LOSS [training: -0.009312022742614268 | validation: -0.006583896013253296]
	TIME [epoch: 19 sec]
EPOCH 195/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009899820728062645		[learning rate: 0.0010839]
	Learning Rate: 0.00108393
	LOSS [training: -0.009899820728062645 | validation: -0.006289263709428858]
	TIME [epoch: 19 sec]
EPOCH 196/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00543394045482482		[learning rate: 0.0010674]
	Learning Rate: 0.00106741
	LOSS [training: -0.00543394045482482 | validation: -0.0066128754858960585]
	TIME [epoch: 19.1 sec]
EPOCH 197/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004133293963430168		[learning rate: 0.0010512]
	Learning Rate: 0.00105115
	LOSS [training: -0.004133293963430168 | validation: -0.0043460376409080615]
	TIME [epoch: 19.1 sec]
EPOCH 198/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004741367109690893		[learning rate: 0.0010351]
	Learning Rate: 0.00103514
	LOSS [training: -0.004741367109690893 | validation: -0.00022870248829998932]
	TIME [epoch: 19.2 sec]
EPOCH 199/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005555183369175188		[learning rate: 0.0010194]
	Learning Rate: 0.00101937
	LOSS [training: -0.005555183369175188 | validation: 0.0014744972307943092]
	TIME [epoch: 19.1 sec]
EPOCH 200/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005266464903810982		[learning rate: 0.0010038]
	Learning Rate: 0.00100384
	LOSS [training: -0.005266464903810982 | validation: 0.0005466356144038344]
	TIME [epoch: 19.1 sec]
EPOCH 201/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008181792836123768		[learning rate: 0.00098855]
	Learning Rate: 0.000988553
	LOSS [training: -0.008181792836123768 | validation: -0.005174955572628675]
	TIME [epoch: 19.1 sec]
EPOCH 202/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010841664662804274		[learning rate: 0.00097349]
	Learning Rate: 0.000973494
	LOSS [training: -0.010841664662804274 | validation: -0.013170974908489856]
	TIME [epoch: 19 sec]
EPOCH 203/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009663922152524082		[learning rate: 0.00095866]
	Learning Rate: 0.000958664
	LOSS [training: -0.009663922152524082 | validation: -0.011752648804513429]
	TIME [epoch: 19.1 sec]
EPOCH 204/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00861964261100624		[learning rate: 0.00094406]
	Learning Rate: 0.000944061
	LOSS [training: -0.00861964261100624 | validation: -0.006044448572042568]
	TIME [epoch: 19 sec]
EPOCH 205/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010401724579266119		[learning rate: 0.00092968]
	Learning Rate: 0.00092968
	LOSS [training: -0.010401724579266119 | validation: -0.01170470942890104]
	TIME [epoch: 19 sec]
EPOCH 206/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010797099791009318		[learning rate: 0.00091552]
	Learning Rate: 0.000915518
	LOSS [training: -0.010797099791009318 | validation: -0.0022405920818058403]
	TIME [epoch: 19 sec]
EPOCH 207/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008067310808077703		[learning rate: 0.00090157]
	Learning Rate: 0.000901571
	LOSS [training: -0.008067310808077703 | validation: -0.00902896083491057]
	TIME [epoch: 19 sec]
EPOCH 208/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008461722761269422		[learning rate: 0.00088784]
	Learning Rate: 0.000887837
	LOSS [training: -0.008461722761269422 | validation: -0.004521756913250275]
	TIME [epoch: 19 sec]
EPOCH 209/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008635841929741577		[learning rate: 0.00087431]
	Learning Rate: 0.000874312
	LOSS [training: -0.008635841929741577 | validation: -0.006515510874376646]
	TIME [epoch: 19 sec]
EPOCH 210/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012783334417166723		[learning rate: 0.00086099]
	Learning Rate: 0.000860994
	LOSS [training: -0.012783334417166723 | validation: -0.00869653859776922]
	TIME [epoch: 19.1 sec]
EPOCH 211/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012833506030412885		[learning rate: 0.00084788]
	Learning Rate: 0.000847878
	LOSS [training: -0.012833506030412885 | validation: -0.006045427556109242]
	TIME [epoch: 19 sec]
EPOCH 212/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013543899647156552		[learning rate: 0.00083496]
	Learning Rate: 0.000834962
	LOSS [training: -0.013543899647156552 | validation: 0.0052853364046442]
	TIME [epoch: 19 sec]
EPOCH 213/500:
	Training over batches...
		[batch 4/4] avg loss: -0.016390720240411022		[learning rate: 0.00082224]
	Learning Rate: 0.000822243
	LOSS [training: -0.016390720240411022 | validation: -0.006988199818704809]
	TIME [epoch: 19 sec]
EPOCH 214/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00941907037579446		[learning rate: 0.00080972]
	Learning Rate: 0.000809717
	LOSS [training: -0.00941907037579446 | validation: -0.012281739011940407]
	TIME [epoch: 19 sec]
EPOCH 215/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009542194779882485		[learning rate: 0.00079738]
	Learning Rate: 0.000797382
	LOSS [training: -0.009542194779882485 | validation: -0.0031703824794854967]
	TIME [epoch: 19.1 sec]
EPOCH 216/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010984708903587373		[learning rate: 0.00078524]
	Learning Rate: 0.000785236
	LOSS [training: -0.010984708903587373 | validation: -0.014063009547914713]
	TIME [epoch: 19 sec]
EPOCH 217/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010832728198758836		[learning rate: 0.00077327]
	Learning Rate: 0.000773274
	LOSS [training: -0.010832728198758836 | validation: -0.00887717971621959]
	TIME [epoch: 19.1 sec]
EPOCH 218/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011979345604408932		[learning rate: 0.00076149]
	Learning Rate: 0.000761494
	LOSS [training: -0.011979345604408932 | validation: -0.01486668177808963]
	TIME [epoch: 19.1 sec]
EPOCH 219/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00911669156720956		[learning rate: 0.00074989]
	Learning Rate: 0.000749894
	LOSS [training: -0.00911669156720956 | validation: 0.0031333593438613487]
	TIME [epoch: 19.1 sec]
EPOCH 220/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010748275466351813		[learning rate: 0.00073847]
	Learning Rate: 0.000738471
	LOSS [training: -0.010748275466351813 | validation: -0.011269967864539723]
	TIME [epoch: 19 sec]
EPOCH 221/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011998533668700571		[learning rate: 0.00072722]
	Learning Rate: 0.000727221
	LOSS [training: -0.011998533668700571 | validation: -0.006935405944525129]
	TIME [epoch: 19 sec]
EPOCH 222/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012298267729717502		[learning rate: 0.00071614]
	Learning Rate: 0.000716143
	LOSS [training: -0.012298267729717502 | validation: -0.009311128621312809]
	TIME [epoch: 19.1 sec]
EPOCH 223/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011216053592035884		[learning rate: 0.00070523]
	Learning Rate: 0.000705234
	LOSS [training: -0.011216053592035884 | validation: -0.011250576290030977]
	TIME [epoch: 19 sec]
EPOCH 224/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010683875351041152		[learning rate: 0.00069449]
	Learning Rate: 0.000694491
	LOSS [training: -0.010683875351041152 | validation: -0.019699903520538832]
	TIME [epoch: 19.1 sec]
EPOCH 225/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012536583034970128		[learning rate: 0.00068391]
	Learning Rate: 0.000683912
	LOSS [training: -0.012536583034970128 | validation: -0.00998169106339933]
	TIME [epoch: 19 sec]
EPOCH 226/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011079887443804505		[learning rate: 0.00067349]
	Learning Rate: 0.000673493
	LOSS [training: -0.011079887443804505 | validation: -0.004871950288622755]
	TIME [epoch: 19 sec]
EPOCH 227/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013608720635694824		[learning rate: 0.00066323]
	Learning Rate: 0.000663234
	LOSS [training: -0.013608720635694824 | validation: -0.005322289201688714]
	TIME [epoch: 19 sec]
EPOCH 228/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012318987571439208		[learning rate: 0.00065313]
	Learning Rate: 0.00065313
	LOSS [training: -0.012318987571439208 | validation: -0.006145387022588357]
	TIME [epoch: 19 sec]
EPOCH 229/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009938499397690781		[learning rate: 0.00064318]
	Learning Rate: 0.000643181
	LOSS [training: -0.009938499397690781 | validation: -0.01049320738423665]
	TIME [epoch: 19.1 sec]
EPOCH 230/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012944435493244156		[learning rate: 0.00063338]
	Learning Rate: 0.000633383
	LOSS [training: -0.012944435493244156 | validation: -0.009053796425691308]
	TIME [epoch: 19 sec]
EPOCH 231/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009748858686797509		[learning rate: 0.00062373]
	Learning Rate: 0.000623735
	LOSS [training: -0.009748858686797509 | validation: -0.011924372882995908]
	TIME [epoch: 19 sec]
EPOCH 232/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01499808995223228		[learning rate: 0.00061423]
	Learning Rate: 0.000614233
	LOSS [training: -0.01499808995223228 | validation: -0.012258125092884795]
	TIME [epoch: 19 sec]
EPOCH 233/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011918314803606613		[learning rate: 0.00060488]
	Learning Rate: 0.000604876
	LOSS [training: -0.011918314803606613 | validation: -0.012122843974645057]
	TIME [epoch: 19 sec]
EPOCH 234/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012215444528107855		[learning rate: 0.00059566]
	Learning Rate: 0.000595662
	LOSS [training: -0.012215444528107855 | validation: -0.009985539868075629]
	TIME [epoch: 19.1 sec]
EPOCH 235/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012265771296251985		[learning rate: 0.00058659]
	Learning Rate: 0.000586588
	LOSS [training: -0.012265771296251985 | validation: -0.00776749994009238]
	TIME [epoch: 19 sec]
EPOCH 236/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010279817883477236		[learning rate: 0.00057765]
	Learning Rate: 0.000577652
	LOSS [training: -0.010279817883477236 | validation: -0.006724650565471954]
	TIME [epoch: 19.1 sec]
EPOCH 237/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011865111016579777		[learning rate: 0.00056885]
	Learning Rate: 0.000568853
	LOSS [training: -0.011865111016579777 | validation: 0.002035775070976762]
	TIME [epoch: 19 sec]
EPOCH 238/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014423693887773986		[learning rate: 0.00056019]
	Learning Rate: 0.000560187
	LOSS [training: -0.014423693887773986 | validation: -0.0007198393190992079]
	TIME [epoch: 19 sec]
EPOCH 239/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009136646961337733		[learning rate: 0.00055165]
	Learning Rate: 0.000551654
	LOSS [training: -0.009136646961337733 | validation: -0.010438541980218971]
	TIME [epoch: 19 sec]
EPOCH 240/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012781416778736603		[learning rate: 0.00054325]
	Learning Rate: 0.00054325
	LOSS [training: -0.012781416778736603 | validation: 0.0027788165528937507]
	TIME [epoch: 19 sec]
EPOCH 241/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008289380653483005		[learning rate: 0.00053497]
	Learning Rate: 0.000534975
	LOSS [training: -0.008289380653483005 | validation: -0.008637872747033499]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20240705_010809/states/model_algphi1_1a_v_klv2_241.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 3658.816 seconds.
