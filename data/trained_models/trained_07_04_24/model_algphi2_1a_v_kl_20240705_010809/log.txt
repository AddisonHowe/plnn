Args:
Namespace(name='model_algphi2_1a_v_kl', outdir='out/model_training/model_algphi2_1a_v_kl', training_data='data/training_data/data_phi2_1a/training', validation_data='data/training_data/data_phi2_1a/validation', model_type='binary_flip', nsims_training=None, nsims_validation=None, num_epochs=500, passes_per_epoch=1, batch_size=250, patience=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=False, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 250], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=False, confinement_factor=1.0, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], phi_final_act='softplus', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=0.0, init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1419835553

Training model...

Saving initial model state to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 4/4] avg loss: 5.184435460056307		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.184435460056307 | validation: 5.373345133594922]
	TIME [epoch: 100 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 4/4] avg loss: 5.040513995262566		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.040513995262566 | validation: 5.521849297489993]
	TIME [epoch: 4.29 sec]
EPOCH 3/500:
	Training over batches...
		[batch 4/4] avg loss: 5.0664571268721925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.0664571268721925 | validation: 5.381660098323843]
	TIME [epoch: 4.19 sec]
EPOCH 4/500:
	Training over batches...
		[batch 4/4] avg loss: 4.792395739993106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.792395739993106 | validation: 4.961553332071161]
	TIME [epoch: 4.19 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 4/4] avg loss: 4.596994639168723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.596994639168723 | validation: 5.0086851878568]
	TIME [epoch: 4.19 sec]
EPOCH 6/500:
	Training over batches...
		[batch 4/4] avg loss: 4.65325988245081		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.65325988245081 | validation: 5.141026019725729]
	TIME [epoch: 4.18 sec]
EPOCH 7/500:
	Training over batches...
		[batch 4/4] avg loss: 4.682194351265344		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.682194351265344 | validation: 5.089532986514579]
	TIME [epoch: 4.18 sec]
EPOCH 8/500:
	Training over batches...
		[batch 4/4] avg loss: 4.574171944366598		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.574171944366598 | validation: 4.917100063958868]
	TIME [epoch: 4.17 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_8.pth
	Model improved!!!
EPOCH 9/500:
	Training over batches...
		[batch 4/4] avg loss: 4.5140005333351985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.5140005333351985 | validation: 5.24252567733675]
	TIME [epoch: 4.17 sec]
EPOCH 10/500:
	Training over batches...
		[batch 4/4] avg loss: 4.743764575831642		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.743764575831642 | validation: 5.2592048505388345]
	TIME [epoch: 4.16 sec]
EPOCH 11/500:
	Training over batches...
		[batch 4/4] avg loss: 4.714771546435033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.714771546435033 | validation: 5.402656223740745]
	TIME [epoch: 4.17 sec]
EPOCH 12/500:
	Training over batches...
		[batch 4/4] avg loss: 4.5882315415840305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.5882315415840305 | validation: 5.1166525292603]
	TIME [epoch: 4.19 sec]
EPOCH 13/500:
	Training over batches...
		[batch 4/4] avg loss: 4.535542712600967		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.535542712600967 | validation: 5.29405297887002]
	TIME [epoch: 4.2 sec]
EPOCH 14/500:
	Training over batches...
		[batch 4/4] avg loss: 4.63940030282623		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.63940030282623 | validation: 5.507641255114651]
	TIME [epoch: 4.18 sec]
EPOCH 15/500:
	Training over batches...
		[batch 4/4] avg loss: 4.632953375630231		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.632953375630231 | validation: 5.2846519272372365]
	TIME [epoch: 4.18 sec]
EPOCH 16/500:
	Training over batches...
		[batch 4/4] avg loss: 4.435349762162545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.435349762162545 | validation: 5.0988440612121995]
	TIME [epoch: 4.17 sec]
EPOCH 17/500:
	Training over batches...
		[batch 4/4] avg loss: 4.243582210017266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.243582210017266 | validation: 4.736781502694997]
	TIME [epoch: 4.17 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_17.pth
	Model improved!!!
EPOCH 18/500:
	Training over batches...
		[batch 4/4] avg loss: 3.940371710745849		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.940371710745849 | validation: 4.283466994832838]
	TIME [epoch: 4.17 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_18.pth
	Model improved!!!
EPOCH 19/500:
	Training over batches...
		[batch 4/4] avg loss: 3.5823680478430666		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5823680478430666 | validation: 3.6529489300361697]
	TIME [epoch: 4.17 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_19.pth
	Model improved!!!
EPOCH 20/500:
	Training over batches...
		[batch 4/4] avg loss: 3.11746572150133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.11746572150133 | validation: 3.403843438274409]
	TIME [epoch: 4.17 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_20.pth
	Model improved!!!
EPOCH 21/500:
	Training over batches...
		[batch 4/4] avg loss: 2.889541077850548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.889541077850548 | validation: 2.8826323754752528]
	TIME [epoch: 4.18 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_21.pth
	Model improved!!!
EPOCH 22/500:
	Training over batches...
		[batch 4/4] avg loss: 2.4955964783063727		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4955964783063727 | validation: 2.5678398943029856]
	TIME [epoch: 4.21 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_22.pth
	Model improved!!!
EPOCH 23/500:
	Training over batches...
		[batch 4/4] avg loss: 2.1938277175886993		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1938277175886993 | validation: 2.288753279900681]
	TIME [epoch: 4.18 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_23.pth
	Model improved!!!
EPOCH 24/500:
	Training over batches...
		[batch 4/4] avg loss: 2.002653125333639		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.002653125333639 | validation: 1.977279449475509]
	TIME [epoch: 4.17 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_24.pth
	Model improved!!!
EPOCH 25/500:
	Training over batches...
		[batch 4/4] avg loss: 1.7480992504040689		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7480992504040689 | validation: 1.7508544584812666]
	TIME [epoch: 4.17 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_25.pth
	Model improved!!!
EPOCH 26/500:
	Training over batches...
		[batch 4/4] avg loss: 1.5236392629822573		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5236392629822573 | validation: 1.3904829282110485]
	TIME [epoch: 4.18 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_26.pth
	Model improved!!!
EPOCH 27/500:
	Training over batches...
		[batch 4/4] avg loss: 1.2281904192210193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2281904192210193 | validation: 1.1168589748483353]
	TIME [epoch: 4.18 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_27.pth
	Model improved!!!
EPOCH 28/500:
	Training over batches...
		[batch 4/4] avg loss: 1.0392877974952708		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0392877974952708 | validation: 0.8884540355396866]
	TIME [epoch: 4.18 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_28.pth
	Model improved!!!
EPOCH 29/500:
	Training over batches...
		[batch 4/4] avg loss: 0.865228048970102		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.865228048970102 | validation: 0.7359613433735142]
	TIME [epoch: 4.18 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_29.pth
	Model improved!!!
EPOCH 30/500:
	Training over batches...
		[batch 4/4] avg loss: 0.7629077104188606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7629077104188606 | validation: 0.71558330412766]
	TIME [epoch: 4.18 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_30.pth
	Model improved!!!
EPOCH 31/500:
	Training over batches...
		[batch 4/4] avg loss: 0.6761468435597665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6761468435597665 | validation: 0.58632701242352]
	TIME [epoch: 4.22 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_31.pth
	Model improved!!!
EPOCH 32/500:
	Training over batches...
		[batch 4/4] avg loss: 0.6126737956221996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6126737956221996 | validation: 0.5522324850427967]
	TIME [epoch: 4.18 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_32.pth
	Model improved!!!
EPOCH 33/500:
	Training over batches...
		[batch 4/4] avg loss: 0.5617292616414915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5617292616414915 | validation: 0.4607718625992524]
	TIME [epoch: 4.18 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_33.pth
	Model improved!!!
EPOCH 34/500:
	Training over batches...
		[batch 4/4] avg loss: 0.4973757632808923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4973757632808923 | validation: 0.39627493843373385]
	TIME [epoch: 4.18 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_34.pth
	Model improved!!!
EPOCH 35/500:
	Training over batches...
		[batch 4/4] avg loss: 0.4586241039631269		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4586241039631269 | validation: 0.3829782663381748]
	TIME [epoch: 4.18 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_35.pth
	Model improved!!!
EPOCH 36/500:
	Training over batches...
		[batch 4/4] avg loss: 0.42724124459328006		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42724124459328006 | validation: 0.35303819478505516]
	TIME [epoch: 4.17 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_36.pth
	Model improved!!!
EPOCH 37/500:
	Training over batches...
		[batch 4/4] avg loss: 0.3947972644181571		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3947972644181571 | validation: 0.35723088900859973]
	TIME [epoch: 4.17 sec]
EPOCH 38/500:
	Training over batches...
		[batch 4/4] avg loss: 0.4171333106215163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4171333106215163 | validation: 0.36068689903569934]
	TIME [epoch: 4.16 sec]
EPOCH 39/500:
	Training over batches...
		[batch 4/4] avg loss: 0.3735552219522966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3735552219522966 | validation: 0.324445612318811]
	TIME [epoch: 4.16 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_39.pth
	Model improved!!!
EPOCH 40/500:
	Training over batches...
		[batch 4/4] avg loss: 0.34884148174787044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34884148174787044 | validation: 0.296227197291504]
	TIME [epoch: 4.2 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_40.pth
	Model improved!!!
EPOCH 41/500:
	Training over batches...
		[batch 4/4] avg loss: 0.3391567624471237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3391567624471237 | validation: 0.304457693403979]
	TIME [epoch: 4.19 sec]
EPOCH 42/500:
	Training over batches...
		[batch 4/4] avg loss: 0.30740372953445694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30740372953445694 | validation: 0.2394922912542008]
	TIME [epoch: 4.16 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_42.pth
	Model improved!!!
EPOCH 43/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2793631198867689		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2793631198867689 | validation: 0.23715788259244297]
	TIME [epoch: 4.18 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_43.pth
	Model improved!!!
EPOCH 44/500:
	Training over batches...
		[batch 4/4] avg loss: 0.26621563056945297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26621563056945297 | validation: 0.20900279561259966]
	TIME [epoch: 4.19 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_44.pth
	Model improved!!!
EPOCH 45/500:
	Training over batches...
		[batch 4/4] avg loss: 0.25063270703495494		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25063270703495494 | validation: 0.23059633736660504]
	TIME [epoch: 4.17 sec]
EPOCH 46/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2650068106859203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2650068106859203 | validation: 0.20376281047798264]
	TIME [epoch: 4.17 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_46.pth
	Model improved!!!
EPOCH 47/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2405681949021868		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2405681949021868 | validation: 0.19237033865294834]
	TIME [epoch: 4.17 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_47.pth
	Model improved!!!
EPOCH 48/500:
	Training over batches...
		[batch 4/4] avg loss: 0.22617444011085236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22617444011085236 | validation: 0.19618917230427224]
	TIME [epoch: 4.17 sec]
EPOCH 49/500:
	Training over batches...
		[batch 4/4] avg loss: 0.21782707226377657		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21782707226377657 | validation: 0.17908655476445356]
	TIME [epoch: 4.19 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_49.pth
	Model improved!!!
EPOCH 50/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1926873657090352		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1926873657090352 | validation: 0.16632188574115112]
	TIME [epoch: 4.19 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_50.pth
	Model improved!!!
EPOCH 51/500:
	Training over batches...
		[batch 4/4] avg loss: 0.09949571267164246		[learning rate: 0.0098855]
	Learning Rate: 0.00988553
	LOSS [training: 0.09949571267164246 | validation: 0.07377927371392554]
	TIME [epoch: 103 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_51.pth
	Model improved!!!
EPOCH 52/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08438970923927482		[learning rate: 0.0097349]
	Learning Rate: 0.00973494
	LOSS [training: 0.08438970923927482 | validation: 0.062000096324602835]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_52.pth
	Model improved!!!
EPOCH 53/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06794752106585457		[learning rate: 0.0095866]
	Learning Rate: 0.00958665
	LOSS [training: 0.06794752106585457 | validation: 0.03889429529184869]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_53.pth
	Model improved!!!
EPOCH 54/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04579710133953896		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.04579710133953896 | validation: 0.029635544825880503]
	TIME [epoch: 8.15 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_54.pth
	Model improved!!!
EPOCH 55/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06165800868029441		[learning rate: 0.0092968]
	Learning Rate: 0.0092968
	LOSS [training: 0.06165800868029441 | validation: 0.06015229817153059]
	TIME [epoch: 8.15 sec]
EPOCH 56/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07486047399562773		[learning rate: 0.0091552]
	Learning Rate: 0.00915517
	LOSS [training: 0.07486047399562773 | validation: 0.03237000462738693]
	TIME [epoch: 8.15 sec]
EPOCH 57/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04780134612508696		[learning rate: 0.0090157]
	Learning Rate: 0.00901571
	LOSS [training: 0.04780134612508696 | validation: 0.023055478966094344]
	TIME [epoch: 8.16 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_57.pth
	Model improved!!!
EPOCH 58/500:
	Training over batches...
		[batch 4/4] avg loss: 0.058945253676338724		[learning rate: 0.0088784]
	Learning Rate: 0.00887837
	LOSS [training: 0.058945253676338724 | validation: 0.030714934422426607]
	TIME [epoch: 8.19 sec]
EPOCH 59/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04670158266053712		[learning rate: 0.0087431]
	Learning Rate: 0.00874312
	LOSS [training: 0.04670158266053712 | validation: 0.027725757155001807]
	TIME [epoch: 8.15 sec]
EPOCH 60/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04685759374850225		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 0.04685759374850225 | validation: 0.03632623173805924]
	TIME [epoch: 8.15 sec]
EPOCH 61/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0575028115653886		[learning rate: 0.0084788]
	Learning Rate: 0.00847878
	LOSS [training: 0.0575028115653886 | validation: 0.04395584243686484]
	TIME [epoch: 8.14 sec]
EPOCH 62/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06660449989065426		[learning rate: 0.0083496]
	Learning Rate: 0.00834962
	LOSS [training: 0.06660449989065426 | validation: 0.04509306024611286]
	TIME [epoch: 8.14 sec]
EPOCH 63/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0502666543617754		[learning rate: 0.0082224]
	Learning Rate: 0.00822243
	LOSS [training: 0.0502666543617754 | validation: 0.039350767807311775]
	TIME [epoch: 8.15 sec]
EPOCH 64/500:
	Training over batches...
		[batch 4/4] avg loss: 0.044925660185875654		[learning rate: 0.0080972]
	Learning Rate: 0.00809717
	LOSS [training: 0.044925660185875654 | validation: 0.02522009434430161]
	TIME [epoch: 8.19 sec]
EPOCH 65/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06667236953019762		[learning rate: 0.0079738]
	Learning Rate: 0.00797382
	LOSS [training: 0.06667236953019762 | validation: 0.10393812502948978]
	TIME [epoch: 8.14 sec]
EPOCH 66/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15691194283861856		[learning rate: 0.0078524]
	Learning Rate: 0.00785236
	LOSS [training: 0.15691194283861856 | validation: 0.09830754181529242]
	TIME [epoch: 8.14 sec]
EPOCH 67/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14260663757958136		[learning rate: 0.0077327]
	Learning Rate: 0.00773274
	LOSS [training: 0.14260663757958136 | validation: 0.0817447937661935]
	TIME [epoch: 8.14 sec]
EPOCH 68/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13811066679627645		[learning rate: 0.0076149]
	Learning Rate: 0.00761494
	LOSS [training: 0.13811066679627645 | validation: 0.11456880285392285]
	TIME [epoch: 8.15 sec]
EPOCH 69/500:
	Training over batches...
		[batch 4/4] avg loss: 0.11406291380064452		[learning rate: 0.0074989]
	Learning Rate: 0.00749894
	LOSS [training: 0.11406291380064452 | validation: 0.055946303103632064]
	TIME [epoch: 8.18 sec]
EPOCH 70/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04114119971228691		[learning rate: 0.0073847]
	Learning Rate: 0.00738471
	LOSS [training: 0.04114119971228691 | validation: 0.0016251197979565354]
	TIME [epoch: 8.16 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_70.pth
	Model improved!!!
EPOCH 71/500:
	Training over batches...
		[batch 4/4] avg loss: 0.028081345531547747		[learning rate: 0.0072722]
	Learning Rate: 0.00727221
	LOSS [training: 0.028081345531547747 | validation: 0.01611233254938179]
	TIME [epoch: 8.14 sec]
EPOCH 72/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023024956513597566		[learning rate: 0.0071614]
	Learning Rate: 0.00716143
	LOSS [training: 0.023024956513597566 | validation: -0.002894215295334396]
	TIME [epoch: 8.13 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_72.pth
	Model improved!!!
EPOCH 73/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006405528054829761		[learning rate: 0.0070523]
	Learning Rate: 0.00705234
	LOSS [training: 0.006405528054829761 | validation: -0.004307128501847416]
	TIME [epoch: 8.13 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_73.pth
	Model improved!!!
EPOCH 74/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006373580761847156		[learning rate: 0.0069449]
	Learning Rate: 0.00694491
	LOSS [training: 0.006373580761847156 | validation: 0.004487361951641036]
	TIME [epoch: 8.2 sec]
EPOCH 75/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020760554163987102		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.020760554163987102 | validation: 0.018825810607103213]
	TIME [epoch: 8.18 sec]
EPOCH 76/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03805618648435783		[learning rate: 0.0067349]
	Learning Rate: 0.00673493
	LOSS [training: 0.03805618648435783 | validation: 0.05873786377223547]
	TIME [epoch: 8.15 sec]
EPOCH 77/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05896335447762763		[learning rate: 0.0066323]
	Learning Rate: 0.00663234
	LOSS [training: 0.05896335447762763 | validation: 0.04034835941585645]
	TIME [epoch: 8.18 sec]
EPOCH 78/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029872375052762943		[learning rate: 0.0065313]
	Learning Rate: 0.00653131
	LOSS [training: 0.029872375052762943 | validation: 0.004008980387344064]
	TIME [epoch: 8.15 sec]
EPOCH 79/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006535284979124132		[learning rate: 0.0064318]
	Learning Rate: 0.00643181
	LOSS [training: 0.006535284979124132 | validation: 0.013410548524571346]
	TIME [epoch: 8.18 sec]
EPOCH 80/500:
	Training over batches...
		[batch 4/4] avg loss: 0.017832195821150136		[learning rate: 0.0063338]
	Learning Rate: 0.00633383
	LOSS [training: 0.017832195821150136 | validation: 0.028435615029942254]
	TIME [epoch: 8.18 sec]
EPOCH 81/500:
	Training over batches...
		[batch 4/4] avg loss: 0.028967555429211103		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.028967555429211103 | validation: 0.019521057149366916]
	TIME [epoch: 8.15 sec]
EPOCH 82/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029185044877349513		[learning rate: 0.0061423]
	Learning Rate: 0.00614233
	LOSS [training: 0.029185044877349513 | validation: 0.013548116412613158]
	TIME [epoch: 8.15 sec]
EPOCH 83/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02639891066657741		[learning rate: 0.0060488]
	Learning Rate: 0.00604876
	LOSS [training: 0.02639891066657741 | validation: 0.01408731688091]
	TIME [epoch: 8.15 sec]
EPOCH 84/500:
	Training over batches...
		[batch 4/4] avg loss: 0.005271065123853916		[learning rate: 0.0059566]
	Learning Rate: 0.00595662
	LOSS [training: 0.005271065123853916 | validation: 0.0033114600562036763]
	TIME [epoch: 8.16 sec]
EPOCH 85/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008108268941781464		[learning rate: 0.0058659]
	Learning Rate: 0.00586588
	LOSS [training: 0.008108268941781464 | validation: 0.02561889514166326]
	TIME [epoch: 8.2 sec]
EPOCH 86/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04331969835159591		[learning rate: 0.0057765]
	Learning Rate: 0.00577653
	LOSS [training: 0.04331969835159591 | validation: 0.04454621909128737]
	TIME [epoch: 8.16 sec]
EPOCH 87/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0722526926600933		[learning rate: 0.0056885]
	Learning Rate: 0.00568853
	LOSS [training: 0.0722526926600933 | validation: 0.04681981575532683]
	TIME [epoch: 8.15 sec]
EPOCH 88/500:
	Training over batches...
		[batch 4/4] avg loss: 0.044906048509975934		[learning rate: 0.0056019]
	Learning Rate: 0.00560187
	LOSS [training: 0.044906048509975934 | validation: 0.018527885251405737]
	TIME [epoch: 8.15 sec]
EPOCH 89/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008194437782638387		[learning rate: 0.0055165]
	Learning Rate: 0.00551654
	LOSS [training: 0.008194437782638387 | validation: -0.005548912630328963]
	TIME [epoch: 8.15 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_89.pth
	Model improved!!!
EPOCH 90/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0064876950863610675		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: -0.0064876950863610675 | validation: -0.01864386693451851]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_90.pth
	Model improved!!!
EPOCH 91/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00687959184047985		[learning rate: 0.0053497]
	Learning Rate: 0.00534975
	LOSS [training: -0.00687959184047985 | validation: -1.0688854186604278e-05]
	TIME [epoch: 8.19 sec]
EPOCH 92/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020463559562541884		[learning rate: 0.0052683]
	Learning Rate: 0.00526825
	LOSS [training: 0.020463559562541884 | validation: 0.01386668641396999]
	TIME [epoch: 8.16 sec]
EPOCH 93/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03067274784190885		[learning rate: 0.005188]
	Learning Rate: 0.005188
	LOSS [training: 0.03067274784190885 | validation: 0.014814379025773882]
	TIME [epoch: 8.17 sec]
EPOCH 94/500:
	Training over batches...
		[batch 4/4] avg loss: 0.022126333285234244		[learning rate: 0.005109]
	Learning Rate: 0.00510897
	LOSS [training: 0.022126333285234244 | validation: 0.017686486046913363]
	TIME [epoch: 8.16 sec]
EPOCH 95/500:
	Training over batches...
		[batch 4/4] avg loss: 0.015033141640749991		[learning rate: 0.0050311]
	Learning Rate: 0.00503114
	LOSS [training: 0.015033141640749991 | validation: 0.007274612244223557]
	TIME [epoch: 8.2 sec]
EPOCH 96/500:
	Training over batches...
		[batch 4/4] avg loss: 0.002019258225748078		[learning rate: 0.0049545]
	Learning Rate: 0.0049545
	LOSS [training: 0.002019258225748078 | validation: -0.00434734397033519]
	TIME [epoch: 8.19 sec]
EPOCH 97/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0038065950599563093		[learning rate: 0.004879]
	Learning Rate: 0.00487903
	LOSS [training: -0.0038065950599563093 | validation: -0.006720519626411474]
	TIME [epoch: 8.17 sec]
EPOCH 98/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002121218336852656		[learning rate: 0.0048047]
	Learning Rate: 0.0048047
	LOSS [training: -0.002121218336852656 | validation: -0.001813955769112143]
	TIME [epoch: 8.15 sec]
EPOCH 99/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0054752312197700265		[learning rate: 0.0047315]
	Learning Rate: 0.00473151
	LOSS [training: -0.0054752312197700265 | validation: -0.019467920456703428]
	TIME [epoch: 8.15 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_99.pth
	Model improved!!!
EPOCH 100/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010041653378535065		[learning rate: 0.0046594]
	Learning Rate: 0.00465944
	LOSS [training: -0.010041653378535065 | validation: -0.022843564688161497]
	TIME [epoch: 8.17 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_100.pth
	Model improved!!!
EPOCH 101/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006334764627703229		[learning rate: 0.0045885]
	Learning Rate: 0.00458846
	LOSS [training: -0.006334764627703229 | validation: -0.007848007909608004]
	TIME [epoch: 112 sec]
EPOCH 102/500:
	Training over batches...
		[batch 4/4] avg loss: -0.016061757592977528		[learning rate: 0.0045186]
	Learning Rate: 0.00451856
	LOSS [training: -0.016061757592977528 | validation: -0.014910693615184593]
	TIME [epoch: 18.8 sec]
EPOCH 103/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008601223468717384		[learning rate: 0.0044497]
	Learning Rate: 0.00444973
	LOSS [training: -0.008601223468717384 | validation: -0.01628386422792561]
	TIME [epoch: 18.6 sec]
EPOCH 104/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00898383618683263		[learning rate: 0.0043819]
	Learning Rate: 0.00438194
	LOSS [training: -0.00898383618683263 | validation: -0.011319114219915256]
	TIME [epoch: 18.5 sec]
EPOCH 105/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00818711280852182		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: -0.00818711280852182 | validation: -0.01754963613280654]
	TIME [epoch: 18.5 sec]
EPOCH 106/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00710847754360822		[learning rate: 0.0042495]
	Learning Rate: 0.00424946
	LOSS [training: -0.00710847754360822 | validation: -0.008650595402231454]
	TIME [epoch: 18.5 sec]
EPOCH 107/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0013281775996287696		[learning rate: 0.0041847]
	Learning Rate: 0.00418472
	LOSS [training: -0.0013281775996287696 | validation: -0.010484044384346622]
	TIME [epoch: 18.5 sec]
EPOCH 108/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008246265905632388		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: -0.008246265905632388 | validation: -0.007311251218208803]
	TIME [epoch: 18.5 sec]
EPOCH 109/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0010589464984290281		[learning rate: 0.0040582]
	Learning Rate: 0.0040582
	LOSS [training: -0.0010589464984290281 | validation: -0.007431434694912456]
	TIME [epoch: 18.5 sec]
EPOCH 110/500:
	Training over batches...
		[batch 4/4] avg loss: 0.003197220117757503		[learning rate: 0.0039964]
	Learning Rate: 0.00399638
	LOSS [training: 0.003197220117757503 | validation: -0.001264068558120484]
	TIME [epoch: 18.5 sec]
EPOCH 111/500:
	Training over batches...
		[batch 4/4] avg loss: 0.012745397165799598		[learning rate: 0.0039355]
	Learning Rate: 0.0039355
	LOSS [training: 0.012745397165799598 | validation: -0.01771989553112173]
	TIME [epoch: 18.5 sec]
EPOCH 112/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0005462600444910298		[learning rate: 0.0038755]
	Learning Rate: 0.00387555
	LOSS [training: 0.0005462600444910298 | validation: -0.002730230442792868]
	TIME [epoch: 18.5 sec]
EPOCH 113/500:
	Training over batches...
		[batch 4/4] avg loss: 0.004262406336986909		[learning rate: 0.0038165]
	Learning Rate: 0.00381651
	LOSS [training: 0.004262406336986909 | validation: 0.0035313343927902588]
	TIME [epoch: 18.5 sec]
EPOCH 114/500:
	Training over batches...
		[batch 4/4] avg loss: 0.001975232491677782		[learning rate: 0.0037584]
	Learning Rate: 0.00375837
	LOSS [training: 0.001975232491677782 | validation: -0.006472102792857953]
	TIME [epoch: 18.5 sec]
EPOCH 115/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001206263190023339		[learning rate: 0.0037011]
	Learning Rate: 0.00370112
	LOSS [training: -0.001206263190023339 | validation: -0.009481636666837153]
	TIME [epoch: 18.5 sec]
EPOCH 116/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0002976661072864068		[learning rate: 0.0036447]
	Learning Rate: 0.00364474
	LOSS [training: -0.0002976661072864068 | validation: -0.004707598707402583]
	TIME [epoch: 18.5 sec]
EPOCH 117/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00924478544862289		[learning rate: 0.0035892]
	Learning Rate: 0.00358922
	LOSS [training: 0.00924478544862289 | validation: 0.00018902306924694755]
	TIME [epoch: 18.6 sec]
EPOCH 118/500:
	Training over batches...
		[batch 4/4] avg loss: 0.011162600432279223		[learning rate: 0.0035345]
	Learning Rate: 0.00353454
	LOSS [training: 0.011162600432279223 | validation: 0.005351696522636895]
	TIME [epoch: 18.5 sec]
EPOCH 119/500:
	Training over batches...
		[batch 4/4] avg loss: 0.015593630252751355		[learning rate: 0.0034807]
	Learning Rate: 0.0034807
	LOSS [training: 0.015593630252751355 | validation: 0.009487931145160923]
	TIME [epoch: 18.6 sec]
EPOCH 120/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03208139357856858		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 0.03208139357856858 | validation: 0.03181006344762709]
	TIME [epoch: 18.6 sec]
EPOCH 121/500:
	Training over batches...
		[batch 4/4] avg loss: 0.039931628396287326		[learning rate: 0.0033755]
	Learning Rate: 0.00337546
	LOSS [training: 0.039931628396287326 | validation: 0.03877280086356277]
	TIME [epoch: 18.6 sec]
EPOCH 122/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0494924826992375		[learning rate: 0.003324]
	Learning Rate: 0.00332404
	LOSS [training: 0.0494924826992375 | validation: 0.04272521110227908]
	TIME [epoch: 18.6 sec]
EPOCH 123/500:
	Training over batches...
		[batch 4/4] avg loss: 0.053640763201169006		[learning rate: 0.0032734]
	Learning Rate: 0.00327341
	LOSS [training: 0.053640763201169006 | validation: 0.02870720684803613]
	TIME [epoch: 18.5 sec]
EPOCH 124/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03634582962939183		[learning rate: 0.0032235]
	Learning Rate: 0.00322354
	LOSS [training: 0.03634582962939183 | validation: 0.020704235245191147]
	TIME [epoch: 18.6 sec]
EPOCH 125/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025135162643715726		[learning rate: 0.0031744]
	Learning Rate: 0.00317444
	LOSS [training: 0.025135162643715726 | validation: 0.009330790876454805]
	TIME [epoch: 18.6 sec]
EPOCH 126/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0312410390406539		[learning rate: 0.0031261]
	Learning Rate: 0.00312608
	LOSS [training: 0.0312410390406539 | validation: 0.03290576758133275]
	TIME [epoch: 18.6 sec]
EPOCH 127/500:
	Training over batches...
		[batch 4/4] avg loss: 0.045621321409801005		[learning rate: 0.0030785]
	Learning Rate: 0.00307846
	LOSS [training: 0.045621321409801005 | validation: 0.039987128471654074]
	TIME [epoch: 18.6 sec]
EPOCH 128/500:
	Training over batches...
		[batch 4/4] avg loss: 0.051831882530839625		[learning rate: 0.0030316]
	Learning Rate: 0.00303156
	LOSS [training: 0.051831882530839625 | validation: 0.03072011847745841]
	TIME [epoch: 18.5 sec]
EPOCH 129/500:
	Training over batches...
		[batch 4/4] avg loss: 0.041917540538659204		[learning rate: 0.0029854]
	Learning Rate: 0.00298538
	LOSS [training: 0.041917540538659204 | validation: 0.04422968018731168]
	TIME [epoch: 18.6 sec]
EPOCH 130/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06198219492176239		[learning rate: 0.0029399]
	Learning Rate: 0.0029399
	LOSS [training: 0.06198219492176239 | validation: 0.06839460485773285]
	TIME [epoch: 18.5 sec]
EPOCH 131/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07825186249809776		[learning rate: 0.0028951]
	Learning Rate: 0.00289512
	LOSS [training: 0.07825186249809776 | validation: 0.08409814617017669]
	TIME [epoch: 18.6 sec]
EPOCH 132/500:
	Training over batches...
		[batch 4/4] avg loss: 0.086058785366089		[learning rate: 0.002851]
	Learning Rate: 0.00285102
	LOSS [training: 0.086058785366089 | validation: 0.05990141561879131]
	TIME [epoch: 18.6 sec]
EPOCH 133/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07572253332614805		[learning rate: 0.0028076]
	Learning Rate: 0.00280759
	LOSS [training: 0.07572253332614805 | validation: 0.04812146300925584]
	TIME [epoch: 18.5 sec]
EPOCH 134/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06889917539623701		[learning rate: 0.0027648]
	Learning Rate: 0.00276482
	LOSS [training: 0.06889917539623701 | validation: 0.06868497086664914]
	TIME [epoch: 18.6 sec]
EPOCH 135/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08377044213153947		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.08377044213153947 | validation: 0.06997778853175088]
	TIME [epoch: 18.5 sec]
EPOCH 136/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06985782381914117		[learning rate: 0.0026812]
	Learning Rate: 0.00268123
	LOSS [training: 0.06985782381914117 | validation: 0.05328234612593316]
	TIME [epoch: 18.6 sec]
EPOCH 137/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06384901633795091		[learning rate: 0.0026404]
	Learning Rate: 0.00264038
	LOSS [training: 0.06384901633795091 | validation: 0.05739588832483605]
	TIME [epoch: 18.6 sec]
EPOCH 138/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08271626707043425		[learning rate: 0.0026002]
	Learning Rate: 0.00260016
	LOSS [training: 0.08271626707043425 | validation: 0.06578166636650348]
	TIME [epoch: 18.5 sec]
EPOCH 139/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07818785030573246		[learning rate: 0.0025606]
	Learning Rate: 0.00256055
	LOSS [training: 0.07818785030573246 | validation: 0.08312926024976511]
	TIME [epoch: 18.6 sec]
EPOCH 140/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08677947480129036		[learning rate: 0.0025215]
	Learning Rate: 0.00252154
	LOSS [training: 0.08677947480129036 | validation: 0.06818376713809021]
	TIME [epoch: 18.5 sec]
EPOCH 141/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0851856722910674		[learning rate: 0.0024831]
	Learning Rate: 0.00248313
	LOSS [training: 0.0851856722910674 | validation: 0.07454038200836738]
	TIME [epoch: 18.6 sec]
EPOCH 142/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08768809505038236		[learning rate: 0.0024453]
	Learning Rate: 0.00244531
	LOSS [training: 0.08768809505038236 | validation: 0.0628516226882021]
	TIME [epoch: 18.5 sec]
EPOCH 143/500:
	Training over batches...
		[batch 4/4] avg loss: 0.077664973874187		[learning rate: 0.0024081]
	Learning Rate: 0.00240806
	LOSS [training: 0.077664973874187 | validation: 0.04920875816832978]
	TIME [epoch: 18.5 sec]
EPOCH 144/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05916887473437587		[learning rate: 0.0023714]
	Learning Rate: 0.00237137
	LOSS [training: 0.05916887473437587 | validation: 0.03453398920172737]
	TIME [epoch: 18.6 sec]
EPOCH 145/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06298648941259768		[learning rate: 0.0023352]
	Learning Rate: 0.00233525
	LOSS [training: 0.06298648941259768 | validation: 0.041111002744889276]
	TIME [epoch: 18.5 sec]
EPOCH 146/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0664058347095989		[learning rate: 0.0022997]
	Learning Rate: 0.00229968
	LOSS [training: 0.0664058347095989 | validation: 0.03986412300962551]
	TIME [epoch: 18.6 sec]
EPOCH 147/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06327813460193611		[learning rate: 0.0022646]
	Learning Rate: 0.00226464
	LOSS [training: 0.06327813460193611 | validation: 0.06076504348022822]
	TIME [epoch: 18.5 sec]
EPOCH 148/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06142310825630909		[learning rate: 0.0022301]
	Learning Rate: 0.00223015
	LOSS [training: 0.06142310825630909 | validation: 0.052147710445107326]
	TIME [epoch: 18.6 sec]
EPOCH 149/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06263011619043146		[learning rate: 0.0021962]
	Learning Rate: 0.00219617
	LOSS [training: 0.06263011619043146 | validation: 0.038563364448759865]
	TIME [epoch: 18.6 sec]
EPOCH 150/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04972282713470175		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: 0.04972282713470175 | validation: 0.033972392141573736]
	TIME [epoch: 18.5 sec]
EPOCH 151/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0479186577702872		[learning rate: 0.0021298]
	Learning Rate: 0.00212977
	LOSS [training: 0.0479186577702872 | validation: 0.043138628753955056]
	TIME [epoch: 18.6 sec]
EPOCH 152/500:
	Training over batches...
		[batch 4/4] avg loss: 0.056238802624526574		[learning rate: 0.0020973]
	Learning Rate: 0.00209733
	LOSS [training: 0.056238802624526574 | validation: 0.04979325740417656]
	TIME [epoch: 18.5 sec]
EPOCH 153/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05837981915660699		[learning rate: 0.0020654]
	Learning Rate: 0.00206538
	LOSS [training: 0.05837981915660699 | validation: 0.042187756404464746]
	TIME [epoch: 18.6 sec]
EPOCH 154/500:
	Training over batches...
		[batch 4/4] avg loss: 0.057119312038953166		[learning rate: 0.0020339]
	Learning Rate: 0.00203392
	LOSS [training: 0.057119312038953166 | validation: 0.03033450860928312]
	TIME [epoch: 18.6 sec]
EPOCH 155/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04381367179980222		[learning rate: 0.0020029]
	Learning Rate: 0.00200293
	LOSS [training: 0.04381367179980222 | validation: 0.0430668606324207]
	TIME [epoch: 18.6 sec]
EPOCH 156/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04016603669594495		[learning rate: 0.0019724]
	Learning Rate: 0.00197242
	LOSS [training: 0.04016603669594495 | validation: 0.00961880647613934]
	TIME [epoch: 18.6 sec]
EPOCH 157/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026957799436654523		[learning rate: 0.0019424]
	Learning Rate: 0.00194238
	LOSS [training: 0.026957799436654523 | validation: 0.0016010371828829861]
	TIME [epoch: 18.6 sec]
EPOCH 158/500:
	Training over batches...
		[batch 4/4] avg loss: 0.014404719740305223		[learning rate: 0.0019128]
	Learning Rate: 0.00191279
	LOSS [training: 0.014404719740305223 | validation: 0.013352607925525267]
	TIME [epoch: 18.6 sec]
EPOCH 159/500:
	Training over batches...
		[batch 4/4] avg loss: 0.017385686140276902		[learning rate: 0.0018836]
	Learning Rate: 0.00188365
	LOSS [training: 0.017385686140276902 | validation: 0.008925199968784773]
	TIME [epoch: 18.6 sec]
EPOCH 160/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027035067420949778		[learning rate: 0.001855]
	Learning Rate: 0.00185495
	LOSS [training: 0.027035067420949778 | validation: 0.010175851267730643]
	TIME [epoch: 18.5 sec]
EPOCH 161/500:
	Training over batches...
		[batch 4/4] avg loss: 0.012032315234966309		[learning rate: 0.0018267]
	Learning Rate: 0.0018267
	LOSS [training: 0.012032315234966309 | validation: 0.0017164354737510905]
	TIME [epoch: 18.6 sec]
EPOCH 162/500:
	Training over batches...
		[batch 4/4] avg loss: 0.014231766848318906		[learning rate: 0.0017989]
	Learning Rate: 0.00179887
	LOSS [training: 0.014231766848318906 | validation: 0.000335244932927292]
	TIME [epoch: 18.5 sec]
EPOCH 163/500:
	Training over batches...
		[batch 4/4] avg loss: 0.010650472744719629		[learning rate: 0.0017715]
	Learning Rate: 0.00177147
	LOSS [training: 0.010650472744719629 | validation: -0.003089932309095527]
	TIME [epoch: 18.5 sec]
EPOCH 164/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008474977953025951		[learning rate: 0.0017445]
	Learning Rate: 0.00174448
	LOSS [training: 0.008474977953025951 | validation: -0.004764392899840159]
	TIME [epoch: 18.5 sec]
EPOCH 165/500:
	Training over batches...
		[batch 4/4] avg loss: 0.010892931574366164		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: 0.010892931574366164 | validation: -0.01298405377306423]
	TIME [epoch: 18.5 sec]
EPOCH 166/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0038814040756129675		[learning rate: 0.0016917]
	Learning Rate: 0.00169174
	LOSS [training: 0.0038814040756129675 | validation: -0.007881257361162212]
	TIME [epoch: 18.5 sec]
EPOCH 167/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0020173270976342594		[learning rate: 0.001666]
	Learning Rate: 0.00166597
	LOSS [training: 0.0020173270976342594 | validation: -0.008194080953114094]
	TIME [epoch: 18.5 sec]
EPOCH 168/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007617181344152043		[learning rate: 0.0016406]
	Learning Rate: 0.00164059
	LOSS [training: 0.007617181344152043 | validation: -0.006566074249330777]
	TIME [epoch: 18.6 sec]
EPOCH 169/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008716367919039063		[learning rate: 0.0016156]
	Learning Rate: 0.0016156
	LOSS [training: 0.008716367919039063 | validation: 0.0012303407148619098]
	TIME [epoch: 18.5 sec]
EPOCH 170/500:
	Training over batches...
		[batch 4/4] avg loss: 0.017582606192924437		[learning rate: 0.001591]
	Learning Rate: 0.00159099
	LOSS [training: 0.017582606192924437 | validation: 0.004840763263074798]
	TIME [epoch: 18.5 sec]
EPOCH 171/500:
	Training over batches...
		[batch 4/4] avg loss: 0.014361287105786574		[learning rate: 0.0015668]
	Learning Rate: 0.00156675
	LOSS [training: 0.014361287105786574 | validation: 0.0029457827246543835]
	TIME [epoch: 18.5 sec]
EPOCH 172/500:
	Training over batches...
		[batch 4/4] avg loss: 0.014698048717907343		[learning rate: 0.0015429]
	Learning Rate: 0.00154288
	LOSS [training: 0.014698048717907343 | validation: 0.0058888938106784455]
	TIME [epoch: 18.5 sec]
EPOCH 173/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01307174163705649		[learning rate: 0.0015194]
	Learning Rate: 0.00151938
	LOSS [training: 0.01307174163705649 | validation: -0.0036303113855340086]
	TIME [epoch: 18.5 sec]
EPOCH 174/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01350363651638371		[learning rate: 0.0014962]
	Learning Rate: 0.00149624
	LOSS [training: 0.01350363651638371 | validation: 0.011586902985676068]
	TIME [epoch: 18.5 sec]
EPOCH 175/500:
	Training over batches...
		[batch 4/4] avg loss: 0.012613348390825448		[learning rate: 0.0014734]
	Learning Rate: 0.00147344
	LOSS [training: 0.012613348390825448 | validation: 0.0023548498088729252]
	TIME [epoch: 18.5 sec]
EPOCH 176/500:
	Training over batches...
		[batch 4/4] avg loss: 0.012570962521867235		[learning rate: 0.001451]
	Learning Rate: 0.001451
	LOSS [training: 0.012570962521867235 | validation: 0.021071399390374772]
	TIME [epoch: 18.5 sec]
EPOCH 177/500:
	Training over batches...
		[batch 4/4] avg loss: 0.010857052471596292		[learning rate: 0.0014289]
	Learning Rate: 0.00142889
	LOSS [training: 0.010857052471596292 | validation: 0.009590779376230494]
	TIME [epoch: 18.5 sec]
EPOCH 178/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009215426119828273		[learning rate: 0.0014071]
	Learning Rate: 0.00140713
	LOSS [training: 0.009215426119828273 | validation: 0.004426683322603795]
	TIME [epoch: 18.6 sec]
EPOCH 179/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0103427726881442		[learning rate: 0.0013857]
	Learning Rate: 0.00138569
	LOSS [training: 0.0103427726881442 | validation: 0.003159424384721088]
	TIME [epoch: 18.5 sec]
EPOCH 180/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009851796686447714		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: 0.009851796686447714 | validation: -0.007109904944744817]
	TIME [epoch: 18.5 sec]
EPOCH 181/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008139677396674865		[learning rate: 0.0013438]
	Learning Rate: 0.0013438
	LOSS [training: 0.008139677396674865 | validation: -0.0009927622881563177]
	TIME [epoch: 18.5 sec]
EPOCH 182/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01397053352596374		[learning rate: 0.0013233]
	Learning Rate: 0.00132333
	LOSS [training: 0.01397053352596374 | validation: 0.006744071554511142]
	TIME [epoch: 18.5 sec]
EPOCH 183/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01840098265574015		[learning rate: 0.0013032]
	Learning Rate: 0.00130317
	LOSS [training: 0.01840098265574015 | validation: 0.004643441730959698]
	TIME [epoch: 18.6 sec]
EPOCH 184/500:
	Training over batches...
		[batch 4/4] avg loss: 0.019202290976781375		[learning rate: 0.0012833]
	Learning Rate: 0.00128332
	LOSS [training: 0.019202290976781375 | validation: 0.011080178639760175]
	TIME [epoch: 18.5 sec]
EPOCH 185/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020238786268393892		[learning rate: 0.0012638]
	Learning Rate: 0.00126377
	LOSS [training: 0.020238786268393892 | validation: 0.0044690793233104955]
	TIME [epoch: 18.5 sec]
EPOCH 186/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029399151715306594		[learning rate: 0.0012445]
	Learning Rate: 0.00124451
	LOSS [training: 0.029399151715306594 | validation: -8.316175629159402e-05]
	TIME [epoch: 18.5 sec]
EPOCH 187/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02460833654740886		[learning rate: 0.0012256]
	Learning Rate: 0.00122556
	LOSS [training: 0.02460833654740886 | validation: 0.01677596340363687]
	TIME [epoch: 18.5 sec]
EPOCH 188/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025110223746276056		[learning rate: 0.0012069]
	Learning Rate: 0.00120689
	LOSS [training: 0.025110223746276056 | validation: 0.02742586196258266]
	TIME [epoch: 18.6 sec]
EPOCH 189/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02414378544781294		[learning rate: 0.0011885]
	Learning Rate: 0.0011885
	LOSS [training: 0.02414378544781294 | validation: 0.013656363404281786]
	TIME [epoch: 18.5 sec]
EPOCH 190/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01985436780567544		[learning rate: 0.0011704]
	Learning Rate: 0.0011704
	LOSS [training: 0.01985436780567544 | validation: 0.006753775441931563]
	TIME [epoch: 18.5 sec]
EPOCH 191/500:
	Training over batches...
		[batch 4/4] avg loss: 0.013860155923810333		[learning rate: 0.0011526]
	Learning Rate: 0.00115257
	LOSS [training: 0.013860155923810333 | validation: 0.0012337163659636315]
	TIME [epoch: 18.5 sec]
EPOCH 192/500:
	Training over batches...
		[batch 4/4] avg loss: 0.018683702036756063		[learning rate: 0.001135]
	Learning Rate: 0.00113501
	LOSS [training: 0.018683702036756063 | validation: 0.011043652803792625]
	TIME [epoch: 18.5 sec]
EPOCH 193/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02048988659909887		[learning rate: 0.0011177]
	Learning Rate: 0.00111772
	LOSS [training: 0.02048988659909887 | validation: 0.003376722129741229]
	TIME [epoch: 18.6 sec]
EPOCH 194/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020126781118264804		[learning rate: 0.0011007]
	Learning Rate: 0.00110069
	LOSS [training: 0.020126781118264804 | validation: 0.004918744807258927]
	TIME [epoch: 18.5 sec]
EPOCH 195/500:
	Training over batches...
		[batch 4/4] avg loss: 0.028858559287714323		[learning rate: 0.0010839]
	Learning Rate: 0.00108393
	LOSS [training: 0.028858559287714323 | validation: 0.011908871965152274]
	TIME [epoch: 18.6 sec]
EPOCH 196/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03228340637430677		[learning rate: 0.0010674]
	Learning Rate: 0.00106741
	LOSS [training: 0.03228340637430677 | validation: 0.017280796743750108]
	TIME [epoch: 18.5 sec]
EPOCH 197/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027363340671004696		[learning rate: 0.0010512]
	Learning Rate: 0.00105115
	LOSS [training: 0.027363340671004696 | validation: 0.01782917047333795]
	TIME [epoch: 18.5 sec]
EPOCH 198/500:
	Training over batches...
		[batch 4/4] avg loss: 0.019965616569012114		[learning rate: 0.0010351]
	Learning Rate: 0.00103514
	LOSS [training: 0.019965616569012114 | validation: 0.009506800471068225]
	TIME [epoch: 18.6 sec]
EPOCH 199/500:
	Training over batches...
		[batch 4/4] avg loss: 0.022867442904981407		[learning rate: 0.0010194]
	Learning Rate: 0.00101937
	LOSS [training: 0.022867442904981407 | validation: 0.013997066156998883]
	TIME [epoch: 18.5 sec]
EPOCH 200/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02127957557864932		[learning rate: 0.0010038]
	Learning Rate: 0.00100384
	LOSS [training: 0.02127957557864932 | validation: 0.012216737409481693]
	TIME [epoch: 18.5 sec]
EPOCH 201/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02077972610919586		[learning rate: 0.00098855]
	Learning Rate: 0.000988553
	LOSS [training: 0.02077972610919586 | validation: 0.014858731473110278]
	TIME [epoch: 18.5 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20240705_010809/states/model_algphi2_1a_v_kl_201.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 2806.861 seconds.
