Args:
Namespace(name='model_phi1_1a_v_mmd1_fix_noise_small', outdir='out/model_training/model_phi1_1a_v_mmd1_fix_noise_small', training_data='data/training_data/data_phi1_1a/training', validation_data='data/training_data/data_phi1_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, patience=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 958726166

Training model...

Saving initial model state to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.4747430496193745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.4747430496193745 | validation: 6.824707989358522]
	TIME [epoch: 168 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.903836708828878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.903836708828878 | validation: 6.2272598079216515]
	TIME [epoch: 7.78 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.515182314474734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.515182314474734 | validation: 6.122715141135693]
	TIME [epoch: 7.65 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.484125093446044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.484125093446044 | validation: 6.0935326066599975]
	TIME [epoch: 7.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.363356693352726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.363356693352726 | validation: 6.111749084000914]
	TIME [epoch: 7.63 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.276746219088961		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.276746219088961 | validation: 6.047926046445303]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.224791323450024		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.224791323450024 | validation: 5.931044166056514]
	TIME [epoch: 7.66 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.156030528189703		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.156030528189703 | validation: 5.986123817847154]
	TIME [epoch: 7.64 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.074438484010062		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.074438484010062 | validation: 5.797478566173533]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.995676257496196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.995676257496196 | validation: 5.71709444288037]
	TIME [epoch: 7.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.912324593817619		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.912324593817619 | validation: 5.63858397984394]
	TIME [epoch: 7.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.75902367695912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.75902367695912 | validation: 5.70994556143965]
	TIME [epoch: 7.66 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.649481197230558		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.649481197230558 | validation: 4.7472447126991]
	TIME [epoch: 7.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8614988182064374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8614988182064374 | validation: 4.1051189023504975]
	TIME [epoch: 7.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.793065319071082		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.793065319071082 | validation: 4.562326959819344]
	TIME [epoch: 7.59 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2710371588567653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2710371588567653 | validation: 3.8178919362343837]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0234266378559984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0234266378559984 | validation: 3.89017953073268]
	TIME [epoch: 7.67 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9958767324272286		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9958767324272286 | validation: 3.93537959179369]
	TIME [epoch: 7.62 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.970528223779625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.970528223779625 | validation: 3.8028999514400557]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.934151988797761		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.934151988797761 | validation: 4.164894336809425]
	TIME [epoch: 7.61 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.067317094270177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.067317094270177 | validation: 3.595306218434339]
	TIME [epoch: 7.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8495661198060693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8495661198060693 | validation: 3.4958478171551306]
	TIME [epoch: 7.66 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8730197046689847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8730197046689847 | validation: 3.754382655647195]
	TIME [epoch: 7.61 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.843373775331879		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.843373775331879 | validation: 3.626112087747206]
	TIME [epoch: 7.61 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.776459803870699		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.776459803870699 | validation: 3.451156609766522]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8841766252407766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8841766252407766 | validation: 3.6742597770707706]
	TIME [epoch: 7.63 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.783633708251934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.783633708251934 | validation: 3.363527228448473]
	TIME [epoch: 7.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6549671286812035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6549671286812035 | validation: 3.360618104924807]
	TIME [epoch: 7.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4792102713464703		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4792102713464703 | validation: 3.2215425724563005]
	TIME [epoch: 7.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5761304606171		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5761304606171 | validation: 3.738088158901234]
	TIME [epoch: 7.61 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.461341130008358		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.461341130008358 | validation: 3.081326378211795]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9530173887877122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9530173887877122 | validation: 4.410822578830954]
	TIME [epoch: 7.64 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8453546937657497		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8453546937657497 | validation: 2.767387754057996]
	TIME [epoch: 7.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1745230603814125		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1745230603814125 | validation: 2.5919779730885963]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.853588956813165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.853588956813165 | validation: 4.041295427027004]
	TIME [epoch: 7.63 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.467140795581439		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.467140795581439 | validation: 2.8571499318521423]
	TIME [epoch: 7.67 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7725666580685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7725666580685 | validation: 2.580444402913037]
	TIME [epoch: 7.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6414130689795972		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6414130689795972 | validation: 2.481252768287435]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6576793510534173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6576793510534173 | validation: 2.507488334573009]
	TIME [epoch: 7.61 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.678850172643993		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.678850172643993 | validation: 2.46636317068139]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6046139482748019		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6046139482748019 | validation: 2.6428492152370904]
	TIME [epoch: 7.65 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.764552221547517		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.764552221547517 | validation: 2.3929728305193363]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7245629221229002		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7245629221229002 | validation: 2.384613015381162]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.724024968355409		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.724024968355409 | validation: 4.716411977167056]
	TIME [epoch: 7.61 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3632364554393055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3632364554393055 | validation: 3.236145137413239]
	TIME [epoch: 7.61 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9590365501965614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9590365501965614 | validation: 2.301649317761094]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6064118759981059		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6064118759981059 | validation: 3.381191967782356]
	TIME [epoch: 7.6 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.350422932395195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.350422932395195 | validation: 2.846959016223259]
	TIME [epoch: 7.6 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6594852113952738		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6594852113952738 | validation: 2.3837607272262726]
	TIME [epoch: 7.59 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5721719188106238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5721719188106238 | validation: 2.3399967695316297]
	TIME [epoch: 7.6 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4817253414991434		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 1.4817253414991434 | validation: 2.316920988922913]
	TIME [epoch: 7.97 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5292292728091554		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 1.5292292728091554 | validation: 2.409355008573943]
	TIME [epoch: 7.65 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6346141410966375		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 1.6346141410966375 | validation: 2.558881267382234]
	TIME [epoch: 7.64 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6399802494064835		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 1.6399802494064835 | validation: 2.06378881713746]
	TIME [epoch: 7.65 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0581767182551727		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 3.0581767182551727 | validation: 3.0028451588857092]
	TIME [epoch: 7.65 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.470256399165377		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 2.470256399165377 | validation: 2.3947490181220727]
	TIME [epoch: 7.65 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6488113326916474		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 1.6488113326916474 | validation: 2.3556305379763307]
	TIME [epoch: 7.62 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6252546682688387		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 1.6252546682688387 | validation: 2.2941834105132886]
	TIME [epoch: 7.62 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5717050785070685		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 1.5717050785070685 | validation: 2.306680382297132]
	TIME [epoch: 7.62 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5741834803749075		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 1.5741834803749075 | validation: 2.3501667457704496]
	TIME [epoch: 7.63 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5795589685858464		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 1.5795589685858464 | validation: 2.2665577675146125]
	TIME [epoch: 7.64 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.530428570619556		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 1.530428570619556 | validation: 2.22659089166622]
	TIME [epoch: 7.6 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8428882338527601		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 1.8428882338527601 | validation: 2.551207204699123]
	TIME [epoch: 7.6 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5723946810415235		[learning rate: 0.0095246]
nan encountered in epoch 63 (validation loss).
	Learning Rate: 0.00952459
	LOSS [training: 1.5723946810415235 | validation: nan]
	TIME [epoch: 7.61 sec]
EPOCH 65/2000:
	Training over batches...
	Encountered nan in loss. Reverting update and performing model surgery (1/4).
		New model confinement_factor: 0.010000000000000002
		[batch 4/4] avg loss: 4.800429298993281		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 4.800429298993281 | validation: 4.202002349541557]
	TIME [epoch: 120 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8943949771530355		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 3.8943949771530355 | validation: 3.7223728070265087]
	TIME [epoch: 7.72 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.316734222323854		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 3.316734222323854 | validation: 2.9592368833756595]
	TIME [epoch: 7.63 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.449889222690937		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 2.449889222690937 | validation: 2.6803221048144614]
	TIME [epoch: 7.63 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.307333640282901		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 2.307333640282901 | validation: 2.6657210031845633]
	TIME [epoch: 7.63 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.262232990016185		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 2.262232990016185 | validation: 2.684301480294744]
	TIME [epoch: 7.66 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.200800119355738		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 2.200800119355738 | validation: 2.705462895903816]
	TIME [epoch: 7.67 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1758245107094663		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 2.1758245107094663 | validation: 2.647414751734745]
	TIME [epoch: 7.62 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.125390935936058		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 2.125390935936058 | validation: 2.6886362413520017]
	TIME [epoch: 7.64 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.149817811138107		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 2.149817811138107 | validation: 2.650041720904907]
	TIME [epoch: 7.63 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.094628974744219		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 2.094628974744219 | validation: 2.6466641562645563]
	TIME [epoch: 7.66 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0647233223399555		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 2.0647233223399555 | validation: 2.7501373930340467]
	TIME [epoch: 7.67 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.019336988557798		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 2.019336988557798 | validation: 2.627492576873654]
	TIME [epoch: 7.63 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9286957113487342		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 1.9286957113487342 | validation: 2.8106263105390035]
	TIME [epoch: 7.63 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.003925487094344		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 2.003925487094344 | validation: 2.5828252452440132]
	TIME [epoch: 7.64 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.975987842843625		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 1.975987842843625 | validation: 2.5451858953843316]
	TIME [epoch: 7.64 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9000922469275565		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 1.9000922469275565 | validation: 2.6009854780664607]
	TIME [epoch: 7.68 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.81507141734164		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 1.81507141734164 | validation: 2.8096387332772172]
	TIME [epoch: 7.63 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9506260336697554		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 1.9506260336697554 | validation: 2.582281978171955]
	TIME [epoch: 7.64 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8065157071684226		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 1.8065157071684226 | validation: 2.5703621725930175]
	TIME [epoch: 7.65 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8068917727786908		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 1.8068917727786908 | validation: 2.549973465861282]
	TIME [epoch: 7.64 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.72364406682404		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 1.72364406682404 | validation: 2.2526905824970447]
	TIME [epoch: 7.67 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.566665114115846		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 1.566665114115846 | validation: 2.180657613997944]
	TIME [epoch: 7.68 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5675519895658985		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 1.5675519895658985 | validation: 2.371549516907168]
	TIME [epoch: 7.64 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6520291623586498		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 1.6520291623586498 | validation: 2.3140808923761194]
	TIME [epoch: 7.64 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5419015340015187		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.5419015340015187 | validation: 2.153507826561624]
	TIME [epoch: 7.65 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.621309802064005		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 1.621309802064005 | validation: 2.033867544486125]
	TIME [epoch: 7.68 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5015267429955659		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 1.5015267429955659 | validation: 2.018792418075046]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4554720125350795		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 1.4554720125350795 | validation: 2.279788085973742]
	TIME [epoch: 7.63 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4892454576705592		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 1.4892454576705592 | validation: 2.051316047440068]
	TIME [epoch: 7.64 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4268642795264472		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 1.4268642795264472 | validation: 1.997707695404185]
	TIME [epoch: 7.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4391379294045272		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.4391379294045272 | validation: 2.16403457341734]
	TIME [epoch: 7.68 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5142270495888495		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 1.5142270495888495 | validation: 1.8966759248938616]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4054720937347707		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.4054720937347707 | validation: 1.9159853011636006]
	TIME [epoch: 7.63 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4215896435211084		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.4215896435211084 | validation: 1.7275207493238178]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5217625471094243		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 1.5217625471094243 | validation: 1.7222678332796058]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.411060994089617		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 1.411060994089617 | validation: 1.7013187170257176]
	TIME [epoch: 7.67 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2960827731683535		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 1.2960827731683535 | validation: 1.7186500003698604]
	TIME [epoch: 7.63 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2744807816556603		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 1.2744807816556603 | validation: 1.8576693115369753]
	TIME [epoch: 7.62 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3098185266491362		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.3098185266491362 | validation: 1.7587168652129372]
	TIME [epoch: 7.62 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1877527427149768		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.1877527427149768 | validation: 1.7531948034588374]
	TIME [epoch: 7.62 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.217817516028583		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 1.217817516028583 | validation: 1.723067084702374]
	TIME [epoch: 7.67 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1617694669753216		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 1.1617694669753216 | validation: 1.8470937044896514]
	TIME [epoch: 7.64 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3334148618199624		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 1.3334148618199624 | validation: 1.4387151827670748]
	TIME [epoch: 7.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2634119434554476		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 1.2634119434554476 | validation: 1.4965882113983806]
	TIME [epoch: 7.62 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.097628503745878		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 1.097628503745878 | validation: 1.3157891360782268]
	TIME [epoch: 7.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_110.pth
	Model improved!!!
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.048881345834897		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 1.048881345834897 | validation: 1.2268980882794764]
	TIME [epoch: 7.67 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_111.pth
	Model improved!!!
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8900676013831188		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.8900676013831188 | validation: 1.1005732436908218]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_112.pth
	Model improved!!!
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8730154798475567		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.8730154798475567 | validation: 1.3182563476452795]
	TIME [epoch: 7.63 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9445204361258164		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.9445204361258164 | validation: 1.0247622113962636]
	TIME [epoch: 7.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_114.pth
	Model improved!!!
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0888618675045303		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 1.0888618675045303 | validation: 1.2547375310117639]
	TIME [epoch: 7.65 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8772732231892078		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.8772732231892078 | validation: 1.118801427700003]
	TIME [epoch: 7.67 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8145898818500195		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.8145898818500195 | validation: 0.7433265782521001]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7551924400067676		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.7551924400067676 | validation: 0.837545160947029]
	TIME [epoch: 7.61 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7357992747420637		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.7357992747420637 | validation: 0.698560758140374]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_119.pth
	Model improved!!!
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6889319096358685		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.6889319096358685 | validation: 0.9023162609472292]
	TIME [epoch: 7.62 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7084455179436948		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.7084455179436948 | validation: 0.9280123172320481]
	TIME [epoch: 7.65 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7058888963670711		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.7058888963670711 | validation: 0.8860759716720596]
	TIME [epoch: 7.62 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.698149025045003		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.698149025045003 | validation: 0.8537000610157772]
	TIME [epoch: 7.63 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7093404475923203		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.7093404475923203 | validation: 0.7349831048456474]
	TIME [epoch: 7.66 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6576068074022852		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.6576068074022852 | validation: 0.6809947662561853]
	TIME [epoch: 7.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_125.pth
	Model improved!!!
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7367662774260748		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.7367662774260748 | validation: 0.7159508063609508]
	TIME [epoch: 7.64 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6590673967381513		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.6590673967381513 | validation: 0.7097108402381807]
	TIME [epoch: 7.66 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6010417211147319		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.6010417211147319 | validation: 1.0002200368823524]
	TIME [epoch: 7.63 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7214073176234392		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.7214073176234392 | validation: 0.8301305214412977]
	TIME [epoch: 7.62 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7605060786306322		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.7605060786306322 | validation: 0.837121639438982]
	TIME [epoch: 7.63 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5733632150713042		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.5733632150713042 | validation: 0.7489322284469822]
	TIME [epoch: 7.62 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.682073458222689		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.682073458222689 | validation: 0.862166027085757]
	TIME [epoch: 7.66 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6346090455651833		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.6346090455651833 | validation: 0.7823003115647135]
	TIME [epoch: 7.64 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.688588480726736		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.688588480726736 | validation: 0.667540083501519]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_134.pth
	Model improved!!!
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.590061769865228		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.590061769865228 | validation: 0.7390290898384284]
	TIME [epoch: 7.62 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6169983044452448		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.6169983044452448 | validation: 0.6806182912018807]
	TIME [epoch: 7.62 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.554913459687841		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.554913459687841 | validation: 0.9022144530894352]
	TIME [epoch: 7.65 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6887358780715445		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.6887358780715445 | validation: 0.7302736890246444]
	TIME [epoch: 7.66 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6204268953526703		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.6204268953526703 | validation: 0.6172083777324433]
	TIME [epoch: 7.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_139.pth
	Model improved!!!
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5942650551852195		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.5942650551852195 | validation: 0.6169762557867037]
	TIME [epoch: 7.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_140.pth
	Model improved!!!
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6120248907783135		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.6120248907783135 | validation: 0.6034210214531008]
	TIME [epoch: 7.67 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5643876905642637		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.5643876905642637 | validation: 0.7130615035695184]
	TIME [epoch: 7.64 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5794600585434804		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.5794600585434804 | validation: 0.6739250403621841]
	TIME [epoch: 7.67 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5590609074601989		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.5590609074601989 | validation: 0.6321738632546764]
	TIME [epoch: 7.62 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5766539828760137		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.5766539828760137 | validation: 0.6525382410192243]
	TIME [epoch: 7.62 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.604218669023789		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.604218669023789 | validation: 0.6774826245951531]
	TIME [epoch: 7.63 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5197618271650712		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.5197618271650712 | validation: 0.7324895996918851]
	TIME [epoch: 7.62 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6161872065031082		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.6161872065031082 | validation: 0.6148050964749252]
	TIME [epoch: 7.65 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5480684519511507		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.5480684519511507 | validation: 0.6050680097949197]
	TIME [epoch: 7.65 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.548900949671589		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.548900949671589 | validation: 0.6360575738428028]
	TIME [epoch: 7.63 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4851558738675895		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.4851558738675895 | validation: 0.6953020260515683]
	TIME [epoch: 7.62 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6369689208107622		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.6369689208107622 | validation: 0.6570020389072458]
	TIME [epoch: 7.63 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5490657981831013		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.5490657981831013 | validation: 0.8413022671179491]
	TIME [epoch: 7.63 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6355489597675472		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.6355489597675472 | validation: 0.7340676484141532]
	TIME [epoch: 7.68 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4907623231001549		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.4907623231001549 | validation: 0.6314244328520049]
	TIME [epoch: 7.63 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5238125619011536		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.5238125619011536 | validation: 0.7197902937106975]
	TIME [epoch: 7.62 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5289286372372768		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.5289286372372768 | validation: 0.6375909082638667]
	TIME [epoch: 7.62 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5585612154939635		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.5585612154939635 | validation: 0.5940597320944234]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_158.pth
	Model improved!!!
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5199457476584018		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.5199457476584018 | validation: 0.6262971844815765]
	TIME [epoch: 7.66 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5303406324145609		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.5303406324145609 | validation: 0.5682076574311985]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_160.pth
	Model improved!!!
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5143985815979034		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.5143985815979034 | validation: 0.5567092171972109]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_161.pth
	Model improved!!!
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47465677196813627		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.47465677196813627 | validation: 0.5672795859972413]
	TIME [epoch: 7.63 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5706569315985476		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.5706569315985476 | validation: 0.5722733696543294]
	TIME [epoch: 7.64 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49279050749013664		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.49279050749013664 | validation: 0.5738334157531562]
	TIME [epoch: 7.65 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4994970775211318		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.4994970775211318 | validation: 0.5975127865105949]
	TIME [epoch: 7.68 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5397670051070641		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.5397670051070641 | validation: 0.5443254220004852]
	TIME [epoch: 7.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_166.pth
	Model improved!!!
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4913628275381452		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.4913628275381452 | validation: 0.6752788157049634]
	TIME [epoch: 7.64 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48168615274380655		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.48168615274380655 | validation: 0.5024468108291863]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_168.pth
	Model improved!!!
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5191706393336488		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.5191706393336488 | validation: 0.5443420382513342]
	TIME [epoch: 7.64 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5002921270519063		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.5002921270519063 | validation: 0.5787198581649787]
	TIME [epoch: 7.68 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48850375766377085		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.48850375766377085 | validation: 0.6585096161519777]
	TIME [epoch: 7.63 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5021341664040607		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.5021341664040607 | validation: 0.5236757083099233]
	TIME [epoch: 7.63 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4668276150432171		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.4668276150432171 | validation: 0.5665837709133055]
	TIME [epoch: 7.62 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5040250710163361		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.5040250710163361 | validation: 0.5134580447744747]
	TIME [epoch: 7.63 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46509497765712027		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.46509497765712027 | validation: 0.6179113484185836]
	TIME [epoch: 7.66 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47033330827044373		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.47033330827044373 | validation: 0.610991769637202]
	TIME [epoch: 7.65 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4891138985155286		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.4891138985155286 | validation: 0.5032290660066565]
	TIME [epoch: 7.63 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49797047910446945		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.49797047910446945 | validation: 0.5128337864363044]
	TIME [epoch: 7.63 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46226559175887394		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.46226559175887394 | validation: 0.5012063142229791]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_179.pth
	Model improved!!!
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4403315233542536		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.4403315233542536 | validation: 0.5086404694509772]
	TIME [epoch: 7.65 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5104172455988313		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.5104172455988313 | validation: 0.5606073262199364]
	TIME [epoch: 7.67 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4575264309837413		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.4575264309837413 | validation: 0.5416076185049107]
	TIME [epoch: 7.62 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43573420694983633		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.43573420694983633 | validation: 0.5974178348994976]
	TIME [epoch: 7.63 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4541601107253006		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.4541601107253006 | validation: 0.5579165215666456]
	TIME [epoch: 7.61 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47266001914689987		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.47266001914689987 | validation: 0.5952124968782191]
	TIME [epoch: 7.63 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.442029389467539		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.442029389467539 | validation: 0.5389110476434966]
	TIME [epoch: 7.64 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48226138337001057		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.48226138337001057 | validation: 0.5248146964201145]
	TIME [epoch: 7.62 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5101297945549668		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.5101297945549668 | validation: 0.48868135222663744]
	TIME [epoch: 7.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_188.pth
	Model improved!!!
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43349731792661095		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.43349731792661095 | validation: 0.4987947983421044]
	TIME [epoch: 7.59 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4177050973640233		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.4177050973640233 | validation: 0.5133176358738976]
	TIME [epoch: 7.59 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43884569078542457		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.43884569078542457 | validation: 0.6020595321383181]
	TIME [epoch: 7.6 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4511111934388942		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.4511111934388942 | validation: 0.5195200379882401]
	TIME [epoch: 7.64 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4981691856249401		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.4981691856249401 | validation: 0.5116832664523093]
	TIME [epoch: 7.59 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43484820057737583		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.43484820057737583 | validation: 0.5748975463297972]
	TIME [epoch: 7.66 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46247395537206537		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.46247395537206537 | validation: 0.5143853463184588]
	TIME [epoch: 7.63 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43226577000742733		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.43226577000742733 | validation: 0.5034448065908236]
	TIME [epoch: 7.63 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43747293449831415		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.43747293449831415 | validation: 0.4783827126779721]
	TIME [epoch: 7.66 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_197.pth
	Model improved!!!
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4480296319172802		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.4480296319172802 | validation: 0.5727835828582402]
	TIME [epoch: 7.64 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45358610113411946		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.45358610113411946 | validation: 0.5258678902873783]
	TIME [epoch: 7.62 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42112338356614976		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.42112338356614976 | validation: 0.5429635869342367]
	TIME [epoch: 7.61 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4494442927859783		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.4494442927859783 | validation: 0.5790661227977967]
	TIME [epoch: 7.62 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45398227517486495		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.45398227517486495 | validation: 0.5083822753683217]
	TIME [epoch: 7.63 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42537745598483556		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.42537745598483556 | validation: 0.5052936251536954]
	TIME [epoch: 7.66 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45042369649764		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.45042369649764 | validation: 0.4961118878706614]
	TIME [epoch: 7.62 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41965368725281904		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.41965368725281904 | validation: 0.5173974332011823]
	TIME [epoch: 7.61 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4251610286433669		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.4251610286433669 | validation: 0.4975958764921986]
	TIME [epoch: 7.62 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4327439245542993		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.4327439245542993 | validation: 0.5625912874470732]
	TIME [epoch: 7.62 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4601963570950263		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.4601963570950263 | validation: 0.5513774586167259]
	TIME [epoch: 7.68 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4458843573102933		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.4458843573102933 | validation: 0.48975502642528174]
	TIME [epoch: 7.63 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4011405214424284		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.4011405214424284 | validation: 0.5267121107084498]
	TIME [epoch: 7.61 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4595023476758109		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.4595023476758109 | validation: 0.4760812372437927]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_211.pth
	Model improved!!!
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42265150297653503		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.42265150297653503 | validation: 0.47246315141132955]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_212.pth
	Model improved!!!
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4110073037201679		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.4110073037201679 | validation: 0.4791886641563894]
	TIME [epoch: 7.67 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4190903801828415		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.4190903801828415 | validation: 0.49156776498769017]
	TIME [epoch: 7.66 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41964472031320865		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.41964472031320865 | validation: 0.49806135945971763]
	TIME [epoch: 7.62 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.417245297120257		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.417245297120257 | validation: 0.530167278763269]
	TIME [epoch: 7.62 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4219902782393904		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.4219902782393904 | validation: 0.6234008803994069]
	TIME [epoch: 7.63 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4643722511555746		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.4643722511555746 | validation: 0.4876083474513486]
	TIME [epoch: 7.64 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38580898353286686		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.38580898353286686 | validation: 0.5036461900458049]
	TIME [epoch: 7.67 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4017387619386438		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.4017387619386438 | validation: 0.473081195661641]
	TIME [epoch: 7.62 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4087030808932255		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.4087030808932255 | validation: 0.49532897833804146]
	TIME [epoch: 7.62 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4287018247638093		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.4287018247638093 | validation: 0.4677483688194342]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_222.pth
	Model improved!!!
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3929393160485204		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.3929393160485204 | validation: 0.4938957424824375]
	TIME [epoch: 7.62 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42651260589341033		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.42651260589341033 | validation: 0.5286845777581533]
	TIME [epoch: 7.64 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4154699534607591		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.4154699534607591 | validation: 0.5087796421413362]
	TIME [epoch: 7.65 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4151899731513419		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.4151899731513419 | validation: 0.547508984713042]
	TIME [epoch: 7.63 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40532689019749757		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.40532689019749757 | validation: 0.4931379348104261]
	TIME [epoch: 7.62 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4196849141330433		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.4196849141330433 | validation: 0.5039043621076247]
	TIME [epoch: 7.62 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38679856314960775		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.38679856314960775 | validation: 0.46786890478551646]
	TIME [epoch: 7.63 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39505967916952894		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.39505967916952894 | validation: 0.49208580819815284]
	TIME [epoch: 7.67 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4121129402202441		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.4121129402202441 | validation: 0.5017725509165086]
	TIME [epoch: 7.63 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3989974390531297		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.3989974390531297 | validation: 0.5250333471703944]
	TIME [epoch: 7.62 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4345262016868079		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.4345262016868079 | validation: 0.5010115051810936]
	TIME [epoch: 7.63 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4136763856978103		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.4136763856978103 | validation: 0.4765586138031058]
	TIME [epoch: 7.62 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3955851430068842		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.3955851430068842 | validation: 0.4619571827593111]
	TIME [epoch: 7.65 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_235.pth
	Model improved!!!
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38496649414608664		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.38496649414608664 | validation: 0.4762821786296354]
	TIME [epoch: 7.68 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4094756090844398		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.4094756090844398 | validation: 0.4892950010017177]
	TIME [epoch: 7.65 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4059963406874426		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.4059963406874426 | validation: 0.4594740390288401]
	TIME [epoch: 7.65 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_238.pth
	Model improved!!!
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3881609476222225		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.3881609476222225 | validation: 0.47339507497460254]
	TIME [epoch: 7.63 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40917519956712156		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.40917519956712156 | validation: 0.5051036058059872]
	TIME [epoch: 7.65 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40894108377549027		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.40894108377549027 | validation: 0.5146960924024667]
	TIME [epoch: 7.69 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40929703955330515		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.40929703955330515 | validation: 0.4755161770033325]
	TIME [epoch: 7.63 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38231077994052415		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.38231077994052415 | validation: 0.45636392257883884]
	TIME [epoch: 7.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_243.pth
	Model improved!!!
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4058776157219631		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.4058776157219631 | validation: 0.5451318974712458]
	TIME [epoch: 7.62 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41636579298249465		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.41636579298249465 | validation: 0.5181043285861293]
	TIME [epoch: 7.63 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40720028625143956		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.40720028625143956 | validation: 0.4977686460582679]
	TIME [epoch: 7.67 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3862188704890715		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.3862188704890715 | validation: 0.4747850558318444]
	TIME [epoch: 7.64 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40070564018255855		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.40070564018255855 | validation: 0.48105985327624046]
	TIME [epoch: 7.63 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40980962045850267		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.40980962045850267 | validation: 0.4680613983118303]
	TIME [epoch: 7.63 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4013363273031928		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.4013363273031928 | validation: 0.5096414489494026]
	TIME [epoch: 7.63 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3978861029424004		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.3978861029424004 | validation: 0.4636433117276964]
	TIME [epoch: 7.64 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39179891816690243		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.39179891816690243 | validation: 0.4801543411189517]
	TIME [epoch: 7.67 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3889616509296364		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.3889616509296364 | validation: 0.4673171146627757]
	TIME [epoch: 7.62 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3904415609685715		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.3904415609685715 | validation: 0.45593200778933013]
	TIME [epoch: 7.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_254.pth
	Model improved!!!
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39289139170023296		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.39289139170023296 | validation: 0.46578452937987397]
	TIME [epoch: 7.63 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40631473014667524		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.40631473014667524 | validation: 0.4678678976966151]
	TIME [epoch: 7.63 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38659746382436455		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.38659746382436455 | validation: 0.45999425201221744]
	TIME [epoch: 7.66 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39446737014795674		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.39446737014795674 | validation: 0.45477302744777115]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_258.pth
	Model improved!!!
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3844866141271408		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.3844866141271408 | validation: 0.4510071211797858]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_259.pth
	Model improved!!!
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3856612835180751		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.3856612835180751 | validation: 0.5491966395022801]
	TIME [epoch: 7.61 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4143135271492884		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.4143135271492884 | validation: 0.44102257586069715]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_261.pth
	Model improved!!!
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.378317919093065		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.378317919093065 | validation: 0.4856648158761212]
	TIME [epoch: 7.64 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3755274210515828		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.3755274210515828 | validation: 0.4883283968372807]
	TIME [epoch: 7.66 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41404482999957815		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.41404482999957815 | validation: 0.4814348193273389]
	TIME [epoch: 7.6 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39222285657352013		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.39222285657352013 | validation: 0.4720010457730739]
	TIME [epoch: 7.66 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37980814963868625		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.37980814963868625 | validation: 0.4798362852283199]
	TIME [epoch: 7.61 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.388805136834647		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.388805136834647 | validation: 0.49172865702469176]
	TIME [epoch: 7.62 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3878431287022424		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.3878431287022424 | validation: 0.45633892041891777]
	TIME [epoch: 7.66 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3822529509559824		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.3822529509559824 | validation: 0.4670310792836716]
	TIME [epoch: 7.63 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3915830496122991		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.3915830496122991 | validation: 0.4915428509647525]
	TIME [epoch: 7.62 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3757753932508481		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.3757753932508481 | validation: 0.4546193274649666]
	TIME [epoch: 7.62 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.386361921604507		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.386361921604507 | validation: 0.4599758766049007]
	TIME [epoch: 7.62 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38559113278494217		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.38559113278494217 | validation: 0.5158323301208011]
	TIME [epoch: 7.64 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3992448554406977		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.3992448554406977 | validation: 0.48040093486292135]
	TIME [epoch: 7.66 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37341745935512627		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.37341745935512627 | validation: 0.5224465922840982]
	TIME [epoch: 7.61 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3768599018390085		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.3768599018390085 | validation: 0.4593945758152431]
	TIME [epoch: 7.62 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3613576787128051		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.3613576787128051 | validation: 0.46185359633367074]
	TIME [epoch: 7.62 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37903385848703475		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.37903385848703475 | validation: 0.48538264153016614]
	TIME [epoch: 7.62 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3824335856138561		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.3824335856138561 | validation: 0.48272843263697074]
	TIME [epoch: 7.67 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38558840448757536		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.38558840448757536 | validation: 0.48151727720244797]
	TIME [epoch: 7.63 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37485095430200316		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.37485095430200316 | validation: 0.47027694581615764]
	TIME [epoch: 7.62 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37716125058035005		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.37716125058035005 | validation: 0.4804966685273938]
	TIME [epoch: 7.62 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37212670586105784		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.37212670586105784 | validation: 0.458844588040856]
	TIME [epoch: 7.62 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36306304302801445		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.36306304302801445 | validation: 0.4849395244716601]
	TIME [epoch: 7.64 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3975714229051979		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.3975714229051979 | validation: 0.4543460928320404]
	TIME [epoch: 7.65 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37435950154389563		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.37435950154389563 | validation: 0.46004887252991683]
	TIME [epoch: 7.62 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37791625252691596		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.37791625252691596 | validation: 0.4972061700042004]
	TIME [epoch: 7.61 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3724274475097371		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.3724274475097371 | validation: 0.4759276407994787]
	TIME [epoch: 7.62 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37263406899828044		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.37263406899828044 | validation: 0.48221846833705523]
	TIME [epoch: 7.63 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3896919364071736		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.3896919364071736 | validation: 0.48284668789940843]
	TIME [epoch: 7.67 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3661464351025022		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.3661464351025022 | validation: 0.46023167553525396]
	TIME [epoch: 7.63 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36747017921216435		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.36747017921216435 | validation: 0.4558535529187484]
	TIME [epoch: 7.61 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.365736249177029		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.365736249177029 | validation: 0.4576109354873473]
	TIME [epoch: 7.61 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35816900654570843		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.35816900654570843 | validation: 0.46758617479379405]
	TIME [epoch: 7.62 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.375317275891482		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.375317275891482 | validation: 0.45858866409831867]
	TIME [epoch: 7.63 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35919027518127666		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.35919027518127666 | validation: 0.47666671591396137]
	TIME [epoch: 7.65 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3704691551196689		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.3704691551196689 | validation: 0.46669235286727234]
	TIME [epoch: 7.62 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37739473040236626		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.37739473040236626 | validation: 0.4444349544743992]
	TIME [epoch: 7.62 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35722119777638267		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.35722119777638267 | validation: 0.45905306069456786]
	TIME [epoch: 7.62 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35463488468090887		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.35463488468090887 | validation: 0.4932624309756459]
	TIME [epoch: 7.62 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38181286320560626		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.38181286320560626 | validation: 0.4316134917736819]
	TIME [epoch: 7.67 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_301.pth
	Model improved!!!
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3525411356162282		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.3525411356162282 | validation: 0.43928552798199416]
	TIME [epoch: 7.63 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.359315379955117		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.359315379955117 | validation: 0.479635244623586]
	TIME [epoch: 7.62 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3646753363912928		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.3646753363912928 | validation: 0.46403100724280855]
	TIME [epoch: 7.62 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3682192520213397		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.3682192520213397 | validation: 0.44971012195617316]
	TIME [epoch: 7.61 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37063812911464616		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.37063812911464616 | validation: 0.4478467805728606]
	TIME [epoch: 7.65 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36297511190524545		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.36297511190524545 | validation: 0.44143478031489414]
	TIME [epoch: 7.66 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3570444287719137		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.3570444287719137 | validation: 0.46106307742341485]
	TIME [epoch: 7.62 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34818367729626465		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.34818367729626465 | validation: 0.4573585352384608]
	TIME [epoch: 7.64 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35552774716712976		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.35552774716712976 | validation: 0.4905517977323817]
	TIME [epoch: 7.62 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37293727087181605		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.37293727087181605 | validation: 0.4738215192193437]
	TIME [epoch: 7.62 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36765920965407506		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.36765920965407506 | validation: 0.47012802829504063]
	TIME [epoch: 7.67 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3487721575693648		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.3487721575693648 | validation: 0.45343984743409455]
	TIME [epoch: 7.63 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3585810248529905		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.3585810248529905 | validation: 0.4412177900150571]
	TIME [epoch: 7.61 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36179817042099927		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.36179817042099927 | validation: 0.45645009128431957]
	TIME [epoch: 7.62 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36738625068422326		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.36738625068422326 | validation: 0.46912925775205117]
	TIME [epoch: 7.62 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3469257177403998		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.3469257177403998 | validation: 0.4466029504396489]
	TIME [epoch: 7.64 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3398894906104213		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.3398894906104213 | validation: 0.4701686767683036]
	TIME [epoch: 7.66 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3578929867048981		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.3578929867048981 | validation: 0.47475022695541735]
	TIME [epoch: 7.63 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34668156281594525		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.34668156281594525 | validation: 0.4405947284971934]
	TIME [epoch: 7.62 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34005812880960423		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.34005812880960423 | validation: 0.49697856056295076]
	TIME [epoch: 7.63 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35372593861514795		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.35372593861514795 | validation: 0.4540978526410873]
	TIME [epoch: 7.63 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3329935104580842		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.3329935104580842 | validation: 0.4651431180746384]
	TIME [epoch: 7.67 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32539064869248724		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.32539064869248724 | validation: 0.46412651906340796]
	TIME [epoch: 7.64 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3557466529868224		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.3557466529868224 | validation: 0.46827146092257715]
	TIME [epoch: 7.62 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3469964686927384		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.3469964686927384 | validation: 0.46106628524218524]
	TIME [epoch: 7.62 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3343848205700065		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.3343848205700065 | validation: 0.4618728697818485]
	TIME [epoch: 7.62 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.334513107026368		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.334513107026368 | validation: 0.4872475395338352]
	TIME [epoch: 7.64 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34059569452774274		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.34059569452774274 | validation: 0.4615583908005194]
	TIME [epoch: 7.65 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32932188445830507		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.32932188445830507 | validation: 0.44334744983450636]
	TIME [epoch: 7.61 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3300330493582403		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.3300330493582403 | validation: 0.4399635979858464]
	TIME [epoch: 7.61 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33730848115655626		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.33730848115655626 | validation: 0.45234197299049783]
	TIME [epoch: 7.6 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3295542304197657		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.3295542304197657 | validation: 0.4463700358988484]
	TIME [epoch: 7.61 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.328196482639823		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.328196482639823 | validation: 0.44769284413333965]
	TIME [epoch: 7.64 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33345204318698607		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.33345204318698607 | validation: 0.4922874995387624]
	TIME [epoch: 7.62 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3341486891867695		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.3341486891867695 | validation: 0.4442161546544512]
	TIME [epoch: 7.6 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31964679543309915		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.31964679543309915 | validation: 0.5226785319109104]
	TIME [epoch: 7.67 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3365363280837308		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.3365363280837308 | validation: 0.4849192085521746]
	TIME [epoch: 7.62 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3242492611524038		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.3242492611524038 | validation: 0.42460945490147206]
	TIME [epoch: 7.65 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_339.pth
	Model improved!!!
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3226258289129683		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.3226258289129683 | validation: 0.4232697098787491]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_340.pth
	Model improved!!!
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.316126661185155		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.316126661185155 | validation: 0.4387715358458055]
	TIME [epoch: 7.61 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31982135937415507		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.31982135937415507 | validation: 0.45002818276203405]
	TIME [epoch: 7.62 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3333053629246961		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.3333053629246961 | validation: 0.45197129646390144]
	TIME [epoch: 7.61 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3126924497159749		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.3126924497159749 | validation: 0.43339628476265557]
	TIME [epoch: 7.63 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.319376826493726		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.319376826493726 | validation: 0.4229852938647478]
	TIME [epoch: 7.66 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_345.pth
	Model improved!!!
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3126440571622228		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.3126440571622228 | validation: 0.4191386249339741]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_346.pth
	Model improved!!!
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30579448589860453		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.30579448589860453 | validation: 0.402547301044082]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_347.pth
	Model improved!!!
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31120662764199725		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.31120662764199725 | validation: 0.401483702017028]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_348.pth
	Model improved!!!
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3106245325097441		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.3106245325097441 | validation: 0.46091823158156975]
	TIME [epoch: 7.64 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3133538158527427		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.3133538158527427 | validation: 0.47839670617514496]
	TIME [epoch: 7.67 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.329493880321968		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.329493880321968 | validation: 0.4424462389333569]
	TIME [epoch: 7.63 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31521733299149296		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.31521733299149296 | validation: 0.41592333446225127]
	TIME [epoch: 7.63 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3320060401658318		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.3320060401658318 | validation: 0.3961467825804449]
	TIME [epoch: 7.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_353.pth
	Model improved!!!
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29566603512735373		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.29566603512735373 | validation: 0.4269292836393668]
	TIME [epoch: 7.62 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30126299843255744		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.30126299843255744 | validation: 0.41955377291852447]
	TIME [epoch: 7.65 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3008245032223936		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.3008245032223936 | validation: 0.4021242915864783]
	TIME [epoch: 7.66 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3066984943317539		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.3066984943317539 | validation: 0.3973310068858088]
	TIME [epoch: 7.62 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2952637220867255		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.2952637220867255 | validation: 0.390624668805697]
	TIME [epoch: 7.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_358.pth
	Model improved!!!
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3041943258712928		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.3041943258712928 | validation: 0.4004095114947766]
	TIME [epoch: 7.62 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2959175862281973		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.2959175862281973 | validation: 0.4202230811680837]
	TIME [epoch: 7.63 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30454747231099233		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.30454747231099233 | validation: 0.40078770516406337]
	TIME [epoch: 7.67 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30643190187641356		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.30643190187641356 | validation: 0.39461699070870215]
	TIME [epoch: 7.62 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29669966572451195		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.29669966572451195 | validation: 0.395308817594454]
	TIME [epoch: 7.62 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2918365123702817		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.2918365123702817 | validation: 0.3873783935257717]
	TIME [epoch: 7.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_364.pth
	Model improved!!!
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29909462856802294		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.29909462856802294 | validation: 0.38982908187402915]
	TIME [epoch: 7.63 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28615883459269276		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.28615883459269276 | validation: 0.4749896592808327]
	TIME [epoch: 7.66 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29197602199134554		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.29197602199134554 | validation: 0.3689458058132574]
	TIME [epoch: 7.65 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_367.pth
	Model improved!!!
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30519792346374386		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.30519792346374386 | validation: 0.43965609318576276]
	TIME [epoch: 7.62 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2902660507013883		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.2902660507013883 | validation: 0.3770001381660431]
	TIME [epoch: 7.63 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27855459480606104		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.27855459480606104 | validation: 0.3911748363806232]
	TIME [epoch: 7.62 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2825478073111693		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.2825478073111693 | validation: 0.40062132979631715]
	TIME [epoch: 7.63 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28848332956886824		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.28848332956886824 | validation: 0.4131512569629447]
	TIME [epoch: 7.66 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2895662923796749		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.2895662923796749 | validation: 0.42742377597241443]
	TIME [epoch: 7.62 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28941519768766455		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.28941519768766455 | validation: 0.3801777409404007]
	TIME [epoch: 7.62 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2917468499459858		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.2917468499459858 | validation: 0.36076215234149284]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_375.pth
	Model improved!!!
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28166615393781747		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.28166615393781747 | validation: 0.4084899646707945]
	TIME [epoch: 7.61 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27977987041727925		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.27977987041727925 | validation: 0.3667971054304767]
	TIME [epoch: 7.65 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.272063788992884		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.272063788992884 | validation: 0.35968227527220575]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_378.pth
	Model improved!!!
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2950864942288136		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.2950864942288136 | validation: 0.36013682729949714]
	TIME [epoch: 7.62 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2761524682134231		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.2761524682134231 | validation: 0.37496294267547464]
	TIME [epoch: 7.61 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27780472331563333		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.27780472331563333 | validation: 0.3578628445492734]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_381.pth
	Model improved!!!
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27633100071783884		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.27633100071783884 | validation: 0.3539885154560277]
	TIME [epoch: 7.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_382.pth
	Model improved!!!
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2709089644374634		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.2709089644374634 | validation: 0.4044273837156107]
	TIME [epoch: 7.67 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27910005024092915		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.27910005024092915 | validation: 0.37503184773459153]
	TIME [epoch: 7.66 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27073808253249415		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.27073808253249415 | validation: 0.358941198712441]
	TIME [epoch: 7.65 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27387393885236244		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.27387393885236244 | validation: 0.4142498833882978]
	TIME [epoch: 7.64 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26697292013108664		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.26697292013108664 | validation: 0.3662448146991729]
	TIME [epoch: 7.65 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27628122410789585		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.27628122410789585 | validation: 0.3547284245636052]
	TIME [epoch: 7.69 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2637350813964346		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.2637350813964346 | validation: 0.3768396735591563]
	TIME [epoch: 7.64 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2698054529995786		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.2698054529995786 | validation: 0.3941520854375373]
	TIME [epoch: 7.65 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26730359891348365		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.26730359891348365 | validation: 0.3366695533564261]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_391.pth
	Model improved!!!
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26030938413249		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.26030938413249 | validation: 0.3714645293569489]
	TIME [epoch: 7.63 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2745559866916498		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.2745559866916498 | validation: 0.3646905867869021]
	TIME [epoch: 7.68 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27313589111820297		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.27313589111820297 | validation: 0.387936384121612]
	TIME [epoch: 7.65 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26543574876350684		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.26543574876350684 | validation: 0.34786085909379805]
	TIME [epoch: 7.63 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27489594093774694		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.27489594093774694 | validation: 0.327479510062448]
	TIME [epoch: 7.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_396.pth
	Model improved!!!
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2585333081897261		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.2585333081897261 | validation: 0.33122938521739764]
	TIME [epoch: 7.62 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2559290689979022		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.2559290689979022 | validation: 0.3330481949878958]
	TIME [epoch: 7.65 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2517367368913644		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.2517367368913644 | validation: 0.33134435543541263]
	TIME [epoch: 7.67 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2799539055264059		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.2799539055264059 | validation: 0.4018109897156509]
	TIME [epoch: 7.62 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3183357305159795		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.3183357305159795 | validation: 0.38520584141970465]
	TIME [epoch: 7.62 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2800101617594679		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.2800101617594679 | validation: 0.3043286778132998]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_402.pth
	Model improved!!!
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2545985454110353		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.2545985454110353 | validation: 0.31962760719485783]
	TIME [epoch: 7.62 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2612755670468243		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.2612755670468243 | validation: 0.3248809730155149]
	TIME [epoch: 7.66 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2413329597472296		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.2413329597472296 | validation: 0.30878372918075725]
	TIME [epoch: 7.62 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24724971635052856		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.24724971635052856 | validation: 0.3203256910222638]
	TIME [epoch: 7.62 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23488688984352402		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.23488688984352402 | validation: 0.3310071678548703]
	TIME [epoch: 7.66 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25945250654891416		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.25945250654891416 | validation: 0.38944694288536963]
	TIME [epoch: 7.65 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2528964944783251		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.2528964944783251 | validation: 0.28512185144602065]
	TIME [epoch: 7.65 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_409.pth
	Model improved!!!
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25019588651644153		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.25019588651644153 | validation: 0.34201641525712007]
	TIME [epoch: 7.67 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25351105544073277		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.25351105544073277 | validation: 0.3153523240452883]
	TIME [epoch: 7.64 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24313790685887487		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.24313790685887487 | validation: 0.2876288693067552]
	TIME [epoch: 7.62 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2329354769155509		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.2329354769155509 | validation: 0.3428883212056215]
	TIME [epoch: 7.61 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24292887070328362		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.24292887070328362 | validation: 0.3358702158611224]
	TIME [epoch: 7.64 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25957427466555794		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.25957427466555794 | validation: 0.3109144508851156]
	TIME [epoch: 7.66 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2395032975413069		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.2395032975413069 | validation: 0.3117740325333868]
	TIME [epoch: 7.63 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24526358763347822		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.24526358763347822 | validation: 0.3459430892437805]
	TIME [epoch: 7.62 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25364635989481066		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.25364635989481066 | validation: 0.33075822984783915]
	TIME [epoch: 7.62 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24721640332562944		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.24721640332562944 | validation: 0.32965003201949983]
	TIME [epoch: 7.63 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23714876546065805		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.23714876546065805 | validation: 0.32078409810301833]
	TIME [epoch: 7.64 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24801027123671782		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.24801027123671782 | validation: 0.3494330843287175]
	TIME [epoch: 7.65 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24008167279367107		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.24008167279367107 | validation: 0.2809198968081408]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_422.pth
	Model improved!!!
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2376582795375124		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.2376582795375124 | validation: 0.32653112534105017]
	TIME [epoch: 7.61 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24244058721329553		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.24244058721329553 | validation: 0.3196420822140652]
	TIME [epoch: 7.62 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24039108643280174		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.24039108643280174 | validation: 0.2978278948926815]
	TIME [epoch: 7.63 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22911859360740072		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.22911859360740072 | validation: 0.30249300955405156]
	TIME [epoch: 7.66 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2387272678874996		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.2387272678874996 | validation: 0.3190940285060805]
	TIME [epoch: 7.62 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2662552489460312		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.2662552489460312 | validation: 0.2976060120001154]
	TIME [epoch: 7.61 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22309333957180463		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.22309333957180463 | validation: 0.28391819891112924]
	TIME [epoch: 7.61 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2404425008626316		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.2404425008626316 | validation: 0.30033710024032145]
	TIME [epoch: 7.61 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22439888968270283		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.22439888968270283 | validation: 0.320056893679053]
	TIME [epoch: 7.64 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24769843103781417		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.24769843103781417 | validation: 0.2778764065698188]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_432.pth
	Model improved!!!
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22928824721562774		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.22928824721562774 | validation: 0.3418790184178382]
	TIME [epoch: 7.6 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25260089909108574		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.25260089909108574 | validation: 0.2846126489829484]
	TIME [epoch: 7.6 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23153189145635578		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.23153189145635578 | validation: 0.32405251581543704]
	TIME [epoch: 7.61 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2332515807727325		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.2332515807727325 | validation: 0.2781523211691838]
	TIME [epoch: 7.61 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2438708832675196		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.2438708832675196 | validation: 0.27983920344114477]
	TIME [epoch: 7.65 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22843334462410025		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.22843334462410025 | validation: 0.2954573870169518]
	TIME [epoch: 7.62 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22867261039126202		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.22867261039126202 | validation: 0.2833069080721633]
	TIME [epoch: 7.61 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23996709117571685		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.23996709117571685 | validation: 0.29395333747006813]
	TIME [epoch: 7.61 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22075423026889845		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.22075423026889845 | validation: 0.2954525728789465]
	TIME [epoch: 7.61 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2196059492581104		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.2196059492581104 | validation: 0.2697427687690801]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_442.pth
	Model improved!!!
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23282676708333683		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.23282676708333683 | validation: 0.31277193657966595]
	TIME [epoch: 7.64 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2358815717494703		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.2358815717494703 | validation: 0.28634413595236385]
	TIME [epoch: 7.62 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2373620792512222		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.2373620792512222 | validation: 0.27973857135321534]
	TIME [epoch: 7.62 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22658855653668025		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.22658855653668025 | validation: 0.2727249150415024]
	TIME [epoch: 7.6 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22674415376022242		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.22674415376022242 | validation: 0.25497381580771167]
	TIME [epoch: 7.68 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_447.pth
	Model improved!!!
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21574425933324834		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.21574425933324834 | validation: 0.2930935495466022]
	TIME [epoch: 7.64 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23344895580857924		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.23344895580857924 | validation: 0.24402998226121242]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_449.pth
	Model improved!!!
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21526925776152253		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.21526925776152253 | validation: 0.2580336068629782]
	TIME [epoch: 7.62 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21944860428251345		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.21944860428251345 | validation: 0.2849929814958435]
	TIME [epoch: 7.61 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22120674821492148		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.22120674821492148 | validation: 0.26718887702157534]
	TIME [epoch: 7.62 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22573385582648103		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.22573385582648103 | validation: 0.2749876527919509]
	TIME [epoch: 7.64 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2195953299195512		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.2195953299195512 | validation: 0.2778242577757293]
	TIME [epoch: 7.61 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21537332247150676		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.21537332247150676 | validation: 0.27394939827627]
	TIME [epoch: 7.62 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2190600730625421		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.2190600730625421 | validation: 0.27617699590640316]
	TIME [epoch: 7.61 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22153750112398923		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.22153750112398923 | validation: 0.2819057930163099]
	TIME [epoch: 7.62 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22714824865194166		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.22714824865194166 | validation: 0.24322598761556716]
	TIME [epoch: 7.65 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_458.pth
	Model improved!!!
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21340984052604578		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.21340984052604578 | validation: 0.26735658368723314]
	TIME [epoch: 7.64 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22355532320965216		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.22355532320965216 | validation: 0.24158916589735582]
	TIME [epoch: 7.65 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_460.pth
	Model improved!!!
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2062276038263474		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.2062276038263474 | validation: 0.24753804520457207]
	TIME [epoch: 7.64 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2038113382111981		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.2038113382111981 | validation: 0.2382859277040392]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_462.pth
	Model improved!!!
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21927106728195966		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.21927106728195966 | validation: 0.26285110239138104]
	TIME [epoch: 7.67 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20541966699199596		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.20541966699199596 | validation: 0.2527925610044059]
	TIME [epoch: 7.63 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20572119848124637		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.20572119848124637 | validation: 0.24395030386499245]
	TIME [epoch: 7.63 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2088181413023496		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.2088181413023496 | validation: 0.22319517262850203]
	TIME [epoch: 7.66 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_466.pth
	Model improved!!!
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2103652600162146		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.2103652600162146 | validation: 0.30173722996701513]
	TIME [epoch: 7.63 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2198429509924155		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.2198429509924155 | validation: 0.24009975675353395]
	TIME [epoch: 7.66 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20269717907899337		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.20269717907899337 | validation: 0.2593128901829156]
	TIME [epoch: 7.64 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20893953261982048		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.20893953261982048 | validation: 0.2438812115076528]
	TIME [epoch: 7.61 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19734887747612756		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.19734887747612756 | validation: 0.24929427184724132]
	TIME [epoch: 7.61 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2098656062394846		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.2098656062394846 | validation: 0.23830968544756273]
	TIME [epoch: 7.61 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20669038982219004		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.20669038982219004 | validation: 0.2427623824964872]
	TIME [epoch: 7.64 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2012344136663995		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.2012344136663995 | validation: 0.24993091418207164]
	TIME [epoch: 7.64 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2064795802156667		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.2064795802156667 | validation: 0.21994040037247126]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_475.pth
	Model improved!!!
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2016981833670956		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.2016981833670956 | validation: 0.2523752986202706]
	TIME [epoch: 7.61 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19083633742672654		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.19083633742672654 | validation: 0.26634598672828724]
	TIME [epoch: 7.62 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21803702273139186		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.21803702273139186 | validation: 0.2457565017733102]
	TIME [epoch: 7.7 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20205916993640788		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.20205916993640788 | validation: 0.22216604394360306]
	TIME [epoch: 7.66 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18813278126083444		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.18813278126083444 | validation: 0.2017385207280582]
	TIME [epoch: 7.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_480.pth
	Model improved!!!
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18860970810343797		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.18860970810343797 | validation: 0.2810968245799584]
	TIME [epoch: 7.63 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21134536349570854		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.21134536349570854 | validation: 0.22789378353986026]
	TIME [epoch: 7.63 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19414902920797053		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.19414902920797053 | validation: 0.19949574391948544]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_483.pth
	Model improved!!!
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1957346325506089		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.1957346325506089 | validation: 0.2520021840099808]
	TIME [epoch: 7.67 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1967337001195517		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.1967337001195517 | validation: 0.21778999971030585]
	TIME [epoch: 7.62 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20029387557999548		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.20029387557999548 | validation: 0.21972976055592336]
	TIME [epoch: 7.62 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18834997632095957		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.18834997632095957 | validation: 0.21850005624524269]
	TIME [epoch: 7.61 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1787027055284789		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.1787027055284789 | validation: 0.18664940641451278]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_488.pth
	Model improved!!!
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19404714903831455		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.19404714903831455 | validation: 0.2331136021594325]
	TIME [epoch: 7.67 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18330441714588347		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.18330441714588347 | validation: 0.20291041275952443]
	TIME [epoch: 7.61 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18169743477713798		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.18169743477713798 | validation: 0.207972978618419]
	TIME [epoch: 7.61 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19124653964102595		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.19124653964102595 | validation: 0.21673892435928455]
	TIME [epoch: 7.61 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1992698917445818		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.1992698917445818 | validation: 0.19061559326029304]
	TIME [epoch: 7.61 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18195360320505538		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.18195360320505538 | validation: 0.18498102862747023]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_494.pth
	Model improved!!!
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17545121903965355		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.17545121903965355 | validation: 0.20902593047269058]
	TIME [epoch: 7.63 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18726466513220458		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.18726466513220458 | validation: 0.2123045481472625]
	TIME [epoch: 7.61 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18907832059495353		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.18907832059495353 | validation: 0.20037412917110992]
	TIME [epoch: 7.62 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17142400690867857		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.17142400690867857 | validation: 0.22169865211262985]
	TIME [epoch: 7.6 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1804432745963304		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.1804432745963304 | validation: 0.19723073499909352]
	TIME [epoch: 7.64 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17987736517497582		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.17987736517497582 | validation: 0.19910156536921153]
	TIME [epoch: 7.63 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16288080050755102		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.16288080050755102 | validation: 0.17455011546437763]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_501.pth
	Model improved!!!
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17853249109828973		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.17853249109828973 | validation: 0.2866307752986839]
	TIME [epoch: 7.6 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20944231124164225		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.20944231124164225 | validation: 0.17745263258678196]
	TIME [epoch: 7.61 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16677811424207728		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.16677811424207728 | validation: 0.1722199982305075]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_504.pth
	Model improved!!!
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1775864986465231		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.1775864986465231 | validation: 0.17111980866769141]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_505.pth
	Model improved!!!
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16288772333177515		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.16288772333177515 | validation: 0.16664630068769956]
	TIME [epoch: 7.65 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_506.pth
	Model improved!!!
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1683771955994318		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.1683771955994318 | validation: 0.19387375156735193]
	TIME [epoch: 7.64 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1763891763955311		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.1763891763955311 | validation: 0.15619160576153682]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_508.pth
	Model improved!!!
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16551541055833388		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.16551541055833388 | validation: 0.1605751159533652]
	TIME [epoch: 7.67 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16762770701892862		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.16762770701892862 | validation: 0.1896115666125844]
	TIME [epoch: 7.66 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1687811693877384		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.1687811693877384 | validation: 0.21790877359129218]
	TIME [epoch: 7.63 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17538244400677366		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.17538244400677366 | validation: 0.18051211453064114]
	TIME [epoch: 7.63 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16387839516159727		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.16387839516159727 | validation: 0.2047118626026404]
	TIME [epoch: 7.64 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1616377767484959		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.1616377767484959 | validation: 0.15802057070543307]
	TIME [epoch: 7.64 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1549789912702716		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.1549789912702716 | validation: 0.18243493768093]
	TIME [epoch: 7.67 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15720743261116885		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.15720743261116885 | validation: 0.16396299991982244]
	TIME [epoch: 7.63 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16697473552049882		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.16697473552049882 | validation: 0.16398740655677385]
	TIME [epoch: 7.63 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16295961897069644		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.16295961897069644 | validation: 0.16112410005598335]
	TIME [epoch: 7.62 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15643302925345878		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.15643302925345878 | validation: 0.1916641207225277]
	TIME [epoch: 7.65 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1497222767285139		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.1497222767285139 | validation: 0.18413391006368476]
	TIME [epoch: 7.67 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15193486197945552		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.15193486197945552 | validation: 0.1522198766709495]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_521.pth
	Model improved!!!
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17413822187424655		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.17413822187424655 | validation: 0.1737940379395445]
	TIME [epoch: 7.63 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15456359138115267		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.15456359138115267 | validation: 0.1533069731594167]
	TIME [epoch: 7.62 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1438874256737701		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.1438874256737701 | validation: 0.1582239353427635]
	TIME [epoch: 7.63 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1568455159365955		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.1568455159365955 | validation: 0.1537415777902412]
	TIME [epoch: 7.67 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13355807745936993		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.13355807745936993 | validation: 0.12998809815155815]
	TIME [epoch: 7.65 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_526.pth
	Model improved!!!
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15354853225322249		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.15354853225322249 | validation: 0.14985578872452213]
	TIME [epoch: 7.63 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14359025359901895		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.14359025359901895 | validation: 0.15599431367143396]
	TIME [epoch: 7.63 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1477376284650489		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.1477376284650489 | validation: 0.15676186064585945]
	TIME [epoch: 7.62 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14203341894162233		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.14203341894162233 | validation: 0.1718584136307665]
	TIME [epoch: 7.66 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1412241171574921		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.1412241171574921 | validation: 0.18303540711161995]
	TIME [epoch: 7.65 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1477534853443066		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.1477534853443066 | validation: 0.13319599753274936]
	TIME [epoch: 7.63 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13821724218824535		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.13821724218824535 | validation: 0.17702839853858893]
	TIME [epoch: 7.67 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14005090652843347		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.14005090652843347 | validation: 0.14830085507341753]
	TIME [epoch: 7.62 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1506973086785115		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.1506973086785115 | validation: 0.17849369486676125]
	TIME [epoch: 7.64 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13293683813384008		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.13293683813384008 | validation: 0.1365583744498679]
	TIME [epoch: 7.66 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13338930842381008		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.13338930842381008 | validation: 0.14852440632395691]
	TIME [epoch: 7.63 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15394783151321573		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.15394783151321573 | validation: 0.14268626915144544]
	TIME [epoch: 7.62 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1383429172890816		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.1383429172890816 | validation: 0.1392289761326173]
	TIME [epoch: 7.62 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1387428917642306		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.1387428917642306 | validation: 0.15226719842914466]
	TIME [epoch: 7.63 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11836769954884524		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.11836769954884524 | validation: 0.150626539763452]
	TIME [epoch: 7.66 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15428691002885456		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.15428691002885456 | validation: 0.14753069999435395]
	TIME [epoch: 7.61 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1282433775760193		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.1282433775760193 | validation: 0.1395966307394964]
	TIME [epoch: 7.61 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13282505108522502		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.13282505108522502 | validation: 0.12695991097210457]
	TIME [epoch: 7.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_544.pth
	Model improved!!!
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11967916752137193		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.11967916752137193 | validation: 0.12161375665688826]
	TIME [epoch: 7.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_545.pth
	Model improved!!!
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13156219276596848		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.13156219276596848 | validation: 0.12742755620346757]
	TIME [epoch: 7.65 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12320267695916526		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.12320267695916526 | validation: 0.1458722863325965]
	TIME [epoch: 7.6 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12517621320209482		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.12517621320209482 | validation: 0.19397268042149213]
	TIME [epoch: 7.65 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12484060025731084		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.12484060025731084 | validation: 0.14367987244749758]
	TIME [epoch: 7.61 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12705129869879603		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.12705129869879603 | validation: 0.13609408887959729]
	TIME [epoch: 7.6 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11629171068159617		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.11629171068159617 | validation: 0.1267938328805583]
	TIME [epoch: 7.65 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13933535857012164		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.13933535857012164 | validation: 0.14020374101188107]
	TIME [epoch: 7.62 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1281350011664055		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.1281350011664055 | validation: 0.14135231209505203]
	TIME [epoch: 7.61 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13214237335074325		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.13214237335074325 | validation: 0.16654222564208007]
	TIME [epoch: 7.61 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11619249837502225		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.11619249837502225 | validation: 0.11362943617680704]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_555.pth
	Model improved!!!
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12413925313065448		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.12413925313065448 | validation: 0.14476200691323451]
	TIME [epoch: 7.63 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12640406130836357		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.12640406130836357 | validation: 0.1234916425184985]
	TIME [epoch: 7.64 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11876152921537497		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.11876152921537497 | validation: 0.12310356053851251]
	TIME [epoch: 7.61 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12089416572397282		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.12089416572397282 | validation: 0.13514729841337614]
	TIME [epoch: 7.61 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1157124330999327		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.1157124330999327 | validation: 0.13165902087447368]
	TIME [epoch: 7.61 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11678016962526999		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.11678016962526999 | validation: 0.15461070248698147]
	TIME [epoch: 7.61 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13027995969719974		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.13027995969719974 | validation: 0.1299482692407109]
	TIME [epoch: 7.66 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11519372181561824		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.11519372181561824 | validation: 0.13942576849185107]
	TIME [epoch: 7.6 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11205379914931735		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.11205379914931735 | validation: 0.1288707456610854]
	TIME [epoch: 7.61 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11665788825688081		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.11665788825688081 | validation: 0.1246823997494741]
	TIME [epoch: 7.61 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12312535713225822		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.12312535713225822 | validation: 0.11093452644370397]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_566.pth
	Model improved!!!
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10341754421289234		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.10341754421289234 | validation: 0.11272244423947475]
	TIME [epoch: 7.67 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11354714625472442		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.11354714625472442 | validation: 0.14858161020138555]
	TIME [epoch: 7.61 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11046952830217813		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.11046952830217813 | validation: 0.10893493981430943]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_569.pth
	Model improved!!!
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10081538980963642		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.10081538980963642 | validation: 0.12158456649228698]
	TIME [epoch: 7.61 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1028329394104898		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.1028329394104898 | validation: 0.14039120815732678]
	TIME [epoch: 7.62 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11760516243377217		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.11760516243377217 | validation: 0.15599603359193742]
	TIME [epoch: 7.65 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11893045066217948		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.11893045066217948 | validation: 0.11638867250245649]
	TIME [epoch: 7.63 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10285634273699165		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.10285634273699165 | validation: 0.12071558849404465]
	TIME [epoch: 7.61 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10781655061413893		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.10781655061413893 | validation: 0.12390188198887592]
	TIME [epoch: 7.61 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11473938722253185		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.11473938722253185 | validation: 0.10158414750835129]
	TIME [epoch: 7.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_576.pth
	Model improved!!!
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10548468703955813		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.10548468703955813 | validation: 0.12444854927079159]
	TIME [epoch: 7.63 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10975184977666583		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.10975184977666583 | validation: 0.09755899339743479]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_578.pth
	Model improved!!!
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09955301530678241		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.09955301530678241 | validation: 0.12775392085812248]
	TIME [epoch: 7.64 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10214827687831898		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.10214827687831898 | validation: 0.11653899920657683]
	TIME [epoch: 7.64 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09450527707372108		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.09450527707372108 | validation: 0.11806594271013171]
	TIME [epoch: 7.64 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10162071892470505		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.10162071892470505 | validation: 0.1372906558375176]
	TIME [epoch: 7.66 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09950458926476682		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.09950458926476682 | validation: 0.11179938552980859]
	TIME [epoch: 7.67 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10503220874550424		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.10503220874550424 | validation: 0.12569923982541756]
	TIME [epoch: 7.65 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10466823923379318		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.10466823923379318 | validation: 0.09460100276670477]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_585.pth
	Model improved!!!
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09854437624206974		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.09854437624206974 | validation: 0.11883368901609015]
	TIME [epoch: 7.64 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09163522677851846		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.09163522677851846 | validation: 0.10490517802475507]
	TIME [epoch: 7.65 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08932397801356606		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.08932397801356606 | validation: 0.10303343245940733]
	TIME [epoch: 7.71 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10824765926496158		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.10824765926496158 | validation: 0.10139412432646776]
	TIME [epoch: 7.64 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0920731061099729		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.0920731061099729 | validation: 0.10572837815634809]
	TIME [epoch: 7.64 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08785954085905555		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.08785954085905555 | validation: 0.09473001452371527]
	TIME [epoch: 7.62 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10194623831959002		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.10194623831959002 | validation: 0.09595640132234794]
	TIME [epoch: 7.64 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08941526761311286		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.08941526761311286 | validation: 0.10932242049278129]
	TIME [epoch: 7.68 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08879558541595017		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.08879558541595017 | validation: 0.0968207617654665]
	TIME [epoch: 7.65 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0913237949701738		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.0913237949701738 | validation: 0.09536478082035701]
	TIME [epoch: 7.63 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09353045478123209		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.09353045478123209 | validation: 0.1388184864849718]
	TIME [epoch: 7.63 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1081274161719471		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.1081274161719471 | validation: 0.1209296303194366]
	TIME [epoch: 7.63 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08798490468087969		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.08798490468087969 | validation: 0.0922238658336399]
	TIME [epoch: 7.68 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_598.pth
	Model improved!!!
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09185564939731329		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.09185564939731329 | validation: 0.0964403657798347]
	TIME [epoch: 7.63 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08196221683080696		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.08196221683080696 | validation: 0.1371067607433163]
	TIME [epoch: 7.62 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09113849173238273		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.09113849173238273 | validation: 0.10254755179876622]
	TIME [epoch: 7.62 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07877329136262962		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.07877329136262962 | validation: 0.10516064739591642]
	TIME [epoch: 7.62 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08586728629573043		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.08586728629573043 | validation: 0.0926051006765897]
	TIME [epoch: 7.66 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08682962988231484		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.08682962988231484 | validation: 0.10507268628742938]
	TIME [epoch: 7.65 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08130013442180835		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.08130013442180835 | validation: 0.11519082994254873]
	TIME [epoch: 7.63 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0841979132534533		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.0841979132534533 | validation: 0.08848898822988445]
	TIME [epoch: 7.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_606.pth
	Model improved!!!
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07230267491082457		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.07230267491082457 | validation: 0.10355514671749011]
	TIME [epoch: 7.62 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07796928427540946		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.07796928427540946 | validation: 0.09822619526837809]
	TIME [epoch: 7.64 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08130340766740343		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.08130340766740343 | validation: 0.09258647362889189]
	TIME [epoch: 7.64 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0829932524630336		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.0829932524630336 | validation: 0.10760818590009341]
	TIME [epoch: 7.62 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08462609225659368		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.08462609225659368 | validation: 0.08664433148966169]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_611.pth
	Model improved!!!
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07455304254372862		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.07455304254372862 | validation: 0.08346929636744019]
	TIME [epoch: 7.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_612.pth
	Model improved!!!
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07227299024280957		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.07227299024280957 | validation: 0.09921036802325035]
	TIME [epoch: 7.62 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07767716969698792		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.07767716969698792 | validation: 0.09568586877936647]
	TIME [epoch: 7.64 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0725228901683125		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.0725228901683125 | validation: 0.07431193131456669]
	TIME [epoch: 7.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_615.pth
	Model improved!!!
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07789743818151734		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.07789743818151734 | validation: 0.11221261219121922]
	TIME [epoch: 7.59 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10356716147013736		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.10356716147013736 | validation: 0.09887058364319673]
	TIME [epoch: 7.59 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0950209029341288		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.0950209029341288 | validation: 0.0795361153198283]
	TIME [epoch: 7.61 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07923052042004164		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.07923052042004164 | validation: 0.08137642387569455]
	TIME [epoch: 7.71 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07158206087088881		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.07158206087088881 | validation: 0.09001379060908801]
	TIME [epoch: 7.62 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07246191587374158		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.07246191587374158 | validation: 0.07142438855319089]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_621.pth
	Model improved!!!
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06820593881725877		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.06820593881725877 | validation: 0.07450642808682396]
	TIME [epoch: 7.61 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12101563478145025		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.12101563478145025 | validation: 0.09286271844872879]
	TIME [epoch: 7.63 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08188262610249816		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.08188262610249816 | validation: 0.08350445726787586]
	TIME [epoch: 7.65 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0642290816504228		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.0642290816504228 | validation: 0.07934806630515143]
	TIME [epoch: 7.63 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06968129167903217		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.06968129167903217 | validation: 0.07515234863957171]
	TIME [epoch: 7.61 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06558131497762631		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.06558131497762631 | validation: 0.0692963552821957]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_627.pth
	Model improved!!!
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0635097453236761		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.0635097453236761 | validation: 0.07626643175315706]
	TIME [epoch: 7.62 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0711686150251078		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.0711686150251078 | validation: 0.07269073049739153]
	TIME [epoch: 7.65 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06666628470058479		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.06666628470058479 | validation: 0.06955127676469426]
	TIME [epoch: 7.63 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06823051840666805		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.06823051840666805 | validation: 0.06188309322991528]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_631.pth
	Model improved!!!
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06118873155587328		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.06118873155587328 | validation: 0.0674803177591526]
	TIME [epoch: 7.64 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07103832809555322		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.07103832809555322 | validation: 0.0674024203413488]
	TIME [epoch: 7.63 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06467668405199245		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.06467668405199245 | validation: 0.07123464279646304]
	TIME [epoch: 7.68 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0579471284870442		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.0579471284870442 | validation: 0.06494923268651852]
	TIME [epoch: 7.67 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06002450033876448		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.06002450033876448 | validation: 0.10063273994452307]
	TIME [epoch: 7.64 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06915138375036715		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.06915138375036715 | validation: 0.07578264901549514]
	TIME [epoch: 7.66 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06344753338650808		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.06344753338650808 | validation: 0.07972782348930577]
	TIME [epoch: 7.65 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05998953650630882		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.05998953650630882 | validation: 0.06242189975868663]
	TIME [epoch: 7.67 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05621782305025904		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.05621782305025904 | validation: 0.06899144813646801]
	TIME [epoch: 7.69 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060186046897157		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.060186046897157 | validation: 0.06697979114702787]
	TIME [epoch: 7.65 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0572230587245594		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.0572230587245594 | validation: 0.05937921317986282]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_642.pth
	Model improved!!!
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06134064912316138		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.06134064912316138 | validation: 0.07918908771234034]
	TIME [epoch: 7.63 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06273270336593852		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.06273270336593852 | validation: 0.06399192757696233]
	TIME [epoch: 7.64 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09296722500378823		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.09296722500378823 | validation: 0.11802983067484676]
	TIME [epoch: 7.69 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11274843899252722		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.11274843899252722 | validation: 0.10641374375493967]
	TIME [epoch: 7.65 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0739020437172378		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.0739020437172378 | validation: 0.06411519686639124]
	TIME [epoch: 7.63 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055505142293527876		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.055505142293527876 | validation: 0.057851584543563095]
	TIME [epoch: 7.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_648.pth
	Model improved!!!
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053634023322586155		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.053634023322586155 | validation: 0.05653175521481097]
	TIME [epoch: 7.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_649.pth
	Model improved!!!
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050855425941375904		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.050855425941375904 | validation: 0.06706289773877465]
	TIME [epoch: 7.67 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054567829221755196		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.054567829221755196 | validation: 0.06023010536296536]
	TIME [epoch: 7.63 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04865164311163073		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.04865164311163073 | validation: 0.05753161351729637]
	TIME [epoch: 7.62 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052963552850924994		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.052963552850924994 | validation: 0.08396410732694623]
	TIME [epoch: 7.63 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058773664661717004		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.058773664661717004 | validation: 0.05013417718736174]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_654.pth
	Model improved!!!
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05918647254971017		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.05918647254971017 | validation: 0.061593865764179495]
	TIME [epoch: 7.67 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05028667355030708		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.05028667355030708 | validation: 0.057249322517170534]
	TIME [epoch: 7.64 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05438565566450112		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.05438565566450112 | validation: 0.07141722197833045]
	TIME [epoch: 7.62 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057193206966055614		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.057193206966055614 | validation: 0.06675874737447882]
	TIME [epoch: 7.63 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0494972812943883		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.0494972812943883 | validation: 0.051885713258377084]
	TIME [epoch: 7.62 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04751444731638098		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.04751444731638098 | validation: 0.05508606672237562]
	TIME [epoch: 7.65 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0520117224242215		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.0520117224242215 | validation: 0.05338386379122122]
	TIME [epoch: 7.64 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06490105373205639		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.06490105373205639 | validation: 0.06163612525699336]
	TIME [epoch: 7.62 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055049769713707904		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.055049769713707904 | validation: 0.05933781836757951]
	TIME [epoch: 7.62 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04685808552967738		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.04685808552967738 | validation: 0.053745184895766185]
	TIME [epoch: 7.63 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049493142182872533		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.049493142182872533 | validation: 0.05887344865815328]
	TIME [epoch: 7.64 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047274620802611585		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.047274620802611585 | validation: 0.0507891800928544]
	TIME [epoch: 7.66 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050216003204592664		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.050216003204592664 | validation: 0.07272079108709112]
	TIME [epoch: 7.62 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05331202012917175		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.05331202012917175 | validation: 0.0523732660223413]
	TIME [epoch: 7.63 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04579414588925343		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.04579414588925343 | validation: 0.06195563724684672]
	TIME [epoch: 7.62 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05446232211242738		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.05446232211242738 | validation: 0.05901000411066064]
	TIME [epoch: 7.62 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04523051134359084		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.04523051134359084 | validation: 0.051295955972770986]
	TIME [epoch: 7.67 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04897808597376227		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.04897808597376227 | validation: 0.05112306513229898]
	TIME [epoch: 7.63 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04770140695573438		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.04770140695573438 | validation: 0.05683883334392424]
	TIME [epoch: 7.62 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04835998454441598		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.04835998454441598 | validation: 0.05440473007272825]
	TIME [epoch: 7.62 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04414015481523227		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.04414015481523227 | validation: 0.04781304688774694]
	TIME [epoch: 7.68 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_675.pth
	Model improved!!!
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0439261217207471		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.0439261217207471 | validation: 0.05536894763517986]
	TIME [epoch: 7.65 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047175994496634364		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.047175994496634364 | validation: 0.0475577618984971]
	TIME [epoch: 7.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_677.pth
	Model improved!!!
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043016669618558885		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.043016669618558885 | validation: 0.04792627709848932]
	TIME [epoch: 7.61 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05035825084959046		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.05035825084959046 | validation: 0.053478160051572896]
	TIME [epoch: 7.61 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04263106114430708		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.04263106114430708 | validation: 0.07524048964079674]
	TIME [epoch: 7.61 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047941037635057936		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.047941037635057936 | validation: 0.04350154264729677]
	TIME [epoch: 7.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_681.pth
	Model improved!!!
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04567250707275322		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.04567250707275322 | validation: 0.047431480930737964]
	TIME [epoch: 7.63 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04523299180421978		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.04523299180421978 | validation: 0.0454114339369725]
	TIME [epoch: 7.6 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04218489523950071		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.04218489523950071 | validation: 0.058401257631656066]
	TIME [epoch: 7.6 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047847902309143535		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.047847902309143535 | validation: 0.05089121755210947]
	TIME [epoch: 7.6 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03804422013370849		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.03804422013370849 | validation: 0.04672082717803215]
	TIME [epoch: 7.62 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03866047305642218		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.03866047305642218 | validation: 0.042109595635257]
	TIME [epoch: 7.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_687.pth
	Model improved!!!
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04384076718829871		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.04384076718829871 | validation: 0.043947913723412335]
	TIME [epoch: 7.6 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04437632539653522		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.04437632539653522 | validation: 0.04748569849995696]
	TIME [epoch: 7.63 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04196754647178336		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.04196754647178336 | validation: 0.04937128173286995]
	TIME [epoch: 7.63 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04047059036453959		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.04047059036453959 | validation: 0.045886317029199084]
	TIME [epoch: 7.62 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044935449537735345		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.044935449537735345 | validation: 0.0438737669105361]
	TIME [epoch: 7.65 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041011700580027025		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.041011700580027025 | validation: 0.04330258194807811]
	TIME [epoch: 7.61 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04195138181863827		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.04195138181863827 | validation: 0.04798464904218694]
	TIME [epoch: 7.62 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039001743171913		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.039001743171913 | validation: 0.058151713998155365]
	TIME [epoch: 7.63 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047317889961944845		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.047317889961944845 | validation: 0.04721728900315217]
	TIME [epoch: 7.62 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037589885694333185		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.037589885694333185 | validation: 0.04420469229418913]
	TIME [epoch: 7.66 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03526836879059471		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.03526836879059471 | validation: 0.03816423738642148]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_698.pth
	Model improved!!!
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038880982960053996		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.038880982960053996 | validation: 0.04832525606701017]
	TIME [epoch: 7.61 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03778950333085118		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.03778950333085118 | validation: 0.049201785473834456]
	TIME [epoch: 7.61 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040319881066199104		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.040319881066199104 | validation: 0.07910774165287926]
	TIME [epoch: 7.62 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05339383882175172		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.05339383882175172 | validation: 0.037010632864794474]
	TIME [epoch: 7.65 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_702.pth
	Model improved!!!
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03740914261012544		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.03740914261012544 | validation: 0.040916353556091314]
	TIME [epoch: 7.64 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035219933817512816		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.035219933817512816 | validation: 0.04431031170929339]
	TIME [epoch: 7.63 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039952345896572344		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.039952345896572344 | validation: 0.038236887490543645]
	TIME [epoch: 7.64 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036799570005863494		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.036799570005863494 | validation: 0.042718848566500475]
	TIME [epoch: 7.65 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03882760134123138		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.03882760134123138 | validation: 0.04169202585999496]
	TIME [epoch: 7.68 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035429932991626084		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.035429932991626084 | validation: 0.04609667328605793]
	TIME [epoch: 7.66 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040809327643764194		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.040809327643764194 | validation: 0.04027494367502285]
	TIME [epoch: 7.64 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03522733815560035		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.03522733815560035 | validation: 0.05101464759191357]
	TIME [epoch: 7.65 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03564646238354325		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.03564646238354325 | validation: 0.04122262538725324]
	TIME [epoch: 7.64 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041123957005624476		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.041123957005624476 | validation: 0.039217707178587066]
	TIME [epoch: 7.68 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03546363492013217		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.03546363492013217 | validation: 0.0396576031491693]
	TIME [epoch: 7.68 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03301165904539444		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.03301165904539444 | validation: 0.040050393745741236]
	TIME [epoch: 7.65 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033236695769918265		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.033236695769918265 | validation: 0.039118861690275376]
	TIME [epoch: 7.64 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03990494832778019		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.03990494832778019 | validation: 0.04050355692091907]
	TIME [epoch: 7.63 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03329130503621256		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.03329130503621256 | validation: 0.04427005792417475]
	TIME [epoch: 7.65 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033969784243737276		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.033969784243737276 | validation: 0.04035941396785992]
	TIME [epoch: 7.7 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03500546297062367		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.03500546297062367 | validation: 0.04417241363150645]
	TIME [epoch: 7.64 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039488018341147436		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.039488018341147436 | validation: 0.037743344669646864]
	TIME [epoch: 7.64 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03674220778586548		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.03674220778586548 | validation: 0.03979078681840283]
	TIME [epoch: 7.64 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03486728271417653		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.03486728271417653 | validation: 0.03558112933196311]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_722.pth
	Model improved!!!
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034085922194590466		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.034085922194590466 | validation: 0.03917731494553429]
	TIME [epoch: 7.7 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03347386144051201		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.03347386144051201 | validation: 0.037283223837699025]
	TIME [epoch: 7.64 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0330743871817553		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.0330743871817553 | validation: 0.03883592390993068]
	TIME [epoch: 7.63 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03165354164159946		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.03165354164159946 | validation: 0.04697612424533455]
	TIME [epoch: 7.64 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035434621505099226		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.035434621505099226 | validation: 0.03382963912841078]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_727.pth
	Model improved!!!
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03575594102429505		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.03575594102429505 | validation: 0.04364173443918136]
	TIME [epoch: 7.67 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0399329200297905		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.0399329200297905 | validation: 0.039673608523875636]
	TIME [epoch: 7.64 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03260667994405829		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.03260667994405829 | validation: 0.0336705113737777]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_730.pth
	Model improved!!!
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03291076629396757		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.03291076629396757 | validation: 0.03861487452340505]
	TIME [epoch: 7.62 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029001173075096073		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.029001173075096073 | validation: 0.03953543662536043]
	TIME [epoch: 7.63 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03177239977388076		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.03177239977388076 | validation: 0.035418930203364694]
	TIME [epoch: 7.66 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03279201416640498		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.03279201416640498 | validation: 0.037275880999233665]
	TIME [epoch: 7.65 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037015270531685816		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.037015270531685816 | validation: 0.03712820638723342]
	TIME [epoch: 7.61 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03029054054116645		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.03029054054116645 | validation: 0.03266827890895367]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_736.pth
	Model improved!!!
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03387483422270151		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.03387483422270151 | validation: 0.040919042408008574]
	TIME [epoch: 7.62 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03346735481633414		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.03346735481633414 | validation: 0.03246056049539589]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_738.pth
	Model improved!!!
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03204515821411031		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.03204515821411031 | validation: 0.037704485784679484]
	TIME [epoch: 7.65 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032721790020454083		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.032721790020454083 | validation: 0.04148238087107241]
	TIME [epoch: 7.61 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02981372702033171		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.02981372702033171 | validation: 0.03492309973611611]
	TIME [epoch: 7.61 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03322515414436075		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.03322515414436075 | validation: 0.03920432146640487]
	TIME [epoch: 7.61 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02956030453400956		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.02956030453400956 | validation: 0.03521332385901684]
	TIME [epoch: 7.62 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03242127698076276		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.03242127698076276 | validation: 0.03620650965055673]
	TIME [epoch: 7.65 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031676426714898995		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.031676426714898995 | validation: 0.033427998550516966]
	TIME [epoch: 7.61 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0303830251682705		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.0303830251682705 | validation: 0.038486773846094]
	TIME [epoch: 7.61 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03054585636556107		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.03054585636556107 | validation: 0.03286454449334184]
	TIME [epoch: 7.6 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031725236630768795		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.031725236630768795 | validation: 0.03836708161318672]
	TIME [epoch: 7.61 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029856961749394832		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.029856961749394832 | validation: 0.032988503387204035]
	TIME [epoch: 7.67 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029257906237817752		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.029257906237817752 | validation: 0.03483507364263906]
	TIME [epoch: 7.62 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03304343793016995		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.03304343793016995 | validation: 0.03836581058741885]
	TIME [epoch: 7.62 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03045513033388922		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.03045513033388922 | validation: 0.03341454868480073]
	TIME [epoch: 7.61 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032826259165752596		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.032826259165752596 | validation: 0.03443443926229206]
	TIME [epoch: 7.6 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030758146894320125		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.030758146894320125 | validation: 0.033651807188029556]
	TIME [epoch: 7.64 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029513353389624606		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.029513353389624606 | validation: 0.04306820582105205]
	TIME [epoch: 7.62 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02919955650354885		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.02919955650354885 | validation: 0.029968583507782108]
	TIME [epoch: 7.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_756.pth
	Model improved!!!
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028130192857184856		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.028130192857184856 | validation: 0.03464534129154582]
	TIME [epoch: 7.6 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028964195495811685		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.028964195495811685 | validation: 0.03836932580331762]
	TIME [epoch: 7.6 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02994174448054585		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.02994174448054585 | validation: 0.03443998895625267]
	TIME [epoch: 7.62 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028028509343393675		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.028028509343393675 | validation: 0.03300641904185326]
	TIME [epoch: 7.67 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029666825781964286		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.029666825781964286 | validation: 0.03774219604321467]
	TIME [epoch: 7.64 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03139385890108398		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.03139385890108398 | validation: 0.034829936452802024]
	TIME [epoch: 7.62 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02853326198191208		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.02853326198191208 | validation: 0.03446914890673282]
	TIME [epoch: 7.61 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029438114158320226		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.029438114158320226 | validation: 0.03443585021447681]
	TIME [epoch: 7.62 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025930650807338695		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.025930650807338695 | validation: 0.03445485578069846]
	TIME [epoch: 7.66 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027546571522337613		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.027546571522337613 | validation: 0.03319248297031682]
	TIME [epoch: 7.62 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025393884092737642		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.025393884092737642 | validation: 0.031032133513088145]
	TIME [epoch: 7.62 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028262847784383066		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.028262847784383066 | validation: 0.034875302295178476]
	TIME [epoch: 7.61 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024961095089165875		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.024961095089165875 | validation: 0.03090160366770963]
	TIME [epoch: 7.61 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030587947216050633		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.030587947216050633 | validation: 0.03958844604776922]
	TIME [epoch: 7.65 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031462916758079246		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.031462916758079246 | validation: 0.032752029382795325]
	TIME [epoch: 7.62 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025011840911768102		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.025011840911768102 | validation: 0.03192560529487379]
	TIME [epoch: 7.61 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02800892839707488		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.02800892839707488 | validation: 0.032627446555320516]
	TIME [epoch: 7.62 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026140999222633955		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.026140999222633955 | validation: 0.029126402076644582]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_774.pth
	Model improved!!!
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024883635163303504		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.024883635163303504 | validation: 0.02933577376291797]
	TIME [epoch: 7.66 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026949600073636823		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.026949600073636823 | validation: 0.04162485180897442]
	TIME [epoch: 7.63 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029440493480014207		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.029440493480014207 | validation: 0.035662484993538794]
	TIME [epoch: 7.62 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02651105094066013		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.02651105094066013 | validation: 0.029354923405298182]
	TIME [epoch: 7.62 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026120469192878956		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.026120469192878956 | validation: 0.03179122797211058]
	TIME [epoch: 7.62 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02995420693664428		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.02995420693664428 | validation: 0.03451426581887362]
	TIME [epoch: 7.64 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027248165726697235		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.027248165726697235 | validation: 0.03403449743653426]
	TIME [epoch: 7.65 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025792309104413824		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.025792309104413824 | validation: 0.029492826472935916]
	TIME [epoch: 7.61 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026950240574872834		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.026950240574872834 | validation: 0.03412406294067239]
	TIME [epoch: 7.61 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028439018597465907		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.028439018597465907 | validation: 0.029474189810546475]
	TIME [epoch: 7.61 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026409708199450828		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.026409708199450828 | validation: 0.02960168556608299]
	TIME [epoch: 7.62 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026408880539254498		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.026408880539254498 | validation: 0.029431203395620206]
	TIME [epoch: 7.65 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02400118968140525		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.02400118968140525 | validation: 0.031389734415134575]
	TIME [epoch: 7.61 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03229061957792939		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.03229061957792939 | validation: 0.043403855552582]
	TIME [epoch: 7.67 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028928392067027683		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.028928392067027683 | validation: 0.03046616372653955]
	TIME [epoch: 7.62 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02612164759419483		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.02612164759419483 | validation: 0.03098033436385849]
	TIME [epoch: 7.61 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02566148924649797		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.02566148924649797 | validation: 0.0350565243409635]
	TIME [epoch: 7.66 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026829308329201128		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.026829308329201128 | validation: 0.029029141489802887]
	TIME [epoch: 7.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_792.pth
	Model improved!!!
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02426409388311372		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.02426409388311372 | validation: 0.031162571566273126]
	TIME [epoch: 7.62 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031127378982969807		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.031127378982969807 | validation: 0.02869578848510211]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_794.pth
	Model improved!!!
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02378192704314719		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.02378192704314719 | validation: 0.026321976696955438]
	TIME [epoch: 7.59 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_795.pth
	Model improved!!!
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023759322944046188		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.023759322944046188 | validation: 0.0306866824228499]
	TIME [epoch: 7.65 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025193594641968194		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.025193594641968194 | validation: 0.02905797383719431]
	TIME [epoch: 7.62 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025660749793993506		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.025660749793993506 | validation: 0.027099410344654837]
	TIME [epoch: 7.59 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02426353084782701		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.02426353084782701 | validation: 0.030534569594240973]
	TIME [epoch: 7.59 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025902575068960522		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.025902575068960522 | validation: 0.03075311361432644]
	TIME [epoch: 7.58 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025318191741729848		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.025318191741729848 | validation: 0.029619317806793034]
	TIME [epoch: 7.68 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026359578384337213		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.026359578384337213 | validation: 0.028520730174817696]
	TIME [epoch: 7.66 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025621554850478657		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.025621554850478657 | validation: 0.029233964791428126]
	TIME [epoch: 7.63 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028020372506246755		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.028020372506246755 | validation: 0.027933619213807763]
	TIME [epoch: 7.63 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023805220513679178		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.023805220513679178 | validation: 0.02624494208799194]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_805.pth
	Model improved!!!
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02473050195235345		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.02473050195235345 | validation: 0.03220974882543715]
	TIME [epoch: 7.65 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027680218665513984		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.027680218665513984 | validation: 0.02896144205060356]
	TIME [epoch: 7.69 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024630107121879224		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.024630107121879224 | validation: 0.028897888469267947]
	TIME [epoch: 7.64 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022654513614809888		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.022654513614809888 | validation: 0.02695799263484743]
	TIME [epoch: 7.64 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024499461851754188		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.024499461851754188 | validation: 0.03259427384320776]
	TIME [epoch: 7.64 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023760141567017348		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.023760141567017348 | validation: 0.02923118325437262]
	TIME [epoch: 7.65 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026289382961924648		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.026289382961924648 | validation: 0.026223485847391398]
	TIME [epoch: 7.67 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_812.pth
	Model improved!!!
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023886568032072654		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.023886568032072654 | validation: 0.031228987749907504]
	TIME [epoch: 7.62 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023664906553711673		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.023664906553711673 | validation: 0.030053017662279278]
	TIME [epoch: 7.63 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02533231099629102		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.02533231099629102 | validation: 0.02819053635353947]
	TIME [epoch: 7.63 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023012970082502436		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.023012970082502436 | validation: 0.029649583340716157]
	TIME [epoch: 7.62 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022659989660208865		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.022659989660208865 | validation: 0.026814491881383427]
	TIME [epoch: 7.67 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025121860562551824		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.025121860562551824 | validation: 0.02743767104597977]
	TIME [epoch: 7.63 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02486612137487359		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.02486612137487359 | validation: 0.026297426645371234]
	TIME [epoch: 7.62 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02339059846276503		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.02339059846276503 | validation: 0.027095474342722428]
	TIME [epoch: 7.61 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022237044819883502		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.022237044819883502 | validation: 0.028229947969003306]
	TIME [epoch: 7.63 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02420943717701479		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.02420943717701479 | validation: 0.034154026958842384]
	TIME [epoch: 7.67 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02394214938309739		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.02394214938309739 | validation: 0.030016956026457584]
	TIME [epoch: 7.63 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024484041493755437		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.024484041493755437 | validation: 0.026753354552226678]
	TIME [epoch: 7.61 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02585140987639928		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.02585140987639928 | validation: 0.04389494917778987]
	TIME [epoch: 7.61 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027336379367812115		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.027336379367812115 | validation: 0.03237633393236207]
	TIME [epoch: 7.61 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023244085530993323		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.023244085530993323 | validation: 0.027128929978903763]
	TIME [epoch: 7.64 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022345474608453444		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.022345474608453444 | validation: 0.03463906244076062]
	TIME [epoch: 7.65 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024170236971841282		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.024170236971841282 | validation: 0.026432246443413594]
	TIME [epoch: 7.61 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021539938966937604		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.021539938966937604 | validation: 0.030929986183448]
	TIME [epoch: 7.6 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025029364002088023		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.025029364002088023 | validation: 0.028914146629268955]
	TIME [epoch: 7.68 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02251541016127246		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.02251541016127246 | validation: 0.02705779451284194]
	TIME [epoch: 7.64 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02159634792454251		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.02159634792454251 | validation: 0.02681625712847243]
	TIME [epoch: 7.68 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023771810072300104		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.023771810072300104 | validation: 0.02602269832032378]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_834.pth
	Model improved!!!
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02132381434760431		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.02132381434760431 | validation: 0.02844422567649372]
	TIME [epoch: 7.62 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023329029380857735		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.023329029380857735 | validation: 0.027783551675392232]
	TIME [epoch: 7.62 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021564121727429577		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.021564121727429577 | validation: 0.025898091597276962]
	TIME [epoch: 7.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_837.pth
	Model improved!!!
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023599719438083304		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.023599719438083304 | validation: 0.03054451951273337]
	TIME [epoch: 7.66 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023723301758468034		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.023723301758468034 | validation: 0.026858194891168464]
	TIME [epoch: 7.62 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022148072089711084		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.022148072089711084 | validation: 0.02914200186078421]
	TIME [epoch: 7.61 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022784278972204926		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.022784278972204926 | validation: 0.0257055858959774]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_841.pth
	Model improved!!!
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021426448326321745		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.021426448326321745 | validation: 0.026873494344381736]
	TIME [epoch: 7.62 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024637476839560826		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.024637476839560826 | validation: 0.02914727634248924]
	TIME [epoch: 7.66 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023259313039685307		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.023259313039685307 | validation: 0.028073172100305015]
	TIME [epoch: 7.61 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022073499142262542		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.022073499142262542 | validation: 0.027261944257176242]
	TIME [epoch: 7.61 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021949617267113246		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.021949617267113246 | validation: 0.030867067466667144]
	TIME [epoch: 7.61 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024710936336030578		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.024710936336030578 | validation: 0.026326460659940078]
	TIME [epoch: 7.61 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021692665488512668		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.021692665488512668 | validation: 0.02377273731480583]
	TIME [epoch: 7.65 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_848.pth
	Model improved!!!
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022893892633857663		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.022893892633857663 | validation: 0.02825706874537727]
	TIME [epoch: 7.63 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021353338272750787		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.021353338272750787 | validation: 0.029831689490280956]
	TIME [epoch: 7.61 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023488163743643594		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.023488163743643594 | validation: 0.024660565183566623]
	TIME [epoch: 7.61 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02193666402828063		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.02193666402828063 | validation: 0.025250610942897565]
	TIME [epoch: 7.61 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021703072622770474		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.021703072622770474 | validation: 0.02986362943271631]
	TIME [epoch: 7.63 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024101248740805367		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.024101248740805367 | validation: 0.029500577008333657]
	TIME [epoch: 7.65 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022983884182547328		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.022983884182547328 | validation: 0.026303987156189784]
	TIME [epoch: 7.62 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02103993049576916		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.02103993049576916 | validation: 0.025776789368817096]
	TIME [epoch: 7.62 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02053532555097979		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.02053532555097979 | validation: 0.027713288330098215]
	TIME [epoch: 7.61 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024560638727552268		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.024560638727552268 | validation: 0.030144379446154855]
	TIME [epoch: 7.62 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021904984810647433		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.021904984810647433 | validation: 0.025719914966630047]
	TIME [epoch: 7.66 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022398457713847533		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.022398457713847533 | validation: 0.026581894965395446]
	TIME [epoch: 7.62 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02252083272686843		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.02252083272686843 | validation: 0.027808022291080238]
	TIME [epoch: 7.6 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02174012566452418		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.02174012566452418 | validation: 0.026355750616795803]
	TIME [epoch: 7.61 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02111753514268192		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.02111753514268192 | validation: 0.026319836890023072]
	TIME [epoch: 7.61 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022077696368399402		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.022077696368399402 | validation: 0.026906639959394144]
	TIME [epoch: 7.65 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021369008714216042		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.021369008714216042 | validation: 0.02547034088941027]
	TIME [epoch: 7.63 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02153825300774312		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.02153825300774312 | validation: 0.029475969577693523]
	TIME [epoch: 7.61 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020763733487081187		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.020763733487081187 | validation: 0.025565092293758446]
	TIME [epoch: 7.6 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021219525907373988		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.021219525907373988 | validation: 0.023001394439867335]
	TIME [epoch: 7.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_868.pth
	Model improved!!!
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021176965137649797		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.021176965137649797 | validation: 0.0243606105438541]
	TIME [epoch: 7.64 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01987645319762868		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.01987645319762868 | validation: 0.02521123279433937]
	TIME [epoch: 7.63 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022307694262015076		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.022307694262015076 | validation: 0.025713113555010342]
	TIME [epoch: 7.62 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022451683387328707		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.022451683387328707 | validation: 0.02671691742205963]
	TIME [epoch: 7.61 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02047383638002325		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.02047383638002325 | validation: 0.02506204199298253]
	TIME [epoch: 7.61 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02233753612121634		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.02233753612121634 | validation: 0.025504567870851216]
	TIME [epoch: 7.63 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020155608217370502		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.020155608217370502 | validation: 0.025102559663378383]
	TIME [epoch: 7.65 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0206394207266156		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.0206394207266156 | validation: 0.023655451634040404]
	TIME [epoch: 7.61 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020380895871192697		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.020380895871192697 | validation: 0.0265049780599484]
	TIME [epoch: 7.61 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021631826869628876		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.021631826869628876 | validation: 0.02694059579600032]
	TIME [epoch: 7.61 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021122256888720048		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.021122256888720048 | validation: 0.02879176221448499]
	TIME [epoch: 7.62 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021144911344322947		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.021144911344322947 | validation: 0.02339880628970918]
	TIME [epoch: 7.66 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02093356961167476		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.02093356961167476 | validation: 0.023706790321298375]
	TIME [epoch: 7.62 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021696243093663484		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.021696243093663484 | validation: 0.025365634619225193]
	TIME [epoch: 7.64 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02006345511549748		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.02006345511549748 | validation: 0.025111913587878818]
	TIME [epoch: 7.62 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021662686784750092		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.021662686784750092 | validation: 0.02410961300311041]
	TIME [epoch: 7.62 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020433804461902398		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.020433804461902398 | validation: 0.02470235559214152]
	TIME [epoch: 7.65 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02040891729853847		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.02040891729853847 | validation: 0.043249319070784525]
	TIME [epoch: 7.62 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030556933448927324		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.030556933448927324 | validation: 0.02624200287984277]
	TIME [epoch: 7.61 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021948576093612053		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.021948576093612053 | validation: 0.024283329509588163]
	TIME [epoch: 7.61 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01933158834487689		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.01933158834487689 | validation: 0.024228781327007412]
	TIME [epoch: 7.61 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01880462851431904		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.01880462851431904 | validation: 0.02405738310721679]
	TIME [epoch: 7.62 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021623027653299477		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.021623027653299477 | validation: 0.02422095907152471]
	TIME [epoch: 7.64 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020118279821843145		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.020118279821843145 | validation: 0.022533237390269294]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_892.pth
	Model improved!!!
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0198687852200756		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.0198687852200756 | validation: 0.025013960645914594]
	TIME [epoch: 7.59 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020360881687665856		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.020360881687665856 | validation: 0.02652441935049664]
	TIME [epoch: 7.58 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021168594945638178		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.021168594945638178 | validation: 0.02521694107609119]
	TIME [epoch: 7.61 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02007553697674299		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.02007553697674299 | validation: 0.024007542818380766]
	TIME [epoch: 7.62 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020816094582179798		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.020816094582179798 | validation: 0.02449461536207566]
	TIME [epoch: 7.59 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020607849895968113		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.020607849895968113 | validation: 0.023706643550502005]
	TIME [epoch: 7.58 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019716980244630842		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.019716980244630842 | validation: 0.0225802984597359]
	TIME [epoch: 7.58 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019300297486501115		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.019300297486501115 | validation: 0.023375829900533465]
	TIME [epoch: 7.59 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020309555438329248		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.020309555438329248 | validation: 0.024649643157539366]
	TIME [epoch: 7.65 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019472490664498143		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.019472490664498143 | validation: 0.025932949518166225]
	TIME [epoch: 7.65 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021233952092415773		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.021233952092415773 | validation: 0.026363687678558397]
	TIME [epoch: 7.59 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020500883220200338		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.020500883220200338 | validation: 0.024268413679634945]
	TIME [epoch: 7.6 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020574497713468164		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.020574497713468164 | validation: 0.02566800112422471]
	TIME [epoch: 7.6 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02195779277368674		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.02195779277368674 | validation: 0.023640718670517223]
	TIME [epoch: 7.64 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02012511105757972		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.02012511105757972 | validation: 0.025270564418492916]
	TIME [epoch: 7.61 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01989855800825531		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.01989855800825531 | validation: 0.02315726783454084]
	TIME [epoch: 7.6 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01906217415088262		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.01906217415088262 | validation: 0.02365261464271197]
	TIME [epoch: 7.59 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019462831064954483		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.019462831064954483 | validation: 0.02938539830218133]
	TIME [epoch: 7.59 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02211502581481604		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.02211502581481604 | validation: 0.02298546471313484]
	TIME [epoch: 7.61 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01978725303040836		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.01978725303040836 | validation: 0.024022426102917264]
	TIME [epoch: 7.63 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019403995667234296		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.019403995667234296 | validation: 0.022528331947788763]
	TIME [epoch: 7.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_913.pth
	Model improved!!!
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020282259049540924		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.020282259049540924 | validation: 0.02296034605895704]
	TIME [epoch: 7.64 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019596153084602802		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.019596153084602802 | validation: 0.023138145797953563]
	TIME [epoch: 7.64 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01977628601536391		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.01977628601536391 | validation: 0.02303820637153707]
	TIME [epoch: 7.67 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01915233985128519		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.01915233985128519 | validation: 0.023295687554819436]
	TIME [epoch: 7.68 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020683392432761707		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.020683392432761707 | validation: 0.027753889205255337]
	TIME [epoch: 7.64 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019576757599178686		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.019576757599178686 | validation: 0.023348337660362203]
	TIME [epoch: 7.64 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01907640442565853		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.01907640442565853 | validation: 0.021999834676883594]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_920.pth
	Model improved!!!
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019258200804805375		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.019258200804805375 | validation: 0.024099187684236655]
	TIME [epoch: 7.64 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019949419114149686		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.019949419114149686 | validation: 0.02307068816669336]
	TIME [epoch: 7.67 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019254304755084196		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.019254304755084196 | validation: 0.025249683126770926]
	TIME [epoch: 7.64 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01973714610868956		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.01973714610868956 | validation: 0.025810473985282863]
	TIME [epoch: 7.63 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019627296357227115		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.019627296357227115 | validation: 0.02174392148937062]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_925.pth
	Model improved!!!
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019618525337225315		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.019618525337225315 | validation: 0.025119227049551312]
	TIME [epoch: 7.63 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019972550078680245		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.019972550078680245 | validation: 0.023119974702080527]
	TIME [epoch: 7.67 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018792651519139923		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.018792651519139923 | validation: 0.025447743781782002]
	TIME [epoch: 7.63 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019099661581765254		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.019099661581765254 | validation: 0.022519100610942644]
	TIME [epoch: 7.64 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01888319701348366		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.01888319701348366 | validation: 0.022124041660371067]
	TIME [epoch: 7.62 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018715916557293797		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.018715916557293797 | validation: 0.025555730180294094]
	TIME [epoch: 7.64 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019070542837994277		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.019070542837994277 | validation: 0.025055773340301138]
	TIME [epoch: 7.67 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02040496202154589		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.02040496202154589 | validation: 0.021461996210249704]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_933.pth
	Model improved!!!
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01870124697920563		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.01870124697920563 | validation: 0.02494864445313391]
	TIME [epoch: 7.61 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018835539064245007		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.018835539064245007 | validation: 0.02363018100478373]
	TIME [epoch: 7.62 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01964885433663344		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.01964885433663344 | validation: 0.022292826572149812]
	TIME [epoch: 7.62 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018611723149218218		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.018611723149218218 | validation: 0.02258618343443363]
	TIME [epoch: 7.65 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019166763406628		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.019166763406628 | validation: 0.022913546048109787]
	TIME [epoch: 7.65 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01956885588417214		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.01956885588417214 | validation: 0.023799788827964526]
	TIME [epoch: 7.61 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019915897346677754		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.019915897346677754 | validation: 0.022093928196178864]
	TIME [epoch: 7.62 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018523857578586364		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.018523857578586364 | validation: 0.022531495288542813]
	TIME [epoch: 7.67 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019792428116496483		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.019792428116496483 | validation: 0.02385797007484671]
	TIME [epoch: 7.64 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019856426047493853		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.019856426047493853 | validation: 0.028233593215681065]
	TIME [epoch: 7.66 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020801356482722477		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.020801356482722477 | validation: 0.022366960606169408]
	TIME [epoch: 7.63 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019592416095269138		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.019592416095269138 | validation: 0.024482257981881025]
	TIME [epoch: 7.63 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019385715020112475		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.019385715020112475 | validation: 0.0229230715334902]
	TIME [epoch: 7.62 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018929266758156732		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.018929266758156732 | validation: 0.023695877376947012]
	TIME [epoch: 7.62 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017882021445903867		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.017882021445903867 | validation: 0.021049074707113195]
	TIME [epoch: 7.67 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_948.pth
	Model improved!!!
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020125758584597045		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.020125758584597045 | validation: 0.022448330278991797]
	TIME [epoch: 7.62 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019436712793179628		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.019436712793179628 | validation: 0.023301267300226452]
	TIME [epoch: 7.62 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01907381367736727		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.01907381367736727 | validation: 0.022435782436673962]
	TIME [epoch: 7.62 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0184838663779145		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.0184838663779145 | validation: 0.023007840640051742]
	TIME [epoch: 7.62 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019114834963232297		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.019114834963232297 | validation: 0.021933304565964873]
	TIME [epoch: 7.66 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01796027746380866		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.01796027746380866 | validation: 0.021957598253164148]
	TIME [epoch: 7.63 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018298448134993872		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.018298448134993872 | validation: 0.0219590070783393]
	TIME [epoch: 7.61 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018330419272501834		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.018330419272501834 | validation: 0.021726831253495556]
	TIME [epoch: 7.63 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018662778691266865		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.018662778691266865 | validation: 0.022785667235586372]
	TIME [epoch: 7.61 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01931749702440453		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.01931749702440453 | validation: 0.02692336062301698]
	TIME [epoch: 7.64 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0196124463693464		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.0196124463693464 | validation: 0.02295186075936194]
	TIME [epoch: 7.66 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018098243401092413		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.018098243401092413 | validation: 0.021807462552823516]
	TIME [epoch: 7.64 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018464995122030405		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.018464995122030405 | validation: 0.02116581404240208]
	TIME [epoch: 7.62 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019892813971899213		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.019892813971899213 | validation: 0.023168606795028617]
	TIME [epoch: 7.61 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018828685880284315		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.018828685880284315 | validation: 0.021672523460339585]
	TIME [epoch: 7.63 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017676522761842887		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.017676522761842887 | validation: 0.022751517388133486]
	TIME [epoch: 7.67 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018590109467684173		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.018590109467684173 | validation: 0.022199064446459436]
	TIME [epoch: 7.6 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018371021612501356		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.018371021612501356 | validation: 0.022624756213901524]
	TIME [epoch: 7.6 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018306789876730782		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.018306789876730782 | validation: 0.022104943205181894]
	TIME [epoch: 7.6 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018714295900377955		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.018714295900377955 | validation: 0.02112325325209078]
	TIME [epoch: 7.6 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018200476555464036		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.018200476555464036 | validation: 0.023119216980125378]
	TIME [epoch: 7.65 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017864616465035413		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.017864616465035413 | validation: 0.021335243138086782]
	TIME [epoch: 7.61 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018430233677698395		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.018430233677698395 | validation: 0.022828055625603874]
	TIME [epoch: 7.61 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018956169636426507		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.018956169636426507 | validation: 0.02306970891348595]
	TIME [epoch: 7.61 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018035350923889436		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.018035350923889436 | validation: 0.022624510295199088]
	TIME [epoch: 7.66 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018585908189858693		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.018585908189858693 | validation: 0.021807113847492256]
	TIME [epoch: 7.66 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018161987817417055		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.018161987817417055 | validation: 0.022158960931937623]
	TIME [epoch: 7.64 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01834343844409955		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.01834343844409955 | validation: 0.023657304470684884]
	TIME [epoch: 7.62 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017741864421862465		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.017741864421862465 | validation: 0.02084270337785093]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_977.pth
	Model improved!!!
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01866331111114737		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.01866331111114737 | validation: 0.024499627988062087]
	TIME [epoch: 7.61 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01912792886668874		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.01912792886668874 | validation: 0.020795054599033747]
	TIME [epoch: 7.65 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_979.pth
	Model improved!!!
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017642670095323623		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.017642670095323623 | validation: 0.02505345605205149]
	TIME [epoch: 7.64 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018953244450215893		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.018953244450215893 | validation: 0.024292151421809807]
	TIME [epoch: 7.61 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019129415857526658		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.019129415857526658 | validation: 0.022784093717648474]
	TIME [epoch: 7.61 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018190332293864887		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.018190332293864887 | validation: 0.02112692414260104]
	TIME [epoch: 7.61 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01724591671958918		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.01724591671958918 | validation: 0.02189381082010755]
	TIME [epoch: 7.63 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017530389621392264		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.017530389621392264 | validation: 0.02353663927004858]
	TIME [epoch: 7.65 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01942948940699678		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.01942948940699678 | validation: 0.021769832713206226]
	TIME [epoch: 7.61 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018332261882388318		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.018332261882388318 | validation: 0.02283573180655732]
	TIME [epoch: 7.6 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018031229950377585		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.018031229950377585 | validation: 0.021109802449265587]
	TIME [epoch: 7.61 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01738174404708675		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.01738174404708675 | validation: 0.02142601163491937]
	TIME [epoch: 7.62 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017705379768759397		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.017705379768759397 | validation: 0.022232346337096094]
	TIME [epoch: 7.66 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019140937103868716		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.019140937103868716 | validation: 0.021109707715964248]
	TIME [epoch: 7.61 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01778694108175362		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.01778694108175362 | validation: 0.020902332230822523]
	TIME [epoch: 7.6 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017222950975243557		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.017222950975243557 | validation: 0.02187588624979754]
	TIME [epoch: 7.61 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0180750251730821		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.0180750251730821 | validation: 0.022211181205751246]
	TIME [epoch: 7.61 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017345029399955934		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.017345029399955934 | validation: 0.023325043732071532]
	TIME [epoch: 7.65 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01735948349430347		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.01735948349430347 | validation: 0.022451783406824848]
	TIME [epoch: 7.62 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017632192391714756		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.017632192391714756 | validation: 0.02180244959830526]
	TIME [epoch: 7.6 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01818433420367193		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.01818433420367193 | validation: 0.022575430542792534]
	TIME [epoch: 7.6 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01839642929356312		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.01839642929356312 | validation: 0.020764739171360104]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_999.pth
	Model improved!!!
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01752162111620881		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.01752162111620881 | validation: 0.0234163406633338]
	TIME [epoch: 7.62 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017121775584664906		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.017121775584664906 | validation: 0.02155215015986555]
	TIME [epoch: 7.64 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01729857516581649		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.01729857516581649 | validation: 0.020680956579449353]
	TIME [epoch: 7.6 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_1002.pth
	Model improved!!!
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01740717861890071		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.01740717861890071 | validation: 0.02149670051961213]
	TIME [epoch: 7.59 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01745041133809256		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.01745041133809256 | validation: 0.02154417060486196]
	TIME [epoch: 7.58 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017768555133905843		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.017768555133905843 | validation: 0.020629406812333592]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_1005.pth
	Model improved!!!
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0175004113953363		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.0175004113953363 | validation: 0.02130286805724415]
	TIME [epoch: 7.63 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0187243938577123		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.0187243938577123 | validation: 0.021754480198384586]
	TIME [epoch: 7.59 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01763395000638308		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.01763395000638308 | validation: 0.020272446351166075]
	TIME [epoch: 7.59 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_1008.pth
	Model improved!!!
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01791831661497826		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.01791831661497826 | validation: 0.020884980586919545]
	TIME [epoch: 7.64 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017254865951891834		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.017254865951891834 | validation: 0.022093893582496353]
	TIME [epoch: 7.67 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017184833806635977		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.017184833806635977 | validation: 0.021625654984777462]
	TIME [epoch: 7.67 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01856244756588525		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.01856244756588525 | validation: 0.020811055299666273]
	TIME [epoch: 7.62 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01733298379486979		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.01733298379486979 | validation: 0.021131814886917386]
	TIME [epoch: 7.64 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016697260645759993		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.016697260645759993 | validation: 0.021797259169012418]
	TIME [epoch: 7.63 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01723077874104667		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.01723077874104667 | validation: 0.025509472402118726]
	TIME [epoch: 7.64 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025005165420145088		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.025005165420145088 | validation: 0.022465306671415174]
	TIME [epoch: 7.68 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01877779150751652		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.01877779150751652 | validation: 0.021424513466418695]
	TIME [epoch: 7.63 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01744137202024477		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.01744137202024477 | validation: 0.021061209631760724]
	TIME [epoch: 7.63 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016846541809614216		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.016846541809614216 | validation: 0.020931037847779846]
	TIME [epoch: 7.63 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016869272352620594		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.016869272352620594 | validation: 0.021862964710305743]
	TIME [epoch: 7.63 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017832543759512157		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.017832543759512157 | validation: 0.021880916409730077]
	TIME [epoch: 7.68 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016883813073392467		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.016883813073392467 | validation: 0.023101203888463165]
	TIME [epoch: 7.64 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01755234238087617		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.01755234238087617 | validation: 0.020799872224062026]
	TIME [epoch: 7.63 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017601748905618386		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.017601748905618386 | validation: 0.02149917701983258]
	TIME [epoch: 7.62 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017141009457193768		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.017141009457193768 | validation: 0.020672078518818866]
	TIME [epoch: 7.63 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016760650076292048		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.016760650076292048 | validation: 0.020021870350885207]
	TIME [epoch: 7.65 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_1026.pth
	Model improved!!!
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01735747552128207		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.01735747552128207 | validation: 0.022222706471305538]
	TIME [epoch: 7.67 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01745535116122675		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.01745535116122675 | validation: 0.020348597006804595]
	TIME [epoch: 7.62 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017312815550649428		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.017312815550649428 | validation: 0.019626714328174956]
	TIME [epoch: 7.63 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_1029.pth
	Model improved!!!
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017299388585636483		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.017299388585636483 | validation: 0.020861420060298706]
	TIME [epoch: 7.63 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016743999170500193		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.016743999170500193 | validation: 0.02076672753279607]
	TIME [epoch: 7.64 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01725044286786692		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.01725044286786692 | validation: 0.01991261638265536]
	TIME [epoch: 7.66 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01702965075584572		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.01702965075584572 | validation: 0.020788289273345695]
	TIME [epoch: 7.62 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016961556799576963		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.016961556799576963 | validation: 0.021175918893632184]
	TIME [epoch: 7.62 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01768084435693543		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.01768084435693543 | validation: 0.020754809480964323]
	TIME [epoch: 7.62 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0175416736480116		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.0175416736480116 | validation: 0.020820880261761664]
	TIME [epoch: 7.61 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018033317371061956		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.018033317371061956 | validation: 0.025220365806766235]
	TIME [epoch: 7.7 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019761812242540634		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.019761812242540634 | validation: 0.023132374343016855]
	TIME [epoch: 7.61 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01674598004067028		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.01674598004067028 | validation: 0.020788928651676065]
	TIME [epoch: 7.61 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016844781779900547		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.016844781779900547 | validation: 0.02151893926418348]
	TIME [epoch: 7.6 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0170540823832896		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.0170540823832896 | validation: 0.020865715263010842]
	TIME [epoch: 7.61 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016493792301089452		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.016493792301089452 | validation: 0.01978158680977231]
	TIME [epoch: 7.65 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01671938600998133		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.01671938600998133 | validation: 0.021228110689589654]
	TIME [epoch: 7.63 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016759117091101533		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.016759117091101533 | validation: 0.02140255746597261]
	TIME [epoch: 7.67 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016995853969169916		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.016995853969169916 | validation: 0.020601833649873884]
	TIME [epoch: 7.63 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01770058387703523		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.01770058387703523 | validation: 0.022001181322519166]
	TIME [epoch: 7.62 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017503786334117363		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.017503786334117363 | validation: 0.021160125987489585]
	TIME [epoch: 7.66 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01634193632870907		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.01634193632870907 | validation: 0.020184022725603018]
	TIME [epoch: 7.65 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01654119879803638		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.01654119879803638 | validation: 0.020750019932225985]
	TIME [epoch: 7.72 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016935610600675194		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.016935610600675194 | validation: 0.02110261701198339]
	TIME [epoch: 7.62 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017408570365051886		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.017408570365051886 | validation: 0.019920624548877826]
	TIME [epoch: 7.63 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017339856137754184		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.017339856137754184 | validation: 0.019233247109250763]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_1052.pth
	Model improved!!!
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01643328047848339		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.01643328047848339 | validation: 0.021007614149185304]
	TIME [epoch: 7.66 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016802197704012697		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.016802197704012697 | validation: 0.021615598353896683]
	TIME [epoch: 7.62 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01777378349653109		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.01777378349653109 | validation: 0.022213467906948288]
	TIME [epoch: 7.61 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016623422117115556		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.016623422117115556 | validation: 0.021459174733927004]
	TIME [epoch: 7.61 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01646252320661928		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.01646252320661928 | validation: 0.022925572913196097]
	TIME [epoch: 7.62 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0165813573387037		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.0165813573387037 | validation: 0.020830138422521315]
	TIME [epoch: 7.66 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017315877695915888		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.017315877695915888 | validation: 0.021065441878372414]
	TIME [epoch: 7.63 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016446157040911798		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.016446157040911798 | validation: 0.0203664570642973]
	TIME [epoch: 7.61 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016691813182436968		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.016691813182436968 | validation: 0.0205497656905411]
	TIME [epoch: 7.62 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016441802287741662		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.016441802287741662 | validation: 0.021168566941788966]
	TIME [epoch: 7.62 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016485365543112078		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.016485365543112078 | validation: 0.021730286147028155]
	TIME [epoch: 7.65 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017791523168036297		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.017791523168036297 | validation: 0.02136925274878712]
	TIME [epoch: 7.63 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01634961591563897		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.01634961591563897 | validation: 0.02066233131024048]
	TIME [epoch: 7.62 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016542349243369045		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.016542349243369045 | validation: 0.020914677698835694]
	TIME [epoch: 7.61 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016655068390615497		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.016655068390615497 | validation: 0.020651770117036467]
	TIME [epoch: 7.62 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016308560424575836		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.016308560424575836 | validation: 0.01955110848645653]
	TIME [epoch: 7.63 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016560002326243092		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.016560002326243092 | validation: 0.020011977706967374]
	TIME [epoch: 7.64 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01636670211428152		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.01636670211428152 | validation: 0.031014404613961738]
	TIME [epoch: 7.62 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022473269343532054		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.022473269343532054 | validation: 0.022908646202644066]
	TIME [epoch: 7.62 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01760395025830415		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.01760395025830415 | validation: 0.02404746897408752]
	TIME [epoch: 7.61 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018601120344282844		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.018601120344282844 | validation: 0.019615273037109547]
	TIME [epoch: 7.63 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0167248282232736		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.0167248282232736 | validation: 0.019428230503861367]
	TIME [epoch: 7.66 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016546032397668508		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.016546032397668508 | validation: 0.019943087824587348]
	TIME [epoch: 7.61 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016291052136645966		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.016291052136645966 | validation: 0.020020423725349932]
	TIME [epoch: 7.62 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01669985121773763		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.01669985121773763 | validation: 0.02246561669943684]
	TIME [epoch: 7.61 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01608443125871832		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.01608443125871832 | validation: 0.02029629574591135]
	TIME [epoch: 7.62 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01600815473539849		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.01600815473539849 | validation: 0.02130126902940581]
	TIME [epoch: 7.66 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01660498992771844		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.01660498992771844 | validation: 0.02325555949722201]
	TIME [epoch: 7.61 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016966895092787544		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.016966895092787544 | validation: 0.021220080016226425]
	TIME [epoch: 7.61 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016506449808067723		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.016506449808067723 | validation: 0.020924309584087575]
	TIME [epoch: 7.61 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017379310011945925		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.017379310011945925 | validation: 0.021148179571469517]
	TIME [epoch: 7.61 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016895342177843473		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.016895342177843473 | validation: 0.02036658818209166]
	TIME [epoch: 7.65 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01710814879063619		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.01710814879063619 | validation: 0.019984819153272076]
	TIME [epoch: 7.62 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016699638534174548		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.016699638534174548 | validation: 0.01971961002940719]
	TIME [epoch: 7.62 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016485948801116285		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.016485948801116285 | validation: 0.01993839167322871]
	TIME [epoch: 7.61 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016471600696747545		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.016471600696747545 | validation: 0.021021994770756926]
	TIME [epoch: 7.61 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01689098590295336		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.01689098590295336 | validation: 0.021280032041476014]
	TIME [epoch: 7.63 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016130773645591685		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.016130773645591685 | validation: 0.020027693771247274]
	TIME [epoch: 7.64 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01629093105051841		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.01629093105051841 | validation: 0.020336299058734998]
	TIME [epoch: 7.61 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01659268054216751		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.01659268054216751 | validation: 0.02050130509242854]
	TIME [epoch: 7.61 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016757314219816875		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.016757314219816875 | validation: 0.020922600459767765]
	TIME [epoch: 7.61 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016024769607682936		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.016024769607682936 | validation: 0.019679171580711374]
	TIME [epoch: 7.62 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016811766730724022		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.016811766730724022 | validation: 0.019719560271851115]
	TIME [epoch: 7.65 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016035096101650253		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.016035096101650253 | validation: 0.019888733992456546]
	TIME [epoch: 7.61 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016417583896474863		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.016417583896474863 | validation: 0.021251120177950666]
	TIME [epoch: 7.61 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01676316791422901		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.01676316791422901 | validation: 0.02049868619520724]
	TIME [epoch: 7.61 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016607545621202785		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.016607545621202785 | validation: 0.020312283659427444]
	TIME [epoch: 7.61 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01662369182281814		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.01662369182281814 | validation: 0.02029482132264518]
	TIME [epoch: 7.64 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01636535692270404		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.01636535692270404 | validation: 0.020319269872269372]
	TIME [epoch: 7.62 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016169042016060467		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.016169042016060467 | validation: 0.021069444216632954]
	TIME [epoch: 7.61 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01646561564445728		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.01646561564445728 | validation: 0.021235307821423313]
	TIME [epoch: 7.6 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016292816416557797		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.016292816416557797 | validation: 0.020659997931652806]
	TIME [epoch: 7.61 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015773566405599296		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.015773566405599296 | validation: 0.0203365191855149]
	TIME [epoch: 7.64 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016172202015554717		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.016172202015554717 | validation: 0.019928399958536416]
	TIME [epoch: 7.62 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015948975221973867		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.015948975221973867 | validation: 0.020397275186301918]
	TIME [epoch: 7.59 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01595581570531972		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.01595581570531972 | validation: 0.021308904662938243]
	TIME [epoch: 7.59 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01682607088190355		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.01682607088190355 | validation: 0.01976732599593227]
	TIME [epoch: 7.59 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016180895997027888		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.016180895997027888 | validation: 0.020645336818746314]
	TIME [epoch: 7.65 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01592304550548312		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.01592304550548312 | validation: 0.0198618961191279]
	TIME [epoch: 7.63 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015803176131350124		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.015803176131350124 | validation: 0.02007936591951391]
	TIME [epoch: 7.59 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015502201632900753		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.015502201632900753 | validation: 0.0214325091440952]
	TIME [epoch: 7.59 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016463691411720525		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.016463691411720525 | validation: 0.020692703410898124]
	TIME [epoch: 7.59 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018915126622061847		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.018915126622061847 | validation: 0.021152086993104387]
	TIME [epoch: 7.65 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016730989794097314		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.016730989794097314 | validation: 0.019808851852926704]
	TIME [epoch: 7.66 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01554371494914546		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.01554371494914546 | validation: 0.019264089570676303]
	TIME [epoch: 7.61 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015546674379601094		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.015546674379601094 | validation: 0.019674998383636816]
	TIME [epoch: 7.61 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015941363514069953		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.015941363514069953 | validation: 0.020554074535766433]
	TIME [epoch: 7.61 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01641973809249432		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.01641973809249432 | validation: 0.019789329807544675]
	TIME [epoch: 7.61 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015854510127285833		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.015854510127285833 | validation: 0.019526184394778597]
	TIME [epoch: 7.65 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015503304108546813		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.015503304108546813 | validation: 0.020062295842082627]
	TIME [epoch: 7.62 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016255060222488404		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.016255060222488404 | validation: 0.019483664701561154]
	TIME [epoch: 7.63 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015834930183572633		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.015834930183572633 | validation: 0.02125981002850661]
	TIME [epoch: 7.61 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016632962407702928		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.016632962407702928 | validation: 0.021179532368430516]
	TIME [epoch: 7.61 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015917642536492093		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.015917642536492093 | validation: 0.019856648673317687]
	TIME [epoch: 7.63 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015932337225452443		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.015932337225452443 | validation: 0.019939951122405295]
	TIME [epoch: 7.65 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016256333709490457		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.016256333709490457 | validation: 0.020360833702933484]
	TIME [epoch: 7.61 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016090580196670163		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.016090580196670163 | validation: 0.020634247364712234]
	TIME [epoch: 7.61 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01600877392528445		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.01600877392528445 | validation: 0.019203204843555047]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_1130.pth
	Model improved!!!
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016460159368336665		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.016460159368336665 | validation: 0.020468892144249802]
	TIME [epoch: 7.62 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016172090120215803		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.016172090120215803 | validation: 0.01936587776591539]
	TIME [epoch: 7.63 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016043066291638507		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.016043066291638507 | validation: 0.020421902342277296]
	TIME [epoch: 7.6 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0158167505693716		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.0158167505693716 | validation: 0.019557432708787244]
	TIME [epoch: 7.6 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0160981516285786		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.0160981516285786 | validation: 0.020089162587435833]
	TIME [epoch: 7.6 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016029368642403344		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.016029368642403344 | validation: 0.0196427635651876]
	TIME [epoch: 7.6 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015654854479983167		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.015654854479983167 | validation: 0.01995121188679248]
	TIME [epoch: 7.64 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016164128213792765		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.016164128213792765 | validation: 0.02016722702109971]
	TIME [epoch: 7.59 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015387149277235994		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.015387149277235994 | validation: 0.019750571164562393]
	TIME [epoch: 7.59 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015764870197582707		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.015764870197582707 | validation: 0.019514488001610576]
	TIME [epoch: 7.59 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015670717915099466		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.015670717915099466 | validation: 0.02013362372883288]
	TIME [epoch: 7.59 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01563001722905954		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.01563001722905954 | validation: 0.019231195126422518]
	TIME [epoch: 7.62 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016032817723323375		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.016032817723323375 | validation: 0.020036291302760356]
	TIME [epoch: 7.6 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01564804484840519		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.01564804484840519 | validation: 0.01928246905541685]
	TIME [epoch: 7.59 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015306763765132271		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.015306763765132271 | validation: 0.019417925378328912]
	TIME [epoch: 7.59 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016570580404393326		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.016570580404393326 | validation: 0.01981603403097528]
	TIME [epoch: 7.59 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01569534533233014		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.01569534533233014 | validation: 0.020708283127814114]
	TIME [epoch: 7.61 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015535745882598751		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.015535745882598751 | validation: 0.019713414109661417]
	TIME [epoch: 7.62 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015512082375269992		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.015512082375269992 | validation: 0.020250646853318004]
	TIME [epoch: 7.59 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015690121807743387		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.015690121807743387 | validation: 0.0202675262481811]
	TIME [epoch: 7.6 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01606421158336451		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.01606421158336451 | validation: 0.01955019228851456]
	TIME [epoch: 7.59 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015301129058488294		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.015301129058488294 | validation: 0.01927480138268263]
	TIME [epoch: 7.61 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015582333039030984		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.015582333039030984 | validation: 0.01984804476954813]
	TIME [epoch: 7.64 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015879443322946312		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.015879443322946312 | validation: 0.020024942387049726]
	TIME [epoch: 7.59 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015647904364403133		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.015647904364403133 | validation: 0.021677357799917068]
	TIME [epoch: 7.59 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015802928939548443		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.015802928939548443 | validation: 0.020434194039966484]
	TIME [epoch: 7.58 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01575808066094666		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.01575808066094666 | validation: 0.019191360880366812]
	TIME [epoch: 7.59 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_1157.pth
	Model improved!!!
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015360753191286616		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.015360753191286616 | validation: 0.019135793701528132]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_1158.pth
	Model improved!!!
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01568920453615431		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.01568920453615431 | validation: 0.018773876239164183]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_1159.pth
	Model improved!!!
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015795272073464074		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.015795272073464074 | validation: 0.020306502612039826]
	TIME [epoch: 7.59 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01559817217226001		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.01559817217226001 | validation: 0.019067206961496413]
	TIME [epoch: 7.58 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015226803066739267		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.015226803066739267 | validation: 0.020337110188932687]
	TIME [epoch: 7.58 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015448288195743794		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.015448288195743794 | validation: 0.019249914139823486]
	TIME [epoch: 7.62 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016645594501087598		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.016645594501087598 | validation: 0.019438809844594545]
	TIME [epoch: 7.6 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01577047709664362		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.01577047709664362 | validation: 0.018939062156450335]
	TIME [epoch: 7.58 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015534581161274747		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.015534581161274747 | validation: 0.018305644652026762]
	TIME [epoch: 7.58 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_1166.pth
	Model improved!!!
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016167716031320112		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.016167716031320112 | validation: 0.01905112213681532]
	TIME [epoch: 7.58 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015506940408741416		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.015506940408741416 | validation: 0.018975968352164807]
	TIME [epoch: 7.62 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015622478227474545		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.015622478227474545 | validation: 0.019233838620729863]
	TIME [epoch: 7.61 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015767729181939496		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.015767729181939496 | validation: 0.019903685661271077]
	TIME [epoch: 7.58 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01568589595106033		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.01568589595106033 | validation: 0.020293074537887028]
	TIME [epoch: 7.58 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015757582187300553		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.015757582187300553 | validation: 0.020036350121633167]
	TIME [epoch: 7.59 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015233197725869578		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.015233197725869578 | validation: 0.020341369721813544]
	TIME [epoch: 7.6 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015501217850566565		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.015501217850566565 | validation: 0.019526693746472538]
	TIME [epoch: 7.62 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015515652183695591		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.015515652183695591 | validation: 0.021070240640848954]
	TIME [epoch: 7.59 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016121108305663052		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.016121108305663052 | validation: 0.019741577709244514]
	TIME [epoch: 7.59 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015656374321809816		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.015656374321809816 | validation: 0.018351406631356468]
	TIME [epoch: 7.59 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015939244333602175		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.015939244333602175 | validation: 0.020208197288128903]
	TIME [epoch: 7.58 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015738117559407773		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.015738117559407773 | validation: 0.01920637216930065]
	TIME [epoch: 7.63 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015463850621614022		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.015463850621614022 | validation: 0.019414032446726598]
	TIME [epoch: 7.58 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015157824046779893		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.015157824046779893 | validation: 0.01910568753889321]
	TIME [epoch: 7.58 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015227033739203411		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.015227033739203411 | validation: 0.01966998630926342]
	TIME [epoch: 7.58 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015570703647751065		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.015570703647751065 | validation: 0.018124011382305755]
	TIME [epoch: 7.58 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_1183.pth
	Model improved!!!
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01544310393818061		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.01544310393818061 | validation: 0.018303780689119836]
	TIME [epoch: 7.64 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015525248411783033		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.015525248411783033 | validation: 0.019117856218910146]
	TIME [epoch: 7.62 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015592726699445728		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.015592726699445728 | validation: 0.0206828059967209]
	TIME [epoch: 7.65 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015947139640157815		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.015947139640157815 | validation: 0.020609457829305823]
	TIME [epoch: 7.61 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015812269674951834		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.015812269674951834 | validation: 0.019231220010241527]
	TIME [epoch: 7.61 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01536260711162713		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.01536260711162713 | validation: 0.021218078591036926]
	TIME [epoch: 7.63 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015629568865824554		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.015629568865824554 | validation: 0.01905433493661211]
	TIME [epoch: 7.65 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015432977226877587		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.015432977226877587 | validation: 0.018792729839560422]
	TIME [epoch: 7.63 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015505789295589482		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.015505789295589482 | validation: 0.019263335617984004]
	TIME [epoch: 7.62 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015212271811261642		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.015212271811261642 | validation: 0.0189006036967605]
	TIME [epoch: 7.61 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015306063183307524		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.015306063183307524 | validation: 0.020398318527646613]
	TIME [epoch: 7.63 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015234828125600045		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.015234828125600045 | validation: 0.0186808504839099]
	TIME [epoch: 7.66 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015583994718402546		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.015583994718402546 | validation: 0.018640951941144897]
	TIME [epoch: 7.63 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015679175707675175		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.015679175707675175 | validation: 0.01922150697006906]
	TIME [epoch: 7.62 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01578825692020464		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.01578825692020464 | validation: 0.01975560950423488]
	TIME [epoch: 7.61 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01511471239574502		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.01511471239574502 | validation: 0.020249767652811633]
	TIME [epoch: 7.63 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015114628554759105		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.015114628554759105 | validation: 0.019506377072086994]
	TIME [epoch: 7.67 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015465877358258565		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.015465877358258565 | validation: 0.01771079791882938]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_1201.pth
	Model improved!!!
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015387650329258202		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.015387650329258202 | validation: 0.018046355525116034]
	TIME [epoch: 7.6 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01515456363522144		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.01515456363522144 | validation: 0.018254329113211083]
	TIME [epoch: 7.61 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015545807195439233		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.015545807195439233 | validation: 0.019341566638976466]
	TIME [epoch: 7.6 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015403197674427199		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.015403197674427199 | validation: 0.020105811981041194]
	TIME [epoch: 7.65 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015014592942563531		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.015014592942563531 | validation: 0.018751703047159524]
	TIME [epoch: 7.61 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01525840633890449		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.01525840633890449 | validation: 0.019453510110605084]
	TIME [epoch: 7.6 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015033727882392213		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.015033727882392213 | validation: 0.019467077357412016]
	TIME [epoch: 7.6 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01560169965111784		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.01560169965111784 | validation: 0.019884244442967436]
	TIME [epoch: 7.6 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01593996898909173		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.01593996898909173 | validation: 0.018947203903713572]
	TIME [epoch: 7.63 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015399380620473812		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.015399380620473812 | validation: 0.019110778915878823]
	TIME [epoch: 7.63 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01507941453382292		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.01507941453382292 | validation: 0.01984718905748934]
	TIME [epoch: 7.6 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015285174142452642		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.015285174142452642 | validation: 0.019776022439348614]
	TIME [epoch: 7.6 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015311538132427593		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.015311538132427593 | validation: 0.01955133752259841]
	TIME [epoch: 7.6 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01506011711018858		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.01506011711018858 | validation: 0.019107302920200332]
	TIME [epoch: 7.62 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015616611417762712		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.015616611417762712 | validation: 0.018900464280710717]
	TIME [epoch: 7.64 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015239933112047282		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.015239933112047282 | validation: 0.01987893174611443]
	TIME [epoch: 7.6 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014973676349608576		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.014973676349608576 | validation: 0.021767282353169895]
	TIME [epoch: 7.6 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01519490008308432		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.01519490008308432 | validation: 0.019156354703269648]
	TIME [epoch: 7.6 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015018347420141631		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.015018347420141631 | validation: 0.019337033856653717]
	TIME [epoch: 7.61 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015232009961337724		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.015232009961337724 | validation: 0.01921222990775881]
	TIME [epoch: 7.65 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015497225595337743		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.015497225595337743 | validation: 0.01812320126670651]
	TIME [epoch: 7.61 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015089462921665513		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.015089462921665513 | validation: 0.019556998885290416]
	TIME [epoch: 7.62 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015382033992997514		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.015382033992997514 | validation: 0.018355719188202523]
	TIME [epoch: 7.6 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015197309678625929		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.015197309678625929 | validation: 0.01910212097357388]
	TIME [epoch: 7.6 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015236923352825196		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.015236923352825196 | validation: 0.01896405123532128]
	TIME [epoch: 7.65 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015121514644163572		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.015121514644163572 | validation: 0.019439553591959664]
	TIME [epoch: 7.62 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015237331933586909		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.015237331933586909 | validation: 0.01934615840528763]
	TIME [epoch: 7.59 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015103053815888346		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.015103053815888346 | validation: 0.018946636098395413]
	TIME [epoch: 7.61 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014931297049985241		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.014931297049985241 | validation: 0.018520399478205676]
	TIME [epoch: 7.59 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014741535098606297		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.014741535098606297 | validation: 0.018908083202611867]
	TIME [epoch: 7.62 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01834271854647937		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.01834271854647937 | validation: 0.018767750740858204]
	TIME [epoch: 7.64 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016639647583343325		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.016639647583343325 | validation: 0.01980651159413886]
	TIME [epoch: 7.61 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014837401204845072		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.014837401204845072 | validation: 0.018217149713368103]
	TIME [epoch: 7.6 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015128412458232026		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.015128412458232026 | validation: 0.019003595004663525]
	TIME [epoch: 7.6 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014985696320743664		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.014985696320743664 | validation: 0.019595251865145595]
	TIME [epoch: 7.61 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014464347974895866		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.014464347974895866 | validation: 0.020104248512413485]
	TIME [epoch: 7.65 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015011934140520985		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.015011934140520985 | validation: 0.020315551136515834]
	TIME [epoch: 7.61 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015075612902135088		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.015075612902135088 | validation: 0.019402908331736343]
	TIME [epoch: 7.61 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015235645233142204		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.015235645233142204 | validation: 0.01951892338811819]
	TIME [epoch: 7.61 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016185678478860356		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.016185678478860356 | validation: 0.019058289779564634]
	TIME [epoch: 7.6 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014637441013231577		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.014637441013231577 | validation: 0.02021667383702739]
	TIME [epoch: 7.64 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014854897165645576		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.014854897165645576 | validation: 0.01909618156121496]
	TIME [epoch: 7.62 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014953077247398017		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.014953077247398017 | validation: 0.0201660652180215]
	TIME [epoch: 7.6 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015200546956561149		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.015200546956561149 | validation: 0.01884183019183888]
	TIME [epoch: 7.6 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015112919427801323		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.015112919427801323 | validation: 0.018919449223310788]
	TIME [epoch: 7.61 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014993943040712677		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.014993943040712677 | validation: 0.019507905396098917]
	TIME [epoch: 7.63 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014881366605803527		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.014881366605803527 | validation: 0.018662044461927388]
	TIME [epoch: 7.63 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015431903602134405		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.015431903602134405 | validation: 0.018133573569561072]
	TIME [epoch: 7.6 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01496410796802742		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.01496410796802742 | validation: 0.019251862499531928]
	TIME [epoch: 7.59 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01528764091114218		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.01528764091114218 | validation: 0.018434377451682415]
	TIME [epoch: 7.59 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015149045069476978		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.015149045069476978 | validation: 0.019456953688132352]
	TIME [epoch: 7.62 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015382403775324174		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.015382403775324174 | validation: 0.01921881179470178]
	TIME [epoch: 7.64 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014918574246611591		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.014918574246611591 | validation: 0.019208602227705786]
	TIME [epoch: 7.6 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014814197694389549		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.014814197694389549 | validation: 0.018252448986531198]
	TIME [epoch: 7.59 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014929053538793063		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.014929053538793063 | validation: 0.018967920703401003]
	TIME [epoch: 7.59 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015283695453069734		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.015283695453069734 | validation: 0.01773418436889488]
	TIME [epoch: 7.65 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014462647018476018		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.014462647018476018 | validation: 0.018871568026480025]
	TIME [epoch: 7.66 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0150433787400889		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.0150433787400889 | validation: 0.018150217043585153]
	TIME [epoch: 7.61 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014625906146243733		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.014625906146243733 | validation: 0.018081465006569784]
	TIME [epoch: 7.61 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01462277871496284		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.01462277871496284 | validation: 0.018935629597210336]
	TIME [epoch: 7.6 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01532030013924455		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.01532030013924455 | validation: 0.01804050019433213]
	TIME [epoch: 7.6 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014914925024768893		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.014914925024768893 | validation: 0.01812246250389425]
	TIME [epoch: 7.64 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014820169551877694		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.014820169551877694 | validation: 0.0185914162160837]
	TIME [epoch: 7.62 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01508150542022413		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.01508150542022413 | validation: 0.01935568791743753]
	TIME [epoch: 7.61 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014540272684061148		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.014540272684061148 | validation: 0.019119619653605605]
	TIME [epoch: 7.6 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014930109119930195		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.014930109119930195 | validation: 0.01879758030155957]
	TIME [epoch: 7.6 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015188425555509229		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.015188425555509229 | validation: 0.01775191081265163]
	TIME [epoch: 7.62 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014898623946662226		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.014898623946662226 | validation: 0.018016405861146233]
	TIME [epoch: 7.64 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014735582046741972		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.014735582046741972 | validation: 0.018929811595069762]
	TIME [epoch: 7.6 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014382465855703252		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.014382465855703252 | validation: 0.01855298232602182]
	TIME [epoch: 7.6 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015078455886055773		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.015078455886055773 | validation: 0.018704093714902895]
	TIME [epoch: 7.6 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01487072783027028		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.01487072783027028 | validation: 0.01919019971766045]
	TIME [epoch: 7.61 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014892511463860957		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.014892511463860957 | validation: 0.018581288901348587]
	TIME [epoch: 7.65 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015201674687692509		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.015201674687692509 | validation: 0.01866621275620355]
	TIME [epoch: 7.6 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014813855126051715		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.014813855126051715 | validation: 0.019528953998534576]
	TIME [epoch: 7.61 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015395642783821634		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.015395642783821634 | validation: 0.019040807009823576]
	TIME [epoch: 7.59 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014818614953238751		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.014818614953238751 | validation: 0.018809592958350975]
	TIME [epoch: 7.6 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014480434966044954		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.014480434966044954 | validation: 0.019499462619429246]
	TIME [epoch: 7.65 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014721309960751067		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.014721309960751067 | validation: 0.020054984086646088]
	TIME [epoch: 7.62 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01459498676794088		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.01459498676794088 | validation: 0.020117210490288997]
	TIME [epoch: 7.6 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014266740637347945		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.014266740637347945 | validation: 0.018278454573786962]
	TIME [epoch: 7.6 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014668955727451699		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.014668955727451699 | validation: 0.018023042976548633]
	TIME [epoch: 7.61 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014472709689717271		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.014472709689717271 | validation: 0.01821443136409806]
	TIME [epoch: 7.63 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014839144330860726		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.014839144330860726 | validation: 0.01966120261727524]
	TIME [epoch: 7.64 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01515929989781511		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.01515929989781511 | validation: 0.018476679621740214]
	TIME [epoch: 7.61 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014778647227220054		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.014778647227220054 | validation: 0.019144753676939172]
	TIME [epoch: 7.6 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014799671576681207		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.014799671576681207 | validation: 0.01848020077972429]
	TIME [epoch: 7.6 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014999993178364287		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.014999993178364287 | validation: 0.019404911425964896]
	TIME [epoch: 7.63 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014773738730514312		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.014773738730514312 | validation: 0.019083818980932733]
	TIME [epoch: 7.65 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014480558105473568		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.014480558105473568 | validation: 0.01742888394142432]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_1291.pth
	Model improved!!!
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015341355823434108		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.015341355823434108 | validation: 0.0199596301861609]
	TIME [epoch: 7.6 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014533880147510286		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.014533880147510286 | validation: 0.018762642567191498]
	TIME [epoch: 7.59 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014406451300970466		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.014406451300970466 | validation: 0.019683909700416374]
	TIME [epoch: 7.6 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014627902291263475		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.014627902291263475 | validation: 0.017871333903281904]
	TIME [epoch: 7.64 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014419162802942934		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.014419162802942934 | validation: 0.017595242876641794]
	TIME [epoch: 7.59 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014690303117656525		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.014690303117656525 | validation: 0.018078495937949884]
	TIME [epoch: 7.59 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014675418151445636		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.014675418151445636 | validation: 0.018636088832597056]
	TIME [epoch: 7.59 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0147897205293285		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.0147897205293285 | validation: 0.01895924761099408]
	TIME [epoch: 7.59 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014728131720543235		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.014728131720543235 | validation: 0.01748876774241659]
	TIME [epoch: 7.63 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014581761343566547		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.014581761343566547 | validation: 0.01932103699295914]
	TIME [epoch: 7.61 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014508533853600045		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.014508533853600045 | validation: 0.018005471157488885]
	TIME [epoch: 7.59 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01454805200715616		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.01454805200715616 | validation: 0.01864592094243141]
	TIME [epoch: 7.59 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014339431974584399		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.014339431974584399 | validation: 0.019565671569909814]
	TIME [epoch: 7.6 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015234339104781908		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.015234339104781908 | validation: 0.017363201698301467]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_1305.pth
	Model improved!!!
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014630205946816372		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.014630205946816372 | validation: 0.01933119911686377]
	TIME [epoch: 7.62 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01452807005192284		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.01452807005192284 | validation: 0.018976442993928186]
	TIME [epoch: 7.59 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015245289865747559		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.015245289865747559 | validation: 0.01740647877762819]
	TIME [epoch: 7.59 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01464751366467158		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.01464751366467158 | validation: 0.018928707078220117]
	TIME [epoch: 7.59 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014472935295652061		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.014472935295652061 | validation: 0.019561649428328637]
	TIME [epoch: 7.61 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014652413252556593		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.014652413252556593 | validation: 0.018890105851703927]
	TIME [epoch: 7.62 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014409863011714718		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.014409863011714718 | validation: 0.018159436187705186]
	TIME [epoch: 7.59 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014754140190573032		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.014754140190573032 | validation: 0.020090521703404973]
	TIME [epoch: 7.59 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014201599845760884		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.014201599845760884 | validation: 0.018062547368387638]
	TIME [epoch: 7.59 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01419688980111099		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.01419688980111099 | validation: 0.01901269431499768]
	TIME [epoch: 7.6 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014341475886040945		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.014341475886040945 | validation: 0.018785298189039918]
	TIME [epoch: 7.63 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014110693963659531		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.014110693963659531 | validation: 0.01975041714204456]
	TIME [epoch: 7.59 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014200344055373857		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.014200344055373857 | validation: 0.01794928411210978]
	TIME [epoch: 7.59 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014382946586497424		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.014382946586497424 | validation: 0.01839926514359065]
	TIME [epoch: 7.59 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014435589474032704		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.014435589474032704 | validation: 0.019454105904244373]
	TIME [epoch: 7.58 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01452286972093991		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.01452286972093991 | validation: 0.018083904286146434]
	TIME [epoch: 7.62 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014622998622274223		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.014622998622274223 | validation: 0.018287687519665807]
	TIME [epoch: 7.59 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014337562223341704		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.014337562223341704 | validation: 0.017580626595604065]
	TIME [epoch: 7.58 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014592887917673521		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.014592887917673521 | validation: 0.01744305757429343]
	TIME [epoch: 7.59 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014146867901169199		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.014146867901169199 | validation: 0.018572028778991348]
	TIME [epoch: 7.58 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014776545290679082		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.014776545290679082 | validation: 0.01774524860966551]
	TIME [epoch: 7.6 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014757488466049809		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.014757488466049809 | validation: 0.01790009471749934]
	TIME [epoch: 7.61 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014441235060515277		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.014441235060515277 | validation: 0.01784327658295779]
	TIME [epoch: 7.62 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014117911754246785		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.014117911754246785 | validation: 0.018601516468589197]
	TIME [epoch: 7.59 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014389513307377902		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.014389513307377902 | validation: 0.017495332241357096]
	TIME [epoch: 7.59 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014321302488529447		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.014321302488529447 | validation: 0.01938812258145232]
	TIME [epoch: 7.59 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01423960482406264		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.01423960482406264 | validation: 0.01873542864140883]
	TIME [epoch: 7.63 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01469217633106119		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.01469217633106119 | validation: 0.018729971884003167]
	TIME [epoch: 7.59 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01430484248889383		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.01430484248889383 | validation: 0.018221580547146232]
	TIME [epoch: 7.59 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014360354515140356		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.014360354515140356 | validation: 0.017767238256266884]
	TIME [epoch: 7.6 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014349380653569756		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.014349380653569756 | validation: 0.01876978942622755]
	TIME [epoch: 7.59 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014430252171058576		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.014430252171058576 | validation: 0.0185486524057816]
	TIME [epoch: 7.63 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014854944122680567		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.014854944122680567 | validation: 0.018394161117607354]
	TIME [epoch: 7.59 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014431745748412755		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.014431745748412755 | validation: 0.0173855482170532]
	TIME [epoch: 7.59 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014338981905895797		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.014338981905895797 | validation: 0.019054148785850253]
	TIME [epoch: 7.59 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014193514905420642		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.014193514905420642 | validation: 0.018197820912862685]
	TIME [epoch: 7.59 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015122901066531339		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.015122901066531339 | validation: 0.02041018457742111]
	TIME [epoch: 7.62 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014630457982293637		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.014630457982293637 | validation: 0.018512246551133187]
	TIME [epoch: 7.61 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013927937684382309		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.013927937684382309 | validation: 0.01838192397903813]
	TIME [epoch: 7.59 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014611719574818122		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.014611719574818122 | validation: 0.018305437288866234]
	TIME [epoch: 7.59 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014511145995568332		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.014511145995568332 | validation: 0.018322359060388236]
	TIME [epoch: 7.59 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0144385278816022		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.0144385278816022 | validation: 0.019407454931147008]
	TIME [epoch: 7.6 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01433383160471677		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.01433383160471677 | validation: 0.017648990293394715]
	TIME [epoch: 7.63 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014513041959604669		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.014513041959604669 | validation: 0.018820702574946564]
	TIME [epoch: 7.59 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014574890780000013		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.014574890780000013 | validation: 0.01855833603800945]
	TIME [epoch: 7.59 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014284462534553635		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.014284462534553635 | validation: 0.018649157795419168]
	TIME [epoch: 7.59 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014644870735647832		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.014644870735647832 | validation: 0.01841450655972393]
	TIME [epoch: 7.59 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014631369845173572		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.014631369845173572 | validation: 0.018441524938951258]
	TIME [epoch: 7.64 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014291616129494974		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.014291616129494974 | validation: 0.018317696891969777]
	TIME [epoch: 7.59 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014556789994708096		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.014556789994708096 | validation: 0.017871161391660687]
	TIME [epoch: 7.59 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014276246531998339		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.014276246531998339 | validation: 0.01895914062169104]
	TIME [epoch: 7.59 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014078060202489974		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.014078060202489974 | validation: 0.016994689292923467]
	TIME [epoch: 7.59 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_1357.pth
	Model improved!!!
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014370429525275487		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.014370429525275487 | validation: 0.017792986546130242]
	TIME [epoch: 7.63 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01412563660446803		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.01412563660446803 | validation: 0.019045615034542086]
	TIME [epoch: 7.6 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01464593507324164		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.01464593507324164 | validation: 0.017771311130295897]
	TIME [epoch: 7.58 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014415425939697683		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.014415425939697683 | validation: 0.0186679088250993]
	TIME [epoch: 7.59 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014305568193681393		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.014305568193681393 | validation: 0.018614670772162098]
	TIME [epoch: 7.58 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014330953074118302		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.014330953074118302 | validation: 0.01804962563004572]
	TIME [epoch: 7.61 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01441783568802856		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.01441783568802856 | validation: 0.018453899826412157]
	TIME [epoch: 7.62 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014168292711526333		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.014168292711526333 | validation: 0.018094618610101608]
	TIME [epoch: 7.59 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01447110817674397		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.01447110817674397 | validation: 0.01818042966529608]
	TIME [epoch: 7.58 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0144406127443429		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.0144406127443429 | validation: 0.019046595218221992]
	TIME [epoch: 7.58 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014070663855755424		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.014070663855755424 | validation: 0.01802658950397415]
	TIME [epoch: 7.59 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014108188924203941		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.014108188924203941 | validation: 0.017117556495513393]
	TIME [epoch: 7.63 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014333713708801661		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.014333713708801661 | validation: 0.018702582651793503]
	TIME [epoch: 7.59 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014615866666937911		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.014615866666937911 | validation: 0.017745775555221364]
	TIME [epoch: 7.59 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014206443814780395		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.014206443814780395 | validation: 0.018133077864481404]
	TIME [epoch: 7.59 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014543177464718077		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.014543177464718077 | validation: 0.01898512879990584]
	TIME [epoch: 7.6 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014102538570932025		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.014102538570932025 | validation: 0.018214377765479538]
	TIME [epoch: 7.64 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0146282504049346		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.0146282504049346 | validation: 0.017692781171845466]
	TIME [epoch: 7.6 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01409603198860478		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.01409603198860478 | validation: 0.017379940479454698]
	TIME [epoch: 7.59 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014150605817798402		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.014150605817798402 | validation: 0.01855846782632916]
	TIME [epoch: 7.59 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014302481552476171		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.014302481552476171 | validation: 0.017709051018573417]
	TIME [epoch: 7.59 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014113045849874583		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.014113045849874583 | validation: 0.01759685943565628]
	TIME [epoch: 7.62 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014711675075742834		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.014711675075742834 | validation: 0.017803410000042666]
	TIME [epoch: 7.62 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013772673539722441		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.013772673539722441 | validation: 0.01821682911903128]
	TIME [epoch: 7.59 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013895357764183807		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.013895357764183807 | validation: 0.017756799456090794]
	TIME [epoch: 7.59 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014054558872551467		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.014054558872551467 | validation: 0.018863423546554212]
	TIME [epoch: 7.59 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014449839356162095		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.014449839356162095 | validation: 0.016897443179822003]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_1384.pth
	Model improved!!!
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014735680286164999		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.014735680286164999 | validation: 0.017799476669644515]
	TIME [epoch: 7.66 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014026060478814658		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.014026060478814658 | validation: 0.016754314633596123]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_1386.pth
	Model improved!!!
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014128421134706151		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.014128421134706151 | validation: 0.01823044320659285]
	TIME [epoch: 7.59 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01416532838409799		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.01416532838409799 | validation: 0.018564443170879266]
	TIME [epoch: 7.59 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014586397547143602		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.014586397547143602 | validation: 0.01802882011252337]
	TIME [epoch: 7.6 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013927561503798359		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.013927561503798359 | validation: 0.01837751259414329]
	TIME [epoch: 7.64 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014249287084513434		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.014249287084513434 | validation: 0.017704889638240323]
	TIME [epoch: 7.58 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01439122103924887		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.01439122103924887 | validation: 0.01775259778041531]
	TIME [epoch: 7.58 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013723915062142449		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.013723915062142449 | validation: 0.019082718935034118]
	TIME [epoch: 7.58 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014451953072764256		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.014451953072764256 | validation: 0.01808418887576654]
	TIME [epoch: 7.58 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01400622930268091		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.01400622930268091 | validation: 0.018018587636800986]
	TIME [epoch: 7.62 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014121522654634878		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.014121522654634878 | validation: 0.018532598125824695]
	TIME [epoch: 7.59 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013682573324618169		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.013682573324618169 | validation: 0.019222571252099984]
	TIME [epoch: 7.58 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013868893503106237		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.013868893503106237 | validation: 0.018345803002013883]
	TIME [epoch: 7.58 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013746738054654525		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.013746738054654525 | validation: 0.01821139553456466]
	TIME [epoch: 7.6 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014299477310127928		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.014299477310127928 | validation: 0.017934305148060284]
	TIME [epoch: 7.64 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014380039565968842		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.014380039565968842 | validation: 0.01949552531392533]
	TIME [epoch: 7.61 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015107081329788363		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.015107081329788363 | validation: 0.01752771408433693]
	TIME [epoch: 7.59 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014364814024192318		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.014364814024192318 | validation: 0.01723523232171087]
	TIME [epoch: 7.59 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0140176240631396		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.0140176240631396 | validation: 0.01910902745277629]
	TIME [epoch: 7.59 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014011782125076878		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.014011782125076878 | validation: 0.018251810607291183]
	TIME [epoch: 7.61 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014085805540327059		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.014085805540327059 | validation: 0.016851364484889123]
	TIME [epoch: 7.62 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014414375756820405		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.014414375756820405 | validation: 0.016945410014472074]
	TIME [epoch: 7.59 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014360672658541695		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.014360672658541695 | validation: 0.01700427614184199]
	TIME [epoch: 7.59 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014716499002652768		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.014716499002652768 | validation: 0.01805701078880676]
	TIME [epoch: 7.59 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014093723659602802		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.014093723659602802 | validation: 0.017911701811512033]
	TIME [epoch: 7.6 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013681036840938281		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.013681036840938281 | validation: 0.01754298858742891]
	TIME [epoch: 7.63 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014298311600999978		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.014298311600999978 | validation: 0.018046689202447327]
	TIME [epoch: 7.59 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014030607611526906		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.014030607611526906 | validation: 0.0174976929141115]
	TIME [epoch: 7.58 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014285695059619444		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.014285695059619444 | validation: 0.019042909774717932]
	TIME [epoch: 7.59 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014408351472318018		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.014408351472318018 | validation: 0.017626654138356124]
	TIME [epoch: 7.59 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013825252480215933		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.013825252480215933 | validation: 0.017436835439170784]
	TIME [epoch: 7.63 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013842269245498582		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.013842269245498582 | validation: 0.018019618034463145]
	TIME [epoch: 7.61 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013835714733028689		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.013835714733028689 | validation: 0.017895851939793237]
	TIME [epoch: 7.58 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013929050269248086		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.013929050269248086 | validation: 0.016218794997027827]
	TIME [epoch: 7.59 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_fix_noise_small_20240523_102345/states/model_phi1_1a_v_mmd1_fix_noise_small_1419.pth
	Model improved!!!
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014364355454377352		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.014364355454377352 | validation: 0.018159709239609537]
	TIME [epoch: 7.59 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01416521454353959		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.01416521454353959 | validation: 0.017202233249954128]
	TIME [epoch: 7.62 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014232059958800315		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.014232059958800315 | validation: 0.01796776059467819]
	TIME [epoch: 7.6 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014044345163236887		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.014044345163236887 | validation: 0.017784168538666247]
	TIME [epoch: 7.59 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014298027548540468		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.014298027548540468 | validation: 0.017386540365299106]
	TIME [epoch: 7.58 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014230119211163333		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.014230119211163333 | validation: 0.017750202107392844]
	TIME [epoch: 7.59 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014470475773395625		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.014470475773395625 | validation: 0.01841662070233134]
	TIME [epoch: 7.61 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013743089768157956		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.013743089768157956 | validation: 0.018715907136620094]
	TIME [epoch: 7.63 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014286354151417695		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.014286354151417695 | validation: 0.017138583191777954]
	TIME [epoch: 7.6 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014176069193352453		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.014176069193352453 | validation: 0.016665653337263768]
	TIME [epoch: 7.59 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014280515162803403		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.014280515162803403 | validation: 0.017576558628236812]
	TIME [epoch: 7.59 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013828875483491727		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.013828875483491727 | validation: 0.018103631998919626]
	TIME [epoch: 7.6 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014069234342245565		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.014069234342245565 | validation: 0.018213347357840838]
	TIME [epoch: 7.63 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014054429749991142		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.014054429749991142 | validation: 0.01747513515928596]
	TIME [epoch: 7.59 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013914898880213557		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.013914898880213557 | validation: 0.01735483945305559]
	TIME [epoch: 7.58 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013796856620377565		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.013796856620377565 | validation: 0.018536666963574505]
	TIME [epoch: 7.59 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014021026760781728		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.014021026760781728 | validation: 0.017539377113483946]
	TIME [epoch: 7.59 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013699994564856592		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.013699994564856592 | validation: 0.017531910485394802]
	TIME [epoch: 7.63 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014263554276562843		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.014263554276562843 | validation: 0.017920893131015338]
	TIME [epoch: 7.6 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014122426627822999		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.014122426627822999 | validation: 0.017426540116493368]
	TIME [epoch: 7.59 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013869399254274349		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.013869399254274349 | validation: 0.017803291189291758]
	TIME [epoch: 7.59 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013940603526647981		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.013940603526647981 | validation: 0.018581669419824715]
	TIME [epoch: 7.59 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013671271240563334		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.013671271240563334 | validation: 0.016886822573229807]
	TIME [epoch: 7.61 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013605232365767984		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.013605232365767984 | validation: 0.01763903526769234]
	TIME [epoch: 7.62 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014361667499527955		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.014361667499527955 | validation: 0.017929360502622078]
	TIME [epoch: 7.59 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013971539213930498		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.013971539213930498 | validation: 0.01766153404497843]
	TIME [epoch: 7.59 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013573780342761488		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.013573780342761488 | validation: 0.01850037943795071]
	TIME [epoch: 7.59 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014068631256330446		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.014068631256330446 | validation: 0.01743634077166974]
	TIME [epoch: 7.6 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013609528576787449		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.013609528576787449 | validation: 0.017392677717081216]
	TIME [epoch: 7.64 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01409403511021509		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.01409403511021509 | validation: 0.017986237015374468]
	TIME [epoch: 7.6 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01428537080863163		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.01428537080863163 | validation: 0.017473271937027187]
	TIME [epoch: 7.59 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014195555214495437		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.014195555214495437 | validation: 0.018837642351964043]
	TIME [epoch: 7.59 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013884765862152586		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.013884765862152586 | validation: 0.018434652671296965]
	TIME [epoch: 7.59 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014086814390591531		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.014086814390591531 | validation: 0.018471945459165282]
	TIME [epoch: 7.63 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013503045334522734		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.013503045334522734 | validation: 0.01877718789243321]
	TIME [epoch: 7.6 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013738835213121263		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.013738835213121263 | validation: 0.017869174554809516]
	TIME [epoch: 7.59 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013845107225724886		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.013845107225724886 | validation: 0.01855773932656366]
	TIME [epoch: 7.59 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01441526989860925		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.01441526989860925 | validation: 0.01752907790054186]
	TIME [epoch: 7.59 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01407304728680953		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.01407304728680953 | validation: 0.01775046742340884]
	TIME [epoch: 7.62 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01409148302304936		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.01409148302304936 | validation: 0.017644472484180697]
	TIME [epoch: 7.61 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014310263440145316		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.014310263440145316 | validation: 0.01741661108597696]
	TIME [epoch: 7.58 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014169195639443051		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.014169195639443051 | validation: 0.018374609912648443]
	TIME [epoch: 7.59 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013947220282143777		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.013947220282143777 | validation: 0.01753736722996587]
	TIME [epoch: 7.59 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014055692319158672		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.014055692319158672 | validation: 0.018352479091661586]
	TIME [epoch: 7.6 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014145560612164623		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.014145560612164623 | validation: 0.0184173563565232]
	TIME [epoch: 7.62 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013654725873704046		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.013654725873704046 | validation: 0.01834824429143772]
	TIME [epoch: 7.59 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01388252927825706		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.01388252927825706 | validation: 0.01770145039973745]
	TIME [epoch: 7.58 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014014297704249216		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.014014297704249216 | validation: 0.0176360495511439]
	TIME [epoch: 7.58 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01387117315330371		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.01387117315330371 | validation: 0.017500796690621136]
	TIME [epoch: 7.59 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01398555051751283		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.01398555051751283 | validation: 0.018950502123796693]
	TIME [epoch: 7.63 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013926627301241988		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.013926627301241988 | validation: 0.018138384804734554]
	TIME [epoch: 7.59 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013523935686632049		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.013523935686632049 | validation: 0.017580605482670916]
	TIME [epoch: 7.61 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013973907434427555		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.013973907434427555 | validation: 0.017949995372205863]
	TIME [epoch: 7.58 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014517787657147556		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.014517787657147556 | validation: 0.017277315893769105]
	TIME [epoch: 7.58 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013717036538244175		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.013717036538244175 | validation: 0.017406810311970628]
	TIME [epoch: 7.62 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014059576449569032		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.014059576449569032 | validation: 0.018053552736183018]
	TIME [epoch: 7.6 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014065554841357249		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.014065554841357249 | validation: 0.018074523631773413]
	TIME [epoch: 7.58 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013816277230192076		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.013816277230192076 | validation: 0.01920414968131951]
	TIME [epoch: 7.58 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013972474165783802		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.013972474165783802 | validation: 0.018254239226003804]
	TIME [epoch: 7.59 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013536693381342935		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.013536693381342935 | validation: 0.01751764328088381]
	TIME [epoch: 7.61 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01411811834960949		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.01411811834960949 | validation: 0.018343127975624793]
	TIME [epoch: 7.62 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014029655200961165		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.014029655200961165 | validation: 0.01779422992488304]
	TIME [epoch: 7.59 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013792855916950467		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.013792855916950467 | validation: 0.018037193680912972]
	TIME [epoch: 7.59 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01377714721639223		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.01377714721639223 | validation: 0.018277939250924243]
	TIME [epoch: 7.58 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0143628863334033		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.0143628863334033 | validation: 0.018154555461430348]
	TIME [epoch: 7.6 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01415866581344217		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.01415866581344217 | validation: 0.017907967650027334]
	TIME [epoch: 7.64 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01449366639145232		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.01449366639145232 | validation: 0.016984438792877962]
	TIME [epoch: 7.59 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013941260754427792		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.013941260754427792 | validation: 0.017936972276246712]
	TIME [epoch: 7.59 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014231193902280885		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.014231193902280885 | validation: 0.016508726372007555]
	TIME [epoch: 7.58 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013774641998207708		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.013774641998207708 | validation: 0.01735741070747829]
	TIME [epoch: 7.59 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013562548253352583		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.013562548253352583 | validation: 0.017995139023714805]
	TIME [epoch: 7.63 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013731694567847057		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.013731694567847057 | validation: 0.016809163083845897]
	TIME [epoch: 7.6 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013681243174628158		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.013681243174628158 | validation: 0.01701699405363276]
	TIME [epoch: 7.58 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013831392811399284		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.013831392811399284 | validation: 0.018562226077561188]
	TIME [epoch: 7.58 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013830608391722331		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.013830608391722331 | validation: 0.017860985362833696]
	TIME [epoch: 7.58 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013481536534599298		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.013481536534599298 | validation: 0.017278102274947756]
	TIME [epoch: 7.6 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013602134091568534		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.013602134091568534 | validation: 0.017319013729059956]
	TIME [epoch: 7.62 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013441571894928811		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.013441571894928811 | validation: 0.018139177126310566]
	TIME [epoch: 7.59 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01393241547064164		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.01393241547064164 | validation: 0.01744810798734918]
	TIME [epoch: 7.59 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013607982702249737		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.013607982702249737 | validation: 0.017629069175004525]
	TIME [epoch: 7.58 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013528222793145398		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.013528222793145398 | validation: 0.018058735798476958]
	TIME [epoch: 7.6 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013559569727826008		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.013559569727826008 | validation: 0.016914975078419516]
	TIME [epoch: 7.67 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01369952807184729		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.01369952807184729 | validation: 0.01720219151714509]
	TIME [epoch: 7.63 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013801300840910512		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.013801300840910512 | validation: 0.018026967627660727]
	TIME [epoch: 7.63 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013798577560876756		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.013798577560876756 | validation: 0.01748004102204872]
	TIME [epoch: 7.62 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014194961073190574		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.014194961073190574 | validation: 0.017761007683482766]
	TIME [epoch: 7.63 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01376057893735825		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.01376057893735825 | validation: 0.017529576606006153]
	TIME [epoch: 7.68 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013966518349459695		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.013966518349459695 | validation: 0.018323267345027483]
	TIME [epoch: 7.63 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013821223884571849		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.013821223884571849 | validation: 0.016796693141216342]
	TIME [epoch: 7.63 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013994200110085302		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.013994200110085302 | validation: 0.018431190719942724]
	TIME [epoch: 7.63 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013841545403729777		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.013841545403729777 | validation: 0.017849932202136425]
	TIME [epoch: 7.62 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013488047822429683		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.013488047822429683 | validation: 0.018033043029231338]
	TIME [epoch: 7.66 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013474414851159008		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.013474414851159008 | validation: 0.017870137475049497]
	TIME [epoch: 7.64 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013453402424158682		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.013453402424158682 | validation: 0.017654327165909863]
	TIME [epoch: 7.63 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013745956477632684		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.013745956477632684 | validation: 0.018184102177759624]
	TIME [epoch: 7.63 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013017485228303706		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.013017485228303706 | validation: 0.017789646304658926]
	TIME [epoch: 7.63 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013565736332928303		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.013565736332928303 | validation: 0.01878489072282196]
	TIME [epoch: 7.64 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013880957450635042		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.013880957450635042 | validation: 0.018341966191126907]
	TIME [epoch: 7.66 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013598823206714787		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.013598823206714787 | validation: 0.01727593627327919]
	TIME [epoch: 7.62 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013945746521722452		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.013945746521722452 | validation: 0.017237130821572223]
	TIME [epoch: 7.62 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01372204861684496		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.01372204861684496 | validation: 0.017389533844134955]
	TIME [epoch: 7.62 sec]
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 12066.805 seconds.
