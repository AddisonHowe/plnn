Args:
Namespace(name='model_phi2_1a_v_mmd4', outdir='out/model_training/model_phi2_1a_v_mmd4', training_data='data/training_data/data_phi2_1a/training', validation_data='data/training_data/data_phi2_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.1, weight_decay=0.9, clip=1.0, lr_schedule='warmup_cosine_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1231336119

Training model...

Saving initial model state to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.059633714727285		[learning rate: 0.01015]
	Learning Rate: 0.01015
	LOSS [training: 4.059633714727285 | validation: 3.7494566551846673]
	TIME [epoch: 128 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2174856729481354		[learning rate: 0.01035]
	Learning Rate: 0.01035
	LOSS [training: 3.2174856729481354 | validation: 3.5313451495604005]
	TIME [epoch: 7.67 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8430441330615475		[learning rate: 0.01055]
	Learning Rate: 0.01055
	LOSS [training: 2.8430441330615475 | validation: 2.2504752556320295]
	TIME [epoch: 7.54 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2928433579047565		[learning rate: 0.01075]
	Learning Rate: 0.01075
	LOSS [training: 2.2928433579047565 | validation: 1.841013615800204]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9818897162409528		[learning rate: 0.01095]
	Learning Rate: 0.01095
	LOSS [training: 1.9818897162409528 | validation: 3.962420052174373]
	TIME [epoch: 7.63 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5111499126832952		[learning rate: 0.01115]
	Learning Rate: 0.01115
	LOSS [training: 2.5111499126832952 | validation: 3.7177978795534976]
	TIME [epoch: 7.59 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2989367029172048		[learning rate: 0.01135]
	Learning Rate: 0.01135
	LOSS [training: 2.2989367029172048 | validation: 1.3962652291826054]
	TIME [epoch: 7.58 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6402351813862686		[learning rate: 0.01155]
	Learning Rate: 0.01155
	LOSS [training: 1.6402351813862686 | validation: 1.2340809801921613]
	TIME [epoch: 7.52 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.723879944188346		[learning rate: 0.01175]
	Learning Rate: 0.01175
	LOSS [training: 1.723879944188346 | validation: 2.9748147634057722]
	TIME [epoch: 7.56 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9617370507033072		[learning rate: 0.01195]
	Learning Rate: 0.01195
	LOSS [training: 1.9617370507033072 | validation: 1.0810106458150583]
	TIME [epoch: 7.59 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3494851933742327		[learning rate: 0.01215]
	Learning Rate: 0.01215
	LOSS [training: 1.3494851933742327 | validation: 1.147635228710809]
	TIME [epoch: 7.54 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3632433421587065		[learning rate: 0.01235]
	Learning Rate: 0.01235
	LOSS [training: 1.3632433421587065 | validation: 1.3012773689182255]
	TIME [epoch: 7.53 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.227916475653325		[learning rate: 0.01255]
	Learning Rate: 0.01255
	LOSS [training: 1.227916475653325 | validation: 1.2315429583271191]
	TIME [epoch: 7.54 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2225409961078615		[learning rate: 0.01275]
	Learning Rate: 0.01275
	LOSS [training: 1.2225409961078615 | validation: 1.3885009423010262]
	TIME [epoch: 7.56 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1928746699411303		[learning rate: 0.01295]
	Learning Rate: 0.01295
	LOSS [training: 1.1928746699411303 | validation: 0.8083146731067222]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9041703628605321		[learning rate: 0.01315]
	Learning Rate: 0.01315
	LOSS [training: 0.9041703628605321 | validation: 1.3269036877153333]
	TIME [epoch: 7.59 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1217183559659278		[learning rate: 0.01335]
	Learning Rate: 0.01335
	LOSS [training: 1.1217183559659278 | validation: 1.0264725487390147]
	TIME [epoch: 7.56 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.156192244708253		[learning rate: 0.01355]
	Learning Rate: 0.01355
	LOSS [training: 1.156192244708253 | validation: 0.7656360230043993]
	TIME [epoch: 7.56 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9580769162517875		[learning rate: 0.01375]
	Learning Rate: 0.01375
	LOSS [training: 0.9580769162517875 | validation: 0.6508758254071734]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9161113560156012		[learning rate: 0.01395]
	Learning Rate: 0.01395
	LOSS [training: 0.9161113560156012 | validation: 0.8459142592316553]
	TIME [epoch: 7.58 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.871121119486613		[learning rate: 0.01415]
	Learning Rate: 0.01415
	LOSS [training: 0.871121119486613 | validation: 0.5196411327911414]
	TIME [epoch: 7.56 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8049296621544676		[learning rate: 0.01435]
	Learning Rate: 0.01435
	LOSS [training: 0.8049296621544676 | validation: 1.2039541789211876]
	TIME [epoch: 7.55 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8237218405529527		[learning rate: 0.01455]
	Learning Rate: 0.01455
	LOSS [training: 0.8237218405529527 | validation: 1.019312944916103]
	TIME [epoch: 7.54 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7802868640373273		[learning rate: 0.01475]
	Learning Rate: 0.01475
	LOSS [training: 0.7802868640373273 | validation: 0.719160816197824]
	TIME [epoch: 7.59 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.675599223878606		[learning rate: 0.01495]
	Learning Rate: 0.01495
	LOSS [training: 0.675599223878606 | validation: 0.9040357130572108]
	TIME [epoch: 7.57 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8962514096584409		[learning rate: 0.01515]
	Learning Rate: 0.01515
	LOSS [training: 0.8962514096584409 | validation: 0.7871754397659079]
	TIME [epoch: 7.58 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.710227527039995		[learning rate: 0.01535]
	Learning Rate: 0.01535
	LOSS [training: 0.710227527039995 | validation: 0.7486163427926377]
	TIME [epoch: 7.55 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.721133633579776		[learning rate: 0.01555]
	Learning Rate: 0.01555
	LOSS [training: 0.721133633579776 | validation: 0.9084340409737607]
	TIME [epoch: 7.56 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7805441735977691		[learning rate: 0.01575]
	Learning Rate: 0.01575
	LOSS [training: 0.7805441735977691 | validation: 0.48854130017041086]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6752758929190563		[learning rate: 0.01595]
	Learning Rate: 0.01595
	LOSS [training: 0.6752758929190563 | validation: 1.0239574615744444]
	TIME [epoch: 7.53 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7524185825413386		[learning rate: 0.01615]
	Learning Rate: 0.01615
	LOSS [training: 0.7524185825413386 | validation: 0.6852410079946605]
	TIME [epoch: 7.52 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7216072218068876		[learning rate: 0.01635]
	Learning Rate: 0.01635
	LOSS [training: 0.7216072218068876 | validation: 0.9512921869358044]
	TIME [epoch: 7.51 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7179604569215491		[learning rate: 0.01655]
	Learning Rate: 0.01655
	LOSS [training: 0.7179604569215491 | validation: 0.4887507368894642]
	TIME [epoch: 7.52 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6728659069197238		[learning rate: 0.01675]
	Learning Rate: 0.01675
	LOSS [training: 0.6728659069197238 | validation: 0.983054372299627]
	TIME [epoch: 7.57 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7751403920508941		[learning rate: 0.01695]
	Learning Rate: 0.01695
	LOSS [training: 0.7751403920508941 | validation: 0.6209215836710368]
	TIME [epoch: 7.52 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6593013211356363		[learning rate: 0.01715]
	Learning Rate: 0.01715
	LOSS [training: 0.6593013211356363 | validation: 0.7478153961832019]
	TIME [epoch: 7.52 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.705529263569002		[learning rate: 0.01735]
	Learning Rate: 0.01735
	LOSS [training: 0.705529263569002 | validation: 0.6070443430415764]
	TIME [epoch: 7.51 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7471130526172104		[learning rate: 0.01755]
	Learning Rate: 0.01755
	LOSS [training: 0.7471130526172104 | validation: 0.7964847757912233]
	TIME [epoch: 7.51 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6854438834660909		[learning rate: 0.01775]
	Learning Rate: 0.01775
	LOSS [training: 0.6854438834660909 | validation: 0.6851519194209212]
	TIME [epoch: 7.57 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5858332391091386		[learning rate: 0.01795]
	Learning Rate: 0.01795
	LOSS [training: 0.5858332391091386 | validation: 0.7934015452678196]
	TIME [epoch: 7.52 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6702672702277666		[learning rate: 0.01815]
	Learning Rate: 0.01815
	LOSS [training: 0.6702672702277666 | validation: 0.6581583466781751]
	TIME [epoch: 7.52 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6924881483118294		[learning rate: 0.01835]
	Learning Rate: 0.01835
	LOSS [training: 0.6924881483118294 | validation: 0.8578190540662547]
	TIME [epoch: 7.51 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.736277356875618		[learning rate: 0.01855]
	Learning Rate: 0.01855
	LOSS [training: 0.736277356875618 | validation: 0.7371051993893087]
	TIME [epoch: 7.5 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6336801737712794		[learning rate: 0.01875]
	Learning Rate: 0.01875
	LOSS [training: 0.6336801737712794 | validation: 0.6129379601299562]
	TIME [epoch: 7.56 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6130025074189883		[learning rate: 0.01895]
	Learning Rate: 0.01895
	LOSS [training: 0.6130025074189883 | validation: 0.7188217878819407]
	TIME [epoch: 7.52 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6769955450559817		[learning rate: 0.01915]
	Learning Rate: 0.01915
	LOSS [training: 0.6769955450559817 | validation: 0.6183250486295934]
	TIME [epoch: 7.53 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.652021586236912		[learning rate: 0.01935]
	Learning Rate: 0.01935
	LOSS [training: 0.652021586236912 | validation: 0.6186036480248341]
	TIME [epoch: 7.51 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6342789396881775		[learning rate: 0.01955]
	Learning Rate: 0.01955
	LOSS [training: 0.6342789396881775 | validation: 0.49381631385348446]
	TIME [epoch: 7.5 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6004581384803528		[learning rate: 0.01975]
	Learning Rate: 0.01975
	LOSS [training: 0.6004581384803528 | validation: 0.6946793122647021]
	TIME [epoch: 7.55 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5593715977417852		[learning rate: 0.01995]
	Learning Rate: 0.01995
	LOSS [training: 0.5593715977417852 | validation: 0.5744167116596198]
	TIME [epoch: 7.52 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6249108608285074		[learning rate: 0.02]
	Learning Rate: 0.02
	LOSS [training: 0.6249108608285074 | validation: 0.573059446139546]
	TIME [epoch: 7.52 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.558846017098041		[learning rate: 0.02]
	Learning Rate: 0.02
	LOSS [training: 0.558846017098041 | validation: 0.49326444918687345]
	TIME [epoch: 7.51 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5392709465153446		[learning rate: 0.02]
	Learning Rate: 0.0199999
	LOSS [training: 0.5392709465153446 | validation: 0.6529994842973004]
	TIME [epoch: 7.5 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5803683484132107		[learning rate: 0.02]
	Learning Rate: 0.0199998
	LOSS [training: 0.5803683484132107 | validation: 0.459226315828977]
	TIME [epoch: 7.54 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5473166937142895		[learning rate: 0.02]
	Learning Rate: 0.0199997
	LOSS [training: 0.5473166937142895 | validation: 0.49124626085397494]
	TIME [epoch: 7.55 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4421288791123532		[learning rate: 0.02]
	Learning Rate: 0.0199995
	LOSS [training: 0.4421288791123532 | validation: 0.4288469504305541]
	TIME [epoch: 7.53 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4724766181953547		[learning rate: 0.019999]
	Learning Rate: 0.0199994
	LOSS [training: 0.4724766181953547 | validation: 0.42555324004195505]
	TIME [epoch: 7.53 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5330516887007254		[learning rate: 0.019999]
	Learning Rate: 0.0199992
	LOSS [training: 0.5330516887007254 | validation: 0.5607821026338358]
	TIME [epoch: 7.55 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5136443173151574		[learning rate: 0.019999]
	Learning Rate: 0.019999
	LOSS [training: 0.5136443173151574 | validation: 0.3392387487468585]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45377642649518557		[learning rate: 0.019999]
	Learning Rate: 0.0199987
	LOSS [training: 0.45377642649518557 | validation: 0.44330514971613777]
	TIME [epoch: 7.57 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4151147261394462		[learning rate: 0.019998]
	Learning Rate: 0.0199984
	LOSS [training: 0.4151147261394462 | validation: 0.3494397527658837]
	TIME [epoch: 7.58 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41531757535305525		[learning rate: 0.019998]
	Learning Rate: 0.0199981
	LOSS [training: 0.41531757535305525 | validation: 0.5278336842232068]
	TIME [epoch: 7.56 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4547984322536284		[learning rate: 0.019998]
	Learning Rate: 0.0199978
	LOSS [training: 0.4547984322536284 | validation: 0.3466010978565977]
	TIME [epoch: 7.56 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3954728008224051		[learning rate: 0.019997]
	Learning Rate: 0.0199974
	LOSS [training: 0.3954728008224051 | validation: 0.37864504855964803]
	TIME [epoch: 7.61 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4045957779887313		[learning rate: 0.019997]
	Learning Rate: 0.019997
	LOSS [training: 0.4045957779887313 | validation: 0.38651333870015625]
	TIME [epoch: 7.59 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38836435103920475		[learning rate: 0.019997]
	Learning Rate: 0.0199966
	LOSS [training: 0.38836435103920475 | validation: 0.280031828304123]
	TIME [epoch: 7.56 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3737225335511421		[learning rate: 0.019996]
	Learning Rate: 0.0199962
	LOSS [training: 0.3737225335511421 | validation: 0.39754964387596153]
	TIME [epoch: 7.61 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47761813066228426		[learning rate: 0.019996]
	Learning Rate: 0.0199957
	LOSS [training: 0.47761813066228426 | validation: 0.3805398399963277]
	TIME [epoch: 7.62 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38348200731189597		[learning rate: 0.019995]
	Learning Rate: 0.0199952
	LOSS [training: 0.38348200731189597 | validation: 0.22992921282613887]
	TIME [epoch: 7.66 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38106604848273373		[learning rate: 0.019995]
	Learning Rate: 0.0199947
	LOSS [training: 0.38106604848273373 | validation: 0.233471129865839]
	TIME [epoch: 7.58 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37102748058464363		[learning rate: 0.019994]
	Learning Rate: 0.0199941
	LOSS [training: 0.37102748058464363 | validation: 0.2620093673970989]
	TIME [epoch: 7.6 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38793316513887344		[learning rate: 0.019994]
	Learning Rate: 0.0199935
	LOSS [training: 0.38793316513887344 | validation: 0.27402969574594943]
	TIME [epoch: 7.59 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3521557694008467		[learning rate: 0.019993]
	Learning Rate: 0.0199929
	LOSS [training: 0.3521557694008467 | validation: 0.21753793320282638]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3480582295103659		[learning rate: 0.019992]
	Learning Rate: 0.0199923
	LOSS [training: 0.3480582295103659 | validation: 0.2261527793884609]
	TIME [epoch: 7.62 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40682132265098797		[learning rate: 0.019992]
	Learning Rate: 0.0199916
	LOSS [training: 0.40682132265098797 | validation: 0.23825118199281517]
	TIME [epoch: 7.63 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35219285080170576		[learning rate: 0.019991]
	Learning Rate: 0.0199909
	LOSS [training: 0.35219285080170576 | validation: 0.2494157957479305]
	TIME [epoch: 7.64 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3362663641635555		[learning rate: 0.01999]
	Learning Rate: 0.0199902
	LOSS [training: 0.3362663641635555 | validation: 0.20364380752825298]
	TIME [epoch: 7.63 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3523230288416769		[learning rate: 0.019989]
	Learning Rate: 0.0199895
	LOSS [training: 0.3523230288416769 | validation: 0.3780074058247612]
	TIME [epoch: 7.54 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3996795368586075		[learning rate: 0.019989]
	Learning Rate: 0.0199887
	LOSS [training: 0.3996795368586075 | validation: 0.21085263521753533]
	TIME [epoch: 7.56 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33459012028054447		[learning rate: 0.019988]
	Learning Rate: 0.0199879
	LOSS [training: 0.33459012028054447 | validation: 0.221263113110489]
	TIME [epoch: 7.53 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3289067954040815		[learning rate: 0.019987]
	Learning Rate: 0.0199871
	LOSS [training: 0.3289067954040815 | validation: 0.20522047687999387]
	TIME [epoch: 7.51 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3110239337155022		[learning rate: 0.019986]
	Learning Rate: 0.0199862
	LOSS [training: 0.3110239337155022 | validation: 0.2219294644844742]
	TIME [epoch: 7.51 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3393075648263986		[learning rate: 0.019985]
	Learning Rate: 0.0199853
	LOSS [training: 0.3393075648263986 | validation: 0.2087317426779167]
	TIME [epoch: 7.53 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3488515657715019		[learning rate: 0.019984]
	Learning Rate: 0.0199844
	LOSS [training: 0.3488515657715019 | validation: 0.20956494549150936]
	TIME [epoch: 7.56 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32891163214716607		[learning rate: 0.019984]
	Learning Rate: 0.0199835
	LOSS [training: 0.32891163214716607 | validation: 0.2643053835913262]
	TIME [epoch: 7.54 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3427431318424801		[learning rate: 0.019983]
	Learning Rate: 0.0199825
	LOSS [training: 0.3427431318424801 | validation: 0.24268992633848996]
	TIME [epoch: 7.52 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3066653346591267		[learning rate: 0.019982]
	Learning Rate: 0.0199816
	LOSS [training: 0.3066653346591267 | validation: 0.20027467536038224]
	TIME [epoch: 7.51 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3213652324815106		[learning rate: 0.019981]
	Learning Rate: 0.0199805
	LOSS [training: 0.3213652324815106 | validation: 0.20945726841117063]
	TIME [epoch: 7.57 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31072148887927364		[learning rate: 0.019979]
	Learning Rate: 0.0199795
	LOSS [training: 0.31072148887927364 | validation: 0.17688271839240532]
	TIME [epoch: 7.58 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30247404005933504		[learning rate: 0.019978]
	Learning Rate: 0.0199784
	LOSS [training: 0.30247404005933504 | validation: 0.2252612126514152]
	TIME [epoch: 7.58 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3465276846337506		[learning rate: 0.019977]
	Learning Rate: 0.0199773
	LOSS [training: 0.3465276846337506 | validation: 0.2558706287599002]
	TIME [epoch: 7.57 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.350256728676038		[learning rate: 0.019976]
	Learning Rate: 0.0199762
	LOSS [training: 0.350256728676038 | validation: 0.18142541159028575]
	TIME [epoch: 7.57 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2943558782000413		[learning rate: 0.019975]
	Learning Rate: 0.019975
	LOSS [training: 0.2943558782000413 | validation: 0.20278307527356487]
	TIME [epoch: 7.6 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3135675885916469		[learning rate: 0.019974]
	Learning Rate: 0.0199739
	LOSS [training: 0.3135675885916469 | validation: 0.19166154760630366]
	TIME [epoch: 7.62 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3269717644700963		[learning rate: 0.019973]
	Learning Rate: 0.0199727
	LOSS [training: 0.3269717644700963 | validation: 0.21603360900598978]
	TIME [epoch: 7.59 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3173206298918132		[learning rate: 0.019971]
	Learning Rate: 0.0199714
	LOSS [training: 0.3173206298918132 | validation: 0.235142238944885]
	TIME [epoch: 7.56 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33506434819333264		[learning rate: 0.01997]
	Learning Rate: 0.0199702
	LOSS [training: 0.33506434819333264 | validation: 0.2822240795749529]
	TIME [epoch: 7.56 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3568171536583701		[learning rate: 0.019969]
	Learning Rate: 0.0199689
	LOSS [training: 0.3568171536583701 | validation: 0.17866244632670517]
	TIME [epoch: 7.6 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.321261510818713		[learning rate: 0.019968]
	Learning Rate: 0.0199675
	LOSS [training: 0.321261510818713 | validation: 0.2775504782629289]
	TIME [epoch: 7.64 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32822656267463357		[learning rate: 0.019966]
	Learning Rate: 0.0199662
	LOSS [training: 0.32822656267463357 | validation: 0.21447817598438684]
	TIME [epoch: 7.58 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3091229803067185		[learning rate: 0.019965]
	Learning Rate: 0.0199648
	LOSS [training: 0.3091229803067185 | validation: 0.27718917309074215]
	TIME [epoch: 7.56 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31753237029542414		[learning rate: 0.019963]
	Learning Rate: 0.0199634
	LOSS [training: 0.31753237029542414 | validation: 0.18593424447348522]
	TIME [epoch: 7.58 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29246966116493905		[learning rate: 0.019962]
	Learning Rate: 0.019962
	LOSS [training: 0.29246966116493905 | validation: 0.18749860656505338]
	TIME [epoch: 7.59 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2892488321726464		[learning rate: 0.019961]
	Learning Rate: 0.0199606
	LOSS [training: 0.2892488321726464 | validation: 0.19961763100783236]
	TIME [epoch: 7.63 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31966260896406784		[learning rate: 0.019959]
	Learning Rate: 0.0199591
	LOSS [training: 0.31966260896406784 | validation: 0.2348865774652873]
	TIME [epoch: 7.58 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34351387885881346		[learning rate: 0.019958]
	Learning Rate: 0.0199576
	LOSS [training: 0.34351387885881346 | validation: 0.26388887762236596]
	TIME [epoch: 7.55 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32775382684990806		[learning rate: 0.019956]
	Learning Rate: 0.019956
	LOSS [training: 0.32775382684990806 | validation: 0.19065899721097268]
	TIME [epoch: 7.56 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2980597738862816		[learning rate: 0.019954]
	Learning Rate: 0.0199545
	LOSS [training: 0.2980597738862816 | validation: 0.20248582518770164]
	TIME [epoch: 7.59 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30871861348569907		[learning rate: 0.019953]
	Learning Rate: 0.0199529
	LOSS [training: 0.30871861348569907 | validation: 0.18744125356183955]
	TIME [epoch: 7.62 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.309327227008455		[learning rate: 0.019951]
	Learning Rate: 0.0199513
	LOSS [training: 0.309327227008455 | validation: 0.19069543600936528]
	TIME [epoch: 7.58 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3186768354138542		[learning rate: 0.01995]
	Learning Rate: 0.0199496
	LOSS [training: 0.3186768354138542 | validation: 0.21282115995044892]
	TIME [epoch: 7.57 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3300643619256899		[learning rate: 0.019948]
	Learning Rate: 0.0199479
	LOSS [training: 0.3300643619256899 | validation: 0.19621197339107194]
	TIME [epoch: 7.58 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.293227548335159		[learning rate: 0.019946]
	Learning Rate: 0.0199462
	LOSS [training: 0.293227548335159 | validation: 0.2898500955703542]
	TIME [epoch: 7.58 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3332032231390431		[learning rate: 0.019945]
	Learning Rate: 0.0199445
	LOSS [training: 0.3332032231390431 | validation: 0.18049676265531114]
	TIME [epoch: 7.61 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2824596473867281		[learning rate: 0.019943]
	Learning Rate: 0.0199428
	LOSS [training: 0.2824596473867281 | validation: 0.19113510393812727]
	TIME [epoch: 7.58 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28627080690460505		[learning rate: 0.019941]
	Learning Rate: 0.019941
	LOSS [training: 0.28627080690460505 | validation: 0.18807531537095498]
	TIME [epoch: 7.57 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3207858610792011		[learning rate: 0.019939]
	Learning Rate: 0.0199392
	LOSS [training: 0.3207858610792011 | validation: 0.21433572971544335]
	TIME [epoch: 7.57 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31041371817856145		[learning rate: 0.019937]
	Learning Rate: 0.0199374
	LOSS [training: 0.31041371817856145 | validation: 0.2859693316894474]
	TIME [epoch: 7.58 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3264903438317783		[learning rate: 0.019935]
	Learning Rate: 0.0199355
	LOSS [training: 0.3264903438317783 | validation: 0.17383842107425512]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_119.pth
	Model improved!!!
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3138491703683508		[learning rate: 0.019934]
	Learning Rate: 0.0199336
	LOSS [training: 0.3138491703683508 | validation: 0.1843823290332199]
	TIME [epoch: 7.6 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2951784690971209		[learning rate: 0.019932]
	Learning Rate: 0.0199317
	LOSS [training: 0.2951784690971209 | validation: 0.25240404182696663]
	TIME [epoch: 7.64 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33306164434430946		[learning rate: 0.01993]
	Learning Rate: 0.0199297
	LOSS [training: 0.33306164434430946 | validation: 0.1864569601812639]
	TIME [epoch: 7.62 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2970893000421425		[learning rate: 0.019928]
	Learning Rate: 0.0199278
	LOSS [training: 0.2970893000421425 | validation: 0.18276533476761342]
	TIME [epoch: 7.66 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30626742400375767		[learning rate: 0.019926]
	Learning Rate: 0.0199258
	LOSS [training: 0.30626742400375767 | validation: 0.1803157963549324]
	TIME [epoch: 7.65 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30543990130278664		[learning rate: 0.019924]
	Learning Rate: 0.0199238
	LOSS [training: 0.30543990130278664 | validation: 0.18254622425736594]
	TIME [epoch: 7.65 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2933616629370198		[learning rate: 0.019922]
	Learning Rate: 0.0199217
	LOSS [training: 0.2933616629370198 | validation: 0.21249841886342624]
	TIME [epoch: 7.65 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30761004343548426		[learning rate: 0.01992]
	Learning Rate: 0.0199196
	LOSS [training: 0.30761004343548426 | validation: 0.1942280127628924]
	TIME [epoch: 7.65 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30250701877926556		[learning rate: 0.019918]
	Learning Rate: 0.0199175
	LOSS [training: 0.30250701877926556 | validation: 0.20045641231304512]
	TIME [epoch: 7.66 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30563646458962923		[learning rate: 0.019915]
	Learning Rate: 0.0199154
	LOSS [training: 0.30563646458962923 | validation: 0.17272951890708238]
	TIME [epoch: 7.66 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_129.pth
	Model improved!!!
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31130182005151014		[learning rate: 0.019913]
	Learning Rate: 0.0199132
	LOSS [training: 0.31130182005151014 | validation: 0.17111333079864943]
	TIME [epoch: 7.6 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_130.pth
	Model improved!!!
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31409611526436265		[learning rate: 0.019911]
	Learning Rate: 0.019911
	LOSS [training: 0.31409611526436265 | validation: 0.19382171809404664]
	TIME [epoch: 7.61 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2967715631048454		[learning rate: 0.019909]
	Learning Rate: 0.0199088
	LOSS [training: 0.2967715631048454 | validation: 0.20471157414379798]
	TIME [epoch: 7.64 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3187192263090165		[learning rate: 0.019907]
	Learning Rate: 0.0199066
	LOSS [training: 0.3187192263090165 | validation: 0.1925402463781929]
	TIME [epoch: 7.66 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2988635965852368		[learning rate: 0.019904]
	Learning Rate: 0.0199043
	LOSS [training: 0.2988635965852368 | validation: 0.18351334404650033]
	TIME [epoch: 7.64 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3071751311303695		[learning rate: 0.019902]
	Learning Rate: 0.019902
	LOSS [training: 0.3071751311303695 | validation: 0.17425873876054981]
	TIME [epoch: 7.65 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30002814278573736		[learning rate: 0.0199]
	Learning Rate: 0.0198997
	LOSS [training: 0.30002814278573736 | validation: 0.20469839303157467]
	TIME [epoch: 7.63 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30851710845265856		[learning rate: 0.019897]
	Learning Rate: 0.0198974
	LOSS [training: 0.30851710845265856 | validation: 0.18593997399587547]
	TIME [epoch: 7.63 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32540459666159816		[learning rate: 0.019895]
	Learning Rate: 0.019895
	LOSS [training: 0.32540459666159816 | validation: 0.18969724453790252]
	TIME [epoch: 7.69 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3041918759092442		[learning rate: 0.019893]
	Learning Rate: 0.0198926
	LOSS [training: 0.3041918759092442 | validation: 0.18538205522505016]
	TIME [epoch: 7.64 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32977468149683103		[learning rate: 0.01989]
	Learning Rate: 0.0198901
	LOSS [training: 0.32977468149683103 | validation: 0.19413096341859792]
	TIME [epoch: 7.64 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30299949816307525		[learning rate: 0.019888]
	Learning Rate: 0.0198877
	LOSS [training: 0.30299949816307525 | validation: 0.18041277263370162]
	TIME [epoch: 7.64 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2888115420694649		[learning rate: 0.019885]
	Learning Rate: 0.0198852
	LOSS [training: 0.2888115420694649 | validation: 0.17237958331093917]
	TIME [epoch: 7.62 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.283077966867939		[learning rate: 0.019883]
	Learning Rate: 0.0198827
	LOSS [training: 0.283077966867939 | validation: 0.1686558057300117]
	TIME [epoch: 7.69 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_143.pth
	Model improved!!!
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3219132193230668		[learning rate: 0.01988]
	Learning Rate: 0.0198802
	LOSS [training: 0.3219132193230668 | validation: 0.1993764978581303]
	TIME [epoch: 7.53 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28537192841434567		[learning rate: 0.019878]
	Learning Rate: 0.0198776
	LOSS [training: 0.28537192841434567 | validation: 0.20046656711148053]
	TIME [epoch: 7.53 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2910299691103471		[learning rate: 0.019875]
	Learning Rate: 0.019875
	LOSS [training: 0.2910299691103471 | validation: 0.2170750665718679]
	TIME [epoch: 7.51 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31228791687362006		[learning rate: 0.019872]
	Learning Rate: 0.0198724
	LOSS [training: 0.31228791687362006 | validation: 0.20091288206450733]
	TIME [epoch: 7.52 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3022461866360593		[learning rate: 0.01987]
	Learning Rate: 0.0198697
	LOSS [training: 0.3022461866360593 | validation: 0.17748027201707764]
	TIME [epoch: 7.56 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2965247766971024		[learning rate: 0.019867]
	Learning Rate: 0.0198671
	LOSS [training: 0.2965247766971024 | validation: 0.17207686645805984]
	TIME [epoch: 7.51 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28913295670578765		[learning rate: 0.019864]
	Learning Rate: 0.0198644
	LOSS [training: 0.28913295670578765 | validation: 0.1713369261524044]
	TIME [epoch: 7.53 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29273429347266905		[learning rate: 0.019862]
	Learning Rate: 0.0198616
	LOSS [training: 0.29273429347266905 | validation: 0.15469132076620395]
	TIME [epoch: 7.52 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2870752020772618		[learning rate: 0.019859]
	Learning Rate: 0.0198589
	LOSS [training: 0.2870752020772618 | validation: 0.38010513009266356]
	TIME [epoch: 7.55 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30385532067212834		[learning rate: 0.019856]
	Learning Rate: 0.0198561
	LOSS [training: 0.30385532067212834 | validation: 0.3857523071084604]
	TIME [epoch: 7.59 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2722212741939793		[learning rate: 0.019853]
	Learning Rate: 0.0198533
	LOSS [training: 0.2722212741939793 | validation: 0.37517202720218246]
	TIME [epoch: 7.54 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27222750489778647		[learning rate: 0.01985]
	Learning Rate: 0.0198505
	LOSS [training: 0.27222750489778647 | validation: 0.14527773361024887]
	TIME [epoch: 7.55 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_155.pth
	Model improved!!!
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2403657989135216		[learning rate: 0.019848]
	Learning Rate: 0.0198476
	LOSS [training: 0.2403657989135216 | validation: 0.1855725464352715]
	TIME [epoch: 7.54 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2875894082803704		[learning rate: 0.019845]
	Learning Rate: 0.0198447
	LOSS [training: 0.2875894082803704 | validation: 0.12256870571158349]
	TIME [epoch: 7.54 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_157.pth
	Model improved!!!
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22895765444849683		[learning rate: 0.019842]
	Learning Rate: 0.0198418
	LOSS [training: 0.22895765444849683 | validation: 0.29846993135632827]
	TIME [epoch: 7.63 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2620714194183148		[learning rate: 0.019839]
	Learning Rate: 0.0198388
	LOSS [training: 0.2620714194183148 | validation: 0.2467034477859918]
	TIME [epoch: 7.58 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19178257020050488		[learning rate: 0.019836]
	Learning Rate: 0.0198359
	LOSS [training: 0.19178257020050488 | validation: 0.12921750906815407]
	TIME [epoch: 7.59 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17304751778409433		[learning rate: 0.019833]
	Learning Rate: 0.0198329
	LOSS [training: 0.17304751778409433 | validation: 0.11313459886035651]
	TIME [epoch: 7.58 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_161.pth
	Model improved!!!
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16111022080388882		[learning rate: 0.01983]
	Learning Rate: 0.0198299
	LOSS [training: 0.16111022080388882 | validation: 0.17500287197418016]
	TIME [epoch: 7.63 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20351736488332203		[learning rate: 0.019827]
	Learning Rate: 0.0198268
	LOSS [training: 0.20351736488332203 | validation: 0.10222217381541446]
	TIME [epoch: 7.69 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_163.pth
	Model improved!!!
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1765298921984161		[learning rate: 0.019824]
	Learning Rate: 0.0198237
	LOSS [training: 0.1765298921984161 | validation: 0.14983986991037435]
	TIME [epoch: 7.65 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20750528074755437		[learning rate: 0.019821]
	Learning Rate: 0.0198206
	LOSS [training: 0.20750528074755437 | validation: 0.12625786166756564]
	TIME [epoch: 7.63 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2106640528578397		[learning rate: 0.019818]
	Learning Rate: 0.0198175
	LOSS [training: 0.2106640528578397 | validation: 0.23110479720322172]
	TIME [epoch: 7.63 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2037123142868074		[learning rate: 0.019814]
	Learning Rate: 0.0198143
	LOSS [training: 0.2037123142868074 | validation: 0.1996959139922158]
	TIME [epoch: 7.65 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18088545472826756		[learning rate: 0.019811]
	Learning Rate: 0.0198112
	LOSS [training: 0.18088545472826756 | validation: 0.12489443234436848]
	TIME [epoch: 7.66 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1729975779805749		[learning rate: 0.019808]
	Learning Rate: 0.0198079
	LOSS [training: 0.1729975779805749 | validation: 0.18401580414171193]
	TIME [epoch: 7.63 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17146664781446994		[learning rate: 0.019805]
	Learning Rate: 0.0198047
	LOSS [training: 0.17146664781446994 | validation: 0.1113842399475324]
	TIME [epoch: 7.62 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1957312275379669		[learning rate: 0.019801]
	Learning Rate: 0.0198014
	LOSS [training: 0.1957312275379669 | validation: 0.1309094011955809]
	TIME [epoch: 7.65 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17588590845002292		[learning rate: 0.019798]
	Learning Rate: 0.0197982
	LOSS [training: 0.17588590845002292 | validation: 0.1436153909399277]
	TIME [epoch: 7.63 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18299999463199676		[learning rate: 0.019795]
	Learning Rate: 0.0197948
	LOSS [training: 0.18299999463199676 | validation: 0.26046498501161625]
	TIME [epoch: 7.67 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1908339717782082		[learning rate: 0.019791]
	Learning Rate: 0.0197915
	LOSS [training: 0.1908339717782082 | validation: 0.10691921905328208]
	TIME [epoch: 7.63 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16492145069769962		[learning rate: 0.019788]
	Learning Rate: 0.0197881
	LOSS [training: 0.16492145069769962 | validation: 0.13233466841053693]
	TIME [epoch: 7.62 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17139967850031773		[learning rate: 0.019785]
	Learning Rate: 0.0197847
	LOSS [training: 0.17139967850031773 | validation: 0.12873929626903463]
	TIME [epoch: 7.63 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1991392145953898		[learning rate: 0.019781]
	Learning Rate: 0.0197813
	LOSS [training: 0.1991392145953898 | validation: 0.12650063872855952]
	TIME [epoch: 7.65 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1802048883262916		[learning rate: 0.019778]
	Learning Rate: 0.0197778
	LOSS [training: 0.1802048883262916 | validation: 0.13357133766607562]
	TIME [epoch: 7.66 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21374549182710095		[learning rate: 0.019774]
	Learning Rate: 0.0197744
	LOSS [training: 0.21374549182710095 | validation: 0.128649856354915]
	TIME [epoch: 7.62 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1817695806637622		[learning rate: 0.019771]
	Learning Rate: 0.0197709
	LOSS [training: 0.1817695806637622 | validation: 0.13569090209541654]
	TIME [epoch: 7.61 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1611926260855755		[learning rate: 0.019767]
	Learning Rate: 0.0197673
	LOSS [training: 0.1611926260855755 | validation: 0.15669750734469573]
	TIME [epoch: 7.62 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17076459588110166		[learning rate: 0.019764]
	Learning Rate: 0.0197638
	LOSS [training: 0.17076459588110166 | validation: 0.23270780089064158]
	TIME [epoch: 7.63 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2045434267679647		[learning rate: 0.01976]
	Learning Rate: 0.0197602
	LOSS [training: 0.2045434267679647 | validation: 0.16909654957934833]
	TIME [epoch: 7.68 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18634329975517505		[learning rate: 0.019757]
	Learning Rate: 0.0197566
	LOSS [training: 0.18634329975517505 | validation: 0.14322089622460293]
	TIME [epoch: 7.63 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15884647687093645		[learning rate: 0.019753]
	Learning Rate: 0.0197529
	LOSS [training: 0.15884647687093645 | validation: 0.10618144432037238]
	TIME [epoch: 7.61 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12926762149660315		[learning rate: 0.019749]
	Learning Rate: 0.0197493
	LOSS [training: 0.12926762149660315 | validation: 0.10475796345893262]
	TIME [epoch: 7.62 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15982695645950926		[learning rate: 0.019746]
	Learning Rate: 0.0197456
	LOSS [training: 0.15982695645950926 | validation: 0.18936773987203886]
	TIME [epoch: 7.63 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21595351543249877		[learning rate: 0.019742]
	Learning Rate: 0.0197419
	LOSS [training: 0.21595351543249877 | validation: 0.2035820482591721]
	TIME [epoch: 7.68 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19100639694079458		[learning rate: 0.019738]
	Learning Rate: 0.0197381
	LOSS [training: 0.19100639694079458 | validation: 0.12763175891669928]
	TIME [epoch: 7.63 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2144532479160476		[learning rate: 0.019734]
	Learning Rate: 0.0197343
	LOSS [training: 0.2144532479160476 | validation: 0.10762401931937418]
	TIME [epoch: 7.62 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1509063726179295		[learning rate: 0.019731]
	Learning Rate: 0.0197305
	LOSS [training: 0.1509063726179295 | validation: 0.1401996715418483]
	TIME [epoch: 7.63 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18262056493763476		[learning rate: 0.019727]
	Learning Rate: 0.0197267
	LOSS [training: 0.18262056493763476 | validation: 0.23327942317754158]
	TIME [epoch: 7.63 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17230747148351985		[learning rate: 0.019723]
	Learning Rate: 0.0197229
	LOSS [training: 0.17230747148351985 | validation: 0.18334127179480986]
	TIME [epoch: 7.68 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1778043322761359		[learning rate: 0.019719]
	Learning Rate: 0.019719
	LOSS [training: 0.1778043322761359 | validation: 0.11160556059081]
	TIME [epoch: 7.66 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15241736497031474		[learning rate: 0.019715]
	Learning Rate: 0.0197151
	LOSS [training: 0.15241736497031474 | validation: 0.13096575985331815]
	TIME [epoch: 7.62 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1626966728777629		[learning rate: 0.019711]
	Learning Rate: 0.0197112
	LOSS [training: 0.1626966728777629 | validation: 0.2449643489223985]
	TIME [epoch: 7.63 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1997005976266646		[learning rate: 0.019707]
	Learning Rate: 0.0197072
	LOSS [training: 0.1997005976266646 | validation: 0.17860418639715206]
	TIME [epoch: 7.63 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20999320676323666		[learning rate: 0.019703]
	Learning Rate: 0.0197032
	LOSS [training: 0.20999320676323666 | validation: 0.12593419895428315]
	TIME [epoch: 7.67 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13249526059668087		[learning rate: 0.019699]
	Learning Rate: 0.0196992
	LOSS [training: 0.13249526059668087 | validation: 0.13133967302952315]
	TIME [epoch: 7.65 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20063188881277108		[learning rate: 0.019695]
	Learning Rate: 0.0196952
	LOSS [training: 0.20063188881277108 | validation: 0.23775077916277038]
	TIME [epoch: 7.63 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20340334968073137		[learning rate: 0.019691]
	Learning Rate: 0.0196911
	LOSS [training: 0.20340334968073137 | validation: 0.09672267764900176]
	TIME [epoch: 138 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_201.pth
	Model improved!!!
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1398604045077918		[learning rate: 0.019687]
	Learning Rate: 0.019687
	LOSS [training: 0.1398604045077918 | validation: 0.12178627579523921]
	TIME [epoch: 14.9 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1873344883457135		[learning rate: 0.019683]
	Learning Rate: 0.0196829
	LOSS [training: 0.1873344883457135 | validation: 0.1451214576858591]
	TIME [epoch: 14.9 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22530441403544513		[learning rate: 0.019679]
	Learning Rate: 0.0196788
	LOSS [training: 0.22530441403544513 | validation: 0.09555035276129153]
	TIME [epoch: 14.9 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_204.pth
	Model improved!!!
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16950464901514045		[learning rate: 0.019675]
	Learning Rate: 0.0196746
	LOSS [training: 0.16950464901514045 | validation: 0.104073603036901]
	TIME [epoch: 14.8 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18661906359730815		[learning rate: 0.01967]
	Learning Rate: 0.0196704
	LOSS [training: 0.18661906359730815 | validation: 0.12494470443731097]
	TIME [epoch: 14.9 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1749500777565689		[learning rate: 0.019666]
	Learning Rate: 0.0196662
	LOSS [training: 0.1749500777565689 | validation: 0.13404834108145292]
	TIME [epoch: 14.9 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15041419889315047		[learning rate: 0.019662]
	Learning Rate: 0.0196619
	LOSS [training: 0.15041419889315047 | validation: 0.2313884606545573]
	TIME [epoch: 14.9 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17592980762593335		[learning rate: 0.019658]
	Learning Rate: 0.0196576
	LOSS [training: 0.17592980762593335 | validation: 0.16561684495091022]
	TIME [epoch: 14.9 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17908928033417368		[learning rate: 0.019653]
	Learning Rate: 0.0196533
	LOSS [training: 0.17908928033417368 | validation: 0.1730004740502715]
	TIME [epoch: 14.9 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17177819944412887		[learning rate: 0.019649]
	Learning Rate: 0.019649
	LOSS [training: 0.17177819944412887 | validation: 0.13527572217621525]
	TIME [epoch: 14.9 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16296834630529541		[learning rate: 0.019645]
	Learning Rate: 0.0196447
	LOSS [training: 0.16296834630529541 | validation: 0.09493205778863018]
	TIME [epoch: 14.9 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_212.pth
	Model improved!!!
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14691811339716446		[learning rate: 0.01964]
	Learning Rate: 0.0196403
	LOSS [training: 0.14691811339716446 | validation: 0.15240743978676724]
	TIME [epoch: 14.8 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1697089821175457		[learning rate: 0.019636]
	Learning Rate: 0.0196359
	LOSS [training: 0.1697089821175457 | validation: 0.15768214367847147]
	TIME [epoch: 14.9 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1728167620317898		[learning rate: 0.019631]
	Learning Rate: 0.0196314
	LOSS [training: 0.1728167620317898 | validation: 0.22845196856938993]
	TIME [epoch: 14.8 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1582623120314003		[learning rate: 0.019627]
	Learning Rate: 0.019627
	LOSS [training: 0.1582623120314003 | validation: 0.15510225024748697]
	TIME [epoch: 14.8 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1768622441177608		[learning rate: 0.019622]
	Learning Rate: 0.0196225
	LOSS [training: 0.1768622441177608 | validation: 0.10128110839848045]
	TIME [epoch: 14.9 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2380459953322711		[learning rate: 0.019618]
	Learning Rate: 0.019618
	LOSS [training: 0.2380459953322711 | validation: 0.1463134651379366]
	TIME [epoch: 14.8 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16758603743750006		[learning rate: 0.019613]
	Learning Rate: 0.0196134
	LOSS [training: 0.16758603743750006 | validation: 0.19238966199908056]
	TIME [epoch: 14.9 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1842690425081857		[learning rate: 0.019609]
	Learning Rate: 0.0196089
	LOSS [training: 0.1842690425081857 | validation: 0.1523614515765942]
	TIME [epoch: 14.9 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18892022888505325		[learning rate: 0.019604]
	Learning Rate: 0.0196043
	LOSS [training: 0.18892022888505325 | validation: 0.1355923757157101]
	TIME [epoch: 14.8 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14147226581333588		[learning rate: 0.0196]
	Learning Rate: 0.0195997
	LOSS [training: 0.14147226581333588 | validation: 0.11302616182103734]
	TIME [epoch: 14.8 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1520538628320218		[learning rate: 0.019595]
	Learning Rate: 0.019595
	LOSS [training: 0.1520538628320218 | validation: 0.19274651725389214]
	TIME [epoch: 14.9 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20384814241230087		[learning rate: 0.01959]
	Learning Rate: 0.0195904
	LOSS [training: 0.20384814241230087 | validation: 0.09980393894721049]
	TIME [epoch: 14.9 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15833123493767487		[learning rate: 0.019586]
	Learning Rate: 0.0195857
	LOSS [training: 0.15833123493767487 | validation: 0.10276077475026098]
	TIME [epoch: 14.9 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16132407536379265		[learning rate: 0.019581]
	Learning Rate: 0.0195809
	LOSS [training: 0.16132407536379265 | validation: 0.09910622540094091]
	TIME [epoch: 14.9 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16631927367694407		[learning rate: 0.019576]
	Learning Rate: 0.0195762
	LOSS [training: 0.16631927367694407 | validation: 0.0974725208099133]
	TIME [epoch: 14.8 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13621248674807176		[learning rate: 0.019571]
	Learning Rate: 0.0195714
	LOSS [training: 0.13621248674807176 | validation: 0.10582216518010458]
	TIME [epoch: 14.9 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15396819997904948		[learning rate: 0.019567]
	Learning Rate: 0.0195666
	LOSS [training: 0.15396819997904948 | validation: 0.10390579205475974]
	TIME [epoch: 14.9 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1316785206971509		[learning rate: 0.019562]
	Learning Rate: 0.0195618
	LOSS [training: 0.1316785206971509 | validation: 0.23343690225691224]
	TIME [epoch: 14.8 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20604278721193048		[learning rate: 0.019557]
	Learning Rate: 0.0195569
	LOSS [training: 0.20604278721193048 | validation: 0.1537552847695154]
	TIME [epoch: 14.9 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1720317661363958		[learning rate: 0.019552]
	Learning Rate: 0.0195521
	LOSS [training: 0.1720317661363958 | validation: 0.13155266485236816]
	TIME [epoch: 14.9 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1487880172726062		[learning rate: 0.019547]
	Learning Rate: 0.0195472
	LOSS [training: 0.1487880172726062 | validation: 0.20047829545992168]
	TIME [epoch: 14.8 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15461474686746257		[learning rate: 0.019542]
	Learning Rate: 0.0195422
	LOSS [training: 0.15461474686746257 | validation: 0.14868480202492335]
	TIME [epoch: 14.9 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16770086280143962		[learning rate: 0.019537]
	Learning Rate: 0.0195373
	LOSS [training: 0.16770086280143962 | validation: 0.22607019350824112]
	TIME [epoch: 14.8 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15581382045293388		[learning rate: 0.019532]
	Learning Rate: 0.0195323
	LOSS [training: 0.15581382045293388 | validation: 0.13465105200513694]
	TIME [epoch: 14.8 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14298305879998233		[learning rate: 0.019527]
	Learning Rate: 0.0195273
	LOSS [training: 0.14298305879998233 | validation: 0.15900491892693283]
	TIME [epoch: 14.9 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1372359824034606		[learning rate: 0.019522]
	Learning Rate: 0.0195222
	LOSS [training: 0.1372359824034606 | validation: 0.12324866095576502]
	TIME [epoch: 14.8 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29467069862998285		[learning rate: 0.019517]
	Learning Rate: 0.0195172
	LOSS [training: 0.29467069862998285 | validation: 0.16977547374916407]
	TIME [epoch: 14.8 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2090542168727867		[learning rate: 0.019512]
	Learning Rate: 0.0195121
	LOSS [training: 0.2090542168727867 | validation: 0.23234019023147165]
	TIME [epoch: 14.9 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13526533756665063		[learning rate: 0.019507]
	Learning Rate: 0.019507
	LOSS [training: 0.13526533756665063 | validation: 0.09271187279110818]
	TIME [epoch: 14.8 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_241.pth
	Model improved!!!
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12426435573047145		[learning rate: 0.019502]
	Learning Rate: 0.0195018
	LOSS [training: 0.12426435573047145 | validation: 0.08079314422918937]
	TIME [epoch: 14.9 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_242.pth
	Model improved!!!
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1410637307775374		[learning rate: 0.019497]
	Learning Rate: 0.0194967
	LOSS [training: 0.1410637307775374 | validation: 0.22099086967222936]
	TIME [epoch: 14.9 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16577747431531478		[learning rate: 0.019491]
	Learning Rate: 0.0194915
	LOSS [training: 0.16577747431531478 | validation: 0.17153271546721294]
	TIME [epoch: 14.8 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1785133400954566		[learning rate: 0.019486]
	Learning Rate: 0.0194863
	LOSS [training: 0.1785133400954566 | validation: 0.10206472980674923]
	TIME [epoch: 14.9 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1311772303240517		[learning rate: 0.019481]
	Learning Rate: 0.019481
	LOSS [training: 0.1311772303240517 | validation: 0.08701227411581035]
	TIME [epoch: 14.8 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1536273397569401		[learning rate: 0.019476]
	Learning Rate: 0.0194757
	LOSS [training: 0.1536273397569401 | validation: 0.0853221968228901]
	TIME [epoch: 14.8 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15357548500914686		[learning rate: 0.01947]
	Learning Rate: 0.0194705
	LOSS [training: 0.15357548500914686 | validation: 0.09384701239089638]
	TIME [epoch: 14.9 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13612619801088272		[learning rate: 0.019465]
	Learning Rate: 0.0194651
	LOSS [training: 0.13612619801088272 | validation: 0.14884182603409246]
	TIME [epoch: 14.8 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1432976964692019		[learning rate: 0.01946]
	Learning Rate: 0.0194598
	LOSS [training: 0.1432976964692019 | validation: 0.2513277150454607]
	TIME [epoch: 14.9 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19107777222014422		[learning rate: 0.019454]
	Learning Rate: 0.0194544
	LOSS [training: 0.19107777222014422 | validation: 0.10452558725337041]
	TIME [epoch: 14.9 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1374951884765999		[learning rate: 0.019449]
	Learning Rate: 0.019449
	LOSS [training: 0.1374951884765999 | validation: 0.14656023389405495]
	TIME [epoch: 14.8 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12434269400179114		[learning rate: 0.019444]
	Learning Rate: 0.0194436
	LOSS [training: 0.12434269400179114 | validation: 0.06828080181519769]
	TIME [epoch: 14.9 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_253.pth
	Model improved!!!
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13335745877955268		[learning rate: 0.019438]
	Learning Rate: 0.0194381
	LOSS [training: 0.13335745877955268 | validation: 0.3237289707472786]
	TIME [epoch: 14.9 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19339754419934213		[learning rate: 0.019433]
	Learning Rate: 0.0194327
	LOSS [training: 0.19339754419934213 | validation: 0.10608276650334142]
	TIME [epoch: 14.9 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1496468289029068		[learning rate: 0.019427]
	Learning Rate: 0.0194272
	LOSS [training: 0.1496468289029068 | validation: 0.08770928989777263]
	TIME [epoch: 14.9 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15344735431213702		[learning rate: 0.019422]
	Learning Rate: 0.0194216
	LOSS [training: 0.15344735431213702 | validation: 0.11903672700781262]
	TIME [epoch: 14.9 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12236656102162015		[learning rate: 0.019416]
	Learning Rate: 0.0194161
	LOSS [training: 0.12236656102162015 | validation: 0.9073708857296972]
	TIME [epoch: 14.9 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43104931964055265		[learning rate: 0.019411]
	Learning Rate: 0.0194105
	LOSS [training: 0.43104931964055265 | validation: 0.12855676095566998]
	TIME [epoch: 14.9 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15229635749881243		[learning rate: 0.019405]
	Learning Rate: 0.0194049
	LOSS [training: 0.15229635749881243 | validation: 0.1030885292962633]
	TIME [epoch: 14.9 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1376536984318948		[learning rate: 0.019399]
	Learning Rate: 0.0193993
	LOSS [training: 0.1376536984318948 | validation: 0.1639278200945577]
	TIME [epoch: 15 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13357731976127982		[learning rate: 0.019394]
	Learning Rate: 0.0193936
	LOSS [training: 0.13357731976127982 | validation: 0.11005840738835854]
	TIME [epoch: 14.9 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14926889536129656		[learning rate: 0.019388]
	Learning Rate: 0.0193879
	LOSS [training: 0.14926889536129656 | validation: 0.10012581745821866]
	TIME [epoch: 14.9 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16028807428221653		[learning rate: 0.019382]
	Learning Rate: 0.0193822
	LOSS [training: 0.16028807428221653 | validation: 0.08853699420594387]
	TIME [epoch: 14.9 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13328716845368385		[learning rate: 0.019376]
	Learning Rate: 0.0193765
	LOSS [training: 0.13328716845368385 | validation: 0.12654454101911108]
	TIME [epoch: 14.9 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12543816345215705		[learning rate: 0.019371]
	Learning Rate: 0.0193707
	LOSS [training: 0.12543816345215705 | validation: 0.21511715956506416]
	TIME [epoch: 14.9 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2608470826408861		[learning rate: 0.019365]
	Learning Rate: 0.0193649
	LOSS [training: 0.2608470826408861 | validation: 0.11612996487575397]
	TIME [epoch: 15 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1512628028580791		[learning rate: 0.019359]
	Learning Rate: 0.0193591
	LOSS [training: 0.1512628028580791 | validation: 0.08757844287008834]
	TIME [epoch: 14.9 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11919125534149753		[learning rate: 0.019353]
	Learning Rate: 0.0193533
	LOSS [training: 0.11919125534149753 | validation: 0.076522156615486]
	TIME [epoch: 15 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.144707293797642		[learning rate: 0.019347]
	Learning Rate: 0.0193474
	LOSS [training: 0.144707293797642 | validation: 0.1111992246435542]
	TIME [epoch: 14.9 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13930842263658666		[learning rate: 0.019342]
	Learning Rate: 0.0193416
	LOSS [training: 0.13930842263658666 | validation: 0.08965167311217609]
	TIME [epoch: 14.9 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14463119320946521		[learning rate: 0.019336]
	Learning Rate: 0.0193356
	LOSS [training: 0.14463119320946521 | validation: 0.08115961694747646]
	TIME [epoch: 15 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12653432119768107		[learning rate: 0.01933]
	Learning Rate: 0.0193297
	LOSS [training: 0.12653432119768107 | validation: 0.0807903383527131]
	TIME [epoch: 14.9 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14905569853624362		[learning rate: 0.019324]
	Learning Rate: 0.0193237
	LOSS [training: 0.14905569853624362 | validation: 0.09838343409185057]
	TIME [epoch: 14.9 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1350506969946103		[learning rate: 0.019318]
	Learning Rate: 0.0193178
	LOSS [training: 0.1350506969946103 | validation: 0.16551195723799914]
	TIME [epoch: 15 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15605307307531308		[learning rate: 0.019312]
	Learning Rate: 0.0193117
	LOSS [training: 0.15605307307531308 | validation: 0.1138991241133176]
	TIME [epoch: 14.9 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13465707872436455		[learning rate: 0.019306]
	Learning Rate: 0.0193057
	LOSS [training: 0.13465707872436455 | validation: 0.07503897124292844]
	TIME [epoch: 14.9 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15631088394302062		[learning rate: 0.0193]
	Learning Rate: 0.0192996
	LOSS [training: 0.15631088394302062 | validation: 0.2209499199413546]
	TIME [epoch: 14.9 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22098173069384644		[learning rate: 0.019294]
	Learning Rate: 0.0192935
	LOSS [training: 0.22098173069384644 | validation: 0.1567404938154993]
	TIME [epoch: 14.9 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12914620010740255		[learning rate: 0.019287]
	Learning Rate: 0.0192874
	LOSS [training: 0.12914620010740255 | validation: 0.11520435173559893]
	TIME [epoch: 14.9 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15660172251721383		[learning rate: 0.019281]
	Learning Rate: 0.0192813
	LOSS [training: 0.15660172251721383 | validation: 0.09134922857038409]
	TIME [epoch: 14.9 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14243614528427673		[learning rate: 0.019275]
	Learning Rate: 0.0192751
	LOSS [training: 0.14243614528427673 | validation: 0.1302308036664176]
	TIME [epoch: 14.9 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12021654591771624		[learning rate: 0.019269]
	Learning Rate: 0.0192689
	LOSS [training: 0.12021654591771624 | validation: 0.1654823965597662]
	TIME [epoch: 15 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16752031569626707		[learning rate: 0.019263]
	Learning Rate: 0.0192627
	LOSS [training: 0.16752031569626707 | validation: 0.11902949303311722]
	TIME [epoch: 14.9 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14638783350546736		[learning rate: 0.019256]
	Learning Rate: 0.0192565
	LOSS [training: 0.14638783350546736 | validation: 0.0913332203185119]
	TIME [epoch: 14.9 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12431737026566786		[learning rate: 0.01925]
	Learning Rate: 0.0192502
	LOSS [training: 0.12431737026566786 | validation: 0.10806820220897029]
	TIME [epoch: 14.9 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2114014189043104		[learning rate: 0.019244]
	Learning Rate: 0.0192439
	LOSS [training: 0.2114014189043104 | validation: 0.19689586281790966]
	TIME [epoch: 14.9 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3192343982488357		[learning rate: 0.019238]
	Learning Rate: 0.0192376
	LOSS [training: 0.3192343982488357 | validation: 0.16176293618058635]
	TIME [epoch: 15 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22151820406128148		[learning rate: 0.019231]
	Learning Rate: 0.0192313
	LOSS [training: 0.22151820406128148 | validation: 0.10251443068589565]
	TIME [epoch: 14.9 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1571384545626494		[learning rate: 0.019225]
	Learning Rate: 0.0192249
	LOSS [training: 0.1571384545626494 | validation: 0.08467139347739597]
	TIME [epoch: 14.9 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13772862229991256		[learning rate: 0.019218]
	Learning Rate: 0.0192185
	LOSS [training: 0.13772862229991256 | validation: 0.09246770600933513]
	TIME [epoch: 15 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15560964777127262		[learning rate: 0.019212]
	Learning Rate: 0.0192121
	LOSS [training: 0.15560964777127262 | validation: 0.11598481983085082]
	TIME [epoch: 14.9 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14037852012149077		[learning rate: 0.019206]
	Learning Rate: 0.0192056
	LOSS [training: 0.14037852012149077 | validation: 0.1340787403558814]
	TIME [epoch: 15 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1362265442824161		[learning rate: 0.019199]
	Learning Rate: 0.0191992
	LOSS [training: 0.1362265442824161 | validation: 0.1343577737168155]
	TIME [epoch: 14.9 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12856848668399118		[learning rate: 0.019193]
	Learning Rate: 0.0191927
	LOSS [training: 0.12856848668399118 | validation: 0.14533259933697312]
	TIME [epoch: 14.9 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15643286451895294		[learning rate: 0.019186]
	Learning Rate: 0.0191861
	LOSS [training: 0.15643286451895294 | validation: 0.12001595954544195]
	TIME [epoch: 14.9 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13477603814826056		[learning rate: 0.01918]
	Learning Rate: 0.0191796
	LOSS [training: 0.13477603814826056 | validation: 0.1854248665439497]
	TIME [epoch: 14.9 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11446571084324439		[learning rate: 0.019173]
	Learning Rate: 0.019173
	LOSS [training: 0.11446571084324439 | validation: 0.09651395612921673]
	TIME [epoch: 14.9 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12929576530453213		[learning rate: 0.019166]
	Learning Rate: 0.0191664
	LOSS [training: 0.12929576530453213 | validation: 0.08960641612047565]
	TIME [epoch: 15 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15229493559783294		[learning rate: 0.01916]
	Learning Rate: 0.0191598
	LOSS [training: 0.15229493559783294 | validation: 0.25726943069983377]
	TIME [epoch: 14.9 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1733239751746537		[learning rate: 0.019153]
	Learning Rate: 0.0191532
	LOSS [training: 0.1733239751746537 | validation: 0.08668992739016262]
	TIME [epoch: 14.9 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14029250506223817		[learning rate: 0.019146]
	Learning Rate: 0.0191465
	LOSS [training: 0.14029250506223817 | validation: 0.1309841052178131]
	TIME [epoch: 14.9 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1411288979139393		[learning rate: 0.01914]
	Learning Rate: 0.0191398
	LOSS [training: 0.1411288979139393 | validation: 0.07629492801963167]
	TIME [epoch: 14.9 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11890614588307016		[learning rate: 0.019133]
	Learning Rate: 0.0191331
	LOSS [training: 0.11890614588307016 | validation: 0.07711291877312587]
	TIME [epoch: 15 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12118623887801867		[learning rate: 0.019126]
	Learning Rate: 0.0191263
	LOSS [training: 0.12118623887801867 | validation: 0.09360803954022374]
	TIME [epoch: 14.9 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14900929835768764		[learning rate: 0.01912]
	Learning Rate: 0.0191196
	LOSS [training: 0.14900929835768764 | validation: 0.10828336424218327]
	TIME [epoch: 14.9 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13767673220635762		[learning rate: 0.019113]
	Learning Rate: 0.0191128
	LOSS [training: 0.13767673220635762 | validation: 0.1631940157983084]
	TIME [epoch: 14.9 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16798175185880562		[learning rate: 0.019106]
	Learning Rate: 0.019106
	LOSS [training: 0.16798175185880562 | validation: 0.17913788738489367]
	TIME [epoch: 14.9 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19900427278606153		[learning rate: 0.019099]
	Learning Rate: 0.0190991
	LOSS [training: 0.19900427278606153 | validation: 0.07951309255542247]
	TIME [epoch: 14.9 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14175748099535507		[learning rate: 0.019092]
	Learning Rate: 0.0190922
	LOSS [training: 0.14175748099535507 | validation: 0.10217805712909836]
	TIME [epoch: 14.9 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10316762802036628		[learning rate: 0.019085]
	Learning Rate: 0.0190853
	LOSS [training: 0.10316762802036628 | validation: 0.08525159249706185]
	TIME [epoch: 14.9 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15028248264678057		[learning rate: 0.019078]
	Learning Rate: 0.0190784
	LOSS [training: 0.15028248264678057 | validation: 0.12938032544684863]
	TIME [epoch: 14.9 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1443556440111921		[learning rate: 0.019071]
	Learning Rate: 0.0190715
	LOSS [training: 0.1443556440111921 | validation: 0.18545247978030976]
	TIME [epoch: 14.9 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19903039195926012		[learning rate: 0.019065]
	Learning Rate: 0.0190645
	LOSS [training: 0.19903039195926012 | validation: 0.11092550310979149]
	TIME [epoch: 14.9 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09453502000279772		[learning rate: 0.019058]
	Learning Rate: 0.0190575
	LOSS [training: 0.09453502000279772 | validation: 0.14907523834193187]
	TIME [epoch: 14.9 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11321205948278693		[learning rate: 0.019051]
	Learning Rate: 0.0190505
	LOSS [training: 0.11321205948278693 | validation: 0.06278063072381257]
	TIME [epoch: 14.9 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_316.pth
	Model improved!!!
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16662003916114185		[learning rate: 0.019043]
	Learning Rate: 0.0190435
	LOSS [training: 0.16662003916114185 | validation: 0.07769345678686149]
	TIME [epoch: 14.9 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10247045198831822		[learning rate: 0.019036]
	Learning Rate: 0.0190364
	LOSS [training: 0.10247045198831822 | validation: 0.06966101638024633]
	TIME [epoch: 14.9 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13667289930521292		[learning rate: 0.019029]
	Learning Rate: 0.0190293
	LOSS [training: 0.13667289930521292 | validation: 0.1324306233585668]
	TIME [epoch: 14.9 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12653802996451796		[learning rate: 0.019022]
	Learning Rate: 0.0190222
	LOSS [training: 0.12653802996451796 | validation: 0.12061047042359704]
	TIME [epoch: 15 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11216433223822037		[learning rate: 0.019015]
	Learning Rate: 0.019015
	LOSS [training: 0.11216433223822037 | validation: 0.20000718319129035]
	TIME [epoch: 14.9 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11260645181624582		[learning rate: 0.019008]
	Learning Rate: 0.0190079
	LOSS [training: 0.11260645181624582 | validation: 0.1474809254755352]
	TIME [epoch: 14.9 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11834150678180719		[learning rate: 0.019001]
	Learning Rate: 0.0190007
	LOSS [training: 0.11834150678180719 | validation: 0.09551193628025453]
	TIME [epoch: 15 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13860104581662572		[learning rate: 0.018993]
	Learning Rate: 0.0189935
	LOSS [training: 0.13860104581662572 | validation: 0.0942021894936606]
	TIME [epoch: 14.9 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10398185463760798		[learning rate: 0.018986]
	Learning Rate: 0.0189862
	LOSS [training: 0.10398185463760798 | validation: 0.15606021515017524]
	TIME [epoch: 14.9 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0965874742457822		[learning rate: 0.018979]
	Learning Rate: 0.018979
	LOSS [training: 0.0965874742457822 | validation: 0.11919781131699941]
	TIME [epoch: 14.9 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1283032167690542		[learning rate: 0.018972]
	Learning Rate: 0.0189717
	LOSS [training: 0.1283032167690542 | validation: 0.16780585649048774]
	TIME [epoch: 14.9 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14046478637310514		[learning rate: 0.018964]
	Learning Rate: 0.0189644
	LOSS [training: 0.14046478637310514 | validation: 0.08857460485198042]
	TIME [epoch: 14.9 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14149017330762292		[learning rate: 0.018957]
	Learning Rate: 0.018957
	LOSS [training: 0.14149017330762292 | validation: 0.07244931894859181]
	TIME [epoch: 14.9 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15286853051915825		[learning rate: 0.01895]
	Learning Rate: 0.0189497
	LOSS [training: 0.15286853051915825 | validation: 0.08866614123051589]
	TIME [epoch: 14.9 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10585220071509135		[learning rate: 0.018942]
	Learning Rate: 0.0189423
	LOSS [training: 0.10585220071509135 | validation: 0.14427430247297418]
	TIME [epoch: 14.9 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11213325658437462		[learning rate: 0.018935]
	Learning Rate: 0.0189349
	LOSS [training: 0.11213325658437462 | validation: 0.09130604757939194]
	TIME [epoch: 14.9 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2128042744516701		[learning rate: 0.018927]
	Learning Rate: 0.0189274
	LOSS [training: 0.2128042744516701 | validation: 0.22055452166804024]
	TIME [epoch: 14.9 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21130816445566444		[learning rate: 0.01892]
	Learning Rate: 0.01892
	LOSS [training: 0.21130816445566444 | validation: 0.27378008266292375]
	TIME [epoch: 14.9 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13674008529835147		[learning rate: 0.018912]
	Learning Rate: 0.0189125
	LOSS [training: 0.13674008529835147 | validation: 0.08791714919118196]
	TIME [epoch: 14.9 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14710208503578767		[learning rate: 0.018905]
	Learning Rate: 0.018905
	LOSS [training: 0.14710208503578767 | validation: 0.060928868378216025]
	TIME [epoch: 14.9 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_336.pth
	Model improved!!!
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09823326396965706		[learning rate: 0.018897]
	Learning Rate: 0.0188974
	LOSS [training: 0.09823326396965706 | validation: 0.10400933194850302]
	TIME [epoch: 14.9 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1587750402456261		[learning rate: 0.01889]
	Learning Rate: 0.0188899
	LOSS [training: 0.1587750402456261 | validation: 0.11197822246836721]
	TIME [epoch: 14.9 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10992714339700053		[learning rate: 0.018882]
	Learning Rate: 0.0188823
	LOSS [training: 0.10992714339700053 | validation: 0.06112255788681167]
	TIME [epoch: 14.9 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10181499516946903		[learning rate: 0.018875]
	Learning Rate: 0.0188747
	LOSS [training: 0.10181499516946903 | validation: 0.09022692364436759]
	TIME [epoch: 14.9 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10358601433267885		[learning rate: 0.018867]
	Learning Rate: 0.0188671
	LOSS [training: 0.10358601433267885 | validation: 0.05408957602514218]
	TIME [epoch: 14.9 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_341.pth
	Model improved!!!
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14615425182576036		[learning rate: 0.018859]
	Learning Rate: 0.0188594
	LOSS [training: 0.14615425182576036 | validation: 0.09474686153465775]
	TIME [epoch: 14.9 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10309831167566491		[learning rate: 0.018852]
	Learning Rate: 0.0188517
	LOSS [training: 0.10309831167566491 | validation: 0.06432992945703926]
	TIME [epoch: 14.8 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12358136680660671		[learning rate: 0.018844]
	Learning Rate: 0.018844
	LOSS [training: 0.12358136680660671 | validation: 0.055145744518571]
	TIME [epoch: 14.9 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11344147801566051		[learning rate: 0.018836]
	Learning Rate: 0.0188363
	LOSS [training: 0.11344147801566051 | validation: 0.09321798134478618]
	TIME [epoch: 14.8 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09926511729029945		[learning rate: 0.018829]
	Learning Rate: 0.0188286
	LOSS [training: 0.09926511729029945 | validation: 0.057740966332912605]
	TIME [epoch: 14.8 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10458970594615401		[learning rate: 0.018821]
	Learning Rate: 0.0188208
	LOSS [training: 0.10458970594615401 | validation: 0.09076173413273841]
	TIME [epoch: 14.9 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09194558259814804		[learning rate: 0.018813]
	Learning Rate: 0.018813
	LOSS [training: 0.09194558259814804 | validation: 0.08216554880306791]
	TIME [epoch: 14.8 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10585688076468971		[learning rate: 0.018805]
	Learning Rate: 0.0188052
	LOSS [training: 0.10585688076468971 | validation: 0.05162916134208289]
	TIME [epoch: 14.8 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_349.pth
	Model improved!!!
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10122409199883768		[learning rate: 0.018797]
	Learning Rate: 0.0187973
	LOSS [training: 0.10122409199883768 | validation: 0.052097474167405934]
	TIME [epoch: 14.9 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11476731307416518		[learning rate: 0.018789]
	Learning Rate: 0.0187894
	LOSS [training: 0.11476731307416518 | validation: 0.08118950931431838]
	TIME [epoch: 14.8 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10740308055748338		[learning rate: 0.018782]
	Learning Rate: 0.0187815
	LOSS [training: 0.10740308055748338 | validation: 0.050723519052875046]
	TIME [epoch: 14.9 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_352.pth
	Model improved!!!
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11239169857041612		[learning rate: 0.018774]
	Learning Rate: 0.0187736
	LOSS [training: 0.11239169857041612 | validation: 0.14549942208821876]
	TIME [epoch: 14.8 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07989574019803153		[learning rate: 0.018766]
	Learning Rate: 0.0187657
	LOSS [training: 0.07989574019803153 | validation: 0.10335413172182706]
	TIME [epoch: 14.8 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0768927576432791		[learning rate: 0.018758]
	Learning Rate: 0.0187577
	LOSS [training: 0.0768927576432791 | validation: 0.13522709155526885]
	TIME [epoch: 14.9 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11005404101110972		[learning rate: 0.01875]
	Learning Rate: 0.0187497
	LOSS [training: 0.11005404101110972 | validation: 0.05126495494815925]
	TIME [epoch: 14.8 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13194080876494954		[learning rate: 0.018742]
	Learning Rate: 0.0187417
	LOSS [training: 0.13194080876494954 | validation: 0.19180318441655214]
	TIME [epoch: 14.9 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15977527176281184		[learning rate: 0.018734]
	Learning Rate: 0.0187337
	LOSS [training: 0.15977527176281184 | validation: 0.0669481674557007]
	TIME [epoch: 14.9 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1421844634096171		[learning rate: 0.018726]
	Learning Rate: 0.0187256
	LOSS [training: 0.1421844634096171 | validation: 0.06571034725326444]
	TIME [epoch: 14.8 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06254194766327123		[learning rate: 0.018718]
	Learning Rate: 0.0187175
	LOSS [training: 0.06254194766327123 | validation: 0.1736775808001675]
	TIME [epoch: 14.9 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1947230718633054		[learning rate: 0.018709]
	Learning Rate: 0.0187094
	LOSS [training: 0.1947230718633054 | validation: 0.05610802456131407]
	TIME [epoch: 14.8 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0974608077385028		[learning rate: 0.018701]
	Learning Rate: 0.0187013
	LOSS [training: 0.0974608077385028 | validation: 0.04938906457470818]
	TIME [epoch: 14.8 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_362.pth
	Model improved!!!
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054896256303478705		[learning rate: 0.018693]
	Learning Rate: 0.0186931
	LOSS [training: 0.054896256303478705 | validation: 0.04603566739399754]
	TIME [epoch: 14.9 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_363.pth
	Model improved!!!
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10272348433970833		[learning rate: 0.018685]
	Learning Rate: 0.0186849
	LOSS [training: 0.10272348433970833 | validation: 0.09135896457576898]
	TIME [epoch: 14.8 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09286041153203253		[learning rate: 0.018677]
	Learning Rate: 0.0186767
	LOSS [training: 0.09286041153203253 | validation: 0.15521598894022168]
	TIME [epoch: 14.8 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1346017433486556		[learning rate: 0.018668]
	Learning Rate: 0.0186685
	LOSS [training: 0.1346017433486556 | validation: 0.04300630355107357]
	TIME [epoch: 14.9 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_366.pth
	Model improved!!!
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0923414916146519		[learning rate: 0.01866]
	Learning Rate: 0.0186602
	LOSS [training: 0.0923414916146519 | validation: 0.0562294108628511]
	TIME [epoch: 14.9 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08245427356987944		[learning rate: 0.018652]
	Learning Rate: 0.018652
	LOSS [training: 0.08245427356987944 | validation: 0.0995165795573057]
	TIME [epoch: 14.9 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.084004761901719		[learning rate: 0.018644]
	Learning Rate: 0.0186437
	LOSS [training: 0.084004761901719 | validation: 0.03709983203733691]
	TIME [epoch: 14.9 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_369.pth
	Model improved!!!
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07773630349820285		[learning rate: 0.018635]
	Learning Rate: 0.0186353
	LOSS [training: 0.07773630349820285 | validation: 0.16100646241195082]
	TIME [epoch: 14.9 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3081939091513759		[learning rate: 0.018627]
	Learning Rate: 0.018627
	LOSS [training: 0.3081939091513759 | validation: 0.07285942077644719]
	TIME [epoch: 14.9 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08962054995876005		[learning rate: 0.018619]
	Learning Rate: 0.0186186
	LOSS [training: 0.08962054995876005 | validation: 0.09043701527101981]
	TIME [epoch: 14.9 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08749391147708949		[learning rate: 0.01861]
	Learning Rate: 0.0186102
	LOSS [training: 0.08749391147708949 | validation: 0.0442638900400226]
	TIME [epoch: 14.9 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0802440055342772		[learning rate: 0.018602]
	Learning Rate: 0.0186018
	LOSS [training: 0.0802440055342772 | validation: 0.046758799331108936]
	TIME [epoch: 15 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08166721983431997		[learning rate: 0.018593]
	Learning Rate: 0.0185934
	LOSS [training: 0.08166721983431997 | validation: 0.11984884430851142]
	TIME [epoch: 14.9 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14091066767115382		[learning rate: 0.018585]
	Learning Rate: 0.0185849
	LOSS [training: 0.14091066767115382 | validation: 0.04438993982368436]
	TIME [epoch: 15 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09498905926900886		[learning rate: 0.018576]
	Learning Rate: 0.0185764
	LOSS [training: 0.09498905926900886 | validation: 0.049851567487700456]
	TIME [epoch: 14.9 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10841620764690646		[learning rate: 0.018568]
	Learning Rate: 0.0185679
	LOSS [training: 0.10841620764690646 | validation: 0.1073073368842932]
	TIME [epoch: 14.9 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18801401757940286		[learning rate: 0.018559]
	Learning Rate: 0.0185594
	LOSS [training: 0.18801401757940286 | validation: 0.10644624507674269]
	TIME [epoch: 15 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08288704829267161		[learning rate: 0.018551]
	Learning Rate: 0.0185508
	LOSS [training: 0.08288704829267161 | validation: 0.05864706648596331]
	TIME [epoch: 14.9 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11800646890745962		[learning rate: 0.018542]
	Learning Rate: 0.0185422
	LOSS [training: 0.11800646890745962 | validation: 0.0795494254554438]
	TIME [epoch: 14.9 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06754530743859867		[learning rate: 0.018534]
	Learning Rate: 0.0185336
	LOSS [training: 0.06754530743859867 | validation: 0.04860344606249159]
	TIME [epoch: 14.9 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08535870235524094		[learning rate: 0.018525]
	Learning Rate: 0.018525
	LOSS [training: 0.08535870235524094 | validation: 0.07327565701912246]
	TIME [epoch: 14.9 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10537843067591081		[learning rate: 0.018516]
	Learning Rate: 0.0185163
	LOSS [training: 0.10537843067591081 | validation: 0.0882755311506547]
	TIME [epoch: 14.9 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10917669100412966		[learning rate: 0.018508]
	Learning Rate: 0.0185077
	LOSS [training: 0.10917669100412966 | validation: 0.06906592463842466]
	TIME [epoch: 14.9 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07322917266679459		[learning rate: 0.018499]
	Learning Rate: 0.018499
	LOSS [training: 0.07322917266679459 | validation: 0.03987601516874503]
	TIME [epoch: 14.9 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07449655206652546		[learning rate: 0.01849]
	Learning Rate: 0.0184902
	LOSS [training: 0.07449655206652546 | validation: 0.07734907524423426]
	TIME [epoch: 15 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11719907954056653		[learning rate: 0.018481]
	Learning Rate: 0.0184815
	LOSS [training: 0.11719907954056653 | validation: 0.18719249441269958]
	TIME [epoch: 14.9 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10085370596344843		[learning rate: 0.018473]
	Learning Rate: 0.0184727
	LOSS [training: 0.10085370596344843 | validation: 0.05800470491968228]
	TIME [epoch: 14.9 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10650047322110666		[learning rate: 0.018464]
	Learning Rate: 0.0184639
	LOSS [training: 0.10650047322110666 | validation: 0.11669785661795964]
	TIME [epoch: 15 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09411371196990831		[learning rate: 0.018455]
	Learning Rate: 0.0184551
	LOSS [training: 0.09411371196990831 | validation: 0.08540679088348416]
	TIME [epoch: 14.9 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06789455716813446		[learning rate: 0.018446]
	Learning Rate: 0.0184463
	LOSS [training: 0.06789455716813446 | validation: 0.09933179895261536]
	TIME [epoch: 14.9 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09235014871547903		[learning rate: 0.018437]
	Learning Rate: 0.0184374
	LOSS [training: 0.09235014871547903 | validation: 0.15009588831280024]
	TIME [epoch: 14.9 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06901032515752602		[learning rate: 0.018429]
	Learning Rate: 0.0184285
	LOSS [training: 0.06901032515752602 | validation: 0.040785715159314284]
	TIME [epoch: 14.9 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1097976214854944		[learning rate: 0.01842]
	Learning Rate: 0.0184196
	LOSS [training: 0.1097976214854944 | validation: 0.18475833876124245]
	TIME [epoch: 14.9 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09477030007629529		[learning rate: 0.018411]
	Learning Rate: 0.0184107
	LOSS [training: 0.09477030007629529 | validation: 0.06702233051498965]
	TIME [epoch: 14.9 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08743608220629581		[learning rate: 0.018402]
	Learning Rate: 0.0184017
	LOSS [training: 0.08743608220629581 | validation: 0.04502268571694836]
	TIME [epoch: 14.9 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08196388411524398		[learning rate: 0.018393]
	Learning Rate: 0.0183928
	LOSS [training: 0.08196388411524398 | validation: 0.10782463572305204]
	TIME [epoch: 14.9 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07042547468724786		[learning rate: 0.018384]
	Learning Rate: 0.0183838
	LOSS [training: 0.07042547468724786 | validation: 0.05262721543315836]
	TIME [epoch: 14.9 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09354393118471233		[learning rate: 0.018375]
	Learning Rate: 0.0183747
	LOSS [training: 0.09354393118471233 | validation: 0.06366468462609895]
	TIME [epoch: 14.9 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12234627683660684		[learning rate: 0.018366]
	Learning Rate: 0.0183657
	LOSS [training: 0.12234627683660684 | validation: 0.11508820909350621]
	TIME [epoch: 14.9 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10088517227485826		[learning rate: 0.018357]
	Learning Rate: 0.0183566
	LOSS [training: 0.10088517227485826 | validation: 0.05559784309171176]
	TIME [epoch: 14.9 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09550240433364988		[learning rate: 0.018348]
	Learning Rate: 0.0183475
	LOSS [training: 0.09550240433364988 | validation: 0.0618707109655506]
	TIME [epoch: 14.9 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09092359341165508		[learning rate: 0.018338]
	Learning Rate: 0.0183384
	LOSS [training: 0.09092359341165508 | validation: 0.07076160193773832]
	TIME [epoch: 14.9 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058646882226374056		[learning rate: 0.018329]
	Learning Rate: 0.0183293
	LOSS [training: 0.058646882226374056 | validation: 0.04964039282151138]
	TIME [epoch: 14.9 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12775402238580705		[learning rate: 0.01832]
	Learning Rate: 0.0183201
	LOSS [training: 0.12775402238580705 | validation: 0.11552500900154733]
	TIME [epoch: 14.9 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0970634297802328		[learning rate: 0.018311]
	Learning Rate: 0.0183109
	LOSS [training: 0.0970634297802328 | validation: 0.04912484076440045]
	TIME [epoch: 14.9 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05971082796131319		[learning rate: 0.018302]
	Learning Rate: 0.0183017
	LOSS [training: 0.05971082796131319 | validation: 0.05072124587662638]
	TIME [epoch: 14.9 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09454336061338756		[learning rate: 0.018293]
	Learning Rate: 0.0182925
	LOSS [training: 0.09454336061338756 | validation: 0.0647476608048477]
	TIME [epoch: 14.9 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11008827895953147		[learning rate: 0.018283]
	Learning Rate: 0.0182833
	LOSS [training: 0.11008827895953147 | validation: 0.06419450207198656]
	TIME [epoch: 14.9 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07654954738726602		[learning rate: 0.018274]
	Learning Rate: 0.018274
	LOSS [training: 0.07654954738726602 | validation: 0.05657949756915593]
	TIME [epoch: 15 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0687494132578247		[learning rate: 0.018265]
	Learning Rate: 0.0182647
	LOSS [training: 0.0687494132578247 | validation: 0.03260118911052548]
	TIME [epoch: 14.9 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_412.pth
	Model improved!!!
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09272781403741555		[learning rate: 0.018255]
	Learning Rate: 0.0182554
	LOSS [training: 0.09272781403741555 | validation: 0.04135914593579564]
	TIME [epoch: 14.9 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09504190174232349		[learning rate: 0.018246]
	Learning Rate: 0.018246
	LOSS [training: 0.09504190174232349 | validation: 0.11765837502153075]
	TIME [epoch: 15 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10980023658770406		[learning rate: 0.018237]
	Learning Rate: 0.0182367
	LOSS [training: 0.10980023658770406 | validation: 0.0339595307332657]
	TIME [epoch: 14.9 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052811472806988044		[learning rate: 0.018227]
	Learning Rate: 0.0182273
	LOSS [training: 0.052811472806988044 | validation: 0.03374913928282835]
	TIME [epoch: 14.9 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08760841509707572		[learning rate: 0.018218]
	Learning Rate: 0.0182179
	LOSS [training: 0.08760841509707572 | validation: 0.047130209385320324]
	TIME [epoch: 14.9 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09465188836416728		[learning rate: 0.018208]
	Learning Rate: 0.0182085
	LOSS [training: 0.09465188836416728 | validation: 0.07247475075103531]
	TIME [epoch: 14.9 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07924611283900686		[learning rate: 0.018199]
	Learning Rate: 0.018199
	LOSS [training: 0.07924611283900686 | validation: 0.0372008446995317]
	TIME [epoch: 14.9 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0800608727672095		[learning rate: 0.01819]
	Learning Rate: 0.0181895
	LOSS [training: 0.0800608727672095 | validation: 0.03830653833703475]
	TIME [epoch: 14.9 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04816762697291097		[learning rate: 0.01818]
	Learning Rate: 0.01818
	LOSS [training: 0.04816762697291097 | validation: 0.05468700022513795]
	TIME [epoch: 14.9 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06043217595856487		[learning rate: 0.018171]
	Learning Rate: 0.0181705
	LOSS [training: 0.06043217595856487 | validation: 0.22855959612955018]
	TIME [epoch: 14.9 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15618908139754356		[learning rate: 0.018161]
	Learning Rate: 0.018161
	LOSS [training: 0.15618908139754356 | validation: 0.13336658110809696]
	TIME [epoch: 14.9 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19065143128131745		[learning rate: 0.018151]
	Learning Rate: 0.0181514
	LOSS [training: 0.19065143128131745 | validation: 0.13191604796730877]
	TIME [epoch: 14.9 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06250553859493323		[learning rate: 0.018142]
	Learning Rate: 0.0181418
	LOSS [training: 0.06250553859493323 | validation: 0.045631992475933615]
	TIME [epoch: 14.9 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06836721347422284		[learning rate: 0.018132]
	Learning Rate: 0.0181322
	LOSS [training: 0.06836721347422284 | validation: 0.03254464101398466]
	TIME [epoch: 14.8 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_426.pth
	Model improved!!!
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05706858259268191		[learning rate: 0.018123]
	Learning Rate: 0.0181226
	LOSS [training: 0.05706858259268191 | validation: 0.1304872190750554]
	TIME [epoch: 14.9 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12002227759681376		[learning rate: 0.018113]
	Learning Rate: 0.0181129
	LOSS [training: 0.12002227759681376 | validation: 0.07371096219710369]
	TIME [epoch: 14.9 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07441528894531416		[learning rate: 0.018103]
	Learning Rate: 0.0181032
	LOSS [training: 0.07441528894531416 | validation: 0.13477940350477086]
	TIME [epoch: 14.9 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07761020781132223		[learning rate: 0.018094]
	Learning Rate: 0.0180936
	LOSS [training: 0.07761020781132223 | validation: 0.06793853951515431]
	TIME [epoch: 14.9 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06556210057310442		[learning rate: 0.018084]
	Learning Rate: 0.0180838
	LOSS [training: 0.06556210057310442 | validation: 0.05990079800386561]
	TIME [epoch: 14.9 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09665719461279328		[learning rate: 0.018074]
	Learning Rate: 0.0180741
	LOSS [training: 0.09665719461279328 | validation: 0.12781938174180885]
	TIME [epoch: 14.9 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10841350072939725		[learning rate: 0.018064]
	Learning Rate: 0.0180643
	LOSS [training: 0.10841350072939725 | validation: 0.06030354526464497]
	TIME [epoch: 14.9 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06890053220977653		[learning rate: 0.018055]
	Learning Rate: 0.0180545
	LOSS [training: 0.06890053220977653 | validation: 0.08120598774501611]
	TIME [epoch: 14.9 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052597814182600566		[learning rate: 0.018045]
	Learning Rate: 0.0180447
	LOSS [training: 0.052597814182600566 | validation: 0.13271264082533615]
	TIME [epoch: 14.9 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14006927952982393		[learning rate: 0.018035]
	Learning Rate: 0.0180349
	LOSS [training: 0.14006927952982393 | validation: 0.23097450735207065]
	TIME [epoch: 14.9 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13403021846426985		[learning rate: 0.018025]
	Learning Rate: 0.0180251
	LOSS [training: 0.13403021846426985 | validation: 0.0678204143178784]
	TIME [epoch: 14.9 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09363119526459066		[learning rate: 0.018015]
	Learning Rate: 0.0180152
	LOSS [training: 0.09363119526459066 | validation: 0.037119689300481165]
	TIME [epoch: 15 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05010042548568436		[learning rate: 0.018005]
	Learning Rate: 0.0180053
	LOSS [training: 0.05010042548568436 | validation: 0.054590717084353216]
	TIME [epoch: 14.9 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10319881014036725		[learning rate: 0.017995]
	Learning Rate: 0.0179954
	LOSS [training: 0.10319881014036725 | validation: 0.030268610221045062]
	TIME [epoch: 14.9 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_440.pth
	Model improved!!!
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0359701093592489		[learning rate: 0.017985]
	Learning Rate: 0.0179854
	LOSS [training: 0.0359701093592489 | validation: 0.07512092249878594]
	TIME [epoch: 14.9 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07566092568836733		[learning rate: 0.017975]
	Learning Rate: 0.0179755
	LOSS [training: 0.07566092568836733 | validation: 0.17460271778142797]
	TIME [epoch: 14.8 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17072323323796254		[learning rate: 0.017965]
	Learning Rate: 0.0179655
	LOSS [training: 0.17072323323796254 | validation: 0.07842409724281876]
	TIME [epoch: 14.9 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0761254529718844		[learning rate: 0.017955]
	Learning Rate: 0.0179555
	LOSS [training: 0.0761254529718844 | validation: 0.044879535751230645]
	TIME [epoch: 14.8 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06410786763398166		[learning rate: 0.017945]
	Learning Rate: 0.0179455
	LOSS [training: 0.06410786763398166 | validation: 0.058541679012762665]
	TIME [epoch: 14.8 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06746202512040295		[learning rate: 0.017935]
	Learning Rate: 0.0179354
	LOSS [training: 0.06746202512040295 | validation: 0.20511185331622706]
	TIME [epoch: 14.9 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18466021362150797		[learning rate: 0.017925]
	Learning Rate: 0.0179253
	LOSS [training: 0.18466021362150797 | validation: 0.13275792761418503]
	TIME [epoch: 14.8 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0885747515382869		[learning rate: 0.017915]
	Learning Rate: 0.0179152
	LOSS [training: 0.0885747515382869 | validation: 0.08068989291075085]
	TIME [epoch: 14.8 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06957920580360243		[learning rate: 0.017905]
	Learning Rate: 0.0179051
	LOSS [training: 0.06957920580360243 | validation: 0.03030349347818155]
	TIME [epoch: 14.9 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035474039394513955		[learning rate: 0.017895]
	Learning Rate: 0.017895
	LOSS [training: 0.035474039394513955 | validation: 0.05986189549999336]
	TIME [epoch: 14.8 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10935648514077367		[learning rate: 0.017885]
	Learning Rate: 0.0178848
	LOSS [training: 0.10935648514077367 | validation: 0.03719831931032487]
	TIME [epoch: 14.9 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08060165736096543		[learning rate: 0.017875]
	Learning Rate: 0.0178747
	LOSS [training: 0.08060165736096543 | validation: 0.0526889823091717]
	TIME [epoch: 14.8 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05746403600912691		[learning rate: 0.017864]
	Learning Rate: 0.0178645
	LOSS [training: 0.05746403600912691 | validation: 0.03132492795157307]
	TIME [epoch: 14.8 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10886535771737285		[learning rate: 0.017854]
	Learning Rate: 0.0178542
	LOSS [training: 0.10886535771737285 | validation: 0.052185365577364015]
	TIME [epoch: 14.9 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07637053997845562		[learning rate: 0.017844]
	Learning Rate: 0.017844
	LOSS [training: 0.07637053997845562 | validation: 0.03195965931242889]
	TIME [epoch: 14.8 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059884856252080516		[learning rate: 0.017834]
	Learning Rate: 0.0178337
	LOSS [training: 0.059884856252080516 | validation: 0.02765008409942141]
	TIME [epoch: 14.8 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_456.pth
	Model improved!!!
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06748280289049444		[learning rate: 0.017823]
	Learning Rate: 0.0178235
	LOSS [training: 0.06748280289049444 | validation: 0.059092458501910576]
	TIME [epoch: 14.9 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057175680645483486		[learning rate: 0.017813]
	Learning Rate: 0.0178131
	LOSS [training: 0.057175680645483486 | validation: 0.04153403189184876]
	TIME [epoch: 14.8 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08503820285601607		[learning rate: 0.017803]
	Learning Rate: 0.0178028
	LOSS [training: 0.08503820285601607 | validation: 0.20161376157746502]
	TIME [epoch: 14.9 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08176967954039835		[learning rate: 0.017792]
	Learning Rate: 0.0177925
	LOSS [training: 0.08176967954039835 | validation: 0.047158108017570595]
	TIME [epoch: 14.9 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0681087133493235		[learning rate: 0.017782]
	Learning Rate: 0.0177821
	LOSS [training: 0.0681087133493235 | validation: 0.09578169992635088]
	TIME [epoch: 14.8 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15001599280738662		[learning rate: 0.017772]
	Learning Rate: 0.0177717
	LOSS [training: 0.15001599280738662 | validation: 0.047554478887076077]
	TIME [epoch: 14.9 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2126936083605832		[learning rate: 0.017761]
	Learning Rate: 0.0177613
	LOSS [training: 0.2126936083605832 | validation: 0.0916555067309637]
	TIME [epoch: 14.8 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08111887762790003		[learning rate: 0.017751]
	Learning Rate: 0.0177509
	LOSS [training: 0.08111887762790003 | validation: 0.08399620915056452]
	TIME [epoch: 14.8 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14592780841475883		[learning rate: 0.01774]
	Learning Rate: 0.0177404
	LOSS [training: 0.14592780841475883 | validation: 0.1491591385553701]
	TIME [epoch: 14.9 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14240633528120106		[learning rate: 0.01773]
	Learning Rate: 0.0177299
	LOSS [training: 0.14240633528120106 | validation: 0.043867364201198376]
	TIME [epoch: 14.8 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06995518054282625		[learning rate: 0.017719]
	Learning Rate: 0.0177194
	LOSS [training: 0.06995518054282625 | validation: 0.04537011054287694]
	TIME [epoch: 14.9 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06069445034790816		[learning rate: 0.017709]
	Learning Rate: 0.0177089
	LOSS [training: 0.06069445034790816 | validation: 0.05691877003211182]
	TIME [epoch: 14.8 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0848999382645489		[learning rate: 0.017698]
	Learning Rate: 0.0176984
	LOSS [training: 0.0848999382645489 | validation: 0.08896620252463995]
	TIME [epoch: 14.8 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06740449535633307		[learning rate: 0.017688]
	Learning Rate: 0.0176878
	LOSS [training: 0.06740449535633307 | validation: 0.07874101216896634]
	TIME [epoch: 14.9 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07217869370226371		[learning rate: 0.017677]
	Learning Rate: 0.0176772
	LOSS [training: 0.07217869370226371 | validation: 0.25955086133162714]
	TIME [epoch: 14.9 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0953018329558554		[learning rate: 0.017667]
	Learning Rate: 0.0176666
	LOSS [training: 0.0953018329558554 | validation: 0.057061632891561506]
	TIME [epoch: 14.8 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09031775131108677		[learning rate: 0.017656]
	Learning Rate: 0.017656
	LOSS [training: 0.09031775131108677 | validation: 0.03291412270270419]
	TIME [epoch: 14.9 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06545821759323335		[learning rate: 0.017645]
	Learning Rate: 0.0176454
	LOSS [training: 0.06545821759323335 | validation: 0.09351474881558552]
	TIME [epoch: 14.8 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09652755369187263		[learning rate: 0.017635]
	Learning Rate: 0.0176347
	LOSS [training: 0.09652755369187263 | validation: 0.034324734803741146]
	TIME [epoch: 14.8 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07132177750574409		[learning rate: 0.017624]
	Learning Rate: 0.017624
	LOSS [training: 0.07132177750574409 | validation: 0.15244489227585473]
	TIME [epoch: 14.9 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0763311395060165		[learning rate: 0.017613]
	Learning Rate: 0.0176133
	LOSS [training: 0.0763311395060165 | validation: 0.034034356874839626]
	TIME [epoch: 14.8 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07637827452410355		[learning rate: 0.017603]
	Learning Rate: 0.0176026
	LOSS [training: 0.07637827452410355 | validation: 0.30767041744748]
	TIME [epoch: 14.9 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3372424898750291		[learning rate: 0.017592]
	Learning Rate: 0.0175918
	LOSS [training: 0.3372424898750291 | validation: 0.19983341821447445]
	TIME [epoch: 14.8 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20861853138742925		[learning rate: 0.017581]
	Learning Rate: 0.0175811
	LOSS [training: 0.20861853138742925 | validation: 0.07688367987494239]
	TIME [epoch: 14.8 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04016089600767303		[learning rate: 0.01757]
	Learning Rate: 0.0175703
	LOSS [training: 0.04016089600767303 | validation: 0.02502403293549654]
	TIME [epoch: 14.9 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_481.pth
	Model improved!!!
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07628526028545092		[learning rate: 0.017559]
	Learning Rate: 0.0175595
	LOSS [training: 0.07628526028545092 | validation: 0.10094104377093205]
	TIME [epoch: 14.8 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07196936969676963		[learning rate: 0.017549]
	Learning Rate: 0.0175486
	LOSS [training: 0.07196936969676963 | validation: 0.0508600189159651]
	TIME [epoch: 14.8 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08318689650121608		[learning rate: 0.017538]
	Learning Rate: 0.0175378
	LOSS [training: 0.08318689650121608 | validation: 0.02546855207859129]
	TIME [epoch: 14.9 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06291347292051144		[learning rate: 0.017527]
	Learning Rate: 0.0175269
	LOSS [training: 0.06291347292051144 | validation: 0.1700235682967262]
	TIME [epoch: 14.8 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10057747369916817		[learning rate: 0.017516]
	Learning Rate: 0.017516
	LOSS [training: 0.10057747369916817 | validation: 0.12694857128866494]
	TIME [epoch: 14.9 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09299716361871108		[learning rate: 0.017505]
	Learning Rate: 0.0175051
	LOSS [training: 0.09299716361871108 | validation: 0.05800598476471959]
	TIME [epoch: 14.8 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05697142267085392		[learning rate: 0.017494]
	Learning Rate: 0.0174942
	LOSS [training: 0.05697142267085392 | validation: 0.1281556153373069]
	TIME [epoch: 14.8 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12094893365823348		[learning rate: 0.017483]
	Learning Rate: 0.0174832
	LOSS [training: 0.12094893365823348 | validation: 0.04562540036845227]
	TIME [epoch: 14.9 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04176315992549144		[learning rate: 0.017472]
	Learning Rate: 0.0174722
	LOSS [training: 0.04176315992549144 | validation: 0.024460757790491967]
	TIME [epoch: 14.8 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_490.pth
	Model improved!!!
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055228038860655033		[learning rate: 0.017461]
	Learning Rate: 0.0174612
	LOSS [training: 0.055228038860655033 | validation: 0.03733980355771637]
	TIME [epoch: 14.9 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07495172253533558		[learning rate: 0.01745]
	Learning Rate: 0.0174502
	LOSS [training: 0.07495172253533558 | validation: 0.07211337624086206]
	TIME [epoch: 14.9 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20961609832198008		[learning rate: 0.017439]
	Learning Rate: 0.0174392
	LOSS [training: 0.20961609832198008 | validation: 0.1777974073029173]
	TIME [epoch: 14.8 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26968421410607507		[learning rate: 0.017428]
	Learning Rate: 0.0174281
	LOSS [training: 0.26968421410607507 | validation: 0.0691928168216194]
	TIME [epoch: 14.9 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08661512303726115		[learning rate: 0.017417]
	Learning Rate: 0.017417
	LOSS [training: 0.08661512303726115 | validation: 0.11104745746973319]
	TIME [epoch: 14.9 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09805436399775389		[learning rate: 0.017406]
	Learning Rate: 0.0174059
	LOSS [training: 0.09805436399775389 | validation: 0.10783573523604331]
	TIME [epoch: 14.8 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09065462150033292		[learning rate: 0.017395]
	Learning Rate: 0.0173948
	LOSS [training: 0.09065462150033292 | validation: 0.06554377721267451]
	TIME [epoch: 14.9 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1793471556541555		[learning rate: 0.017384]
	Learning Rate: 0.0173837
	LOSS [training: 0.1793471556541555 | validation: 0.12211081132384768]
	TIME [epoch: 14.8 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10810515387628222		[learning rate: 0.017373]
	Learning Rate: 0.0173725
	LOSS [training: 0.10810515387628222 | validation: 0.05000833361489648]
	TIME [epoch: 14.8 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06001748041340799		[learning rate: 0.017361]
	Learning Rate: 0.0173614
	LOSS [training: 0.06001748041340799 | validation: 0.03393658332946094]
	TIME [epoch: 14.9 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041690920806326304		[learning rate: 0.01735]
	Learning Rate: 0.0173502
	LOSS [training: 0.041690920806326304 | validation: 0.040145771029500475]
	TIME [epoch: 156 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06303834430902512		[learning rate: 0.017339]
	Learning Rate: 0.0173389
	LOSS [training: 0.06303834430902512 | validation: 0.04752938650679947]
	TIME [epoch: 32.3 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07837604410615111		[learning rate: 0.017328]
	Learning Rate: 0.0173277
	LOSS [training: 0.07837604410615111 | validation: 0.043160703713911654]
	TIME [epoch: 32.3 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05162545223732289		[learning rate: 0.017316]
	Learning Rate: 0.0173164
	LOSS [training: 0.05162545223732289 | validation: 0.048185480271254036]
	TIME [epoch: 32.3 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038991400590964634		[learning rate: 0.017305]
	Learning Rate: 0.0173052
	LOSS [training: 0.038991400590964634 | validation: 0.023861101179165692]
	TIME [epoch: 32.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_505.pth
	Model improved!!!
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1359465791229594		[learning rate: 0.017294]
	Learning Rate: 0.0172939
	LOSS [training: 0.1359465791229594 | validation: 0.05387694891508271]
	TIME [epoch: 32.4 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13824115489875222		[learning rate: 0.017283]
	Learning Rate: 0.0172826
	LOSS [training: 0.13824115489875222 | validation: 0.04814825732758117]
	TIME [epoch: 32.3 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1677444819844321		[learning rate: 0.017271]
	Learning Rate: 0.0172712
	LOSS [training: 0.1677444819844321 | validation: 0.15604565770230353]
	TIME [epoch: 32.3 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15460445552487145		[learning rate: 0.01726]
	Learning Rate: 0.0172599
	LOSS [training: 0.15460445552487145 | validation: 0.056454353907040025]
	TIME [epoch: 32.3 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0600359440985216		[learning rate: 0.017248]
	Learning Rate: 0.0172485
	LOSS [training: 0.0600359440985216 | validation: 0.033354824736376965]
	TIME [epoch: 32.3 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029677746285200604		[learning rate: 0.017237]
	Learning Rate: 0.0172371
	LOSS [training: 0.029677746285200604 | validation: 0.02930194969635263]
	TIME [epoch: 32.3 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08131670463971825		[learning rate: 0.017226]
	Learning Rate: 0.0172257
	LOSS [training: 0.08131670463971825 | validation: 0.03071741460489185]
	TIME [epoch: 32.2 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03922042258659965		[learning rate: 0.017214]
	Learning Rate: 0.0172142
	LOSS [training: 0.03922042258659965 | validation: 0.03284858951392327]
	TIME [epoch: 32.3 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05465979120140574		[learning rate: 0.017203]
	Learning Rate: 0.0172028
	LOSS [training: 0.05465979120140574 | validation: 0.04800394667247143]
	TIME [epoch: 32.3 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09709145158216967		[learning rate: 0.017191]
	Learning Rate: 0.0171913
	LOSS [training: 0.09709145158216967 | validation: 0.05714613114446959]
	TIME [epoch: 32.3 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07042537793773987		[learning rate: 0.01718]
	Learning Rate: 0.0171798
	LOSS [training: 0.07042537793773987 | validation: 0.09028086206037783]
	TIME [epoch: 32.3 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11397690220503004		[learning rate: 0.017168]
	Learning Rate: 0.0171683
	LOSS [training: 0.11397690220503004 | validation: 0.08342277212693086]
	TIME [epoch: 32.2 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10623195280296031		[learning rate: 0.017157]
	Learning Rate: 0.0171567
	LOSS [training: 0.10623195280296031 | validation: 0.058761638354802845]
	TIME [epoch: 32.2 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053982469383710825		[learning rate: 0.017145]
	Learning Rate: 0.0171452
	LOSS [training: 0.053982469383710825 | validation: 0.1286147693190549]
	TIME [epoch: 32.3 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10642557249095883		[learning rate: 0.017134]
	Learning Rate: 0.0171336
	LOSS [training: 0.10642557249095883 | validation: 0.04453848032646484]
	TIME [epoch: 32.3 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054428934437643114		[learning rate: 0.017122]
	Learning Rate: 0.017122
	LOSS [training: 0.054428934437643114 | validation: 0.05093358919732854]
	TIME [epoch: 32.3 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0649932235622998		[learning rate: 0.01711]
	Learning Rate: 0.0171104
	LOSS [training: 0.0649932235622998 | validation: 0.2685881867760393]
	TIME [epoch: 32.2 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16038314860682285		[learning rate: 0.017099]
	Learning Rate: 0.0170988
	LOSS [training: 0.16038314860682285 | validation: 0.09078053903675308]
	TIME [epoch: 32.3 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09117181451556461		[learning rate: 0.017087]
	Learning Rate: 0.0170871
	LOSS [training: 0.09117181451556461 | validation: 0.054729642876370485]
	TIME [epoch: 32.3 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03755537351455334		[learning rate: 0.017075]
	Learning Rate: 0.0170755
	LOSS [training: 0.03755537351455334 | validation: 0.28142776864744534]
	TIME [epoch: 32.3 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13981297302912674		[learning rate: 0.017064]
	Learning Rate: 0.0170638
	LOSS [training: 0.13981297302912674 | validation: 0.07546076905355542]
	TIME [epoch: 32.2 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07545311644657754		[learning rate: 0.017052]
	Learning Rate: 0.0170521
	LOSS [training: 0.07545311644657754 | validation: 0.044010772642642366]
	TIME [epoch: 32.2 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06220201452612844		[learning rate: 0.01704]
	Learning Rate: 0.0170403
	LOSS [training: 0.06220201452612844 | validation: 0.018633854723481186]
	TIME [epoch: 32.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_528.pth
	Model improved!!!
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06821253344365405		[learning rate: 0.017029]
	Learning Rate: 0.0170286
	LOSS [training: 0.06821253344365405 | validation: 0.06270067575735026]
	TIME [epoch: 32.3 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05808533356994482		[learning rate: 0.017017]
	Learning Rate: 0.0170168
	LOSS [training: 0.05808533356994482 | validation: 0.05280276546557318]
	TIME [epoch: 32.3 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03794669536981286		[learning rate: 0.017005]
	Learning Rate: 0.017005
	LOSS [training: 0.03794669536981286 | validation: 0.09823692220426633]
	TIME [epoch: 32.3 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06309763408998183		[learning rate: 0.016993]
	Learning Rate: 0.0169932
	LOSS [training: 0.06309763408998183 | validation: 0.12013027227073472]
	TIME [epoch: 32.3 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08400647448824546		[learning rate: 0.016981]
	Learning Rate: 0.0169814
	LOSS [training: 0.08400647448824546 | validation: 0.057154646021557794]
	TIME [epoch: 32.3 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08624493987474953		[learning rate: 0.01697]
	Learning Rate: 0.0169695
	LOSS [training: 0.08624493987474953 | validation: 0.09307143496201788]
	TIME [epoch: 32.3 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05025822866355273		[learning rate: 0.016958]
	Learning Rate: 0.0169577
	LOSS [training: 0.05025822866355273 | validation: 0.10937773197080133]
	TIME [epoch: 32.3 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04350377307346424		[learning rate: 0.016946]
	Learning Rate: 0.0169458
	LOSS [training: 0.04350377307346424 | validation: 0.031188474365308232]
	TIME [epoch: 32.3 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15130172327603827		[learning rate: 0.016934]
	Learning Rate: 0.0169339
	LOSS [training: 0.15130172327603827 | validation: 0.11282597936549132]
	TIME [epoch: 32.3 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09801658949380022		[learning rate: 0.016922]
	Learning Rate: 0.016922
	LOSS [training: 0.09801658949380022 | validation: 0.03143258361669807]
	TIME [epoch: 32.3 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03572514172500633		[learning rate: 0.01691]
	Learning Rate: 0.01691
	LOSS [training: 0.03572514172500633 | validation: 0.02634461874311507]
	TIME [epoch: 32.3 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06562684985992095		[learning rate: 0.016898]
	Learning Rate: 0.0168981
	LOSS [training: 0.06562684985992095 | validation: 0.022109499228310587]
	TIME [epoch: 32.3 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03158903255143578		[learning rate: 0.016886]
	Learning Rate: 0.0168861
	LOSS [training: 0.03158903255143578 | validation: 0.04045775406043454]
	TIME [epoch: 32.3 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04345875130660916		[learning rate: 0.016874]
	Learning Rate: 0.0168741
	LOSS [training: 0.04345875130660916 | validation: 0.019818911689598283]
	TIME [epoch: 32.3 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06716560203820751		[learning rate: 0.016862]
	Learning Rate: 0.0168621
	LOSS [training: 0.06716560203820751 | validation: 0.043642953184821406]
	TIME [epoch: 32.3 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05422339080151328		[learning rate: 0.01685]
	Learning Rate: 0.0168501
	LOSS [training: 0.05422339080151328 | validation: 0.040742616511312724]
	TIME [epoch: 32.3 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04610882471501963		[learning rate: 0.016838]
	Learning Rate: 0.016838
	LOSS [training: 0.04610882471501963 | validation: 0.03011386476975748]
	TIME [epoch: 32.3 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05952159413570475		[learning rate: 0.016826]
	Learning Rate: 0.0168259
	LOSS [training: 0.05952159413570475 | validation: 0.04905153452050179]
	TIME [epoch: 32.3 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04605842129834647		[learning rate: 0.016814]
	Learning Rate: 0.0168138
	LOSS [training: 0.04605842129834647 | validation: 0.022186663502785413]
	TIME [epoch: 32.3 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11290839167199868		[learning rate: 0.016802]
	Learning Rate: 0.0168017
	LOSS [training: 0.11290839167199868 | validation: 0.037576235742180754]
	TIME [epoch: 32.4 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04630971515280956		[learning rate: 0.01679]
	Learning Rate: 0.0167896
	LOSS [training: 0.04630971515280956 | validation: 0.05137256229300695]
	TIME [epoch: 32.3 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08600610378431363		[learning rate: 0.016777]
	Learning Rate: 0.0167775
	LOSS [training: 0.08600610378431363 | validation: 0.08342335013457648]
	TIME [epoch: 32.3 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08422321922220138		[learning rate: 0.016765]
	Learning Rate: 0.0167653
	LOSS [training: 0.08422321922220138 | validation: 0.02917659090839564]
	TIME [epoch: 32.3 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028801245533995816		[learning rate: 0.016753]
	Learning Rate: 0.0167531
	LOSS [training: 0.028801245533995816 | validation: 0.028315775680805382]
	TIME [epoch: 32.3 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03604711601144939		[learning rate: 0.016741]
	Learning Rate: 0.0167409
	LOSS [training: 0.03604711601144939 | validation: 0.0243006827564044]
	TIME [epoch: 32.3 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07245065376881087		[learning rate: 0.016729]
	Learning Rate: 0.0167287
	LOSS [training: 0.07245065376881087 | validation: 0.09499858494512252]
	TIME [epoch: 32.3 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10064871720040058		[learning rate: 0.016716]
	Learning Rate: 0.0167165
	LOSS [training: 0.10064871720040058 | validation: 0.034064091015268055]
	TIME [epoch: 32.3 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029886314869026938		[learning rate: 0.016704]
	Learning Rate: 0.0167042
	LOSS [training: 0.029886314869026938 | validation: 0.021467319910470857]
	TIME [epoch: 32.3 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07324947873959459		[learning rate: 0.016692]
	Learning Rate: 0.0166919
	LOSS [training: 0.07324947873959459 | validation: 0.17175652418824094]
	TIME [epoch: 32.3 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1468045396558206		[learning rate: 0.01668]
	Learning Rate: 0.0166796
	LOSS [training: 0.1468045396558206 | validation: 0.2365078660671931]
	TIME [epoch: 32.3 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17902653265416468		[learning rate: 0.016667]
	Learning Rate: 0.0166673
	LOSS [training: 0.17902653265416468 | validation: 0.09545409287061535]
	TIME [epoch: 32.2 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0982453022734006		[learning rate: 0.016655]
	Learning Rate: 0.016655
	LOSS [training: 0.0982453022734006 | validation: 0.03051317941720893]
	TIME [epoch: 32.3 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03204943927991557		[learning rate: 0.016643]
	Learning Rate: 0.0166427
	LOSS [training: 0.03204943927991557 | validation: 0.02013536499937176]
	TIME [epoch: 32.3 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03613052546365078		[learning rate: 0.01663]
	Learning Rate: 0.0166303
	LOSS [training: 0.03613052546365078 | validation: 0.0691587325415331]
	TIME [epoch: 32.3 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08472883736176645		[learning rate: 0.016618]
	Learning Rate: 0.0166179
	LOSS [training: 0.08472883736176645 | validation: 0.03754358449105309]
	TIME [epoch: 32.3 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060703181772938465		[learning rate: 0.016606]
	Learning Rate: 0.0166055
	LOSS [training: 0.060703181772938465 | validation: 0.03731835848961956]
	TIME [epoch: 32.3 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04175566812320663		[learning rate: 0.016593]
	Learning Rate: 0.0165931
	LOSS [training: 0.04175566812320663 | validation: 0.031338261791540256]
	TIME [epoch: 32.3 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09374814794374		[learning rate: 0.016581]
	Learning Rate: 0.0165807
	LOSS [training: 0.09374814794374 | validation: 0.06247422151886202]
	TIME [epoch: 32.3 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046901032241569565		[learning rate: 0.016568]
	Learning Rate: 0.0165682
	LOSS [training: 0.046901032241569565 | validation: 0.09599632171899095]
	TIME [epoch: 32.3 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07721265454182392		[learning rate: 0.016556]
	Learning Rate: 0.0165557
	LOSS [training: 0.07721265454182392 | validation: 0.0925335974496462]
	TIME [epoch: 32.3 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1577991418284843		[learning rate: 0.016543]
	Learning Rate: 0.0165432
	LOSS [training: 0.1577991418284843 | validation: 0.11996055913219175]
	TIME [epoch: 32.3 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08284885447586948		[learning rate: 0.016531]
	Learning Rate: 0.0165307
	LOSS [training: 0.08284885447586948 | validation: 0.021262206321364052]
	TIME [epoch: 32.3 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04559174093893248		[learning rate: 0.016518]
	Learning Rate: 0.0165182
	LOSS [training: 0.04559174093893248 | validation: 0.03579359489640731]
	TIME [epoch: 32.4 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0396829383080541		[learning rate: 0.016506]
	Learning Rate: 0.0165057
	LOSS [training: 0.0396829383080541 | validation: 0.024798415224929867]
	TIME [epoch: 32.4 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06519511976169114		[learning rate: 0.016493]
	Learning Rate: 0.0164931
	LOSS [training: 0.06519511976169114 | validation: 0.023109639415102044]
	TIME [epoch: 32.3 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027417526678973923		[learning rate: 0.016481]
	Learning Rate: 0.0164805
	LOSS [training: 0.027417526678973923 | validation: 0.02132816951106086]
	TIME [epoch: 32.3 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053747474713776895		[learning rate: 0.016468]
	Learning Rate: 0.0164679
	LOSS [training: 0.053747474713776895 | validation: 0.030013689246824363]
	TIME [epoch: 32.3 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03157375142437375		[learning rate: 0.016455]
	Learning Rate: 0.0164553
	LOSS [training: 0.03157375142437375 | validation: 0.027983490997540456]
	TIME [epoch: 32.3 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06752285802696269		[learning rate: 0.016443]
	Learning Rate: 0.0164427
	LOSS [training: 0.06752285802696269 | validation: 0.031137629109584734]
	TIME [epoch: 32.4 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04485492508838313		[learning rate: 0.01643]
	Learning Rate: 0.01643
	LOSS [training: 0.04485492508838313 | validation: 0.09042043738341311]
	TIME [epoch: 32.3 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11161143993793879		[learning rate: 0.016417]
	Learning Rate: 0.0164173
	LOSS [training: 0.11161143993793879 | validation: 0.08101549052648288]
	TIME [epoch: 32.3 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08377184477312084		[learning rate: 0.016405]
	Learning Rate: 0.0164047
	LOSS [training: 0.08377184477312084 | validation: 0.03382825066205739]
	TIME [epoch: 32.3 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031329456496506106		[learning rate: 0.016392]
	Learning Rate: 0.016392
	LOSS [training: 0.031329456496506106 | validation: 0.039558068982169806]
	TIME [epoch: 32.4 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09181517657066174		[learning rate: 0.016379]
	Learning Rate: 0.0163792
	LOSS [training: 0.09181517657066174 | validation: 0.030190586356416933]
	TIME [epoch: 32.3 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033476456535983266		[learning rate: 0.016366]
	Learning Rate: 0.0163665
	LOSS [training: 0.033476456535983266 | validation: 0.09846132653780808]
	TIME [epoch: 32.3 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06915994006278095		[learning rate: 0.016354]
	Learning Rate: 0.0163537
	LOSS [training: 0.06915994006278095 | validation: 0.03601493554393573]
	TIME [epoch: 32.3 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04347217173427762		[learning rate: 0.016341]
	Learning Rate: 0.016341
	LOSS [training: 0.04347217173427762 | validation: 0.02403923727064917]
	TIME [epoch: 32.4 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037272615020273875		[learning rate: 0.016328]
	Learning Rate: 0.0163282
	LOSS [training: 0.037272615020273875 | validation: 0.27206785166365394]
	TIME [epoch: 32.4 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21299618332660636		[learning rate: 0.016315]
	Learning Rate: 0.0163154
	LOSS [training: 0.21299618332660636 | validation: 0.19154042349754208]
	TIME [epoch: 32.4 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1707100809012417		[learning rate: 0.016303]
	Learning Rate: 0.0163025
	LOSS [training: 0.1707100809012417 | validation: 0.049087340200061044]
	TIME [epoch: 32.3 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04110472750513581		[learning rate: 0.01629]
	Learning Rate: 0.0162897
	LOSS [training: 0.04110472750513581 | validation: 0.03029192010562226]
	TIME [epoch: 32.4 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05450828215826025		[learning rate: 0.016277]
	Learning Rate: 0.0162768
	LOSS [training: 0.05450828215826025 | validation: 0.02599895124305731]
	TIME [epoch: 32.4 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030045984787525883		[learning rate: 0.016264]
	Learning Rate: 0.016264
	LOSS [training: 0.030045984787525883 | validation: 0.06811262357968283]
	TIME [epoch: 32.3 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06659377928250779		[learning rate: 0.016251]
	Learning Rate: 0.0162511
	LOSS [training: 0.06659377928250779 | validation: 0.08437478724452248]
	TIME [epoch: 32.3 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06317897363565217		[learning rate: 0.016238]
	Learning Rate: 0.0162382
	LOSS [training: 0.06317897363565217 | validation: 0.04378219376312593]
	TIME [epoch: 32.3 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06203279493535728		[learning rate: 0.016225]
	Learning Rate: 0.0162252
	LOSS [training: 0.06203279493535728 | validation: 0.03524445937820403]
	TIME [epoch: 32.3 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051380272916313086		[learning rate: 0.016212]
	Learning Rate: 0.0162123
	LOSS [training: 0.051380272916313086 | validation: 0.025457578764252965]
	TIME [epoch: 32.4 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029653931114798863		[learning rate: 0.016199]
	Learning Rate: 0.0161993
	LOSS [training: 0.029653931114798863 | validation: 0.08066563570143638]
	TIME [epoch: 32.4 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07145526765315349		[learning rate: 0.016186]
	Learning Rate: 0.0161864
	LOSS [training: 0.07145526765315349 | validation: 0.03810765604246435]
	TIME [epoch: 32.3 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0365673171181175		[learning rate: 0.016173]
	Learning Rate: 0.0161734
	LOSS [training: 0.0365673171181175 | validation: 0.09857064329493381]
	TIME [epoch: 32.3 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09725918748269086		[learning rate: 0.01616]
	Learning Rate: 0.0161603
	LOSS [training: 0.09725918748269086 | validation: 0.02210297192084878]
	TIME [epoch: 32.4 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0870572816896009		[learning rate: 0.016147]
	Learning Rate: 0.0161473
	LOSS [training: 0.0870572816896009 | validation: 0.04346634183763045]
	TIME [epoch: 32.4 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1033530650577913		[learning rate: 0.016134]
	Learning Rate: 0.0161343
	LOSS [training: 0.1033530650577913 | validation: 0.05236149011764479]
	TIME [epoch: 32.4 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050473603974510506		[learning rate: 0.016121]
	Learning Rate: 0.0161212
	LOSS [training: 0.050473603974510506 | validation: 0.024702444178542667]
	TIME [epoch: 32.3 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02467603067904336		[learning rate: 0.016108]
	Learning Rate: 0.0161081
	LOSS [training: 0.02467603067904336 | validation: 0.028117250156367957]
	TIME [epoch: 32.4 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048612850265138625		[learning rate: 0.016095]
	Learning Rate: 0.016095
	LOSS [training: 0.048612850265138625 | validation: 0.044905098469353824]
	TIME [epoch: 32.4 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10471130030260674		[learning rate: 0.016082]
	Learning Rate: 0.0160819
	LOSS [training: 0.10471130030260674 | validation: 0.0412691382124726]
	TIME [epoch: 32.4 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061335955700993476		[learning rate: 0.016069]
	Learning Rate: 0.0160688
	LOSS [training: 0.061335955700993476 | validation: 0.027595114580208385]
	TIME [epoch: 32.4 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039729133436294944		[learning rate: 0.016056]
	Learning Rate: 0.0160556
	LOSS [training: 0.039729133436294944 | validation: 0.077127150740918]
	TIME [epoch: 32.3 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06837939903736928		[learning rate: 0.016042]
	Learning Rate: 0.0160425
	LOSS [training: 0.06837939903736928 | validation: 0.03488727358625321]
	TIME [epoch: 32.3 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05006131622561056		[learning rate: 0.016029]
	Learning Rate: 0.0160293
	LOSS [training: 0.05006131622561056 | validation: 0.018881895660322362]
	TIME [epoch: 32.3 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12415432311806882		[learning rate: 0.016016]
	Learning Rate: 0.0160161
	LOSS [training: 0.12415432311806882 | validation: 0.08595382238988768]
	TIME [epoch: 32.4 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05686608520279068		[learning rate: 0.016003]
	Learning Rate: 0.0160029
	LOSS [training: 0.05686608520279068 | validation: 0.03219957667783047]
	TIME [epoch: 32.3 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027811513445141517		[learning rate: 0.01599]
	Learning Rate: 0.0159897
	LOSS [training: 0.027811513445141517 | validation: 0.025964020637973907]
	TIME [epoch: 32.3 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08870332009371854		[learning rate: 0.015976]
	Learning Rate: 0.0159764
	LOSS [training: 0.08870332009371854 | validation: 0.05084302323041644]
	TIME [epoch: 32.3 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07839940359796391		[learning rate: 0.015963]
	Learning Rate: 0.0159632
	LOSS [training: 0.07839940359796391 | validation: 0.05315213786669925]
	TIME [epoch: 32.3 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11220358502111416		[learning rate: 0.01595]
	Learning Rate: 0.0159499
	LOSS [training: 0.11220358502111416 | validation: 0.047845792321639075]
	TIME [epoch: 32.4 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0449768603835517		[learning rate: 0.015937]
	Learning Rate: 0.0159366
	LOSS [training: 0.0449768603835517 | validation: 0.019719272776542097]
	TIME [epoch: 32.3 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022952140550765242		[learning rate: 0.015923]
	Learning Rate: 0.0159233
	LOSS [training: 0.022952140550765242 | validation: 0.01898551184057721]
	TIME [epoch: 32.3 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0253225558234945		[learning rate: 0.01591]
	Learning Rate: 0.01591
	LOSS [training: 0.0253225558234945 | validation: 0.022397499904627506]
	TIME [epoch: 32.3 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07574281675134158		[learning rate: 0.015897]
	Learning Rate: 0.0158966
	LOSS [training: 0.07574281675134158 | validation: 0.04475658969159968]
	TIME [epoch: 32.3 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05501191961847279		[learning rate: 0.015883]
	Learning Rate: 0.0158833
	LOSS [training: 0.05501191961847279 | validation: 0.11045362914117562]
	TIME [epoch: 32.3 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06892348995283086		[learning rate: 0.01587]
	Learning Rate: 0.0158699
	LOSS [training: 0.06892348995283086 | validation: 0.09839287243193137]
	TIME [epoch: 32.3 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06589363511280184		[learning rate: 0.015856]
	Learning Rate: 0.0158565
	LOSS [training: 0.06589363511280184 | validation: 0.033110445606785915]
	TIME [epoch: 32.3 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10182893479280523		[learning rate: 0.015843]
	Learning Rate: 0.0158431
	LOSS [training: 0.10182893479280523 | validation: 0.08456098376153665]
	TIME [epoch: 32.3 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07407610540474291		[learning rate: 0.01583]
	Learning Rate: 0.0158297
	LOSS [training: 0.07407610540474291 | validation: 0.04689987577714601]
	TIME [epoch: 32.3 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039582690991488076		[learning rate: 0.015816]
	Learning Rate: 0.0158162
	LOSS [training: 0.039582690991488076 | validation: 0.018243254761939817]
	TIME [epoch: 32.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_625.pth
	Model improved!!!
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026598246507354553		[learning rate: 0.015803]
	Learning Rate: 0.0158028
	LOSS [training: 0.026598246507354553 | validation: 0.05077910698441088]
	TIME [epoch: 32.3 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10313529761163288		[learning rate: 0.015789]
	Learning Rate: 0.0157893
	LOSS [training: 0.10313529761163288 | validation: 0.024018337780712558]
	TIME [epoch: 32.3 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0624637535920483		[learning rate: 0.015776]
	Learning Rate: 0.0157758
	LOSS [training: 0.0624637535920483 | validation: 0.031867358960977574]
	TIME [epoch: 32.4 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0420753354345801		[learning rate: 0.015762]
	Learning Rate: 0.0157623
	LOSS [training: 0.0420753354345801 | validation: 0.037137465703746056]
	TIME [epoch: 32.4 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035127740643313206		[learning rate: 0.015749]
	Learning Rate: 0.0157488
	LOSS [training: 0.035127740643313206 | validation: 0.01798439958975755]
	TIME [epoch: 32.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_630.pth
	Model improved!!!
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03454134583493147		[learning rate: 0.015735]
	Learning Rate: 0.0157353
	LOSS [training: 0.03454134583493147 | validation: 0.044514475467155375]
	TIME [epoch: 32.3 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045697837479901575		[learning rate: 0.015722]
	Learning Rate: 0.0157217
	LOSS [training: 0.045697837479901575 | validation: 0.014816050456074288]
	TIME [epoch: 32.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_632.pth
	Model improved!!!
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10120714094474462		[learning rate: 0.015708]
	Learning Rate: 0.0157082
	LOSS [training: 0.10120714094474462 | validation: 0.29050141769525883]
	TIME [epoch: 32.4 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21396069433886733		[learning rate: 0.015695]
	Learning Rate: 0.0156946
	LOSS [training: 0.21396069433886733 | validation: 0.04337455330190992]
	TIME [epoch: 32.4 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16738289630144906		[learning rate: 0.015681]
	Learning Rate: 0.015681
	LOSS [training: 0.16738289630144906 | validation: 0.18238859382603273]
	TIME [epoch: 32.4 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1390831691046776		[learning rate: 0.015667]
	Learning Rate: 0.0156674
	LOSS [training: 0.1390831691046776 | validation: 0.030743140234161415]
	TIME [epoch: 32.3 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03014836753089014		[learning rate: 0.015654]
	Learning Rate: 0.0156537
	LOSS [training: 0.03014836753089014 | validation: 0.02527785708278047]
	TIME [epoch: 32.3 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03294970633837575		[learning rate: 0.01564]
	Learning Rate: 0.0156401
	LOSS [training: 0.03294970633837575 | validation: 0.024294060240798537]
	TIME [epoch: 32.4 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03375478603387269		[learning rate: 0.015626]
	Learning Rate: 0.0156264
	LOSS [training: 0.03375478603387269 | validation: 0.13306098230542582]
	TIME [epoch: 32.4 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0776823002082121		[learning rate: 0.015613]
	Learning Rate: 0.0156128
	LOSS [training: 0.0776823002082121 | validation: 0.025440894074569002]
	TIME [epoch: 32.4 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026566266196740258		[learning rate: 0.015599]
	Learning Rate: 0.0155991
	LOSS [training: 0.026566266196740258 | validation: 0.06621778328106825]
	TIME [epoch: 32.3 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06944315253811703		[learning rate: 0.015585]
	Learning Rate: 0.0155854
	LOSS [training: 0.06944315253811703 | validation: 0.2087438397427277]
	TIME [epoch: 32.4 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08394825702561555		[learning rate: 0.015572]
	Learning Rate: 0.0155717
	LOSS [training: 0.08394825702561555 | validation: 0.025059518612967673]
	TIME [epoch: 32.4 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042025443974143505		[learning rate: 0.015558]
	Learning Rate: 0.0155579
	LOSS [training: 0.042025443974143505 | validation: 0.12243469408471891]
	TIME [epoch: 32.4 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11436094957000892		[learning rate: 0.015544]
	Learning Rate: 0.0155442
	LOSS [training: 0.11436094957000892 | validation: 0.04412433914622417]
	TIME [epoch: 32.3 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08215250761059939		[learning rate: 0.01553]
	Learning Rate: 0.0155304
	LOSS [training: 0.08215250761059939 | validation: 0.02791575730646046]
	TIME [epoch: 32.4 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03174509190695897		[learning rate: 0.015517]
	Learning Rate: 0.0155166
	LOSS [training: 0.03174509190695897 | validation: 0.04147501113550306]
	TIME [epoch: 32.4 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049751554254038835		[learning rate: 0.015503]
	Learning Rate: 0.0155028
	LOSS [training: 0.049751554254038835 | validation: 0.02933820611344919]
	TIME [epoch: 32.4 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028101605463816674		[learning rate: 0.015489]
	Learning Rate: 0.015489
	LOSS [training: 0.028101605463816674 | validation: 0.033412580624128004]
	TIME [epoch: 32.4 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0451863122068078		[learning rate: 0.015475]
	Learning Rate: 0.0154752
	LOSS [training: 0.0451863122068078 | validation: 0.05951766874645159]
	TIME [epoch: 32.3 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07179272543245303		[learning rate: 0.015461]
	Learning Rate: 0.0154614
	LOSS [training: 0.07179272543245303 | validation: 0.23395087635006262]
	TIME [epoch: 32.3 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09417388302310309		[learning rate: 0.015448]
	Learning Rate: 0.0154475
	LOSS [training: 0.09417388302310309 | validation: 0.25217779242477795]
	TIME [epoch: 32.4 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1765483920564813		[learning rate: 0.015434]
	Learning Rate: 0.0154336
	LOSS [training: 0.1765483920564813 | validation: 0.06781862694542362]
	TIME [epoch: 32.4 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07113018287553319		[learning rate: 0.01542]
	Learning Rate: 0.0154198
	LOSS [training: 0.07113018287553319 | validation: 0.03296611047336863]
	TIME [epoch: 32.4 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04836810704386721		[learning rate: 0.015406]
	Learning Rate: 0.0154059
	LOSS [training: 0.04836810704386721 | validation: 0.028960997735145676]
	TIME [epoch: 32.4 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039145019510338226		[learning rate: 0.015392]
	Learning Rate: 0.0153919
	LOSS [training: 0.039145019510338226 | validation: 0.021429307656296352]
	TIME [epoch: 32.4 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04123880222140866		[learning rate: 0.015378]
	Learning Rate: 0.015378
	LOSS [training: 0.04123880222140866 | validation: 0.03919757149877746]
	TIME [epoch: 32.4 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042096776538868216		[learning rate: 0.015364]
	Learning Rate: 0.0153641
	LOSS [training: 0.042096776538868216 | validation: 0.08795500230406686]
	TIME [epoch: 32.4 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04884288750160092		[learning rate: 0.01535]
	Learning Rate: 0.0153501
	LOSS [training: 0.04884288750160092 | validation: 0.033789038211888764]
	TIME [epoch: 32.4 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08573365787115683		[learning rate: 0.015336]
	Learning Rate: 0.0153361
	LOSS [training: 0.08573365787115683 | validation: 0.028583752129545198]
	TIME [epoch: 32.4 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031569936095506235		[learning rate: 0.015322]
	Learning Rate: 0.0153222
	LOSS [training: 0.031569936095506235 | validation: 0.021519950129955206]
	TIME [epoch: 32.4 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04838759694365456		[learning rate: 0.015308]
	Learning Rate: 0.0153082
	LOSS [training: 0.04838759694365456 | validation: 0.033549699698507025]
	TIME [epoch: 32.4 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05641223884349834		[learning rate: 0.015294]
	Learning Rate: 0.0152941
	LOSS [training: 0.05641223884349834 | validation: 0.04044731958995286]
	TIME [epoch: 32.3 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05188334650287263		[learning rate: 0.01528]
	Learning Rate: 0.0152801
	LOSS [training: 0.05188334650287263 | validation: 0.022554521882997686]
	TIME [epoch: 32.4 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06895018892194316		[learning rate: 0.015266]
	Learning Rate: 0.0152661
	LOSS [training: 0.06895018892194316 | validation: 0.0434370089737274]
	TIME [epoch: 32.4 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04061267977168341		[learning rate: 0.015252]
	Learning Rate: 0.015252
	LOSS [training: 0.04061267977168341 | validation: 0.02740850683515316]
	TIME [epoch: 32.4 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029927128594605057		[learning rate: 0.015238]
	Learning Rate: 0.0152379
	LOSS [training: 0.029927128594605057 | validation: 0.015101319573305372]
	TIME [epoch: 32.4 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06068507691333648		[learning rate: 0.015224]
	Learning Rate: 0.0152238
	LOSS [training: 0.06068507691333648 | validation: 0.10489351095327425]
	TIME [epoch: 32.4 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13281910305980538		[learning rate: 0.01521]
	Learning Rate: 0.0152097
	LOSS [training: 0.13281910305980538 | validation: 0.0777903767524882]
	TIME [epoch: 32.4 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07265687154320401		[learning rate: 0.015196]
	Learning Rate: 0.0151956
	LOSS [training: 0.07265687154320401 | validation: 0.028326647967916153]
	TIME [epoch: 32.4 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027063396556808682		[learning rate: 0.015182]
	Learning Rate: 0.0151815
	LOSS [training: 0.027063396556808682 | validation: 0.04193235581528547]
	TIME [epoch: 32.4 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10439713506832698		[learning rate: 0.015167]
	Learning Rate: 0.0151674
	LOSS [training: 0.10439713506832698 | validation: 0.027864074042267716]
	TIME [epoch: 32.5 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028868770694350884		[learning rate: 0.015153]
	Learning Rate: 0.0151532
	LOSS [training: 0.028868770694350884 | validation: 0.016541626159977018]
	TIME [epoch: 32.5 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021783554108347484		[learning rate: 0.015139]
	Learning Rate: 0.015139
	LOSS [training: 0.021783554108347484 | validation: 0.024850591749646996]
	TIME [epoch: 32.3 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02933801827978779		[learning rate: 0.015125]
	Learning Rate: 0.0151248
	LOSS [training: 0.02933801827978779 | validation: 0.041314537591251185]
	TIME [epoch: 32.5 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04225514031404662		[learning rate: 0.015111]
	Learning Rate: 0.0151106
	LOSS [training: 0.04225514031404662 | validation: 0.038689433564220346]
	TIME [epoch: 32.4 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06646535937613461		[learning rate: 0.015096]
	Learning Rate: 0.0150964
	LOSS [training: 0.06646535937613461 | validation: 0.01659134882759469]
	TIME [epoch: 32.5 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026835956937005023		[learning rate: 0.015082]
	Learning Rate: 0.0150822
	LOSS [training: 0.026835956937005023 | validation: 0.02555260791204031]
	TIME [epoch: 32.4 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05378444924048942		[learning rate: 0.015068]
	Learning Rate: 0.015068
	LOSS [training: 0.05378444924048942 | validation: 0.04912761246036165]
	TIME [epoch: 32.4 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05766353041454686		[learning rate: 0.015054]
	Learning Rate: 0.0150537
	LOSS [training: 0.05766353041454686 | validation: 0.0601552818148165]
	TIME [epoch: 32.4 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08152856872878203		[learning rate: 0.015039]
	Learning Rate: 0.0150394
	LOSS [training: 0.08152856872878203 | validation: 0.0406084240677846]
	TIME [epoch: 32.4 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04297692519816483		[learning rate: 0.015025]
	Learning Rate: 0.0150251
	LOSS [training: 0.04297692519816483 | validation: 0.01571578720775907]
	TIME [epoch: 32.5 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10539394358373522		[learning rate: 0.015011]
	Learning Rate: 0.0150108
	LOSS [training: 0.10539394358373522 | validation: 0.09764592720753772]
	TIME [epoch: 32.4 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06929784863202709		[learning rate: 0.014997]
	Learning Rate: 0.0149965
	LOSS [training: 0.06929784863202709 | validation: 0.06067705273658747]
	TIME [epoch: 32.4 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1715178403744334		[learning rate: 0.014982]
	Learning Rate: 0.0149822
	LOSS [training: 0.1715178403744334 | validation: 0.2856427561209971]
	TIME [epoch: 32.4 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1595994214332113		[learning rate: 0.014968]
	Learning Rate: 0.0149679
	LOSS [training: 0.1595994214332113 | validation: 0.025645099592648782]
	TIME [epoch: 32.4 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050432492044282524		[learning rate: 0.014954]
	Learning Rate: 0.0149535
	LOSS [training: 0.050432492044282524 | validation: 0.025436717499629422]
	TIME [epoch: 32.4 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03933249779159971		[learning rate: 0.014939]
	Learning Rate: 0.0149392
	LOSS [training: 0.03933249779159971 | validation: 0.039735246225916655]
	TIME [epoch: 32.4 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03905375958122292		[learning rate: 0.014925]
	Learning Rate: 0.0149248
	LOSS [training: 0.03905375958122292 | validation: 0.025267948156709904]
	TIME [epoch: 32.4 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05302304729197693		[learning rate: 0.01491]
	Learning Rate: 0.0149104
	LOSS [training: 0.05302304729197693 | validation: 0.22287086428856578]
	TIME [epoch: 32.4 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17222002232805061		[learning rate: 0.014896]
	Learning Rate: 0.014896
	LOSS [training: 0.17222002232805061 | validation: 0.05756336789044435]
	TIME [epoch: 32.5 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05703451008363377		[learning rate: 0.014882]
	Learning Rate: 0.0148816
	LOSS [training: 0.05703451008363377 | validation: 0.0251428682037841]
	TIME [epoch: 32.5 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03960555080734355		[learning rate: 0.014867]
	Learning Rate: 0.0148671
	LOSS [training: 0.03960555080734355 | validation: 0.0841252416638636]
	TIME [epoch: 32.4 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06044612097181446		[learning rate: 0.014853]
	Learning Rate: 0.0148527
	LOSS [training: 0.06044612097181446 | validation: 0.0201780309980139]
	TIME [epoch: 32.4 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028605516488858042		[learning rate: 0.014838]
	Learning Rate: 0.0148382
	LOSS [training: 0.028605516488858042 | validation: 0.03366974921033626]
	TIME [epoch: 32.4 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03378983835341397		[learning rate: 0.014824]
	Learning Rate: 0.0148237
	LOSS [training: 0.03378983835341397 | validation: 0.028354160677425924]
	TIME [epoch: 32.4 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059443361461147114		[learning rate: 0.014809]
	Learning Rate: 0.0148093
	LOSS [training: 0.059443361461147114 | validation: 0.021144249052508897]
	TIME [epoch: 32.5 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07721582032921762		[learning rate: 0.014795]
	Learning Rate: 0.0147948
	LOSS [training: 0.07721582032921762 | validation: 0.1012868708880083]
	TIME [epoch: 32.4 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044279944838904205		[learning rate: 0.01478]
	Learning Rate: 0.0147803
	LOSS [training: 0.044279944838904205 | validation: 0.01656189568105559]
	TIME [epoch: 32.4 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03076023142640537		[learning rate: 0.014766]
	Learning Rate: 0.0147657
	LOSS [training: 0.03076023142640537 | validation: 0.04568653239649674]
	TIME [epoch: 32.5 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08538274844860168		[learning rate: 0.014751]
	Learning Rate: 0.0147512
	LOSS [training: 0.08538274844860168 | validation: 0.09407836363268869]
	TIME [epoch: 32.5 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10237989378707515		[learning rate: 0.014737]
	Learning Rate: 0.0147366
	LOSS [training: 0.10237989378707515 | validation: 0.04015834441401745]
	TIME [epoch: 32.5 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03214094658896932		[learning rate: 0.014722]
	Learning Rate: 0.0147221
	LOSS [training: 0.03214094658896932 | validation: 0.08678955367806883]
	TIME [epoch: 32.4 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15685732264109079		[learning rate: 0.014707]
	Learning Rate: 0.0147075
	LOSS [training: 0.15685732264109079 | validation: 0.14000015906227495]
	TIME [epoch: 32.5 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09758064580430482		[learning rate: 0.014693]
	Learning Rate: 0.0146929
	LOSS [training: 0.09758064580430482 | validation: 0.12293043956022931]
	TIME [epoch: 32.5 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08248724681540076		[learning rate: 0.014678]
	Learning Rate: 0.0146783
	LOSS [training: 0.08248724681540076 | validation: 0.10105279019150107]
	TIME [epoch: 32.5 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07394427496641434		[learning rate: 0.014664]
	Learning Rate: 0.0146637
	LOSS [training: 0.07394427496641434 | validation: 0.11022223803240092]
	TIME [epoch: 32.5 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06446001368967719		[learning rate: 0.014649]
	Learning Rate: 0.0146491
	LOSS [training: 0.06446001368967719 | validation: 0.10346868121648486]
	TIME [epoch: 32.4 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10090003143851403		[learning rate: 0.014634]
	Learning Rate: 0.0146344
	LOSS [training: 0.10090003143851403 | validation: 0.05834592404547523]
	TIME [epoch: 32.3 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044166789266900486		[learning rate: 0.01462]
	Learning Rate: 0.0146198
	LOSS [training: 0.044166789266900486 | validation: 0.046866392451921035]
	TIME [epoch: 32.5 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03871220678024877		[learning rate: 0.014605]
	Learning Rate: 0.0146051
	LOSS [training: 0.03871220678024877 | validation: 0.061993530369022484]
	TIME [epoch: 32.4 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036194746595995655		[learning rate: 0.01459]
	Learning Rate: 0.0145904
	LOSS [training: 0.036194746595995655 | validation: 0.019999464551230934]
	TIME [epoch: 32.4 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031034375700810354		[learning rate: 0.014576]
	Learning Rate: 0.0145757
	LOSS [training: 0.031034375700810354 | validation: 0.040080855714244856]
	TIME [epoch: 32.4 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09921379976800543		[learning rate: 0.014561]
	Learning Rate: 0.014561
	LOSS [training: 0.09921379976800543 | validation: 0.09258047059581054]
	TIME [epoch: 32.4 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07772681595937024		[learning rate: 0.014546]
	Learning Rate: 0.0145463
	LOSS [training: 0.07772681595937024 | validation: 0.02795465758228248]
	TIME [epoch: 32.4 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029285620509160986		[learning rate: 0.014532]
	Learning Rate: 0.0145316
	LOSS [training: 0.029285620509160986 | validation: 0.021114125029841536]
	TIME [epoch: 32.5 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027081163690428824		[learning rate: 0.014517]
	Learning Rate: 0.0145168
	LOSS [training: 0.027081163690428824 | validation: 0.02556427433204106]
	TIME [epoch: 32.4 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024661963622641458		[learning rate: 0.014502]
	Learning Rate: 0.0145021
	LOSS [training: 0.024661963622641458 | validation: 0.025467096597989423]
	TIME [epoch: 32.4 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1077648845296747		[learning rate: 0.014487]
	Learning Rate: 0.0144873
	LOSS [training: 0.1077648845296747 | validation: 0.11413977284549964]
	TIME [epoch: 32.4 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0654386886701739		[learning rate: 0.014473]
	Learning Rate: 0.0144726
	LOSS [training: 0.0654386886701739 | validation: 0.023213374163056293]
	TIME [epoch: 32.5 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035995420440883504		[learning rate: 0.014458]
	Learning Rate: 0.0144578
	LOSS [training: 0.035995420440883504 | validation: 0.028164147159724786]
	TIME [epoch: 32.4 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025955282235814066		[learning rate: 0.014443]
	Learning Rate: 0.014443
	LOSS [training: 0.025955282235814066 | validation: 0.02232518102600279]
	TIME [epoch: 32.4 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02246884303314723		[learning rate: 0.014428]
	Learning Rate: 0.0144281
	LOSS [training: 0.02246884303314723 | validation: 0.025385714701783697]
	TIME [epoch: 32.4 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053241811375030895		[learning rate: 0.014413]
	Learning Rate: 0.0144133
	LOSS [training: 0.053241811375030895 | validation: 0.026516401831542136]
	TIME [epoch: 32.5 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2046749206170015		[learning rate: 0.014398]
	Learning Rate: 0.0143985
	LOSS [training: 0.2046749206170015 | validation: 0.13408298119320883]
	TIME [epoch: 32.4 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08356254410711864		[learning rate: 0.014384]
	Learning Rate: 0.0143836
	LOSS [training: 0.08356254410711864 | validation: 0.02372379033829549]
	TIME [epoch: 32.5 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06803338116168946		[learning rate: 0.014369]
	Learning Rate: 0.0143688
	LOSS [training: 0.06803338116168946 | validation: 0.030279970788352997]
	TIME [epoch: 32.4 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0298276903876221		[learning rate: 0.014354]
	Learning Rate: 0.0143539
	LOSS [training: 0.0298276903876221 | validation: 0.0232955269971929]
	TIME [epoch: 32.5 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032989518808826786		[learning rate: 0.014339]
	Learning Rate: 0.014339
	LOSS [training: 0.032989518808826786 | validation: 0.0210721869028528]
	TIME [epoch: 32.4 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01957759448925376		[learning rate: 0.014324]
	Learning Rate: 0.0143241
	LOSS [training: 0.01957759448925376 | validation: 0.02337110141642595]
	TIME [epoch: 32.4 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04016414272029124		[learning rate: 0.014309]
	Learning Rate: 0.0143092
	LOSS [training: 0.04016414272029124 | validation: 0.033805165232409]
	TIME [epoch: 32.4 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14282247682723892		[learning rate: 0.014294]
	Learning Rate: 0.0142943
	LOSS [training: 0.14282247682723892 | validation: 0.07387220991959403]
	TIME [epoch: 32.4 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06832000153067119		[learning rate: 0.014279]
	Learning Rate: 0.0142793
	LOSS [training: 0.06832000153067119 | validation: 0.029301034870819354]
	TIME [epoch: 32.4 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05530658817171252		[learning rate: 0.014264]
	Learning Rate: 0.0142644
	LOSS [training: 0.05530658817171252 | validation: 0.019622601001916592]
	TIME [epoch: 32.4 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06487742293688191		[learning rate: 0.014249]
	Learning Rate: 0.0142494
	LOSS [training: 0.06487742293688191 | validation: 0.03855535201293954]
	TIME [epoch: 32.4 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040060200888142765		[learning rate: 0.014234]
	Learning Rate: 0.0142345
	LOSS [training: 0.040060200888142765 | validation: 0.053645953936334895]
	TIME [epoch: 32.4 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09748006636747655		[learning rate: 0.014219]
	Learning Rate: 0.0142195
	LOSS [training: 0.09748006636747655 | validation: 0.025377586993853618]
	TIME [epoch: 32.4 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02388416617113839		[learning rate: 0.014205]
	Learning Rate: 0.0142045
	LOSS [training: 0.02388416617113839 | validation: 0.023128820491345396]
	TIME [epoch: 32.4 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029777629881969872		[learning rate: 0.01419]
	Learning Rate: 0.0141895
	LOSS [training: 0.029777629881969872 | validation: 0.019576023335815353]
	TIME [epoch: 32.4 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029745630236134423		[learning rate: 0.014174]
	Learning Rate: 0.0141745
	LOSS [training: 0.029745630236134423 | validation: 0.1725787735630979]
	TIME [epoch: 32.4 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11425628443387331		[learning rate: 0.014159]
	Learning Rate: 0.0141595
	LOSS [training: 0.11425628443387331 | validation: 0.03486550063714413]
	TIME [epoch: 32.4 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03861621273184198		[learning rate: 0.014144]
	Learning Rate: 0.0141444
	LOSS [training: 0.03861621273184198 | validation: 0.029162703302996605]
	TIME [epoch: 32.4 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03226124080745697		[learning rate: 0.014129]
	Learning Rate: 0.0141294
	LOSS [training: 0.03226124080745697 | validation: 0.025554054322059483]
	TIME [epoch: 32.4 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06646348157524415		[learning rate: 0.014114]
	Learning Rate: 0.0141143
	LOSS [training: 0.06646348157524415 | validation: 0.0498944510431369]
	TIME [epoch: 32.4 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051797346298671776		[learning rate: 0.014099]
	Learning Rate: 0.0140992
	LOSS [training: 0.051797346298671776 | validation: 0.08836123236053384]
	TIME [epoch: 32.4 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04583729871561083		[learning rate: 0.014084]
	Learning Rate: 0.0140842
	LOSS [training: 0.04583729871561083 | validation: 0.0287876503091861]
	TIME [epoch: 32.5 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034583059478685556		[learning rate: 0.014069]
	Learning Rate: 0.0140691
	LOSS [training: 0.034583059478685556 | validation: 0.02386101943144674]
	TIME [epoch: 32.4 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08606316040006201		[learning rate: 0.014054]
	Learning Rate: 0.014054
	LOSS [training: 0.08606316040006201 | validation: 0.051416777932598814]
	TIME [epoch: 32.5 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029625145625598127		[learning rate: 0.014039]
	Learning Rate: 0.0140389
	LOSS [training: 0.029625145625598127 | validation: 0.016825311560308174]
	TIME [epoch: 32.5 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031672113005718615		[learning rate: 0.014024]
	Learning Rate: 0.0140237
	LOSS [training: 0.031672113005718615 | validation: 0.022520588174245577]
	TIME [epoch: 32.6 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02186581771601254		[learning rate: 0.014009]
	Learning Rate: 0.0140086
	LOSS [training: 0.02186581771601254 | validation: 0.04370689625611523]
	TIME [epoch: 32.5 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0461849142418501		[learning rate: 0.013993]
	Learning Rate: 0.0139934
	LOSS [training: 0.0461849142418501 | validation: 0.026317371002971893]
	TIME [epoch: 32.6 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038067509780263784		[learning rate: 0.013978]
	Learning Rate: 0.0139783
	LOSS [training: 0.038067509780263784 | validation: 0.12739797422014867]
	TIME [epoch: 32.6 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0779365090593159		[learning rate: 0.013963]
	Learning Rate: 0.0139631
	LOSS [training: 0.0779365090593159 | validation: 0.09328296418427895]
	TIME [epoch: 32.6 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05326094144545433		[learning rate: 0.013948]
	Learning Rate: 0.0139479
	LOSS [training: 0.05326094144545433 | validation: 0.03079488833983645]
	TIME [epoch: 32.6 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052516184071568675		[learning rate: 0.013933]
	Learning Rate: 0.0139327
	LOSS [training: 0.052516184071568675 | validation: 0.04209569240591468]
	TIME [epoch: 32.5 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05396000991204611		[learning rate: 0.013918]
	Learning Rate: 0.0139175
	LOSS [training: 0.05396000991204611 | validation: 0.027644574321127154]
	TIME [epoch: 32.6 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053290564551378934		[learning rate: 0.013902]
	Learning Rate: 0.0139023
	LOSS [training: 0.053290564551378934 | validation: 0.036848924926067214]
	TIME [epoch: 32.6 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02479935187206353		[learning rate: 0.013887]
	Learning Rate: 0.0138871
	LOSS [training: 0.02479935187206353 | validation: 0.019505902312567137]
	TIME [epoch: 32.6 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024170069451155445		[learning rate: 0.013872]
	Learning Rate: 0.0138719
	LOSS [training: 0.024170069451155445 | validation: 0.02056003260553109]
	TIME [epoch: 32.6 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027512428387237886		[learning rate: 0.013857]
	Learning Rate: 0.0138566
	LOSS [training: 0.027512428387237886 | validation: 0.09599387273602966]
	TIME [epoch: 32.6 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07860284696778048		[learning rate: 0.013841]
	Learning Rate: 0.0138414
	LOSS [training: 0.07860284696778048 | validation: 0.02204818920556238]
	TIME [epoch: 32.6 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12703711062098005		[learning rate: 0.013826]
	Learning Rate: 0.0138261
	LOSS [training: 0.12703711062098005 | validation: 0.19290076326750477]
	TIME [epoch: 32.7 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10697335961353382		[learning rate: 0.013811]
	Learning Rate: 0.0138108
	LOSS [training: 0.10697335961353382 | validation: 0.03144842597849698]
	TIME [epoch: 32.6 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033112250076400083		[learning rate: 0.013796]
	Learning Rate: 0.0137955
	LOSS [training: 0.033112250076400083 | validation: 0.01794057118630632]
	TIME [epoch: 32.6 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08420104747621154		[learning rate: 0.01378]
	Learning Rate: 0.0137802
	LOSS [training: 0.08420104747621154 | validation: 0.02100718556599397]
	TIME [epoch: 32.5 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03360491815809097		[learning rate: 0.013765]
	Learning Rate: 0.0137649
	LOSS [training: 0.03360491815809097 | validation: 0.029137533201101965]
	TIME [epoch: 32.6 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02561225814761892		[learning rate: 0.01375]
	Learning Rate: 0.0137496
	LOSS [training: 0.02561225814761892 | validation: 0.01833612727010831]
	TIME [epoch: 32.6 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06530518496850285		[learning rate: 0.013734]
	Learning Rate: 0.0137343
	LOSS [training: 0.06530518496850285 | validation: 0.054836485892084716]
	TIME [epoch: 32.5 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0954408943185374		[learning rate: 0.013719]
	Learning Rate: 0.013719
	LOSS [training: 0.0954408943185374 | validation: 0.026213548302902175]
	TIME [epoch: 32.5 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030999598039635527		[learning rate: 0.013704]
	Learning Rate: 0.0137036
	LOSS [training: 0.030999598039635527 | validation: 0.0196179348156081]
	TIME [epoch: 32.5 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02236056512349497		[learning rate: 0.013688]
	Learning Rate: 0.0136882
	LOSS [training: 0.02236056512349497 | validation: 0.015789988020748595]
	TIME [epoch: 32.5 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18060371022656072		[learning rate: 0.013673]
	Learning Rate: 0.0136729
	LOSS [training: 0.18060371022656072 | validation: 0.07531574888311701]
	TIME [epoch: 32.5 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0640368920562254		[learning rate: 0.013657]
	Learning Rate: 0.0136575
	LOSS [training: 0.0640368920562254 | validation: 0.057356926892144014]
	TIME [epoch: 32.5 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04619314718533249		[learning rate: 0.013642]
	Learning Rate: 0.0136421
	LOSS [training: 0.04619314718533249 | validation: 0.020196252756774866]
	TIME [epoch: 32.6 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022557691276879593		[learning rate: 0.013627]
	Learning Rate: 0.0136267
	LOSS [training: 0.022557691276879593 | validation: 0.01825208461432799]
	TIME [epoch: 32.5 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021469869522124835		[learning rate: 0.013611]
	Learning Rate: 0.0136113
	LOSS [training: 0.021469869522124835 | validation: 0.018754321505754085]
	TIME [epoch: 32.5 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023341322359195185		[learning rate: 0.013596]
	Learning Rate: 0.0135959
	LOSS [training: 0.023341322359195185 | validation: 0.04347478713921479]
	TIME [epoch: 32.5 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045823804213768554		[learning rate: 0.01358]
	Learning Rate: 0.0135805
	LOSS [training: 0.045823804213768554 | validation: 0.02904912627190672]
	TIME [epoch: 32.6 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07366316674528278		[learning rate: 0.013565]
	Learning Rate: 0.013565
	LOSS [training: 0.07366316674528278 | validation: 0.050938439879387266]
	TIME [epoch: 32.6 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03590464627945805		[learning rate: 0.01355]
	Learning Rate: 0.0135496
	LOSS [training: 0.03590464627945805 | validation: 0.01677140344710608]
	TIME [epoch: 32.5 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13938795119161468		[learning rate: 0.013534]
	Learning Rate: 0.0135341
	LOSS [training: 0.13938795119161468 | validation: 0.11205115625570038]
	TIME [epoch: 32.5 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.066994543283454		[learning rate: 0.013519]
	Learning Rate: 0.0135186
	LOSS [training: 0.066994543283454 | validation: 0.04775886419436014]
	TIME [epoch: 32.5 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04677341001971713		[learning rate: 0.013503]
	Learning Rate: 0.0135032
	LOSS [training: 0.04677341001971713 | validation: 0.038569006027303274]
	TIME [epoch: 32.4 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03399705807465133		[learning rate: 0.013488]
	Learning Rate: 0.0134877
	LOSS [training: 0.03399705807465133 | validation: 0.025503014701200005]
	TIME [epoch: 32.4 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0226888362827613		[learning rate: 0.013472]
	Learning Rate: 0.0134722
	LOSS [training: 0.0226888362827613 | validation: 0.030698354742510335]
	TIME [epoch: 32.4 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03259475940732422		[learning rate: 0.013457]
	Learning Rate: 0.0134567
	LOSS [training: 0.03259475940732422 | validation: 0.03169461929139019]
	TIME [epoch: 32.5 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022236715246039464		[learning rate: 0.013441]
	Learning Rate: 0.0134412
	LOSS [training: 0.022236715246039464 | validation: 0.026706145530133046]
	TIME [epoch: 32.4 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0461442226992073		[learning rate: 0.013426]
	Learning Rate: 0.0134256
	LOSS [training: 0.0461442226992073 | validation: 0.04753806800470668]
	TIME [epoch: 32.4 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03470584325541527		[learning rate: 0.01341]
	Learning Rate: 0.0134101
	LOSS [training: 0.03470584325541527 | validation: 0.021692618134340265]
	TIME [epoch: 32.4 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020362777043211176		[learning rate: 0.013395]
	Learning Rate: 0.0133946
	LOSS [training: 0.020362777043211176 | validation: 0.014177414879761138]
	TIME [epoch: 32.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_791.pth
	Model improved!!!
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039284985372291456		[learning rate: 0.013379]
	Learning Rate: 0.013379
	LOSS [training: 0.039284985372291456 | validation: 0.017926955458117302]
	TIME [epoch: 32.6 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04606008495882478		[learning rate: 0.013363]
	Learning Rate: 0.0133635
	LOSS [training: 0.04606008495882478 | validation: 0.06386875217841056]
	TIME [epoch: 32.6 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05215320637986148		[learning rate: 0.013348]
	Learning Rate: 0.0133479
	LOSS [training: 0.05215320637986148 | validation: 0.02529169549596839]
	TIME [epoch: 32.5 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06092584289062292		[learning rate: 0.013332]
	Learning Rate: 0.0133323
	LOSS [training: 0.06092584289062292 | validation: 0.02725465929721258]
	TIME [epoch: 32.5 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024779653101719815		[learning rate: 0.013317]
	Learning Rate: 0.0133167
	LOSS [training: 0.024779653101719815 | validation: 0.01868075738111629]
	TIME [epoch: 32.4 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06137971551327294		[learning rate: 0.013301]
	Learning Rate: 0.0133011
	LOSS [training: 0.06137971551327294 | validation: 0.0339210447537496]
	TIME [epoch: 32.5 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029669048877429723		[learning rate: 0.013286]
	Learning Rate: 0.0132855
	LOSS [training: 0.029669048877429723 | validation: 0.01937207495387446]
	TIME [epoch: 32.6 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02637796551278177		[learning rate: 0.01327]
	Learning Rate: 0.0132699
	LOSS [training: 0.02637796551278177 | validation: 0.02085120181188917]
	TIME [epoch: 32.6 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03179152704845348		[learning rate: 0.013254]
	Learning Rate: 0.0132543
	LOSS [training: 0.03179152704845348 | validation: 0.022852687614580924]
	TIME [epoch: 32.6 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025956175323886332		[learning rate: 0.013239]
	Learning Rate: 0.0132386
	LOSS [training: 0.025956175323886332 | validation: 0.029889346837905787]
	TIME [epoch: 32.6 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08460486127149328		[learning rate: 0.013223]
	Learning Rate: 0.013223
	LOSS [training: 0.08460486127149328 | validation: 0.05439069861811731]
	TIME [epoch: 32.5 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07939840910869315		[learning rate: 0.013207]
	Learning Rate: 0.0132074
	LOSS [training: 0.07939840910869315 | validation: 0.03240903673031505]
	TIME [epoch: 32.5 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033402381467001016		[learning rate: 0.013192]
	Learning Rate: 0.0131917
	LOSS [training: 0.033402381467001016 | validation: 0.02199234847617333]
	TIME [epoch: 32.5 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022798733627791352		[learning rate: 0.013176]
	Learning Rate: 0.013176
	LOSS [training: 0.022798733627791352 | validation: 0.026318004698988373]
	TIME [epoch: 32.5 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06743452707592015		[learning rate: 0.01316]
	Learning Rate: 0.0131603
	LOSS [training: 0.06743452707592015 | validation: 0.029346875374538985]
	TIME [epoch: 32.5 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02813372961831899		[learning rate: 0.013145]
	Learning Rate: 0.0131447
	LOSS [training: 0.02813372961831899 | validation: 0.019367174805883007]
	TIME [epoch: 32.6 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05100881716180298		[learning rate: 0.013129]
	Learning Rate: 0.013129
	LOSS [training: 0.05100881716180298 | validation: 0.06631560905733062]
	TIME [epoch: 32.6 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22207860802952178		[learning rate: 0.013113]
	Learning Rate: 0.0131133
	LOSS [training: 0.22207860802952178 | validation: 0.0770298465574032]
	TIME [epoch: 32.6 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048649128016388994		[learning rate: 0.013098]
	Learning Rate: 0.0130976
	LOSS [training: 0.048649128016388994 | validation: 0.06445007945256453]
	TIME [epoch: 32.6 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03065936780282458		[learning rate: 0.013082]
	Learning Rate: 0.0130818
	LOSS [training: 0.03065936780282458 | validation: 0.014687583084496754]
	TIME [epoch: 32.5 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022065901251401607		[learning rate: 0.013066]
	Learning Rate: 0.0130661
	LOSS [training: 0.022065901251401607 | validation: 0.015651800708611052]
	TIME [epoch: 32.5 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02365673949062081		[learning rate: 0.01305]
	Learning Rate: 0.0130504
	LOSS [training: 0.02365673949062081 | validation: 0.05133753012690169]
	TIME [epoch: 32.6 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052170338395647865		[learning rate: 0.013035]
	Learning Rate: 0.0130346
	LOSS [training: 0.052170338395647865 | validation: 0.021733178937603178]
	TIME [epoch: 32.6 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020649289923830375		[learning rate: 0.013019]
	Learning Rate: 0.0130189
	LOSS [training: 0.020649289923830375 | validation: 0.014386094586086574]
	TIME [epoch: 32.6 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017370089466354596		[learning rate: 0.013003]
	Learning Rate: 0.0130031
	LOSS [training: 0.017370089466354596 | validation: 0.02081437764624941]
	TIME [epoch: 32.6 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11859029731738886		[learning rate: 0.012987]
	Learning Rate: 0.0129873
	LOSS [training: 0.11859029731738886 | validation: 0.04635038803708383]
	TIME [epoch: 32.6 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05538860479794472		[learning rate: 0.012972]
	Learning Rate: 0.0129716
	LOSS [training: 0.05538860479794472 | validation: 0.05471492439190595]
	TIME [epoch: 32.5 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08973313610038167		[learning rate: 0.012956]
	Learning Rate: 0.0129558
	LOSS [training: 0.08973313610038167 | validation: 0.022332333171224395]
	TIME [epoch: 32.6 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02010432186367849		[learning rate: 0.01294]
	Learning Rate: 0.01294
	LOSS [training: 0.02010432186367849 | validation: 0.01285574107421736]
	TIME [epoch: 32.5 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_820.pth
	Model improved!!!
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01687559320651887		[learning rate: 0.012924]
	Learning Rate: 0.0129242
	LOSS [training: 0.01687559320651887 | validation: 0.017053405549059906]
	TIME [epoch: 32.6 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02189725380573668		[learning rate: 0.012908]
	Learning Rate: 0.0129084
	LOSS [training: 0.02189725380573668 | validation: 0.020902510241329355]
	TIME [epoch: 32.6 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020541075128160044		[learning rate: 0.012893]
	Learning Rate: 0.0128926
	LOSS [training: 0.020541075128160044 | validation: 0.01457640643890213]
	TIME [epoch: 32.6 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04559157206687148		[learning rate: 0.012877]
	Learning Rate: 0.0128767
	LOSS [training: 0.04559157206687148 | validation: 0.030670354537525105]
	TIME [epoch: 32.6 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05213782157844968		[learning rate: 0.012861]
	Learning Rate: 0.0128609
	LOSS [training: 0.05213782157844968 | validation: 0.03246174260879689]
	TIME [epoch: 32.6 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030604433660393348		[learning rate: 0.012845]
	Learning Rate: 0.0128451
	LOSS [training: 0.030604433660393348 | validation: 0.018284490715318086]
	TIME [epoch: 32.6 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019418831060690627		[learning rate: 0.012829]
	Learning Rate: 0.0128292
	LOSS [training: 0.019418831060690627 | validation: 0.023595883787113078]
	TIME [epoch: 32.7 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10742145260047353		[learning rate: 0.012813]
	Learning Rate: 0.0128133
	LOSS [training: 0.10742145260047353 | validation: 0.15723744970180417]
	TIME [epoch: 32.7 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.303729535736574		[learning rate: 0.012797]
	Learning Rate: 0.0127975
	LOSS [training: 0.303729535736574 | validation: 0.156473063658092]
	TIME [epoch: 32.6 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2670314250916349		[learning rate: 0.012782]
	Learning Rate: 0.0127816
	LOSS [training: 0.2670314250916349 | validation: 0.06413582179262452]
	TIME [epoch: 32.7 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04924292881237458		[learning rate: 0.012766]
	Learning Rate: 0.0127657
	LOSS [training: 0.04924292881237458 | validation: 0.02415867850256781]
	TIME [epoch: 32.7 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04404948859063967		[learning rate: 0.01275]
	Learning Rate: 0.0127498
	LOSS [training: 0.04404948859063967 | validation: 0.02446333354192968]
	TIME [epoch: 32.7 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02255052588712637		[learning rate: 0.012734]
	Learning Rate: 0.0127339
	LOSS [training: 0.02255052588712637 | validation: 0.016360796848603105]
	TIME [epoch: 32.7 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01843781487430503		[learning rate: 0.012718]
	Learning Rate: 0.012718
	LOSS [training: 0.01843781487430503 | validation: 0.06489012090894529]
	TIME [epoch: 32.7 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040428219168821576		[learning rate: 0.012702]
	Learning Rate: 0.0127021
	LOSS [training: 0.040428219168821576 | validation: 0.016101372890931102]
	TIME [epoch: 32.7 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014816704114951923		[learning rate: 0.012686]
	Learning Rate: 0.0126862
	LOSS [training: 0.014816704114951923 | validation: 0.014622169988458259]
	TIME [epoch: 32.7 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024592491834961316		[learning rate: 0.01267]
	Learning Rate: 0.0126703
	LOSS [training: 0.024592491834961316 | validation: 0.024216993341495657]
	TIME [epoch: 32.8 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04721012657485171		[learning rate: 0.012654]
	Learning Rate: 0.0126544
	LOSS [training: 0.04721012657485171 | validation: 0.03809043539195081]
	TIME [epoch: 32.9 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05957753977898972		[learning rate: 0.012638]
	Learning Rate: 0.0126384
	LOSS [training: 0.05957753977898972 | validation: 0.049275476661320566]
	TIME [epoch: 32.8 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08549332952791563		[learning rate: 0.012622]
	Learning Rate: 0.0126225
	LOSS [training: 0.08549332952791563 | validation: 0.03911939059668793]
	TIME [epoch: 32.8 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038460661934333173		[learning rate: 0.012607]
	Learning Rate: 0.0126065
	LOSS [training: 0.038460661934333173 | validation: 0.02171889248892685]
	TIME [epoch: 32.8 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02072975154440349		[learning rate: 0.012591]
	Learning Rate: 0.0125906
	LOSS [training: 0.02072975154440349 | validation: 0.020213204653247302]
	TIME [epoch: 32.9 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037699099423968443		[learning rate: 0.012575]
	Learning Rate: 0.0125746
	LOSS [training: 0.037699099423968443 | validation: 0.05154419674822294]
	TIME [epoch: 32.9 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04485368861781646		[learning rate: 0.012559]
	Learning Rate: 0.0125586
	LOSS [training: 0.04485368861781646 | validation: 0.032790166580320454]
	TIME [epoch: 32.9 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06024454514362642		[learning rate: 0.012543]
	Learning Rate: 0.0125426
	LOSS [training: 0.06024454514362642 | validation: 0.02603399551696984]
	TIME [epoch: 32.8 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023072472378119577		[learning rate: 0.012527]
	Learning Rate: 0.0125267
	LOSS [training: 0.023072472378119577 | validation: 0.014261836689564426]
	TIME [epoch: 32.9 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08244197924134666		[learning rate: 0.012511]
	Learning Rate: 0.0125107
	LOSS [training: 0.08244197924134666 | validation: 0.06510749478367589]
	TIME [epoch: 32.9 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04574019019892858		[learning rate: 0.012495]
	Learning Rate: 0.0124947
	LOSS [training: 0.04574019019892858 | validation: 0.03843693061093385]
	TIME [epoch: 33 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07795606370757434		[learning rate: 0.012479]
	Learning Rate: 0.0124786
	LOSS [training: 0.07795606370757434 | validation: 0.037288117768431786]
	TIME [epoch: 32.6 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03204147834090107		[learning rate: 0.012463]
	Learning Rate: 0.0124626
	LOSS [training: 0.03204147834090107 | validation: 0.02461992077799771]
	TIME [epoch: 32.8 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02175373554819646		[learning rate: 0.012447]
	Learning Rate: 0.0124466
	LOSS [training: 0.02175373554819646 | validation: 0.016922138529705158]
	TIME [epoch: 32.6 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01882896233038605		[learning rate: 0.012431]
	Learning Rate: 0.0124306
	LOSS [training: 0.01882896233038605 | validation: 0.022820709091613316]
	TIME [epoch: 32.7 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02421687456296376		[learning rate: 0.012415]
	Learning Rate: 0.0124145
	LOSS [training: 0.02421687456296376 | validation: 0.057447243610255806]
	TIME [epoch: 32.7 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040305075591073006		[learning rate: 0.012399]
	Learning Rate: 0.0123985
	LOSS [training: 0.040305075591073006 | validation: 0.025992112281962257]
	TIME [epoch: 32.8 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10604982271977309		[learning rate: 0.012382]
	Learning Rate: 0.0123825
	LOSS [training: 0.10604982271977309 | validation: 0.09797553334370832]
	TIME [epoch: 32.7 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08516956465267922		[learning rate: 0.012366]
	Learning Rate: 0.0123664
	LOSS [training: 0.08516956465267922 | validation: 0.047514150692948745]
	TIME [epoch: 32.7 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0547958308197065		[learning rate: 0.01235]
	Learning Rate: 0.0123503
	LOSS [training: 0.0547958308197065 | validation: 0.054956274773579575]
	TIME [epoch: 32.8 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039074277516631443		[learning rate: 0.012334]
	Learning Rate: 0.0123343
	LOSS [training: 0.039074277516631443 | validation: 0.01583704050565838]
	TIME [epoch: 32.7 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020059667472141645		[learning rate: 0.012318]
	Learning Rate: 0.0123182
	LOSS [training: 0.020059667472141645 | validation: 0.01491456624315684]
	TIME [epoch: 32.7 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028316716832240248		[learning rate: 0.012302]
	Learning Rate: 0.0123021
	LOSS [training: 0.028316716832240248 | validation: 0.0342540491224973]
	TIME [epoch: 32.8 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025094095333905882		[learning rate: 0.012286]
	Learning Rate: 0.012286
	LOSS [training: 0.025094095333905882 | validation: 0.01411639875462124]
	TIME [epoch: 32.7 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021185546000072022		[learning rate: 0.01227]
	Learning Rate: 0.0122699
	LOSS [training: 0.021185546000072022 | validation: 0.03450145820938059]
	TIME [epoch: 32.8 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04876848472963638		[learning rate: 0.012254]
	Learning Rate: 0.0122538
	LOSS [training: 0.04876848472963638 | validation: 0.03592180808113224]
	TIME [epoch: 32.9 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03965530777780796		[learning rate: 0.012238]
	Learning Rate: 0.0122377
	LOSS [training: 0.03965530777780796 | validation: 0.05889830015561476]
	TIME [epoch: 32.8 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03322322061420297		[learning rate: 0.012222]
	Learning Rate: 0.0122216
	LOSS [training: 0.03322322061420297 | validation: 0.021087306917417302]
	TIME [epoch: 32.8 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036358531731348225		[learning rate: 0.012205]
	Learning Rate: 0.0122055
	LOSS [training: 0.036358531731348225 | validation: 0.02485130099115964]
	TIME [epoch: 32.8 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024190936793649448		[learning rate: 0.012189]
	Learning Rate: 0.0121894
	LOSS [training: 0.024190936793649448 | validation: 0.01689000666256893]
	TIME [epoch: 32.9 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020984646053591693		[learning rate: 0.012173]
	Learning Rate: 0.0121732
	LOSS [training: 0.020984646053591693 | validation: 0.06495344833866903]
	TIME [epoch: 32.9 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0664614683329733		[learning rate: 0.012157]
	Learning Rate: 0.0121571
	LOSS [training: 0.0664614683329733 | validation: 0.0749227667432611]
	TIME [epoch: 32.9 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06640595206738832		[learning rate: 0.012141]
	Learning Rate: 0.012141
	LOSS [training: 0.06640595206738832 | validation: 0.011674443665782352]
	TIME [epoch: 32.8 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_870.pth
	Model improved!!!
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030890917691186855		[learning rate: 0.012125]
	Learning Rate: 0.0121248
	LOSS [training: 0.030890917691186855 | validation: 0.03145199884242493]
	TIME [epoch: 32.8 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042881820130939725		[learning rate: 0.012109]
	Learning Rate: 0.0121087
	LOSS [training: 0.042881820130939725 | validation: 0.022561779635066885]
	TIME [epoch: 32.9 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02070648732727958		[learning rate: 0.012093]
	Learning Rate: 0.0120925
	LOSS [training: 0.02070648732727958 | validation: 0.014150200707949753]
	TIME [epoch: 32.9 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019716853909201665		[learning rate: 0.012076]
	Learning Rate: 0.0120763
	LOSS [training: 0.019716853909201665 | validation: 0.024307056015990272]
	TIME [epoch: 32.9 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031285918215874835		[learning rate: 0.01206]
	Learning Rate: 0.0120602
	LOSS [training: 0.031285918215874835 | validation: 0.03958378060891545]
	TIME [epoch: 32.8 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04502799035177193		[learning rate: 0.012044]
	Learning Rate: 0.012044
	LOSS [training: 0.04502799035177193 | validation: 0.025417589368725606]
	TIME [epoch: 32.8 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04371151211129409		[learning rate: 0.012028]
	Learning Rate: 0.0120278
	LOSS [training: 0.04371151211129409 | validation: 0.014830526598837008]
	TIME [epoch: 32.9 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03738244844792748		[learning rate: 0.012012]
	Learning Rate: 0.0120116
	LOSS [training: 0.03738244844792748 | validation: 0.0284636532163821]
	TIME [epoch: 33 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08812035464426576		[learning rate: 0.011995]
	Learning Rate: 0.0119954
	LOSS [training: 0.08812035464426576 | validation: 0.15439986552421794]
	TIME [epoch: 32.9 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12369867672580465		[learning rate: 0.011979]
	Learning Rate: 0.0119792
	LOSS [training: 0.12369867672580465 | validation: 0.018067913233781645]
	TIME [epoch: 32.8 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019469130018862794		[learning rate: 0.011963]
	Learning Rate: 0.011963
	LOSS [training: 0.019469130018862794 | validation: 0.016507864254923184]
	TIME [epoch: 32.8 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047798023302531197		[learning rate: 0.011947]
	Learning Rate: 0.0119468
	LOSS [training: 0.047798023302531197 | validation: 0.017267237112753207]
	TIME [epoch: 32.9 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032596279186556956		[learning rate: 0.011931]
	Learning Rate: 0.0119306
	LOSS [training: 0.032596279186556956 | validation: 0.02849931926569093]
	TIME [epoch: 32.9 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023554616940339633		[learning rate: 0.011914]
	Learning Rate: 0.0119144
	LOSS [training: 0.023554616940339633 | validation: 0.01792647440867986]
	TIME [epoch: 32.8 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0450225671643675		[learning rate: 0.011898]
	Learning Rate: 0.0118982
	LOSS [training: 0.0450225671643675 | validation: 0.020822058289252127]
	TIME [epoch: 32.8 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023156355274012465		[learning rate: 0.011882]
	Learning Rate: 0.0118819
	LOSS [training: 0.023156355274012465 | validation: 0.014450530974289399]
	TIME [epoch: 32.9 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01825092282057036		[learning rate: 0.011866]
	Learning Rate: 0.0118657
	LOSS [training: 0.01825092282057036 | validation: 0.01887490054519541]
	TIME [epoch: 32.9 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0889217500128717		[learning rate: 0.011849]
	Learning Rate: 0.0118495
	LOSS [training: 0.0889217500128717 | validation: 0.0574860366050187]
	TIME [epoch: 32.8 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06568302292612989		[learning rate: 0.011833]
	Learning Rate: 0.0118332
	LOSS [training: 0.06568302292612989 | validation: 0.03986496069339002]
	TIME [epoch: 32.8 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03054881540102319		[learning rate: 0.011817]
	Learning Rate: 0.011817
	LOSS [training: 0.03054881540102319 | validation: 0.0163935944889558]
	TIME [epoch: 32.8 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02602240810115897		[learning rate: 0.011801]
	Learning Rate: 0.0118007
	LOSS [training: 0.02602240810115897 | validation: 0.016146353508886577]
	TIME [epoch: 32.7 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16123126579126495		[learning rate: 0.011784]
	Learning Rate: 0.0117844
	LOSS [training: 0.16123126579126495 | validation: 0.33806888872734053]
	TIME [epoch: 32.8 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24636571989783934		[learning rate: 0.011768]
	Learning Rate: 0.0117682
	LOSS [training: 0.24636571989783934 | validation: 0.06976404022763888]
	TIME [epoch: 32.7 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041823412326653285		[learning rate: 0.011752]
	Learning Rate: 0.0117519
	LOSS [training: 0.041823412326653285 | validation: 0.01716586273109925]
	TIME [epoch: 32.8 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02328643585101315		[learning rate: 0.011736]
	Learning Rate: 0.0117356
	LOSS [training: 0.02328643585101315 | validation: 0.01748173043005241]
	TIME [epoch: 32.9 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022536189200227427		[learning rate: 0.011719]
	Learning Rate: 0.0117194
	LOSS [training: 0.022536189200227427 | validation: 0.020199713399261285]
	TIME [epoch: 32.9 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050972553432385596		[learning rate: 0.011703]
	Learning Rate: 0.0117031
	LOSS [training: 0.050972553432385596 | validation: 0.01652818118507253]
	TIME [epoch: 32.9 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018318532587883473		[learning rate: 0.011687]
	Learning Rate: 0.0116868
	LOSS [training: 0.018318532587883473 | validation: 0.022816536660500243]
	TIME [epoch: 32.9 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02144350407563321		[learning rate: 0.01167]
	Learning Rate: 0.0116705
	LOSS [training: 0.02144350407563321 | validation: 0.020127550515599984]
	TIME [epoch: 32.9 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035157134589672526		[learning rate: 0.011654]
	Learning Rate: 0.0116542
	LOSS [training: 0.035157134589672526 | validation: 0.017667338160223006]
	TIME [epoch: 32.9 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02367368877231247		[learning rate: 0.011638]
	Learning Rate: 0.0116379
	LOSS [training: 0.02367368877231247 | validation: 0.025287526673510335]
	TIME [epoch: 32.8 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05677183898230334		[learning rate: 0.011622]
	Learning Rate: 0.0116216
	LOSS [training: 0.05677183898230334 | validation: 0.01988844638588611]
	TIME [epoch: 32.9 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02159223948231451		[learning rate: 0.011605]
	Learning Rate: 0.0116053
	LOSS [training: 0.02159223948231451 | validation: 0.024724387078795915]
	TIME [epoch: 32.9 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10475943212484785		[learning rate: 0.011589]
	Learning Rate: 0.011589
	LOSS [training: 0.10475943212484785 | validation: 0.018785942623190676]
	TIME [epoch: 32.9 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030160900865597747		[learning rate: 0.011573]
	Learning Rate: 0.0115726
	LOSS [training: 0.030160900865597747 | validation: 0.015252920035351905]
	TIME [epoch: 32.9 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017870569227018192		[learning rate: 0.011556]
	Learning Rate: 0.0115563
	LOSS [training: 0.017870569227018192 | validation: 0.012806870202505288]
	TIME [epoch: 32.9 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01872597510639846		[learning rate: 0.01154]
	Learning Rate: 0.01154
	LOSS [training: 0.01872597510639846 | validation: 0.022381012587612464]
	TIME [epoch: 32.9 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02482764707822003		[learning rate: 0.011524]
	Learning Rate: 0.0115237
	LOSS [training: 0.02482764707822003 | validation: 0.0204704958083178]
	TIME [epoch: 32.9 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021357601733676325		[learning rate: 0.011507]
	Learning Rate: 0.0115073
	LOSS [training: 0.021357601733676325 | validation: 0.030741439541110194]
	TIME [epoch: 32.8 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03353129654739726		[learning rate: 0.011491]
	Learning Rate: 0.011491
	LOSS [training: 0.03353129654739726 | validation: 0.018867367071067703]
	TIME [epoch: 32.9 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03485571423014998		[learning rate: 0.011475]
	Learning Rate: 0.0114746
	LOSS [training: 0.03485571423014998 | validation: 0.02518894058214271]
	TIME [epoch: 32.9 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03712288663722071		[learning rate: 0.011458]
	Learning Rate: 0.0114583
	LOSS [training: 0.03712288663722071 | validation: 0.03407354948669095]
	TIME [epoch: 32.9 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040837306881014945		[learning rate: 0.011442]
	Learning Rate: 0.0114419
	LOSS [training: 0.040837306881014945 | validation: 0.036937132280492675]
	TIME [epoch: 32.9 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03282836173387433		[learning rate: 0.011426]
	Learning Rate: 0.0114256
	LOSS [training: 0.03282836173387433 | validation: 0.01884782249729554]
	TIME [epoch: 32.9 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021530020288905972		[learning rate: 0.011409]
	Learning Rate: 0.0114092
	LOSS [training: 0.021530020288905972 | validation: 0.06559477952113554]
	TIME [epoch: 32.9 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049027919889958256		[learning rate: 0.011393]
	Learning Rate: 0.0113929
	LOSS [training: 0.049027919889958256 | validation: 0.03289895702981711]
	TIME [epoch: 32.9 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036878019451078485		[learning rate: 0.011376]
	Learning Rate: 0.0113765
	LOSS [training: 0.036878019451078485 | validation: 0.01655508341431043]
	TIME [epoch: 32.9 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045373940129696255		[learning rate: 0.01136]
	Learning Rate: 0.0113601
	LOSS [training: 0.045373940129696255 | validation: 0.017356304523484533]
	TIME [epoch: 32.9 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01738090796325566		[learning rate: 0.011344]
	Learning Rate: 0.0113437
	LOSS [training: 0.01738090796325566 | validation: 0.01378787238558694]
	TIME [epoch: 32.9 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021559876653098217		[learning rate: 0.011327]
	Learning Rate: 0.0113274
	LOSS [training: 0.021559876653098217 | validation: 0.019260519442800418]
	TIME [epoch: 33 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036631610322930955		[learning rate: 0.011311]
	Learning Rate: 0.011311
	LOSS [training: 0.036631610322930955 | validation: 0.0166185618744344]
	TIME [epoch: 32.9 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09881830583796579		[learning rate: 0.011295]
	Learning Rate: 0.0112946
	LOSS [training: 0.09881830583796579 | validation: 0.062053736652387795]
	TIME [epoch: 32.9 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07699011542751319		[learning rate: 0.011278]
	Learning Rate: 0.0112782
	LOSS [training: 0.07699011542751319 | validation: 0.040652003236761866]
	TIME [epoch: 32.9 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05553254753522166		[learning rate: 0.011262]
	Learning Rate: 0.0112618
	LOSS [training: 0.05553254753522166 | validation: 0.028983960037331308]
	TIME [epoch: 32.9 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032878559559622995		[learning rate: 0.011245]
	Learning Rate: 0.0112454
	LOSS [training: 0.032878559559622995 | validation: 0.025757832117386168]
	TIME [epoch: 32.9 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03430636493907774		[learning rate: 0.011229]
	Learning Rate: 0.011229
	LOSS [training: 0.03430636493907774 | validation: 0.07433473267706936]
	TIME [epoch: 32.9 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06557948118730675		[learning rate: 0.011213]
	Learning Rate: 0.0112126
	LOSS [training: 0.06557948118730675 | validation: 0.018830800885915492]
	TIME [epoch: 32.9 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02443801473910882		[learning rate: 0.011196]
	Learning Rate: 0.0111962
	LOSS [training: 0.02443801473910882 | validation: 0.016485381581945284]
	TIME [epoch: 32.9 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056511242037021105		[learning rate: 0.01118]
	Learning Rate: 0.0111798
	LOSS [training: 0.056511242037021105 | validation: 0.025245278155927933]
	TIME [epoch: 33 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03438540505880824		[learning rate: 0.011163]
	Learning Rate: 0.0111634
	LOSS [training: 0.03438540505880824 | validation: 0.015445110460265442]
	TIME [epoch: 33 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09077624243033339		[learning rate: 0.011147]
	Learning Rate: 0.011147
	LOSS [training: 0.09077624243033339 | validation: 0.027090866427876475]
	TIME [epoch: 33.1 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034259586086745		[learning rate: 0.011131]
	Learning Rate: 0.0111305
	LOSS [training: 0.034259586086745 | validation: 0.018252183346836023]
	TIME [epoch: 33.1 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02219790326100208		[learning rate: 0.011114]
	Learning Rate: 0.0111141
	LOSS [training: 0.02219790326100208 | validation: 0.02456390889099104]
	TIME [epoch: 33.1 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02767527827913901		[learning rate: 0.011098]
	Learning Rate: 0.0110977
	LOSS [training: 0.02767527827913901 | validation: 0.022125918767741476]
	TIME [epoch: 33 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020557934651336845		[learning rate: 0.011081]
	Learning Rate: 0.0110813
	LOSS [training: 0.020557934651336845 | validation: 0.018457047598638844]
	TIME [epoch: 33 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03215536254077479		[learning rate: 0.011065]
	Learning Rate: 0.0110648
	LOSS [training: 0.03215536254077479 | validation: 0.029171016091220532]
	TIME [epoch: 33.1 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07309916646578776		[learning rate: 0.011048]
	Learning Rate: 0.0110484
	LOSS [training: 0.07309916646578776 | validation: 0.010484234914189098]
	TIME [epoch: 33.1 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_937.pth
	Model improved!!!
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014836246409458005		[learning rate: 0.011032]
	Learning Rate: 0.011032
	LOSS [training: 0.014836246409458005 | validation: 0.01575637020047946]
	TIME [epoch: 33 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019469645071668203		[learning rate: 0.011016]
	Learning Rate: 0.0110155
	LOSS [training: 0.019469645071668203 | validation: 0.0246632055972469]
	TIME [epoch: 33 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0924636698248866		[learning rate: 0.010999]
	Learning Rate: 0.0109991
	LOSS [training: 0.0924636698248866 | validation: 0.1465619707747135]
	TIME [epoch: 33 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17640197440254082		[learning rate: 0.010983]
	Learning Rate: 0.0109826
	LOSS [training: 0.17640197440254082 | validation: 0.02277032097956251]
	TIME [epoch: 33 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023313275964529822		[learning rate: 0.010966]
	Learning Rate: 0.0109662
	LOSS [training: 0.023313275964529822 | validation: 0.01755404040605993]
	TIME [epoch: 33 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04773520351430467		[learning rate: 0.01095]
	Learning Rate: 0.0109497
	LOSS [training: 0.04773520351430467 | validation: 0.01737775979188954]
	TIME [epoch: 33 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019086250009326948		[learning rate: 0.010933]
	Learning Rate: 0.0109333
	LOSS [training: 0.019086250009326948 | validation: 0.01682020949446835]
	TIME [epoch: 33 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015916846051995948		[learning rate: 0.010917]
	Learning Rate: 0.0109168
	LOSS [training: 0.015916846051995948 | validation: 0.04218463223541]
	TIME [epoch: 33.1 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020799285546456242		[learning rate: 0.0109]
	Learning Rate: 0.0109004
	LOSS [training: 0.020799285546456242 | validation: 0.00824257256873974]
	TIME [epoch: 33 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_946.pth
	Model improved!!!
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009577428842807784		[learning rate: 0.010884]
	Learning Rate: 0.0108839
	LOSS [training: 0.009577428842807784 | validation: 0.009560270034858775]
	TIME [epoch: 33 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026520430727615476		[learning rate: 0.010867]
	Learning Rate: 0.0108674
	LOSS [training: 0.026520430727615476 | validation: 0.0175786459887095]
	TIME [epoch: 33 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017639336693011553		[learning rate: 0.010851]
	Learning Rate: 0.010851
	LOSS [training: 0.017639336693011553 | validation: 0.011325200772081406]
	TIME [epoch: 33 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013673888263214761		[learning rate: 0.010834]
	Learning Rate: 0.0108345
	LOSS [training: 0.013673888263214761 | validation: 0.012602191019953895]
	TIME [epoch: 33 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027913360018434787		[learning rate: 0.010818]
	Learning Rate: 0.010818
	LOSS [training: 0.027913360018434787 | validation: 0.03250104791943016]
	TIME [epoch: 33 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021442027835667413		[learning rate: 0.010802]
	Learning Rate: 0.0108016
	LOSS [training: 0.021442027835667413 | validation: 0.19733969673902244]
	TIME [epoch: 33 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08987523894438734		[learning rate: 0.010785]
	Learning Rate: 0.0107851
	LOSS [training: 0.08987523894438734 | validation: 0.022963793543517626]
	TIME [epoch: 33 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029739978475682206		[learning rate: 0.010769]
	Learning Rate: 0.0107686
	LOSS [training: 0.029739978475682206 | validation: 0.011062040193689815]
	TIME [epoch: 33 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017793276256753553		[learning rate: 0.010752]
	Learning Rate: 0.0107521
	LOSS [training: 0.017793276256753553 | validation: 0.12439674908093053]
	TIME [epoch: 33 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2719880399277182		[learning rate: 0.010736]
	Learning Rate: 0.0107356
	LOSS [training: 0.2719880399277182 | validation: 0.12990705976730169]
	TIME [epoch: 33 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0920630667804826		[learning rate: 0.010719]
	Learning Rate: 0.0107192
	LOSS [training: 0.0920630667804826 | validation: 0.020603064350960404]
	TIME [epoch: 33 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06688265252559764		[learning rate: 0.010703]
	Learning Rate: 0.0107027
	LOSS [training: 0.06688265252559764 | validation: 0.14174032038177742]
	TIME [epoch: 33 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10146548418520462		[learning rate: 0.010686]
	Learning Rate: 0.0106862
	LOSS [training: 0.10146548418520462 | validation: 0.014719292590914609]
	TIME [epoch: 33 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07591839864524323		[learning rate: 0.01067]
	Learning Rate: 0.0106697
	LOSS [training: 0.07591839864524323 | validation: 0.034451073002198684]
	TIME [epoch: 33 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07276149800141182		[learning rate: 0.010653]
	Learning Rate: 0.0106532
	LOSS [training: 0.07276149800141182 | validation: 0.02092987815340397]
	TIME [epoch: 33 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0415047738752282		[learning rate: 0.010637]
	Learning Rate: 0.0106367
	LOSS [training: 0.0415047738752282 | validation: 0.06637386123667152]
	TIME [epoch: 33 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06802718312224987		[learning rate: 0.01062]
	Learning Rate: 0.0106202
	LOSS [training: 0.06802718312224987 | validation: 0.031003270645868428]
	TIME [epoch: 33 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038693168871755834		[learning rate: 0.010604]
	Learning Rate: 0.0106037
	LOSS [training: 0.038693168871755834 | validation: 0.017366384932616722]
	TIME [epoch: 33 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02834080515928078		[learning rate: 0.010587]
	Learning Rate: 0.0105872
	LOSS [training: 0.02834080515928078 | validation: 0.014851925471652646]
	TIME [epoch: 33 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021193167734724655		[learning rate: 0.010571]
	Learning Rate: 0.0105707
	LOSS [training: 0.021193167734724655 | validation: 0.02193768755144157]
	TIME [epoch: 33 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03789133881260014		[learning rate: 0.010554]
	Learning Rate: 0.0105542
	LOSS [training: 0.03789133881260014 | validation: 0.013758821386138605]
	TIME [epoch: 33 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02223055764806635		[learning rate: 0.010538]
	Learning Rate: 0.0105377
	LOSS [training: 0.02223055764806635 | validation: 0.14421862964171522]
	TIME [epoch: 33 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06611755944508355		[learning rate: 0.010521]
	Learning Rate: 0.0105212
	LOSS [training: 0.06611755944508355 | validation: 0.012834265767924763]
	TIME [epoch: 33 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03594347791418977		[learning rate: 0.010505]
	Learning Rate: 0.0105047
	LOSS [training: 0.03594347791418977 | validation: 0.012282389101533696]
	TIME [epoch: 33 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051419501377294834		[learning rate: 0.010488]
	Learning Rate: 0.0104882
	LOSS [training: 0.051419501377294834 | validation: 0.01495543109266858]
	TIME [epoch: 33 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020860198430348975		[learning rate: 0.010472]
	Learning Rate: 0.0104717
	LOSS [training: 0.020860198430348975 | validation: 0.012967515819667923]
	TIME [epoch: 33 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01752997432039647		[learning rate: 0.010455]
	Learning Rate: 0.0104552
	LOSS [training: 0.01752997432039647 | validation: 0.020754972849924537]
	TIME [epoch: 33 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049646990684175635		[learning rate: 0.010439]
	Learning Rate: 0.0104387
	LOSS [training: 0.049646990684175635 | validation: 0.03909057963721926]
	TIME [epoch: 33 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07722219879650867		[learning rate: 0.010422]
	Learning Rate: 0.0104222
	LOSS [training: 0.07722219879650867 | validation: 0.14771996961248718]
	TIME [epoch: 33 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0710949518959652		[learning rate: 0.010406]
	Learning Rate: 0.0104057
	LOSS [training: 0.0710949518959652 | validation: 0.012473635956823069]
	TIME [epoch: 33 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028609306891602147		[learning rate: 0.010389]
	Learning Rate: 0.0103891
	LOSS [training: 0.028609306891602147 | validation: 0.02510620367508319]
	TIME [epoch: 33 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044500723399433284		[learning rate: 0.010373]
	Learning Rate: 0.0103726
	LOSS [training: 0.044500723399433284 | validation: 0.028331301837196565]
	TIME [epoch: 33 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0639984060008055		[learning rate: 0.010356]
	Learning Rate: 0.0103561
	LOSS [training: 0.0639984060008055 | validation: 0.17739577394454326]
	TIME [epoch: 33 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060020524658469764		[learning rate: 0.01034]
	Learning Rate: 0.0103396
	LOSS [training: 0.060020524658469764 | validation: 0.010663678953394266]
	TIME [epoch: 33 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03164480618370126		[learning rate: 0.010323]
	Learning Rate: 0.0103231
	LOSS [training: 0.03164480618370126 | validation: 0.07100912198781673]
	TIME [epoch: 33 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09974066613094733		[learning rate: 0.010307]
	Learning Rate: 0.0103066
	LOSS [training: 0.09974066613094733 | validation: 0.013029372059312596]
	TIME [epoch: 33.1 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016921130810191767		[learning rate: 0.01029]
	Learning Rate: 0.01029
	LOSS [training: 0.016921130810191767 | validation: 0.01264928000703454]
	TIME [epoch: 33 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016564228245598354		[learning rate: 0.010274]
	Learning Rate: 0.0102735
	LOSS [training: 0.016564228245598354 | validation: 0.014884350234993161]
	TIME [epoch: 33 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014915709220442532		[learning rate: 0.010257]
	Learning Rate: 0.010257
	LOSS [training: 0.014915709220442532 | validation: 0.008873542995277726]
	TIME [epoch: 33 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013821880925887847		[learning rate: 0.01024]
	Learning Rate: 0.0102405
	LOSS [training: 0.013821880925887847 | validation: 0.09046586496338344]
	TIME [epoch: 33 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03903499597031085		[learning rate: 0.010224]
	Learning Rate: 0.010224
	LOSS [training: 0.03903499597031085 | validation: 0.012741356494160468]
	TIME [epoch: 33 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015588791164027897		[learning rate: 0.010207]
	Learning Rate: 0.0102074
	LOSS [training: 0.015588791164027897 | validation: 0.013021127189107548]
	TIME [epoch: 33 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013345328089960808		[learning rate: 0.010191]
	Learning Rate: 0.0101909
	LOSS [training: 0.013345328089960808 | validation: 0.029411163244985765]
	TIME [epoch: 33 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029954773802943837		[learning rate: 0.010174]
	Learning Rate: 0.0101744
	LOSS [training: 0.029954773802943837 | validation: 0.04586671074396324]
	TIME [epoch: 33 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02774455380267597		[learning rate: 0.010158]
	Learning Rate: 0.0101579
	LOSS [training: 0.02774455380267597 | validation: 0.02175999077014206]
	TIME [epoch: 33 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02047894654424369		[learning rate: 0.010141]
	Learning Rate: 0.0101413
	LOSS [training: 0.02047894654424369 | validation: 0.06583661526336301]
	TIME [epoch: 33 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07230407295076713		[learning rate: 0.010125]
	Learning Rate: 0.0101248
	LOSS [training: 0.07230407295076713 | validation: 0.10908933956616419]
	TIME [epoch: 33 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044286766580797304		[learning rate: 0.010108]
	Learning Rate: 0.0101083
	LOSS [training: 0.044286766580797304 | validation: 0.013129171381505905]
	TIME [epoch: 33 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019039130054233293		[learning rate: 0.010092]
	Learning Rate: 0.0100918
	LOSS [training: 0.019039130054233293 | validation: 0.009467757162067693]
	TIME [epoch: 33 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025141913987110416		[learning rate: 0.010075]
	Learning Rate: 0.0100752
	LOSS [training: 0.025141913987110416 | validation: 0.009417547941618958]
	TIME [epoch: 33 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044727573548275015		[learning rate: 0.010059]
	Learning Rate: 0.0100587
	LOSS [training: 0.044727573548275015 | validation: 0.015080968982151274]
	TIME [epoch: 33 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01660276203950834		[learning rate: 0.010042]
	Learning Rate: 0.0100422
	LOSS [training: 0.01660276203950834 | validation: 0.012464521318392714]
	TIME [epoch: 33 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16390134216073465		[learning rate: 0.010026]
	Learning Rate: 0.0100257
	LOSS [training: 0.16390134216073465 | validation: 0.05246641102908946]
	TIME [epoch: 33 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03054040313704493		[learning rate: 0.010009]
	Learning Rate: 0.0100091
	LOSS [training: 0.03054040313704493 | validation: 0.014243330225665055]
	TIME [epoch: 33 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0442969885480511		[learning rate: 0.0099926]
	Learning Rate: 0.00999261
	LOSS [training: 0.0442969885480511 | validation: 0.020983894179361955]
	TIME [epoch: 177 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013869730287857818		[learning rate: 0.0099761]
	Learning Rate: 0.00997608
	LOSS [training: 0.013869730287857818 | validation: 0.008537967357174752]
	TIME [epoch: 70.2 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011791824372159383		[learning rate: 0.0099596]
	Learning Rate: 0.00995955
	LOSS [training: 0.011791824372159383 | validation: 0.009626310134765344]
	TIME [epoch: 70.4 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012564718495199946		[learning rate: 0.009943]
	Learning Rate: 0.00994303
	LOSS [training: 0.012564718495199946 | validation: 0.015624671349842285]
	TIME [epoch: 70.4 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01971760337854875		[learning rate: 0.0099265]
	Learning Rate: 0.0099265
	LOSS [training: 0.01971760337854875 | validation: 0.01359026714107471]
	TIME [epoch: 70.4 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013346388219055424		[learning rate: 0.00991]
	Learning Rate: 0.00990997
	LOSS [training: 0.013346388219055424 | validation: 0.012727851596049911]
	TIME [epoch: 70.5 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042753914094837975		[learning rate: 0.0098934]
	Learning Rate: 0.00989345
	LOSS [training: 0.042753914094837975 | validation: 0.015252354198154086]
	TIME [epoch: 70.5 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021137223530792563		[learning rate: 0.0098769]
	Learning Rate: 0.00987692
	LOSS [training: 0.021137223530792563 | validation: 0.014524075911344404]
	TIME [epoch: 70.5 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014319159088131935		[learning rate: 0.0098604]
	Learning Rate: 0.0098604
	LOSS [training: 0.014319159088131935 | validation: 0.014394060517389605]
	TIME [epoch: 70.5 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01855802626873017		[learning rate: 0.0098439]
	Learning Rate: 0.00984387
	LOSS [training: 0.01855802626873017 | validation: 0.11435784775098748]
	TIME [epoch: 70.5 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047299538786027336		[learning rate: 0.0098274]
	Learning Rate: 0.00982735
	LOSS [training: 0.047299538786027336 | validation: 0.010305335646055434]
	TIME [epoch: 70.5 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01187449161837351		[learning rate: 0.0098108]
	Learning Rate: 0.00981083
	LOSS [training: 0.01187449161837351 | validation: 0.010887312718424871]
	TIME [epoch: 70.5 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013782893074208605		[learning rate: 0.0097943]
	Learning Rate: 0.0097943
	LOSS [training: 0.013782893074208605 | validation: 0.012865930447839864]
	TIME [epoch: 70.5 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01776189749657607		[learning rate: 0.0097778]
	Learning Rate: 0.00977778
	LOSS [training: 0.01776189749657607 | validation: 0.022328123814667984]
	TIME [epoch: 70.5 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027684729889099736		[learning rate: 0.0097613]
	Learning Rate: 0.00976126
	LOSS [training: 0.027684729889099736 | validation: 0.03995731618353278]
	TIME [epoch: 70.5 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033653798587779296		[learning rate: 0.0097447]
	Learning Rate: 0.00974474
	LOSS [training: 0.033653798587779296 | validation: 0.009984072248549216]
	TIME [epoch: 70.5 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042669435069958725		[learning rate: 0.0097282]
	Learning Rate: 0.00972822
	LOSS [training: 0.042669435069958725 | validation: 0.19410429852508354]
	TIME [epoch: 70.1 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12553676525749155		[learning rate: 0.0097117]
	Learning Rate: 0.0097117
	LOSS [training: 0.12553676525749155 | validation: 0.03182729414019646]
	TIME [epoch: 70.2 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030976593179518775		[learning rate: 0.0096952]
	Learning Rate: 0.00969518
	LOSS [training: 0.030976593179518775 | validation: 0.019829835177814743]
	TIME [epoch: 70.2 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13277638187199567		[learning rate: 0.0096787]
	Learning Rate: 0.00967866
	LOSS [training: 0.13277638187199567 | validation: 0.04658862329544184]
	TIME [epoch: 70.2 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027027468569709903		[learning rate: 0.0096621]
	Learning Rate: 0.00966214
	LOSS [training: 0.027027468569709903 | validation: 0.011191306548062604]
	TIME [epoch: 70.2 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014581412134521993		[learning rate: 0.0096456]
	Learning Rate: 0.00964563
	LOSS [training: 0.014581412134521993 | validation: 0.011532335732776913]
	TIME [epoch: 70.2 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01299606772132852		[learning rate: 0.0096291]
	Learning Rate: 0.00962911
	LOSS [training: 0.01299606772132852 | validation: 0.011659730295233038]
	TIME [epoch: 70.4 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03572430141534748		[learning rate: 0.0096126]
	Learning Rate: 0.0096126
	LOSS [training: 0.03572430141534748 | validation: 0.014374261628679386]
	TIME [epoch: 70.2 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01574781623958175		[learning rate: 0.0095961]
	Learning Rate: 0.00959609
	LOSS [training: 0.01574781623958175 | validation: 0.011586716133118178]
	TIME [epoch: 70.1 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014338487913451155		[learning rate: 0.0095796]
	Learning Rate: 0.00957957
	LOSS [training: 0.014338487913451155 | validation: 0.017616916577873273]
	TIME [epoch: 70.1 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017293799496774107		[learning rate: 0.0095631]
	Learning Rate: 0.00956306
	LOSS [training: 0.017293799496774107 | validation: 0.013119673443363665]
	TIME [epoch: 70.5 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08249234104117997		[learning rate: 0.0095466]
	Learning Rate: 0.00954655
	LOSS [training: 0.08249234104117997 | validation: 0.017394036675611717]
	TIME [epoch: 70.4 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030892352482569444		[learning rate: 0.00953]
	Learning Rate: 0.00953004
	LOSS [training: 0.030892352482569444 | validation: 0.02440592210952414]
	TIME [epoch: 70.4 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020314943237575364		[learning rate: 0.0095135]
	Learning Rate: 0.00951354
	LOSS [training: 0.020314943237575364 | validation: 0.010816508387676024]
	TIME [epoch: 70.3 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014450963842131964		[learning rate: 0.009497]
	Learning Rate: 0.00949703
	LOSS [training: 0.014450963842131964 | validation: 0.01057183180062911]
	TIME [epoch: 70.1 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11903087417776521		[learning rate: 0.0094805]
	Learning Rate: 0.00948053
	LOSS [training: 0.11903087417776521 | validation: 0.022058858123874293]
	TIME [epoch: 70.2 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013430879184462152		[learning rate: 0.009464]
	Learning Rate: 0.00946402
	LOSS [training: 0.013430879184462152 | validation: 0.007308822245966812]
	TIME [epoch: 70.2 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_1033.pth
	Model improved!!!
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027526054709322893		[learning rate: 0.0094475]
	Learning Rate: 0.00944752
	LOSS [training: 0.027526054709322893 | validation: 0.006339917596957804]
	TIME [epoch: 70.1 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_1034.pth
	Model improved!!!
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008186802315576391		[learning rate: 0.009431]
	Learning Rate: 0.00943102
	LOSS [training: 0.008186802315576391 | validation: 0.004428140679690509]
	TIME [epoch: 70.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_1035.pth
	Model improved!!!
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01311828606678318		[learning rate: 0.0094145]
	Learning Rate: 0.00941452
	LOSS [training: 0.01311828606678318 | validation: 0.009966300955622153]
	TIME [epoch: 70.6 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008869022079570882		[learning rate: 0.009398]
	Learning Rate: 0.00939803
	LOSS [training: 0.008869022079570882 | validation: 0.04732473445706258]
	TIME [epoch: 70.6 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09237331305853826		[learning rate: 0.0093815]
	Learning Rate: 0.00938153
	LOSS [training: 0.09237331305853826 | validation: 0.13855966263736383]
	TIME [epoch: 70.5 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19351692107469115		[learning rate: 0.009365]
	Learning Rate: 0.00936504
	LOSS [training: 0.19351692107469115 | validation: 0.01796725350923114]
	TIME [epoch: 70.6 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021581741153098553		[learning rate: 0.0093485]
	Learning Rate: 0.00934855
	LOSS [training: 0.021581741153098553 | validation: 0.010626989997781843]
	TIME [epoch: 70.6 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0196321261704782		[learning rate: 0.0093321]
	Learning Rate: 0.00933206
	LOSS [training: 0.0196321261704782 | validation: 0.012747297916719955]
	TIME [epoch: 70.5 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010778801151129776		[learning rate: 0.0093156]
	Learning Rate: 0.00931557
	LOSS [training: 0.010778801151129776 | validation: 0.011624712423012799]
	TIME [epoch: 70.5 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019871530394642872		[learning rate: 0.0092991]
	Learning Rate: 0.00929908
	LOSS [training: 0.019871530394642872 | validation: 0.007449755869802229]
	TIME [epoch: 70.5 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01438504932518431		[learning rate: 0.0092826]
	Learning Rate: 0.0092826
	LOSS [training: 0.01438504932518431 | validation: 0.012465460654011962]
	TIME [epoch: 70.5 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029397743404057056		[learning rate: 0.0092661]
	Learning Rate: 0.00926612
	LOSS [training: 0.029397743404057056 | validation: 0.01690797005373018]
	TIME [epoch: 70.5 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04258841161418418		[learning rate: 0.0092496]
	Learning Rate: 0.00924964
	LOSS [training: 0.04258841161418418 | validation: 0.07888012231308802]
	TIME [epoch: 70.5 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07989454087688788		[learning rate: 0.0092332]
	Learning Rate: 0.00923316
	LOSS [training: 0.07989454087688788 | validation: 0.025938147041852308]
	TIME [epoch: 70.5 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057487439166384297		[learning rate: 0.0092167]
	Learning Rate: 0.00921668
	LOSS [training: 0.057487439166384297 | validation: 0.04405946931564973]
	TIME [epoch: 70.5 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07967270149817651		[learning rate: 0.0092002]
	Learning Rate: 0.00920021
	LOSS [training: 0.07967270149817651 | validation: 0.044037202561554696]
	TIME [epoch: 70.5 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027322309150478886		[learning rate: 0.0091837]
	Learning Rate: 0.00918374
	LOSS [training: 0.027322309150478886 | validation: 0.008797412787417183]
	TIME [epoch: 70.5 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011364615570842703		[learning rate: 0.0091673]
	Learning Rate: 0.00916727
	LOSS [training: 0.011364615570842703 | validation: 0.004972509701878509]
	TIME [epoch: 70.6 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018252485622311892		[learning rate: 0.0091508]
	Learning Rate: 0.0091508
	LOSS [training: 0.018252485622311892 | validation: 0.21428187352100667]
	TIME [epoch: 70.6 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13921252750153704		[learning rate: 0.0091343]
	Learning Rate: 0.00913434
	LOSS [training: 0.13921252750153704 | validation: 0.029097276209519258]
	TIME [epoch: 70.6 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028277915111447248		[learning rate: 0.0091179]
	Learning Rate: 0.00911787
	LOSS [training: 0.028277915111447248 | validation: 0.0164632657561567]
	TIME [epoch: 70.6 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020232371579189015		[learning rate: 0.0091014]
	Learning Rate: 0.00910141
	LOSS [training: 0.020232371579189015 | validation: 0.09799446318586066]
	TIME [epoch: 70.5 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06208783800598289		[learning rate: 0.009085]
	Learning Rate: 0.00908496
	LOSS [training: 0.06208783800598289 | validation: 0.012221594128304222]
	TIME [epoch: 70.6 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020990106331296797		[learning rate: 0.0090685]
	Learning Rate: 0.0090685
	LOSS [training: 0.020990106331296797 | validation: 0.012739134471256783]
	TIME [epoch: 70.6 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012861633414924207		[learning rate: 0.009052]
	Learning Rate: 0.00905205
	LOSS [training: 0.012861633414924207 | validation: 0.009487432378984764]
	TIME [epoch: 70.5 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012261494519477707		[learning rate: 0.0090356]
	Learning Rate: 0.0090356
	LOSS [training: 0.012261494519477707 | validation: 0.010384611068987411]
	TIME [epoch: 70.6 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035211282721831674		[learning rate: 0.0090192]
	Learning Rate: 0.00901915
	LOSS [training: 0.035211282721831674 | validation: 0.03348782356353644]
	TIME [epoch: 70.7 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10853090267852533		[learning rate: 0.0090027]
	Learning Rate: 0.00900271
	LOSS [training: 0.10853090267852533 | validation: 0.0812675840755498]
	TIME [epoch: 70.5 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04391228856338901		[learning rate: 0.0089863]
	Learning Rate: 0.00898627
	LOSS [training: 0.04391228856338901 | validation: 0.010563097447446986]
	TIME [epoch: 70.5 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00907208273517843		[learning rate: 0.0089698]
	Learning Rate: 0.00896983
	LOSS [training: 0.00907208273517843 | validation: 0.006520365298426867]
	TIME [epoch: 70.6 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005479910930440491		[learning rate: 0.0089534]
	Learning Rate: 0.00895339
	LOSS [training: 0.005479910930440491 | validation: 0.0059744437770285486]
	TIME [epoch: 70.5 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04908304672245162		[learning rate: 0.008937]
	Learning Rate: 0.00893696
	LOSS [training: 0.04908304672245162 | validation: 0.017275377529214507]
	TIME [epoch: 70.6 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0220148302919426		[learning rate: 0.0089205]
	Learning Rate: 0.00892053
	LOSS [training: 0.0220148302919426 | validation: 0.01315560367876024]
	TIME [epoch: 70.7 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01666913966523247		[learning rate: 0.0089041]
	Learning Rate: 0.0089041
	LOSS [training: 0.01666913966523247 | validation: 0.011899298593214085]
	TIME [epoch: 70.6 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014213516330506094		[learning rate: 0.0088877]
	Learning Rate: 0.00888767
	LOSS [training: 0.014213516330506094 | validation: 0.01714194670157124]
	TIME [epoch: 70.6 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0167200492742124		[learning rate: 0.0088713]
	Learning Rate: 0.00887125
	LOSS [training: 0.0167200492742124 | validation: 0.006305464569549531]
	TIME [epoch: 70.7 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009203862767389884		[learning rate: 0.0088548]
	Learning Rate: 0.00885484
	LOSS [training: 0.009203862767389884 | validation: 0.010459658382606441]
	TIME [epoch: 70.5 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03795307061400781		[learning rate: 0.0088384]
	Learning Rate: 0.00883842
	LOSS [training: 0.03795307061400781 | validation: 0.006040207067812899]
	TIME [epoch: 70.6 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007163538736485832		[learning rate: 0.008822]
	Learning Rate: 0.00882201
	LOSS [training: 0.007163538736485832 | validation: 0.00702153736309147]
	TIME [epoch: 70.6 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02413029220088876		[learning rate: 0.0088056]
	Learning Rate: 0.0088056
	LOSS [training: 0.02413029220088876 | validation: 0.02063956997491935]
	TIME [epoch: 70.6 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025200216724853175		[learning rate: 0.0087892]
	Learning Rate: 0.00878919
	LOSS [training: 0.025200216724853175 | validation: 0.011561969582699297]
	TIME [epoch: 70.7 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012982596882411171		[learning rate: 0.0087728]
	Learning Rate: 0.00877279
	LOSS [training: 0.012982596882411171 | validation: 0.012949990048313775]
	TIME [epoch: 70.7 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013851943970497183		[learning rate: 0.0087564]
	Learning Rate: 0.00875639
	LOSS [training: 0.013851943970497183 | validation: 0.01041165273436313]
	TIME [epoch: 70.6 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021064756910796067		[learning rate: 0.00874]
	Learning Rate: 0.00874
	LOSS [training: 0.021064756910796067 | validation: 0.04168476153694819]
	TIME [epoch: 70.5 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029169323080058023		[learning rate: 0.0087236]
	Learning Rate: 0.00872361
	LOSS [training: 0.029169323080058023 | validation: 0.019534507899969935]
	TIME [epoch: 70.6 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01959310846083878		[learning rate: 0.0087072]
	Learning Rate: 0.00870722
	LOSS [training: 0.01959310846083878 | validation: 0.012791144427904109]
	TIME [epoch: 70.4 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05087593311903939		[learning rate: 0.0086908]
	Learning Rate: 0.00869083
	LOSS [training: 0.05087593311903939 | validation: 0.010506931901630663]
	TIME [epoch: 70.7 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010688108964553175		[learning rate: 0.0086745]
	Learning Rate: 0.00867445
	LOSS [training: 0.010688108964553175 | validation: 0.006611391499654657]
	TIME [epoch: 70.4 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010769523171231855		[learning rate: 0.0086581]
	Learning Rate: 0.00865807
	LOSS [training: 0.010769523171231855 | validation: 0.012465706138488372]
	TIME [epoch: 70.7 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0403989180537238		[learning rate: 0.0086417]
	Learning Rate: 0.0086417
	LOSS [training: 0.0403989180537238 | validation: 0.024430515894383123]
	TIME [epoch: 70.5 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018619424572263905		[learning rate: 0.0086253]
	Learning Rate: 0.00862533
	LOSS [training: 0.018619424572263905 | validation: 0.009893958212023367]
	TIME [epoch: 70.7 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008527825557306355		[learning rate: 0.008609]
	Learning Rate: 0.00860896
	LOSS [training: 0.008527825557306355 | validation: 0.0055011711349243755]
	TIME [epoch: 70.6 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02503840647450168		[learning rate: 0.0085926]
	Learning Rate: 0.0085926
	LOSS [training: 0.02503840647450168 | validation: 0.056689430255596654]
	TIME [epoch: 70.6 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03184224047511122		[learning rate: 0.0085762]
	Learning Rate: 0.00857624
	LOSS [training: 0.03184224047511122 | validation: 0.012995283195510302]
	TIME [epoch: 70.7 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020400749558034458		[learning rate: 0.0085599]
	Learning Rate: 0.00855989
	LOSS [training: 0.020400749558034458 | validation: 0.1033258232116317]
	TIME [epoch: 70.7 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05801909713322491		[learning rate: 0.0085435]
	Learning Rate: 0.00854354
	LOSS [training: 0.05801909713322491 | validation: 0.019076295844865594]
	TIME [epoch: 70.7 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020828070660302615		[learning rate: 0.0085272]
	Learning Rate: 0.00852719
	LOSS [training: 0.020828070660302615 | validation: 0.013759691486131716]
	TIME [epoch: 70.7 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027209357395588454		[learning rate: 0.0085108]
	Learning Rate: 0.00851085
	LOSS [training: 0.027209357395588454 | validation: 0.02842460179453163]
	TIME [epoch: 70.7 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017271616701743885		[learning rate: 0.0084945]
	Learning Rate: 0.00849451
	LOSS [training: 0.017271616701743885 | validation: 0.00753242275181098]
	TIME [epoch: 70.6 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010910090730676732		[learning rate: 0.0084782]
	Learning Rate: 0.00847817
	LOSS [training: 0.010910090730676732 | validation: 0.016510384379299373]
	TIME [epoch: 70.6 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012059379761922843		[learning rate: 0.0084618]
	Learning Rate: 0.00846184
	LOSS [training: 0.012059379761922843 | validation: 0.0066056051847601365]
	TIME [epoch: 70.6 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010255907453246213		[learning rate: 0.0084455]
	Learning Rate: 0.00844552
	LOSS [training: 0.010255907453246213 | validation: 0.012242410418506182]
	TIME [epoch: 70.6 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08395254624611469		[learning rate: 0.0084292]
	Learning Rate: 0.0084292
	LOSS [training: 0.08395254624611469 | validation: 0.044496799064480605]
	TIME [epoch: 70.5 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05642561921577691		[learning rate: 0.0084129]
	Learning Rate: 0.00841288
	LOSS [training: 0.05642561921577691 | validation: 0.01366623144297002]
	TIME [epoch: 70.6 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012773636245825287		[learning rate: 0.0083966]
	Learning Rate: 0.00839657
	LOSS [training: 0.012773636245825287 | validation: 0.017653446002549023]
	TIME [epoch: 70.6 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013310040190556297		[learning rate: 0.0083803]
	Learning Rate: 0.00838026
	LOSS [training: 0.013310040190556297 | validation: 0.00617402751846457]
	TIME [epoch: 70.6 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008110165896129425		[learning rate: 0.008364]
	Learning Rate: 0.00836395
	LOSS [training: 0.008110165896129425 | validation: 0.00628511277943537]
	TIME [epoch: 70.5 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021913445067653227		[learning rate: 0.0083477]
	Learning Rate: 0.00834765
	LOSS [training: 0.021913445067653227 | validation: 0.02980484431331507]
	TIME [epoch: 70.5 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023268572241652494		[learning rate: 0.0083314]
	Learning Rate: 0.00833136
	LOSS [training: 0.023268572241652494 | validation: 0.1022470331626389]
	TIME [epoch: 70.6 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09712631919890048		[learning rate: 0.0083151]
	Learning Rate: 0.00831507
	LOSS [training: 0.09712631919890048 | validation: 0.08545288296941167]
	TIME [epoch: 70.6 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05030368823399667		[learning rate: 0.0082988]
	Learning Rate: 0.00829878
	LOSS [training: 0.05030368823399667 | validation: 0.03976330145846253]
	TIME [epoch: 70.6 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03738164225271474		[learning rate: 0.0082825]
	Learning Rate: 0.0082825
	LOSS [training: 0.03738164225271474 | validation: 0.011857056234940485]
	TIME [epoch: 70.6 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013821946525936367		[learning rate: 0.0082662]
	Learning Rate: 0.00826622
	LOSS [training: 0.013821946525936367 | validation: 0.013707930886528174]
	TIME [epoch: 70.7 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020214544828226766		[learning rate: 0.0082499]
	Learning Rate: 0.00824995
	LOSS [training: 0.020214544828226766 | validation: 0.011074055020395202]
	TIME [epoch: 70.7 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012741495681305358		[learning rate: 0.0082337]
	Learning Rate: 0.00823368
	LOSS [training: 0.012741495681305358 | validation: 0.011419751116496006]
	TIME [epoch: 70.6 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013707183676443642		[learning rate: 0.0082174]
	Learning Rate: 0.00821742
	LOSS [training: 0.013707183676443642 | validation: 0.01658390590771504]
	TIME [epoch: 70.6 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014152676212223329		[learning rate: 0.0082012]
	Learning Rate: 0.00820116
	LOSS [training: 0.014152676212223329 | validation: 0.013079623408172336]
	TIME [epoch: 70.6 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017160266719295117		[learning rate: 0.0081849]
	Learning Rate: 0.00818491
	LOSS [training: 0.017160266719295117 | validation: 0.029647702796838045]
	TIME [epoch: 70.6 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03127720241307855		[learning rate: 0.0081687]
	Learning Rate: 0.00816866
	LOSS [training: 0.03127720241307855 | validation: 0.011726559617090154]
	TIME [epoch: 70.6 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013098548006003099		[learning rate: 0.0081524]
	Learning Rate: 0.00815242
	LOSS [training: 0.013098548006003099 | validation: 0.016644600672868486]
	TIME [epoch: 70.6 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02320188643844029		[learning rate: 0.0081362]
	Learning Rate: 0.00813618
	LOSS [training: 0.02320188643844029 | validation: 0.014676202441333403]
	TIME [epoch: 70.7 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07359086077604127		[learning rate: 0.00812]
	Learning Rate: 0.00811995
	LOSS [training: 0.07359086077604127 | validation: 0.07720184584181039]
	TIME [epoch: 70.7 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04937371412755408		[learning rate: 0.0081037]
	Learning Rate: 0.00810372
	LOSS [training: 0.04937371412755408 | validation: 0.015435980964791988]
	TIME [epoch: 70.7 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0534217763436885		[learning rate: 0.0080875]
	Learning Rate: 0.0080875
	LOSS [training: 0.0534217763436885 | validation: 0.01631146022763951]
	TIME [epoch: 70.6 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019547996937592522		[learning rate: 0.0080713]
	Learning Rate: 0.00807128
	LOSS [training: 0.019547996937592522 | validation: 0.022682316671769138]
	TIME [epoch: 70.6 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020534110849971112		[learning rate: 0.0080551]
	Learning Rate: 0.00805507
	LOSS [training: 0.020534110849971112 | validation: 0.01349055480847747]
	TIME [epoch: 70.7 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010198936647944436		[learning rate: 0.0080389]
	Learning Rate: 0.00803887
	LOSS [training: 0.010198936647944436 | validation: 0.006992498069301348]
	TIME [epoch: 70.7 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021595358759796623		[learning rate: 0.0080227]
	Learning Rate: 0.00802267
	LOSS [training: 0.021595358759796623 | validation: 0.013323377535688942]
	TIME [epoch: 70.7 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010002874558538166		[learning rate: 0.0080065]
	Learning Rate: 0.00800647
	LOSS [training: 0.010002874558538166 | validation: 0.004542380765832573]
	TIME [epoch: 70.8 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007090395614016584		[learning rate: 0.0079903]
	Learning Rate: 0.00799028
	LOSS [training: 0.007090395614016584 | validation: 0.021083786331440053]
	TIME [epoch: 70.8 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021843157307799104		[learning rate: 0.0079741]
	Learning Rate: 0.0079741
	LOSS [training: 0.021843157307799104 | validation: 0.04926734758501592]
	TIME [epoch: 70.8 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023478929084472695		[learning rate: 0.0079579]
	Learning Rate: 0.00795792
	LOSS [training: 0.023478929084472695 | validation: 0.009276207278075587]
	TIME [epoch: 70.7 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03667470411765311		[learning rate: 0.0079417]
	Learning Rate: 0.00794174
	LOSS [training: 0.03667470411765311 | validation: 0.017935787466410818]
	TIME [epoch: 70.8 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01992954435342575		[learning rate: 0.0079256]
	Learning Rate: 0.00792558
	LOSS [training: 0.01992954435342575 | validation: 0.0063378513469428506]
	TIME [epoch: 70.7 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00747467030525216		[learning rate: 0.0079094]
	Learning Rate: 0.00790941
	LOSS [training: 0.00747467030525216 | validation: 0.0091831017089145]
	TIME [epoch: 70.8 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01524637364652399		[learning rate: 0.0078933]
	Learning Rate: 0.00789326
	LOSS [training: 0.01524637364652399 | validation: 0.03558248079690467]
	TIME [epoch: 70.6 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031008831234217063		[learning rate: 0.0078771]
	Learning Rate: 0.00787711
	LOSS [training: 0.031008831234217063 | validation: 0.013100167529483231]
	TIME [epoch: 70.8 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012547940542556481		[learning rate: 0.007861]
	Learning Rate: 0.00786096
	LOSS [training: 0.012547940542556481 | validation: 0.005886354475412234]
	TIME [epoch: 70.7 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03505304739598379		[learning rate: 0.0078448]
	Learning Rate: 0.00784482
	LOSS [training: 0.03505304739598379 | validation: 0.06292961617821212]
	TIME [epoch: 70.7 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062693841685419		[learning rate: 0.0078287]
	Learning Rate: 0.00782869
	LOSS [training: 0.062693841685419 | validation: 0.009126192535700536]
	TIME [epoch: 70.6 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008058488868378403		[learning rate: 0.0078126]
	Learning Rate: 0.00781256
	LOSS [training: 0.008058488868378403 | validation: 0.0069584937053915556]
	TIME [epoch: 70.7 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02318298364824898		[learning rate: 0.0077964]
	Learning Rate: 0.00779644
	LOSS [training: 0.02318298364824898 | validation: 0.010408673252835504]
	TIME [epoch: 70.6 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009396967997837562		[learning rate: 0.0077803]
	Learning Rate: 0.00778033
	LOSS [training: 0.009396967997837562 | validation: 0.006987850688696277]
	TIME [epoch: 70.7 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007617450774326733		[learning rate: 0.0077642]
	Learning Rate: 0.00776422
	LOSS [training: 0.007617450774326733 | validation: 0.007369656961603879]
	TIME [epoch: 70.7 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011217117712221898		[learning rate: 0.0077481]
	Learning Rate: 0.00774812
	LOSS [training: 0.011217117712221898 | validation: 0.013368318645737582]
	TIME [epoch: 70.7 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00903807795761264		[learning rate: 0.007732]
	Learning Rate: 0.00773202
	LOSS [training: 0.00903807795761264 | validation: 0.007059677017673684]
	TIME [epoch: 70.7 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0073976129558710494		[learning rate: 0.0077159]
	Learning Rate: 0.00771593
	LOSS [training: 0.0073976129558710494 | validation: 0.01287817899697125]
	TIME [epoch: 70.7 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15811842129573567		[learning rate: 0.0076998]
	Learning Rate: 0.00769985
	LOSS [training: 0.15811842129573567 | validation: 0.16050019801536314]
	TIME [epoch: 70.6 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29242611796100226		[learning rate: 0.0076838]
	Learning Rate: 0.00768377
	LOSS [training: 0.29242611796100226 | validation: 0.14105491413641336]
	TIME [epoch: 70.8 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25274011557287923		[learning rate: 0.0076677]
	Learning Rate: 0.0076677
	LOSS [training: 0.25274011557287923 | validation: 0.11463590949115808]
	TIME [epoch: 70.8 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09332934918926436		[learning rate: 0.0076516]
	Learning Rate: 0.00765163
	LOSS [training: 0.09332934918926436 | validation: 0.019920709823676507]
	TIME [epoch: 70.7 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017401522888130766		[learning rate: 0.0076356]
	Learning Rate: 0.00763557
	LOSS [training: 0.017401522888130766 | validation: 0.005789171684975555]
	TIME [epoch: 70.6 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006026532056399235		[learning rate: 0.0076195]
	Learning Rate: 0.00761952
	LOSS [training: 0.006026532056399235 | validation: 0.08144820491188606]
	TIME [epoch: 70.7 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10763592686899014		[learning rate: 0.0076035]
	Learning Rate: 0.00760347
	LOSS [training: 0.10763592686899014 | validation: 0.03220210870050585]
	TIME [epoch: 70.5 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02083651723680379		[learning rate: 0.0075874]
	Learning Rate: 0.00758744
	LOSS [training: 0.02083651723680379 | validation: 0.00822834257982448]
	TIME [epoch: 70.6 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010987741904326956		[learning rate: 0.0075714]
	Learning Rate: 0.0075714
	LOSS [training: 0.010987741904326956 | validation: 0.007528831496804833]
	TIME [epoch: 70.6 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007320389323663419		[learning rate: 0.0075554]
	Learning Rate: 0.00755538
	LOSS [training: 0.007320389323663419 | validation: 0.005352697931138387]
	TIME [epoch: 70.5 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006237111795579894		[learning rate: 0.0075394]
	Learning Rate: 0.00753936
	LOSS [training: 0.006237111795579894 | validation: 0.00746862839752167]
	TIME [epoch: 70.5 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02776807739044154		[learning rate: 0.0075233]
	Learning Rate: 0.00752335
	LOSS [training: 0.02776807739044154 | validation: 0.008308487175980653]
	TIME [epoch: 70.6 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006768591212537546		[learning rate: 0.0075073]
	Learning Rate: 0.00750734
	LOSS [training: 0.006768591212537546 | validation: 0.0035843274150432983]
	TIME [epoch: 70.5 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_1153.pth
	Model improved!!!
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02513563118463672		[learning rate: 0.0074913]
	Learning Rate: 0.00749134
	LOSS [training: 0.02513563118463672 | validation: 0.011372460785821523]
	TIME [epoch: 70.8 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013455203401055866		[learning rate: 0.0074754]
	Learning Rate: 0.00747535
	LOSS [training: 0.013455203401055866 | validation: 0.02315711139776144]
	TIME [epoch: 70.8 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03989082403586473		[learning rate: 0.0074594]
	Learning Rate: 0.00745937
	LOSS [training: 0.03989082403586473 | validation: 0.045735610245307826]
	TIME [epoch: 70.7 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022431151101373774		[learning rate: 0.0074434]
	Learning Rate: 0.00744339
	LOSS [training: 0.022431151101373774 | validation: 0.0054353977196729]
	TIME [epoch: 70.7 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013539224873515943		[learning rate: 0.0074274]
	Learning Rate: 0.00742742
	LOSS [training: 0.013539224873515943 | validation: 0.030647560696571707]
	TIME [epoch: 70.8 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015755145510157255		[learning rate: 0.0074115]
	Learning Rate: 0.00741145
	LOSS [training: 0.015755145510157255 | validation: 0.008217196238034652]
	TIME [epoch: 70.8 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009559455215911858		[learning rate: 0.0073955]
	Learning Rate: 0.0073955
	LOSS [training: 0.009559455215911858 | validation: 0.01477993612587614]
	TIME [epoch: 70.8 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036222811805367634		[learning rate: 0.0073795]
	Learning Rate: 0.00737955
	LOSS [training: 0.036222811805367634 | validation: 0.0063741866289812625]
	TIME [epoch: 70.8 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030776533172759753		[learning rate: 0.0073636]
	Learning Rate: 0.0073636
	LOSS [training: 0.030776533172759753 | validation: 0.020777291216935112]
	TIME [epoch: 70.8 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03460429165126032		[learning rate: 0.0073477]
	Learning Rate: 0.00734767
	LOSS [training: 0.03460429165126032 | validation: 0.02711988056517352]
	TIME [epoch: 70.8 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027833519455181286		[learning rate: 0.0073317]
	Learning Rate: 0.00733174
	LOSS [training: 0.027833519455181286 | validation: 0.009259006887055197]
	TIME [epoch: 70.8 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013678911335487407		[learning rate: 0.0073158]
	Learning Rate: 0.00731582
	LOSS [training: 0.013678911335487407 | validation: 0.011884391579756159]
	TIME [epoch: 70.6 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013087989465060432		[learning rate: 0.0072999]
	Learning Rate: 0.00729991
	LOSS [training: 0.013087989465060432 | validation: 0.00628549638010122]
	TIME [epoch: 70.8 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007912110674513403		[learning rate: 0.007284]
	Learning Rate: 0.007284
	LOSS [training: 0.007912110674513403 | validation: 0.009650764972917829]
	TIME [epoch: 70.9 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009942532109433452		[learning rate: 0.0072681]
	Learning Rate: 0.0072681
	LOSS [training: 0.009942532109433452 | validation: 0.006324555312422691]
	TIME [epoch: 70.8 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0082817066035631		[learning rate: 0.0072522]
	Learning Rate: 0.00725221
	LOSS [training: 0.0082817066035631 | validation: 0.0101790974355344]
	TIME [epoch: 70.7 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05017466970363775		[learning rate: 0.0072363]
	Learning Rate: 0.00723633
	LOSS [training: 0.05017466970363775 | validation: 0.011441703535977508]
	TIME [epoch: 70.8 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012422630835354862		[learning rate: 0.0072205]
	Learning Rate: 0.00722045
	LOSS [training: 0.012422630835354862 | validation: 0.009088136925941653]
	TIME [epoch: 70.8 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02314701620618976		[learning rate: 0.0072046]
	Learning Rate: 0.00720458
	LOSS [training: 0.02314701620618976 | validation: 0.005978637837837115]
	TIME [epoch: 70.6 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008962850838122887		[learning rate: 0.0071887]
	Learning Rate: 0.00718872
	LOSS [training: 0.008962850838122887 | validation: 0.004739648055465615]
	TIME [epoch: 70.8 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007097824215437778		[learning rate: 0.0071729]
	Learning Rate: 0.00717287
	LOSS [training: 0.007097824215437778 | validation: 0.008149717452641501]
	TIME [epoch: 70.7 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008674473479011707		[learning rate: 0.007157]
	Learning Rate: 0.00715702
	LOSS [training: 0.008674473479011707 | validation: 0.017655034714734737]
	TIME [epoch: 70.8 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01703832802489012		[learning rate: 0.0071412]
	Learning Rate: 0.00714119
	LOSS [training: 0.01703832802489012 | validation: 0.014839198924753355]
	TIME [epoch: 70.9 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013138950471318992		[learning rate: 0.0071254]
	Learning Rate: 0.00712536
	LOSS [training: 0.013138950471318992 | validation: 0.006500266605930026]
	TIME [epoch: 70.8 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014505925555538403		[learning rate: 0.0071095]
	Learning Rate: 0.00710954
	LOSS [training: 0.014505925555538403 | validation: 0.00791322112085688]
	TIME [epoch: 70.8 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014235915605576036		[learning rate: 0.0070937]
	Learning Rate: 0.00709372
	LOSS [training: 0.014235915605576036 | validation: 0.018551631961281966]
	TIME [epoch: 70.9 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03539328877034822		[learning rate: 0.0070779]
	Learning Rate: 0.00707792
	LOSS [training: 0.03539328877034822 | validation: 0.011819016210642401]
	TIME [epoch: 70.8 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012123698481318727		[learning rate: 0.0070621]
	Learning Rate: 0.00706212
	LOSS [training: 0.012123698481318727 | validation: 0.024266320771169816]
	TIME [epoch: 70.8 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04156254212113919		[learning rate: 0.0070463]
	Learning Rate: 0.00704633
	LOSS [training: 0.04156254212113919 | validation: 0.010796551358698715]
	TIME [epoch: 70.7 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011754903774581186		[learning rate: 0.0070305]
	Learning Rate: 0.00703055
	LOSS [training: 0.011754903774581186 | validation: 0.007768863848591325]
	TIME [epoch: 70.8 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022224279116426035		[learning rate: 0.0070148]
	Learning Rate: 0.00701477
	LOSS [training: 0.022224279116426035 | validation: 0.11990560367428618]
	TIME [epoch: 70.8 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05208815895667395		[learning rate: 0.006999]
	Learning Rate: 0.00699901
	LOSS [training: 0.05208815895667395 | validation: 0.01153241842214138]
	TIME [epoch: 70.8 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00896383346352123		[learning rate: 0.0069833]
	Learning Rate: 0.00698325
	LOSS [training: 0.00896383346352123 | validation: 0.006072955340592356]
	TIME [epoch: 70.8 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010006641526147463		[learning rate: 0.0069675]
	Learning Rate: 0.0069675
	LOSS [training: 0.010006641526147463 | validation: 0.008815705381719734]
	TIME [epoch: 70.9 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011125345661002435		[learning rate: 0.0069518]
	Learning Rate: 0.00695176
	LOSS [training: 0.011125345661002435 | validation: 0.006532854939469783]
	TIME [epoch: 70.8 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009863866335211517		[learning rate: 0.006936]
	Learning Rate: 0.00693603
	LOSS [training: 0.009863866335211517 | validation: 0.008774141226538789]
	TIME [epoch: 70.9 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013321522488033597		[learning rate: 0.0069203]
	Learning Rate: 0.0069203
	LOSS [training: 0.013321522488033597 | validation: 0.012280445790689664]
	TIME [epoch: 70.8 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015036052953607066		[learning rate: 0.0069046]
	Learning Rate: 0.00690459
	LOSS [training: 0.015036052953607066 | validation: 0.030324690340592167]
	TIME [epoch: 70.8 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018267565133159327		[learning rate: 0.0068889]
	Learning Rate: 0.00688888
	LOSS [training: 0.018267565133159327 | validation: 0.005729698672626189]
	TIME [epoch: 70.9 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008022333550513733		[learning rate: 0.0068732]
	Learning Rate: 0.00687318
	LOSS [training: 0.008022333550513733 | validation: 0.01223694461548526]
	TIME [epoch: 70.8 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02484647148635497		[learning rate: 0.0068575]
	Learning Rate: 0.00685749
	LOSS [training: 0.02484647148635497 | validation: 0.04499639671741672]
	TIME [epoch: 70.8 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03801035920637039		[learning rate: 0.0068418]
	Learning Rate: 0.00684181
	LOSS [training: 0.03801035920637039 | validation: 0.014940227859933028]
	TIME [epoch: 70.7 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010477895864948973		[learning rate: 0.0068261]
	Learning Rate: 0.00682614
	LOSS [training: 0.010477895864948973 | validation: 0.0071247926935579815]
	TIME [epoch: 70.8 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00923712925092557		[learning rate: 0.0068105]
	Learning Rate: 0.00681048
	LOSS [training: 0.00923712925092557 | validation: 0.011181148405541904]
	TIME [epoch: 70.7 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01382653918691995		[learning rate: 0.0067948]
	Learning Rate: 0.00679482
	LOSS [training: 0.01382653918691995 | validation: 0.008512961897709073]
	TIME [epoch: 70.8 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00997271380816832		[learning rate: 0.0067792]
	Learning Rate: 0.00677917
	LOSS [training: 0.00997271380816832 | validation: 0.005485300405563561]
	TIME [epoch: 70.7 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008315208259987264		[learning rate: 0.0067635]
	Learning Rate: 0.00676354
	LOSS [training: 0.008315208259987264 | validation: 0.011522756648098906]
	TIME [epoch: 70.8 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01320581646165937		[learning rate: 0.0067479]
	Learning Rate: 0.00674791
	LOSS [training: 0.01320581646165937 | validation: 0.009315443726018084]
	TIME [epoch: 70.8 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012795379013097246		[learning rate: 0.0067323]
	Learning Rate: 0.00673229
	LOSS [training: 0.012795379013097246 | validation: 0.009603745083556922]
	TIME [epoch: 70.7 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02039806136724416		[learning rate: 0.0067167]
	Learning Rate: 0.00671668
	LOSS [training: 0.02039806136724416 | validation: 0.041999765755250426]
	TIME [epoch: 70.8 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03549369755288229		[learning rate: 0.0067011]
	Learning Rate: 0.00670108
	LOSS [training: 0.03549369755288229 | validation: 0.007111037249458661]
	TIME [epoch: 70.8 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026945567573913688		[learning rate: 0.0066855]
	Learning Rate: 0.00668548
	LOSS [training: 0.026945567573913688 | validation: 0.008442288014851914]
	TIME [epoch: 70.8 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008246659060516722		[learning rate: 0.0066699]
	Learning Rate: 0.0066699
	LOSS [training: 0.008246659060516722 | validation: 0.00475482616162446]
	TIME [epoch: 70.9 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006684348478376189		[learning rate: 0.0066543]
	Learning Rate: 0.00665432
	LOSS [training: 0.006684348478376189 | validation: 0.005426669509618891]
	TIME [epoch: 70.7 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08893209775251779		[learning rate: 0.0066388]
	Learning Rate: 0.00663876
	LOSS [training: 0.08893209775251779 | validation: 0.01870983108614839]
	TIME [epoch: 70.9 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011545851371277421		[learning rate: 0.0066232]
	Learning Rate: 0.0066232
	LOSS [training: 0.011545851371277421 | validation: 0.0101439257557148]
	TIME [epoch: 70.8 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006585478122613409		[learning rate: 0.0066077]
	Learning Rate: 0.00660765
	LOSS [training: 0.006585478122613409 | validation: 0.004481581693537922]
	TIME [epoch: 70.9 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003739114900727909		[learning rate: 0.0065921]
	Learning Rate: 0.00659212
	LOSS [training: 0.003739114900727909 | validation: 0.0036326212877696618]
	TIME [epoch: 70.9 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014480519028716912		[learning rate: 0.0065766]
	Learning Rate: 0.00657659
	LOSS [training: 0.014480519028716912 | validation: 0.017386383647187652]
	TIME [epoch: 70.9 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012503386547064392		[learning rate: 0.0065611]
	Learning Rate: 0.00656107
	LOSS [training: 0.012503386547064392 | validation: 0.005790427218032626]
	TIME [epoch: 70.8 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009492290965722558		[learning rate: 0.0065456]
	Learning Rate: 0.00654556
	LOSS [training: 0.009492290965722558 | validation: 0.01057634843148383]
	TIME [epoch: 70.8 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007809042445971093		[learning rate: 0.0065301]
	Learning Rate: 0.00653006
	LOSS [training: 0.007809042445971093 | validation: 0.011033438943578042]
	TIME [epoch: 70.8 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013519331714380635		[learning rate: 0.0065146]
	Learning Rate: 0.00651457
	LOSS [training: 0.013519331714380635 | validation: 0.002323562945689482]
	TIME [epoch: 70.9 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_1216.pth
	Model improved!!!
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028517550267670054		[learning rate: 0.0064991]
	Learning Rate: 0.00649909
	LOSS [training: 0.0028517550267670054 | validation: 0.0023961494199703274]
	TIME [epoch: 70.7 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017950935498394105		[learning rate: 0.0064836]
	Learning Rate: 0.00648362
	LOSS [training: 0.017950935498394105 | validation: 0.01353724093640921]
	TIME [epoch: 70.9 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00915803563360612		[learning rate: 0.0064682]
	Learning Rate: 0.00646815
	LOSS [training: 0.00915803563360612 | validation: 0.005940388113260279]
	TIME [epoch: 70.8 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06584871960582629		[learning rate: 0.0064527]
	Learning Rate: 0.0064527
	LOSS [training: 0.06584871960582629 | validation: 0.030554902474816167]
	TIME [epoch: 70.8 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025856840309528055		[learning rate: 0.0064373]
	Learning Rate: 0.00643726
	LOSS [training: 0.025856840309528055 | validation: 0.014479738985841747]
	TIME [epoch: 70.9 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01609711722368868		[learning rate: 0.0064218]
	Learning Rate: 0.00642183
	LOSS [training: 0.01609711722368868 | validation: 0.010186903145801608]
	TIME [epoch: 70.8 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010081189685786689		[learning rate: 0.0064064]
	Learning Rate: 0.0064064
	LOSS [training: 0.010081189685786689 | validation: 0.0063232831775572994]
	TIME [epoch: 70.8 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008249499133202182		[learning rate: 0.006391]
	Learning Rate: 0.00639099
	LOSS [training: 0.008249499133202182 | validation: 0.004986390600290103]
	TIME [epoch: 70.8 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006283156012264542		[learning rate: 0.0063756]
	Learning Rate: 0.00637559
	LOSS [training: 0.006283156012264542 | validation: 0.003772618340695668]
	TIME [epoch: 71 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0066904606672686245		[learning rate: 0.0063602]
	Learning Rate: 0.00636019
	LOSS [training: 0.0066904606672686245 | validation: 0.00731464758719645]
	TIME [epoch: 70.8 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00622609537314518		[learning rate: 0.0063448]
	Learning Rate: 0.00634481
	LOSS [training: 0.00622609537314518 | validation: 0.004001952856222584]
	TIME [epoch: 70.9 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004951446343741423		[learning rate: 0.0063294]
	Learning Rate: 0.00632944
	LOSS [training: 0.004951446343741423 | validation: 0.0031080035975951403]
	TIME [epoch: 70.9 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004806981439147672		[learning rate: 0.0063141]
	Learning Rate: 0.00631407
	LOSS [training: 0.004806981439147672 | validation: 0.0048869658977664125]
	TIME [epoch: 70.8 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00918501138340987		[learning rate: 0.0062987]
	Learning Rate: 0.00629872
	LOSS [training: 0.00918501138340987 | validation: 0.023351901927719403]
	TIME [epoch: 70.8 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013161875466861764		[learning rate: 0.0062834]
	Learning Rate: 0.00628338
	LOSS [training: 0.013161875466861764 | validation: 0.0035583396177954222]
	TIME [epoch: 70.8 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006656097978434585		[learning rate: 0.006268]
	Learning Rate: 0.00626804
	LOSS [training: 0.006656097978434585 | validation: 0.0031786988977963635]
	TIME [epoch: 70.7 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035949725970531475		[learning rate: 0.0062527]
	Learning Rate: 0.00625272
	LOSS [training: 0.0035949725970531475 | validation: 0.006089202165394526]
	TIME [epoch: 70.8 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0067140242568269155		[learning rate: 0.0062374]
	Learning Rate: 0.00623741
	LOSS [training: 0.0067140242568269155 | validation: 0.0049988560606052095]
	TIME [epoch: 70.8 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02212267251959287		[learning rate: 0.0062221]
	Learning Rate: 0.00622211
	LOSS [training: 0.02212267251959287 | validation: 0.009964580927090861]
	TIME [epoch: 70.8 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024783291317295293		[learning rate: 0.0062068]
	Learning Rate: 0.00620681
	LOSS [training: 0.024783291317295293 | validation: 0.019306027647762083]
	TIME [epoch: 70.7 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012156927047894242		[learning rate: 0.0061915]
	Learning Rate: 0.00619153
	LOSS [training: 0.012156927047894242 | validation: 0.005505613035648348]
	TIME [epoch: 70.8 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004575745260992096		[learning rate: 0.0061763]
	Learning Rate: 0.00617626
	LOSS [training: 0.004575745260992096 | validation: 0.002477461372891528]
	TIME [epoch: 70.7 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029751398627412967		[learning rate: 0.006161]
	Learning Rate: 0.006161
	LOSS [training: 0.029751398627412967 | validation: 0.025842634313890615]
	TIME [epoch: 70.8 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03183621289492729		[learning rate: 0.0061458]
	Learning Rate: 0.00614575
	LOSS [training: 0.03183621289492729 | validation: 0.012214481540126318]
	TIME [epoch: 70.7 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008906857688680532		[learning rate: 0.0061305]
	Learning Rate: 0.00613051
	LOSS [training: 0.008906857688680532 | validation: 0.0072785814540331124]
	TIME [epoch: 70.8 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007713574439006175		[learning rate: 0.0061153]
	Learning Rate: 0.00611528
	LOSS [training: 0.007713574439006175 | validation: 0.008228719536333817]
	TIME [epoch: 70.9 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008200624310832098		[learning rate: 0.0061001]
	Learning Rate: 0.00610007
	LOSS [training: 0.008200624310832098 | validation: 0.007891069362267874]
	TIME [epoch: 70.9 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010210149274723851		[learning rate: 0.0060849]
	Learning Rate: 0.00608486
	LOSS [training: 0.010210149274723851 | validation: 0.0075209260373554545]
	TIME [epoch: 70.8 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008050333660074967		[learning rate: 0.0060697]
	Learning Rate: 0.00606966
	LOSS [training: 0.008050333660074967 | validation: 0.005303135851674491]
	TIME [epoch: 70.8 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0078052841739747894		[learning rate: 0.0060545]
	Learning Rate: 0.00605447
	LOSS [training: 0.0078052841739747894 | validation: 0.019750118215746057]
	TIME [epoch: 70.9 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019376825652507222		[learning rate: 0.0060393]
	Learning Rate: 0.0060393
	LOSS [training: 0.019376825652507222 | validation: 0.016272673951234457]
	TIME [epoch: 70.6 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016759348940570493		[learning rate: 0.0060241]
	Learning Rate: 0.00602413
	LOSS [training: 0.016759348940570493 | validation: 0.007483102998059624]
	TIME [epoch: 70.8 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006659888966321064		[learning rate: 0.006009]
	Learning Rate: 0.00600898
	LOSS [training: 0.006659888966321064 | validation: 0.009246129388137639]
	TIME [epoch: 70.8 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011842335516089415		[learning rate: 0.0059938]
	Learning Rate: 0.00599384
	LOSS [training: 0.011842335516089415 | validation: 0.005345397867335179]
	TIME [epoch: 70.8 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008573343301613735		[learning rate: 0.0059787]
	Learning Rate: 0.00597871
	LOSS [training: 0.008573343301613735 | validation: 0.0029757367248015015]
	TIME [epoch: 70.7 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06203157199556709		[learning rate: 0.0059636]
	Learning Rate: 0.00596359
	LOSS [training: 0.06203157199556709 | validation: 0.006400469761596533]
	TIME [epoch: 70.8 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007731372590320175		[learning rate: 0.0059485]
	Learning Rate: 0.00594848
	LOSS [training: 0.007731372590320175 | validation: 0.004284740665128594]
	TIME [epoch: 70.7 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005766798114085447		[learning rate: 0.0059334]
	Learning Rate: 0.00593338
	LOSS [training: 0.005766798114085447 | validation: 0.0027612824405406963]
	TIME [epoch: 70.7 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028600612351821547		[learning rate: 0.0059183]
	Learning Rate: 0.00591829
	LOSS [training: 0.0028600612351821547 | validation: 0.0042846509730648475]
	TIME [epoch: 70.8 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004647294959164902		[learning rate: 0.0059032]
	Learning Rate: 0.00590321
	LOSS [training: 0.004647294959164902 | validation: 0.0019758851785393414]
	TIME [epoch: 70.8 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_1256.pth
	Model improved!!!
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003090836760367893		[learning rate: 0.0058881]
	Learning Rate: 0.00588815
	LOSS [training: 0.003090836760367893 | validation: 0.009415198994115314]
	TIME [epoch: 70.8 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008064479068581022		[learning rate: 0.0058731]
	Learning Rate: 0.00587309
	LOSS [training: 0.008064479068581022 | validation: 0.05068950517732967]
	TIME [epoch: 70.9 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04044813534316173		[learning rate: 0.0058581]
	Learning Rate: 0.00585805
	LOSS [training: 0.04044813534316173 | validation: 0.012509359124077963]
	TIME [epoch: 70.8 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011640160783053922		[learning rate: 0.005843]
	Learning Rate: 0.00584302
	LOSS [training: 0.011640160783053922 | validation: 0.004760631219027485]
	TIME [epoch: 70.8 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0064580286576722875		[learning rate: 0.005828]
	Learning Rate: 0.005828
	LOSS [training: 0.0064580286576722875 | validation: 0.004171093908884387]
	TIME [epoch: 70.8 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006772810782397401		[learning rate: 0.005813]
	Learning Rate: 0.00581299
	LOSS [training: 0.006772810782397401 | validation: 0.0029570053490932447]
	TIME [epoch: 70.8 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004646140285909459		[learning rate: 0.005798]
	Learning Rate: 0.005798
	LOSS [training: 0.004646140285909459 | validation: 0.003770704089127614]
	TIME [epoch: 70.8 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023668804316748994		[learning rate: 0.005783]
	Learning Rate: 0.00578301
	LOSS [training: 0.0023668804316748994 | validation: 0.04833659057888185]
	TIME [epoch: 70.8 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029218182857438144		[learning rate: 0.005768]
	Learning Rate: 0.00576804
	LOSS [training: 0.029218182857438144 | validation: 0.00571435423720072]
	TIME [epoch: 70.8 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010642064147937742		[learning rate: 0.0057531]
	Learning Rate: 0.00575307
	LOSS [training: 0.010642064147937742 | validation: 0.0018390508445620683]
	TIME [epoch: 70.8 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_1266.pth
	Model improved!!!
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009143570056397737		[learning rate: 0.0057381]
	Learning Rate: 0.00573812
	LOSS [training: 0.009143570056397737 | validation: 0.005204207913137012]
	TIME [epoch: 70.8 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0061377716506896786		[learning rate: 0.0057232]
	Learning Rate: 0.00572318
	LOSS [training: 0.0061377716506896786 | validation: 0.005949790641047309]
	TIME [epoch: 70.8 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009377587943037499		[learning rate: 0.0057083]
	Learning Rate: 0.00570826
	LOSS [training: 0.009377587943037499 | validation: 0.012408347590532625]
	TIME [epoch: 70.9 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029101471182926032		[learning rate: 0.0056933]
	Learning Rate: 0.00569334
	LOSS [training: 0.029101471182926032 | validation: 0.03751005699418684]
	TIME [epoch: 70.9 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025515934576251693		[learning rate: 0.0056784]
	Learning Rate: 0.00567844
	LOSS [training: 0.025515934576251693 | validation: 0.005200128529565922]
	TIME [epoch: 70.8 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005645139165252947		[learning rate: 0.0056635]
	Learning Rate: 0.00566355
	LOSS [training: 0.005645139165252947 | validation: 0.002969170608521572]
	TIME [epoch: 70.8 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003339255858183769		[learning rate: 0.0056487]
	Learning Rate: 0.00564867
	LOSS [training: 0.003339255858183769 | validation: 0.004530655595798233]
	TIME [epoch: 70.8 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0047509729556558		[learning rate: 0.0056338]
	Learning Rate: 0.0056338
	LOSS [training: 0.0047509729556558 | validation: 0.0036355088765083502]
	TIME [epoch: 70.8 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0043460538236589664		[learning rate: 0.0056189]
	Learning Rate: 0.00561894
	LOSS [training: 0.0043460538236589664 | validation: 0.007107844234264343]
	TIME [epoch: 70.8 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006838805516872206		[learning rate: 0.0056041]
	Learning Rate: 0.0056041
	LOSS [training: 0.006838805516872206 | validation: 0.0038814553033273864]
	TIME [epoch: 70.8 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004210271184786433		[learning rate: 0.0055893]
	Learning Rate: 0.00558927
	LOSS [training: 0.004210271184786433 | validation: 0.08617770910920444]
	TIME [epoch: 70.8 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05229800360536078		[learning rate: 0.0055744]
	Learning Rate: 0.00557445
	LOSS [training: 0.05229800360536078 | validation: 0.011117622887013134]
	TIME [epoch: 70.8 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00991927503431618		[learning rate: 0.0055596]
	Learning Rate: 0.00555964
	LOSS [training: 0.00991927503431618 | validation: 0.004824933190373531]
	TIME [epoch: 70.8 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007278874616705909		[learning rate: 0.0055448]
	Learning Rate: 0.00554484
	LOSS [training: 0.007278874616705909 | validation: 0.002689142546701156]
	TIME [epoch: 70.7 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00311483350678285		[learning rate: 0.0055301]
	Learning Rate: 0.00553006
	LOSS [training: 0.00311483350678285 | validation: 0.0020590650239423183]
	TIME [epoch: 70.7 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014253810902551255		[learning rate: 0.0055153]
	Learning Rate: 0.00551529
	LOSS [training: 0.014253810902551255 | validation: 0.010494849910761665]
	TIME [epoch: 70.8 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0062972536651447145		[learning rate: 0.0055005]
	Learning Rate: 0.00550053
	LOSS [training: 0.0062972536651447145 | validation: 0.0013835435078894342]
	TIME [epoch: 70.8 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd4_20240707_125500/states/model_phi2_1a_v_mmd4_1283.pth
	Model improved!!!
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033612113806947854		[learning rate: 0.0054858]
	Learning Rate: 0.00548578
	LOSS [training: 0.0033612113806947854 | validation: 0.010778266368668856]
	TIME [epoch: 70.8 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006889017674275932		[learning rate: 0.005471]
	Learning Rate: 0.00547105
	LOSS [training: 0.006889017674275932 | validation: 0.057201092166612774]
	TIME [epoch: 70.8 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03288321724270372		[learning rate: 0.0054563]
	Learning Rate: 0.00545632
	LOSS [training: 0.03288321724270372 | validation: 0.005234582306355601]
	TIME [epoch: 70.8 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006216666690651731		[learning rate: 0.0054416]
	Learning Rate: 0.00544161
	LOSS [training: 0.006216666690651731 | validation: 0.003869290277455112]
	TIME [epoch: 70.8 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04080560896128639		[learning rate: 0.0054269]
	Learning Rate: 0.00542692
	LOSS [training: 0.04080560896128639 | validation: 0.12191635690638886]
	TIME [epoch: 70.9 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07890443733615561		[learning rate: 0.0054122]
	Learning Rate: 0.00541223
	LOSS [training: 0.07890443733615561 | validation: 0.019966340209943968]
	TIME [epoch: 70.8 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015484901463508035		[learning rate: 0.0053976]
	Learning Rate: 0.00539756
	LOSS [training: 0.015484901463508035 | validation: 0.010425605300292892]
	TIME [epoch: 70.7 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008423018600546136		[learning rate: 0.0053829]
	Learning Rate: 0.0053829
	LOSS [training: 0.008423018600546136 | validation: 0.026778229062947845]
	TIME [epoch: 70.8 sec]
EPOCH 1292/2000:
	Training over batches...
