Args:
Namespace(name='model_phi2_1a_v2', outdir='out/model_training/model_phi2_1a_v2', training_data='data/training_data/data_phi2_1a/training', validation_data='data/training_data/data_phi2_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.3, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 703841299

Training model...

Saving initial model state to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.274385780195365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.274385780195365 | validation: 3.8394928609409997]
	TIME [epoch: 162 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8958174524772025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.8958174524772025 | validation: 4.0022245356085895]
	TIME [epoch: 6.35 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3937685943489764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3937685943489764 | validation: 3.144345356078844]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.040027793982332		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.040027793982332 | validation: 3.0130865472383035]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.830275819358742		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.830275819358742 | validation: 2.9190913770955245]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.653383900064241		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.653383900064241 | validation: 2.1447767992245077]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.278189701730282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.278189701730282 | validation: 2.169345702640957]
	TIME [epoch: 6.31 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3890041223331533		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3890041223331533 | validation: 2.3566914126705347]
	TIME [epoch: 6.3 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2051520169894365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2051520169894365 | validation: 1.8570566850989696]
	TIME [epoch: 6.29 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0577199796356425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0577199796356425 | validation: 2.0008139501911772]
	TIME [epoch: 6.28 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1786051164902127		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1786051164902127 | validation: 1.9028298569807607]
	TIME [epoch: 6.28 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0634477902557955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0634477902557955 | validation: 2.0431865425591056]
	TIME [epoch: 6.28 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.28522077658763		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.28522077658763 | validation: 1.9458012835283096]
	TIME [epoch: 6.3 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.065598820834788		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.065598820834788 | validation: 1.785829712727232]
	TIME [epoch: 6.33 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.207581405931295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.207581405931295 | validation: 2.236520503423559]
	TIME [epoch: 6.26 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1410160526688933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1410160526688933 | validation: 1.8320076401312622]
	TIME [epoch: 6.27 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9859335857418463		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9859335857418463 | validation: 1.89734407430843]
	TIME [epoch: 6.28 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.01517467511338		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.01517467511338 | validation: 1.8320424185294297]
	TIME [epoch: 6.29 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0790743560689084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0790743560689084 | validation: 1.8448669519945224]
	TIME [epoch: 6.3 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0740706587644526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0740706587644526 | validation: 2.05697283130166]
	TIME [epoch: 6.32 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.108449730557897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.108449730557897 | validation: 1.8510751363894953]
	TIME [epoch: 6.28 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.063264474544476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.063264474544476 | validation: 2.026613188634302]
	TIME [epoch: 6.29 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0517940979808005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0517940979808005 | validation: 1.9152896707822389]
	TIME [epoch: 6.28 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0051222164453226		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0051222164453226 | validation: 1.8034640632867351]
	TIME [epoch: 6.27 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.000780701343046		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.000780701343046 | validation: 1.986952309217222]
	TIME [epoch: 6.29 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1246839121539924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1246839121539924 | validation: 1.7924305605147737]
	TIME [epoch: 6.31 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0705898864745116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0705898864745116 | validation: 1.9147164092742517]
	TIME [epoch: 6.29 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9982979013109392		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9982979013109392 | validation: 1.8006263091052856]
	TIME [epoch: 6.28 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9460566336899898		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9460566336899898 | validation: 1.8087654675904943]
	TIME [epoch: 6.28 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0462018094050327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0462018094050327 | validation: 1.8019590183441103]
	TIME [epoch: 6.26 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9544057536902923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9544057536902923 | validation: 1.8103211788724507]
	TIME [epoch: 6.27 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9390320225777884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9390320225777884 | validation: 1.803041695597896]
	TIME [epoch: 6.33 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.125152440341284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.125152440341284 | validation: 1.9328298381454139]
	TIME [epoch: 6.3 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.004895192482811		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.004895192482811 | validation: 1.963270134851637]
	TIME [epoch: 6.28 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9938967665896803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9938967665896803 | validation: 1.8753562235217818]
	TIME [epoch: 6.29 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9448138553664356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9448138553664356 | validation: 2.420684520175436]
	TIME [epoch: 6.29 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1110969370557786		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1110969370557786 | validation: 1.7663552696468667]
	TIME [epoch: 6.28 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.931555367153853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.931555367153853 | validation: 1.7907830609451219]
	TIME [epoch: 6.31 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.970773468332367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.970773468332367 | validation: 1.8865808832382518]
	TIME [epoch: 6.28 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9575262392684165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9575262392684165 | validation: 1.7667283868438415]
	TIME [epoch: 6.3 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.96873953906498		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.96873953906498 | validation: 1.7742226787100743]
	TIME [epoch: 6.29 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9690985831216765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9690985831216765 | validation: 1.7706012136851679]
	TIME [epoch: 6.29 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.970080398025902		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.970080398025902 | validation: 1.8157663894464755]
	TIME [epoch: 6.29 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.924709017739418		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.924709017739418 | validation: 1.9944184155677445]
	TIME [epoch: 6.32 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9845605022286108		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9845605022286108 | validation: 1.9230997446673483]
	TIME [epoch: 6.31 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9523317187550466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9523317187550466 | validation: 1.83529864651798]
	TIME [epoch: 6.29 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.929970435161057		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.929970435161057 | validation: 1.8477188881786055]
	TIME [epoch: 6.3 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.945376539455187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.945376539455187 | validation: 1.8329194979012735]
	TIME [epoch: 6.29 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9540864781893632		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9540864781893632 | validation: 2.0204611600540323]
	TIME [epoch: 6.29 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0247700902184484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0247700902184484 | validation: 2.024859025731133]
	TIME [epoch: 6.33 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9847923430248877		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 1.9847923430248877 | validation: 2.0058308365177333]
	TIME [epoch: 6.3 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8899125235592351		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 1.8899125235592351 | validation: 1.7309414265061673]
	TIME [epoch: 6.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9136255505473065		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 1.9136255505473065 | validation: 1.8162423311476843]
	TIME [epoch: 6.26 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9431042458634875		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 1.9431042458634875 | validation: 1.7558085187067414]
	TIME [epoch: 6.25 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8060704806677441		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 1.8060704806677441 | validation: 1.7851018337228832]
	TIME [epoch: 6.26 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9434093576643194		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 1.9434093576643194 | validation: 1.76202419783669]
	TIME [epoch: 6.3 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.79639273550815		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 1.79639273550815 | validation: 1.7211308965494034]
	TIME [epoch: 6.29 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8407148088917065		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 1.8407148088917065 | validation: 1.709924581278342]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8894584329643396		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 1.8894584329643396 | validation: 1.7218159472626355]
	TIME [epoch: 6.29 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7834015411941753		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 1.7834015411941753 | validation: 1.786537714860761]
	TIME [epoch: 6.28 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.813532164350285		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 1.813532164350285 | validation: 2.025671234166839]
	TIME [epoch: 6.28 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8155537155007577		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 1.8155537155007577 | validation: 1.6888813718251972]
	TIME [epoch: 6.32 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.710286300109981		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 1.710286300109981 | validation: 1.6109558429435848]
	TIME [epoch: 6.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.284755827284926		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 2.284755827284926 | validation: 1.8258902967679784]
	TIME [epoch: 6.26 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7464131593187		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 1.7464131593187 | validation: 1.607939609942687]
	TIME [epoch: 6.29 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6874193323806588		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 1.6874193323806588 | validation: 1.645616233538052]
	TIME [epoch: 6.28 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7817024769155254		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 1.7817024769155254 | validation: 1.6181460842580153]
	TIME [epoch: 6.27 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6493780054986598		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 1.6493780054986598 | validation: 1.5581534081963644]
	TIME [epoch: 6.31 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.62008418609617		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 1.62008418609617 | validation: 1.5316080260261766]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5571651750055748		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 1.5571651750055748 | validation: 1.6821451146236357]
	TIME [epoch: 6.26 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5409174754402664		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 1.5409174754402664 | validation: 1.5185784334792385]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5369083944759911		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 1.5369083944759911 | validation: 1.4258538435921086]
	TIME [epoch: 6.28 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.692618948672726		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 1.692618948672726 | validation: 1.439643412834013]
	TIME [epoch: 6.27 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3934496320860892		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 1.3934496320860892 | validation: 1.2572329349682776]
	TIME [epoch: 6.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3333431033576215		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 1.3333431033576215 | validation: 1.2694311992344138]
	TIME [epoch: 6.26 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3044155422463446		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 1.3044155422463446 | validation: 1.7585852609443027]
	TIME [epoch: 6.28 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5934963012118386		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 1.5934963012118386 | validation: 1.4212841674569363]
	TIME [epoch: 6.27 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4301017312564155		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 1.4301017312564155 | validation: 1.2123521845925227]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1676232683135956		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 1.1676232683135956 | validation: 2.7243904654189803]
	TIME [epoch: 6.27 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.827493143074557		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 1.827493143074557 | validation: 2.3308833713652057]
	TIME [epoch: 6.31 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6457039344045874		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 1.6457039344045874 | validation: 1.1595167478054091]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1376932694601418		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 1.1376932694601418 | validation: 1.0553450144954937]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4665228591861414		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 1.4665228591861414 | validation: 0.940677030345042]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9929377642228401		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.9929377642228401 | validation: 1.37051282247715]
	TIME [epoch: 6.26 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.367396016872368		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 1.367396016872368 | validation: 0.9332415803057945]
	TIME [epoch: 6.29 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1063596631423833		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 1.1063596631423833 | validation: 0.935252396791686]
	TIME [epoch: 6.3 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2656138897252136		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 1.2656138897252136 | validation: 1.1059988911583016]
	TIME [epoch: 6.26 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.00084117938626		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 1.00084117938626 | validation: 1.331221252786091]
	TIME [epoch: 6.28 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3828273037448309		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 1.3828273037448309 | validation: 0.9066844585394813]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1213893766228424		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.1213893766228424 | validation: 1.3524767266501916]
	TIME [epoch: 6.26 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1649072242123926		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 1.1649072242123926 | validation: 0.9787062084678672]
	TIME [epoch: 6.3 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8515449149309596		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.8515449149309596 | validation: 0.8978319163534285]
	TIME [epoch: 6.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.921648299212499		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 0.921648299212499 | validation: 0.6967711544044857]
	TIME [epoch: 6.28 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8833111566387383		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.8833111566387383 | validation: 0.7051923947376599]
	TIME [epoch: 6.26 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.737197114104073		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.737197114104073 | validation: 0.9235956815380868]
	TIME [epoch: 6.26 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9193849285777121		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.9193849285777121 | validation: 0.6131420407600656]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7713936532167953		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.7713936532167953 | validation: 1.1544710030558165]
	TIME [epoch: 6.29 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7483753932380162		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.7483753932380162 | validation: 0.4814555359513861]
	TIME [epoch: 6.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6234557416792423		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.6234557416792423 | validation: 0.6332111754381959]
	TIME [epoch: 6.27 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6764748876743052		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.6764748876743052 | validation: 0.7989742402112192]
	TIME [epoch: 6.28 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6091671294755608		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.6091671294755608 | validation: 1.0839548595130861]
	TIME [epoch: 6.28 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2417763007372273		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 1.2417763007372273 | validation: 0.7337065069902509]
	TIME [epoch: 6.27 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1486866203983699		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 1.1486866203983699 | validation: 0.6417599623044364]
	TIME [epoch: 6.29 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1038557033130056		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.1038557033130056 | validation: 0.7599172029611758]
	TIME [epoch: 6.3 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1050233502294033		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.1050233502294033 | validation: 0.7020092631166182]
	TIME [epoch: 6.28 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1367708585065015		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 1.1367708585065015 | validation: 0.8221140326417322]
	TIME [epoch: 6.28 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0622147329130773		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 1.0622147329130773 | validation: 0.6534831299075257]
	TIME [epoch: 6.28 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0461372551558448		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 1.0461372551558448 | validation: 0.7636093167964451]
	TIME [epoch: 6.27 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1337322106420158		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 1.1337322106420158 | validation: 0.553760412084159]
	TIME [epoch: 6.29 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9521397641407794		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.9521397641407794 | validation: 0.9159961676062374]
	TIME [epoch: 6.32 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0638967294209642		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 1.0638967294209642 | validation: 0.5554528716289261]
	TIME [epoch: 6.28 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0013715246643133		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 1.0013715246643133 | validation: 0.5084679861195777]
	TIME [epoch: 6.28 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.057333391100252		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 1.057333391100252 | validation: 0.7203083444258787]
	TIME [epoch: 6.28 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0507088608423798		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 1.0507088608423798 | validation: 0.5363837856863601]
	TIME [epoch: 6.28 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.050810119328159		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 1.050810119328159 | validation: 0.562165652683268]
	TIME [epoch: 6.29 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9162696362384538		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.9162696362384538 | validation: 0.7484932616742588]
	TIME [epoch: 6.31 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9924365794698662		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.9924365794698662 | validation: 0.5155835308965335]
	TIME [epoch: 6.28 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8868336097791145		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.8868336097791145 | validation: 0.7510353917995334]
	TIME [epoch: 6.28 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3112249012884996		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 1.3112249012884996 | validation: 0.5526237165031878]
	TIME [epoch: 6.29 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9138880412758598		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.9138880412758598 | validation: 0.5827218084091956]
	TIME [epoch: 6.28 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.078563438557564		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 1.078563438557564 | validation: 0.5202359716349327]
	TIME [epoch: 6.28 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3535331446130585		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 1.3535331446130585 | validation: 0.5788101375863431]
	TIME [epoch: 6.32 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9495208335087005		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.9495208335087005 | validation: 0.5913371033663891]
	TIME [epoch: 6.29 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.692959519448837		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 1.692959519448837 | validation: 2.8519272474106914]
	TIME [epoch: 6.28 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5762231712683394		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.5762231712683394 | validation: 1.651156124559038]
	TIME [epoch: 6.29 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3501748270118317		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 1.3501748270118317 | validation: 0.5848179379808547]
	TIME [epoch: 6.28 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9488208330641341		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.9488208330641341 | validation: 0.5124205000120279]
	TIME [epoch: 6.28 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9820273338510817		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.9820273338510817 | validation: 0.6010530986100501]
	TIME [epoch: 6.32 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8678267815972687		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.8678267815972687 | validation: 0.5447726739983533]
	TIME [epoch: 6.29 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9876160040921759		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.9876160040921759 | validation: 0.5029663555293007]
	TIME [epoch: 6.28 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8584931026155851		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.8584931026155851 | validation: 0.4743236465332226]
	TIME [epoch: 6.28 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_131.pth
	Model improved!!!
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0014481887050446		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 1.0014481887050446 | validation: 0.566957225416428]
	TIME [epoch: 6.26 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.008491076316628		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.008491076316628 | validation: 0.7982026162437645]
	TIME [epoch: 6.25 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9624815261729214		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.9624815261729214 | validation: 0.49856778780124317]
	TIME [epoch: 6.31 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9182373652075511		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.9182373652075511 | validation: 0.46017030662593417]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_135.pth
	Model improved!!!
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8543103794396936		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.8543103794396936 | validation: 0.527929820185478]
	TIME [epoch: 6.26 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9072439372193187		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.9072439372193187 | validation: 0.6495070425353761]
	TIME [epoch: 6.26 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9407485615995411		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.9407485615995411 | validation: 0.47240510505578553]
	TIME [epoch: 6.26 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9154454403182923		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.9154454403182923 | validation: 0.5001962476070456]
	TIME [epoch: 6.25 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0189177615974436		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 1.0189177615974436 | validation: 0.7340577578599795]
	TIME [epoch: 6.29 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1164509598211332		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 1.1164509598211332 | validation: 0.48117163015599135]
	TIME [epoch: 6.26 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8536086128532647		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.8536086128532647 | validation: 0.6873986722206987]
	TIME [epoch: 6.25 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8746403484775112		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.8746403484775112 | validation: 0.5695553598174953]
	TIME [epoch: 6.25 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9300021638069613		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.9300021638069613 | validation: 0.5169008010938516]
	TIME [epoch: 6.25 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8664957597572974		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.8664957597572974 | validation: 0.5042790014277128]
	TIME [epoch: 6.25 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.860045841505101		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.860045841505101 | validation: 0.48554135630038486]
	TIME [epoch: 6.28 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8494904061941719		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.8494904061941719 | validation: 0.5971352912969423]
	TIME [epoch: 6.27 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9174947537291938		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.9174947537291938 | validation: 0.45900105843161426]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_148.pth
	Model improved!!!
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8958968311554735		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.8958968311554735 | validation: 0.5655007054199641]
	TIME [epoch: 6.26 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8945532189222147		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.8945532189222147 | validation: 0.4801519704618544]
	TIME [epoch: 6.26 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5594844047191827		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.5594844047191827 | validation: 2.7009996313002107]
	TIME [epoch: 6.26 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.826128964522888		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.826128964522888 | validation: 0.6709468715175793]
	TIME [epoch: 6.29 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.290123281618731		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.290123281618731 | validation: 1.5856437447447225]
	TIME [epoch: 6.28 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3418175711877582		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.3418175711877582 | validation: 0.6393265490985507]
	TIME [epoch: 6.28 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9984207434909413		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.9984207434909413 | validation: 0.5968803985607236]
	TIME [epoch: 6.27 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9144701285236394		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.9144701285236394 | validation: 0.511995778579362]
	TIME [epoch: 6.27 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8686621045339017		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.8686621045339017 | validation: 0.45844595375210356]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_157.pth
	Model improved!!!
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8250061944912764		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.8250061944912764 | validation: 0.5959895793927568]
	TIME [epoch: 6.29 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8882546158992065		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.8882546158992065 | validation: 0.5794697017737469]
	TIME [epoch: 6.28 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8859212862985277		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.8859212862985277 | validation: 0.4867788278974996]
	TIME [epoch: 6.26 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.855958228431658		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.855958228431658 | validation: 0.42553748623291326]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_161.pth
	Model improved!!!
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8133620711248426		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.8133620711248426 | validation: 0.6551105921600834]
	TIME [epoch: 6.25 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8611115505567629		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.8611115505567629 | validation: 0.5890117751661388]
	TIME [epoch: 6.25 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9519102126166045		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.9519102126166045 | validation: 0.44217279332595444]
	TIME [epoch: 6.29 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8124904781727208		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.8124904781727208 | validation: 0.43882337215227263]
	TIME [epoch: 6.3 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9259676237702776		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.9259676237702776 | validation: 0.6646880727749429]
	TIME [epoch: 6.26 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.880302559540646		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.880302559540646 | validation: 0.4267305918753298]
	TIME [epoch: 6.27 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.834587739300611		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.834587739300611 | validation: 0.5340718899965021]
	TIME [epoch: 6.26 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8352513140081035		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.8352513140081035 | validation: 0.4947233601177532]
	TIME [epoch: 6.27 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9054985224161022		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.9054985224161022 | validation: 0.6167541496450831]
	TIME [epoch: 6.28 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9773660154036423		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.9773660154036423 | validation: 0.502556267385943]
	TIME [epoch: 6.31 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8268052415857052		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.8268052415857052 | validation: 0.4345183242049549]
	TIME [epoch: 6.27 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.006651020644344		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.006651020644344 | validation: 0.5797583326514977]
	TIME [epoch: 6.28 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9747831571954066		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.9747831571954066 | validation: 0.5387602173032118]
	TIME [epoch: 6.27 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8934765362213453		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.8934765362213453 | validation: 0.4739361286736135]
	TIME [epoch: 6.27 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8269308660147984		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.8269308660147984 | validation: 0.42608789752567877]
	TIME [epoch: 6.29 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8235928447652753		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.8235928447652753 | validation: 0.6244825941488632]
	TIME [epoch: 6.3 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9750355090807308		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.9750355090807308 | validation: 0.6301991903767459]
	TIME [epoch: 6.27 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9508952405054953		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.9508952405054953 | validation: 0.5278956522537983]
	TIME [epoch: 6.27 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8721090237076872		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.8721090237076872 | validation: 0.4583093539915034]
	TIME [epoch: 6.27 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9116160594476839		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.9116160594476839 | validation: 0.5108408421152014]
	TIME [epoch: 6.27 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8507542040683203		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.8507542040683203 | validation: 0.47904774714396536]
	TIME [epoch: 6.28 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9129879502940439		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.9129879502940439 | validation: 0.44615243940405414]
	TIME [epoch: 6.31 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.935164399502591		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.935164399502591 | validation: 0.45146970805432524]
	TIME [epoch: 6.27 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8061090408398737		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.8061090408398737 | validation: 0.41703711504138685]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_185.pth
	Model improved!!!
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8441008893022106		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.8441008893022106 | validation: 0.5844962497217039]
	TIME [epoch: 6.26 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8904246410218523		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.8904246410218523 | validation: 0.7351942025370071]
	TIME [epoch: 6.26 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8851700752012226		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.8851700752012226 | validation: 0.5100599846148381]
	TIME [epoch: 6.29 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8318548728082356		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.8318548728082356 | validation: 0.4292714091343577]
	TIME [epoch: 6.3 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8085309712458195		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.8085309712458195 | validation: 0.5339291649328869]
	TIME [epoch: 6.28 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1474934757349262		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 1.1474934757349262 | validation: 0.61417161061646]
	TIME [epoch: 6.28 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9101700490392629		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.9101700490392629 | validation: 0.43643064766222817]
	TIME [epoch: 6.28 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8248661869923017		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.8248661869923017 | validation: 0.47653885753572545]
	TIME [epoch: 6.28 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.869064785345324		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.869064785345324 | validation: 0.5460757162963256]
	TIME [epoch: 6.28 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.872315550401259		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.872315550401259 | validation: 0.49116124839317826]
	TIME [epoch: 6.32 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8160157175627176		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.8160157175627176 | validation: 0.4455035132280494]
	TIME [epoch: 6.29 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9326654309787943		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.9326654309787943 | validation: 0.599739804224212]
	TIME [epoch: 6.28 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9068444118359844		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.9068444118359844 | validation: 0.4942263857706767]
	TIME [epoch: 6.28 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8107776756048604		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.8107776756048604 | validation: 0.47816109981459554]
	TIME [epoch: 6.28 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8652085747252943		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.8652085747252943 | validation: 0.601750972211459]
	TIME [epoch: 6.29 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.862012563835242		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.862012563835242 | validation: 0.45739230942263814]
	TIME [epoch: 6.31 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8203324744830753		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.8203324744830753 | validation: 0.4458724468718086]
	TIME [epoch: 6.29 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8841854411539717		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.8841854411539717 | validation: 0.5006997531147322]
	TIME [epoch: 6.28 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8151504736121691		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.8151504736121691 | validation: 0.42261641269546557]
	TIME [epoch: 6.27 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.848738512959065		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.848738512959065 | validation: 0.54031918431049]
	TIME [epoch: 6.29 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8217795257909727		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.8217795257909727 | validation: 0.42846408182180606]
	TIME [epoch: 6.28 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8221372161901113		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.8221372161901113 | validation: 0.4537199935211342]
	TIME [epoch: 6.32 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9066528583067139		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.9066528583067139 | validation: 0.48977011136122617]
	TIME [epoch: 6.3 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8323977470061555		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.8323977470061555 | validation: 0.46510455352548086]
	TIME [epoch: 6.28 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.799832473281045		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.799832473281045 | validation: 0.46440450386281995]
	TIME [epoch: 6.29 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8613359343802409		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.8613359343802409 | validation: 0.5485348828284701]
	TIME [epoch: 6.28 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8333753187338959		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.8333753187338959 | validation: 0.44211459431004785]
	TIME [epoch: 6.28 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7999329516234035		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.7999329516234035 | validation: 0.4166085455503096]
	TIME [epoch: 6.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_213.pth
	Model improved!!!
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8427061721033251		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.8427061721033251 | validation: 0.43090195953334887]
	TIME [epoch: 6.3 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8279070660600962		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.8279070660600962 | validation: 0.45643418024901383]
	TIME [epoch: 6.26 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8355207426345721		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.8355207426345721 | validation: 0.5178288186539963]
	TIME [epoch: 6.25 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8163857899281116		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.8163857899281116 | validation: 0.5000555686936908]
	TIME [epoch: 6.26 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8573294398234704		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.8573294398234704 | validation: 0.4597866112069301]
	TIME [epoch: 6.26 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9703658260683845		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.9703658260683845 | validation: 0.46962509581933076]
	TIME [epoch: 6.29 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8291601013403459		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.8291601013403459 | validation: 0.40434943667180445]
	TIME [epoch: 6.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_220.pth
	Model improved!!!
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7633813906730562		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.7633813906730562 | validation: 0.41945392895240835]
	TIME [epoch: 6.28 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.784889052795543		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.784889052795543 | validation: 0.4385494849050816]
	TIME [epoch: 6.28 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8501212961936645		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.8501212961936645 | validation: 0.5582517470163195]
	TIME [epoch: 6.29 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8436022347714348		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.8436022347714348 | validation: 0.4447238572477411]
	TIME [epoch: 6.28 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7975940768411165		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.7975940768411165 | validation: 0.43887980241812574]
	TIME [epoch: 6.31 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7925122609695511		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.7925122609695511 | validation: 0.39876251184958605]
	TIME [epoch: 6.32 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_226.pth
	Model improved!!!
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8215873582732623		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.8215873582732623 | validation: 0.4318126656563032]
	TIME [epoch: 6.29 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.815931036204928		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.815931036204928 | validation: 0.4459770987748604]
	TIME [epoch: 6.29 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8169612020977093		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.8169612020977093 | validation: 0.5305274642389206]
	TIME [epoch: 6.29 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8198340138668342		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.8198340138668342 | validation: 0.5550899772209505]
	TIME [epoch: 6.29 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8665688912501357		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.8665688912501357 | validation: 0.4072847106642929]
	TIME [epoch: 6.31 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7895715081343361		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.7895715081343361 | validation: 0.45071647081607646]
	TIME [epoch: 6.32 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.799356199017136		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.799356199017136 | validation: 0.44821817457982993]
	TIME [epoch: 6.28 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8280785261890388		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.8280785261890388 | validation: 0.43414724644129754]
	TIME [epoch: 6.3 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7922843188860799		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.7922843188860799 | validation: 0.43726529144431076]
	TIME [epoch: 6.29 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.779041082782807		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.779041082782807 | validation: 0.44169409351420397]
	TIME [epoch: 6.28 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9356693171029394		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.9356693171029394 | validation: 0.4728625363379724]
	TIME [epoch: 6.3 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8057970966329016		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.8057970966329016 | validation: 0.39248514245270566]
	TIME [epoch: 6.32 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_238.pth
	Model improved!!!
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.789869839436222		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.789869839436222 | validation: 0.43039457591263386]
	TIME [epoch: 6.29 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8430114420772061		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.8430114420772061 | validation: 0.433258115711795]
	TIME [epoch: 6.29 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8251331647634735		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.8251331647634735 | validation: 0.47327942234764553]
	TIME [epoch: 6.28 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7849480213487809		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.7849480213487809 | validation: 0.4220175520650351]
	TIME [epoch: 6.3 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7837528244920138		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.7837528244920138 | validation: 0.40721457660386484]
	TIME [epoch: 6.3 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8169715684954998		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.8169715684954998 | validation: 0.48647540156668756]
	TIME [epoch: 6.35 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8222366832949576		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.8222366832949576 | validation: 0.46977829088319173]
	TIME [epoch: 6.3 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8106019586544372		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.8106019586544372 | validation: 0.49876694594180765]
	TIME [epoch: 6.31 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8059660420501842		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.8059660420501842 | validation: 0.42376939940529945]
	TIME [epoch: 6.28 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0249655341832757		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 1.0249655341832757 | validation: 0.5321389708457338]
	TIME [epoch: 6.29 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7991263438505556		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.7991263438505556 | validation: 0.425764402800287]
	TIME [epoch: 6.31 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7900480713308942		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.7900480713308942 | validation: 0.4254667576731188]
	TIME [epoch: 6.33 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7780818438551835		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.7780818438551835 | validation: 0.3981582012626625]
	TIME [epoch: 6.3 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8546349709516409		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.8546349709516409 | validation: 0.659877541798287]
	TIME [epoch: 6.31 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8639752300310353		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.8639752300310353 | validation: 0.3977606609105536]
	TIME [epoch: 6.28 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9434238834834603		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.9434238834834603 | validation: 1.114060012397954]
	TIME [epoch: 6.31 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.311323283309399		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 1.311323283309399 | validation: 0.7617787205113562]
	TIME [epoch: 6.29 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9403395204474299		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.9403395204474299 | validation: 0.5159574892416903]
	TIME [epoch: 6.34 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8307610038067054		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.8307610038067054 | validation: 0.462764221608158]
	TIME [epoch: 6.29 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8382260601905038		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.8382260601905038 | validation: 0.4538332730044523]
	TIME [epoch: 6.29 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7939664645840492		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.7939664645840492 | validation: 0.393733522657994]
	TIME [epoch: 6.29 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.787878244624804		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.787878244624804 | validation: 0.3989243619679331]
	TIME [epoch: 6.29 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7755758816389952		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.7755758816389952 | validation: 0.41118701747166975]
	TIME [epoch: 6.3 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8111973131493314		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.8111973131493314 | validation: 0.4125759803121213]
	TIME [epoch: 6.33 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7869654890763841		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.7869654890763841 | validation: 0.4124410188030943]
	TIME [epoch: 6.28 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7775101839068745		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.7775101839068745 | validation: 0.3856419972990664]
	TIME [epoch: 6.28 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_264.pth
	Model improved!!!
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7704629637391023		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.7704629637391023 | validation: 0.42011521910813676]
	TIME [epoch: 6.29 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7805885617758471		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.7805885617758471 | validation: 0.42307028281025993]
	TIME [epoch: 6.29 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7859172114733116		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.7859172114733116 | validation: 0.3967244322120259]
	TIME [epoch: 6.3 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7898983681098705		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.7898983681098705 | validation: 0.4654761717485604]
	TIME [epoch: 6.34 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9142498975137118		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.9142498975137118 | validation: 0.5421050761091487]
	TIME [epoch: 6.29 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8167167708278907		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.8167167708278907 | validation: 0.4484048710052833]
	TIME [epoch: 6.28 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.034944861161612		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 1.034944861161612 | validation: 0.4748310422632319]
	TIME [epoch: 6.28 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8410907644052248		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.8410907644052248 | validation: 0.4267773683521698]
	TIME [epoch: 6.28 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7750515002750911		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.7750515002750911 | validation: 0.4112398724968996]
	TIME [epoch: 6.3 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8120202694868891		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.8120202694868891 | validation: 0.39849071754894017]
	TIME [epoch: 6.34 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7858854518131054		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.7858854518131054 | validation: 0.39963381750668514]
	TIME [epoch: 6.31 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7556634014639203		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.7556634014639203 | validation: 0.4626668907013374]
	TIME [epoch: 6.3 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.779139879500196		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.779139879500196 | validation: 0.4100109873393811]
	TIME [epoch: 6.31 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7728365052247653		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.7728365052247653 | validation: 0.42055081347595014]
	TIME [epoch: 6.31 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7671497900511002		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.7671497900511002 | validation: 0.4295424172915128]
	TIME [epoch: 6.3 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7825167451720267		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.7825167451720267 | validation: 0.401881020123089]
	TIME [epoch: 6.34 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.74985930008327		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.74985930008327 | validation: 0.39266110458151776]
	TIME [epoch: 6.32 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7640023322937481		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.7640023322937481 | validation: 0.4587733265950563]
	TIME [epoch: 6.29 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8308534407065217		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.8308534407065217 | validation: 0.4611608168439889]
	TIME [epoch: 6.29 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7714961175921746		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.7714961175921746 | validation: 0.416575928954249]
	TIME [epoch: 6.29 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7915685385110659		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.7915685385110659 | validation: 0.3996158838185666]
	TIME [epoch: 6.3 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.740501132951448		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.740501132951448 | validation: 0.5769588631617647]
	TIME [epoch: 6.33 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.832667286340323		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.832667286340323 | validation: 0.3797199430712184]
	TIME [epoch: 6.32 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_287.pth
	Model improved!!!
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7616964761481678		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.7616964761481678 | validation: 0.37295030269734347]
	TIME [epoch: 6.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_288.pth
	Model improved!!!
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7559187406977919		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.7559187406977919 | validation: 0.43942438076388934]
	TIME [epoch: 6.29 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.81536153915		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.81536153915 | validation: 0.4111170166345307]
	TIME [epoch: 6.29 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7646706282072371		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.7646706282072371 | validation: 0.4652164541946485]
	TIME [epoch: 6.29 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7659172472926814		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.7659172472926814 | validation: 0.41072167247214486]
	TIME [epoch: 6.33 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.771879670836391		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.771879670836391 | validation: 0.3839392485857838]
	TIME [epoch: 6.31 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.82781262954142		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.82781262954142 | validation: 0.3935034868292062]
	TIME [epoch: 6.29 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7853765285867889		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.7853765285867889 | validation: 0.5436436780555796]
	TIME [epoch: 6.29 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8012183789363941		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.8012183789363941 | validation: 0.4620326650735139]
	TIME [epoch: 6.29 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7732101815717071		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.7732101815717071 | validation: 0.578021809526889]
	TIME [epoch: 6.28 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8177797757950289		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.8177797757950289 | validation: 0.391369236209967]
	TIME [epoch: 6.32 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8023073686372655		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.8023073686372655 | validation: 0.4036629236248682]
	TIME [epoch: 6.3 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7809481566575611		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.7809481566575611 | validation: 0.3943846660098056]
	TIME [epoch: 6.29 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7563287906002698		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.7563287906002698 | validation: 0.3972762585043928]
	TIME [epoch: 6.28 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.753681102795766		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.753681102795766 | validation: 0.39564311892083853]
	TIME [epoch: 6.29 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8744830011690475		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.8744830011690475 | validation: 0.37545715489434406]
	TIME [epoch: 6.29 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7699211581175156		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.7699211581175156 | validation: 0.4285736730765857]
	TIME [epoch: 6.31 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.766304858487195		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.766304858487195 | validation: 0.402905229826139]
	TIME [epoch: 6.32 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8022028941998904		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.8022028941998904 | validation: 0.41982036446176474]
	TIME [epoch: 6.3 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7685593802431273		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.7685593802431273 | validation: 0.6297401302953785]
	TIME [epoch: 6.29 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8362728628348656		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.8362728628348656 | validation: 0.406930808018978]
	TIME [epoch: 6.29 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7501393389414142		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.7501393389414142 | validation: 0.40357877711756523]
	TIME [epoch: 6.29 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7572050319367677		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.7572050319367677 | validation: 0.4223571415174173]
	TIME [epoch: 6.31 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7710501623049484		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.7710501623049484 | validation: 0.41195772647161805]
	TIME [epoch: 6.32 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7517898277453517		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.7517898277453517 | validation: 0.3978258121168283]
	TIME [epoch: 6.29 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.777622368974504		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.777622368974504 | validation: 0.3989627795072212]
	TIME [epoch: 6.29 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7985342656487703		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.7985342656487703 | validation: 0.4168125769971229]
	TIME [epoch: 6.29 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7718219424797234		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.7718219424797234 | validation: 0.38055840973333516]
	TIME [epoch: 6.3 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8156277898137934		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.8156277898137934 | validation: 0.40092684546535307]
	TIME [epoch: 6.3 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7989805007257158		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.7989805007257158 | validation: 0.43791368215913795]
	TIME [epoch: 6.33 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7727984253844372		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.7727984253844372 | validation: 0.42356866141123417]
	TIME [epoch: 6.3 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7777418451014898		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.7777418451014898 | validation: 0.4765028123767303]
	TIME [epoch: 6.29 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7933325680213614		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.7933325680213614 | validation: 0.4356314156546853]
	TIME [epoch: 6.3 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7728044641946319		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.7728044641946319 | validation: 0.40582465505044674]
	TIME [epoch: 6.3 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7670002411005384		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.7670002411005384 | validation: 0.40061390791451507]
	TIME [epoch: 6.3 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7858668698664364		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.7858668698664364 | validation: 0.408174338881608]
	TIME [epoch: 6.33 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7835740609493038		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.7835740609493038 | validation: 0.4030576977074508]
	TIME [epoch: 6.3 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7561687837199023		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.7561687837199023 | validation: 0.39414080096704274]
	TIME [epoch: 6.28 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7737256160987975		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.7737256160987975 | validation: 0.4919221152689592]
	TIME [epoch: 6.29 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7889098437944182		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.7889098437944182 | validation: 0.4412265094213148]
	TIME [epoch: 6.29 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.840045791526439		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.840045791526439 | validation: 0.4174840041355821]
	TIME [epoch: 6.3 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8083939318609743		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.8083939318609743 | validation: 0.4404909027399371]
	TIME [epoch: 6.33 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7555734743621922		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.7555734743621922 | validation: 0.4262508405589901]
	TIME [epoch: 6.3 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7483334243147484		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.7483334243147484 | validation: 0.4107336098548441]
	TIME [epoch: 6.3 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7575454696463659		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.7575454696463659 | validation: 0.4043458269069654]
	TIME [epoch: 6.29 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7694295023321299		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.7694295023321299 | validation: 0.39378336443527645]
	TIME [epoch: 6.3 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8229767779844883		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.8229767779844883 | validation: 0.5370924797234965]
	TIME [epoch: 6.29 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8215501377947498		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.8215501377947498 | validation: 0.4042685611863964]
	TIME [epoch: 6.33 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8219739967639313		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.8219739967639313 | validation: 0.5218683482872695]
	TIME [epoch: 6.29 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7735434144303992		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.7735434144303992 | validation: 0.42271385315176724]
	TIME [epoch: 6.29 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.766398516186138		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.766398516186138 | validation: 0.4121740660320899]
	TIME [epoch: 6.29 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7599334382985407		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.7599334382985407 | validation: 0.4025728636736555]
	TIME [epoch: 6.29 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7607284359193989		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.7607284359193989 | validation: 0.4082125703114485]
	TIME [epoch: 6.29 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7828582305687191		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.7828582305687191 | validation: 0.4637701655602155]
	TIME [epoch: 6.33 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.773770907657483		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.773770907657483 | validation: 0.4083027028963402]
	TIME [epoch: 6.3 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7563275682442058		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.7563275682442058 | validation: 0.6729326799935811]
	TIME [epoch: 6.28 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8977320077313307		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.8977320077313307 | validation: 0.4284158714755859]
	TIME [epoch: 6.29 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7612029750695632		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.7612029750695632 | validation: 0.404725574145908]
	TIME [epoch: 6.28 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7544593260975556		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.7544593260975556 | validation: 0.39587637920965113]
	TIME [epoch: 6.28 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.746111073007946		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.746111073007946 | validation: 0.40408827863879215]
	TIME [epoch: 6.32 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7594598059719733		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.7594598059719733 | validation: 0.41391154604343644]
	TIME [epoch: 6.29 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.764530227984706		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.764530227984706 | validation: 0.3772739188806026]
	TIME [epoch: 6.29 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7483862040763596		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.7483862040763596 | validation: 0.5266387311769032]
	TIME [epoch: 6.27 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8271700367903901		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.8271700367903901 | validation: 0.42661320944091796]
	TIME [epoch: 6.28 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7458596262523483		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.7458596262523483 | validation: 0.395363592990701]
	TIME [epoch: 6.28 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7610373638411613		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.7610373638411613 | validation: 0.4496672230991817]
	TIME [epoch: 6.3 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7668219050865284		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.7668219050865284 | validation: 0.40533382571842036]
	TIME [epoch: 6.3 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7594770050964279		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.7594770050964279 | validation: 0.4087232731538664]
	TIME [epoch: 6.28 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7475917404113059		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.7475917404113059 | validation: 0.38904094476772594]
	TIME [epoch: 6.27 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7474518957564548		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.7474518957564548 | validation: 0.4243150634805313]
	TIME [epoch: 6.28 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8120471832072075		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.8120471832072075 | validation: 0.40989257722482886]
	TIME [epoch: 6.28 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7959371635114918		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.7959371635114918 | validation: 0.40688439141649424]
	TIME [epoch: 6.3 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7622232454699511		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.7622232454699511 | validation: 0.4025717860551237]
	TIME [epoch: 6.3 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7628456757635912		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.7628456757635912 | validation: 0.38723737465608077]
	TIME [epoch: 6.28 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7387383554538254		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.7387383554538254 | validation: 0.45150284321093515]
	TIME [epoch: 6.28 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7826109547144747		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.7826109547144747 | validation: 0.3784485333856484]
	TIME [epoch: 6.28 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7478570783864154		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.7478570783864154 | validation: 0.3738643943008705]
	TIME [epoch: 6.28 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7486547394665729		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.7486547394665729 | validation: 0.4192621629138826]
	TIME [epoch: 6.29 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7794341856549079		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.7794341856549079 | validation: 0.3897144949621576]
	TIME [epoch: 6.32 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7306895970895199		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.7306895970895199 | validation: 0.38032239365533627]
	TIME [epoch: 6.28 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7910364467719238		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.7910364467719238 | validation: 0.46304635922596943]
	TIME [epoch: 6.27 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.775754848494004		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.775754848494004 | validation: 0.4159936552917526]
	TIME [epoch: 6.27 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7730841915894472		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.7730841915894472 | validation: 0.4891976821102435]
	TIME [epoch: 6.27 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.833776541249899		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.833776541249899 | validation: 0.41567106316177466]
	TIME [epoch: 6.27 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7589857358125214		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.7589857358125214 | validation: 0.38461041140233]
	TIME [epoch: 6.3 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7448780421100073		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.7448780421100073 | validation: 0.3924619049484678]
	TIME [epoch: 6.27 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7463943227147243		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.7463943227147243 | validation: 0.48531504216449406]
	TIME [epoch: 6.27 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8763397066245026		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.8763397066245026 | validation: 0.455662160761169]
	TIME [epoch: 6.26 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7840923848151509		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.7840923848151509 | validation: 0.4094720148494445]
	TIME [epoch: 6.27 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7529673887534085		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.7529673887534085 | validation: 0.40395052047300645]
	TIME [epoch: 6.27 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7579345700860564		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.7579345700860564 | validation: 0.4079104170063563]
	TIME [epoch: 6.31 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7532092417930899		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.7532092417930899 | validation: 0.38975673649032233]
	TIME [epoch: 6.28 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7524954508011097		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.7524954508011097 | validation: 0.4480586496697504]
	TIME [epoch: 6.27 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7578389860759579		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.7578389860759579 | validation: 0.39353359695323326]
	TIME [epoch: 6.27 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7506718656950104		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.7506718656950104 | validation: 0.4028952891862202]
	TIME [epoch: 6.27 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7665149226689094		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.7665149226689094 | validation: 0.4134727474527688]
	TIME [epoch: 6.28 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7792201900824343		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.7792201900824343 | validation: 0.3720809642482822]
	TIME [epoch: 6.31 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_384.pth
	Model improved!!!
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7408891821919776		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.7408891821919776 | validation: 0.38300360909985787]
	TIME [epoch: 6.27 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7465644588907633		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.7465644588907633 | validation: 0.3851057807871803]
	TIME [epoch: 6.27 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7784404682021083		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.7784404682021083 | validation: 0.3899149262358419]
	TIME [epoch: 6.27 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7475663815445048		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.7475663815445048 | validation: 0.38189412071342344]
	TIME [epoch: 6.27 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7414135666083558		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.7414135666083558 | validation: 0.39982512245420776]
	TIME [epoch: 6.27 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.748516177558278		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.748516177558278 | validation: 0.4127256427360305]
	TIME [epoch: 6.31 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0637688886099743		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 1.0637688886099743 | validation: 0.7341891454671736]
	TIME [epoch: 6.28 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8809307365909052		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.8809307365909052 | validation: 0.4294218779015655]
	TIME [epoch: 6.27 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7714927602714621		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.7714927602714621 | validation: 0.4025157769431145]
	TIME [epoch: 6.27 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7684129641941863		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.7684129641941863 | validation: 0.4509425197820984]
	TIME [epoch: 6.27 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7727048853202709		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.7727048853202709 | validation: 0.3961933170370368]
	TIME [epoch: 6.27 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7893500738366366		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.7893500738366366 | validation: 0.4121774116168633]
	TIME [epoch: 6.31 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.911346162100432		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.911346162100432 | validation: 0.5592722484987616]
	TIME [epoch: 6.28 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8496844003298045		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.8496844003298045 | validation: 0.4168657097869083]
	TIME [epoch: 6.28 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7806393846278797		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.7806393846278797 | validation: 0.4835217743384308]
	TIME [epoch: 6.28 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1896917211079823		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 1.1896917211079823 | validation: 0.44227868658345554]
	TIME [epoch: 6.28 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7657414470288146		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.7657414470288146 | validation: 0.3971313112952784]
	TIME [epoch: 6.27 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7382999592766584		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.7382999592766584 | validation: 0.36535477248932263]
	TIME [epoch: 6.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_402.pth
	Model improved!!!
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7442921473306008		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.7442921473306008 | validation: 0.3798903343578605]
	TIME [epoch: 6.29 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7414821965945639		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.7414821965945639 | validation: 0.3971379485220776]
	TIME [epoch: 6.27 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7380379803077437		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.7380379803077437 | validation: 0.38937110376545037]
	TIME [epoch: 6.28 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7531976860325366		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.7531976860325366 | validation: 0.37927282220483727]
	TIME [epoch: 6.29 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7449085792034896		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.7449085792034896 | validation: 0.3834293748068643]
	TIME [epoch: 6.28 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7456930538986208		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.7456930538986208 | validation: 0.3813185595398114]
	TIME [epoch: 6.32 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7411763419947409		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.7411763419947409 | validation: 0.40662024235628436]
	TIME [epoch: 6.3 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7598631965532094		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.7598631965532094 | validation: 0.3752765594941279]
	TIME [epoch: 6.29 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.760679086998141		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.760679086998141 | validation: 0.389285110096506]
	TIME [epoch: 6.29 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7487493224583782		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.7487493224583782 | validation: 0.3861772678197836]
	TIME [epoch: 6.29 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7394543447054533		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.7394543447054533 | validation: 0.3748233944420047]
	TIME [epoch: 6.3 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7422196557228959		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.7422196557228959 | validation: 0.37773763178978603]
	TIME [epoch: 6.31 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7390230775014178		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.7390230775014178 | validation: 0.40320106936129174]
	TIME [epoch: 6.31 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7528473472005232		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.7528473472005232 | validation: 0.5327054068160366]
	TIME [epoch: 6.29 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7861749778775189		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.7861749778775189 | validation: 0.395755214849429]
	TIME [epoch: 6.29 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7468453966940877		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.7468453966940877 | validation: 0.3884942436547897]
	TIME [epoch: 6.29 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7476444366321201		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.7476444366321201 | validation: 0.3774396645063574]
	TIME [epoch: 6.29 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.740202739383748		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.740202739383748 | validation: 0.3934553602950739]
	TIME [epoch: 6.31 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7413372266300223		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.7413372266300223 | validation: 0.3823330872209131]
	TIME [epoch: 6.32 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7565164741246692		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.7565164741246692 | validation: 0.3746307145091596]
	TIME [epoch: 6.29 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8195623314999432		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.8195623314999432 | validation: 0.4676954528394679]
	TIME [epoch: 6.29 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7590710870396817		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.7590710870396817 | validation: 0.3947358586815798]
	TIME [epoch: 6.29 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7371536577516391		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.7371536577516391 | validation: 0.3665905899166259]
	TIME [epoch: 6.3 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7543154258572171		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.7543154258572171 | validation: 0.39340041977201684]
	TIME [epoch: 6.3 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7524573138679687		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.7524573138679687 | validation: 0.39317940748526287]
	TIME [epoch: 6.33 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7515758268656145		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.7515758268656145 | validation: 0.3917219929838288]
	TIME [epoch: 6.3 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.785976892500882		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.785976892500882 | validation: 0.3673164141842335]
	TIME [epoch: 6.3 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7356663315049208		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.7356663315049208 | validation: 0.3781620885419988]
	TIME [epoch: 6.3 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7437429317779931		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.7437429317779931 | validation: 0.44152650569588703]
	TIME [epoch: 6.3 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7596265843271535		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.7596265843271535 | validation: 0.3850513502286281]
	TIME [epoch: 6.3 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.810584995937713		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.810584995937713 | validation: 0.45492984491069527]
	TIME [epoch: 6.34 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7738058884221242		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.7738058884221242 | validation: 0.4037724867336658]
	TIME [epoch: 6.29 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7449717487070908		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.7449717487070908 | validation: 0.3844801689071367]
	TIME [epoch: 6.29 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.741152043931734		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.741152043931734 | validation: 0.38280621214967503]
	TIME [epoch: 6.3 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7363183754901377		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.7363183754901377 | validation: 0.3853555453707304]
	TIME [epoch: 6.3 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7644555130215167		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.7644555130215167 | validation: 0.41018898198238296]
	TIME [epoch: 6.3 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7469868478659192		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.7469868478659192 | validation: 0.37118990322683704]
	TIME [epoch: 6.32 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7376697770201887		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.7376697770201887 | validation: 0.4047300246740597]
	TIME [epoch: 6.3 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7475364134272149		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.7475364134272149 | validation: 0.39054846623689665]
	TIME [epoch: 6.29 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7431044219272125		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.7431044219272125 | validation: 0.4285287286821864]
	TIME [epoch: 6.27 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7661010272898416		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.7661010272898416 | validation: 0.4056995773245242]
	TIME [epoch: 6.3 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7609649376438137		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.7609649376438137 | validation: 0.39567347489078386]
	TIME [epoch: 6.27 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7693325902872359		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.7693325902872359 | validation: 0.39985707390277087]
	TIME [epoch: 6.33 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7600762069897428		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.7600762069897428 | validation: 0.38832420151401337]
	TIME [epoch: 6.29 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7486966350378754		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.7486966350378754 | validation: 0.39988450703132095]
	TIME [epoch: 6.27 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7426363802556544		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.7426363802556544 | validation: 0.3898705357938327]
	TIME [epoch: 6.27 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7470902646715885		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.7470902646715885 | validation: 0.4093562721774884]
	TIME [epoch: 6.29 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7523761696502633		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.7523761696502633 | validation: 0.390288150051759]
	TIME [epoch: 6.28 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7612304215415008		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.7612304215415008 | validation: 0.44783602746856727]
	TIME [epoch: 6.32 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8234657020009479		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.8234657020009479 | validation: 0.5338352321989417]
	TIME [epoch: 6.26 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8400599262010371		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.8400599262010371 | validation: 0.48878260514463606]
	TIME [epoch: 6.3 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8082846417325401		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.8082846417325401 | validation: 0.4455268392550986]
	TIME [epoch: 6.27 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7631181909496002		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.7631181909496002 | validation: 0.38863687688687615]
	TIME [epoch: 6.26 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7750606372901997		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.7750606372901997 | validation: 0.3935436884607877]
	TIME [epoch: 6.27 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7831573828384913		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.7831573828384913 | validation: 0.4484926854820582]
	TIME [epoch: 6.31 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7581266357620359		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.7581266357620359 | validation: 0.395957257275167]
	TIME [epoch: 6.28 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7709540760303997		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.7709540760303997 | validation: 0.4114196200091429]
	TIME [epoch: 6.28 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.74552271996724		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.74552271996724 | validation: 0.45238341112168345]
	TIME [epoch: 6.27 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7871503460891391		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.7871503460891391 | validation: 0.5311966316265315]
	TIME [epoch: 6.26 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.854756227040854		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.854756227040854 | validation: 0.49992430131694915]
	TIME [epoch: 6.25 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7861266946517462		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.7861266946517462 | validation: 0.4052979009467947]
	TIME [epoch: 6.29 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7389060565388083		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.7389060565388083 | validation: 0.4087385980014586]
	TIME [epoch: 6.28 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7655288471333027		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.7655288471333027 | validation: 0.3732949255816739]
	TIME [epoch: 6.28 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7397193818961183		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.7397193818961183 | validation: 0.39262386957827616]
	TIME [epoch: 6.27 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7470916124945258		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.7470916124945258 | validation: 0.386061891040811]
	TIME [epoch: 6.28 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7386938737123487		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.7386938737123487 | validation: 0.4232793404015943]
	TIME [epoch: 6.27 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7433707798971422		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.7433707798971422 | validation: 0.3767960650041211]
	TIME [epoch: 6.27 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7431521855704417		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.7431521855704417 | validation: 0.37623705117498285]
	TIME [epoch: 6.31 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.728734217310121		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.728734217310121 | validation: 0.38695851335237796]
	TIME [epoch: 6.28 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.765600432895998		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.765600432895998 | validation: 0.395594700802105]
	TIME [epoch: 6.27 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7421246887439285		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.7421246887439285 | validation: 0.41385252702480924]
	TIME [epoch: 6.28 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7583692867068457		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.7583692867068457 | validation: 0.39909849384611024]
	TIME [epoch: 6.27 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7449923941837465		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.7449923941837465 | validation: 0.367494656663222]
	TIME [epoch: 6.27 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7383420919636008		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.7383420919636008 | validation: 0.44220087536121433]
	TIME [epoch: 6.32 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7593467591423435		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.7593467591423435 | validation: 0.36633940768251344]
	TIME [epoch: 6.28 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7333462387467393		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.7333462387467393 | validation: 0.38086480191572225]
	TIME [epoch: 6.27 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7527918312414541		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.7527918312414541 | validation: 0.4030763133881443]
	TIME [epoch: 6.27 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7647870567925257		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.7647870567925257 | validation: 0.4112345200953789]
	TIME [epoch: 6.26 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9626840785853432		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.9626840785853432 | validation: 0.6243530223788806]
	TIME [epoch: 6.29 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8263490741166675		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.8263490741166675 | validation: 0.4038902002952899]
	TIME [epoch: 6.3 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7547280267038023		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.7547280267038023 | validation: 0.3893162103977276]
	TIME [epoch: 6.26 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8036269485822864		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.8036269485822864 | validation: 0.3783260415108885]
	TIME [epoch: 6.27 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7302659951887034		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.7302659951887034 | validation: 0.3789563194614347]
	TIME [epoch: 6.25 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7359270396305914		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.7359270396305914 | validation: 0.4154458942615954]
	TIME [epoch: 6.27 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7362572093552952		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.7362572093552952 | validation: 0.3708526449810959]
	TIME [epoch: 6.28 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7300457526596615		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.7300457526596615 | validation: 0.38236495672150655]
	TIME [epoch: 6.3 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7300194880726711		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.7300194880726711 | validation: 0.36963578923889523]
	TIME [epoch: 6.27 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.731205937329049		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.731205937329049 | validation: 0.3907683988577425]
	TIME [epoch: 6.25 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7310329340542321		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.7310329340542321 | validation: 0.378847332651082]
	TIME [epoch: 6.28 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7845769191394417		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.7845769191394417 | validation: 0.7222994485069425]
	TIME [epoch: 6.26 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.908978992366813		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.908978992366813 | validation: 0.41131328871070727]
	TIME [epoch: 6.28 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7694699690544592		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.7694699690544592 | validation: 0.48815086198834107]
	TIME [epoch: 6.29 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.915911082050411		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.915911082050411 | validation: 0.4177487397938001]
	TIME [epoch: 6.28 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7960149740504826		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.7960149740504826 | validation: 0.46461504382756186]
	TIME [epoch: 6.26 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.81078255127366		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.81078255127366 | validation: 0.4165012117214355]
	TIME [epoch: 6.28 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7600811774279853		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.7600811774279853 | validation: 0.40345400696988787]
	TIME [epoch: 6.27 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7613081766947873		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.7613081766947873 | validation: 0.3922961636838939]
	TIME [epoch: 6.29 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7662679631857418		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.7662679631857418 | validation: 0.49917349053293436]
	TIME [epoch: 6.32 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8111931627686754		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.8111931627686754 | validation: 0.46105751818645796]
	TIME [epoch: 6.26 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7752413535761127		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.7752413535761127 | validation: 0.38375609658995186]
	TIME [epoch: 6.29 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7425366897944152		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.7425366897944152 | validation: 0.40336037071576875]
	TIME [epoch: 6.28 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7661483377594098		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.7661483377594098 | validation: 0.4462421836689998]
	TIME [epoch: 6.28 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8040688586255758		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.8040688586255758 | validation: 0.3898304021266765]
	TIME [epoch: 6.26 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7660485016037512		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.7660485016037512 | validation: 0.5081191383381728]
	TIME [epoch: 6.31 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8274423678633509		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.8274423678633509 | validation: 0.40580529883913696]
	TIME [epoch: 6.28 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7632234064806952		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.7632234064806952 | validation: 0.39588229904695615]
	TIME [epoch: 6.27 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8188949261425307		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.8188949261425307 | validation: 0.42826893042702896]
	TIME [epoch: 6.26 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7670152173905674		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.7670152173905674 | validation: 0.4093900112275204]
	TIME [epoch: 6.27 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7501750275444803		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.7501750275444803 | validation: 0.49081014192480027]
	TIME [epoch: 6.27 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8396124364369045		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.8396124364369045 | validation: 0.4456290175218893]
	TIME [epoch: 6.29 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7848745543435103		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.7848745543435103 | validation: 0.4771873082235282]
	TIME [epoch: 6.27 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7751297761267726		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.7751297761267726 | validation: 0.411559414992498]
	TIME [epoch: 6.28 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8100334348870795		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.8100334348870795 | validation: 0.6610880580828935]
	TIME [epoch: 6.26 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9170095960120441		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.9170095960120441 | validation: 0.41766491080464824]
	TIME [epoch: 6.27 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7689956432710345		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.7689956432710345 | validation: 0.41001048382589533]
	TIME [epoch: 6.26 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7661648709994728		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.7661648709994728 | validation: 0.4033257581631824]
	TIME [epoch: 6.3 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7543478459009665		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.7543478459009665 | validation: 0.3888725875612682]
	TIME [epoch: 6.28 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7501243783092112		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.7501243783092112 | validation: 0.38512970041489025]
	TIME [epoch: 6.27 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7571646946264696		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.7571646946264696 | validation: 0.3966771119569568]
	TIME [epoch: 6.26 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7556835396947564		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.7556835396947564 | validation: 0.38603253409751603]
	TIME [epoch: 6.27 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7408270669438065		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.7408270669438065 | validation: 0.3959213633975421]
	TIME [epoch: 6.26 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7539426519532643		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.7539426519532643 | validation: 0.43582101311017296]
	TIME [epoch: 6.29 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7624031370232965		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.7624031370232965 | validation: 0.3656554036157655]
	TIME [epoch: 6.31 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.733737303437259		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.733737303437259 | validation: 0.3997494887685144]
	TIME [epoch: 6.27 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7407089088350065		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.7407089088350065 | validation: 0.4095887398972256]
	TIME [epoch: 6.26 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7477848707893702		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.7477848707893702 | validation: 0.38641492054969484]
	TIME [epoch: 6.26 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.731574747978776		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.731574747978776 | validation: 0.3832746888282912]
	TIME [epoch: 6.27 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7479680742804817		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.7479680742804817 | validation: 0.37942750410162535]
	TIME [epoch: 6.28 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7781554991327858		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.7781554991327858 | validation: 0.39809470268672087]
	TIME [epoch: 6.31 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7394469020640597		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.7394469020640597 | validation: 0.38063963297542297]
	TIME [epoch: 6.27 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7373226510601039		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.7373226510601039 | validation: 0.37432377543976014]
	TIME [epoch: 6.27 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7391878129007645		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.7391878129007645 | validation: 0.39315421316376786]
	TIME [epoch: 6.27 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.74555250368492		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.74555250368492 | validation: 0.37377923953079684]
	TIME [epoch: 6.26 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7315149716021218		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.7315149716021218 | validation: 0.3751662399082274]
	TIME [epoch: 6.28 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7385311224783816		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.7385311224783816 | validation: 0.3671061940145217]
	TIME [epoch: 6.31 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7276873940576871		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.7276873940576871 | validation: 0.3776968447206974]
	TIME [epoch: 6.26 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7393182160267475		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.7393182160267475 | validation: 0.387283062114968]
	TIME [epoch: 6.26 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7358764742398317		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.7358764742398317 | validation: 0.38034000130878254]
	TIME [epoch: 6.26 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7611342377948781		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.7611342377948781 | validation: 0.40597872080493774]
	TIME [epoch: 6.27 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7651822685916603		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.7651822685916603 | validation: 0.3719352112831127]
	TIME [epoch: 6.29 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7398501205702874		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.7398501205702874 | validation: 0.6234397586404006]
	TIME [epoch: 6.3 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9213780200339324		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.9213780200339324 | validation: 0.4191611562563996]
	TIME [epoch: 6.26 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7520004343464085		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.7520004343464085 | validation: 0.3958678125175439]
	TIME [epoch: 6.28 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7443456208624301		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.7443456208624301 | validation: 0.3915106852277309]
	TIME [epoch: 6.28 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7513114146438852		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.7513114146438852 | validation: 0.43255463144223627]
	TIME [epoch: 6.29 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7885919858155781		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.7885919858155781 | validation: 0.3891229731593574]
	TIME [epoch: 6.28 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7385941741020924		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.7385941741020924 | validation: 0.38606218218269517]
	TIME [epoch: 6.32 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7400557391439493		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.7400557391439493 | validation: 0.3799359933699542]
	TIME [epoch: 6.28 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7862268051349034		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.7862268051349034 | validation: 0.4314095177639754]
	TIME [epoch: 6.27 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7574256962410408		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.7574256962410408 | validation: 0.38262695617653747]
	TIME [epoch: 6.26 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7336202739800688		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.7336202739800688 | validation: 0.4211525734520982]
	TIME [epoch: 6.29 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7575699554450658		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.7575699554450658 | validation: 0.38107539278112423]
	TIME [epoch: 6.27 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7365248545750316		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.7365248545750316 | validation: 0.36747639877485794]
	TIME [epoch: 6.31 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7274657553382677		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.7274657553382677 | validation: 0.3689044233553027]
	TIME [epoch: 6.31 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7400542102982532		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.7400542102982532 | validation: 0.42405515421322265]
	TIME [epoch: 6.27 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7477608998439987		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.7477608998439987 | validation: 0.37547908691848364]
	TIME [epoch: 6.27 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7332715649547827		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.7332715649547827 | validation: 0.4306651225943213]
	TIME [epoch: 6.27 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7863620845074581		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.7863620845074581 | validation: 0.3865331223292303]
	TIME [epoch: 6.27 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7472198054275139		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.7472198054275139 | validation: 0.3830537158181758]
	TIME [epoch: 6.31 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7436142205123084		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.7436142205123084 | validation: 0.38612253014135234]
	TIME [epoch: 6.3 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7397095231159078		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.7397095231159078 | validation: 0.3792092778923192]
	TIME [epoch: 6.29 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7340925969361485		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.7340925969361485 | validation: 0.360255131995818]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_564.pth
	Model improved!!!
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7325389737490495		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.7325389737490495 | validation: 0.3762134564577915]
	TIME [epoch: 6.29 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7290113111594272		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.7290113111594272 | validation: 0.3705095918437755]
	TIME [epoch: 6.28 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7377315712917225		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.7377315712917225 | validation: 0.37760394852158663]
	TIME [epoch: 6.3 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7358695459007627		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.7358695459007627 | validation: 0.3810457341006025]
	TIME [epoch: 6.32 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7336623533762325		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.7336623533762325 | validation: 0.38507550400042484]
	TIME [epoch: 6.27 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.737063479415294		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.737063479415294 | validation: 0.36490134963880894]
	TIME [epoch: 6.3 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7328498094026277		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.7328498094026277 | validation: 0.4008117164746651]
	TIME [epoch: 6.3 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.740210284699536		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.740210284699536 | validation: 0.38020653336182064]
	TIME [epoch: 6.31 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7383163255150677		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.7383163255150677 | validation: 0.363755498565376]
	TIME [epoch: 6.28 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7278870021862704		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.7278870021862704 | validation: 0.38565080886224656]
	TIME [epoch: 6.33 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7584645465212122		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.7584645465212122 | validation: 0.393941365762997]
	TIME [epoch: 6.29 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7635183814851941		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.7635183814851941 | validation: 0.3736627774061114]
	TIME [epoch: 6.3 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7413397940103903		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.7413397940103903 | validation: 0.38077445118844905]
	TIME [epoch: 6.28 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7312118572504316		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.7312118572504316 | validation: 0.36716465170101165]
	TIME [epoch: 6.3 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7470690637351031		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.7470690637351031 | validation: 0.377328501566634]
	TIME [epoch: 6.3 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7305096186025856		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.7305096186025856 | validation: 0.36518687652692333]
	TIME [epoch: 6.33 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7265537613160576		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.7265537613160576 | validation: 0.368228362055132]
	TIME [epoch: 6.3 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.731191501238788		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.731191501238788 | validation: 0.37057518219879954]
	TIME [epoch: 6.29 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.735590581397833		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.735590581397833 | validation: 0.4494903968788436]
	TIME [epoch: 6.29 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7562154802415577		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.7562154802415577 | validation: 0.3753243737055675]
	TIME [epoch: 6.3 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7364532364145008		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.7364532364145008 | validation: 0.380306603692032]
	TIME [epoch: 6.31 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7313981448783843		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.7313981448783843 | validation: 0.3777340065253135]
	TIME [epoch: 6.33 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7608221553598481		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.7608221553598481 | validation: 0.4342012454288266]
	TIME [epoch: 6.29 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7421843726866313		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.7421843726866313 | validation: 0.36721081910620657]
	TIME [epoch: 6.29 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7376667359201234		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.7376667359201234 | validation: 0.3801829451040242]
	TIME [epoch: 6.29 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.736679756455062		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.736679756455062 | validation: 0.3756374964630408]
	TIME [epoch: 6.29 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7333285420515377		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.7333285420515377 | validation: 0.38817555600050535]
	TIME [epoch: 6.28 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7369513743536441		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.7369513743536441 | validation: 0.3831986446948013]
	TIME [epoch: 6.32 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7330509769069949		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.7330509769069949 | validation: 0.42216056740978164]
	TIME [epoch: 6.28 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7687785367802668		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.7687785367802668 | validation: 0.37726996912661803]
	TIME [epoch: 6.27 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7391294806058476		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.7391294806058476 | validation: 0.3769939752466048]
	TIME [epoch: 6.28 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7345602881507001		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.7345602881507001 | validation: 0.38713906315568125]
	TIME [epoch: 6.29 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7426457764382395		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.7426457764382395 | validation: 0.38590609138604315]
	TIME [epoch: 6.28 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7355138958809779		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.7355138958809779 | validation: 0.3734748991371091]
	TIME [epoch: 6.31 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7359472520448419		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.7359472520448419 | validation: 0.37742276096629956]
	TIME [epoch: 6.28 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7380663001504219		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.7380663001504219 | validation: 0.37329270657373315]
	TIME [epoch: 6.28 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7403107856932085		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.7403107856932085 | validation: 0.39282563487499816]
	TIME [epoch: 6.29 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7353969274658387		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.7353969274658387 | validation: 0.3825423505475961]
	TIME [epoch: 6.27 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7311839048071491		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.7311839048071491 | validation: 0.37599280610593844]
	TIME [epoch: 6.29 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7294757697604349		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.7294757697604349 | validation: 0.39139522956717016]
	TIME [epoch: 6.34 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7360839526494437		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.7360839526494437 | validation: 0.392438033945724]
	TIME [epoch: 6.29 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7380051288708953		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.7380051288708953 | validation: 0.370569583664801]
	TIME [epoch: 6.28 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7343812929147268		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.7343812929147268 | validation: 0.37882619779036997]
	TIME [epoch: 6.28 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7361003101183917		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.7361003101183917 | validation: 0.3833909229243957]
	TIME [epoch: 6.27 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7362522246783703		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.7362522246783703 | validation: 0.376732020773575]
	TIME [epoch: 6.27 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.730360170587769		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.730360170587769 | validation: 0.36872731638420875]
	TIME [epoch: 6.31 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.731831416811328		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.731831416811328 | validation: 0.36847578170458106]
	TIME [epoch: 6.3 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7366286000773403		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.7366286000773403 | validation: 0.38649292771717964]
	TIME [epoch: 6.27 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7446774702055169		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.7446774702055169 | validation: 0.3709321008224162]
	TIME [epoch: 6.28 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7328014178298098		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.7328014178298098 | validation: 0.38002755782759634]
	TIME [epoch: 6.26 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7411764601714306		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.7411764601714306 | validation: 0.38709111256145795]
	TIME [epoch: 6.26 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7359086941958991		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.7359086941958991 | validation: 0.39326492858169326]
	TIME [epoch: 6.31 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.732565893092384		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.732565893092384 | validation: 0.3714913698246246]
	TIME [epoch: 6.3 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7439545910840518		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.7439545910840518 | validation: 0.3890549053290007]
	TIME [epoch: 6.27 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7487861247950606		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.7487861247950606 | validation: 0.40136103610559504]
	TIME [epoch: 6.28 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7383947814629854		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.7383947814629854 | validation: 0.3843345935303218]
	TIME [epoch: 6.27 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7952332486818057		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.7952332486818057 | validation: 0.4258125020780649]
	TIME [epoch: 6.28 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7508471454832497		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.7508471454832497 | validation: 0.3753362378324166]
	TIME [epoch: 6.3 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7443322639107709		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.7443322639107709 | validation: 0.41767094640983227]
	TIME [epoch: 6.31 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7487614652786835		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.7487614652786835 | validation: 0.38648803317269537]
	TIME [epoch: 6.28 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.736543077565551		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.736543077565551 | validation: 0.3764029380887105]
	TIME [epoch: 6.28 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7355892583810167		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.7355892583810167 | validation: 0.38100477963561075]
	TIME [epoch: 6.27 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7301366634983067		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.7301366634983067 | validation: 0.3799923239882058]
	TIME [epoch: 6.28 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7383394109452067		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.7383394109452067 | validation: 0.3830578900710836]
	TIME [epoch: 6.29 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7293921803814828		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.7293921803814828 | validation: 0.46548089055677533]
	TIME [epoch: 6.31 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7771636355954984		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.7771636355954984 | validation: 0.36483579823336615]
	TIME [epoch: 6.27 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7334033530193947		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.7334033530193947 | validation: 0.37136811072718007]
	TIME [epoch: 6.28 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7251362582680958		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.7251362582680958 | validation: 0.37426001755440264]
	TIME [epoch: 6.26 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7294383677020295		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.7294383677020295 | validation: 0.374986067156708]
	TIME [epoch: 6.25 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.785330438026761		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.785330438026761 | validation: 0.6493316966638989]
	TIME [epoch: 6.28 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8342690380706099		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.8342690380706099 | validation: 0.37071517437218393]
	TIME [epoch: 6.31 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7386601617192223		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.7386601617192223 | validation: 0.3753057958399765]
	TIME [epoch: 6.26 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7387736610381386		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.7387736610381386 | validation: 0.38256749070753304]
	TIME [epoch: 6.28 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.733652448970522		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.733652448970522 | validation: 0.3832273064481367]
	TIME [epoch: 6.27 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7369001721191519		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.7369001721191519 | validation: 0.4145710971546562]
	TIME [epoch: 6.27 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7662967291796864		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.7662967291796864 | validation: 0.38715804768359685]
	TIME [epoch: 6.28 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7358724907052909		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.7358724907052909 | validation: 0.3723415258141762]
	TIME [epoch: 6.31 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7356974790076766		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.7356974790076766 | validation: 0.3813719803359224]
	TIME [epoch: 6.26 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7353445069269055		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.7353445069269055 | validation: 0.379252928105264]
	TIME [epoch: 6.26 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7323244827915915		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.7323244827915915 | validation: 0.3806070818965871]
	TIME [epoch: 6.26 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7307637702150388		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.7307637702150388 | validation: 0.37486396928068816]
	TIME [epoch: 6.28 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.728446575361746		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.728446575361746 | validation: 0.382986526047973]
	TIME [epoch: 6.26 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7338526762544401		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.7338526762544401 | validation: 0.3710182428872421]
	TIME [epoch: 6.33 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7254449088482577		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.7254449088482577 | validation: 0.36607193798788085]
	TIME [epoch: 6.27 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7251783723339611		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.7251783723339611 | validation: 0.3727548387077095]
	TIME [epoch: 6.26 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7453002288435732		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.7453002288435732 | validation: 0.3827328501709216]
	TIME [epoch: 6.25 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7525778239078652		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.7525778239078652 | validation: 0.36983390147111855]
	TIME [epoch: 6.27 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7294848103828988		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.7294848103828988 | validation: 0.40226519931696125]
	TIME [epoch: 6.26 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7431956169407006		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.7431956169407006 | validation: 0.39542093883600915]
	TIME [epoch: 6.32 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.730593977197377		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.730593977197377 | validation: 0.3774003390568997]
	TIME [epoch: 6.26 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7319973226234673		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.7319973226234673 | validation: 0.37831595189012795]
	TIME [epoch: 6.27 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.728132105332804		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.728132105332804 | validation: 0.3757233877141927]
	TIME [epoch: 6.26 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7302818110140779		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.7302818110140779 | validation: 0.3777284549638834]
	TIME [epoch: 6.27 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7460090805821705		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.7460090805821705 | validation: 0.4044891339033436]
	TIME [epoch: 6.27 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7523285741389676		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.7523285741389676 | validation: 0.36522010760698215]
	TIME [epoch: 6.3 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7328542564602117		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.7328542564602117 | validation: 0.37497722020022]
	TIME [epoch: 6.28 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7324881436339303		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.7324881436339303 | validation: 0.37806569920198446]
	TIME [epoch: 6.26 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7268580749306881		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.7268580749306881 | validation: 0.37023139704643904]
	TIME [epoch: 6.26 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.730054154821604		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.730054154821604 | validation: 0.37120590548704613]
	TIME [epoch: 6.26 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7280203049965824		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.7280203049965824 | validation: 0.36691768948680964]
	TIME [epoch: 6.27 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7233206906473016		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.7233206906473016 | validation: 0.37960738017907164]
	TIME [epoch: 6.31 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7372259181555784		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.7372259181555784 | validation: 0.37796741805367107]
	TIME [epoch: 6.3 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.736020607481806		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.736020607481806 | validation: 0.39119514383702747]
	TIME [epoch: 6.26 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7355855599084415		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.7355855599084415 | validation: 0.37084703999613855]
	TIME [epoch: 6.27 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7237793056659502		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.7237793056659502 | validation: 0.3688345635002199]
	TIME [epoch: 6.27 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7285796900710043		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.7285796900710043 | validation: 0.3731747964672135]
	TIME [epoch: 6.27 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7301460171556292		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.7301460171556292 | validation: 0.3800324059276252]
	TIME [epoch: 6.29 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7378201612677491		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.7378201612677491 | validation: 0.3872992917674999]
	TIME [epoch: 6.3 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7336208862382493		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.7336208862382493 | validation: 0.3823090434449621]
	TIME [epoch: 6.28 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7248720962199899		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.7248720962199899 | validation: 0.37438120455181073]
	TIME [epoch: 6.26 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.731415096146327		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.731415096146327 | validation: 0.36299252772999785]
	TIME [epoch: 6.27 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7273649772324875		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.7273649772324875 | validation: 0.37024571124417055]
	TIME [epoch: 6.28 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7269941255569046		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.7269941255569046 | validation: 0.36887589606589744]
	TIME [epoch: 6.3 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7325287672989549		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.7325287672989549 | validation: 0.3860129143288723]
	TIME [epoch: 6.3 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7780578016166716		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.7780578016166716 | validation: 0.3938442723775648]
	TIME [epoch: 6.27 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7486681806105087		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.7486681806105087 | validation: 0.38098694438225794]
	TIME [epoch: 6.26 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7329966395507035		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.7329966395507035 | validation: 0.3675787843271134]
	TIME [epoch: 6.27 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7289355836453537		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.7289355836453537 | validation: 0.38015758116755044]
	TIME [epoch: 6.27 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7308329699303266		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.7308329699303266 | validation: 0.389361874562949]
	TIME [epoch: 6.29 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7325046210829105		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.7325046210829105 | validation: 0.3603443759458609]
	TIME [epoch: 6.3 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7290763299219634		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.7290763299219634 | validation: 0.3656814706128043]
	TIME [epoch: 6.27 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7271719662207684		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.7271719662207684 | validation: 0.38464032728667275]
	TIME [epoch: 6.27 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7280144715317285		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.7280144715317285 | validation: 0.3620355088264782]
	TIME [epoch: 6.28 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7369646927572955		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.7369646927572955 | validation: 0.3835769398145932]
	TIME [epoch: 6.27 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7316977061018706		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.7316977061018706 | validation: 0.3736283312443335]
	TIME [epoch: 6.28 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7340293901437809		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.7340293901437809 | validation: 0.4532571701122131]
	TIME [epoch: 6.31 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7897266975128145		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.7897266975128145 | validation: 0.39578933088945983]
	TIME [epoch: 6.26 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7382539127289782		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.7382539127289782 | validation: 0.3790633370143426]
	TIME [epoch: 6.27 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7322486673197077		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.7322486673197077 | validation: 0.3744956527914145]
	TIME [epoch: 6.27 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7351763553738634		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.7351763553738634 | validation: 0.41321434727877016]
	TIME [epoch: 6.27 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.763847494278331		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.763847494278331 | validation: 0.39540679471858653]
	TIME [epoch: 6.28 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.742474781805799		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.742474781805799 | validation: 0.3864432256725158]
	TIME [epoch: 6.3 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7412091497290761		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.7412091497290761 | validation: 0.3736444521519021]
	TIME [epoch: 6.27 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7385701559258759		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.7385701559258759 | validation: 0.3765720551273492]
	TIME [epoch: 6.25 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7294886962991255		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.7294886962991255 | validation: 0.3836348749913049]
	TIME [epoch: 6.27 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.73471657961375		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.73471657961375 | validation: 0.37599992550427574]
	TIME [epoch: 6.25 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7303584799164029		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.7303584799164029 | validation: 0.38204864815771544]
	TIME [epoch: 6.28 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7345732654917675		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.7345732654917675 | validation: 0.37875650860569166]
	TIME [epoch: 6.32 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7366633876441674		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.7366633876441674 | validation: 0.3840501124393861]
	TIME [epoch: 6.27 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7322226855917761		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.7322226855917761 | validation: 0.37997652569545864]
	TIME [epoch: 6.27 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7271806931774012		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.7271806931774012 | validation: 0.3721675476098595]
	TIME [epoch: 6.27 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7368922198778038		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.7368922198778038 | validation: 0.3870733916921965]
	TIME [epoch: 6.27 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7410694438410437		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.7410694438410437 | validation: 0.39112424105965915]
	TIME [epoch: 6.27 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7345965956498411		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.7345965956498411 | validation: 0.38853704830382396]
	TIME [epoch: 6.32 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7334273507585186		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.7334273507585186 | validation: 0.3844740673783273]
	TIME [epoch: 6.28 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7258802483921969		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.7258802483921969 | validation: 0.3726011532886426]
	TIME [epoch: 6.27 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7309899319159655		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.7309899319159655 | validation: 0.368791621322608]
	TIME [epoch: 6.27 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7293919762499006		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.7293919762499006 | validation: 0.36357692660277124]
	TIME [epoch: 6.26 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7248179490427363		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.7248179490427363 | validation: 0.38018594147831164]
	TIME [epoch: 6.28 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7500744410116408		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.7500744410116408 | validation: 0.37735055603117096]
	TIME [epoch: 6.3 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7321312659924938		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.7321312659924938 | validation: 0.38491421879101184]
	TIME [epoch: 6.29 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7313141133939608		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.7313141133939608 | validation: 0.3602501879277685]
	TIME [epoch: 6.28 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_716.pth
	Model improved!!!
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7324676103264454		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.7324676103264454 | validation: 0.37910639472331636]
	TIME [epoch: 6.28 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7359822324334137		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.7359822324334137 | validation: 0.3613798066521741]
	TIME [epoch: 6.28 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7255621247836296		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.7255621247836296 | validation: 0.3664295979929645]
	TIME [epoch: 6.29 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.72402037336865		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.72402037336865 | validation: 0.36886476006259444]
	TIME [epoch: 6.31 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7370443915905712		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.7370443915905712 | validation: 0.37073851996352364]
	TIME [epoch: 6.31 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7231938997688955		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.7231938997688955 | validation: 0.37117976300103955]
	TIME [epoch: 6.29 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7339211234036747		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.7339211234036747 | validation: 0.36960236926941376]
	TIME [epoch: 6.27 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7254911017990918		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.7254911017990918 | validation: 0.3733236344281386]
	TIME [epoch: 6.29 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7286287216547759		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.7286287216547759 | validation: 0.4179549409204026]
	TIME [epoch: 6.29 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7517788700020612		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.7517788700020612 | validation: 0.368553370727243]
	TIME [epoch: 6.31 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7364213788016799		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.7364213788016799 | validation: 0.3657035600238663]
	TIME [epoch: 6.33 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7319280886072707		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.7319280886072707 | validation: 0.3718917678254365]
	TIME [epoch: 6.3 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7281749322490569		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.7281749322490569 | validation: 0.38047525999608256]
	TIME [epoch: 6.31 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7270935384840655		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.7270935384840655 | validation: 0.36938167078683964]
	TIME [epoch: 6.31 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.727796795972995		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.727796795972995 | validation: 0.3686723043565559]
	TIME [epoch: 6.31 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7294997577934292		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.7294997577934292 | validation: 0.41981804766581043]
	TIME [epoch: 6.31 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7559415347345557		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.7559415347345557 | validation: 0.37565388144218986]
	TIME [epoch: 6.33 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7310521156573964		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.7310521156573964 | validation: 0.38021884497379066]
	TIME [epoch: 6.31 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7320558069846247		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.7320558069846247 | validation: 0.39959321662517855]
	TIME [epoch: 6.3 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7380984921418655		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.7380984921418655 | validation: 0.3588478986086264]
	TIME [epoch: 6.29 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_736.pth
	Model improved!!!
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7333743426469297		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.7333743426469297 | validation: 0.3644231806227735]
	TIME [epoch: 6.29 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7264502220566715		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.7264502220566715 | validation: 0.3705186197644972]
	TIME [epoch: 6.29 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7252494003661041		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.7252494003661041 | validation: 0.3630060420130979]
	TIME [epoch: 6.32 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7293223012758991		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.7293223012758991 | validation: 0.3678922151367717]
	TIME [epoch: 6.29 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7364123646932001		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.7364123646932001 | validation: 0.3767456974558035]
	TIME [epoch: 6.28 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7250149622160251		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.7250149622160251 | validation: 0.36923248272992804]
	TIME [epoch: 6.29 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.723524315064818		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.723524315064818 | validation: 0.36796002110034587]
	TIME [epoch: 6.28 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7284496201539257		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.7284496201539257 | validation: 0.36702482453035357]
	TIME [epoch: 6.3 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.728012074135218		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.728012074135218 | validation: 0.3734623805376731]
	TIME [epoch: 6.32 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7238159495575719		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.7238159495575719 | validation: 0.3660309744246668]
	TIME [epoch: 6.29 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7279793046277762		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.7279793046277762 | validation: 0.380938604647989]
	TIME [epoch: 6.27 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7303362295202982		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.7303362295202982 | validation: 0.3697182053092499]
	TIME [epoch: 6.26 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7355762764776637		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.7355762764776637 | validation: 0.3767172848174726]
	TIME [epoch: 6.29 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7360349059613187		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.7360349059613187 | validation: 0.37219811761271615]
	TIME [epoch: 6.29 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7383450442224296		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.7383450442224296 | validation: 0.3833160222445199]
	TIME [epoch: 6.33 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7319009996282377		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.7319009996282377 | validation: 0.3661218090170644]
	TIME [epoch: 6.28 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7278457661508371		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.7278457661508371 | validation: 0.37151386810590564]
	TIME [epoch: 6.28 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7356737636782837		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.7356737636782837 | validation: 0.37904315713109166]
	TIME [epoch: 6.27 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7414338006867323		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.7414338006867323 | validation: 0.421794683642986]
	TIME [epoch: 6.28 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7536179030211149		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.7536179030211149 | validation: 0.36398980734644554]
	TIME [epoch: 6.28 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7357896453725712		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.7357896453725712 | validation: 0.3797959160241542]
	TIME [epoch: 6.33 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7283029184370998		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.7283029184370998 | validation: 0.36360662456134574]
	TIME [epoch: 6.27 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7232075581435792		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.7232075581435792 | validation: 0.3633484997774404]
	TIME [epoch: 6.29 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7350062322875853		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.7350062322875853 | validation: 0.3671133716853946]
	TIME [epoch: 6.28 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7240402148415569		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.7240402148415569 | validation: 0.36592270077193534]
	TIME [epoch: 6.28 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.723870393603802		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.723870393603802 | validation: 0.38086195030922526]
	TIME [epoch: 6.27 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7257420458949001		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.7257420458949001 | validation: 0.376679617459273]
	TIME [epoch: 6.31 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7332584176888866		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.7332584176888866 | validation: 0.3863756702008685]
	TIME [epoch: 6.26 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7370063515772872		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.7370063515772872 | validation: 0.3785938958096442]
	TIME [epoch: 6.3 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7272400418363885		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.7272400418363885 | validation: 0.3923146275286717]
	TIME [epoch: 6.28 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7301292134289905		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.7301292134289905 | validation: 0.3662521983085781]
	TIME [epoch: 6.27 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7312772251493265		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.7312772251493265 | validation: 0.36928770729952104]
	TIME [epoch: 6.29 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7278510698079337		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.7278510698079337 | validation: 0.3666446288722361]
	TIME [epoch: 6.3 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7251584113241829		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.7251584113241829 | validation: 0.3639404695717889]
	TIME [epoch: 6.29 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7212757191520657		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.7212757191520657 | validation: 0.38266006839435496]
	TIME [epoch: 6.28 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7389921716728446		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.7389921716728446 | validation: 0.3692766760019854]
	TIME [epoch: 6.3 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7224635661277936		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.7224635661277936 | validation: 0.3716475991393282]
	TIME [epoch: 6.27 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7278991781499753		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.7278991781499753 | validation: 0.3784861906610285]
	TIME [epoch: 6.29 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7321591813025419		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.7321591813025419 | validation: 0.3712534762611404]
	TIME [epoch: 6.32 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7331348879706608		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.7331348879706608 | validation: 0.36991848474660977]
	TIME [epoch: 6.28 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7236857379195222		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.7236857379195222 | validation: 0.3754104635251642]
	TIME [epoch: 6.29 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7248786282613395		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.7248786282613395 | validation: 0.3688052607288776]
	TIME [epoch: 6.27 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7299863331329552		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.7299863331329552 | validation: 0.37851640383758667]
	TIME [epoch: 6.27 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7242675456014888		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.7242675456014888 | validation: 0.36563165130914743]
	TIME [epoch: 6.27 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7259957935516317		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.7259957935516317 | validation: 0.36332757905091034]
	TIME [epoch: 6.3 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7293066839499334		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.7293066839499334 | validation: 0.3760068710297262]
	TIME [epoch: 6.31 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.72519462636764		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.72519462636764 | validation: 0.3844233409812693]
	TIME [epoch: 6.28 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.73320220697865		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.73320220697865 | validation: 0.3642828067836184]
	TIME [epoch: 6.28 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7265922929113812		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.7265922929113812 | validation: 0.3813460192784213]
	TIME [epoch: 6.28 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7280044502378289		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.7280044502378289 | validation: 0.35683462933025595]
	TIME [epoch: 6.29 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_786.pth
	Model improved!!!
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7221134292447979		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.7221134292447979 | validation: 0.36103133758242684]
	TIME [epoch: 6.32 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7265047789177554		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.7265047789177554 | validation: 0.3738522323074281]
	TIME [epoch: 6.3 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7230851665165179		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.7230851665165179 | validation: 0.36081145933768294]
	TIME [epoch: 6.3 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.727040707940685		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.727040707940685 | validation: 0.3696102054738871]
	TIME [epoch: 6.29 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7321954229490139		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.7321954229490139 | validation: 0.36602865898017733]
	TIME [epoch: 6.29 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7247616513504024		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.7247616513504024 | validation: 0.36694806933797613]
	TIME [epoch: 6.3 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7251545270605492		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.7251545270605492 | validation: 0.37321166380979814]
	TIME [epoch: 6.31 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7412861816920235		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.7412861816920235 | validation: 0.3898175359928212]
	TIME [epoch: 6.31 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7367910619799247		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.7367910619799247 | validation: 0.3812095442777391]
	TIME [epoch: 6.29 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7259806657538744		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.7259806657538744 | validation: 0.3606211045893918]
	TIME [epoch: 6.29 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7336961821927922		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.7336961821927922 | validation: 0.3849327855586907]
	TIME [epoch: 6.3 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7482205584319241		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.7482205584319241 | validation: 0.38301123216415867]
	TIME [epoch: 6.29 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7386112773456709		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.7386112773456709 | validation: 0.3676446953694006]
	TIME [epoch: 6.31 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7245140379715603		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.7245140379715603 | validation: 0.35543989069113535]
	TIME [epoch: 6.32 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_800.pth
	Model improved!!!
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7286747395601136		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.7286747395601136 | validation: 0.3670560652186865]
	TIME [epoch: 6.27 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7275099928724935		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.7275099928724935 | validation: 0.3707467615209768]
	TIME [epoch: 6.28 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7255938834170408		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.7255938834170408 | validation: 0.3755268751739455]
	TIME [epoch: 6.28 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7268043734904566		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.7268043734904566 | validation: 0.36594952595276803]
	TIME [epoch: 6.28 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7242667390680855		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.7242667390680855 | validation: 0.3550330440772457]
	TIME [epoch: 6.31 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_805.pth
	Model improved!!!
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7299319935059464		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.7299319935059464 | validation: 0.370862458310151]
	TIME [epoch: 6.32 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7284489929729674		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.7284489929729674 | validation: 0.38197059989939264]
	TIME [epoch: 6.29 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.732407027012953		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.732407027012953 | validation: 0.37245767360675247]
	TIME [epoch: 6.26 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7268293611480519		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.7268293611480519 | validation: 0.36737586044859727]
	TIME [epoch: 6.27 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7273721442073986		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.7273721442073986 | validation: 0.3828494705299492]
	TIME [epoch: 6.27 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7360943786541978		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.7360943786541978 | validation: 0.3746100280460683]
	TIME [epoch: 6.29 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7242905527081693		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.7242905527081693 | validation: 0.36942711802455847]
	TIME [epoch: 6.3 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7328354748896533		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.7328354748896533 | validation: 0.36402027989399355]
	TIME [epoch: 6.28 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7300537488713035		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.7300537488713035 | validation: 0.3681840500040065]
	TIME [epoch: 6.27 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7226776860943799		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.7226776860943799 | validation: 0.3694412073994702]
	TIME [epoch: 6.28 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.725906870874536		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.725906870874536 | validation: 0.36552824770698145]
	TIME [epoch: 6.28 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7255056599034845		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.7255056599034845 | validation: 0.3822752653589818]
	TIME [epoch: 6.3 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7414813547299509		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.7414813547299509 | validation: 0.3895164605698172]
	TIME [epoch: 6.32 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.728623669783022		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.728623669783022 | validation: 0.3646018604495455]
	TIME [epoch: 6.3 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.725235568041551		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.725235568041551 | validation: 0.37210206111158634]
	TIME [epoch: 6.28 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.729879292532031		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.729879292532031 | validation: 0.37017291160970656]
	TIME [epoch: 6.28 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7297943849437291		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.7297943849437291 | validation: 0.37428583020954465]
	TIME [epoch: 6.27 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.721763386706229		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.721763386706229 | validation: 0.37174612731340734]
	TIME [epoch: 6.29 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7223115211464703		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.7223115211464703 | validation: 0.3704454446248184]
	TIME [epoch: 6.32 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7281852563946958		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.7281852563946958 | validation: 0.3667353627088315]
	TIME [epoch: 6.29 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7192509763147992		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.7192509763147992 | validation: 0.366179041563298]
	TIME [epoch: 6.28 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7249069862581109		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.7249069862581109 | validation: 0.3909644903528604]
	TIME [epoch: 6.29 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7267680512157876		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.7267680512157876 | validation: 0.37373590664678924]
	TIME [epoch: 6.29 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.723370139267962		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.723370139267962 | validation: 0.37185267250757]
	TIME [epoch: 6.3 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7278687003454102		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.7278687003454102 | validation: 0.3627587596831287]
	TIME [epoch: 6.32 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7273717205961158		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.7273717205961158 | validation: 0.36888607397550965]
	TIME [epoch: 6.29 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7211737707184408		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.7211737707184408 | validation: 0.38026812462850645]
	TIME [epoch: 6.28 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.727412908069246		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.727412908069246 | validation: 0.3704308937692841]
	TIME [epoch: 6.29 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7246300983206532		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.7246300983206532 | validation: 0.3656997092322719]
	TIME [epoch: 6.28 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7209028586206621		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.7209028586206621 | validation: 0.36966088855943285]
	TIME [epoch: 6.3 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7329815388647152		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.7329815388647152 | validation: 0.385338882838808]
	TIME [epoch: 6.33 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7312183514639781		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.7312183514639781 | validation: 0.37358049886124745]
	TIME [epoch: 6.29 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7283806907487328		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.7283806907487328 | validation: 0.3625978720418837]
	TIME [epoch: 6.29 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.723325506026337		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.723325506026337 | validation: 0.35849852554593675]
	TIME [epoch: 6.29 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7202739599074054		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.7202739599074054 | validation: 0.364106675477751]
	TIME [epoch: 6.28 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7264767764916829		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.7264767764916829 | validation: 0.36768953925650094]
	TIME [epoch: 6.3 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7273036358443372		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.7273036358443372 | validation: 0.377217099939456]
	TIME [epoch: 6.33 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.723939907169719		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.723939907169719 | validation: 0.3721398708857995]
	TIME [epoch: 6.3 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7249140950089183		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.7249140950089183 | validation: 0.3749052379410365]
	TIME [epoch: 6.29 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7246641576831188		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.7246641576831188 | validation: 0.37130600160393995]
	TIME [epoch: 6.28 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7277996875124841		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.7277996875124841 | validation: 0.3726920495054643]
	TIME [epoch: 6.29 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7250443867614044		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.7250443867614044 | validation: 0.37381402933594676]
	TIME [epoch: 6.3 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7342139887666372		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.7342139887666372 | validation: 0.39241266698385213]
	TIME [epoch: 6.33 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7275950912078241		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.7275950912078241 | validation: 0.36098739747832254]
	TIME [epoch: 6.29 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7239770100780716		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.7239770100780716 | validation: 0.36515489952403135]
	TIME [epoch: 6.28 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7211034665265621		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.7211034665265621 | validation: 0.3667557880468976]
	TIME [epoch: 6.29 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7320984963656996		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.7320984963656996 | validation: 0.36521395998686745]
	TIME [epoch: 6.29 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.727181022232321		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.727181022232321 | validation: 0.36360014604340274]
	TIME [epoch: 6.3 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7226094444368056		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.7226094444368056 | validation: 0.3603737162887376]
	TIME [epoch: 6.32 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7236160730080657		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.7236160730080657 | validation: 0.381862070409118]
	TIME [epoch: 6.31 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7405510499667108		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.7405510499667108 | validation: 0.38353582016994414]
	TIME [epoch: 6.29 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7295299687165447		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.7295299687165447 | validation: 0.3712042687822236]
	TIME [epoch: 6.29 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7249139512501559		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.7249139512501559 | validation: 0.3661361467699873]
	TIME [epoch: 6.3 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7258709940102435		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.7258709940102435 | validation: 0.37391227727845233]
	TIME [epoch: 6.28 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7290168772846636		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.7290168772846636 | validation: 0.3667810130048681]
	TIME [epoch: 6.32 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7289433416748559		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.7289433416748559 | validation: 0.3643006864649067]
	TIME [epoch: 6.3 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7236265566282918		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.7236265566282918 | validation: 0.3661174136466012]
	TIME [epoch: 6.28 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7228971952794114		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.7228971952794114 | validation: 0.3695230725710284]
	TIME [epoch: 6.31 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7284251347937916		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.7284251347937916 | validation: 0.3662445465848744]
	TIME [epoch: 6.27 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7270024481673005		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.7270024481673005 | validation: 0.3829527149317924]
	TIME [epoch: 6.28 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7483069782822749		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.7483069782822749 | validation: 0.3606227159815932]
	TIME [epoch: 6.3 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7253898529414199		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.7253898529414199 | validation: 0.3702170534939122]
	TIME [epoch: 6.32 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7188030867019422		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.7188030867019422 | validation: 0.37403184587976135]
	TIME [epoch: 6.27 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7240450975163862		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.7240450975163862 | validation: 0.3693324972821794]
	TIME [epoch: 6.28 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7227784131358446		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.7227784131358446 | validation: 0.37218031848978583]
	TIME [epoch: 6.28 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7270107780250877		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.7270107780250877 | validation: 0.36845136195347467]
	TIME [epoch: 6.28 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7233443332010324		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.7233443332010324 | validation: 0.35824355841873123]
	TIME [epoch: 6.31 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7298737125438547		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.7298737125438547 | validation: 0.3715833908611663]
	TIME [epoch: 6.33 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7276913782819564		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.7276913782819564 | validation: 0.37136184584105064]
	TIME [epoch: 6.29 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.728744811351657		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.728744811351657 | validation: 0.3665503489186952]
	TIME [epoch: 6.29 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7227663559388705		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.7227663559388705 | validation: 0.36823740637260427]
	TIME [epoch: 6.29 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7258535806985291		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.7258535806985291 | validation: 0.3752725787175326]
	TIME [epoch: 6.28 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7319236430554574		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.7319236430554574 | validation: 0.37323355362182237]
	TIME [epoch: 6.3 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7223108592730877		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.7223108592730877 | validation: 0.3589291009739786]
	TIME [epoch: 6.32 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7234266994212515		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.7234266994212515 | validation: 0.37247326220003335]
	TIME [epoch: 6.28 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7294227417607678		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.7294227417607678 | validation: 0.36856661019458437]
	TIME [epoch: 6.28 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7226420619790526		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.7226420619790526 | validation: 0.36147057849159553]
	TIME [epoch: 6.29 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7203928262421597		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.7203928262421597 | validation: 0.37211741983266694]
	TIME [epoch: 6.27 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7213938932276884		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.7213938932276884 | validation: 0.37221367511738584]
	TIME [epoch: 6.29 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7296794737214839		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.7296794737214839 | validation: 0.36703916696109096]
	TIME [epoch: 6.32 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7214256234844146		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.7214256234844146 | validation: 0.37691178976427797]
	TIME [epoch: 6.28 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7254223722230954		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.7254223722230954 | validation: 0.3718412333646945]
	TIME [epoch: 6.28 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7288532209870453		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.7288532209870453 | validation: 0.37663113994215547]
	TIME [epoch: 6.29 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7282951382210858		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.7282951382210858 | validation: 0.3697600565728243]
	TIME [epoch: 6.29 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7198373262774191		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.7198373262774191 | validation: 0.36450690992358065]
	TIME [epoch: 6.3 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7287424724927111		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.7287424724927111 | validation: 0.36230278152987266]
	TIME [epoch: 6.33 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7272459181681514		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.7272459181681514 | validation: 0.36883775478444897]
	TIME [epoch: 6.29 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7403861388488538		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.7403861388488538 | validation: 0.37117171961561723]
	TIME [epoch: 6.29 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.723101122840536		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.723101122840536 | validation: 0.35776614198743073]
	TIME [epoch: 6.29 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7229379639427225		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.7229379639427225 | validation: 0.3600886162843284]
	TIME [epoch: 6.28 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7270444780405293		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.7270444780405293 | validation: 0.36414181783563904]
	TIME [epoch: 6.29 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7280356936736899		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.7280356936736899 | validation: 0.37210812553316835]
	TIME [epoch: 6.33 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7271121630589388		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.7271121630589388 | validation: 0.3767577321263694]
	TIME [epoch: 6.3 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7283652938422663		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.7283652938422663 | validation: 0.38134447911149505]
	TIME [epoch: 6.28 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7239752070169678		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.7239752070169678 | validation: 0.363892225881306]
	TIME [epoch: 6.29 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7246833724043074		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.7246833724043074 | validation: 0.365932941040644]
	TIME [epoch: 6.28 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7217513476893471		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.7217513476893471 | validation: 0.3611238229988681]
	TIME [epoch: 6.28 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.723967680871876		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.723967680871876 | validation: 0.363660877182619]
	TIME [epoch: 6.33 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.723708024712056		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.723708024712056 | validation: 0.37320576997522725]
	TIME [epoch: 6.29 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7280720654704435		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.7280720654704435 | validation: 0.36662886047998633]
	TIME [epoch: 6.28 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7283400670415502		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.7283400670415502 | validation: 0.36451656972216145]
	TIME [epoch: 6.28 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7273621524361968		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.7273621524361968 | validation: 0.37032676591719926]
	TIME [epoch: 6.28 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7256130528655453		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.7256130528655453 | validation: 0.36811998529771495]
	TIME [epoch: 6.29 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7251002806902944		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.7251002806902944 | validation: 0.3610597452449949]
	TIME [epoch: 6.33 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7315035803366502		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.7315035803366502 | validation: 0.3878255094931169]
	TIME [epoch: 6.29 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7366132082208302		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.7366132082208302 | validation: 0.38238191175374703]
	TIME [epoch: 6.29 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7293541252547029		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.7293541252547029 | validation: 0.36837853105837576]
	TIME [epoch: 6.29 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7242531088281422		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.7242531088281422 | validation: 0.37846951624473013]
	TIME [epoch: 6.29 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7382317538873122		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.7382317538873122 | validation: 0.3972235788000607]
	TIME [epoch: 6.29 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7443175459987047		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.7443175459987047 | validation: 0.3773880571349715]
	TIME [epoch: 6.32 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7321338596307465		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.7321338596307465 | validation: 0.3845493046254981]
	TIME [epoch: 6.31 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7356290819687977		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.7356290819687977 | validation: 0.37643956529215483]
	TIME [epoch: 6.29 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7325839484725807		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.7325839484725807 | validation: 0.37411225399884246]
	TIME [epoch: 6.29 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.725330717130116		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.725330717130116 | validation: 0.38341535586470055]
	TIME [epoch: 6.28 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7316358207171174		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.7316358207171174 | validation: 0.37624151257582866]
	TIME [epoch: 6.27 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7335142885814978		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.7335142885814978 | validation: 0.3684800752425632]
	TIME [epoch: 6.32 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7304355250561598		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.7304355250561598 | validation: 0.3719582642483378]
	TIME [epoch: 6.29 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7307004856973423		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.7307004856973423 | validation: 0.3686930118148876]
	TIME [epoch: 6.27 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7266254296476894		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.7266254296476894 | validation: 0.3647936511636439]
	TIME [epoch: 6.28 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7234568138936164		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.7234568138936164 | validation: 0.3732516037632177]
	TIME [epoch: 6.28 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7258930019767024		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.7258930019767024 | validation: 0.3783242794879781]
	TIME [epoch: 6.26 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7357491375670402		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.7357491375670402 | validation: 0.3767563667338393]
	TIME [epoch: 6.3 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.732427332280401		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.732427332280401 | validation: 0.3735973050337503]
	TIME [epoch: 6.32 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.726592585115789		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.726592585115789 | validation: 0.3646166524715706]
	TIME [epoch: 6.27 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7230988771431534		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.7230988771431534 | validation: 0.3702308659770839]
	TIME [epoch: 6.26 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.724680965478708		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.724680965478708 | validation: 0.37026269913632087]
	TIME [epoch: 6.26 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7253463371937658		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.7253463371937658 | validation: 0.3790194698571303]
	TIME [epoch: 6.27 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7273341775691374		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.7273341775691374 | validation: 0.3721475649479126]
	TIME [epoch: 6.31 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7265950519793936		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.7265950519793936 | validation: 0.3669080857153653]
	TIME [epoch: 6.31 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7260001722406851		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.7260001722406851 | validation: 0.3620786973482753]
	TIME [epoch: 6.29 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.725725753109639		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.725725753109639 | validation: 0.3643296227723244]
	TIME [epoch: 6.29 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7289711727762079		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.7289711727762079 | validation: 0.37920489195373197]
	TIME [epoch: 6.29 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7228637751922928		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.7228637751922928 | validation: 0.37253853142087223]
	TIME [epoch: 6.29 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7290720387996948		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.7290720387996948 | validation: 0.37632242369622304]
	TIME [epoch: 6.3 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7288747034179046		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.7288747034179046 | validation: 0.35590355380347927]
	TIME [epoch: 6.32 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7221628781282448		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.7221628781282448 | validation: 0.36846926842091643]
	TIME [epoch: 6.29 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7275391351400441		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.7275391351400441 | validation: 0.37259273529266296]
	TIME [epoch: 6.28 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7331543106370924		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.7331543106370924 | validation: 0.4202133177953553]
	TIME [epoch: 6.27 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.769705636225019		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.769705636225019 | validation: 0.4033857177141271]
	TIME [epoch: 6.28 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7303842723603718		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.7303842723603718 | validation: 0.37952951562611725]
	TIME [epoch: 6.29 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7466276889247325		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.7466276889247325 | validation: 0.3821924621363336]
	TIME [epoch: 6.33 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7413193933929334		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.7413193933929334 | validation: 0.3697658457641473]
	TIME [epoch: 6.27 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7319691914368103		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.7319691914368103 | validation: 0.36961190113493436]
	TIME [epoch: 6.28 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7256385691469822		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.7256385691469822 | validation: 0.373321653770939]
	TIME [epoch: 6.27 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7216109722129563		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.7216109722129563 | validation: 0.3606788997440197]
	TIME [epoch: 6.28 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7220777193667773		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.7220777193667773 | validation: 0.37252178830523563]
	TIME [epoch: 6.29 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7272040979785905		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.7272040979785905 | validation: 0.3702752397268328]
	TIME [epoch: 6.34 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7310872058372024		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.7310872058372024 | validation: 0.3764216314779497]
	TIME [epoch: 6.3 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.726527772250372		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.726527772250372 | validation: 0.3634901695848106]
	TIME [epoch: 6.28 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7257856805911629		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.7257856805911629 | validation: 0.3632578704874422]
	TIME [epoch: 6.28 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.720363301494064		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.720363301494064 | validation: 0.3632412938533396]
	TIME [epoch: 6.28 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.72310348243398		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.72310348243398 | validation: 0.3688692461557923]
	TIME [epoch: 6.29 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7229712957720164		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.7229712957720164 | validation: 0.35948370503807686]
	TIME [epoch: 6.34 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.734507893383005		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.734507893383005 | validation: 0.3802432375983811]
	TIME [epoch: 6.29 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7308395815314227		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.7308395815314227 | validation: 0.375732644394588]
	TIME [epoch: 6.28 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7253875419427169		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.7253875419427169 | validation: 0.36226761552162245]
	TIME [epoch: 6.29 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7238497710960222		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.7238497710960222 | validation: 0.37067988335219604]
	TIME [epoch: 6.28 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7217931726383413		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.7217931726383413 | validation: 0.3762259827937805]
	TIME [epoch: 6.27 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7259480801623501		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.7259480801623501 | validation: 0.368991129950187]
	TIME [epoch: 6.32 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7204633548724285		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.7204633548724285 | validation: 0.37558888136379226]
	TIME [epoch: 6.28 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7237698462808557		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.7237698462808557 | validation: 0.3656788746083719]
	TIME [epoch: 6.29 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7225521357107909		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.7225521357107909 | validation: 0.37184156242247146]
	TIME [epoch: 6.3 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7236180032283657		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.7236180032283657 | validation: 0.3593470822989693]
	TIME [epoch: 6.3 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.722807426293926		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.722807426293926 | validation: 0.3678570978445443]
	TIME [epoch: 6.3 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7282381075252		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.7282381075252 | validation: 0.3766891958760312]
	TIME [epoch: 6.34 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7270511840641497		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.7270511840641497 | validation: 0.3668770489951447]
	TIME [epoch: 6.32 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7274666173042565		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.7274666173042565 | validation: 0.3805087408254818]
	TIME [epoch: 6.31 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.730820597500307		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.730820597500307 | validation: 0.3572301059079517]
	TIME [epoch: 6.3 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7250270690475586		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.7250270690475586 | validation: 0.3635942230218469]
	TIME [epoch: 6.31 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7241804343723948		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.7241804343723948 | validation: 0.36640196329081487]
	TIME [epoch: 6.31 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7273686577729646		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.7273686577729646 | validation: 0.3677674576601576]
	TIME [epoch: 6.34 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7226887505194477		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.7226887505194477 | validation: 0.3736099368653174]
	TIME [epoch: 6.32 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7221078104102338		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.7221078104102338 | validation: 0.3671490020310022]
	TIME [epoch: 6.31 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7248800750401463		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.7248800750401463 | validation: 0.36493709050516154]
	TIME [epoch: 6.31 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.723840042099489		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.723840042099489 | validation: 0.37467154488137017]
	TIME [epoch: 6.31 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7256769886015461		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.7256769886015461 | validation: 0.3703190528316167]
	TIME [epoch: 6.31 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.726021707971459		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.726021707971459 | validation: 0.36658197250186153]
	TIME [epoch: 6.36 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7234050688076198		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.7234050688076198 | validation: 0.3697452078310493]
	TIME [epoch: 6.33 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7247462085125487		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.7247462085125487 | validation: 0.3841280042902287]
	TIME [epoch: 6.32 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7333196837361224		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.7333196837361224 | validation: 0.3698674441625007]
	TIME [epoch: 6.31 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7257651603853618		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.7257651603853618 | validation: 0.36639549810564465]
	TIME [epoch: 6.31 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7255140189406881		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.7255140189406881 | validation: 0.3671918047604806]
	TIME [epoch: 6.31 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.722374272967816		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.722374272967816 | validation: 0.3747241941320213]
	TIME [epoch: 6.33 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7272433454867062		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.7272433454867062 | validation: 0.36278587467045176]
	TIME [epoch: 6.33 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7217048802209183		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.7217048802209183 | validation: 0.3704718213387423]
	TIME [epoch: 6.31 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.72565800595938		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.72565800595938 | validation: 0.3716848539505515]
	TIME [epoch: 6.31 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7216817675522973		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.7216817675522973 | validation: 0.375637878198426]
	TIME [epoch: 6.31 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7204168152395365		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.7204168152395365 | validation: 0.36947143981973024]
	TIME [epoch: 6.3 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7251443739922847		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.7251443739922847 | validation: 0.36316742311427197]
	TIME [epoch: 6.34 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7291236662205759		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.7291236662205759 | validation: 0.37263448990755976]
	TIME [epoch: 6.34 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7222152480970754		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.7222152480970754 | validation: 0.36643231682541033]
	TIME [epoch: 6.31 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7254305450614058		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.7254305450614058 | validation: 0.37242868050230254]
	TIME [epoch: 6.32 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7233601140986202		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.7233601140986202 | validation: 0.3697351512907194]
	TIME [epoch: 6.32 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.725985984985892		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.725985984985892 | validation: 0.3775926048454717]
	TIME [epoch: 6.3 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.732027819538549		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.732027819538549 | validation: 0.3830250412717629]
	TIME [epoch: 6.33 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.732541716206647		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.732541716206647 | validation: 0.3637776250588533]
	TIME [epoch: 6.34 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7254319290635498		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.7254319290635498 | validation: 0.3664394451980826]
	TIME [epoch: 6.32 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7291622870129848		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.7291622870129848 | validation: 0.3714171830254333]
	TIME [epoch: 6.32 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7270626373783238		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.7270626373783238 | validation: 0.3666348239770248]
	TIME [epoch: 6.31 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7283813650591147		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.7283813650591147 | validation: 0.3731905387721842]
	TIME [epoch: 6.32 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7264593989680578		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.7264593989680578 | validation: 0.3644088493628425]
	TIME [epoch: 6.31 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7256465663287535		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.7256465663287535 | validation: 0.3722913891184046]
	TIME [epoch: 6.36 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7297696350129174		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.7297696350129174 | validation: 0.37210252136200267]
	TIME [epoch: 6.31 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7254851362531158		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.7254851362531158 | validation: 0.3696835912629001]
	TIME [epoch: 6.32 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7226280487955362		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.7226280487955362 | validation: 0.3694305847055575]
	TIME [epoch: 6.31 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7231167885724521		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.7231167885724521 | validation: 0.3652895795531238]
	TIME [epoch: 6.31 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7215905450249829		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.7215905450249829 | validation: 0.37185349908511645]
	TIME [epoch: 6.33 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7263654003666833		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.7263654003666833 | validation: 0.36324594658506426]
	TIME [epoch: 6.36 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7232712242785619		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.7232712242785619 | validation: 0.3659271129049831]
	TIME [epoch: 6.31 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7275039093526444		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.7275039093526444 | validation: 0.36734703668297836]
	TIME [epoch: 6.32 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7240120842243428		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.7240120842243428 | validation: 0.36977650414830615]
	TIME [epoch: 6.31 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7247333823958406		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.7247333823958406 | validation: 0.37229072572386823]
	TIME [epoch: 6.31 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7259714889296103		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.7259714889296103 | validation: 0.37021555917253457]
	TIME [epoch: 6.32 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7263218816234333		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.7263218816234333 | validation: 0.3679735542119037]
	TIME [epoch: 6.34 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7268632561698692		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.7268632561698692 | validation: 0.3756948712984031]
	TIME [epoch: 6.32 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7312375466771042		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.7312375466771042 | validation: 0.36561823896072176]
	TIME [epoch: 6.31 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7296208833126999		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.7296208833126999 | validation: 0.3680217876874365]
	TIME [epoch: 6.31 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7264343761770596		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.7264343761770596 | validation: 0.36300463362191243]
	TIME [epoch: 6.31 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7248756758808752		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.7248756758808752 | validation: 0.3699522484198911]
	TIME [epoch: 6.33 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7230592650834309		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.7230592650834309 | validation: 0.3717610128498492]
	TIME [epoch: 6.34 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.722475687447888		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.722475687447888 | validation: 0.3614502106040449]
	TIME [epoch: 6.31 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7249754745830167		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.7249754745830167 | validation: 0.36145537170910497]
	TIME [epoch: 6.31 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7240546443839795		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.7240546443839795 | validation: 0.3634259869127045]
	TIME [epoch: 6.31 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7257269041412088		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.7257269041412088 | validation: 0.3734014963676967]
	TIME [epoch: 6.32 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7249781966667063		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.7249781966667063 | validation: 0.3655803122121606]
	TIME [epoch: 6.32 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7248968860290603		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.7248968860290603 | validation: 0.3584969168694342]
	TIME [epoch: 6.35 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7214687677809778		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.7214687677809778 | validation: 0.36758281183892205]
	TIME [epoch: 6.31 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7260035134669176		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.7260035134669176 | validation: 0.3585895881933581]
	TIME [epoch: 6.31 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7235563760335806		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.7235563760335806 | validation: 0.367473569243329]
	TIME [epoch: 6.31 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7239351987001182		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.7239351987001182 | validation: 0.3580778550342261]
	TIME [epoch: 6.3 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7171760003294253		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.7171760003294253 | validation: 0.3579046910248853]
	TIME [epoch: 6.31 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7236631406389706		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.7236631406389706 | validation: 0.3637691106751895]
	TIME [epoch: 6.35 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7257592025114565		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.7257592025114565 | validation: 0.36207273320103744]
	TIME [epoch: 6.32 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.719534761845693		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.719534761845693 | validation: 0.3696855775700072]
	TIME [epoch: 6.3 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7199819658999731		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.7199819658999731 | validation: 0.3751286207915709]
	TIME [epoch: 6.31 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7202274256840853		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.7202274256840853 | validation: 0.36656489334762987]
	TIME [epoch: 6.31 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7279228120921692		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.7279228120921692 | validation: 0.36344599546565126]
	TIME [epoch: 6.32 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7227466452161573		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.7227466452161573 | validation: 0.36000022268319315]
	TIME [epoch: 6.36 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7234867695416395		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.7234867695416395 | validation: 0.3669229096299898]
	TIME [epoch: 6.33 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7257143769176243		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.7257143769176243 | validation: 0.3723156132936831]
	TIME [epoch: 6.32 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7295240003403045		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.7295240003403045 | validation: 0.369750430132872]
	TIME [epoch: 6.32 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.723638968167		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.723638968167 | validation: 0.35722498924510987]
	TIME [epoch: 6.31 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7247434799659561		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.7247434799659561 | validation: 0.36748500486743524]
	TIME [epoch: 6.31 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7225102057395578		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.7225102057395578 | validation: 0.375619303176674]
	TIME [epoch: 6.36 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7243856535831983		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.7243856535831983 | validation: 0.3672041032156902]
	TIME [epoch: 6.33 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7217067147307357		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.7217067147307357 | validation: 0.36753210435695627]
	TIME [epoch: 6.33 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7236344284186651		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.7236344284186651 | validation: 0.367773738444826]
	TIME [epoch: 6.31 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7287420327346302		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.7287420327346302 | validation: 0.3750713437279955]
	TIME [epoch: 6.32 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7245596919753376		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.7245596919753376 | validation: 0.3675021145408181]
	TIME [epoch: 6.32 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7234643303546392		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.7234643303546392 | validation: 0.37228736331841455]
	TIME [epoch: 6.34 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7221630424408381		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.7221630424408381 | validation: 0.37436810228806305]
	TIME [epoch: 6.33 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7216665303732731		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.7216665303732731 | validation: 0.3628089769700542]
	TIME [epoch: 6.32 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7242010717341872		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.7242010717341872 | validation: 0.3656520018793419]
	TIME [epoch: 6.31 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7254643870297501		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.7254643870297501 | validation: 0.3751880798890557]
	TIME [epoch: 6.32 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7305059732220569		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.7305059732220569 | validation: 0.3665710051072656]
	TIME [epoch: 6.31 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7230070058454273		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.7230070058454273 | validation: 0.36907010231229737]
	TIME [epoch: 6.34 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7272611744038799		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.7272611744038799 | validation: 0.3667381918953838]
	TIME [epoch: 6.33 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7258058481593932		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.7258058481593932 | validation: 0.35980005048406327]
	TIME [epoch: 6.31 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7250417841151747		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.7250417841151747 | validation: 0.36834403866948184]
	TIME [epoch: 6.31 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7205468722279108		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.7205468722279108 | validation: 0.37348588741467037]
	TIME [epoch: 6.31 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7226919276057853		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.7226919276057853 | validation: 0.369714918277743]
	TIME [epoch: 6.3 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7219307987392536		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.7219307987392536 | validation: 0.36249421455114417]
	TIME [epoch: 6.32 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7264404574749409		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.7264404574749409 | validation: 0.36894311770781163]
	TIME [epoch: 6.32 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7215255941132088		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.7215255941132088 | validation: 0.3675854052612787]
	TIME [epoch: 6.3 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7238377233173261		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.7238377233173261 | validation: 0.3589167128016829]
	TIME [epoch: 6.3 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7238790947952042		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.7238790947952042 | validation: 0.36491428361498013]
	TIME [epoch: 6.31 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7220743243913663		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.7220743243913663 | validation: 0.36689874487361257]
	TIME [epoch: 6.29 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7278051696078381		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.7278051696078381 | validation: 0.3650621168977401]
	TIME [epoch: 6.32 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7240534312858556		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.7240534312858556 | validation: 0.37433913832483723]
	TIME [epoch: 6.32 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7242814533350717		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.7242814533350717 | validation: 0.3651942536361682]
	TIME [epoch: 6.29 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7217037835958988		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.7217037835958988 | validation: 0.36477795499904675]
	TIME [epoch: 6.31 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7224808291861343		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.7224808291861343 | validation: 0.37561701121334645]
	TIME [epoch: 6.29 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7273845535256191		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.7273845535256191 | validation: 0.3738180245185204]
	TIME [epoch: 6.3 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7254163171188172		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.7254163171188172 | validation: 0.3636582496690844]
	TIME [epoch: 6.32 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7214472226637365		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.7214472226637365 | validation: 0.36541387052869684]
	TIME [epoch: 6.33 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7194282338056631		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.7194282338056631 | validation: 0.37567368439656157]
	TIME [epoch: 6.31 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7257782899764852		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.7257782899764852 | validation: 0.35748786627070983]
	TIME [epoch: 6.31 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7242464257774675		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.7242464257774675 | validation: 0.36600060197755596]
	TIME [epoch: 6.32 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7217515371044139		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.7217515371044139 | validation: 0.3755888607025607]
	TIME [epoch: 6.31 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7216206635893531		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.7216206635893531 | validation: 0.37662111644192275]
	TIME [epoch: 6.32 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.725285848549139		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.725285848549139 | validation: 0.3779735563549315]
	TIME [epoch: 6.35 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7267135838565877		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.7267135838565877 | validation: 0.37610658295365923]
	TIME [epoch: 6.3 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.731796932377696		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.731796932377696 | validation: 0.36585600566448523]
	TIME [epoch: 6.3 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7248129092367102		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.7248129092367102 | validation: 0.35834280459845785]
	TIME [epoch: 6.3 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7209127662008936		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.7209127662008936 | validation: 0.3593044856877342]
	TIME [epoch: 6.3 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7227090262152446		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.7227090262152446 | validation: 0.36940866260575117]
	TIME [epoch: 6.32 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7279558173713264		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.7279558173713264 | validation: 0.3694348735045242]
	TIME [epoch: 6.34 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7239354687799187		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.7239354687799187 | validation: 0.3535021352347747]
	TIME [epoch: 6.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_1093.pth
	Model improved!!!
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7206504746980223		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.7206504746980223 | validation: 0.3720426897069068]
	TIME [epoch: 6.28 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7193281125145716		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.7193281125145716 | validation: 0.3664316998092229]
	TIME [epoch: 6.29 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7235906888327841		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.7235906888327841 | validation: 0.36502631845850475]
	TIME [epoch: 6.28 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7230337229415869		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.7230337229415869 | validation: 0.3690877941008569]
	TIME [epoch: 6.3 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7226281270529804		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.7226281270529804 | validation: 0.366120190770345]
	TIME [epoch: 6.33 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7240111983796346		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.7240111983796346 | validation: 0.35444857891553283]
	TIME [epoch: 6.28 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7237081826652961		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.7237081826652961 | validation: 0.3680411117804213]
	TIME [epoch: 6.3 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7260559920629575		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.7260559920629575 | validation: 0.3784563465348413]
	TIME [epoch: 6.31 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7259138765618007		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.7259138765618007 | validation: 0.39814078442701845]
	TIME [epoch: 6.31 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7378626645082317		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.7378626645082317 | validation: 0.3777722218667948]
	TIME [epoch: 6.31 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7292824267486727		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.7292824267486727 | validation: 0.3707586744503859]
	TIME [epoch: 6.34 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7215054248900499		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.7215054248900499 | validation: 0.3736042816314077]
	TIME [epoch: 6.32 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.721543369400977		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.721543369400977 | validation: 0.3672756755267767]
	TIME [epoch: 6.31 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7203539254211238		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.7203539254211238 | validation: 0.36997024563104053]
	TIME [epoch: 6.31 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7203227245285626		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.7203227245285626 | validation: 0.36850242769705527]
	TIME [epoch: 6.31 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7234080344078355		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.7234080344078355 | validation: 0.36393232777630635]
	TIME [epoch: 6.31 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7208282919689857		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.7208282919689857 | validation: 0.36015954594306204]
	TIME [epoch: 6.35 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7212612433791189		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.7212612433791189 | validation: 0.36590686762299385]
	TIME [epoch: 6.31 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7219209167377478		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.7219209167377478 | validation: 0.3683118126230371]
	TIME [epoch: 6.3 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.721576344678718		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.721576344678718 | validation: 0.36045075262628534]
	TIME [epoch: 6.31 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7155017643487591		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.7155017643487591 | validation: 0.3654111678844235]
	TIME [epoch: 6.31 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7210734012092089		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.7210734012092089 | validation: 0.3676144026807069]
	TIME [epoch: 6.31 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7195498225699613		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.7195498225699613 | validation: 0.37001435019912937]
	TIME [epoch: 6.35 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7289403292303044		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.7289403292303044 | validation: 0.36301742334712855]
	TIME [epoch: 6.3 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7251260699816344		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.7251260699816344 | validation: 0.363657281895541]
	TIME [epoch: 6.3 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7260929439213971		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.7260929439213971 | validation: 0.3769407438564323]
	TIME [epoch: 6.3 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7214231355080224		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.7214231355080224 | validation: 0.36715253333337783]
	TIME [epoch: 6.3 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7235270814320272		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.7235270814320272 | validation: 0.3644736016645669]
	TIME [epoch: 6.3 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.72805324837713		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.72805324837713 | validation: 0.3665465156606862]
	TIME [epoch: 6.35 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7234416308784535		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.7234416308784535 | validation: 0.365690668786237]
	TIME [epoch: 6.3 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7201228257698541		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.7201228257698541 | validation: 0.3644575754808445]
	TIME [epoch: 6.3 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.721669052927629		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.721669052927629 | validation: 0.36443386793757404]
	TIME [epoch: 6.3 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7230792613318859		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.7230792613318859 | validation: 0.37364209736743814]
	TIME [epoch: 6.29 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7240391693542327		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.7240391693542327 | validation: 0.3754603729775867]
	TIME [epoch: 6.29 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7230546801197284		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.7230546801197284 | validation: 0.36796442632973975]
	TIME [epoch: 6.33 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7228227598174022		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.7228227598174022 | validation: 0.3587530478856334]
	TIME [epoch: 6.31 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.727436509298533		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.727436509298533 | validation: 0.3673585590388346]
	TIME [epoch: 6.3 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7242689331088931		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.7242689331088931 | validation: 0.3664239426041847]
	TIME [epoch: 6.29 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7230492977536483		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.7230492977536483 | validation: 0.36269841599733843]
	TIME [epoch: 6.3 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7215340592917803		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.7215340592917803 | validation: 0.3732938392108778]
	TIME [epoch: 6.31 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7239312543428758		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.7239312543428758 | validation: 0.3698996231123872]
	TIME [epoch: 6.35 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7266546765301849		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.7266546765301849 | validation: 0.3614762077183027]
	TIME [epoch: 6.32 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7264238943783967		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.7264238943783967 | validation: 0.36708618911818514]
	TIME [epoch: 6.29 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7221129965512624		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.7221129965512624 | validation: 0.37097096050512335]
	TIME [epoch: 6.29 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7224534665018354		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.7224534665018354 | validation: 0.36441900003403177]
	TIME [epoch: 6.3 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.720391174932873		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.720391174932873 | validation: 0.35129966732918755]
	TIME [epoch: 6.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_1139.pth
	Model improved!!!
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7192936710183531		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.7192936710183531 | validation: 0.3632307562181312]
	TIME [epoch: 6.33 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7205627727228644		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.7205627727228644 | validation: 0.3539684654080891]
	TIME [epoch: 6.3 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7195665369009656		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.7195665369009656 | validation: 0.3731408169191214]
	TIME [epoch: 6.3 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7212803362148513		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.7212803362148513 | validation: 0.3735235502205661]
	TIME [epoch: 6.29 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7260597458652879		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.7260597458652879 | validation: 0.3692318490897145]
	TIME [epoch: 6.3 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7212660078324753		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.7212660078324753 | validation: 0.36942897557276216]
	TIME [epoch: 6.29 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7274974220255732		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.7274974220255732 | validation: 0.3768955757162256]
	TIME [epoch: 6.33 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7237941986765889		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.7237941986765889 | validation: 0.37158762861257544]
	TIME [epoch: 6.33 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7219703652427227		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.7219703652427227 | validation: 0.3708187174825939]
	TIME [epoch: 6.3 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7210687822834296		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.7210687822834296 | validation: 0.3587162147111185]
	TIME [epoch: 6.31 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.72443699224002		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.72443699224002 | validation: 0.36456359254037124]
	TIME [epoch: 6.32 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7191680829400966		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.7191680829400966 | validation: 0.36707211437209897]
	TIME [epoch: 6.31 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7253266099365354		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.7253266099365354 | validation: 0.3762617726309072]
	TIME [epoch: 6.36 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7307907688175103		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.7307907688175103 | validation: 0.37303818943135625]
	TIME [epoch: 6.33 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7252636935646959		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.7252636935646959 | validation: 0.3734996618672199]
	TIME [epoch: 6.31 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.725681928042498		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.725681928042498 | validation: 0.36237446848318733]
	TIME [epoch: 6.31 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7222881298584944		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.7222881298584944 | validation: 0.3594560895913552]
	TIME [epoch: 6.31 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7193180433799429		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.7193180433799429 | validation: 0.36353699836618336]
	TIME [epoch: 6.31 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7232857578513123		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.7232857578513123 | validation: 0.3648895181163965]
	TIME [epoch: 6.33 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7174828228106301		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.7174828228106301 | validation: 0.35994267077782044]
	TIME [epoch: 6.34 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7176089190847024		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.7176089190847024 | validation: 0.36503088239486015]
	TIME [epoch: 6.32 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7218089240851481		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.7218089240851481 | validation: 0.37263572189451677]
	TIME [epoch: 6.31 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7282449844634431		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.7282449844634431 | validation: 0.3718440368777721]
	TIME [epoch: 6.31 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.721073532862746		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.721073532862746 | validation: 0.3552767970027322]
	TIME [epoch: 6.31 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7205918819654105		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.7205918819654105 | validation: 0.3684554329539039]
	TIME [epoch: 6.33 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7226532294985437		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.7226532294985437 | validation: 0.3563223639754674]
	TIME [epoch: 6.34 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7215900085749505		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.7215900085749505 | validation: 0.3661752986546341]
	TIME [epoch: 6.32 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7239865938431455		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.7239865938431455 | validation: 0.3547086106809454]
	TIME [epoch: 6.31 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7206828228095976		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.7206828228095976 | validation: 0.36841433630754905]
	TIME [epoch: 6.31 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7222748644932414		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.7222748644932414 | validation: 0.37322504912027094]
	TIME [epoch: 6.31 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7208774873197399		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.7208774873197399 | validation: 0.35969185612781884]
	TIME [epoch: 6.33 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7206770070715218		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.7206770070715218 | validation: 0.36119971788475486]
	TIME [epoch: 6.33 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7221159185496258		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.7221159185496258 | validation: 0.36604648393689876]
	TIME [epoch: 6.32 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7251446087378872		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.7251446087378872 | validation: 0.36281074237369004]
	TIME [epoch: 6.31 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.722208643509413		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.722208643509413 | validation: 0.37365593269888303]
	TIME [epoch: 6.31 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7266257212384613		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.7266257212384613 | validation: 0.362499325777483]
	TIME [epoch: 6.31 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7214862584321298		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.7214862584321298 | validation: 0.36371284691098343]
	TIME [epoch: 6.34 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7239266117121537		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.7239266117121537 | validation: 0.37117534800761454]
	TIME [epoch: 6.36 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.722006416495251		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.722006416495251 | validation: 0.36472313767048364]
	TIME [epoch: 6.3 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7214883900123417		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.7214883900123417 | validation: 0.36213322724161934]
	TIME [epoch: 6.32 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7203603714624163		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.7203603714624163 | validation: 0.366301434564885]
	TIME [epoch: 6.3 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7227162869917263		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.7227162869917263 | validation: 0.37283218250904454]
	TIME [epoch: 6.31 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7223394642937928		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.7223394642937928 | validation: 0.3624617447326212]
	TIME [epoch: 6.32 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7232100131641133		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.7232100131641133 | validation: 0.37724179606824626]
	TIME [epoch: 6.36 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7203066263794067		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.7203066263794067 | validation: 0.36367947522820226]
	TIME [epoch: 6.32 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7215394880903642		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.7215394880903642 | validation: 0.3567890098548313]
	TIME [epoch: 6.31 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7154025153369838		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.7154025153369838 | validation: 0.37048345822065065]
	TIME [epoch: 6.3 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7201374371752953		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.7201374371752953 | validation: 0.36526722107978316]
	TIME [epoch: 6.31 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.720365859342372		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.720365859342372 | validation: 0.3585429497474164]
	TIME [epoch: 6.31 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7234421744219304		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.7234421744219304 | validation: 0.3667429405912858]
	TIME [epoch: 6.35 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7193726603747512		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.7193726603747512 | validation: 0.36470322609475847]
	TIME [epoch: 6.3 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7236673068938273		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.7236673068938273 | validation: 0.36961907521606024]
	TIME [epoch: 6.3 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7221629563633191		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.7221629563633191 | validation: 0.37218527672203794]
	TIME [epoch: 6.28 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7179228068558671		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.7179228068558671 | validation: 0.3627536913720618]
	TIME [epoch: 6.31 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7268428063421246		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.7268428063421246 | validation: 0.376887292822699]
	TIME [epoch: 6.29 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7305990863924894		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.7305990863924894 | validation: 0.37452942414931834]
	TIME [epoch: 6.34 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7314497870396016		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.7314497870396016 | validation: 0.3749929635348064]
	TIME [epoch: 6.3 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7202853203818936		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.7202853203818936 | validation: 0.3654568902724083]
	TIME [epoch: 6.3 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7202503668621238		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.7202503668621238 | validation: 0.36718898117188153]
	TIME [epoch: 6.3 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7198154864247536		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.7198154864247536 | validation: 0.3748847928270537]
	TIME [epoch: 6.3 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7218815077455463		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.7218815077455463 | validation: 0.3712126202429035]
	TIME [epoch: 6.31 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7185992612356096		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.7185992612356096 | validation: 0.3605770062403356]
	TIME [epoch: 6.35 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7189924429047558		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.7189924429047558 | validation: 0.3657246287740408]
	TIME [epoch: 6.31 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7191605078120542		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.7191605078120542 | validation: 0.36822341552202426]
	TIME [epoch: 6.3 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7228640943311653		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.7228640943311653 | validation: 0.3613018958569133]
	TIME [epoch: 6.31 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7202034444808569		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.7202034444808569 | validation: 0.36107858994516273]
	TIME [epoch: 6.29 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7216310533116856		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.7216310533116856 | validation: 0.36150451737820366]
	TIME [epoch: 6.31 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7200451798329285		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.7200451798329285 | validation: 0.3703572275411348]
	TIME [epoch: 6.35 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7210529956653052		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.7210529956653052 | validation: 0.37032537665695797]
	TIME [epoch: 6.3 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7184911103446242		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.7184911103446242 | validation: 0.360299602932455]
	TIME [epoch: 6.31 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7203203302410592		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.7203203302410592 | validation: 0.3779697542645267]
	TIME [epoch: 6.31 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7272632482441579		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.7272632482441579 | validation: 0.3680262357413634]
	TIME [epoch: 6.3 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7223742779885709		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.7223742779885709 | validation: 0.3658693889998294]
	TIME [epoch: 6.3 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7232475745375762		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.7232475745375762 | validation: 0.3665505684699527]
	TIME [epoch: 6.36 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7232043696641861		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.7232043696641861 | validation: 0.3639407168873913]
	TIME [epoch: 6.33 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7206966858499233		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.7206966858499233 | validation: 0.37186356741619614]
	TIME [epoch: 6.31 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7188861941135392		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.7188861941135392 | validation: 0.36894363341639574]
	TIME [epoch: 6.31 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7239709813626752		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.7239709813626752 | validation: 0.3645632629482705]
	TIME [epoch: 6.31 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7207032419815333		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.7207032419815333 | validation: 0.37016340888604904]
	TIME [epoch: 6.32 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7226534811615998		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.7226534811615998 | validation: 0.36656386304247024]
	TIME [epoch: 6.36 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7168498566832172		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.7168498566832172 | validation: 0.36924171401830147]
	TIME [epoch: 6.31 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7209884847604549		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.7209884847604549 | validation: 0.36390288931353015]
	TIME [epoch: 6.31 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7201898575981295		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.7201898575981295 | validation: 0.3692167231136697]
	TIME [epoch: 6.32 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7206450697498585		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.7206450697498585 | validation: 0.36592763613806006]
	TIME [epoch: 6.31 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7229067856728802		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.7229067856728802 | validation: 0.3725479636025576]
	TIME [epoch: 6.32 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7253641436296747		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.7253641436296747 | validation: 0.3669983942549684]
	TIME [epoch: 6.36 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.722652859404726		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.722652859404726 | validation: 0.3674695104532842]
	TIME [epoch: 6.33 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7243628728573858		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.7243628728573858 | validation: 0.3696597843806114]
	TIME [epoch: 6.32 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7238408973757354		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.7238408973757354 | validation: 0.3675351691161833]
	TIME [epoch: 6.31 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7212912197804374		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.7212912197804374 | validation: 0.36762008375003935]
	TIME [epoch: 6.32 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7192804740227934		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.7192804740227934 | validation: 0.36507042617039964]
	TIME [epoch: 6.31 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7243697176099885		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.7243697176099885 | validation: 0.37330533561382206]
	TIME [epoch: 6.36 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7199581453880177		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.7199581453880177 | validation: 0.36663090857063146]
	TIME [epoch: 6.34 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7232346768196857		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.7232346768196857 | validation: 0.36403773981330456]
	TIME [epoch: 6.31 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7200337229100523		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.7200337229100523 | validation: 0.35664012824054137]
	TIME [epoch: 6.32 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7209478027359278		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.7209478027359278 | validation: 0.3620108269120583]
	TIME [epoch: 6.3 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7177034491974995		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.7177034491974995 | validation: 0.36659542427020453]
	TIME [epoch: 6.33 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7223728195916093		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.7223728195916093 | validation: 0.36539799340178003]
	TIME [epoch: 6.34 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7200676746188224		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.7200676746188224 | validation: 0.36135999272511654]
	TIME [epoch: 6.34 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7222772230111911		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.7222772230111911 | validation: 0.368805003030502]
	TIME [epoch: 6.32 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7227723617328827		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.7227723617328827 | validation: 0.3632140928017608]
	TIME [epoch: 6.32 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7224146820699404		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.7224146820699404 | validation: 0.3737786403082399]
	TIME [epoch: 6.31 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7243517312396017		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.7243517312396017 | validation: 0.3662539562858642]
	TIME [epoch: 6.3 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7247266199455191		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.7247266199455191 | validation: 0.3595360817179407]
	TIME [epoch: 6.32 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7188203068367751		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.7188203068367751 | validation: 0.3476030824471899]
	TIME [epoch: 6.35 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240311_131333/states/model_phi2_1a_v2_1244.pth
	Model improved!!!
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.72028760492123		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.72028760492123 | validation: 0.3624256190833672]
	TIME [epoch: 6.29 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7196471176075525		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.7196471176075525 | validation: 0.3597277092308726]
	TIME [epoch: 6.3 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7228707886065997		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.7228707886065997 | validation: 0.3661656967273933]
	TIME [epoch: 6.31 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7235055425413413		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.7235055425413413 | validation: 0.35853126909471666]
	TIME [epoch: 6.3 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7217782459257693		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.7217782459257693 | validation: 0.358319332935537]
	TIME [epoch: 6.33 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7168462205743413		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.7168462205743413 | validation: 0.36325533504202373]
	TIME [epoch: 6.34 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7230409950857607		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.7230409950857607 | validation: 0.3652422688438951]
	TIME [epoch: 6.3 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7236293278071592		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.7236293278071592 | validation: 0.37207347066602364]
	TIME [epoch: 6.31 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.723220826000173		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.723220826000173 | validation: 0.3690574647511395]
	TIME [epoch: 6.29 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7271549893325265		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.7271549893325265 | validation: 0.35499815824290487]
	TIME [epoch: 6.3 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7195106528315993		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.7195106528315993 | validation: 0.3614704717207861]
	TIME [epoch: 6.32 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7200422843722811		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.7200422843722811 | validation: 0.36533386292613446]
	TIME [epoch: 6.34 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7224047959744992		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.7224047959744992 | validation: 0.360353672087325]
	TIME [epoch: 6.31 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7215637275657067		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.7215637275657067 | validation: 0.35967069831332543]
	TIME [epoch: 6.31 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7239011318481705		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.7239011318481705 | validation: 0.36839602445682923]
	TIME [epoch: 6.31 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7219564806944245		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.7219564806944245 | validation: 0.36542430370048784]
	TIME [epoch: 6.31 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.720572368675067		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.720572368675067 | validation: 0.36178540464635617]
	TIME [epoch: 6.35 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.719613860957985		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.719613860957985 | validation: 0.36301606653555246]
	TIME [epoch: 6.34 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7174507143637899		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.7174507143637899 | validation: 0.3681263573791915]
	TIME [epoch: 6.33 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7214187081466317		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.7214187081466317 | validation: 0.3626476192299189]
	TIME [epoch: 6.31 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7196604509832732		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.7196604509832732 | validation: 0.36188120136102836]
	TIME [epoch: 6.32 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7212615146550814		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.7212615146550814 | validation: 0.3699048946874364]
	TIME [epoch: 6.32 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7245880697088789		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.7245880697088789 | validation: 0.35961604187563095]
	TIME [epoch: 6.34 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7235395230440669		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.7235395230440669 | validation: 0.3712924837505652]
	TIME [epoch: 6.35 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.722217342229224		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.722217342229224 | validation: 0.3659214792298185]
	TIME [epoch: 6.31 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7245268212986795		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.7245268212986795 | validation: 0.3603089580607639]
	TIME [epoch: 6.31 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.722908802448914		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.722908802448914 | validation: 0.3621761573863568]
	TIME [epoch: 6.31 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7232192090834888		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.7232192090834888 | validation: 0.3668294936775933]
	TIME [epoch: 6.31 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7234251904083312		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.7234251904083312 | validation: 0.3621656115817189]
	TIME [epoch: 6.33 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7225909501244977		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.7225909501244977 | validation: 0.3605512077176822]
	TIME [epoch: 6.35 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7231444237749409		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.7231444237749409 | validation: 0.36719372495044583]
	TIME [epoch: 6.31 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7183704523953633		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.7183704523953633 | validation: 0.3604508557696336]
	TIME [epoch: 6.32 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7254378539564632		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.7254378539564632 | validation: 0.3654749885365251]
	TIME [epoch: 6.31 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7204898844283046		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.7204898844283046 | validation: 0.36235993045631437]
	TIME [epoch: 6.32 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7213228290358757		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.7213228290358757 | validation: 0.3679704457579393]
	TIME [epoch: 6.33 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7220831332583857		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.7220831332583857 | validation: 0.36901141793218317]
	TIME [epoch: 6.36 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7217230654329941		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.7217230654329941 | validation: 0.3621481561625147]
	TIME [epoch: 6.33 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7200730224370373		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.7200730224370373 | validation: 0.36901059917835]
	TIME [epoch: 6.33 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7198714988470137		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.7198714988470137 | validation: 0.36528668693227556]
	TIME [epoch: 6.32 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7228193264055846		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.7228193264055846 | validation: 0.3614399768010309]
	TIME [epoch: 6.32 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7223165221859768		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.7223165221859768 | validation: 0.3581622861083907]
	TIME [epoch: 6.34 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7198804032856374		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.7198804032856374 | validation: 0.36317395195039276]
	TIME [epoch: 6.37 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7228002271501286		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.7228002271501286 | validation: 0.3631773993963958]
	TIME [epoch: 6.33 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7191665107785257		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.7191665107785257 | validation: 0.3590859583326207]
	TIME [epoch: 6.32 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.72377183015785		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.72377183015785 | validation: 0.3671282511473027]
	TIME [epoch: 6.31 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7189502622941305		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.7189502622941305 | validation: 0.3631557035245872]
	TIME [epoch: 6.32 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7216972304955166		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.7216972304955166 | validation: 0.36145969939877776]
	TIME [epoch: 6.33 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7213768100503724		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.7213768100503724 | validation: 0.37268095939990264]
	TIME [epoch: 6.36 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7204286706498982		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.7204286706498982 | validation: 0.36321897191223984]
	TIME [epoch: 6.33 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.718295567979089		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.718295567979089 | validation: 0.3747066214418763]
	TIME [epoch: 6.51 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.720053888667002		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.720053888667002 | validation: 0.36240408098614085]
	TIME [epoch: 6.33 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7205244582475459		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.7205244582475459 | validation: 0.35679266519733727]
	TIME [epoch: 6.33 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7210348725744611		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.7210348725744611 | validation: 0.36104958412545807]
	TIME [epoch: 6.32 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7244958305589211		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.7244958305589211 | validation: 0.3622461279710656]
	TIME [epoch: 6.36 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7228998332912882		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.7228998332912882 | validation: 0.36399385856240907]
	TIME [epoch: 6.32 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7196902461403532		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.7196902461403532 | validation: 0.3698795929871499]
	TIME [epoch: 6.31 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7197620778196927		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.7197620778196927 | validation: 0.3557491949771979]
	TIME [epoch: 6.32 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7234396227628339		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.7234396227628339 | validation: 0.37361689425310246]
	TIME [epoch: 6.31 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7228875294981838		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.7228875294981838 | validation: 0.3640321295589515]
	TIME [epoch: 6.33 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.722033306849973		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.722033306849973 | validation: 0.3606558091313311]
	TIME [epoch: 6.35 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7227798731337014		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.7227798731337014 | validation: 0.36659098918176763]
	TIME [epoch: 6.32 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7202570034490277		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.7202570034490277 | validation: 0.3630403524790725]
	TIME [epoch: 6.31 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7309946794336364		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.7309946794336364 | validation: 0.360308712470538]
	TIME [epoch: 6.31 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7247612057084635		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.7247612057084635 | validation: 0.36800692787644224]
	TIME [epoch: 6.3 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7282222110200952		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.7282222110200952 | validation: 0.36830691664826537]
	TIME [epoch: 6.32 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7215622563900922		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.7215622563900922 | validation: 0.36308962470796136]
	TIME [epoch: 6.36 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.722435765360685		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.722435765360685 | validation: 0.35862717512108094]
	TIME [epoch: 6.33 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7243254955819867		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.7243254955819867 | validation: 0.3639524406811853]
	TIME [epoch: 6.31 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.718657322760989		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.718657322760989 | validation: 0.3573626881374432]
	TIME [epoch: 6.31 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7223977836201563		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.7223977836201563 | validation: 0.36459583422698416]
	TIME [epoch: 6.31 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7245279502762545		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.7245279502762545 | validation: 0.36848418158622]
	TIME [epoch: 6.32 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7260872843888129		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.7260872843888129 | validation: 0.3757249762039765]
	TIME [epoch: 6.36 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7277387832419896		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.7277387832419896 | validation: 0.37125268065228834]
	TIME [epoch: 6.32 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7254509610455285		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.7254509610455285 | validation: 0.37384768992695583]
	TIME [epoch: 6.31 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7233178231584898		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.7233178231584898 | validation: 0.3683110384889372]
	TIME [epoch: 6.31 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7235345261732404		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.7235345261732404 | validation: 0.3613224726630304]
	TIME [epoch: 6.31 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7185584381301835		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.7185584381301835 | validation: 0.36424887830159836]
	TIME [epoch: 6.31 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7249966422300682		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.7249966422300682 | validation: 0.3608192542379603]
	TIME [epoch: 6.37 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7226180721850481		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.7226180721850481 | validation: 0.3675047734295606]
	TIME [epoch: 6.31 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7215945763920367		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.7215945763920367 | validation: 0.3597868501806364]
	TIME [epoch: 6.32 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7191231299761889		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.7191231299761889 | validation: 0.3685665669978599]
	TIME [epoch: 6.32 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7236202885164275		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.7236202885164275 | validation: 0.36171940282778847]
	TIME [epoch: 6.31 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.722821827948577		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.722821827948577 | validation: 0.3725233297055761]
	TIME [epoch: 6.33 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7234728625907608		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.7234728625907608 | validation: 0.36175600875521163]
	TIME [epoch: 6.37 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7198437503484144		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.7198437503484144 | validation: 0.36378491907831667]
	TIME [epoch: 6.34 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7200989479362216		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.7200989479362216 | validation: 0.3655450552629898]
	TIME [epoch: 6.33 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7214332777688652		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.7214332777688652 | validation: 0.3594008112113202]
	TIME [epoch: 6.31 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7182057524915013		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.7182057524915013 | validation: 0.35958055305849873]
	TIME [epoch: 6.32 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7228017229637567		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.7228017229637567 | validation: 0.35361632996988795]
	TIME [epoch: 6.33 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7236386506897783		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.7236386506897783 | validation: 0.3667637235134237]
	TIME [epoch: 6.35 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7196689770352547		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.7196689770352547 | validation: 0.3704890128211847]
	TIME [epoch: 6.33 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7202457281555948		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.7202457281555948 | validation: 0.37429701312589275]
	TIME [epoch: 6.32 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7199680523379015		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.7199680523379015 | validation: 0.3760315099855037]
	TIME [epoch: 6.32 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7230705444425716		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.7230705444425716 | validation: 0.36764937140651277]
	TIME [epoch: 6.32 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7187756883979425		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.7187756883979425 | validation: 0.37107696914914734]
	TIME [epoch: 6.33 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7216328953610588		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.7216328953610588 | validation: 0.36115253585858276]
	TIME [epoch: 6.35 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7199117650509795		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.7199117650509795 | validation: 0.36771641806227784]
	TIME [epoch: 6.33 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7171330655833593		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.7171330655833593 | validation: 0.3659119739444418]
	TIME [epoch: 6.32 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7209691808469034		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.7209691808469034 | validation: 0.36644604820815196]
	TIME [epoch: 6.31 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7205357302824493		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.7205357302824493 | validation: 0.3637191144232128]
	TIME [epoch: 6.31 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7202028702225904		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.7202028702225904 | validation: 0.36453927053361806]
	TIME [epoch: 6.31 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.71775687658046		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.71775687658046 | validation: 0.3681960944045139]
	TIME [epoch: 6.35 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.718270302442903		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.718270302442903 | validation: 0.3703921632355958]
	TIME [epoch: 6.36 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7161936523836209		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.7161936523836209 | validation: 0.3625857168794497]
	TIME [epoch: 6.31 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7220848209967516		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.7220848209967516 | validation: 0.36591692003339743]
	TIME [epoch: 6.31 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7250379504234099		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.7250379504234099 | validation: 0.3656641836272675]
	TIME [epoch: 6.32 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7245531418359352		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.7245531418359352 | validation: 0.3619717258725744]
	TIME [epoch: 6.32 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7226872515691466		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.7226872515691466 | validation: 0.3578009615210819]
	TIME [epoch: 6.35 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7205404030957127		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.7205404030957127 | validation: 0.3637659750551262]
	TIME [epoch: 6.36 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7237844770861114		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.7237844770861114 | validation: 0.365695629681088]
	TIME [epoch: 6.32 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7216760312001983		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.7216760312001983 | validation: 0.3616180006540676]
	TIME [epoch: 6.33 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.719365376105393		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.719365376105393 | validation: 0.36021183754510944]
	TIME [epoch: 6.33 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7252076374761287		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.7252076374761287 | validation: 0.37581844605549286]
	TIME [epoch: 6.33 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.722703873861381		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.722703873861381 | validation: 0.36638826853368456]
	TIME [epoch: 6.35 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7216043960606451		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.7216043960606451 | validation: 0.37525501290034113]
	TIME [epoch: 6.36 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.721106370699495		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.721106370699495 | validation: 0.3612059852789096]
	TIME [epoch: 6.32 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7196378063751889		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.7196378063751889 | validation: 0.36058529448731247]
	TIME [epoch: 6.32 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7196121579546905		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.7196121579546905 | validation: 0.35712231850071463]
	TIME [epoch: 6.33 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7214014793883525		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.7214014793883525 | validation: 0.37558262460989994]
	TIME [epoch: 6.32 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7231855336028544		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.7231855336028544 | validation: 0.3670015628980278]
	TIME [epoch: 6.34 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7214350003984358		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.7214350003984358 | validation: 0.36762512470664466]
	TIME [epoch: 6.35 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7230917981289364		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.7230917981289364 | validation: 0.35847670025759737]
	TIME [epoch: 6.32 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7195540092356576		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.7195540092356576 | validation: 0.3534775377910563]
	TIME [epoch: 6.34 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7200058677973614		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.7200058677973614 | validation: 0.3656665245436611]
	TIME [epoch: 6.32 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7204260528742173		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.7204260528742173 | validation: 0.3650584926086222]
	TIME [epoch: 6.33 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7195648928026062		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.7195648928026062 | validation: 0.37195944284372284]
	TIME [epoch: 6.34 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7182793483410655		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.7182793483410655 | validation: 0.35799584452357314]
	TIME [epoch: 6.36 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7156774171620115		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.7156774171620115 | validation: 0.3554733158047653]
	TIME [epoch: 6.33 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.719350605103747		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.719350605103747 | validation: 0.3701258402365323]
	TIME [epoch: 6.32 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7226560874393827		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.7226560874393827 | validation: 0.35350333069745776]
	TIME [epoch: 6.33 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7217218260776711		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.7217218260776711 | validation: 0.35876454680482117]
	TIME [epoch: 6.31 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7206246323127388		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.7206246323127388 | validation: 0.365973140308212]
	TIME [epoch: 6.33 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7208721233529007		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.7208721233529007 | validation: 0.3591163243605378]
	TIME [epoch: 6.36 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7158716301400591		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.7158716301400591 | validation: 0.3632563149407813]
	TIME [epoch: 6.31 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7206840995573991		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.7206840995573991 | validation: 0.3610019769643963]
	TIME [epoch: 6.3 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7241428704283545		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.7241428704283545 | validation: 0.3549790274129781]
	TIME [epoch: 6.3 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7254721663564051		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.7254721663564051 | validation: 0.37221721344099173]
	TIME [epoch: 6.3 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7237589844606059		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.7237589844606059 | validation: 0.3626257340796634]
	TIME [epoch: 6.32 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7224495329953136		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.7224495329953136 | validation: 0.3570911648640719]
	TIME [epoch: 6.35 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7203128234987604		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.7203128234987604 | validation: 0.370925299785094]
	TIME [epoch: 6.31 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7238314606228984		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.7238314606228984 | validation: 0.3524554839481375]
	TIME [epoch: 6.29 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7226289227726411		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.7226289227726411 | validation: 0.36778159822432205]
	TIME [epoch: 6.31 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.720014930827803		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.720014930827803 | validation: 0.3588178666990632]
	TIME [epoch: 6.31 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7194545965809203		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.7194545965809203 | validation: 0.374247312556968]
	TIME [epoch: 6.33 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7220742394376574		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.7220742394376574 | validation: 0.3672565414438742]
	TIME [epoch: 6.35 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7234922474147878		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.7234922474147878 | validation: 0.36799771441892726]
	TIME [epoch: 6.32 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.720927229349855		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.720927229349855 | validation: 0.3574076305925109]
	TIME [epoch: 6.31 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.721051081947029		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.721051081947029 | validation: 0.37265033485667554]
	TIME [epoch: 6.32 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7248300135678011		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.7248300135678011 | validation: 0.3667558149844476]
	TIME [epoch: 6.32 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.723830857729916		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.723830857729916 | validation: 0.3654054862846897]
	TIME [epoch: 6.34 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7214476548320106		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.7214476548320106 | validation: 0.3604706157268119]
	TIME [epoch: 6.37 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7184661329934912		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.7184661329934912 | validation: 0.36034668059271624]
	TIME [epoch: 6.32 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7199136559192979		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.7199136559192979 | validation: 0.36985410095088633]
	TIME [epoch: 6.32 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7209393585710103		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.7209393585710103 | validation: 0.3632089886428402]
	TIME [epoch: 6.32 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.724748563748578		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.724748563748578 | validation: 0.37033190504839064]
	TIME [epoch: 6.32 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7187472329968447		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.7187472329968447 | validation: 0.3650730888178279]
	TIME [epoch: 6.32 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7200733912223036		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.7200733912223036 | validation: 0.3632371910091988]
	TIME [epoch: 6.36 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7214333178315937		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.7214333178315937 | validation: 0.363086421161539]
	TIME [epoch: 6.33 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7190367019862905		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.7190367019862905 | validation: 0.36165845405686425]
	TIME [epoch: 6.31 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7226507516955741		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.7226507516955741 | validation: 0.3697188653667312]
	TIME [epoch: 6.32 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7227559702778776		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.7227559702778776 | validation: 0.36905887048879776]
	TIME [epoch: 6.31 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7195634328891132		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.7195634328891132 | validation: 0.3657347899099853]
	TIME [epoch: 6.32 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7242146435897254		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.7242146435897254 | validation: 0.37335057098764757]
	TIME [epoch: 6.35 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7203268452118808		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.7203268452118808 | validation: 0.3655688123731763]
	TIME [epoch: 6.32 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7213515353031863		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.7213515353031863 | validation: 0.36591564729599274]
	TIME [epoch: 6.31 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7202958928791745		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.7202958928791745 | validation: 0.36539380073713446]
	TIME [epoch: 6.33 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7216428003414604		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.7216428003414604 | validation: 0.36429609400725216]
	TIME [epoch: 6.3 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7200868731893137		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.7200868731893137 | validation: 0.35966477884467696]
	TIME [epoch: 6.31 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7187359132266586		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.7187359132266586 | validation: 0.3639728335373352]
	TIME [epoch: 6.36 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7216236530546505		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.7216236530546505 | validation: 0.3595548765354039]
	TIME [epoch: 6.32 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7191707790394107		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.7191707790394107 | validation: 0.3575024995329632]
	TIME [epoch: 6.32 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7227968681507734		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.7227968681507734 | validation: 0.3647734091940083]
	TIME [epoch: 6.29 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7192764889298975		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.7192764889298975 | validation: 0.37032098679653697]
	TIME [epoch: 6.3 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7220162367419876		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.7220162367419876 | validation: 0.3641287655091122]
	TIME [epoch: 6.31 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.721315785436347		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.721315785436347 | validation: 0.3710529741704648]
	TIME [epoch: 6.36 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7206867191527206		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.7206867191527206 | validation: 0.3701834352761121]
	TIME [epoch: 6.32 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7237860227656427		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.7237860227656427 | validation: 0.36063452627158304]
	TIME [epoch: 6.31 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7218684070449484		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.7218684070449484 | validation: 0.36999771357864947]
	TIME [epoch: 6.32 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7234715736322278		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.7234715736322278 | validation: 0.3714505181960621]
	TIME [epoch: 6.32 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7217324213101818		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.7217324213101818 | validation: 0.37224688125123334]
	TIME [epoch: 6.32 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7218741985201507		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.7218741985201507 | validation: 0.3687303321679393]
	TIME [epoch: 6.37 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7197141448137576		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.7197141448137576 | validation: 0.3590678002793702]
	TIME [epoch: 6.33 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7191367116385453		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.7191367116385453 | validation: 0.35457925320527267]
	TIME [epoch: 6.32 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7227918668723223		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.7227918668723223 | validation: 0.35646173204075615]
	TIME [epoch: 6.31 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.720114158402619		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.720114158402619 | validation: 0.37252522578650193]
	TIME [epoch: 6.31 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7243409594844674		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.7243409594844674 | validation: 0.35779093557962327]
	TIME [epoch: 6.3 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7178791740106392		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.7178791740106392 | validation: 0.36562251411230023]
	TIME [epoch: 6.35 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7269181653208248		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.7269181653208248 | validation: 0.3696547017841283]
	TIME [epoch: 6.33 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7214964515303932		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.7214964515303932 | validation: 0.3551633360473981]
	TIME [epoch: 6.31 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7193106435803819		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.7193106435803819 | validation: 0.36508409971880235]
	TIME [epoch: 6.31 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7237098910570798		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.7237098910570798 | validation: 0.3642230440471449]
	TIME [epoch: 6.32 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7207302893869285		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.7207302893869285 | validation: 0.3586093395091855]
	TIME [epoch: 6.32 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7235308834463965		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.7235308834463965 | validation: 0.3663459541980692]
	TIME [epoch: 6.34 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7243939586998215		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.7243939586998215 | validation: 0.3617851057135937]
	TIME [epoch: 6.32 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7248745002955299		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.7248745002955299 | validation: 0.37069008017302246]
	TIME [epoch: 6.32 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.726127260346449		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.726127260346449 | validation: 0.36626374866948813]
	TIME [epoch: 6.3 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7225067650453871		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.7225067650453871 | validation: 0.3706585146469207]
	TIME [epoch: 6.3 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7269984166399073		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.7269984166399073 | validation: 0.3724171385073318]
	TIME [epoch: 6.3 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7278445871276618		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.7278445871276618 | validation: 0.36393649656615806]
	TIME [epoch: 6.35 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7235003360285739		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.7235003360285739 | validation: 0.3690378352497493]
	TIME [epoch: 6.32 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.723541999963472		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.723541999963472 | validation: 0.362884746441894]
	TIME [epoch: 6.3 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7220283083097099		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.7220283083097099 | validation: 0.3706785555502577]
	TIME [epoch: 6.3 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7225836316436898		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.7225836316436898 | validation: 0.36448813709229966]
	TIME [epoch: 6.32 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7183328832302485		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.7183328832302485 | validation: 0.36947835525491995]
	TIME [epoch: 6.32 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7243820011960134		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.7243820011960134 | validation: 0.3622204491540898]
	TIME [epoch: 6.32 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.716423134193159		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.716423134193159 | validation: 0.3639920626440848]
	TIME [epoch: 6.35 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7232328310970781		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.7232328310970781 | validation: 0.3579987181042087]
	TIME [epoch: 6.32 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7207234700458331		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.7207234700458331 | validation: 0.3584433777383088]
	TIME [epoch: 6.31 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.719548051611762		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.719548051611762 | validation: 0.3718138578159699]
	TIME [epoch: 6.32 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.724380593757628		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.724380593757628 | validation: 0.36711022106434943]
	TIME [epoch: 6.32 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7193934379117922		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.7193934379117922 | validation: 0.3678931244791077]
	TIME [epoch: 6.33 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7161998583881672		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.7161998583881672 | validation: 0.3638709503270213]
	TIME [epoch: 6.35 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7222183486137401		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.7222183486137401 | validation: 0.3622434958229909]
	TIME [epoch: 6.3 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7227388240205435		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.7227388240205435 | validation: 0.356493395472898]
	TIME [epoch: 6.33 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7216077494261586		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.7216077494261586 | validation: 0.3700152991961375]
	TIME [epoch: 6.31 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.722594127314734		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.722594127314734 | validation: 0.36292523371547086]
	TIME [epoch: 6.31 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7213269173947985		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.7213269173947985 | validation: 0.35969825368088987]
	TIME [epoch: 6.34 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7186301809194374		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.7186301809194374 | validation: 0.36072381795871633]
	TIME [epoch: 6.34 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7190298067718245		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.7190298067718245 | validation: 0.36154549245045]
	TIME [epoch: 6.31 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7228538425124031		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.7228538425124031 | validation: 0.3656510090315582]
	TIME [epoch: 6.31 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7190851311911111		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.7190851311911111 | validation: 0.3646114909277357]
	TIME [epoch: 6.33 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7214494994590781		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.7214494994590781 | validation: 0.35191403449366676]
	TIME [epoch: 6.31 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7227885851977055		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.7227885851977055 | validation: 0.36125866979615356]
	TIME [epoch: 6.33 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7279499582868346		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.7279499582868346 | validation: 0.3648825154884405]
	TIME [epoch: 6.36 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7211643377287387		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.7211643377287387 | validation: 0.35988307478371784]
	TIME [epoch: 6.32 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7223996146230379		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.7223996146230379 | validation: 0.36077183491298737]
	TIME [epoch: 6.32 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7238332398338407		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.7238332398338407 | validation: 0.36476400737330855]
	TIME [epoch: 6.31 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7207701229971557		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.7207701229971557 | validation: 0.36757387544595]
	TIME [epoch: 6.31 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7227065026760627		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.7227065026760627 | validation: 0.36804856190235213]
	TIME [epoch: 6.32 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7181030121534423		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.7181030121534423 | validation: 0.36179540158528845]
	TIME [epoch: 6.37 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.718066024395587		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.718066024395587 | validation: 0.3664032890822657]
	TIME [epoch: 6.33 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7215259615781953		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.7215259615781953 | validation: 0.36350510008452175]
	TIME [epoch: 6.33 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7195378111533985		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.7195378111533985 | validation: 0.3632756507604753]
	TIME [epoch: 6.33 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7186761633491034		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.7186761633491034 | validation: 0.3621087690235325]
	TIME [epoch: 6.32 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7219217802840379		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.7219217802840379 | validation: 0.37072560489526607]
	TIME [epoch: 6.33 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7222751057581048		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.7222751057581048 | validation: 0.36874364578747276]
	TIME [epoch: 6.37 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7230531658346674		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.7230531658346674 | validation: 0.3657638189940254]
	TIME [epoch: 6.32 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7213369726872193		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.7213369726872193 | validation: 0.35274682950120057]
	TIME [epoch: 6.32 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.720696148660795		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.720696148660795 | validation: 0.3655713881754549]
	TIME [epoch: 6.32 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7224707470816156		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.7224707470816156 | validation: 0.3590374819565805]
	TIME [epoch: 6.31 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7219617514263417		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.7219617514263417 | validation: 0.35843909433870763]
	TIME [epoch: 6.34 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7203158882309761		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.7203158882309761 | validation: 0.35340348217090073]
	TIME [epoch: 6.37 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.720805604371302		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.720805604371302 | validation: 0.37422357783275007]
	TIME [epoch: 6.33 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7219684727638098		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.7219684727638098 | validation: 0.3669792983135061]
	TIME [epoch: 6.33 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7204710814706377		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.7204710814706377 | validation: 0.36857013159839574]
	TIME [epoch: 6.32 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7186112880295009		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.7186112880295009 | validation: 0.3685389227155073]
	TIME [epoch: 6.32 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7207495980504002		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.7207495980504002 | validation: 0.3698897679514042]
	TIME [epoch: 6.36 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7210890074809454		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.7210890074809454 | validation: 0.36925378825735045]
	TIME [epoch: 6.36 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7249309604555978		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.7249309604555978 | validation: 0.35306577421190266]
	TIME [epoch: 6.33 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7223868769512953		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.7223868769512953 | validation: 0.3710991725755309]
	TIME [epoch: 6.33 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7181418623564445		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.7181418623564445 | validation: 0.36723863051739897]
	TIME [epoch: 6.32 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7231122345145915		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.7231122345145915 | validation: 0.365606410451899]
	TIME [epoch: 6.33 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7202577768648237		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.7202577768648237 | validation: 0.36070489939904926]
	TIME [epoch: 6.33 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7174230423773156		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.7174230423773156 | validation: 0.36478179560472745]
	TIME [epoch: 6.37 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7231586916771114		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.7231586916771114 | validation: 0.3687888226223265]
	TIME [epoch: 6.32 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7169281365290836		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.7169281365290836 | validation: 0.365095879060281]
	TIME [epoch: 6.32 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7222798984481129		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.7222798984481129 | validation: 0.3628893357117478]
	TIME [epoch: 6.33 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7224372855674615		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.7224372855674615 | validation: 0.36343544839175607]
	TIME [epoch: 6.33 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7227008608293626		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.7227008608293626 | validation: 0.3671019264985421]
	TIME [epoch: 6.34 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7220300747150161		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.7220300747150161 | validation: 0.3636015382189679]
	TIME [epoch: 6.37 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7190924669729152		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.7190924669729152 | validation: 0.36385150456356585]
	TIME [epoch: 6.32 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7175525830528755		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.7175525830528755 | validation: 0.36609604707054594]
	TIME [epoch: 6.31 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7188301045978174		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.7188301045978174 | validation: 0.3615941150987312]
	TIME [epoch: 6.32 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7223651811913335		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.7223651811913335 | validation: 0.36576351154535136]
	TIME [epoch: 6.32 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7195768260007902		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.7195768260007902 | validation: 0.3655688586043397]
	TIME [epoch: 6.33 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7187208667521461		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.7187208667521461 | validation: 0.36421518948836945]
	TIME [epoch: 6.38 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7188584789217531		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.7188584789217531 | validation: 0.3608406569694569]
	TIME [epoch: 6.33 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7206433087894761		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.7206433087894761 | validation: 0.36184626930626107]
	TIME [epoch: 6.33 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.720855303480717		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.720855303480717 | validation: 0.37080155001946424]
	TIME [epoch: 6.32 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7178291178774284		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.7178291178774284 | validation: 0.37104839913536025]
	TIME [epoch: 6.32 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7205347480293584		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.7205347480293584 | validation: 0.3741803170150028]
	TIME [epoch: 6.33 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7197799190064854		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.7197799190064854 | validation: 0.3640547330872934]
	TIME [epoch: 6.37 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7244080065169054		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.7244080065169054 | validation: 0.3629116474909218]
	TIME [epoch: 6.33 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7219313141511917		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.7219313141511917 | validation: 0.3635347681639728]
	TIME [epoch: 6.33 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7184390936575363		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.7184390936575363 | validation: 0.36761468962234056]
	TIME [epoch: 6.32 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7171316247883243		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.7171316247883243 | validation: 0.3665609913436238]
	TIME [epoch: 6.32 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7195324744994404		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.7195324744994404 | validation: 0.3701505571022872]
	TIME [epoch: 6.32 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7245934917112613		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.7245934917112613 | validation: 0.3578997359890895]
	TIME [epoch: 6.38 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7202593478220577		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.7202593478220577 | validation: 0.36100556339367657]
	TIME [epoch: 6.32 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7203166017818166		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.7203166017818166 | validation: 0.3652761952025885]
	TIME [epoch: 6.33 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7186545704749976		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.7186545704749976 | validation: 0.3663305863792802]
	TIME [epoch: 6.33 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7208905151490694		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.7208905151490694 | validation: 0.36433590056947723]
	TIME [epoch: 6.33 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7165437439224436		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.7165437439224436 | validation: 0.36231224596263495]
	TIME [epoch: 6.32 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.717493418003272		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.717493418003272 | validation: 0.3706485599238704]
	TIME [epoch: 6.37 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7210207842296888		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.7210207842296888 | validation: 0.36306872599489726]
	TIME [epoch: 6.33 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.719885439187091		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.719885439187091 | validation: 0.3736172542387972]
	TIME [epoch: 6.32 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7198664170701701		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.7198664170701701 | validation: 0.356749428138177]
	TIME [epoch: 6.33 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7212847270667891		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.7212847270667891 | validation: 0.37194268258196905]
	TIME [epoch: 6.33 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7200340186630033		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.7200340186630033 | validation: 0.366653126545578]
	TIME [epoch: 6.31 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7225381631637455		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.7225381631637455 | validation: 0.36487324638749996]
	TIME [epoch: 6.39 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7226874925371851		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.7226874925371851 | validation: 0.37292495439587586]
	TIME [epoch: 6.32 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7177397673795889		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.7177397673795889 | validation: 0.3657261253964395]
	TIME [epoch: 6.32 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7177265089721396		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.7177265089721396 | validation: 0.3729193268156352]
	TIME [epoch: 6.32 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7218225664087108		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.7218225664087108 | validation: 0.36451926035105886]
	TIME [epoch: 6.33 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7190599494766153		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.7190599494766153 | validation: 0.36831169090428584]
	TIME [epoch: 6.32 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7202486177228135		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.7202486177228135 | validation: 0.3607996097071925]
	TIME [epoch: 6.36 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7228612108902399		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.7228612108902399 | validation: 0.3702645311545758]
	TIME [epoch: 6.33 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7222160586707708		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.7222160586707708 | validation: 0.3598834361269861]
	TIME [epoch: 6.32 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7162880152252681		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.7162880152252681 | validation: 0.3640627304442285]
	TIME [epoch: 6.33 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7231343461766865		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.7231343461766865 | validation: 0.3640003364682762]
	TIME [epoch: 6.32 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7190213510583721		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.7190213510583721 | validation: 0.3663118515799746]
	TIME [epoch: 6.34 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.72122402782421		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.72122402782421 | validation: 0.3673275719296296]
	TIME [epoch: 6.35 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7237394830290229		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.7237394830290229 | validation: 0.3720193952593282]
	TIME [epoch: 6.34 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7216242854931693		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.7216242854931693 | validation: 0.3582815996539006]
	TIME [epoch: 6.33 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7192436787553825		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.7192436787553825 | validation: 0.3613370694937263]
	TIME [epoch: 6.32 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7214541991238499		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.7214541991238499 | validation: 0.36896888277739964]
	TIME [epoch: 6.33 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7171843065695902		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.7171843065695902 | validation: 0.36680866226163755]
	TIME [epoch: 6.32 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7207341646342487		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.7207341646342487 | validation: 0.3650978857474171]
	TIME [epoch: 6.36 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7226918046782477		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.7226918046782477 | validation: 0.3639932475437309]
	TIME [epoch: 6.34 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7207806689642893		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.7207806689642893 | validation: 0.3620179404771733]
	TIME [epoch: 6.33 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7230607403158299		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.7230607403158299 | validation: 0.3619379927270706]
	TIME [epoch: 6.32 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7220325341513181		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.7220325341513181 | validation: 0.3697670932842719]
	TIME [epoch: 6.32 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7203085798182294		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.7203085798182294 | validation: 0.35980594100153324]
	TIME [epoch: 6.33 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7223310263136423		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.7223310263136423 | validation: 0.35926175677809136]
	TIME [epoch: 6.35 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7222811903496043		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.7222811903496043 | validation: 0.359246462290355]
	TIME [epoch: 6.35 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7205221390856257		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.7205221390856257 | validation: 0.3635974406596285]
	TIME [epoch: 6.33 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7214378973667498		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.7214378973667498 | validation: 0.35843846020536946]
	TIME [epoch: 6.32 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7198388409074494		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.7198388409074494 | validation: 0.36548157092593847]
	TIME [epoch: 6.32 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.719606436623239		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.719606436623239 | validation: 0.3635152593713304]
	TIME [epoch: 6.32 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7228015452577666		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.7228015452577666 | validation: 0.3629793534029082]
	TIME [epoch: 6.34 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7209601593912264		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.7209601593912264 | validation: 0.35459332881675665]
	TIME [epoch: 6.35 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7209933209399108		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.7209933209399108 | validation: 0.36810825431024413]
	TIME [epoch: 6.31 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7197444199969301		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.7197444199969301 | validation: 0.3694264914612625]
	TIME [epoch: 6.31 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7215899781164621		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.7215899781164621 | validation: 0.372249036542236]
	TIME [epoch: 6.31 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7187273771995645		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.7187273771995645 | validation: 0.3642138575890834]
	TIME [epoch: 6.31 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7210659102358037		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.7210659102358037 | validation: 0.36138435484273423]
	TIME [epoch: 6.34 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7241139106808052		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.7241139106808052 | validation: 0.35863795938207665]
	TIME [epoch: 6.35 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7192242504844991		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.7192242504844991 | validation: 0.36279016105913786]
	TIME [epoch: 6.32 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7185086108041255		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.7185086108041255 | validation: 0.3642869563507338]
	TIME [epoch: 6.31 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7197619091378343		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.7197619091378343 | validation: 0.35951206027691834]
	TIME [epoch: 6.32 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7209638077376574		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.7209638077376574 | validation: 0.35891990783121824]
	TIME [epoch: 6.31 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7201243942688953		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.7201243942688953 | validation: 0.36083857083470156]
	TIME [epoch: 6.35 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7197453804986976		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.7197453804986976 | validation: 0.36870555668286287]
	TIME [epoch: 6.35 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7200991970994596		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.7200991970994596 | validation: 0.3589804131913317]
	TIME [epoch: 6.32 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7218933302276187		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.7218933302276187 | validation: 0.3672811769104315]
	TIME [epoch: 6.32 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7225688610237498		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.7225688610237498 | validation: 0.3663684710537984]
	TIME [epoch: 6.32 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7206598064923542		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.7206598064923542 | validation: 0.3702036675760706]
	TIME [epoch: 6.33 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7209228537061886		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.7209228537061886 | validation: 0.36063595805303433]
	TIME [epoch: 6.34 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7211509155349358		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.7211509155349358 | validation: 0.36140760328511745]
	TIME [epoch: 6.35 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7199460681663239		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.7199460681663239 | validation: 0.35095125347029354]
	TIME [epoch: 6.31 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7219688832013953		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.7219688832013953 | validation: 0.369424463099239]
	TIME [epoch: 6.32 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7224037104870412		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.7224037104870412 | validation: 0.35848968787794727]
	TIME [epoch: 6.31 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7198904640818883		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.7198904640818883 | validation: 0.36154492342927164]
	TIME [epoch: 6.31 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7193874856736316		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.7193874856736316 | validation: 0.3693954091023819]
	TIME [epoch: 6.34 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7214432697091344		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.7214432697091344 | validation: 0.3615162807971066]
	TIME [epoch: 6.36 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7209253902967463		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.7209253902967463 | validation: 0.3638730969222704]
	TIME [epoch: 6.32 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7227971805445802		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.7227971805445802 | validation: 0.3569494068779188]
	TIME [epoch: 6.31 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.723282102276051		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.723282102276051 | validation: 0.3625392036242985]
	TIME [epoch: 6.32 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7199060581496707		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.7199060581496707 | validation: 0.3595478882442984]
	TIME [epoch: 6.32 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7230473760635966		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.7230473760635966 | validation: 0.3669918964166805]
	TIME [epoch: 6.33 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7213316298232699		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.7213316298232699 | validation: 0.37631681456868915]
	TIME [epoch: 6.36 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7208708903567534		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.7208708903567534 | validation: 0.37185994336139366]
	TIME [epoch: 6.31 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7209609267646723		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.7209609267646723 | validation: 0.37070820136841354]
	TIME [epoch: 6.32 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7202059951944091		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.7202059951944091 | validation: 0.361090907507148]
	TIME [epoch: 6.31 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7189078938179505		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.7189078938179505 | validation: 0.3680863845705759]
	TIME [epoch: 6.32 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7202992885223133		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.7202992885223133 | validation: 0.36180946203383896]
	TIME [epoch: 6.32 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7204504542622027		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.7204504542622027 | validation: 0.3640804335408359]
	TIME [epoch: 6.37 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7205954477862941		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.7205954477862941 | validation: 0.3652271016091427]
	TIME [epoch: 6.32 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7192669995986836		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.7192669995986836 | validation: 0.3632571714257688]
	TIME [epoch: 6.31 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7221067722420093		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.7221067722420093 | validation: 0.37197212076727176]
	TIME [epoch: 6.32 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7222011843089282		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.7222011843089282 | validation: 0.3671755285395648]
	TIME [epoch: 6.32 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7210892490838101		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.7210892490838101 | validation: 0.3699511529335662]
	TIME [epoch: 6.33 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.717231043792474		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.717231043792474 | validation: 0.35891789893985626]
	TIME [epoch: 6.36 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7207470781781063		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.7207470781781063 | validation: 0.36857296422879626]
	TIME [epoch: 6.31 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7202247004278729		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.7202247004278729 | validation: 0.3547837836954919]
	TIME [epoch: 6.32 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7185915975359904		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.7185915975359904 | validation: 0.36885193714474007]
	TIME [epoch: 6.33 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7191991854443656		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.7191991854443656 | validation: 0.37093927242166]
	TIME [epoch: 6.32 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7194331460660427		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.7194331460660427 | validation: 0.3587758819063891]
	TIME [epoch: 6.33 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7201085223864593		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.7201085223864593 | validation: 0.3686932914942478]
	TIME [epoch: 6.36 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7210186272170158		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.7210186272170158 | validation: 0.3707232395721142]
	TIME [epoch: 6.31 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7193430649770794		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.7193430649770794 | validation: 0.37435906103564787]
	TIME [epoch: 6.31 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7220762022930922		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.7220762022930922 | validation: 0.3626342925504787]
	TIME [epoch: 6.31 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7209901572952964		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.7209901572952964 | validation: 0.36118195809362386]
	TIME [epoch: 6.32 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7190371595023021		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.7190371595023021 | validation: 0.3731983252145713]
	TIME [epoch: 6.32 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7219630680354855		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.7219630680354855 | validation: 0.36505916694556684]
	TIME [epoch: 6.35 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7204987929943072		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.7204987929943072 | validation: 0.36198411014656545]
	TIME [epoch: 6.31 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7209740112614358		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.7209740112614358 | validation: 0.3590687839173079]
	TIME [epoch: 6.31 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7237230166136448		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.7237230166136448 | validation: 0.3712402652643166]
	TIME [epoch: 6.31 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7218121788852474		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.7218121788852474 | validation: 0.3757944453339372]
	TIME [epoch: 6.31 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7223935932951198		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.7223935932951198 | validation: 0.36040000728128]
	TIME [epoch: 6.31 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7191135987794018		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.7191135987794018 | validation: 0.36575728678259634]
	TIME [epoch: 6.37 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7199216643640769		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.7199216643640769 | validation: 0.3671897568615499]
	TIME [epoch: 6.32 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7243924577996262		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.7243924577996262 | validation: 0.3627447465462007]
	TIME [epoch: 6.32 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7221609490312968		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.7221609490312968 | validation: 0.36037379659280655]
	TIME [epoch: 6.31 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7206337993040681		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.7206337993040681 | validation: 0.36149551520893763]
	TIME [epoch: 6.32 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7196627976452434		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.7196627976452434 | validation: 0.363350514542227]
	TIME [epoch: 6.32 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7166081210228705		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.7166081210228705 | validation: 0.36065776209101]
	TIME [epoch: 6.36 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7204881443793149		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.7204881443793149 | validation: 0.3590154797568901]
	TIME [epoch: 6.31 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7224263552607014		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.7224263552607014 | validation: 0.3613953121828072]
	TIME [epoch: 6.32 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.72015381592729		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.72015381592729 | validation: 0.3669688408054519]
	TIME [epoch: 6.32 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7207499222882235		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.7207499222882235 | validation: 0.3747584572699892]
	TIME [epoch: 6.33 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7248762995571542		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.7248762995571542 | validation: 0.3690833035721792]
	TIME [epoch: 6.32 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7236170721336239		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.7236170721336239 | validation: 0.36924830855407537]
	TIME [epoch: 6.37 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7232463791399714		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.7232463791399714 | validation: 0.3525726743502181]
	TIME [epoch: 6.31 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7187012391345909		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.7187012391345909 | validation: 0.36186376010707666]
	TIME [epoch: 6.31 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7216726810032941		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.7216726810032941 | validation: 0.3655816765773953]
	TIME [epoch: 6.31 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.718764146065466		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.718764146065466 | validation: 0.3556721901212316]
	TIME [epoch: 6.31 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7244917119062741		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.7244917119062741 | validation: 0.3682153124560573]
	TIME [epoch: 6.32 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7194216990391887		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.7194216990391887 | validation: 0.36463729103579406]
	TIME [epoch: 6.37 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.72090729272416		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.72090729272416 | validation: 0.3647557976614026]
	TIME [epoch: 6.33 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7218923833266128		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.7218923833266128 | validation: 0.35956712749783204]
	TIME [epoch: 6.31 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7240475910602286		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.7240475910602286 | validation: 0.36421764046016386]
	TIME [epoch: 6.32 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7163088571090389		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.7163088571090389 | validation: 0.3651936856299133]
	TIME [epoch: 6.32 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7243307715038841		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.7243307715038841 | validation: 0.3567371856981543]
	TIME [epoch: 6.32 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.723158793839655		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.723158793839655 | validation: 0.3685192172607579]
	TIME [epoch: 6.36 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7184103404172659		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.7184103404172659 | validation: 0.3652650952377442]
	TIME [epoch: 6.33 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7193876414592876		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.7193876414592876 | validation: 0.35995668355456845]
	TIME [epoch: 6.32 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7183251973538294		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.7183251973538294 | validation: 0.3587831309988814]
	TIME [epoch: 6.3 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7213201198370959		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.7213201198370959 | validation: 0.36221503259747173]
	TIME [epoch: 6.32 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7226066856417568		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.7226066856417568 | validation: 0.36671316482075944]
	TIME [epoch: 6.32 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7208384551140009		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.7208384551140009 | validation: 0.3672786848857316]
	TIME [epoch: 6.34 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7209384667266143		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.7209384667266143 | validation: 0.36662239280823394]
	TIME [epoch: 6.33 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7218219876002732		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.7218219876002732 | validation: 0.36942875704027045]
	TIME [epoch: 6.31 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7253681396578529		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.7253681396578529 | validation: 0.36237737039652756]
	TIME [epoch: 6.31 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7221071563082568		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.7221071563082568 | validation: 0.37009603853935474]
	TIME [epoch: 6.32 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7183430518993872		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.7183430518993872 | validation: 0.3671853584401611]
	TIME [epoch: 6.31 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7218682551571026		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.7218682551571026 | validation: 0.37332950391732495]
	TIME [epoch: 6.35 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7232488745961565		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.7232488745961565 | validation: 0.36440939651712173]
	TIME [epoch: 6.43 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7204815361289898		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.7204815361289898 | validation: 0.3606027456676968]
	TIME [epoch: 6.31 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7237530633893967		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.7237530633893967 | validation: 0.36549283398178845]
	TIME [epoch: 6.3 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7213333554220294		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.7213333554220294 | validation: 0.36229220482079755]
	TIME [epoch: 6.31 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7236735283980148		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.7236735283980148 | validation: 0.3680079306812801]
	TIME [epoch: 6.32 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7156236315708446		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.7156236315708446 | validation: 0.35834957547339213]
	TIME [epoch: 6.36 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7187419171678144		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.7187419171678144 | validation: 0.3759069123367779]
	TIME [epoch: 6.34 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7202355336008723		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.7202355336008723 | validation: 0.35553222920753674]
	TIME [epoch: 6.31 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7183958509568288		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.7183958509568288 | validation: 0.3660774005589708]
	TIME [epoch: 6.32 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7191148083396981		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.7191148083396981 | validation: 0.3674077025232952]
	TIME [epoch: 6.31 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7228250789007002		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.7228250789007002 | validation: 0.3616882518490343]
	TIME [epoch: 6.32 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7189184284586652		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.7189184284586652 | validation: 0.3663827965303574]
	TIME [epoch: 6.34 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7202955125965838		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.7202955125965838 | validation: 0.36362291910597605]
	TIME [epoch: 6.34 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7177453229178027		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.7177453229178027 | validation: 0.3655950244877396]
	TIME [epoch: 6.31 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7169457202237521		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.7169457202237521 | validation: 0.35829530374780383]
	TIME [epoch: 6.31 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7165738893061901		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.7165738893061901 | validation: 0.35615982443403515]
	TIME [epoch: 6.32 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7164666529687619		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.7164666529687619 | validation: 0.3627651541897567]
	TIME [epoch: 6.31 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7174272694242771		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.7174272694242771 | validation: 0.3623348431649258]
	TIME [epoch: 6.33 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.718003576173335		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.718003576173335 | validation: 0.3647348044677198]
	TIME [epoch: 6.35 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7189395900675913		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.7189395900675913 | validation: 0.37003314874630244]
	TIME [epoch: 6.32 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7220524832356789		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.7220524832356789 | validation: 0.3635629997758405]
	TIME [epoch: 6.31 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7175195324789239		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.7175195324789239 | validation: 0.36289723465145024]
	TIME [epoch: 6.32 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.721198648892209		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.721198648892209 | validation: 0.36820386807905675]
	TIME [epoch: 6.32 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7165734839870317		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.7165734839870317 | validation: 0.3768539958755258]
	TIME [epoch: 6.34 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7221627718855093		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.7221627718855093 | validation: 0.37649355272644214]
	TIME [epoch: 6.35 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.724410989543141		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.724410989543141 | validation: 0.3574376948787848]
	TIME [epoch: 6.31 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7262020612185398		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.7262020612185398 | validation: 0.3713438790874577]
	TIME [epoch: 6.31 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7192601343539891		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.7192601343539891 | validation: 0.3643763689517038]
	TIME [epoch: 6.31 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7196978920474519		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.7196978920474519 | validation: 0.3682792744413377]
	TIME [epoch: 6.31 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7210940523318409		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.7210940523318409 | validation: 0.3627311886194247]
	TIME [epoch: 6.34 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7214290195115876		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.7214290195115876 | validation: 0.3637715743487265]
	TIME [epoch: 6.34 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7246689921753487		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.7246689921753487 | validation: 0.3602590417244542]
	TIME [epoch: 6.32 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7164709612208308		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.7164709612208308 | validation: 0.3629927571643729]
	TIME [epoch: 6.33 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7209371044113098		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.7209371044113098 | validation: 0.3689829644940068]
	TIME [epoch: 6.31 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7220903265107064		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.7220903265107064 | validation: 0.3629662074054121]
	TIME [epoch: 6.32 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7213654946265174		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.7213654946265174 | validation: 0.36384320295626404]
	TIME [epoch: 6.33 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7248124269341125		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.7248124269341125 | validation: 0.3578553350842603]
	TIME [epoch: 6.36 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7202623855410385		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.7202623855410385 | validation: 0.3675373599637249]
	TIME [epoch: 6.31 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7225683066531486		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.7225683066531486 | validation: 0.37033076747455396]
	TIME [epoch: 6.32 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7227525275708933		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.7227525275708933 | validation: 0.374632956830646]
	TIME [epoch: 6.31 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7247441648372239		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.7247441648372239 | validation: 0.3612153832157785]
	TIME [epoch: 6.31 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7224049260932245		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.7224049260932245 | validation: 0.37058574204830175]
	TIME [epoch: 6.33 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7212842377892161		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.7212842377892161 | validation: 0.36923132762162375]
	TIME [epoch: 6.36 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7211034524969677		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.7211034524969677 | validation: 0.3585318772098439]
	TIME [epoch: 6.32 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7221042166720151		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.7221042166720151 | validation: 0.3599919231584719]
	TIME [epoch: 6.32 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7233186963895042		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.7233186963895042 | validation: 0.36704567331828125]
	TIME [epoch: 6.31 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7197225191452228		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.7197225191452228 | validation: 0.37129007854794]
	TIME [epoch: 6.31 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7220875701304523		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.7220875701304523 | validation: 0.36339137514502956]
	TIME [epoch: 6.33 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7203161798011883		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.7203161798011883 | validation: 0.36514939626649806]
	TIME [epoch: 6.37 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7208591663385868		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.7208591663385868 | validation: 0.3660852448525099]
	TIME [epoch: 6.32 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7212922998059123		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.7212922998059123 | validation: 0.35862933990937046]
	TIME [epoch: 6.32 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7228905500108666		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.7228905500108666 | validation: 0.36338506227218026]
	TIME [epoch: 6.32 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7201541213639762		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.7201541213639762 | validation: 0.3709720899553127]
	TIME [epoch: 6.31 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7190263496908708		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.7190263496908708 | validation: 0.3644849598346376]
	TIME [epoch: 6.33 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.721852118620222		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.721852118620222 | validation: 0.36540625992890724]
	TIME [epoch: 6.35 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.719585740278518		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.719585740278518 | validation: 0.36094478195068996]
	TIME [epoch: 6.32 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7238150836748158		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.7238150836748158 | validation: 0.3650034040911833]
	TIME [epoch: 6.31 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.717132238000449		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.717132238000449 | validation: 0.3632211363770379]
	TIME [epoch: 6.32 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7226583973252468		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.7226583973252468 | validation: 0.36501287996553267]
	TIME [epoch: 6.31 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.718689317896178		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.718689317896178 | validation: 0.3707465284859596]
	TIME [epoch: 6.32 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7203565437938713		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.7203565437938713 | validation: 0.36191784022968476]
	TIME [epoch: 6.36 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7242197764739258		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.7242197764739258 | validation: 0.3580865235534299]
	TIME [epoch: 6.32 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7213699257002166		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.7213699257002166 | validation: 0.36317049781701394]
	TIME [epoch: 6.32 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.719782521221185		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.719782521221185 | validation: 0.3718874858270136]
	TIME [epoch: 6.32 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7204165111412331		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.7204165111412331 | validation: 0.3655817797553547]
	TIME [epoch: 6.32 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7181675833269081		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.7181675833269081 | validation: 0.3613829444607653]
	TIME [epoch: 6.31 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7198176448348806		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.7198176448348806 | validation: 0.3644402566853274]
	TIME [epoch: 6.38 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7197084733199529		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.7197084733199529 | validation: 0.3623194728909891]
	TIME [epoch: 6.32 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.718531369593709		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.718531369593709 | validation: 0.3629780270481588]
	TIME [epoch: 6.33 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7231026322470939		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.7231026322470939 | validation: 0.3644266218268525]
	TIME [epoch: 6.31 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7239613334194877		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.7239613334194877 | validation: 0.3611589635598169]
	TIME [epoch: 6.32 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7179754179861337		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.7179754179861337 | validation: 0.35285396595266394]
	TIME [epoch: 6.32 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7220845475605411		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.7220845475605411 | validation: 0.36410036978111815]
	TIME [epoch: 6.36 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.719638509557954		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.719638509557954 | validation: 0.3680944866953909]
	TIME [epoch: 6.31 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7215162284685757		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.7215162284685757 | validation: 0.36348063291475896]
	TIME [epoch: 6.32 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7222795017437177		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.7222795017437177 | validation: 0.356067465905792]
	TIME [epoch: 6.32 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7237167068747843		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.7237167068747843 | validation: 0.3649414330200949]
	TIME [epoch: 6.32 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7219806399558917		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.7219806399558917 | validation: 0.3672882546537441]
	TIME [epoch: 6.32 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7203146127394274		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.7203146127394274 | validation: 0.3667506353696206]
	TIME [epoch: 6.36 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7223076917820082		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.7223076917820082 | validation: 0.37091565971143464]
	TIME [epoch: 6.31 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7250179644601011		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.7250179644601011 | validation: 0.37191318119872996]
	TIME [epoch: 6.32 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7207950120257922		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.7207950120257922 | validation: 0.3529514748253516]
	TIME [epoch: 6.31 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7230845728415722		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.7230845728415722 | validation: 0.36066269096128517]
	TIME [epoch: 6.32 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7179664185288057		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.7179664185288057 | validation: 0.3639357920428963]
	TIME [epoch: 6.33 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7197927422423047		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.7197927422423047 | validation: 0.36578975671471403]
	TIME [epoch: 6.36 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7189540517757717		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.7189540517757717 | validation: 0.3677228481134748]
	TIME [epoch: 6.32 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7198548687966282		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.7198548687966282 | validation: 0.36493606720751626]
	TIME [epoch: 6.32 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7236554158527617		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.7236554158527617 | validation: 0.35939996561476345]
	TIME [epoch: 6.32 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7254000877729024		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.7254000877729024 | validation: 0.3601381124177597]
	TIME [epoch: 6.31 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7213690839719225		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.7213690839719225 | validation: 0.3600668410386856]
	TIME [epoch: 6.32 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7192096419222982		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.7192096419222982 | validation: 0.3668502930496439]
	TIME [epoch: 6.35 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7211255802342378		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.7211255802342378 | validation: 0.35840106026448915]
	TIME [epoch: 6.33 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7209407279482004		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.7209407279482004 | validation: 0.3580453829878138]
	TIME [epoch: 6.32 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7211058539421028		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.7211058539421028 | validation: 0.3723815226515204]
	TIME [epoch: 6.32 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7206336087600433		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.7206336087600433 | validation: 0.3556444983758549]
	TIME [epoch: 6.31 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7211257513742193		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.7211257513742193 | validation: 0.3630099855458828]
	TIME [epoch: 6.32 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7195821583440063		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.7195821583440063 | validation: 0.3577515054624803]
	TIME [epoch: 6.36 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7205698481309818		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.7205698481309818 | validation: 0.3701483377815981]
	TIME [epoch: 6.31 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7209855738906819		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.7209855738906819 | validation: 0.3672995729061612]
	TIME [epoch: 6.32 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.719594287615323		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.719594287615323 | validation: 0.3706996401515992]
	TIME [epoch: 6.32 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7176980518178361		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.7176980518178361 | validation: 0.36121432767749406]
	TIME [epoch: 6.32 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7172339920922942		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.7172339920922942 | validation: 0.36358984997281285]
	TIME [epoch: 6.31 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7203842512860766		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.7203842512860766 | validation: 0.3695939900211388]
	TIME [epoch: 6.36 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7218452995103537		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.7218452995103537 | validation: 0.3744542294981086]
	TIME [epoch: 6.33 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7182860818440475		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.7182860818440475 | validation: 0.3570246583085372]
	TIME [epoch: 6.31 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7203752752165068		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.7203752752165068 | validation: 0.364995662446756]
	TIME [epoch: 6.32 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7172077606346337		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.7172077606346337 | validation: 0.36582014996076617]
	TIME [epoch: 6.31 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7192516876292857		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.7192516876292857 | validation: 0.35958862746592424]
	TIME [epoch: 6.32 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7170648450500933		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.7170648450500933 | validation: 0.3591579239595704]
	TIME [epoch: 6.35 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7229129297489281		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.7229129297489281 | validation: 0.3648360872851486]
	TIME [epoch: 6.33 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7175589020334764		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.7175589020334764 | validation: 0.3631385454408209]
	TIME [epoch: 6.31 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7210562606629956		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.7210562606629956 | validation: 0.35971406497298547]
	TIME [epoch: 6.31 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7201818972975036		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.7201818972975036 | validation: 0.36569911452951714]
	TIME [epoch: 6.32 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7193733204065094		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.7193733204065094 | validation: 0.3583091515333599]
	TIME [epoch: 6.31 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7252536117487144		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.7252536117487144 | validation: 0.3665867116110428]
	TIME [epoch: 6.35 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7206088410051282		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.7206088410051282 | validation: 0.36618600747143926]
	TIME [epoch: 6.34 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7218701772945141		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.7218701772945141 | validation: 0.37017642860536204]
	TIME [epoch: 6.29 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7222221483740329		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.7222221483740329 | validation: 0.3589212082145161]
	TIME [epoch: 6.31 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7260787880460865		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.7260787880460865 | validation: 0.36745914083181125]
	TIME [epoch: 6.3 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7226698995387681		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.7226698995387681 | validation: 0.3588864739132768]
	TIME [epoch: 6.32 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7218930064815743		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.7218930064815743 | validation: 0.3639747602214171]
	TIME [epoch: 6.35 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7217545895474597		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.7217545895474597 | validation: 0.3611089761221022]
	TIME [epoch: 6.35 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7205092044538045		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.7205092044538045 | validation: 0.35970800324519386]
	TIME [epoch: 6.31 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7159755934575507		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.7159755934575507 | validation: 0.36006709839651696]
	TIME [epoch: 6.32 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7221432218365117		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.7221432218365117 | validation: 0.36909217172338094]
	TIME [epoch: 6.32 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7218992611870876		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.7218992611870876 | validation: 0.36913661566786565]
	TIME [epoch: 6.31 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7184280244441974		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.7184280244441974 | validation: 0.3682463692556146]
	TIME [epoch: 6.34 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7245301258591635		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.7245301258591635 | validation: 0.36024705663752576]
	TIME [epoch: 6.35 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7193777773766918		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.7193777773766918 | validation: 0.3726687437409346]
	TIME [epoch: 6.31 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7201362424770669		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.7201362424770669 | validation: 0.3663436324653711]
	TIME [epoch: 6.33 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7211906064165212		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.7211906064165212 | validation: 0.36635391706684856]
	TIME [epoch: 6.31 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7225136113239958		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.7225136113239958 | validation: 0.3608628844713536]
	TIME [epoch: 6.32 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7195028713854801		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.7195028713854801 | validation: 0.364640821179866]
	TIME [epoch: 6.34 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7213529428382893		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.7213529428382893 | validation: 0.36749969849799896]
	TIME [epoch: 6.35 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7180024546176855		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.7180024546176855 | validation: 0.36351320296175704]
	TIME [epoch: 6.32 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7225390920109599		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.7225390920109599 | validation: 0.36598061008292293]
	TIME [epoch: 6.32 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7219228595980539		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.7219228595980539 | validation: 0.36122302473213086]
	TIME [epoch: 6.32 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7176889126127809		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.7176889126127809 | validation: 0.362612823698749]
	TIME [epoch: 6.32 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7227003100827689		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.7227003100827689 | validation: 0.3651108891374921]
	TIME [epoch: 6.35 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7183934958309379		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.7183934958309379 | validation: 0.3719269333123748]
	TIME [epoch: 6.34 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7163768576097416		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.7163768576097416 | validation: 0.3647681818391629]
	TIME [epoch: 6.33 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.718001958222058		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.718001958222058 | validation: 0.36149316410872456]
	TIME [epoch: 6.32 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7175571852844231		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.7175571852844231 | validation: 0.3671515577011426]
	TIME [epoch: 6.31 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7207274840023338		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.7207274840023338 | validation: 0.3619636825240243]
	TIME [epoch: 6.31 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.723828330993738		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.723828330993738 | validation: 0.36142262707601025]
	TIME [epoch: 6.33 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7247033631652589		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.7247033631652589 | validation: 0.35698301454331677]
	TIME [epoch: 6.34 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7181939439728048		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.7181939439728048 | validation: 0.37360796029684895]
	TIME [epoch: 6.31 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7171658114588055		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.7171658114588055 | validation: 0.3728115275390454]
	TIME [epoch: 6.31 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7217300731523222		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.7217300731523222 | validation: 0.3670777563177244]
	TIME [epoch: 6.31 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7138025245628072		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.7138025245628072 | validation: 0.3658949643905274]
	TIME [epoch: 6.31 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7218316515548026		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.7218316515548026 | validation: 0.3602342407636088]
	TIME [epoch: 6.34 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7156166189030356		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.7156166189030356 | validation: 0.35706161355652477]
	TIME [epoch: 6.34 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7188708764133439		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.7188708764133439 | validation: 0.36616747823472146]
	TIME [epoch: 6.32 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7241635452020845		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.7241635452020845 | validation: 0.3563623309992282]
	TIME [epoch: 6.31 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7189520795004422		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.7189520795004422 | validation: 0.3694637408864949]
	TIME [epoch: 6.31 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7210022714390136		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.7210022714390136 | validation: 0.3687750188904513]
	TIME [epoch: 6.32 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7240668103463457		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.7240668103463457 | validation: 0.35880014542774047]
	TIME [epoch: 6.33 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.717357249483473		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.717357249483473 | validation: 0.36486975955615275]
	TIME [epoch: 6.35 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7210574411746177		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.7210574411746177 | validation: 0.36091268205379745]
	TIME [epoch: 6.31 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7219581149103904		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.7219581149103904 | validation: 0.3649173630481679]
	TIME [epoch: 6.31 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7232193531112978		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.7232193531112978 | validation: 0.36299433285651556]
	TIME [epoch: 6.32 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.721291809836463		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.721291809836463 | validation: 0.36180303445961404]
	TIME [epoch: 6.31 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7171644469117218		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.7171644469117218 | validation: 0.3617565606383489]
	TIME [epoch: 6.33 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7216909208796869		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.7216909208796869 | validation: 0.36661902121545864]
	TIME [epoch: 6.35 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7176653494213645		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.7176653494213645 | validation: 0.3599251703849336]
	TIME [epoch: 6.32 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7180978806498		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.7180978806498 | validation: 0.35755177160379736]
	TIME [epoch: 6.32 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7218471055587444		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.7218471055587444 | validation: 0.36939887500621005]
	TIME [epoch: 6.3 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.719197365180141		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.719197365180141 | validation: 0.36625672276967486]
	TIME [epoch: 6.32 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7177312440307881		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.7177312440307881 | validation: 0.37693620042080683]
	TIME [epoch: 6.33 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7218740148427378		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.7218740148427378 | validation: 0.36155654140097476]
	TIME [epoch: 6.36 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7231846453119045		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.7231846453119045 | validation: 0.3666254797492707]
	TIME [epoch: 6.31 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7220719344664159		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.7220719344664159 | validation: 0.36722522607745794]
	TIME [epoch: 6.31 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7218699249146048		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.7218699249146048 | validation: 0.36951280276438814]
	TIME [epoch: 6.32 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7213630029503614		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.7213630029503614 | validation: 0.3683877438854941]
	TIME [epoch: 6.33 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7185415554904584		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.7185415554904584 | validation: 0.3574332505890952]
	TIME [epoch: 6.32 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7185740654773007		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.7185740654773007 | validation: 0.3716245232978541]
	TIME [epoch: 6.37 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7248993852512682		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.7248993852512682 | validation: 0.3645695693492541]
	TIME [epoch: 6.31 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.719772722138174		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.719772722138174 | validation: 0.36126611795689484]
	TIME [epoch: 6.32 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.720827239552474		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.720827239552474 | validation: 0.3692629974462093]
	TIME [epoch: 6.31 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7158072571529075		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.7158072571529075 | validation: 0.36979831012652975]
	TIME [epoch: 6.32 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7181461063439449		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.7181461063439449 | validation: 0.36729091403328146]
	TIME [epoch: 6.33 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7204268069844882		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.7204268069844882 | validation: 0.36506953884394455]
	TIME [epoch: 6.36 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7204337946792955		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.7204337946792955 | validation: 0.36951224170238134]
	TIME [epoch: 6.33 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7193713806973497		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.7193713806973497 | validation: 0.3569303419989552]
	TIME [epoch: 6.32 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7211982240998812		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.7211982240998812 | validation: 0.3644768805714869]
	TIME [epoch: 6.33 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7209475265943992		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.7209475265943992 | validation: 0.3681710419046933]
	TIME [epoch: 6.31 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7209582721029284		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.7209582721029284 | validation: 0.36830743885813344]
	TIME [epoch: 6.32 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7210202325876257		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.7210202325876257 | validation: 0.3622261829621195]
	TIME [epoch: 6.36 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7212341849446251		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.7212341849446251 | validation: 0.37327068959534615]
	TIME [epoch: 6.32 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7180022183084152		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.7180022183084152 | validation: 0.36537445583900374]
	TIME [epoch: 6.32 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7177183729733931		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.7177183729733931 | validation: 0.366126997557076]
	TIME [epoch: 6.32 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7220251436269853		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.7220251436269853 | validation: 0.3645729970033732]
	TIME [epoch: 6.32 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7215223486698996		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.7215223486698996 | validation: 0.3649216753397459]
	TIME [epoch: 6.32 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7218744562100737		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.7218744562100737 | validation: 0.3649434549158617]
	TIME [epoch: 6.37 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7211469847756822		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.7211469847756822 | validation: 0.3595007286688022]
	TIME [epoch: 6.32 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.721415749225238		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.721415749225238 | validation: 0.3724157904039059]
	TIME [epoch: 6.31 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7218395042144885		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.7218395042144885 | validation: 0.36744659633349713]
	TIME [epoch: 6.31 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7195275933977758		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.7195275933977758 | validation: 0.3656050690148506]
	TIME [epoch: 6.32 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7239512147074227		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.7239512147074227 | validation: 0.3714574741031812]
	TIME [epoch: 6.32 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7214087011692062		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.7214087011692062 | validation: 0.36546879317063824]
	TIME [epoch: 6.37 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.721721403295521		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.721721403295521 | validation: 0.3645673458654908]
	TIME [epoch: 6.32 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7237513755113156		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.7237513755113156 | validation: 0.36831980699394595]
	TIME [epoch: 6.31 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7193909357592322		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.7193909357592322 | validation: 0.36009893873088067]
	TIME [epoch: 6.31 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7188961434631448		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.7188961434631448 | validation: 0.3639863171603974]
	TIME [epoch: 6.31 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7236345279398662		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.7236345279398662 | validation: 0.3658211840304872]
	TIME [epoch: 6.32 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7210373089614681		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.7210373089614681 | validation: 0.3605968920414805]
	TIME [epoch: 6.36 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.722552793886383		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.722552793886383 | validation: 0.3638497783033678]
	TIME [epoch: 6.32 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7178772168218585		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.7178772168218585 | validation: 0.366428780159388]
	TIME [epoch: 6.31 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7261271244841949		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.7261271244841949 | validation: 0.3636891473489789]
	TIME [epoch: 6.32 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7228816561843272		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.7228816561843272 | validation: 0.36692568581411694]
	TIME [epoch: 6.32 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7160373078190427		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.7160373078190427 | validation: 0.36415975513649246]
	TIME [epoch: 6.33 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7188004592271607		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.7188004592271607 | validation: 0.36678246654045693]
	TIME [epoch: 6.37 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.722149203951181		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.722149203951181 | validation: 0.3612997794884609]
	TIME [epoch: 6.32 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7184794892184541		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.7184794892184541 | validation: 0.36532904913519537]
	TIME [epoch: 6.31 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7185436854871432		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.7185436854871432 | validation: 0.36280877431065245]
	TIME [epoch: 6.31 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7204489563733911		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.7204489563733911 | validation: 0.35983702117406163]
	TIME [epoch: 6.31 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7205158001259043		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.7205158001259043 | validation: 0.3541281010786626]
	TIME [epoch: 6.3 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7203155841933075		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.7203155841933075 | validation: 0.3673281864120927]
	TIME [epoch: 6.37 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7196897110566056		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.7196897110566056 | validation: 0.3579485805805186]
	TIME [epoch: 6.32 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7231664112912765		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.7231664112912765 | validation: 0.3698267032427726]
	TIME [epoch: 6.32 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7187128046265394		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.7187128046265394 | validation: 0.36351539120973914]
	TIME [epoch: 6.32 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7178929431381773		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.7178929431381773 | validation: 0.362540731996689]
	TIME [epoch: 6.3 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7235349123553856		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.7235349123553856 | validation: 0.3619124096163064]
	TIME [epoch: 6.31 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7181223331555983		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.7181223331555983 | validation: 0.36545197131815255]
	TIME [epoch: 6.35 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7214040019423555		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.7214040019423555 | validation: 0.35946071349882225]
	TIME [epoch: 6.32 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7172509641831937		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.7172509641831937 | validation: 0.36993158688534755]
	TIME [epoch: 6.32 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7194915371416993		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.7194915371416993 | validation: 0.35796502952875314]
	TIME [epoch: 6.32 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7209423104569859		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.7209423104569859 | validation: 0.37155387157364383]
	TIME [epoch: 6.32 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7196161582463587		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.7196161582463587 | validation: 0.3617728529178434]
	TIME [epoch: 6.31 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7188335288671517		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.7188335288671517 | validation: 0.360723729430991]
	TIME [epoch: 6.36 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7204390227986064		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.7204390227986064 | validation: 0.35925733010386834]
	TIME [epoch: 6.32 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7186367329184442		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.7186367329184442 | validation: 0.36546873874689034]
	TIME [epoch: 6.32 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7209340170697902		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.7209340170697902 | validation: 0.3660898414814061]
	TIME [epoch: 6.32 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7211738805096546		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.7211738805096546 | validation: 0.3722251635266323]
	TIME [epoch: 6.31 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7185143556575158		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.7185143556575158 | validation: 0.3732700946899381]
	TIME [epoch: 6.31 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7201473218508686		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.7201473218508686 | validation: 0.36332805609763463]
	TIME [epoch: 6.36 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7191978632216335		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.7191978632216335 | validation: 0.3577085406434469]
	TIME [epoch: 6.34 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7211552432962078		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.7211552432962078 | validation: 0.353839584753763]
	TIME [epoch: 6.32 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.719027057707705		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.719027057707705 | validation: 0.35627598307128217]
	TIME [epoch: 6.31 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7198188720265081		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.7198188720265081 | validation: 0.362083944298387]
	TIME [epoch: 6.33 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.718490428525379		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.718490428525379 | validation: 0.3597264293937103]
	TIME [epoch: 6.32 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7185018991185217		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.7185018991185217 | validation: 0.3678434531563673]
	TIME [epoch: 6.36 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7210312522252741		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.7210312522252741 | validation: 0.36456558900024383]
	TIME [epoch: 6.34 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7253490361627655		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.7253490361627655 | validation: 0.37442386468846606]
	TIME [epoch: 6.32 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7238862661239636		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.7238862661239636 | validation: 0.36575044556063935]
	TIME [epoch: 6.32 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7208396519759013		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.7208396519759013 | validation: 0.35173494605618305]
	TIME [epoch: 6.31 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7227226324848275		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.7227226324848275 | validation: 0.3641020645068269]
	TIME [epoch: 6.31 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7201520864456147		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.7201520864456147 | validation: 0.3593636341403894]
	TIME [epoch: 6.35 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7226253875744887		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.7226253875744887 | validation: 0.3589917505575201]
	TIME [epoch: 6.35 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7219496335757241		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.7219496335757241 | validation: 0.3689430254233984]
	TIME [epoch: 6.32 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.718118050515319		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.718118050515319 | validation: 0.3553054089961903]
	TIME [epoch: 6.31 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7202926993933902		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.7202926993933902 | validation: 0.36232940677229375]
	TIME [epoch: 6.32 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7189294861688013		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.7189294861688013 | validation: 0.36397623502518706]
	TIME [epoch: 6.31 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7170214390417334		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.7170214390417334 | validation: 0.36787157831530437]
	TIME [epoch: 6.34 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7186875881430687		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.7186875881430687 | validation: 0.3530184626123914]
	TIME [epoch: 6.35 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7175005322895909		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.7175005322895909 | validation: 0.37886724531802296]
	TIME [epoch: 6.32 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7176193763245804		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.7176193763245804 | validation: 0.35669670117448005]
	TIME [epoch: 6.31 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.714813689822801		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.714813689822801 | validation: 0.3642342107019752]
	TIME [epoch: 6.32 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7204844931520648		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.7204844931520648 | validation: 0.36445377583390215]
	TIME [epoch: 6.32 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7194300661201168		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.7194300661201168 | validation: 0.36481717868533764]
	TIME [epoch: 6.34 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.718893419496828		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.718893419496828 | validation: 0.3706793672599864]
	TIME [epoch: 6.34 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7223316072815736		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.7223316072815736 | validation: 0.3647928256667498]
	TIME [epoch: 6.32 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7209428081823439		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.7209428081823439 | validation: 0.36466245101052375]
	TIME [epoch: 6.3 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.721058579126766		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.721058579126766 | validation: 0.36057639384063056]
	TIME [epoch: 6.32 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7199554504110827		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.7199554504110827 | validation: 0.35870211167838223]
	TIME [epoch: 6.32 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7210261200253888		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.7210261200253888 | validation: 0.3675731424275256]
	TIME [epoch: 6.34 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7205678464189225		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.7205678464189225 | validation: 0.3579137889637313]
	TIME [epoch: 6.35 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.71760377842109		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.71760377842109 | validation: 0.3653454555653869]
	TIME [epoch: 6.32 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7202569551416572		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.7202569551416572 | validation: 0.3610148044047594]
	TIME [epoch: 6.32 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7209008794251232		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.7209008794251232 | validation: 0.35917352078344406]
	TIME [epoch: 6.31 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7200218384212544		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.7200218384212544 | validation: 0.36424536606235713]
	TIME [epoch: 6.32 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.716847743364554		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.716847743364554 | validation: 0.36316309088475746]
	TIME [epoch: 6.35 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7172377173960178		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.7172377173960178 | validation: 0.36066680844789567]
	TIME [epoch: 6.34 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7219766701905388		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.7219766701905388 | validation: 0.36568834475313733]
	TIME [epoch: 6.31 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7197376286817906		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.7197376286817906 | validation: 0.35789904683089846]
	TIME [epoch: 6.32 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7225443589243814		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.7225443589243814 | validation: 0.3676004406359553]
	TIME [epoch: 6.32 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.720275460111405		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.720275460111405 | validation: 0.3656486095490106]
	TIME [epoch: 6.31 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7177314556422032		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.7177314556422032 | validation: 0.35819735283392556]
	TIME [epoch: 6.34 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7250637027061945		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.7250637027061945 | validation: 0.35415653846733347]
	TIME [epoch: 6.35 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7217175014304272		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.7217175014304272 | validation: 0.3616252381049871]
	TIME [epoch: 6.31 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7214415309213853		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.7214415309213853 | validation: 0.3612343834857399]
	TIME [epoch: 6.32 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7218328802551633		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.7218328802551633 | validation: 0.3668545584056233]
	TIME [epoch: 6.32 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7223550306457414		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.7223550306457414 | validation: 0.3720522113638012]
	TIME [epoch: 6.31 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7217156664310812		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.7217156664310812 | validation: 0.3637140462349725]
	TIME [epoch: 6.33 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7227024137799144		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.7227024137799144 | validation: 0.35829269575974587]
	TIME [epoch: 6.36 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7190265980426365		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.7190265980426365 | validation: 0.3678952084551481]
	TIME [epoch: 6.33 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7235162256409005		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.7235162256409005 | validation: 0.36386317324556394]
	TIME [epoch: 6.32 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7218704278302019		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.7218704278302019 | validation: 0.3686241831988861]
	TIME [epoch: 6.31 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7230367595420797		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.7230367595420797 | validation: 0.3554250638340588]
	TIME [epoch: 6.32 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7204610764823733		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.7204610764823733 | validation: 0.3683435980998483]
	TIME [epoch: 6.34 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7203173985062585		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.7203173985062585 | validation: 0.3724923178072931]
	TIME [epoch: 6.35 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7203715029422395		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.7203715029422395 | validation: 0.3657590133308538]
	TIME [epoch: 6.31 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7141795053111961		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.7141795053111961 | validation: 0.35854476762029436]
	TIME [epoch: 6.32 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7188147137613977		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.7188147137613977 | validation: 0.36058404789135157]
	TIME [epoch: 6.33 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7182757750249624		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.7182757750249624 | validation: 0.36786066511838494]
	TIME [epoch: 6.32 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7191703471998598		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.7191703471998598 | validation: 0.36382726677343247]
	TIME [epoch: 6.32 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7180114536874409		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.7180114536874409 | validation: 0.3662987365069713]
	TIME [epoch: 6.37 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7185675893266947		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.7185675893266947 | validation: 0.3581653231291069]
	TIME [epoch: 6.33 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7187754359590078		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.7187754359590078 | validation: 0.3616831241811432]
	TIME [epoch: 6.31 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.71779285158535		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.71779285158535 | validation: 0.36620690663243166]
	TIME [epoch: 6.32 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7175354525400146		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.7175354525400146 | validation: 0.3615456579094979]
	TIME [epoch: 6.32 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7214000141197391		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.7214000141197391 | validation: 0.36305903364760433]
	TIME [epoch: 6.33 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7211109066265262		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.7211109066265262 | validation: 0.36564331611949086]
	TIME [epoch: 6.36 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7196890258258797		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.7196890258258797 | validation: 0.3630376335757916]
	TIME [epoch: 6.32 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7206315943796613		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.7206315943796613 | validation: 0.36274815559634815]
	TIME [epoch: 6.31 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7221414938037675		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.7221414938037675 | validation: 0.36047427054912007]
	TIME [epoch: 6.32 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7207465091725851		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.7207465091725851 | validation: 0.37202232966059245]
	TIME [epoch: 6.32 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7169322329199601		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.7169322329199601 | validation: 0.3548775820501103]
	TIME [epoch: 6.33 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7187593087174186		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.7187593087174186 | validation: 0.3693078195794243]
	TIME [epoch: 6.36 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7204705979175496		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.7204705979175496 | validation: 0.3591344042940506]
	TIME [epoch: 6.33 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7171609281363667		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.7171609281363667 | validation: 0.36278798498465914]
	TIME [epoch: 6.31 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7183287044539497		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.7183287044539497 | validation: 0.36135333063279723]
	TIME [epoch: 6.31 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7219158223274683		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.7219158223274683 | validation: 0.36569123387871894]
	TIME [epoch: 6.32 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7188967324377121		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.7188967324377121 | validation: 0.37192383149673597]
	TIME [epoch: 6.32 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.719815981761105		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.719815981761105 | validation: 0.35641546238525107]
	TIME [epoch: 6.35 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7198290673881501		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.7198290673881501 | validation: 0.3740834776239932]
	TIME [epoch: 6.33 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7211766726904015		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.7211766726904015 | validation: 0.3707810521800561]
	TIME [epoch: 6.32 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.719693617866229		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.719693617866229 | validation: 0.36277531454922185]
	TIME [epoch: 6.32 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7209115686785865		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.7209115686785865 | validation: 0.366305885216235]
	TIME [epoch: 6.32 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7186139503829927		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.7186139503829927 | validation: 0.3669418555850377]
	TIME [epoch: 6.33 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.719654709511319		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.719654709511319 | validation: 0.36615518854329404]
	TIME [epoch: 6.37 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7232210473041382		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.7232210473041382 | validation: 0.36713069272301496]
	TIME [epoch: 6.33 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7190289595866317		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.7190289595866317 | validation: 0.36632896105997137]
	TIME [epoch: 6.32 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7179170615562018		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.7179170615562018 | validation: 0.36454290509718473]
	TIME [epoch: 6.31 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7209650020445907		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.7209650020445907 | validation: 0.3656474067561362]
	TIME [epoch: 6.32 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7203180441464974		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.7203180441464974 | validation: 0.36464080807675]
	TIME [epoch: 6.35 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7207098081138408		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.7207098081138408 | validation: 0.36521726459775655]
	TIME [epoch: 6.37 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7209232510118406		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.7209232510118406 | validation: 0.36129170374002273]
	TIME [epoch: 6.32 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.719370741671711		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.719370741671711 | validation: 0.3712595954199278]
	TIME [epoch: 6.32 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7160638108551615		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.7160638108551615 | validation: 0.35947131277569255]
	TIME [epoch: 6.32 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7210697672543092		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.7210697672543092 | validation: 0.368108243989971]
	TIME [epoch: 6.33 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7209152678316484		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.7209152678316484 | validation: 0.3605404185694158]
	TIME [epoch: 6.33 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7201347563538467		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.7201347563538467 | validation: 0.3604746691998667]
	TIME [epoch: 6.36 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7226245261586313		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.7226245261586313 | validation: 0.3594212347793484]
	TIME [epoch: 6.32 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7225029938457705		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.7225029938457705 | validation: 0.36939072114935545]
	TIME [epoch: 6.31 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7208245848232517		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.7208245848232517 | validation: 0.3582690387515704]
	TIME [epoch: 6.32 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7204703466536102		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.7204703466536102 | validation: 0.366138380773255]
	TIME [epoch: 6.31 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7176571939796575		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.7176571939796575 | validation: 0.35947529608296924]
	TIME [epoch: 6.31 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.722780927294951		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.722780927294951 | validation: 0.37397210855886664]
	TIME [epoch: 6.35 sec]
Finished training in 12866.020 seconds.
