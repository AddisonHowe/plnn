Args:
Namespace(name='model_phi2_1a_v1', outdir='out/model_training/model_phi2_1a_v1', training_data='data/training_data/data_phi2_1a/training', validation_data='data/training_data/data_phi2_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 617085632

Training model...

Saving initial model state to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.69084592769978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.69084592769978 | validation: 8.614466902590754]
	TIME [epoch: 104 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.515628073453922		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.515628073453922 | validation: 7.911108628299632]
	TIME [epoch: 7.01 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.983944323634207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.983944323634207 | validation: 7.7785420173524225]
	TIME [epoch: 6.58 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.337899647885683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.337899647885683 | validation: 5.184487985739965]
	TIME [epoch: 6.62 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.293925311435528		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.293925311435528 | validation: 3.8640263497703105]
	TIME [epoch: 6.57 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.610305934561045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.610305934561045 | validation: 4.386182543638946]
	TIME [epoch: 6.57 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5134823194803415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5134823194803415 | validation: 2.851569545278457]
	TIME [epoch: 6.57 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7369284975967503		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7369284975967503 | validation: 3.565907938919421]
	TIME [epoch: 6.57 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5984300977000405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5984300977000405 | validation: 1.8120372145815002]
	TIME [epoch: 6.61 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1075313556517927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1075313556517927 | validation: 2.2607414099134315]
	TIME [epoch: 6.57 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3420080728573422		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3420080728573422 | validation: 4.8976479925697785]
	TIME [epoch: 6.57 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7674183743380683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7674183743380683 | validation: 1.6930976490915932]
	TIME [epoch: 6.57 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9040240475657182		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9040240475657182 | validation: 1.862555988331026]
	TIME [epoch: 6.57 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1287897919415437		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1287897919415437 | validation: 1.282639528765745]
	TIME [epoch: 6.6 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8393862572371646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8393862572371646 | validation: 1.8837231832250942]
	TIME [epoch: 6.58 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7860354128205862		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7860354128205862 | validation: 1.6121435073301722]
	TIME [epoch: 6.58 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.84831078038444		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.84831078038444 | validation: 1.4845205881768853]
	TIME [epoch: 6.56 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.081741577495718		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.081741577495718 | validation: 1.6681050974921479]
	TIME [epoch: 6.57 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8449798432733864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8449798432733864 | validation: 2.9085457132897483]
	TIME [epoch: 6.58 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.999184609243687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.999184609243687 | validation: 1.2779229439445232]
	TIME [epoch: 6.6 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.335163922565783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.335163922565783 | validation: 6.055194529894994]
	TIME [epoch: 6.57 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.1140231942445435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.1140231942445435 | validation: 5.716282795495144]
	TIME [epoch: 6.57 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.817535029531253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.817535029531253 | validation: 4.839536978735882]
	TIME [epoch: 6.56 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5867372703385065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5867372703385065 | validation: 2.5516689723538803]
	TIME [epoch: 6.56 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.526919577552935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.526919577552935 | validation: 2.3807238255367267]
	TIME [epoch: 6.6 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1592342524877193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1592342524877193 | validation: 1.4047008726144945]
	TIME [epoch: 6.57 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.217687015473242		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.217687015473242 | validation: 1.497287321545321]
	TIME [epoch: 6.58 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.705259827249736		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.705259827249736 | validation: 1.4299776652578375]
	TIME [epoch: 6.57 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5483149221982013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5483149221982013 | validation: 2.0383476878430598]
	TIME [epoch: 6.57 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6630736111652271		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6630736111652271 | validation: 1.497114975223347]
	TIME [epoch: 6.58 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7759550026033737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7759550026033737 | validation: 1.19551576305859]
	TIME [epoch: 6.6 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5236053764973776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5236053764973776 | validation: 1.7757559485380625]
	TIME [epoch: 6.57 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6273350430462372		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6273350430462372 | validation: 1.1573855071368646]
	TIME [epoch: 6.57 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3981739946346279		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3981739946346279 | validation: 1.6114266708846006]
	TIME [epoch: 6.56 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7367741919032516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7367741919032516 | validation: 1.0538273127172824]
	TIME [epoch: 6.56 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5977762859698892		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5977762859698892 | validation: 1.203068814546222]
	TIME [epoch: 6.61 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4109612883012692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4109612883012692 | validation: 1.114058799879392]
	TIME [epoch: 6.58 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.339665945804081		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.339665945804081 | validation: 0.9194679483848753]
	TIME [epoch: 6.57 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3340205404864807		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3340205404864807 | validation: 1.01554564054578]
	TIME [epoch: 6.58 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4501501830126116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4501501830126116 | validation: 0.9227994419119663]
	TIME [epoch: 6.58 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.272873051572309		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.272873051572309 | validation: 0.9967148887585813]
	TIME [epoch: 6.61 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3190493612659502		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3190493612659502 | validation: 0.9101230032210137]
	TIME [epoch: 6.59 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2207611801699532		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2207611801699532 | validation: 0.8701618515001205]
	TIME [epoch: 6.58 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5906366123250661		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5906366123250661 | validation: 1.0432952145988774]
	TIME [epoch: 6.57 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3601572034912828		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3601572034912828 | validation: 1.7033467617424582]
	TIME [epoch: 6.57 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.471781951403544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.471781951403544 | validation: 1.2049519249095562]
	TIME [epoch: 6.57 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2586089792583854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2586089792583854 | validation: 1.1695477322576788]
	TIME [epoch: 6.62 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5566980613047048		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5566980613047048 | validation: 0.9993344030084527]
	TIME [epoch: 6.58 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.337413711240497		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.337413711240497 | validation: 1.253627673164322]
	TIME [epoch: 6.58 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.258485513089187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.258485513089187 | validation: 0.844196113591043]
	TIME [epoch: 6.57 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1307427417984972		[learning rate: 0.0099811]
	Learning Rate: 0.00998112
	LOSS [training: 1.1307427417984972 | validation: 1.0444910600544572]
	TIME [epoch: 6.58 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5375266847588553		[learning rate: 0.0099576]
	Learning Rate: 0.00995758
	LOSS [training: 1.5375266847588553 | validation: 1.043621276719421]
	TIME [epoch: 6.61 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4801527671623682		[learning rate: 0.0099341]
	Learning Rate: 0.00993409
	LOSS [training: 1.4801527671623682 | validation: 0.9558689083753371]
	TIME [epoch: 6.59 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3520938501409723		[learning rate: 0.0099107]
	Learning Rate: 0.00991066
	LOSS [training: 1.3520938501409723 | validation: 1.089056271624962]
	TIME [epoch: 6.58 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2663870877175532		[learning rate: 0.0098873]
	Learning Rate: 0.00988728
	LOSS [training: 1.2663870877175532 | validation: 1.1048625634208056]
	TIME [epoch: 6.58 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.31932083766494		[learning rate: 0.009864]
	Learning Rate: 0.00986396
	LOSS [training: 1.31932083766494 | validation: 1.0076827865911717]
	TIME [epoch: 6.57 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.433066374796175		[learning rate: 0.0098407]
	Learning Rate: 0.00984069
	LOSS [training: 1.433066374796175 | validation: 0.9505237230812122]
	TIME [epoch: 6.62 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8503370823061283		[learning rate: 0.0098175]
	Learning Rate: 0.00981748
	LOSS [training: 1.8503370823061283 | validation: 0.8724170484220226]
	TIME [epoch: 6.59 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1452230143094557		[learning rate: 0.0097943]
	Learning Rate: 0.00979432
	LOSS [training: 1.1452230143094557 | validation: 0.9882949217137812]
	TIME [epoch: 6.58 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.248693959769026		[learning rate: 0.0097712]
	Learning Rate: 0.00977122
	LOSS [training: 1.248693959769026 | validation: 1.018012095397432]
	TIME [epoch: 6.59 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4786782747003264		[learning rate: 0.0097482]
	Learning Rate: 0.00974817
	LOSS [training: 1.4786782747003264 | validation: 1.1561763815325137]
	TIME [epoch: 6.59 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2854886167311506		[learning rate: 0.0097252]
	Learning Rate: 0.00972517
	LOSS [training: 1.2854886167311506 | validation: 0.917551944622964]
	TIME [epoch: 6.6 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1905738750680361		[learning rate: 0.0097022]
	Learning Rate: 0.00970223
	LOSS [training: 1.1905738750680361 | validation: 1.046689058630853]
	TIME [epoch: 6.62 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1917508636889111		[learning rate: 0.0096793]
	Learning Rate: 0.00967935
	LOSS [training: 1.1917508636889111 | validation: 0.8101354367417664]
	TIME [epoch: 6.58 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0632280817480348		[learning rate: 0.0096565]
	Learning Rate: 0.00965652
	LOSS [training: 1.0632280817480348 | validation: 0.8000558177969235]
	TIME [epoch: 6.58 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1171667395379647		[learning rate: 0.0096337]
	Learning Rate: 0.00963374
	LOSS [training: 1.1171667395379647 | validation: 0.8512210968844924]
	TIME [epoch: 6.58 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2371945715139343		[learning rate: 0.009611]
	Learning Rate: 0.00961101
	LOSS [training: 1.2371945715139343 | validation: 0.8957936358314642]
	TIME [epoch: 6.6 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.339717075517584		[learning rate: 0.0095883]
	Learning Rate: 0.00958834
	LOSS [training: 1.339717075517584 | validation: 1.0293632720832862]
	TIME [epoch: 6.61 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1414411731514242		[learning rate: 0.0095657]
	Learning Rate: 0.00956573
	LOSS [training: 1.1414411731514242 | validation: 0.7798519859902312]
	TIME [epoch: 6.59 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7750213261710694		[learning rate: 0.0095432]
	Learning Rate: 0.00954316
	LOSS [training: 1.7750213261710694 | validation: 0.8978190617564104]
	TIME [epoch: 6.58 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.071159194839056		[learning rate: 0.0095207]
	Learning Rate: 0.00952065
	LOSS [training: 1.071159194839056 | validation: 0.7732357693581223]
	TIME [epoch: 6.57 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0228970856177981		[learning rate: 0.0094982]
	Learning Rate: 0.00949819
	LOSS [training: 1.0228970856177981 | validation: 0.7904767634143122]
	TIME [epoch: 6.58 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.067078490184081		[learning rate: 0.0094758]
	Learning Rate: 0.00947579
	LOSS [training: 1.067078490184081 | validation: 0.9241131766748569]
	TIME [epoch: 6.62 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1265957883653126		[learning rate: 0.0094534]
	Learning Rate: 0.00945344
	LOSS [training: 1.1265957883653126 | validation: 0.9229282963610816]
	TIME [epoch: 6.58 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1362660264675113		[learning rate: 0.0094311]
	Learning Rate: 0.00943114
	LOSS [training: 1.1362660264675113 | validation: 1.9728446271438544]
	TIME [epoch: 6.58 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2990921064028396		[learning rate: 0.0094089]
	Learning Rate: 0.00940889
	LOSS [training: 1.2990921064028396 | validation: 0.7989089112917651]
	TIME [epoch: 6.58 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0678987529484865		[learning rate: 0.0093867]
	Learning Rate: 0.0093867
	LOSS [training: 1.0678987529484865 | validation: 0.7654203948104792]
	TIME [epoch: 6.58 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.208586221735751		[learning rate: 0.0093646]
	Learning Rate: 0.00936456
	LOSS [training: 1.208586221735751 | validation: 0.9121420814424225]
	TIME [epoch: 6.61 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1022881240983264		[learning rate: 0.0093425]
	Learning Rate: 0.00934247
	LOSS [training: 1.1022881240983264 | validation: 0.797722348940381]
	TIME [epoch: 6.58 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0588778535369212		[learning rate: 0.0093204]
	Learning Rate: 0.00932043
	LOSS [training: 1.0588778535369212 | validation: 0.7397442836807938]
	TIME [epoch: 6.58 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0271176964345872		[learning rate: 0.0092984]
	Learning Rate: 0.00929844
	LOSS [training: 1.0271176964345872 | validation: 0.8208864647272234]
	TIME [epoch: 6.58 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.299633935435765		[learning rate: 0.0092765]
	Learning Rate: 0.00927651
	LOSS [training: 1.299633935435765 | validation: 0.8561693704765665]
	TIME [epoch: 6.57 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0856441324573638		[learning rate: 0.0092546]
	Learning Rate: 0.00925463
	LOSS [training: 1.0856441324573638 | validation: 0.7646119751818468]
	TIME [epoch: 6.61 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.012502036636867		[learning rate: 0.0092328]
	Learning Rate: 0.0092328
	LOSS [training: 1.012502036636867 | validation: 0.7634278127003387]
	TIME [epoch: 6.59 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0515134110699436		[learning rate: 0.009211]
	Learning Rate: 0.00921102
	LOSS [training: 1.0515134110699436 | validation: 1.2114658959325326]
	TIME [epoch: 6.57 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.089139344494328		[learning rate: 0.0091893]
	Learning Rate: 0.00918929
	LOSS [training: 1.089139344494328 | validation: 0.9079235512258391]
	TIME [epoch: 6.58 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0894772338584167		[learning rate: 0.0091676]
	Learning Rate: 0.00916762
	LOSS [training: 1.0894772338584167 | validation: 0.8201014186021818]
	TIME [epoch: 6.57 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0392190608227008		[learning rate: 0.009146]
	Learning Rate: 0.00914599
	LOSS [training: 1.0392190608227008 | validation: 2.5004383280053775]
	TIME [epoch: 6.6 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4557410403678352		[learning rate: 0.0091244]
	Learning Rate: 0.00912442
	LOSS [training: 1.4557410403678352 | validation: 0.8221597429936913]
	TIME [epoch: 6.59 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.019582175991512		[learning rate: 0.0091029]
	Learning Rate: 0.00910289
	LOSS [training: 1.019582175991512 | validation: 0.8399319121413142]
	TIME [epoch: 6.58 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2223947026681867		[learning rate: 0.0090814]
	Learning Rate: 0.00908142
	LOSS [training: 1.2223947026681867 | validation: 0.9272205916806875]
	TIME [epoch: 6.57 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1013296409299052		[learning rate: 0.00906]
	Learning Rate: 0.00906
	LOSS [training: 1.1013296409299052 | validation: 0.8564064362780958]
	TIME [epoch: 6.58 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0691875921452216		[learning rate: 0.0090386]
	Learning Rate: 0.00903863
	LOSS [training: 1.0691875921452216 | validation: 0.8343046613136493]
	TIME [epoch: 6.59 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0487084286999635		[learning rate: 0.0090173]
	Learning Rate: 0.00901731
	LOSS [training: 1.0487084286999635 | validation: 0.9458062596080582]
	TIME [epoch: 6.61 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0286125061273552		[learning rate: 0.008996]
	Learning Rate: 0.00899604
	LOSS [training: 1.0286125061273552 | validation: 0.8527999372534246]
	TIME [epoch: 6.59 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.043049422981054		[learning rate: 0.0089748]
	Learning Rate: 0.00897482
	LOSS [training: 1.043049422981054 | validation: 0.8531332084096981]
	TIME [epoch: 6.58 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0377321408565652		[learning rate: 0.0089536]
	Learning Rate: 0.00895365
	LOSS [training: 1.0377321408565652 | validation: 3.891282881868639]
	TIME [epoch: 6.58 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.718671984591215		[learning rate: 0.0089325]
	Learning Rate: 0.00893253
	LOSS [training: 1.718671984591215 | validation: 0.9926488342114433]
	TIME [epoch: 6.58 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0564416291470275		[learning rate: 0.0089115]
	Learning Rate: 0.00891146
	LOSS [training: 1.0564416291470275 | validation: 0.7600096065747581]
	TIME [epoch: 6.62 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9936358682108997		[learning rate: 0.0088904]
	Learning Rate: 0.00889044
	LOSS [training: 0.9936358682108997 | validation: 0.7204728118217144]
	TIME [epoch: 6.58 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9854111281945069		[learning rate: 0.0088695]
	Learning Rate: 0.00886946
	LOSS [training: 0.9854111281945069 | validation: 0.8082256873052851]
	TIME [epoch: 6.59 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2429883195485498		[learning rate: 0.0088485]
	Learning Rate: 0.00884854
	LOSS [training: 1.2429883195485498 | validation: 1.2785592496967861]
	TIME [epoch: 6.6 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1195967477847681		[learning rate: 0.0088277]
	Learning Rate: 0.00882767
	LOSS [training: 1.1195967477847681 | validation: 0.754035227665889]
	TIME [epoch: 6.6 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0004382753653176		[learning rate: 0.0088068]
	Learning Rate: 0.00880685
	LOSS [training: 1.0004382753653176 | validation: 0.7333816304940124]
	TIME [epoch: 6.64 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5784731690053746		[learning rate: 0.0087861]
	Learning Rate: 0.00878607
	LOSS [training: 1.5784731690053746 | validation: 1.3997093669158205]
	TIME [epoch: 6.6 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1366643583636633		[learning rate: 0.0087653]
	Learning Rate: 0.00876535
	LOSS [training: 1.1366643583636633 | validation: 0.7411983232372741]
	TIME [epoch: 6.6 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0388288542581718		[learning rate: 0.0087447]
	Learning Rate: 0.00874467
	LOSS [training: 1.0388288542581718 | validation: 0.7275511815568325]
	TIME [epoch: 6.59 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9846898110571596		[learning rate: 0.008724]
	Learning Rate: 0.00872405
	LOSS [training: 0.9846898110571596 | validation: 0.810124406897019]
	TIME [epoch: 6.58 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0452456317068786		[learning rate: 0.0087035]
	Learning Rate: 0.00870347
	LOSS [training: 1.0452456317068786 | validation: 0.8741396085736826]
	TIME [epoch: 6.62 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9948897538003607		[learning rate: 0.0086829]
	Learning Rate: 0.00868294
	LOSS [training: 0.9948897538003607 | validation: 0.8064106032500702]
	TIME [epoch: 6.59 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9744957327738184		[learning rate: 0.0086625]
	Learning Rate: 0.00866246
	LOSS [training: 0.9744957327738184 | validation: 0.7440123130104521]
	TIME [epoch: 6.58 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.986092709858603		[learning rate: 0.008642]
	Learning Rate: 0.00864202
	LOSS [training: 0.986092709858603 | validation: 0.9130942178521432]
	TIME [epoch: 6.58 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0282340763937807		[learning rate: 0.0086216]
	Learning Rate: 0.00862164
	LOSS [training: 1.0282340763937807 | validation: 0.7945589105497657]
	TIME [epoch: 6.59 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.084734178080632		[learning rate: 0.0086013]
	Learning Rate: 0.0086013
	LOSS [training: 1.084734178080632 | validation: 0.6882825844994923]
	TIME [epoch: 6.62 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_114.pth
	Model improved!!!
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.01933683288458		[learning rate: 0.008581]
	Learning Rate: 0.00858101
	LOSS [training: 1.01933683288458 | validation: 0.7157545553587369]
	TIME [epoch: 6.6 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0052275640285064		[learning rate: 0.0085608]
	Learning Rate: 0.00856077
	LOSS [training: 1.0052275640285064 | validation: 0.788180081072545]
	TIME [epoch: 6.58 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9820572712364978		[learning rate: 0.0085406]
	Learning Rate: 0.00854058
	LOSS [training: 0.9820572712364978 | validation: 0.9694142692488665]
	TIME [epoch: 6.58 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0364730749998532		[learning rate: 0.0085204]
	Learning Rate: 0.00852043
	LOSS [training: 1.0364730749998532 | validation: 0.7783369651105981]
	TIME [epoch: 6.58 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.135286271369431		[learning rate: 0.0085003]
	Learning Rate: 0.00850033
	LOSS [training: 1.135286271369431 | validation: 0.7277449461376833]
	TIME [epoch: 6.59 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0280333934292851		[learning rate: 0.0084803]
	Learning Rate: 0.00848028
	LOSS [training: 1.0280333934292851 | validation: 0.8247402139806101]
	TIME [epoch: 6.62 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1789647080163266		[learning rate: 0.0084603]
	Learning Rate: 0.00846028
	LOSS [training: 1.1789647080163266 | validation: 1.0852494360457565]
	TIME [epoch: 6.59 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.207385581563634		[learning rate: 0.0084403]
	Learning Rate: 0.00844032
	LOSS [training: 1.207385581563634 | validation: 0.8478667383276155]
	TIME [epoch: 6.56 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0958946141465007		[learning rate: 0.0084204]
	Learning Rate: 0.00842041
	LOSS [training: 1.0958946141465007 | validation: 0.7079626800251438]
	TIME [epoch: 6.57 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0326694700502212		[learning rate: 0.0084005]
	Learning Rate: 0.00840055
	LOSS [training: 1.0326694700502212 | validation: 0.7557159461941505]
	TIME [epoch: 6.57 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0448013841424717		[learning rate: 0.0083807]
	Learning Rate: 0.00838073
	LOSS [training: 1.0448013841424717 | validation: 0.7832947570494657]
	TIME [epoch: 6.6 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.003121292345543		[learning rate: 0.008361]
	Learning Rate: 0.00836096
	LOSS [training: 1.003121292345543 | validation: 0.7229465462093727]
	TIME [epoch: 6.57 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1383846494048675		[learning rate: 0.0083412]
	Learning Rate: 0.00834124
	LOSS [training: 1.1383846494048675 | validation: 0.7560851532796298]
	TIME [epoch: 6.57 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0099447694829493		[learning rate: 0.0083216]
	Learning Rate: 0.00832157
	LOSS [training: 1.0099447694829493 | validation: 0.8960265043397617]
	TIME [epoch: 6.57 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3269828516410993		[learning rate: 0.0083019]
	Learning Rate: 0.00830194
	LOSS [training: 1.3269828516410993 | validation: 1.0387373417826151]
	TIME [epoch: 6.57 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1645030807514567		[learning rate: 0.0082824]
	Learning Rate: 0.00828236
	LOSS [training: 1.1645030807514567 | validation: 0.7803178310472993]
	TIME [epoch: 6.61 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0243502839467076		[learning rate: 0.0082628]
	Learning Rate: 0.00826282
	LOSS [training: 1.0243502839467076 | validation: 0.7761422670880553]
	TIME [epoch: 6.58 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9908740536351223		[learning rate: 0.0082433]
	Learning Rate: 0.00824333
	LOSS [training: 0.9908740536351223 | validation: 1.3256749350307604]
	TIME [epoch: 6.57 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1886874732784416		[learning rate: 0.0082239]
	Learning Rate: 0.00822388
	LOSS [training: 1.1886874732784416 | validation: 0.7316047685117232]
	TIME [epoch: 6.57 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.027558736352536		[learning rate: 0.0082045]
	Learning Rate: 0.00820448
	LOSS [training: 1.027558736352536 | validation: 0.8685144311758088]
	TIME [epoch: 6.57 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0084752056682205		[learning rate: 0.0081851]
	Learning Rate: 0.00818513
	LOSS [training: 1.0084752056682205 | validation: 0.7477474264834927]
	TIME [epoch: 6.6 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0218788947336814		[learning rate: 0.0081658]
	Learning Rate: 0.00816582
	LOSS [training: 1.0218788947336814 | validation: 0.8012060268224096]
	TIME [epoch: 6.58 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0605022250995977		[learning rate: 0.0081466]
	Learning Rate: 0.00814656
	LOSS [training: 1.0605022250995977 | validation: 0.6767640955255104]
	TIME [epoch: 6.58 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_137.pth
	Model improved!!!
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.05890377729834		[learning rate: 0.0081273]
	Learning Rate: 0.00812735
	LOSS [training: 1.05890377729834 | validation: 0.7409815528766288]
	TIME [epoch: 6.58 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0143298833611287		[learning rate: 0.0081082]
	Learning Rate: 0.00810817
	LOSS [training: 1.0143298833611287 | validation: 0.7019233731372908]
	TIME [epoch: 6.57 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0100718261113564		[learning rate: 0.008089]
	Learning Rate: 0.00808905
	LOSS [training: 1.0100718261113564 | validation: 0.7606343632396716]
	TIME [epoch: 6.58 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0110969334743578		[learning rate: 0.00807]
	Learning Rate: 0.00806997
	LOSS [training: 1.0110969334743578 | validation: 0.7055075108706625]
	TIME [epoch: 6.6 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1256187384041352		[learning rate: 0.0080509]
	Learning Rate: 0.00805093
	LOSS [training: 1.1256187384041352 | validation: 0.7176481974900819]
	TIME [epoch: 6.57 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9551370790137673		[learning rate: 0.0080319]
	Learning Rate: 0.00803194
	LOSS [training: 0.9551370790137673 | validation: 0.8348275571536412]
	TIME [epoch: 6.57 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9962096497674496		[learning rate: 0.008013]
	Learning Rate: 0.00801299
	LOSS [training: 0.9962096497674496 | validation: 0.8225395523700838]
	TIME [epoch: 6.57 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9563211595998146		[learning rate: 0.0079941]
	Learning Rate: 0.00799409
	LOSS [training: 0.9563211595998146 | validation: 0.8300444975825364]
	TIME [epoch: 6.57 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9482677021729737		[learning rate: 0.0079752]
	Learning Rate: 0.00797524
	LOSS [training: 0.9482677021729737 | validation: 0.6627170382165709]
	TIME [epoch: 6.61 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_146.pth
	Model improved!!!
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8733645621626206		[learning rate: 0.0079564]
	Learning Rate: 0.00795642
	LOSS [training: 0.8733645621626206 | validation: 0.6083524827070692]
	TIME [epoch: 6.58 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_147.pth
	Model improved!!!
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8461596664780968		[learning rate: 0.0079377]
	Learning Rate: 0.00793766
	LOSS [training: 0.8461596664780968 | validation: 0.7261262936900755]
	TIME [epoch: 6.58 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5693489930273109		[learning rate: 0.0079189]
	Learning Rate: 0.00791893
	LOSS [training: 0.5693489930273109 | validation: 0.38541947225115625]
	TIME [epoch: 6.57 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_149.pth
	Model improved!!!
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3869902893623941		[learning rate: 0.0079003]
	Learning Rate: 0.00790025
	LOSS [training: 0.3869902893623941 | validation: 0.4385160037970257]
	TIME [epoch: 6.58 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3215448486230982		[learning rate: 0.0078816]
	Learning Rate: 0.00788162
	LOSS [training: 0.3215448486230982 | validation: 0.28623837935845076]
	TIME [epoch: 6.61 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2876052575098377		[learning rate: 0.007863]
	Learning Rate: 0.00786303
	LOSS [training: 0.2876052575098377 | validation: 0.2961968639066648]
	TIME [epoch: 6.58 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2844183028024975		[learning rate: 0.0078445]
	Learning Rate: 0.00784448
	LOSS [training: 0.2844183028024975 | validation: 0.5128530355724868]
	TIME [epoch: 6.57 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43901948423375653		[learning rate: 0.007826]
	Learning Rate: 0.00782597
	LOSS [training: 0.43901948423375653 | validation: 0.5701353268572675]
	TIME [epoch: 6.58 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39782477511033487		[learning rate: 0.0078075]
	Learning Rate: 0.00780751
	LOSS [training: 0.39782477511033487 | validation: 0.2969695061388768]
	TIME [epoch: 6.57 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3066573320252551		[learning rate: 0.0077891]
	Learning Rate: 0.0077891
	LOSS [training: 0.3066573320252551 | validation: 0.2468290367276728]
	TIME [epoch: 6.62 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_156.pth
	Model improved!!!
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3665689361998479		[learning rate: 0.0077707]
	Learning Rate: 0.00777072
	LOSS [training: 0.3665689361998479 | validation: 0.49502860824078043]
	TIME [epoch: 6.58 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35606904305321957		[learning rate: 0.0077524]
	Learning Rate: 0.00775239
	LOSS [training: 0.35606904305321957 | validation: 0.3132782487810921]
	TIME [epoch: 6.57 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2872381787858257		[learning rate: 0.0077341]
	Learning Rate: 0.00773411
	LOSS [training: 0.2872381787858257 | validation: 0.22983835182535078]
	TIME [epoch: 6.57 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_159.pth
	Model improved!!!
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28591765987600687		[learning rate: 0.0077159]
	Learning Rate: 0.00771586
	LOSS [training: 0.28591765987600687 | validation: 0.2850063900034915]
	TIME [epoch: 6.57 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4287427243148111		[learning rate: 0.0076977]
	Learning Rate: 0.00769766
	LOSS [training: 0.4287427243148111 | validation: 0.3824838587785205]
	TIME [epoch: 6.61 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31013993403274726		[learning rate: 0.0076795]
	Learning Rate: 0.00767951
	LOSS [training: 0.31013993403274726 | validation: 0.2646542110102773]
	TIME [epoch: 6.57 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27180107003871934		[learning rate: 0.0076614]
	Learning Rate: 0.00766139
	LOSS [training: 0.27180107003871934 | validation: 0.30038705032450935]
	TIME [epoch: 6.57 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26793006411691345		[learning rate: 0.0076433]
	Learning Rate: 0.00764332
	LOSS [training: 0.26793006411691345 | validation: 0.1926878494291786]
	TIME [epoch: 6.57 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_164.pth
	Model improved!!!
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32209190162995754		[learning rate: 0.0076253]
	Learning Rate: 0.00762529
	LOSS [training: 0.32209190162995754 | validation: 0.39909124719986855]
	TIME [epoch: 6.57 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2846816627701809		[learning rate: 0.0076073]
	Learning Rate: 0.0076073
	LOSS [training: 0.2846816627701809 | validation: 0.28927888061014406]
	TIME [epoch: 6.6 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30202327136721696		[learning rate: 0.0075894]
	Learning Rate: 0.00758936
	LOSS [training: 0.30202327136721696 | validation: 0.23926042458408783]
	TIME [epoch: 6.57 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37182785194774787		[learning rate: 0.0075715]
	Learning Rate: 0.00757146
	LOSS [training: 0.37182785194774787 | validation: 0.28721245920887134]
	TIME [epoch: 6.57 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30199216474269985		[learning rate: 0.0075536]
	Learning Rate: 0.0075536
	LOSS [training: 0.30199216474269985 | validation: 0.3011014553574166]
	TIME [epoch: 6.57 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28219157612539536		[learning rate: 0.0075358]
	Learning Rate: 0.00753578
	LOSS [training: 0.28219157612539536 | validation: 0.35005539318515394]
	TIME [epoch: 6.57 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29633392489014004		[learning rate: 0.007518]
	Learning Rate: 0.007518
	LOSS [training: 0.29633392489014004 | validation: 0.1927424036003449]
	TIME [epoch: 6.6 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27047199845570186		[learning rate: 0.0075003]
	Learning Rate: 0.00750027
	LOSS [training: 0.27047199845570186 | validation: 0.2606953085434843]
	TIME [epoch: 6.58 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2826380216076557		[learning rate: 0.0074826]
	Learning Rate: 0.00748258
	LOSS [training: 0.2826380216076557 | validation: 0.34427251417735727]
	TIME [epoch: 6.57 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24226579743827298		[learning rate: 0.0074649]
	Learning Rate: 0.00746493
	LOSS [training: 0.24226579743827298 | validation: 0.23299955771306638]
	TIME [epoch: 6.57 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25756414873499445		[learning rate: 0.0074473]
	Learning Rate: 0.00744732
	LOSS [training: 0.25756414873499445 | validation: 0.26196904154788375]
	TIME [epoch: 6.58 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28578297210834674		[learning rate: 0.0074298]
	Learning Rate: 0.00742975
	LOSS [training: 0.28578297210834674 | validation: 0.17729764985043045]
	TIME [epoch: 6.58 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_176.pth
	Model improved!!!
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22874291596607854		[learning rate: 0.0074122]
	Learning Rate: 0.00741223
	LOSS [training: 0.22874291596607854 | validation: 0.2691300519205605]
	TIME [epoch: 6.61 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.235274450019261		[learning rate: 0.0073947]
	Learning Rate: 0.00739474
	LOSS [training: 0.235274450019261 | validation: 0.17595542530945474]
	TIME [epoch: 6.57 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_178.pth
	Model improved!!!
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22593783463812006		[learning rate: 0.0073773]
	Learning Rate: 0.0073773
	LOSS [training: 0.22593783463812006 | validation: 0.1965407895245037]
	TIME [epoch: 6.58 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21983413188998085		[learning rate: 0.0073599]
	Learning Rate: 0.0073599
	LOSS [training: 0.21983413188998085 | validation: 0.3070270350235731]
	TIME [epoch: 6.58 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22513015624285568		[learning rate: 0.0073425]
	Learning Rate: 0.00734254
	LOSS [training: 0.22513015624285568 | validation: 0.18890111663093512]
	TIME [epoch: 6.58 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.241372505105441		[learning rate: 0.0073252]
	Learning Rate: 0.00732522
	LOSS [training: 0.241372505105441 | validation: 0.2186611250428261]
	TIME [epoch: 6.61 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2611809804347268		[learning rate: 0.0073079]
	Learning Rate: 0.00730794
	LOSS [training: 0.2611809804347268 | validation: 0.1702460388646726]
	TIME [epoch: 6.59 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_183.pth
	Model improved!!!
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20737629813049607		[learning rate: 0.0072907]
	Learning Rate: 0.0072907
	LOSS [training: 0.20737629813049607 | validation: 0.24572816501680733]
	TIME [epoch: 6.58 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.250868306489783		[learning rate: 0.0072735]
	Learning Rate: 0.0072735
	LOSS [training: 0.250868306489783 | validation: 0.1744752814481085]
	TIME [epoch: 6.58 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23364114937029692		[learning rate: 0.0072563]
	Learning Rate: 0.00725635
	LOSS [training: 0.23364114937029692 | validation: 0.25248624603918834]
	TIME [epoch: 6.58 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24497069425700105		[learning rate: 0.0072392]
	Learning Rate: 0.00723923
	LOSS [training: 0.24497069425700105 | validation: 0.3170462920393475]
	TIME [epoch: 6.62 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23044375691262084		[learning rate: 0.0072222]
	Learning Rate: 0.00722215
	LOSS [training: 0.23044375691262084 | validation: 0.17910781053623187]
	TIME [epoch: 6.58 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18732784570866126		[learning rate: 0.0072051]
	Learning Rate: 0.00720512
	LOSS [training: 0.18732784570866126 | validation: 0.24562744362195899]
	TIME [epoch: 6.58 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24174752840445812		[learning rate: 0.0071881]
	Learning Rate: 0.00718812
	LOSS [training: 0.24174752840445812 | validation: 0.3902657797733254]
	TIME [epoch: 6.58 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27273987121489573		[learning rate: 0.0071712]
	Learning Rate: 0.00717117
	LOSS [training: 0.27273987121489573 | validation: 0.1497626597165529]
	TIME [epoch: 6.58 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_191.pth
	Model improved!!!
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20947628861391654		[learning rate: 0.0071542]
	Learning Rate: 0.00715425
	LOSS [training: 0.20947628861391654 | validation: 0.202677476207616]
	TIME [epoch: 6.61 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1993638576128067		[learning rate: 0.0071374]
	Learning Rate: 0.00713737
	LOSS [training: 0.1993638576128067 | validation: 0.21214462921768862]
	TIME [epoch: 6.59 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24923769834757853		[learning rate: 0.0071205]
	Learning Rate: 0.00712054
	LOSS [training: 0.24923769834757853 | validation: 0.13045951478042467]
	TIME [epoch: 6.57 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_194.pth
	Model improved!!!
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18230703016712596		[learning rate: 0.0071037]
	Learning Rate: 0.00710374
	LOSS [training: 0.18230703016712596 | validation: 0.24219656671773165]
	TIME [epoch: 6.57 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2041870188337101		[learning rate: 0.007087]
	Learning Rate: 0.00708698
	LOSS [training: 0.2041870188337101 | validation: 0.1935888657627703]
	TIME [epoch: 6.57 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20849997557490899		[learning rate: 0.0070703]
	Learning Rate: 0.00707027
	LOSS [training: 0.20849997557490899 | validation: 0.2581928279765535]
	TIME [epoch: 6.61 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3318611966994703		[learning rate: 0.0070536]
	Learning Rate: 0.00705359
	LOSS [training: 0.3318611966994703 | validation: 0.2535300426348139]
	TIME [epoch: 6.59 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2542224727268124		[learning rate: 0.007037]
	Learning Rate: 0.00703695
	LOSS [training: 0.2542224727268124 | validation: 0.10590666143531843]
	TIME [epoch: 6.58 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_199.pth
	Model improved!!!
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16174146908406273		[learning rate: 0.0070204]
	Learning Rate: 0.00702035
	LOSS [training: 0.16174146908406273 | validation: 0.22736054241638798]
	TIME [epoch: 6.58 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27261181535662193		[learning rate: 0.0070038]
	Learning Rate: 0.00700379
	LOSS [training: 0.27261181535662193 | validation: 0.24150236431178226]
	TIME [epoch: 6.58 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.184226391645181		[learning rate: 0.0069873]
	Learning Rate: 0.00698727
	LOSS [training: 0.184226391645181 | validation: 0.1212110651995974]
	TIME [epoch: 6.61 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1773370775472249		[learning rate: 0.0069708]
	Learning Rate: 0.00697079
	LOSS [training: 0.1773370775472249 | validation: 0.13509536270423816]
	TIME [epoch: 6.6 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2246626394857718		[learning rate: 0.0069543]
	Learning Rate: 0.00695435
	LOSS [training: 0.2246626394857718 | validation: 0.08245306133870253]
	TIME [epoch: 6.58 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_204.pth
	Model improved!!!
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20114910633563848		[learning rate: 0.0069379]
	Learning Rate: 0.00693794
	LOSS [training: 0.20114910633563848 | validation: 0.2727610806133833]
	TIME [epoch: 6.58 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16111418656221643		[learning rate: 0.0069216]
	Learning Rate: 0.00692158
	LOSS [training: 0.16111418656221643 | validation: 0.178710156076227]
	TIME [epoch: 6.58 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29494800985247616		[learning rate: 0.0069053]
	Learning Rate: 0.00690525
	LOSS [training: 0.29494800985247616 | validation: 0.17483078230153432]
	TIME [epoch: 6.59 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15593277918302167		[learning rate: 0.006889]
	Learning Rate: 0.00688896
	LOSS [training: 0.15593277918302167 | validation: 0.15460756874990403]
	TIME [epoch: 6.61 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17948542531583087		[learning rate: 0.0068727]
	Learning Rate: 0.00687271
	LOSS [training: 0.17948542531583087 | validation: 0.1473961077338329]
	TIME [epoch: 6.58 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1883268504147499		[learning rate: 0.0068565]
	Learning Rate: 0.0068565
	LOSS [training: 0.1883268504147499 | validation: 0.16212977968518197]
	TIME [epoch: 6.57 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1759852206730224		[learning rate: 0.0068403]
	Learning Rate: 0.00684033
	LOSS [training: 0.1759852206730224 | validation: 0.16772339193836863]
	TIME [epoch: 6.58 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1844421394310455		[learning rate: 0.0068242]
	Learning Rate: 0.00682419
	LOSS [training: 0.1844421394310455 | validation: 0.15449480088445766]
	TIME [epoch: 6.58 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2597613611617209		[learning rate: 0.0068081]
	Learning Rate: 0.0068081
	LOSS [training: 0.2597613611617209 | validation: 0.13243358589644857]
	TIME [epoch: 6.6 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.156683174673429		[learning rate: 0.006792]
	Learning Rate: 0.00679204
	LOSS [training: 0.156683174673429 | validation: 0.26177711912631174]
	TIME [epoch: 6.57 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.198282955450294		[learning rate: 0.006776]
	Learning Rate: 0.00677601
	LOSS [training: 0.198282955450294 | validation: 0.1277483326866439]
	TIME [epoch: 6.57 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14886646347793514		[learning rate: 0.00676]
	Learning Rate: 0.00676003
	LOSS [training: 0.14886646347793514 | validation: 0.2327409825445864]
	TIME [epoch: 6.57 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16274259983918987		[learning rate: 0.0067441]
	Learning Rate: 0.00674409
	LOSS [training: 0.16274259983918987 | validation: 0.11882131658319278]
	TIME [epoch: 6.56 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2733450782838083		[learning rate: 0.0067282]
	Learning Rate: 0.00672818
	LOSS [training: 0.2733450782838083 | validation: 0.29958681287991107]
	TIME [epoch: 6.59 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2820544325202973		[learning rate: 0.0067123]
	Learning Rate: 0.00671231
	LOSS [training: 0.2820544325202973 | validation: 0.15553804850957276]
	TIME [epoch: 6.57 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13682037123005675		[learning rate: 0.0066965]
	Learning Rate: 0.00669647
	LOSS [training: 0.13682037123005675 | validation: 0.10921958520345436]
	TIME [epoch: 6.57 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17780120855676446		[learning rate: 0.0066807]
	Learning Rate: 0.00668068
	LOSS [training: 0.17780120855676446 | validation: 0.08672546742153961]
	TIME [epoch: 6.58 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1467217274432216		[learning rate: 0.0066649]
	Learning Rate: 0.00666492
	LOSS [training: 0.1467217274432216 | validation: 0.24115872728934395]
	TIME [epoch: 6.57 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20936344447263977		[learning rate: 0.0066492]
	Learning Rate: 0.0066492
	LOSS [training: 0.20936344447263977 | validation: 0.14193797320231877]
	TIME [epoch: 6.61 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14756641606475673		[learning rate: 0.0066335]
	Learning Rate: 0.00663351
	LOSS [training: 0.14756641606475673 | validation: 0.16985395737118397]
	TIME [epoch: 6.58 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14144036717273012		[learning rate: 0.0066179]
	Learning Rate: 0.00661787
	LOSS [training: 0.14144036717273012 | validation: 0.09558572609930861]
	TIME [epoch: 6.58 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1234603674530731		[learning rate: 0.0066023]
	Learning Rate: 0.00660226
	LOSS [training: 0.1234603674530731 | validation: 0.10186087606687641]
	TIME [epoch: 6.57 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15418301716067506		[learning rate: 0.0065867]
	Learning Rate: 0.00658668
	LOSS [training: 0.15418301716067506 | validation: 0.19993798966122114]
	TIME [epoch: 6.57 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25271143962899734		[learning rate: 0.0065711]
	Learning Rate: 0.00657114
	LOSS [training: 0.25271143962899734 | validation: 0.14059999351259178]
	TIME [epoch: 6.58 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12695393666567328		[learning rate: 0.0065556]
	Learning Rate: 0.00655564
	LOSS [training: 0.12695393666567328 | validation: 0.0672718925923289]
	TIME [epoch: 6.6 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_229.pth
	Model improved!!!
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11057679641522182		[learning rate: 0.0065402]
	Learning Rate: 0.00654018
	LOSS [training: 0.11057679641522182 | validation: 0.09409257474626306]
	TIME [epoch: 6.57 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14217869034489058		[learning rate: 0.0065248]
	Learning Rate: 0.00652475
	LOSS [training: 0.14217869034489058 | validation: 0.1251995434685153]
	TIME [epoch: 6.56 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14087829361249865		[learning rate: 0.0065094]
	Learning Rate: 0.00650936
	LOSS [training: 0.14087829361249865 | validation: 0.13180270092349236]
	TIME [epoch: 6.57 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16581272161909824		[learning rate: 0.006494]
	Learning Rate: 0.00649401
	LOSS [training: 0.16581272161909824 | validation: 0.0963513412175634]
	TIME [epoch: 6.57 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.238656537321646		[learning rate: 0.0064787]
	Learning Rate: 0.00647869
	LOSS [training: 0.238656537321646 | validation: 0.1936002522004981]
	TIME [epoch: 6.6 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15596875666592588		[learning rate: 0.0064634]
	Learning Rate: 0.00646341
	LOSS [training: 0.15596875666592588 | validation: 0.1980526469437937]
	TIME [epoch: 6.57 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16002229004364615		[learning rate: 0.0064482]
	Learning Rate: 0.00644816
	LOSS [training: 0.16002229004364615 | validation: 0.11235408786345401]
	TIME [epoch: 6.57 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14263350597327046		[learning rate: 0.006433]
	Learning Rate: 0.00643295
	LOSS [training: 0.14263350597327046 | validation: 0.14575687617165148]
	TIME [epoch: 6.57 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11455637977040874		[learning rate: 0.0064178]
	Learning Rate: 0.00641778
	LOSS [training: 0.11455637977040874 | validation: 0.09043776352511089]
	TIME [epoch: 6.57 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09707630045133865		[learning rate: 0.0064026]
	Learning Rate: 0.00640264
	LOSS [training: 0.09707630045133865 | validation: 0.13082342041573697]
	TIME [epoch: 6.6 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15582538597757836		[learning rate: 0.0063875]
	Learning Rate: 0.00638754
	LOSS [training: 0.15582538597757836 | validation: 0.26510870145444754]
	TIME [epoch: 6.57 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3143071728265726		[learning rate: 0.0063725]
	Learning Rate: 0.00637247
	LOSS [training: 0.3143071728265726 | validation: 0.28428815979935074]
	TIME [epoch: 6.57 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20114317098030648		[learning rate: 0.0063574]
	Learning Rate: 0.00635744
	LOSS [training: 0.20114317098030648 | validation: 0.1141053744616228]
	TIME [epoch: 6.57 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16762358085265494		[learning rate: 0.0063424]
	Learning Rate: 0.00634244
	LOSS [training: 0.16762358085265494 | validation: 0.1509800317422511]
	TIME [epoch: 6.56 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1382296258599691		[learning rate: 0.0063275]
	Learning Rate: 0.00632748
	LOSS [training: 0.1382296258599691 | validation: 0.16466703317119785]
	TIME [epoch: 6.6 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14246835622609144		[learning rate: 0.0063126]
	Learning Rate: 0.00631255
	LOSS [training: 0.14246835622609144 | validation: 0.2785397577084361]
	TIME [epoch: 6.58 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.358516162355654		[learning rate: 0.0062977]
	Learning Rate: 0.00629766
	LOSS [training: 0.358516162355654 | validation: 0.05409898254048599]
	TIME [epoch: 6.57 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_246.pth
	Model improved!!!
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09704799976073451		[learning rate: 0.0062828]
	Learning Rate: 0.00628281
	LOSS [training: 0.09704799976073451 | validation: 0.09366202981477245]
	TIME [epoch: 6.57 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13377480734210004		[learning rate: 0.006268]
	Learning Rate: 0.00626799
	LOSS [training: 0.13377480734210004 | validation: 0.22504073873287211]
	TIME [epoch: 6.56 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20270623863600257		[learning rate: 0.0062532]
	Learning Rate: 0.0062532
	LOSS [training: 0.20270623863600257 | validation: 0.08870169453101373]
	TIME [epoch: 6.59 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10182154598310537		[learning rate: 0.0062385]
	Learning Rate: 0.00623845
	LOSS [training: 0.10182154598310537 | validation: 0.37039169661896704]
	TIME [epoch: 6.57 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2392733297642637		[learning rate: 0.0062237]
	Learning Rate: 0.00622374
	LOSS [training: 0.2392733297642637 | validation: 0.13828948095968807]
	TIME [epoch: 6.56 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17444408934115394		[learning rate: 0.0062091]
	Learning Rate: 0.00620906
	LOSS [training: 0.17444408934115394 | validation: 0.07448567967447574]
	TIME [epoch: 6.56 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11473968719878669		[learning rate: 0.0061944]
	Learning Rate: 0.00619441
	LOSS [training: 0.11473968719878669 | validation: 0.11256300209841039]
	TIME [epoch: 6.56 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16419705908258772		[learning rate: 0.0061798]
	Learning Rate: 0.0061798
	LOSS [training: 0.16419705908258772 | validation: 0.1166376376247561]
	TIME [epoch: 6.57 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13140324323938013		[learning rate: 0.0061652]
	Learning Rate: 0.00616522
	LOSS [training: 0.13140324323938013 | validation: 0.07879326784273408]
	TIME [epoch: 6.59 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12218192691511051		[learning rate: 0.0061507]
	Learning Rate: 0.00615068
	LOSS [training: 0.12218192691511051 | validation: 0.19555524787107464]
	TIME [epoch: 6.57 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14293591409437273		[learning rate: 0.0061362]
	Learning Rate: 0.00613617
	LOSS [training: 0.14293591409437273 | validation: 0.10765026475703438]
	TIME [epoch: 6.57 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17493788892656517		[learning rate: 0.0061217]
	Learning Rate: 0.0061217
	LOSS [training: 0.17493788892656517 | validation: 0.10643420599206349]
	TIME [epoch: 6.56 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1207675343276375		[learning rate: 0.0061073]
	Learning Rate: 0.00610726
	LOSS [training: 0.1207675343276375 | validation: 0.3427956811889733]
	TIME [epoch: 6.56 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2211824268154238		[learning rate: 0.0060929]
	Learning Rate: 0.00609285
	LOSS [training: 0.2211824268154238 | validation: 0.26988179601045825]
	TIME [epoch: 6.6 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21778215831811437		[learning rate: 0.0060785]
	Learning Rate: 0.00607848
	LOSS [training: 0.21778215831811437 | validation: 0.14403345253842176]
	TIME [epoch: 6.56 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15973346182427262		[learning rate: 0.0060641]
	Learning Rate: 0.00606414
	LOSS [training: 0.15973346182427262 | validation: 0.10307452352903967]
	TIME [epoch: 6.56 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12196895420860288		[learning rate: 0.0060498]
	Learning Rate: 0.00604984
	LOSS [training: 0.12196895420860288 | validation: 0.18185189191227297]
	TIME [epoch: 6.57 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19990356555595482		[learning rate: 0.0060356]
	Learning Rate: 0.00603556
	LOSS [training: 0.19990356555595482 | validation: 0.07399422119524843]
	TIME [epoch: 6.57 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12227353501709762		[learning rate: 0.0060213]
	Learning Rate: 0.00602133
	LOSS [training: 0.12227353501709762 | validation: 0.0908819165321767]
	TIME [epoch: 6.61 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21753219710782012		[learning rate: 0.0060071]
	Learning Rate: 0.00600712
	LOSS [training: 0.21753219710782012 | validation: 0.12512206550097923]
	TIME [epoch: 6.58 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23809538741588496		[learning rate: 0.005993]
	Learning Rate: 0.00599296
	LOSS [training: 0.23809538741588496 | validation: 0.08805313604789841]
	TIME [epoch: 6.57 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15098040338959262		[learning rate: 0.0059788]
	Learning Rate: 0.00597882
	LOSS [training: 0.15098040338959262 | validation: 0.1345488256250257]
	TIME [epoch: 6.56 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14851261460865262		[learning rate: 0.0059647]
	Learning Rate: 0.00596472
	LOSS [training: 0.14851261460865262 | validation: 0.0788410369637942]
	TIME [epoch: 6.57 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11016038946589062		[learning rate: 0.0059506]
	Learning Rate: 0.00595065
	LOSS [training: 0.11016038946589062 | validation: 0.12390800312025343]
	TIME [epoch: 6.58 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15566845009776664		[learning rate: 0.0059366]
	Learning Rate: 0.00593661
	LOSS [training: 0.15566845009776664 | validation: 0.08090784482552349]
	TIME [epoch: 6.59 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13154111402318847		[learning rate: 0.0059226]
	Learning Rate: 0.00592261
	LOSS [training: 0.13154111402318847 | validation: 0.07551899033373055]
	TIME [epoch: 6.57 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17361509736763497		[learning rate: 0.0059086]
	Learning Rate: 0.00590863
	LOSS [training: 0.17361509736763497 | validation: 0.09082955624419109]
	TIME [epoch: 6.56 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12150797419687757		[learning rate: 0.0058947]
	Learning Rate: 0.0058947
	LOSS [training: 0.12150797419687757 | validation: 0.08631934081910925]
	TIME [epoch: 6.57 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13770693295694378		[learning rate: 0.0058808]
	Learning Rate: 0.00588079
	LOSS [training: 0.13770693295694378 | validation: 0.1030469491795818]
	TIME [epoch: 6.57 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17259746302345888		[learning rate: 0.0058669]
	Learning Rate: 0.00586692
	LOSS [training: 0.17259746302345888 | validation: 0.09971318020374634]
	TIME [epoch: 6.6 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17094308098507738		[learning rate: 0.0058531]
	Learning Rate: 0.00585308
	LOSS [training: 0.17094308098507738 | validation: 0.13490577282752153]
	TIME [epoch: 6.57 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14811354635742618		[learning rate: 0.0058393]
	Learning Rate: 0.00583928
	LOSS [training: 0.14811354635742618 | validation: 0.14618612023283778]
	TIME [epoch: 6.56 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12082435283929134		[learning rate: 0.0058255]
	Learning Rate: 0.0058255
	LOSS [training: 0.12082435283929134 | validation: 0.05743286271216241]
	TIME [epoch: 6.56 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12756081106573874		[learning rate: 0.0058118]
	Learning Rate: 0.00581176
	LOSS [training: 0.12756081106573874 | validation: 0.09859052106407346]
	TIME [epoch: 6.56 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13441775192781796		[learning rate: 0.0057981]
	Learning Rate: 0.00579805
	LOSS [training: 0.13441775192781796 | validation: 0.06914453392664252]
	TIME [epoch: 6.6 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1210534098984489		[learning rate: 0.0057844]
	Learning Rate: 0.00578438
	LOSS [training: 0.1210534098984489 | validation: 0.09303325966046662]
	TIME [epoch: 6.56 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13873765200301547		[learning rate: 0.0057707]
	Learning Rate: 0.00577073
	LOSS [training: 0.13873765200301547 | validation: 0.16846422718146753]
	TIME [epoch: 6.56 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14975857292632327		[learning rate: 0.0057571]
	Learning Rate: 0.00575712
	LOSS [training: 0.14975857292632327 | validation: 0.09138633891796202]
	TIME [epoch: 6.56 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11734709496994158		[learning rate: 0.0057435]
	Learning Rate: 0.00574354
	LOSS [training: 0.11734709496994158 | validation: 0.07681336865213567]
	TIME [epoch: 6.56 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08260127402777034		[learning rate: 0.00573]
	Learning Rate: 0.00572999
	LOSS [training: 0.08260127402777034 | validation: 0.056195986619296374]
	TIME [epoch: 6.6 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1141169594911136		[learning rate: 0.0057165]
	Learning Rate: 0.00571647
	LOSS [training: 0.1141169594911136 | validation: 0.2530663714274456]
	TIME [epoch: 6.57 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1511257111690329		[learning rate: 0.005703]
	Learning Rate: 0.00570299
	LOSS [training: 0.1511257111690329 | validation: 0.0644103959928743]
	TIME [epoch: 6.56 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12265607724677344		[learning rate: 0.0056895]
	Learning Rate: 0.00568954
	LOSS [training: 0.12265607724677344 | validation: 0.12909978044179948]
	TIME [epoch: 6.56 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0905810570114064		[learning rate: 0.0056761]
	Learning Rate: 0.00567612
	LOSS [training: 0.0905810570114064 | validation: 0.08531905576069317]
	TIME [epoch: 6.56 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13632811052948587		[learning rate: 0.0056627]
	Learning Rate: 0.00566273
	LOSS [training: 0.13632811052948587 | validation: 0.09811756354773235]
	TIME [epoch: 6.58 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15056919446873362		[learning rate: 0.0056494]
	Learning Rate: 0.00564937
	LOSS [training: 0.15056919446873362 | validation: 0.10532049988565492]
	TIME [epoch: 6.58 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11336231350026797		[learning rate: 0.005636]
	Learning Rate: 0.00563604
	LOSS [training: 0.11336231350026797 | validation: 0.2770123220119227]
	TIME [epoch: 6.56 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1402334667702923		[learning rate: 0.0056227]
	Learning Rate: 0.00562275
	LOSS [training: 0.1402334667702923 | validation: 0.10263709613099618]
	TIME [epoch: 6.56 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11484751924469486		[learning rate: 0.0056095]
	Learning Rate: 0.00560949
	LOSS [training: 0.11484751924469486 | validation: 0.13558523013067372]
	TIME [epoch: 6.57 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12865106781370064		[learning rate: 0.0055963]
	Learning Rate: 0.00559625
	LOSS [training: 0.12865106781370064 | validation: 0.07536436999984078]
	TIME [epoch: 6.56 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09565071202998669		[learning rate: 0.0055831]
	Learning Rate: 0.00558305
	LOSS [training: 0.09565071202998669 | validation: 0.07399382248030173]
	TIME [epoch: 6.6 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10801844534610405		[learning rate: 0.0055699]
	Learning Rate: 0.00556988
	LOSS [training: 0.10801844534610405 | validation: 0.390969677622109]
	TIME [epoch: 6.57 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22763950210504397		[learning rate: 0.0055567]
	Learning Rate: 0.00555674
	LOSS [training: 0.22763950210504397 | validation: 0.10248542310683818]
	TIME [epoch: 6.57 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10070929641921156		[learning rate: 0.0055436]
	Learning Rate: 0.00554364
	LOSS [training: 0.10070929641921156 | validation: 0.05831724153676613]
	TIME [epoch: 6.57 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08752700675209525		[learning rate: 0.0055306]
	Learning Rate: 0.00553056
	LOSS [training: 0.08752700675209525 | validation: 0.07386282474531579]
	TIME [epoch: 6.57 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15587964774681515		[learning rate: 0.0055175]
	Learning Rate: 0.00551752
	LOSS [training: 0.15587964774681515 | validation: 0.149155684211961]
	TIME [epoch: 6.61 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14274353556347916		[learning rate: 0.0055045]
	Learning Rate: 0.0055045
	LOSS [training: 0.14274353556347916 | validation: 0.09889970016242405]
	TIME [epoch: 6.57 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11509346378338459		[learning rate: 0.0054915]
	Learning Rate: 0.00549152
	LOSS [training: 0.11509346378338459 | validation: 0.08100439695693623]
	TIME [epoch: 6.57 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11005621565597046		[learning rate: 0.0054786]
	Learning Rate: 0.00547856
	LOSS [training: 0.11005621565597046 | validation: 0.09849908631579468]
	TIME [epoch: 6.57 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09875468495300438		[learning rate: 0.0054656]
	Learning Rate: 0.00546564
	LOSS [training: 0.09875468495300438 | validation: 0.09829761538936882]
	TIME [epoch: 6.56 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12991613875532437		[learning rate: 0.0054527]
	Learning Rate: 0.00545275
	LOSS [training: 0.12991613875532437 | validation: 0.14287872012626104]
	TIME [epoch: 6.6 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10618099153076795		[learning rate: 0.0054399]
	Learning Rate: 0.00543988
	LOSS [training: 0.10618099153076795 | validation: 0.0739510164202694]
	TIME [epoch: 6.58 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07825896195911232		[learning rate: 0.0054271]
	Learning Rate: 0.00542705
	LOSS [training: 0.07825896195911232 | validation: 0.05857243199060437]
	TIME [epoch: 6.57 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11006054637863887		[learning rate: 0.0054143]
	Learning Rate: 0.00541425
	LOSS [training: 0.11006054637863887 | validation: 0.18829438053888187]
	TIME [epoch: 6.57 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10960643802410353		[learning rate: 0.0054015]
	Learning Rate: 0.00540148
	LOSS [training: 0.10960643802410353 | validation: 0.08586769077930897]
	TIME [epoch: 6.57 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.112814902497371		[learning rate: 0.0053887]
	Learning Rate: 0.00538874
	LOSS [training: 0.112814902497371 | validation: 0.12884846942879308]
	TIME [epoch: 6.58 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23724601997919986		[learning rate: 0.005376]
	Learning Rate: 0.00537603
	LOSS [training: 0.23724601997919986 | validation: 0.22877711203696233]
	TIME [epoch: 6.6 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34553439952033516		[learning rate: 0.0053633]
	Learning Rate: 0.00536335
	LOSS [training: 0.34553439952033516 | validation: 0.09676141335896245]
	TIME [epoch: 6.57 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09982920862076235		[learning rate: 0.0053507]
	Learning Rate: 0.00535069
	LOSS [training: 0.09982920862076235 | validation: 0.07686025336914051]
	TIME [epoch: 6.57 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09688581092643425		[learning rate: 0.0053381]
	Learning Rate: 0.00533807
	LOSS [training: 0.09688581092643425 | validation: 0.19490398109927098]
	TIME [epoch: 6.57 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13753825768423072		[learning rate: 0.0053255]
	Learning Rate: 0.00532548
	LOSS [training: 0.13753825768423072 | validation: 0.08550724840625822]
	TIME [epoch: 6.57 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07752540943448313		[learning rate: 0.0053129]
	Learning Rate: 0.00531292
	LOSS [training: 0.07752540943448313 | validation: 0.34433759696379296]
	TIME [epoch: 6.6 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1817956434791786		[learning rate: 0.0053004]
	Learning Rate: 0.00530039
	LOSS [training: 0.1817956434791786 | validation: 0.07170010142973196]
	TIME [epoch: 6.57 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13905063693257044		[learning rate: 0.0052879]
	Learning Rate: 0.00528789
	LOSS [training: 0.13905063693257044 | validation: 0.22218146325366026]
	TIME [epoch: 6.57 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13979190729836125		[learning rate: 0.0052754]
	Learning Rate: 0.00527541
	LOSS [training: 0.13979190729836125 | validation: 0.07096427070287972]
	TIME [epoch: 6.57 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08674404477119713		[learning rate: 0.005263]
	Learning Rate: 0.00526297
	LOSS [training: 0.08674404477119713 | validation: 0.07744649399416179]
	TIME [epoch: 6.56 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08559445195523101		[learning rate: 0.0052506]
	Learning Rate: 0.00525055
	LOSS [training: 0.08559445195523101 | validation: 0.08793215715905478]
	TIME [epoch: 6.6 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12209177521538683		[learning rate: 0.0052382]
	Learning Rate: 0.00523817
	LOSS [training: 0.12209177521538683 | validation: 0.07623408601894]
	TIME [epoch: 6.57 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1251666587867462		[learning rate: 0.0052258]
	Learning Rate: 0.00522581
	LOSS [training: 0.1251666587867462 | validation: 0.08216861017121956]
	TIME [epoch: 6.57 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11193686061053358		[learning rate: 0.0052135]
	Learning Rate: 0.00521349
	LOSS [training: 0.11193686061053358 | validation: 0.22755250494675883]
	TIME [epoch: 6.56 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23569678756816045		[learning rate: 0.0052012]
	Learning Rate: 0.00520119
	LOSS [training: 0.23569678756816045 | validation: 0.07401379266694041]
	TIME [epoch: 6.57 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11474942117411038		[learning rate: 0.0051889]
	Learning Rate: 0.00518892
	LOSS [training: 0.11474942117411038 | validation: 0.12359646159517243]
	TIME [epoch: 6.6 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12439686161760469		[learning rate: 0.0051767]
	Learning Rate: 0.00517668
	LOSS [training: 0.12439686161760469 | validation: 0.07391327967938222]
	TIME [epoch: 6.57 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1026127317770602		[learning rate: 0.0051645]
	Learning Rate: 0.00516447
	LOSS [training: 0.1026127317770602 | validation: 0.05872212537485105]
	TIME [epoch: 6.57 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09300391814169555		[learning rate: 0.0051523]
	Learning Rate: 0.00515229
	LOSS [training: 0.09300391814169555 | validation: 0.08241208021303928]
	TIME [epoch: 6.57 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11918291414400921		[learning rate: 0.0051401]
	Learning Rate: 0.00514013
	LOSS [training: 0.11918291414400921 | validation: 0.10721592963794904]
	TIME [epoch: 6.57 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11970545461579049		[learning rate: 0.005128]
	Learning Rate: 0.00512801
	LOSS [training: 0.11970545461579049 | validation: 0.07705469513735166]
	TIME [epoch: 6.58 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10380449322899148		[learning rate: 0.0051159]
	Learning Rate: 0.00511591
	LOSS [training: 0.10380449322899148 | validation: 0.7430455187234583]
	TIME [epoch: 6.6 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3751646545933939		[learning rate: 0.0051038]
	Learning Rate: 0.00510384
	LOSS [training: 0.3751646545933939 | validation: 0.11995787856976324]
	TIME [epoch: 6.56 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0999562527131278		[learning rate: 0.0050918]
	Learning Rate: 0.00509181
	LOSS [training: 0.0999562527131278 | validation: 0.08414189506344318]
	TIME [epoch: 6.56 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0978009802300025		[learning rate: 0.0050798]
	Learning Rate: 0.00507979
	LOSS [training: 0.0978009802300025 | validation: 0.12445423160270558]
	TIME [epoch: 6.56 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11871934755419322		[learning rate: 0.0050678]
	Learning Rate: 0.00506781
	LOSS [training: 0.11871934755419322 | validation: 0.07436371300323398]
	TIME [epoch: 6.57 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08930166164325452		[learning rate: 0.0050559]
	Learning Rate: 0.00505586
	LOSS [training: 0.08930166164325452 | validation: 0.07105440505261759]
	TIME [epoch: 6.61 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08385833670278103		[learning rate: 0.0050439]
	Learning Rate: 0.00504393
	LOSS [training: 0.08385833670278103 | validation: 0.06990617582530098]
	TIME [epoch: 6.57 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1543286361487032		[learning rate: 0.005032]
	Learning Rate: 0.00503203
	LOSS [training: 0.1543286361487032 | validation: 0.11886643275378249]
	TIME [epoch: 6.57 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10257150908333443		[learning rate: 0.0050202]
	Learning Rate: 0.00502016
	LOSS [training: 0.10257150908333443 | validation: 0.08889200259444766]
	TIME [epoch: 6.57 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10104584469693005		[learning rate: 0.0050083]
	Learning Rate: 0.00500832
	LOSS [training: 0.10104584469693005 | validation: 0.08205796615628878]
	TIME [epoch: 6.57 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09789917157673976		[learning rate: 0.0049965]
	Learning Rate: 0.00499651
	LOSS [training: 0.09789917157673976 | validation: 0.049928404507071575]
	TIME [epoch: 6.61 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_344.pth
	Model improved!!!
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0799516949368492		[learning rate: 0.0049847]
	Learning Rate: 0.00498472
	LOSS [training: 0.0799516949368492 | validation: 0.07655673776975315]
	TIME [epoch: 6.57 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10520208148517111		[learning rate: 0.004973]
	Learning Rate: 0.00497296
	LOSS [training: 0.10520208148517111 | validation: 0.053733678757557926]
	TIME [epoch: 6.56 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08754624452349999		[learning rate: 0.0049612]
	Learning Rate: 0.00496123
	LOSS [training: 0.08754624452349999 | validation: 0.14538739014704793]
	TIME [epoch: 6.57 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13465376698000067		[learning rate: 0.0049495]
	Learning Rate: 0.00494953
	LOSS [training: 0.13465376698000067 | validation: 0.07779600132799766]
	TIME [epoch: 6.57 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09354929600840235		[learning rate: 0.0049379]
	Learning Rate: 0.00493786
	LOSS [training: 0.09354929600840235 | validation: 0.10258964192920716]
	TIME [epoch: 6.6 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11823524787935216		[learning rate: 0.0049262]
	Learning Rate: 0.00492621
	LOSS [training: 0.11823524787935216 | validation: 0.10443288501427742]
	TIME [epoch: 6.58 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1750283464910667		[learning rate: 0.0049146]
	Learning Rate: 0.00491459
	LOSS [training: 0.1750283464910667 | validation: 0.09938601094342608]
	TIME [epoch: 6.57 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11365169989715351		[learning rate: 0.004903]
	Learning Rate: 0.004903
	LOSS [training: 0.11365169989715351 | validation: 0.1490188875783322]
	TIME [epoch: 6.56 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09759267640302824		[learning rate: 0.0048914]
	Learning Rate: 0.00489143
	LOSS [training: 0.09759267640302824 | validation: 0.09455695919308704]
	TIME [epoch: 6.56 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10101325207638276		[learning rate: 0.0048799]
	Learning Rate: 0.00487989
	LOSS [training: 0.10101325207638276 | validation: 0.06011337866118892]
	TIME [epoch: 6.59 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12522910033539775		[learning rate: 0.0048684]
	Learning Rate: 0.00486838
	LOSS [training: 0.12522910033539775 | validation: 0.12037005375667663]
	TIME [epoch: 6.58 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11981014083625183		[learning rate: 0.0048569]
	Learning Rate: 0.0048569
	LOSS [training: 0.11981014083625183 | validation: 0.05834693473032479]
	TIME [epoch: 6.56 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09621028516489975		[learning rate: 0.0048454]
	Learning Rate: 0.00484544
	LOSS [training: 0.09621028516489975 | validation: 0.18169620556955343]
	TIME [epoch: 6.56 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1027442128490413		[learning rate: 0.004834]
	Learning Rate: 0.00483401
	LOSS [training: 0.1027442128490413 | validation: 0.07241667929641768]
	TIME [epoch: 6.57 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12648027237868922		[learning rate: 0.0048226]
	Learning Rate: 0.00482261
	LOSS [training: 0.12648027237868922 | validation: 0.057905700073370765]
	TIME [epoch: 6.57 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08787727669775246		[learning rate: 0.0048112]
	Learning Rate: 0.00481123
	LOSS [training: 0.08787727669775246 | validation: 0.06468875121398801]
	TIME [epoch: 6.59 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10341019307397892		[learning rate: 0.0047999]
	Learning Rate: 0.00479988
	LOSS [training: 0.10341019307397892 | validation: 0.0685318294241931]
	TIME [epoch: 6.57 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09812193186342928		[learning rate: 0.0047886]
	Learning Rate: 0.00478856
	LOSS [training: 0.09812193186342928 | validation: 0.06659521196740448]
	TIME [epoch: 6.57 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09212090438149975		[learning rate: 0.0047773]
	Learning Rate: 0.00477727
	LOSS [training: 0.09212090438149975 | validation: 0.11388765729486976]
	TIME [epoch: 6.56 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1088835014482227		[learning rate: 0.004766]
	Learning Rate: 0.004766
	LOSS [training: 0.1088835014482227 | validation: 0.10807616926244185]
	TIME [epoch: 6.56 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19506663999796373		[learning rate: 0.0047548]
	Learning Rate: 0.00475476
	LOSS [training: 0.19506663999796373 | validation: 0.12991941757637013]
	TIME [epoch: 6.6 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13331960864235873		[learning rate: 0.0047435]
	Learning Rate: 0.00474354
	LOSS [training: 0.13331960864235873 | validation: 0.09814790133225874]
	TIME [epoch: 6.57 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09905908712436422		[learning rate: 0.0047324]
	Learning Rate: 0.00473235
	LOSS [training: 0.09905908712436422 | validation: 0.05734111370830862]
	TIME [epoch: 6.56 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11963444786502268		[learning rate: 0.0047212]
	Learning Rate: 0.00472119
	LOSS [training: 0.11963444786502268 | validation: 0.07474412918585174]
	TIME [epoch: 6.57 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09886167368641843		[learning rate: 0.0047101]
	Learning Rate: 0.00471005
	LOSS [training: 0.09886167368641843 | validation: 0.14996133885841895]
	TIME [epoch: 6.56 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14394165575782242		[learning rate: 0.0046989]
	Learning Rate: 0.00469894
	LOSS [training: 0.14394165575782242 | validation: 0.06839185355606173]
	TIME [epoch: 6.6 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09054728240813051		[learning rate: 0.0046879]
	Learning Rate: 0.00468786
	LOSS [training: 0.09054728240813051 | validation: 0.05774278126279268]
	TIME [epoch: 6.57 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08026201385793523		[learning rate: 0.0046768]
	Learning Rate: 0.0046768
	LOSS [training: 0.08026201385793523 | validation: 0.07378576743475104]
	TIME [epoch: 6.56 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09235083516585915		[learning rate: 0.0046658]
	Learning Rate: 0.00466577
	LOSS [training: 0.09235083516585915 | validation: 0.09692852064611851]
	TIME [epoch: 6.57 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08656866508626596		[learning rate: 0.0046548]
	Learning Rate: 0.00465476
	LOSS [training: 0.08656866508626596 | validation: 0.06436653235937682]
	TIME [epoch: 6.56 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10149397960162113		[learning rate: 0.0046438]
	Learning Rate: 0.00464378
	LOSS [training: 0.10149397960162113 | validation: 0.08147471197579632]
	TIME [epoch: 6.59 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09779236050030345		[learning rate: 0.0046328]
	Learning Rate: 0.00463283
	LOSS [training: 0.09779236050030345 | validation: 0.1035413697534377]
	TIME [epoch: 6.58 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10228276014969037		[learning rate: 0.0046219]
	Learning Rate: 0.0046219
	LOSS [training: 0.10228276014969037 | validation: 0.12562142210895288]
	TIME [epoch: 6.56 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1440473511616252		[learning rate: 0.004611]
	Learning Rate: 0.004611
	LOSS [training: 0.1440473511616252 | validation: 0.0978088057290914]
	TIME [epoch: 6.56 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1019319801823934		[learning rate: 0.0046001]
	Learning Rate: 0.00460012
	LOSS [training: 0.1019319801823934 | validation: 0.0812502580949053]
	TIME [epoch: 6.55 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11470228827393462		[learning rate: 0.0045893]
	Learning Rate: 0.00458927
	LOSS [training: 0.11470228827393462 | validation: 0.10946757736025531]
	TIME [epoch: 6.57 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1084746700551582		[learning rate: 0.0045784]
	Learning Rate: 0.00457844
	LOSS [training: 0.1084746700551582 | validation: 0.0796437789128289]
	TIME [epoch: 6.59 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09173473199265411		[learning rate: 0.0045676]
	Learning Rate: 0.00456765
	LOSS [training: 0.09173473199265411 | validation: 0.07748365963977]
	TIME [epoch: 6.56 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09192096517016254		[learning rate: 0.0045569]
	Learning Rate: 0.00455687
	LOSS [training: 0.09192096517016254 | validation: 0.07788367005421515]
	TIME [epoch: 6.55 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11098379676161699		[learning rate: 0.0045461]
	Learning Rate: 0.00454612
	LOSS [training: 0.11098379676161699 | validation: 0.05617703751496676]
	TIME [epoch: 6.56 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07590705318521886		[learning rate: 0.0045354]
	Learning Rate: 0.0045354
	LOSS [training: 0.07590705318521886 | validation: 0.09400100945295144]
	TIME [epoch: 6.55 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12285012956428631		[learning rate: 0.0045247]
	Learning Rate: 0.0045247
	LOSS [training: 0.12285012956428631 | validation: 0.05184881142680442]
	TIME [epoch: 6.6 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09244056114617485		[learning rate: 0.004514]
	Learning Rate: 0.00451403
	LOSS [training: 0.09244056114617485 | validation: 0.07105554352438102]
	TIME [epoch: 6.56 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06998923479000514		[learning rate: 0.0045034]
	Learning Rate: 0.00450338
	LOSS [training: 0.06998923479000514 | validation: 0.11574144173971994]
	TIME [epoch: 6.56 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1007170789862866		[learning rate: 0.0044928]
	Learning Rate: 0.00449276
	LOSS [training: 0.1007170789862866 | validation: 0.07962847281901357]
	TIME [epoch: 6.56 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11981645040195654		[learning rate: 0.0044822]
	Learning Rate: 0.00448216
	LOSS [training: 0.11981645040195654 | validation: 0.04634892456161893]
	TIME [epoch: 6.56 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_390.pth
	Model improved!!!
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.102012894740618		[learning rate: 0.0044716]
	Learning Rate: 0.00447159
	LOSS [training: 0.102012894740618 | validation: 0.07512008328301188]
	TIME [epoch: 6.59 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08432091395546303		[learning rate: 0.004461]
	Learning Rate: 0.00446104
	LOSS [training: 0.08432091395546303 | validation: 0.07624610428630527]
	TIME [epoch: 6.56 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07952948653151416		[learning rate: 0.0044505]
	Learning Rate: 0.00445051
	LOSS [training: 0.07952948653151416 | validation: 0.0719592114376709]
	TIME [epoch: 6.55 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11525217596639026		[learning rate: 0.00444]
	Learning Rate: 0.00444002
	LOSS [training: 0.11525217596639026 | validation: 0.07486062888201994]
	TIME [epoch: 6.55 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07624995732506443		[learning rate: 0.0044295]
	Learning Rate: 0.00442954
	LOSS [training: 0.07624995732506443 | validation: 0.045661005020905275]
	TIME [epoch: 6.55 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_395.pth
	Model improved!!!
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07979739548586469		[learning rate: 0.0044191]
	Learning Rate: 0.00441909
	LOSS [training: 0.07979739548586469 | validation: 0.04521331832578795]
	TIME [epoch: 6.61 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_396.pth
	Model improved!!!
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07421143766706009		[learning rate: 0.0044087]
	Learning Rate: 0.00440867
	LOSS [training: 0.07421143766706009 | validation: 0.0658486886334196]
	TIME [epoch: 6.59 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08783741032972464		[learning rate: 0.0043983]
	Learning Rate: 0.00439827
	LOSS [training: 0.08783741032972464 | validation: 0.11151866792916557]
	TIME [epoch: 6.57 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09093046359760808		[learning rate: 0.0043879]
	Learning Rate: 0.0043879
	LOSS [training: 0.09093046359760808 | validation: 0.05035098414708111]
	TIME [epoch: 6.57 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11109793848613356		[learning rate: 0.0043775]
	Learning Rate: 0.00437755
	LOSS [training: 0.11109793848613356 | validation: 0.06017914164050891]
	TIME [epoch: 6.57 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07865026490047984		[learning rate: 0.0043672]
	Learning Rate: 0.00436722
	LOSS [training: 0.07865026490047984 | validation: 0.12444676708718302]
	TIME [epoch: 6.6 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12500759325175165		[learning rate: 0.0043569]
	Learning Rate: 0.00435692
	LOSS [training: 0.12500759325175165 | validation: 0.10081543956674607]
	TIME [epoch: 6.59 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08888661537883005		[learning rate: 0.0043466]
	Learning Rate: 0.00434664
	LOSS [training: 0.08888661537883005 | validation: 0.07664947250841031]
	TIME [epoch: 6.57 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07985908850821583		[learning rate: 0.0043364]
	Learning Rate: 0.00433639
	LOSS [training: 0.07985908850821583 | validation: 0.06944724082838818]
	TIME [epoch: 6.57 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07152502979662843		[learning rate: 0.0043262]
	Learning Rate: 0.00432616
	LOSS [training: 0.07152502979662843 | validation: 0.06289131482495766]
	TIME [epoch: 6.57 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08083123195878031		[learning rate: 0.004316]
	Learning Rate: 0.00431596
	LOSS [training: 0.08083123195878031 | validation: 0.049685092489430815]
	TIME [epoch: 6.58 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1040983099921109		[learning rate: 0.0043058]
	Learning Rate: 0.00430577
	LOSS [training: 0.1040983099921109 | validation: 0.14826339646031222]
	TIME [epoch: 6.6 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11956013838653681		[learning rate: 0.0042956]
	Learning Rate: 0.00429562
	LOSS [training: 0.11956013838653681 | validation: 0.0553171634180587]
	TIME [epoch: 6.58 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07820268235308937		[learning rate: 0.0042855]
	Learning Rate: 0.00428549
	LOSS [training: 0.07820268235308937 | validation: 0.05915397375053754]
	TIME [epoch: 6.56 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08623963833814557		[learning rate: 0.0042754]
	Learning Rate: 0.00427538
	LOSS [training: 0.08623963833814557 | validation: 0.04301112638012002]
	TIME [epoch: 6.57 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_410.pth
	Model improved!!!
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11269297247122922		[learning rate: 0.0042653]
	Learning Rate: 0.00426529
	LOSS [training: 0.11269297247122922 | validation: 0.06181987715814577]
	TIME [epoch: 6.58 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09390234342150094		[learning rate: 0.0042552]
	Learning Rate: 0.00425523
	LOSS [training: 0.09390234342150094 | validation: 0.1101454927314629]
	TIME [epoch: 6.6 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09287595291034631		[learning rate: 0.0042452]
	Learning Rate: 0.00424519
	LOSS [training: 0.09287595291034631 | validation: 0.08382568622618125]
	TIME [epoch: 6.58 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11385677129511511		[learning rate: 0.0042352]
	Learning Rate: 0.00423518
	LOSS [training: 0.11385677129511511 | validation: 0.12188246879285433]
	TIME [epoch: 6.58 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10183358452485643		[learning rate: 0.0042252]
	Learning Rate: 0.00422519
	LOSS [training: 0.10183358452485643 | validation: 0.07959519117679827]
	TIME [epoch: 6.57 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08197387289695865		[learning rate: 0.0042152]
	Learning Rate: 0.00421522
	LOSS [training: 0.08197387289695865 | validation: 0.23135615124094658]
	TIME [epoch: 6.57 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16850283530205906		[learning rate: 0.0042053]
	Learning Rate: 0.00420528
	LOSS [training: 0.16850283530205906 | validation: 0.1681709440192714]
	TIME [epoch: 6.61 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1292599741679517		[learning rate: 0.0041954]
	Learning Rate: 0.00419536
	LOSS [training: 0.1292599741679517 | validation: 0.06751137010832134]
	TIME [epoch: 6.58 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08856261163397353		[learning rate: 0.0041855]
	Learning Rate: 0.00418546
	LOSS [training: 0.08856261163397353 | validation: 0.16574195957240012]
	TIME [epoch: 6.58 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11232244953065991		[learning rate: 0.0041756]
	Learning Rate: 0.00417559
	LOSS [training: 0.11232244953065991 | validation: 0.1025571055576356]
	TIME [epoch: 6.57 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09026861367880243		[learning rate: 0.0041657]
	Learning Rate: 0.00416574
	LOSS [training: 0.09026861367880243 | validation: 0.045540921360338424]
	TIME [epoch: 6.58 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07191854317160774		[learning rate: 0.0041559]
	Learning Rate: 0.00415592
	LOSS [training: 0.07191854317160774 | validation: 0.07081544140847026]
	TIME [epoch: 6.61 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10275820948177286		[learning rate: 0.0041461]
	Learning Rate: 0.00414611
	LOSS [training: 0.10275820948177286 | validation: 0.09561553243073141]
	TIME [epoch: 6.59 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08912017239599228		[learning rate: 0.0041363]
	Learning Rate: 0.00413633
	LOSS [training: 0.08912017239599228 | validation: 0.1453165216905285]
	TIME [epoch: 6.58 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10941867331005331		[learning rate: 0.0041266]
	Learning Rate: 0.00412657
	LOSS [training: 0.10941867331005331 | validation: 0.07716466341392009]
	TIME [epoch: 6.59 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09934394631326035		[learning rate: 0.0041168]
	Learning Rate: 0.00411684
	LOSS [training: 0.09934394631326035 | validation: 0.07954778155328977]
	TIME [epoch: 6.58 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07301967323406504		[learning rate: 0.0041071]
	Learning Rate: 0.00410713
	LOSS [training: 0.07301967323406504 | validation: 0.051324258060422887]
	TIME [epoch: 6.6 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0875568589006607		[learning rate: 0.0040974]
	Learning Rate: 0.00409744
	LOSS [training: 0.0875568589006607 | validation: 0.09734048151308278]
	TIME [epoch: 6.61 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07572808056663963		[learning rate: 0.0040878]
	Learning Rate: 0.00408778
	LOSS [training: 0.07572808056663963 | validation: 0.08025452101269254]
	TIME [epoch: 6.58 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10995646670407258		[learning rate: 0.0040781]
	Learning Rate: 0.00407813
	LOSS [training: 0.10995646670407258 | validation: 0.056817512362676216]
	TIME [epoch: 6.59 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0664095093255995		[learning rate: 0.0040685]
	Learning Rate: 0.00406851
	LOSS [training: 0.0664095093255995 | validation: 0.07885123708930218]
	TIME [epoch: 6.58 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07492768675320673		[learning rate: 0.0040589]
	Learning Rate: 0.00405892
	LOSS [training: 0.07492768675320673 | validation: 0.06251994868807516]
	TIME [epoch: 6.58 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08215878695055248		[learning rate: 0.0040493]
	Learning Rate: 0.00404934
	LOSS [training: 0.08215878695055248 | validation: 0.059105204570486715]
	TIME [epoch: 6.62 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09005169663121959		[learning rate: 0.0040398]
	Learning Rate: 0.00403979
	LOSS [training: 0.09005169663121959 | validation: 0.09750722673291526]
	TIME [epoch: 6.58 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09239488327257153		[learning rate: 0.0040303]
	Learning Rate: 0.00403026
	LOSS [training: 0.09239488327257153 | validation: 0.09821933074604704]
	TIME [epoch: 6.58 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08279833461724466		[learning rate: 0.0040208]
	Learning Rate: 0.00402076
	LOSS [training: 0.08279833461724466 | validation: 0.03459930966486126]
	TIME [epoch: 6.58 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_436.pth
	Model improved!!!
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09346749983067429		[learning rate: 0.0040113]
	Learning Rate: 0.00401127
	LOSS [training: 0.09346749983067429 | validation: 0.08558150377580445]
	TIME [epoch: 6.57 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07587234712261712		[learning rate: 0.0040018]
	Learning Rate: 0.00400181
	LOSS [training: 0.07587234712261712 | validation: 0.0754667713674758]
	TIME [epoch: 6.61 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08241601011135641		[learning rate: 0.0039924]
	Learning Rate: 0.00399237
	LOSS [training: 0.08241601011135641 | validation: 0.05255846675765127]
	TIME [epoch: 6.57 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07309457372214999		[learning rate: 0.003983]
	Learning Rate: 0.00398295
	LOSS [training: 0.07309457372214999 | validation: 0.059466471035446986]
	TIME [epoch: 6.56 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08740339053131482		[learning rate: 0.0039736]
	Learning Rate: 0.00397356
	LOSS [training: 0.08740339053131482 | validation: 0.061909627728126596]
	TIME [epoch: 6.56 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0955363813999535		[learning rate: 0.0039642]
	Learning Rate: 0.00396418
	LOSS [training: 0.0955363813999535 | validation: 0.07051379877396083]
	TIME [epoch: 6.57 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06765274021827074		[learning rate: 0.0039548]
	Learning Rate: 0.00395483
	LOSS [training: 0.06765274021827074 | validation: 0.08676189188303697]
	TIME [epoch: 6.6 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10666877327870317		[learning rate: 0.0039455]
	Learning Rate: 0.0039455
	LOSS [training: 0.10666877327870317 | validation: 0.08045126057737417]
	TIME [epoch: 6.57 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10940263241819008		[learning rate: 0.0039362]
	Learning Rate: 0.0039362
	LOSS [training: 0.10940263241819008 | validation: 0.0644092604462807]
	TIME [epoch: 6.56 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13479441722875155		[learning rate: 0.0039269]
	Learning Rate: 0.00392691
	LOSS [training: 0.13479441722875155 | validation: 0.20875970914780884]
	TIME [epoch: 6.56 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13322435439289393		[learning rate: 0.0039176]
	Learning Rate: 0.00391765
	LOSS [training: 0.13322435439289393 | validation: 0.07038978924138889]
	TIME [epoch: 6.57 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08061763120757123		[learning rate: 0.0039084]
	Learning Rate: 0.00390841
	LOSS [training: 0.08061763120757123 | validation: 0.07924768980408246]
	TIME [epoch: 6.6 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0754028870033543		[learning rate: 0.0038992]
	Learning Rate: 0.00389919
	LOSS [training: 0.0754028870033543 | validation: 0.07826062796997246]
	TIME [epoch: 6.58 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11192245302841		[learning rate: 0.00389]
	Learning Rate: 0.00388999
	LOSS [training: 0.11192245302841 | validation: 0.07005257746241514]
	TIME [epoch: 6.57 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0983745069805557		[learning rate: 0.0038808]
	Learning Rate: 0.00388082
	LOSS [training: 0.0983745069805557 | validation: 0.08292455656209058]
	TIME [epoch: 6.56 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1045488995752826		[learning rate: 0.0038717]
	Learning Rate: 0.00387166
	LOSS [training: 0.1045488995752826 | validation: 0.11042860780300665]
	TIME [epoch: 6.56 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08877051360872118		[learning rate: 0.0038625]
	Learning Rate: 0.00386253
	LOSS [training: 0.08877051360872118 | validation: 0.07589128538333045]
	TIME [epoch: 6.57 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.105936404726197		[learning rate: 0.0038534]
	Learning Rate: 0.00385342
	LOSS [training: 0.105936404726197 | validation: 0.06979216260470211]
	TIME [epoch: 6.6 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09286583774272168		[learning rate: 0.0038443]
	Learning Rate: 0.00384433
	LOSS [training: 0.09286583774272168 | validation: 0.048797809444571974]
	TIME [epoch: 6.57 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09676907085779644		[learning rate: 0.0038353]
	Learning Rate: 0.00383526
	LOSS [training: 0.09676907085779644 | validation: 0.04686813478761628]
	TIME [epoch: 6.57 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12690435697175523		[learning rate: 0.0038262]
	Learning Rate: 0.00382621
	LOSS [training: 0.12690435697175523 | validation: 0.08358108288635177]
	TIME [epoch: 6.57 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09933761057762068		[learning rate: 0.0038172]
	Learning Rate: 0.00381719
	LOSS [training: 0.09933761057762068 | validation: 0.05474615296606068]
	TIME [epoch: 6.57 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07295225072705146		[learning rate: 0.0038082]
	Learning Rate: 0.00380818
	LOSS [training: 0.07295225072705146 | validation: 0.07660712853148599]
	TIME [epoch: 6.61 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1043083354242356		[learning rate: 0.0037992]
	Learning Rate: 0.0037992
	LOSS [training: 0.1043083354242356 | validation: 0.04912257509839828]
	TIME [epoch: 6.58 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07927219694497427		[learning rate: 0.0037902]
	Learning Rate: 0.00379024
	LOSS [training: 0.07927219694497427 | validation: 0.08558885830441676]
	TIME [epoch: 6.57 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08385803399470852		[learning rate: 0.0037813]
	Learning Rate: 0.0037813
	LOSS [training: 0.08385803399470852 | validation: 0.07706259456720495]
	TIME [epoch: 6.57 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06214254275002116		[learning rate: 0.0037724]
	Learning Rate: 0.00377238
	LOSS [training: 0.06214254275002116 | validation: 0.05416650221579205]
	TIME [epoch: 6.57 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05747560686276572		[learning rate: 0.0037635]
	Learning Rate: 0.00376348
	LOSS [training: 0.05747560686276572 | validation: 0.03281102696024453]
	TIME [epoch: 6.61 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_464.pth
	Model improved!!!
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1260394219459549		[learning rate: 0.0037546]
	Learning Rate: 0.0037546
	LOSS [training: 0.1260394219459549 | validation: 0.04891685814851307]
	TIME [epoch: 6.58 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0778412774339248		[learning rate: 0.0037457]
	Learning Rate: 0.00374575
	LOSS [training: 0.0778412774339248 | validation: 0.08977229410532597]
	TIME [epoch: 6.56 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08899626214230265		[learning rate: 0.0037369]
	Learning Rate: 0.00373691
	LOSS [training: 0.08899626214230265 | validation: 0.050412675320853445]
	TIME [epoch: 6.56 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08105354628147199		[learning rate: 0.0037281]
	Learning Rate: 0.0037281
	LOSS [training: 0.08105354628147199 | validation: 0.0797947928908954]
	TIME [epoch: 6.55 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07419045948406656		[learning rate: 0.0037193]
	Learning Rate: 0.0037193
	LOSS [training: 0.07419045948406656 | validation: 0.07106249519159934]
	TIME [epoch: 6.58 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09028123067031715		[learning rate: 0.0037105]
	Learning Rate: 0.00371053
	LOSS [training: 0.09028123067031715 | validation: 0.11427537676606953]
	TIME [epoch: 6.57 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10078905938595714		[learning rate: 0.0037018]
	Learning Rate: 0.00370178
	LOSS [training: 0.10078905938595714 | validation: 0.02805193622294988]
	TIME [epoch: 6.55 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_471.pth
	Model improved!!!
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07099162662717401		[learning rate: 0.003693]
	Learning Rate: 0.00369304
	LOSS [training: 0.07099162662717401 | validation: 0.07125262740547282]
	TIME [epoch: 6.56 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10404642045484702		[learning rate: 0.0036843]
	Learning Rate: 0.00368433
	LOSS [training: 0.10404642045484702 | validation: 0.04228818416933681]
	TIME [epoch: 6.55 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06644642891090133		[learning rate: 0.0036756]
	Learning Rate: 0.00367564
	LOSS [training: 0.06644642891090133 | validation: 0.03482164279286372]
	TIME [epoch: 6.57 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05624451357062612		[learning rate: 0.003667]
	Learning Rate: 0.00366697
	LOSS [training: 0.05624451357062612 | validation: 0.08650653665337155]
	TIME [epoch: 6.59 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11544962543621747		[learning rate: 0.0036583]
	Learning Rate: 0.00365832
	LOSS [training: 0.11544962543621747 | validation: 0.06922638231051374]
	TIME [epoch: 6.56 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11526271307813482		[learning rate: 0.0036497]
	Learning Rate: 0.00364969
	LOSS [training: 0.11526271307813482 | validation: 0.030712032158919246]
	TIME [epoch: 6.55 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039538408291382394		[learning rate: 0.0036411]
	Learning Rate: 0.00364108
	LOSS [training: 0.039538408291382394 | validation: 0.11327195511009569]
	TIME [epoch: 6.55 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10249576327041607		[learning rate: 0.0036325]
	Learning Rate: 0.0036325
	LOSS [training: 0.10249576327041607 | validation: 0.05735063205001509]
	TIME [epoch: 6.56 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09937992577693786		[learning rate: 0.0036239]
	Learning Rate: 0.00362393
	LOSS [training: 0.09937992577693786 | validation: 0.1323929367501508]
	TIME [epoch: 6.6 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09996070264731215		[learning rate: 0.0036154]
	Learning Rate: 0.00361538
	LOSS [training: 0.09996070264731215 | validation: 0.08692785911683722]
	TIME [epoch: 6.56 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09180802040203179		[learning rate: 0.0036069]
	Learning Rate: 0.00360685
	LOSS [training: 0.09180802040203179 | validation: 0.11313036199627187]
	TIME [epoch: 6.56 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06944720583691576		[learning rate: 0.0035983]
	Learning Rate: 0.00359834
	LOSS [training: 0.06944720583691576 | validation: 0.028745517517020612]
	TIME [epoch: 6.56 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06554755876718873		[learning rate: 0.0035899]
	Learning Rate: 0.00358986
	LOSS [training: 0.06554755876718873 | validation: 0.0616718594969113]
	TIME [epoch: 6.56 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0911511717624559		[learning rate: 0.0035814]
	Learning Rate: 0.00358139
	LOSS [training: 0.0911511717624559 | validation: 0.08963481710675297]
	TIME [epoch: 6.59 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10336874451853202		[learning rate: 0.0035729]
	Learning Rate: 0.00357294
	LOSS [training: 0.10336874451853202 | validation: 0.03943471798828628]
	TIME [epoch: 6.56 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07639875295185382		[learning rate: 0.0035645]
	Learning Rate: 0.00356451
	LOSS [training: 0.07639875295185382 | validation: 0.08767180793197984]
	TIME [epoch: 6.56 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10369483162639974		[learning rate: 0.0035561]
	Learning Rate: 0.0035561
	LOSS [training: 0.10369483162639974 | validation: 0.0512853351294243]
	TIME [epoch: 6.56 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08750480700577545		[learning rate: 0.0035477]
	Learning Rate: 0.00354771
	LOSS [training: 0.08750480700577545 | validation: 0.043645369882417115]
	TIME [epoch: 6.55 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07246131722337183		[learning rate: 0.0035393]
	Learning Rate: 0.00353935
	LOSS [training: 0.07246131722337183 | validation: 0.048545278669784364]
	TIME [epoch: 6.59 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06270347348890352		[learning rate: 0.003531]
	Learning Rate: 0.003531
	LOSS [training: 0.06270347348890352 | validation: 0.040683264559371796]
	TIME [epoch: 6.57 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06856882521977292		[learning rate: 0.0035227]
	Learning Rate: 0.00352267
	LOSS [training: 0.06856882521977292 | validation: 0.09595806073523133]
	TIME [epoch: 6.56 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11700267903062041		[learning rate: 0.0035144]
	Learning Rate: 0.00351436
	LOSS [training: 0.11700267903062041 | validation: 0.05024465191769792]
	TIME [epoch: 6.57 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07037854054568558		[learning rate: 0.0035061]
	Learning Rate: 0.00350607
	LOSS [training: 0.07037854054568558 | validation: 0.06183371087846857]
	TIME [epoch: 6.56 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06799117057894541		[learning rate: 0.0034978]
	Learning Rate: 0.0034978
	LOSS [training: 0.06799117057894541 | validation: 0.05958583148769611]
	TIME [epoch: 6.57 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07983849899743718		[learning rate: 0.0034895]
	Learning Rate: 0.00348955
	LOSS [training: 0.07983849899743718 | validation: 0.058670327635255884]
	TIME [epoch: 6.59 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06693777565402355		[learning rate: 0.0034813]
	Learning Rate: 0.00348132
	LOSS [training: 0.06693777565402355 | validation: 0.033156325673582995]
	TIME [epoch: 6.56 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07428711782818649		[learning rate: 0.0034731]
	Learning Rate: 0.00347311
	LOSS [training: 0.07428711782818649 | validation: 0.14155606928290465]
	TIME [epoch: 6.56 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11952252252516235		[learning rate: 0.0034649]
	Learning Rate: 0.00346491
	LOSS [training: 0.11952252252516235 | validation: 0.07514810045120712]
	TIME [epoch: 6.56 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.122370863705108		[learning rate: 0.0034567]
	Learning Rate: 0.00345674
	LOSS [training: 0.122370863705108 | validation: 0.027206632845317078]
	TIME [epoch: 6.57 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_500.pth
	Model improved!!!
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0801629011595588		[learning rate: 0.0034486]
	Learning Rate: 0.00344859
	LOSS [training: 0.0801629011595588 | validation: 0.03669341294027429]
	TIME [epoch: 6.6 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08564195881772692		[learning rate: 0.0034405]
	Learning Rate: 0.00344045
	LOSS [training: 0.08564195881772692 | validation: 0.04843269556631398]
	TIME [epoch: 6.56 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09583157423789342		[learning rate: 0.0034323]
	Learning Rate: 0.00343234
	LOSS [training: 0.09583157423789342 | validation: 0.1842563479104661]
	TIME [epoch: 6.56 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14825072607522993		[learning rate: 0.0034242]
	Learning Rate: 0.00342424
	LOSS [training: 0.14825072607522993 | validation: 0.06308111223533099]
	TIME [epoch: 6.56 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0692344259535624		[learning rate: 0.0034162]
	Learning Rate: 0.00341616
	LOSS [training: 0.0692344259535624 | validation: 0.04839620093566609]
	TIME [epoch: 6.56 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07074283787473795		[learning rate: 0.0034081]
	Learning Rate: 0.0034081
	LOSS [training: 0.07074283787473795 | validation: 0.09940396044254343]
	TIME [epoch: 6.6 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13061457778587987		[learning rate: 0.0034001]
	Learning Rate: 0.00340006
	LOSS [training: 0.13061457778587987 | validation: 0.16208384840897627]
	TIME [epoch: 6.56 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11391945661986402		[learning rate: 0.003392]
	Learning Rate: 0.00339204
	LOSS [training: 0.11391945661986402 | validation: 0.038379835574570705]
	TIME [epoch: 6.56 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06077015391889945		[learning rate: 0.003384]
	Learning Rate: 0.00338404
	LOSS [training: 0.06077015391889945 | validation: 0.05365576748244923]
	TIME [epoch: 6.56 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07433424891055647		[learning rate: 0.0033761]
	Learning Rate: 0.00337606
	LOSS [training: 0.07433424891055647 | validation: 0.07187402635367798]
	TIME [epoch: 6.56 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1179223908148516		[learning rate: 0.0033681]
	Learning Rate: 0.0033681
	LOSS [training: 0.1179223908148516 | validation: 0.027853630289132427]
	TIME [epoch: 6.6 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04916540720222009		[learning rate: 0.0033602]
	Learning Rate: 0.00336015
	LOSS [training: 0.04916540720222009 | validation: 0.03357142492506161]
	TIME [epoch: 6.57 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05220703790461313		[learning rate: 0.0033522]
	Learning Rate: 0.00335223
	LOSS [training: 0.05220703790461313 | validation: 0.08984902347219789]
	TIME [epoch: 6.56 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09859714984020462		[learning rate: 0.0033443]
	Learning Rate: 0.00334432
	LOSS [training: 0.09859714984020462 | validation: 0.07115438748423002]
	TIME [epoch: 6.56 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07285149464879365		[learning rate: 0.0033364]
	Learning Rate: 0.00333643
	LOSS [training: 0.07285149464879365 | validation: 0.035323366229684336]
	TIME [epoch: 6.56 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060307453137930386		[learning rate: 0.0033286]
	Learning Rate: 0.00332856
	LOSS [training: 0.060307453137930386 | validation: 0.02971316257441795]
	TIME [epoch: 6.57 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06309724949470903		[learning rate: 0.0033207]
	Learning Rate: 0.00332071
	LOSS [training: 0.06309724949470903 | validation: 0.03424556277836968]
	TIME [epoch: 6.59 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059690938348758084		[learning rate: 0.0033129]
	Learning Rate: 0.00331288
	LOSS [training: 0.059690938348758084 | validation: 0.0470173733467027]
	TIME [epoch: 6.56 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06091682158832114		[learning rate: 0.0033051]
	Learning Rate: 0.00330506
	LOSS [training: 0.06091682158832114 | validation: 0.01720426654660371]
	TIME [epoch: 6.56 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_519.pth
	Model improved!!!
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0676555053087357		[learning rate: 0.0032973]
	Learning Rate: 0.00329727
	LOSS [training: 0.0676555053087357 | validation: 0.05250749009489415]
	TIME [epoch: 6.56 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06307692419993452		[learning rate: 0.0032895]
	Learning Rate: 0.00328949
	LOSS [training: 0.06307692419993452 | validation: 0.08761885883355805]
	TIME [epoch: 6.56 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12261935242355562		[learning rate: 0.0032817]
	Learning Rate: 0.00328173
	LOSS [training: 0.12261935242355562 | validation: 0.06171920106711193]
	TIME [epoch: 6.58 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0569466067089323		[learning rate: 0.003274]
	Learning Rate: 0.00327399
	LOSS [training: 0.0569466067089323 | validation: 0.07243494657431339]
	TIME [epoch: 6.56 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12253212824267186		[learning rate: 0.0032663]
	Learning Rate: 0.00326626
	LOSS [training: 0.12253212824267186 | validation: 0.03317550079481812]
	TIME [epoch: 6.55 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039816828197951556		[learning rate: 0.0032586]
	Learning Rate: 0.00325856
	LOSS [training: 0.039816828197951556 | validation: 0.029116682018284334]
	TIME [epoch: 6.55 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05693919180560607		[learning rate: 0.0032509]
	Learning Rate: 0.00325087
	LOSS [training: 0.05693919180560607 | validation: 0.03748451654093492]
	TIME [epoch: 6.55 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09181159171408407		[learning rate: 0.0032432]
	Learning Rate: 0.0032432
	LOSS [training: 0.09181159171408407 | validation: 0.06192667150901095]
	TIME [epoch: 6.59 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057838346278417094		[learning rate: 0.0032356]
	Learning Rate: 0.00323555
	LOSS [training: 0.057838346278417094 | validation: 0.02670423583696285]
	TIME [epoch: 6.55 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07642456634740825		[learning rate: 0.0032279]
	Learning Rate: 0.00322792
	LOSS [training: 0.07642456634740825 | validation: 0.05455304642648677]
	TIME [epoch: 6.55 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09603182501022545		[learning rate: 0.0032203]
	Learning Rate: 0.00322031
	LOSS [training: 0.09603182501022545 | validation: 0.0810559089958397]
	TIME [epoch: 6.56 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06548442281766453		[learning rate: 0.0032127]
	Learning Rate: 0.00321271
	LOSS [training: 0.06548442281766453 | validation: 0.04252365520871685]
	TIME [epoch: 6.55 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07180575365843807		[learning rate: 0.0032051]
	Learning Rate: 0.00320513
	LOSS [training: 0.07180575365843807 | validation: 0.027848805104116154]
	TIME [epoch: 6.59 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05557789434334222		[learning rate: 0.0031976]
	Learning Rate: 0.00319757
	LOSS [training: 0.05557789434334222 | validation: 0.08703955000105518]
	TIME [epoch: 6.56 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21507243727095965		[learning rate: 0.00319]
	Learning Rate: 0.00319003
	LOSS [training: 0.21507243727095965 | validation: 0.06617877091797936]
	TIME [epoch: 6.55 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09230259542585953		[learning rate: 0.0031825]
	Learning Rate: 0.00318251
	LOSS [training: 0.09230259542585953 | validation: 0.037063956591317004]
	TIME [epoch: 6.56 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05606555869039696		[learning rate: 0.003175]
	Learning Rate: 0.003175
	LOSS [training: 0.05606555869039696 | validation: 0.04448066324654038]
	TIME [epoch: 6.55 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05971412377575262		[learning rate: 0.0031675]
	Learning Rate: 0.00316751
	LOSS [training: 0.05971412377575262 | validation: 0.0808329135921798]
	TIME [epoch: 6.57 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09473098065016769		[learning rate: 0.00316]
	Learning Rate: 0.00316004
	LOSS [training: 0.09473098065016769 | validation: 0.0472376470984798]
	TIME [epoch: 6.57 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06937076728721692		[learning rate: 0.0031526]
	Learning Rate: 0.00315258
	LOSS [training: 0.06937076728721692 | validation: 0.041018497332026824]
	TIME [epoch: 6.56 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08778694700585042		[learning rate: 0.0031451]
	Learning Rate: 0.00314515
	LOSS [training: 0.08778694700585042 | validation: 0.038231711058128434]
	TIME [epoch: 6.56 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07925221635580379		[learning rate: 0.0031377]
	Learning Rate: 0.00313773
	LOSS [training: 0.07925221635580379 | validation: 0.05665555900846445]
	TIME [epoch: 6.55 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06809843286518576		[learning rate: 0.0031303]
	Learning Rate: 0.00313033
	LOSS [training: 0.06809843286518576 | validation: 0.0441538255505619]
	TIME [epoch: 6.56 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05403803603547878		[learning rate: 0.0031229]
	Learning Rate: 0.00312294
	LOSS [training: 0.05403803603547878 | validation: 0.037156507573886915]
	TIME [epoch: 6.59 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0862102783478845		[learning rate: 0.0031156]
	Learning Rate: 0.00311558
	LOSS [training: 0.0862102783478845 | validation: 0.04133065804004962]
	TIME [epoch: 6.56 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07994034876708857		[learning rate: 0.0031082]
	Learning Rate: 0.00310823
	LOSS [training: 0.07994034876708857 | validation: 0.07473601880596782]
	TIME [epoch: 6.55 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05478075320899446		[learning rate: 0.0031009]
	Learning Rate: 0.0031009
	LOSS [training: 0.05478075320899446 | validation: 0.03504103862189752]
	TIME [epoch: 6.56 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0803700836867615		[learning rate: 0.0030936]
	Learning Rate: 0.00309358
	LOSS [training: 0.0803700836867615 | validation: 0.13954041200878764]
	TIME [epoch: 6.56 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1008117956232002		[learning rate: 0.0030863]
	Learning Rate: 0.00308628
	LOSS [training: 0.1008117956232002 | validation: 0.03514150125544605]
	TIME [epoch: 6.59 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0585513483726194		[learning rate: 0.003079]
	Learning Rate: 0.003079
	LOSS [training: 0.0585513483726194 | validation: 0.04317567967589195]
	TIME [epoch: 6.56 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11899047080655553		[learning rate: 0.0030717]
	Learning Rate: 0.00307174
	LOSS [training: 0.11899047080655553 | validation: 0.07835993435047364]
	TIME [epoch: 6.55 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0790375364294743		[learning rate: 0.0030645]
	Learning Rate: 0.0030645
	LOSS [training: 0.0790375364294743 | validation: 0.06861725748699445]
	TIME [epoch: 6.57 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08066901614003934		[learning rate: 0.0030573]
	Learning Rate: 0.00305727
	LOSS [training: 0.08066901614003934 | validation: 0.0747363694910089]
	TIME [epoch: 6.55 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11560235634792664		[learning rate: 0.0030501]
	Learning Rate: 0.00305006
	LOSS [training: 0.11560235634792664 | validation: 0.0585342154837185]
	TIME [epoch: 6.59 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0825742099578366		[learning rate: 0.0030429]
	Learning Rate: 0.00304286
	LOSS [training: 0.0825742099578366 | validation: 0.13083523140308637]
	TIME [epoch: 6.57 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1533764357045		[learning rate: 0.0030357]
	Learning Rate: 0.00303568
	LOSS [training: 0.1533764357045 | validation: 0.08421348837302871]
	TIME [epoch: 6.55 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09090042933728093		[learning rate: 0.0030285]
	Learning Rate: 0.00302852
	LOSS [training: 0.09090042933728093 | validation: 0.06632553254058532]
	TIME [epoch: 6.56 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09168177941506687		[learning rate: 0.0030214]
	Learning Rate: 0.00302138
	LOSS [training: 0.09168177941506687 | validation: 0.06543078087012541]
	TIME [epoch: 6.56 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07539366077155199		[learning rate: 0.0030143]
	Learning Rate: 0.00301425
	LOSS [training: 0.07539366077155199 | validation: 0.09867674186867531]
	TIME [epoch: 6.58 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07315039038701016		[learning rate: 0.0030071]
	Learning Rate: 0.00300714
	LOSS [training: 0.07315039038701016 | validation: 0.0443854038450161]
	TIME [epoch: 6.58 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07778882126388278		[learning rate: 0.003]
	Learning Rate: 0.00300005
	LOSS [training: 0.07778882126388278 | validation: 0.06871766058022993]
	TIME [epoch: 6.55 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11918819224854504		[learning rate: 0.002993]
	Learning Rate: 0.00299297
	LOSS [training: 0.11918819224854504 | validation: 0.14414682233414056]
	TIME [epoch: 6.56 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1351774343732989		[learning rate: 0.0029859]
	Learning Rate: 0.00298591
	LOSS [training: 0.1351774343732989 | validation: 0.03952951645369701]
	TIME [epoch: 6.56 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0759876579452862		[learning rate: 0.0029789]
	Learning Rate: 0.00297887
	LOSS [training: 0.0759876579452862 | validation: 0.06602529656930237]
	TIME [epoch: 6.56 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06727216149066174		[learning rate: 0.0029718]
	Learning Rate: 0.00297184
	LOSS [training: 0.06727216149066174 | validation: 0.04452711912548127]
	TIME [epoch: 6.6 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05971457215396127		[learning rate: 0.0029648]
	Learning Rate: 0.00296483
	LOSS [training: 0.05971457215396127 | validation: 0.07199828553773144]
	TIME [epoch: 6.57 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07283610810028177		[learning rate: 0.0029578]
	Learning Rate: 0.00295784
	LOSS [training: 0.07283610810028177 | validation: 0.07423286750221411]
	TIME [epoch: 6.56 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.080183408318896		[learning rate: 0.0029509]
	Learning Rate: 0.00295086
	LOSS [training: 0.080183408318896 | validation: 0.0720538718893528]
	TIME [epoch: 6.56 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06336243171271412		[learning rate: 0.0029439]
	Learning Rate: 0.0029439
	LOSS [training: 0.06336243171271412 | validation: 0.05912058901863805]
	TIME [epoch: 6.56 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07390844008941343		[learning rate: 0.002937]
	Learning Rate: 0.00293696
	LOSS [training: 0.07390844008941343 | validation: 0.051779634188473964]
	TIME [epoch: 6.6 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0965278393628977		[learning rate: 0.00293]
	Learning Rate: 0.00293003
	LOSS [training: 0.0965278393628977 | validation: 0.10617999351246624]
	TIME [epoch: 6.56 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09423013365220989		[learning rate: 0.0029231]
	Learning Rate: 0.00292312
	LOSS [training: 0.09423013365220989 | validation: 0.08715141923740055]
	TIME [epoch: 6.57 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08402579679030713		[learning rate: 0.0029162]
	Learning Rate: 0.00291622
	LOSS [training: 0.08402579679030713 | validation: 0.10981950202404756]
	TIME [epoch: 6.56 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08118665815528059		[learning rate: 0.0029093]
	Learning Rate: 0.00290934
	LOSS [training: 0.08118665815528059 | validation: 0.06080183352657739]
	TIME [epoch: 6.56 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08919230460785384		[learning rate: 0.0029025]
	Learning Rate: 0.00290248
	LOSS [training: 0.08919230460785384 | validation: 0.07315916361796057]
	TIME [epoch: 6.59 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07953577074377635		[learning rate: 0.0028956]
	Learning Rate: 0.00289563
	LOSS [training: 0.07953577074377635 | validation: 0.07265157132787234]
	TIME [epoch: 6.56 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07115646272031444		[learning rate: 0.0028888]
	Learning Rate: 0.0028888
	LOSS [training: 0.07115646272031444 | validation: 0.05479814582327206]
	TIME [epoch: 6.56 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060631632873419904		[learning rate: 0.002882]
	Learning Rate: 0.00288199
	LOSS [training: 0.060631632873419904 | validation: 0.07321268739987088]
	TIME [epoch: 6.55 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09648744940263208		[learning rate: 0.0028752]
	Learning Rate: 0.00287519
	LOSS [training: 0.09648744940263208 | validation: 0.05090723524111695]
	TIME [epoch: 6.55 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07472088440601413		[learning rate: 0.0028684]
	Learning Rate: 0.00286841
	LOSS [training: 0.07472088440601413 | validation: 0.05642849920361314]
	TIME [epoch: 6.58 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09706100054781859		[learning rate: 0.0028616]
	Learning Rate: 0.00286164
	LOSS [training: 0.09706100054781859 | validation: 0.16131464637811294]
	TIME [epoch: 6.58 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16333128048414344		[learning rate: 0.0028549]
	Learning Rate: 0.00285489
	LOSS [training: 0.16333128048414344 | validation: 0.054468133457054486]
	TIME [epoch: 6.56 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05514517184441694		[learning rate: 0.0028482]
	Learning Rate: 0.00284816
	LOSS [training: 0.05514517184441694 | validation: 0.04870776941210744]
	TIME [epoch: 6.55 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07487262972904425		[learning rate: 0.0028414]
	Learning Rate: 0.00284144
	LOSS [training: 0.07487262972904425 | validation: 0.09106304559765123]
	TIME [epoch: 6.56 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09846503290691733		[learning rate: 0.0028347]
	Learning Rate: 0.00283474
	LOSS [training: 0.09846503290691733 | validation: 0.08840512714054181]
	TIME [epoch: 6.55 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1057526057741534		[learning rate: 0.0028281]
	Learning Rate: 0.00282805
	LOSS [training: 0.1057526057741534 | validation: 0.05528429885697404]
	TIME [epoch: 6.6 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06108447049820089		[learning rate: 0.0028214]
	Learning Rate: 0.00282138
	LOSS [training: 0.06108447049820089 | validation: 0.12340361713187017]
	TIME [epoch: 6.55 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1074866363284207		[learning rate: 0.0028147]
	Learning Rate: 0.00281472
	LOSS [training: 0.1074866363284207 | validation: 0.07943504103087093]
	TIME [epoch: 6.55 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0679314149549147		[learning rate: 0.0028081]
	Learning Rate: 0.00280808
	LOSS [training: 0.0679314149549147 | validation: 0.07852721665485538]
	TIME [epoch: 6.54 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0766742923391237		[learning rate: 0.0028015]
	Learning Rate: 0.00280146
	LOSS [training: 0.0766742923391237 | validation: 0.0672201778836643]
	TIME [epoch: 6.55 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12945975888222483		[learning rate: 0.0027949]
	Learning Rate: 0.00279485
	LOSS [training: 0.12945975888222483 | validation: 0.07674063950546586]
	TIME [epoch: 6.58 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07329498101725429		[learning rate: 0.0027883]
	Learning Rate: 0.00278826
	LOSS [training: 0.07329498101725429 | validation: 0.058709847678257765]
	TIME [epoch: 6.55 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050941764787764576		[learning rate: 0.0027817]
	Learning Rate: 0.00278168
	LOSS [training: 0.050941764787764576 | validation: 0.040155124947721194]
	TIME [epoch: 6.55 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05104085580073218		[learning rate: 0.0027751]
	Learning Rate: 0.00277512
	LOSS [training: 0.05104085580073218 | validation: 0.06136572110074565]
	TIME [epoch: 6.55 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06174827369756999		[learning rate: 0.0027686]
	Learning Rate: 0.00276858
	LOSS [training: 0.06174827369756999 | validation: 0.04585727761137725]
	TIME [epoch: 6.55 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06290323696022818		[learning rate: 0.002762]
	Learning Rate: 0.00276205
	LOSS [training: 0.06290323696022818 | validation: 0.0755822762432413]
	TIME [epoch: 6.59 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1588340520690819		[learning rate: 0.0027555]
	Learning Rate: 0.00275553
	LOSS [training: 0.1588340520690819 | validation: 0.061593042496383754]
	TIME [epoch: 6.56 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10414616730151863		[learning rate: 0.002749]
	Learning Rate: 0.00274903
	LOSS [training: 0.10414616730151863 | validation: 0.08015003226662544]
	TIME [epoch: 6.55 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08211814340688606		[learning rate: 0.0027425]
	Learning Rate: 0.00274255
	LOSS [training: 0.08211814340688606 | validation: 0.07395761423906892]
	TIME [epoch: 6.55 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0684818797660314		[learning rate: 0.0027361]
	Learning Rate: 0.00273608
	LOSS [training: 0.0684818797660314 | validation: 0.06970250139492642]
	TIME [epoch: 6.55 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06364847431137205		[learning rate: 0.0027296]
	Learning Rate: 0.00272962
	LOSS [training: 0.06364847431137205 | validation: 0.0866379549780579]
	TIME [epoch: 6.57 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10150350973826705		[learning rate: 0.0027232]
	Learning Rate: 0.00272318
	LOSS [training: 0.10150350973826705 | validation: 0.08321829007714465]
	TIME [epoch: 6.57 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13359894328384697		[learning rate: 0.0027168]
	Learning Rate: 0.00271676
	LOSS [training: 0.13359894328384697 | validation: 0.08889186415024204]
	TIME [epoch: 6.55 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0899056722652357		[learning rate: 0.0027104]
	Learning Rate: 0.00271035
	LOSS [training: 0.0899056722652357 | validation: 0.053036937706620935]
	TIME [epoch: 6.55 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07894621723146253		[learning rate: 0.002704]
	Learning Rate: 0.00270396
	LOSS [training: 0.07894621723146253 | validation: 0.03737067671316342]
	TIME [epoch: 6.55 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07811794738685937		[learning rate: 0.0026976]
	Learning Rate: 0.00269758
	LOSS [training: 0.07811794738685937 | validation: 0.030758806380715938]
	TIME [epoch: 6.56 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07132412027662934		[learning rate: 0.0026912]
	Learning Rate: 0.00269122
	LOSS [training: 0.07132412027662934 | validation: 0.04501891299110252]
	TIME [epoch: 6.59 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030308115961193954		[learning rate: 0.0026849]
	Learning Rate: 0.00268487
	LOSS [training: 0.030308115961193954 | validation: 0.04405837811182204]
	TIME [epoch: 6.56 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06778538507752008		[learning rate: 0.0026785]
	Learning Rate: 0.00267854
	LOSS [training: 0.06778538507752008 | validation: 0.03481627843630296]
	TIME [epoch: 6.55 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06145780501937559		[learning rate: 0.0026722]
	Learning Rate: 0.00267222
	LOSS [training: 0.06145780501937559 | validation: 0.023003579397348765]
	TIME [epoch: 6.55 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10321688942465745		[learning rate: 0.0026659]
	Learning Rate: 0.00266591
	LOSS [training: 0.10321688942465745 | validation: 0.08326164746292468]
	TIME [epoch: 6.55 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07620222853532135		[learning rate: 0.0026596]
	Learning Rate: 0.00265963
	LOSS [training: 0.07620222853532135 | validation: 0.03629080847675054]
	TIME [epoch: 6.59 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06021900100975312		[learning rate: 0.0026534]
	Learning Rate: 0.00265335
	LOSS [training: 0.06021900100975312 | validation: 0.06749577485617345]
	TIME [epoch: 6.55 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07533029776536473		[learning rate: 0.0026471]
	Learning Rate: 0.00264709
	LOSS [training: 0.07533029776536473 | validation: 0.07221831312700827]
	TIME [epoch: 6.55 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05686474653679826		[learning rate: 0.0026408]
	Learning Rate: 0.00264085
	LOSS [training: 0.05686474653679826 | validation: 0.05465899798752709]
	TIME [epoch: 6.55 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07642061691948093		[learning rate: 0.0026346]
	Learning Rate: 0.00263462
	LOSS [training: 0.07642061691948093 | validation: 0.07011514221329632]
	TIME [epoch: 6.55 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06056071442345119		[learning rate: 0.0026284]
	Learning Rate: 0.00262841
	LOSS [training: 0.06056071442345119 | validation: 0.0607290567578291]
	TIME [epoch: 6.58 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08286429261026648		[learning rate: 0.0026222]
	Learning Rate: 0.00262221
	LOSS [training: 0.08286429261026648 | validation: 0.06025581769683486]
	TIME [epoch: 6.56 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07839263265255161		[learning rate: 0.002616]
	Learning Rate: 0.00261602
	LOSS [training: 0.07839263265255161 | validation: 0.06927233528168303]
	TIME [epoch: 6.55 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11274624717397368		[learning rate: 0.0026098]
	Learning Rate: 0.00260985
	LOSS [training: 0.11274624717397368 | validation: 0.06438275128406375]
	TIME [epoch: 6.55 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055056354826107566		[learning rate: 0.0026037]
	Learning Rate: 0.00260369
	LOSS [training: 0.055056354826107566 | validation: 0.03172845312738437]
	TIME [epoch: 6.55 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19050252647169105		[learning rate: 0.0025976]
	Learning Rate: 0.00259755
	LOSS [training: 0.19050252647169105 | validation: 0.02201990590134911]
	TIME [epoch: 6.57 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08007999242092124		[learning rate: 0.0025914]
	Learning Rate: 0.00259142
	LOSS [training: 0.08007999242092124 | validation: 0.07208272105368481]
	TIME [epoch: 6.58 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0720154403981281		[learning rate: 0.0025853]
	Learning Rate: 0.00258531
	LOSS [training: 0.0720154403981281 | validation: 0.04680233703098165]
	TIME [epoch: 6.55 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07195651874726947		[learning rate: 0.0025792]
	Learning Rate: 0.00257921
	LOSS [training: 0.07195651874726947 | validation: 0.06115607587377113]
	TIME [epoch: 6.54 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0882648799973335		[learning rate: 0.0025731]
	Learning Rate: 0.00257313
	LOSS [training: 0.0882648799973335 | validation: 0.05543063711077011]
	TIME [epoch: 6.55 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07007216149810389		[learning rate: 0.0025671]
	Learning Rate: 0.00256706
	LOSS [training: 0.07007216149810389 | validation: 0.08839503164639359]
	TIME [epoch: 6.55 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09588228117265887		[learning rate: 0.002561]
	Learning Rate: 0.002561
	LOSS [training: 0.09588228117265887 | validation: 0.0726291396892043]
	TIME [epoch: 6.59 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08994071045960086		[learning rate: 0.002555]
	Learning Rate: 0.00255496
	LOSS [training: 0.08994071045960086 | validation: 0.05900042806071046]
	TIME [epoch: 6.55 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0828561661924943		[learning rate: 0.0025489]
	Learning Rate: 0.00254894
	LOSS [training: 0.0828561661924943 | validation: 0.09376935891496184]
	TIME [epoch: 6.55 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09722796968844705		[learning rate: 0.0025429]
	Learning Rate: 0.00254292
	LOSS [training: 0.09722796968844705 | validation: 0.07126366239844412]
	TIME [epoch: 6.55 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0805858882811011		[learning rate: 0.0025369]
	Learning Rate: 0.00253693
	LOSS [training: 0.0805858882811011 | validation: 0.04500070405282357]
	TIME [epoch: 6.55 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09335807235089724		[learning rate: 0.0025309]
	Learning Rate: 0.00253094
	LOSS [training: 0.09335807235089724 | validation: 0.061978799951275046]
	TIME [epoch: 6.58 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09787901795396108		[learning rate: 0.002525]
	Learning Rate: 0.00252497
	LOSS [training: 0.09787901795396108 | validation: 0.05619449777978014]
	TIME [epoch: 6.55 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08386983960016979		[learning rate: 0.002519]
	Learning Rate: 0.00251901
	LOSS [training: 0.08386983960016979 | validation: 0.057427717918848986]
	TIME [epoch: 6.54 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06579567696898751		[learning rate: 0.0025131]
	Learning Rate: 0.00251307
	LOSS [training: 0.06579567696898751 | validation: 0.05332392990770188]
	TIME [epoch: 6.55 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06952259057417484		[learning rate: 0.0025071]
	Learning Rate: 0.00250715
	LOSS [training: 0.06952259057417484 | validation: 0.07969469987721006]
	TIME [epoch: 6.54 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08818930952913209		[learning rate: 0.0025012]
	Learning Rate: 0.00250123
	LOSS [training: 0.08818930952913209 | validation: 0.07273735946599585]
	TIME [epoch: 6.58 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12922338854291177		[learning rate: 0.0024953]
	Learning Rate: 0.00249533
	LOSS [training: 0.12922338854291177 | validation: 0.07677569968560471]
	TIME [epoch: 6.55 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09521224369697005		[learning rate: 0.0024894]
	Learning Rate: 0.00248945
	LOSS [training: 0.09521224369697005 | validation: 0.06073748431021764]
	TIME [epoch: 6.55 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09188232057200574		[learning rate: 0.0024836]
	Learning Rate: 0.00248357
	LOSS [training: 0.09188232057200574 | validation: 0.0870968158211266]
	TIME [epoch: 6.54 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0960876569599749		[learning rate: 0.0024777]
	Learning Rate: 0.00247771
	LOSS [training: 0.0960876569599749 | validation: 0.09679553564715145]
	TIME [epoch: 6.54 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1101040611633393		[learning rate: 0.0024719]
	Learning Rate: 0.00247187
	LOSS [training: 0.1101040611633393 | validation: 0.0963950055258225]
	TIME [epoch: 6.56 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09191860680241645		[learning rate: 0.002466]
	Learning Rate: 0.00246604
	LOSS [training: 0.09191860680241645 | validation: 0.0626330243854627]
	TIME [epoch: 6.58 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07139203903374661		[learning rate: 0.0024602]
	Learning Rate: 0.00246022
	LOSS [training: 0.07139203903374661 | validation: 0.056150928948489956]
	TIME [epoch: 6.55 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07802766648212375		[learning rate: 0.0024544]
	Learning Rate: 0.00245442
	LOSS [training: 0.07802766648212375 | validation: 0.06189762746037829]
	TIME [epoch: 6.55 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0880299558012508		[learning rate: 0.0024486]
	Learning Rate: 0.00244863
	LOSS [training: 0.0880299558012508 | validation: 0.04463023023291729]
	TIME [epoch: 6.55 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0936729516386708		[learning rate: 0.0024429]
	Learning Rate: 0.00244285
	LOSS [training: 0.0936729516386708 | validation: 0.06376731936118232]
	TIME [epoch: 6.55 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0813809945418422		[learning rate: 0.0024371]
	Learning Rate: 0.00243709
	LOSS [training: 0.0813809945418422 | validation: 0.05686675931464277]
	TIME [epoch: 6.58 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06839952181604755		[learning rate: 0.0024313]
	Learning Rate: 0.00243134
	LOSS [training: 0.06839952181604755 | validation: 0.06299551386313182]
	TIME [epoch: 6.55 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060993951177627195		[learning rate: 0.0024256]
	Learning Rate: 0.00242561
	LOSS [training: 0.060993951177627195 | validation: 0.047880829329104875]
	TIME [epoch: 6.55 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06546347613153539		[learning rate: 0.0024199]
	Learning Rate: 0.00241989
	LOSS [training: 0.06546347613153539 | validation: 0.05059359312441379]
	TIME [epoch: 6.54 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07321169768432137		[learning rate: 0.0024142]
	Learning Rate: 0.00241418
	LOSS [training: 0.07321169768432137 | validation: 0.059663507019104514]
	TIME [epoch: 6.55 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06788735417887184		[learning rate: 0.0024085]
	Learning Rate: 0.00240848
	LOSS [training: 0.06788735417887184 | validation: 0.08313320998165195]
	TIME [epoch: 6.58 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0736104673716085		[learning rate: 0.0024028]
	Learning Rate: 0.0024028
	LOSS [training: 0.0736104673716085 | validation: 0.05039991146705194]
	TIME [epoch: 6.55 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10441281889317652		[learning rate: 0.0023971]
	Learning Rate: 0.00239713
	LOSS [training: 0.10441281889317652 | validation: 0.0650942452060212]
	TIME [epoch: 6.54 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07774485679903129		[learning rate: 0.0023915]
	Learning Rate: 0.00239148
	LOSS [training: 0.07774485679903129 | validation: 0.04505559466542059]
	TIME [epoch: 6.54 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06857732910411457		[learning rate: 0.0023858]
	Learning Rate: 0.00238584
	LOSS [training: 0.06857732910411457 | validation: 0.06112447834674625]
	TIME [epoch: 6.54 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08438892578153306		[learning rate: 0.0023802]
	Learning Rate: 0.00238021
	LOSS [training: 0.08438892578153306 | validation: 0.06772987074690238]
	TIME [epoch: 6.58 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0905254678291684		[learning rate: 0.0023746]
	Learning Rate: 0.0023746
	LOSS [training: 0.0905254678291684 | validation: 0.05662960511662405]
	TIME [epoch: 6.56 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08174830331444091		[learning rate: 0.002369]
	Learning Rate: 0.00236899
	LOSS [training: 0.08174830331444091 | validation: 0.05908516211030386]
	TIME [epoch: 6.54 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07507413437865916		[learning rate: 0.0023634]
	Learning Rate: 0.00236341
	LOSS [training: 0.07507413437865916 | validation: 0.08949141562572596]
	TIME [epoch: 6.55 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08463342277724736		[learning rate: 0.0023578]
	Learning Rate: 0.00235783
	LOSS [training: 0.08463342277724736 | validation: 0.06639963280945232]
	TIME [epoch: 6.54 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08079706617299694		[learning rate: 0.0023523]
	Learning Rate: 0.00235227
	LOSS [training: 0.08079706617299694 | validation: 0.0853710597744587]
	TIME [epoch: 6.56 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09217454480514983		[learning rate: 0.0023467]
	Learning Rate: 0.00234672
	LOSS [training: 0.09217454480514983 | validation: 0.08193285766875576]
	TIME [epoch: 6.58 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07478006659406532		[learning rate: 0.0023412]
	Learning Rate: 0.00234119
	LOSS [training: 0.07478006659406532 | validation: 0.06656399132692609]
	TIME [epoch: 6.55 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09228462168411446		[learning rate: 0.0023357]
	Learning Rate: 0.00233566
	LOSS [training: 0.09228462168411446 | validation: 0.06885980695302499]
	TIME [epoch: 6.54 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0769925440900648		[learning rate: 0.0023302]
	Learning Rate: 0.00233015
	LOSS [training: 0.0769925440900648 | validation: 0.07422287172530014]
	TIME [epoch: 6.54 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07392291244970509		[learning rate: 0.0023247]
	Learning Rate: 0.00232466
	LOSS [training: 0.07392291244970509 | validation: 0.04619514773713691]
	TIME [epoch: 6.55 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06267862677649311		[learning rate: 0.0023192]
	Learning Rate: 0.00231917
	LOSS [training: 0.06267862677649311 | validation: 0.05405681362341588]
	TIME [epoch: 6.57 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05887887222732439		[learning rate: 0.0023137]
	Learning Rate: 0.0023137
	LOSS [training: 0.05887887222732439 | validation: 0.05020262983938463]
	TIME [epoch: 6.54 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.070703981819123		[learning rate: 0.0023082]
	Learning Rate: 0.00230825
	LOSS [training: 0.070703981819123 | validation: 0.05186692229543271]
	TIME [epoch: 6.55 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09474970899482173		[learning rate: 0.0023028]
	Learning Rate: 0.0023028
	LOSS [training: 0.09474970899482173 | validation: 0.07416971915258458]
	TIME [epoch: 6.54 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07953588343990795		[learning rate: 0.0022974]
	Learning Rate: 0.00229737
	LOSS [training: 0.07953588343990795 | validation: 0.04493706598414303]
	TIME [epoch: 6.54 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07125365922381625		[learning rate: 0.0022919]
	Learning Rate: 0.00229195
	LOSS [training: 0.07125365922381625 | validation: 0.06043006223827341]
	TIME [epoch: 6.58 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06692284679181679		[learning rate: 0.0022865]
	Learning Rate: 0.00228654
	LOSS [training: 0.06692284679181679 | validation: 0.0733955023102271]
	TIME [epoch: 6.55 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06716901958169175		[learning rate: 0.0022811]
	Learning Rate: 0.00228115
	LOSS [training: 0.06716901958169175 | validation: 0.048140520476610806]
	TIME [epoch: 6.54 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06158925034395579		[learning rate: 0.0022758]
	Learning Rate: 0.00227577
	LOSS [training: 0.06158925034395579 | validation: 0.04553468997571]
	TIME [epoch: 6.54 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.088405148411237		[learning rate: 0.0022704]
	Learning Rate: 0.0022704
	LOSS [training: 0.088405148411237 | validation: 0.06439361480026913]
	TIME [epoch: 6.54 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07530725632993891		[learning rate: 0.002265]
	Learning Rate: 0.00226505
	LOSS [training: 0.07530725632993891 | validation: 0.06818491079567668]
	TIME [epoch: 6.57 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07973473335652215		[learning rate: 0.0022597]
	Learning Rate: 0.0022597
	LOSS [training: 0.07973473335652215 | validation: 0.06683099494758074]
	TIME [epoch: 6.55 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.079265560421488		[learning rate: 0.0022544]
	Learning Rate: 0.00225437
	LOSS [training: 0.079265560421488 | validation: 0.03380469050688915]
	TIME [epoch: 6.54 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07990915545244207		[learning rate: 0.0022491]
	Learning Rate: 0.00224905
	LOSS [training: 0.07990915545244207 | validation: 0.06658350843768915]
	TIME [epoch: 6.55 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07003075807578976		[learning rate: 0.0022437]
	Learning Rate: 0.00224375
	LOSS [training: 0.07003075807578976 | validation: 0.05692290053381688]
	TIME [epoch: 6.55 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07557176142686227		[learning rate: 0.0022385]
	Learning Rate: 0.00223846
	LOSS [training: 0.07557176142686227 | validation: 0.056636745913189616]
	TIME [epoch: 6.56 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07103772860154386		[learning rate: 0.0022332]
	Learning Rate: 0.00223318
	LOSS [training: 0.07103772860154386 | validation: 0.04420533165545408]
	TIME [epoch: 6.58 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06482383796261623		[learning rate: 0.0022279]
	Learning Rate: 0.00222791
	LOSS [training: 0.06482383796261623 | validation: 0.04608966733231861]
	TIME [epoch: 6.55 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06524031478853216		[learning rate: 0.0022227]
	Learning Rate: 0.00222265
	LOSS [training: 0.06524031478853216 | validation: 0.05629799764235664]
	TIME [epoch: 6.55 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06221929243900316		[learning rate: 0.0022174]
	Learning Rate: 0.00221741
	LOSS [training: 0.06221929243900316 | validation: 0.0515529888583266]
	TIME [epoch: 6.55 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06265286113934707		[learning rate: 0.0022122]
	Learning Rate: 0.00221218
	LOSS [training: 0.06265286113934707 | validation: 0.05780767902638974]
	TIME [epoch: 6.55 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06514626104913135		[learning rate: 0.002207]
	Learning Rate: 0.00220696
	LOSS [training: 0.06514626104913135 | validation: 0.038975402527076174]
	TIME [epoch: 6.59 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0720453680155428		[learning rate: 0.0022018]
	Learning Rate: 0.00220176
	LOSS [training: 0.0720453680155428 | validation: 0.06158305690903567]
	TIME [epoch: 6.55 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07541150727657583		[learning rate: 0.0021966]
	Learning Rate: 0.00219656
	LOSS [training: 0.07541150727657583 | validation: 0.03677962765330073]
	TIME [epoch: 6.55 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0601889014190065		[learning rate: 0.0021914]
	Learning Rate: 0.00219138
	LOSS [training: 0.0601889014190065 | validation: 0.06386066401624027]
	TIME [epoch: 6.54 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08965959031883368		[learning rate: 0.0021862]
	Learning Rate: 0.00218621
	LOSS [training: 0.08965959031883368 | validation: 0.07502591086306429]
	TIME [epoch: 6.54 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07392525883478691		[learning rate: 0.0021811]
	Learning Rate: 0.00218106
	LOSS [training: 0.07392525883478691 | validation: 0.09747480431676096]
	TIME [epoch: 6.58 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08716812207624144		[learning rate: 0.0021759]
	Learning Rate: 0.00217591
	LOSS [training: 0.08716812207624144 | validation: 0.045260930945846344]
	TIME [epoch: 6.54 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06858725303298949		[learning rate: 0.0021708]
	Learning Rate: 0.00217078
	LOSS [training: 0.06858725303298949 | validation: 0.07616324338627356]
	TIME [epoch: 6.54 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08046369362761978		[learning rate: 0.0021657]
	Learning Rate: 0.00216566
	LOSS [training: 0.08046369362761978 | validation: 0.0699108495862646]
	TIME [epoch: 6.54 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07102879906695389		[learning rate: 0.0021605]
	Learning Rate: 0.00216055
	LOSS [training: 0.07102879906695389 | validation: 0.07241875475343362]
	TIME [epoch: 6.55 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06640166731285471		[learning rate: 0.0021555]
	Learning Rate: 0.00215545
	LOSS [training: 0.06640166731285471 | validation: 0.054740593671285594]
	TIME [epoch: 6.58 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06938613672733117		[learning rate: 0.0021504]
	Learning Rate: 0.00215037
	LOSS [training: 0.06938613672733117 | validation: 0.050593353874189645]
	TIME [epoch: 6.56 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.070733995512734		[learning rate: 0.0021453]
	Learning Rate: 0.0021453
	LOSS [training: 0.070733995512734 | validation: 0.05812050856393744]
	TIME [epoch: 6.55 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06481899497587032		[learning rate: 0.0021402]
	Learning Rate: 0.00214024
	LOSS [training: 0.06481899497587032 | validation: 0.042142638013665856]
	TIME [epoch: 6.55 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05932044068450557		[learning rate: 0.0021352]
	Learning Rate: 0.00213519
	LOSS [training: 0.05932044068450557 | validation: 0.04223695740897607]
	TIME [epoch: 6.55 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060376382499766165		[learning rate: 0.0021302]
	Learning Rate: 0.00213015
	LOSS [training: 0.060376382499766165 | validation: 0.03939894722284526]
	TIME [epoch: 6.56 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06805520563987816		[learning rate: 0.0021251]
	Learning Rate: 0.00212513
	LOSS [training: 0.06805520563987816 | validation: 0.049686424778767085]
	TIME [epoch: 6.57 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07000147215947312		[learning rate: 0.0021201]
	Learning Rate: 0.00212011
	LOSS [training: 0.07000147215947312 | validation: 0.04679982160835789]
	TIME [epoch: 6.55 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06397123261517666		[learning rate: 0.0021151]
	Learning Rate: 0.00211511
	LOSS [training: 0.06397123261517666 | validation: 0.06795026532318359]
	TIME [epoch: 6.55 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07396932118540137		[learning rate: 0.0021101]
	Learning Rate: 0.00211012
	LOSS [training: 0.07396932118540137 | validation: 0.09152245876341364]
	TIME [epoch: 6.55 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09198473315981856		[learning rate: 0.0021051]
	Learning Rate: 0.00210515
	LOSS [training: 0.09198473315981856 | validation: 0.11484216617961387]
	TIME [epoch: 6.55 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08274796549036342		[learning rate: 0.0021002]
	Learning Rate: 0.00210018
	LOSS [training: 0.08274796549036342 | validation: 0.03812601831470289]
	TIME [epoch: 6.58 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0591008077552493		[learning rate: 0.0020952]
	Learning Rate: 0.00209523
	LOSS [training: 0.0591008077552493 | validation: 0.04319778760283854]
	TIME [epoch: 6.55 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060200059753837756		[learning rate: 0.0020903]
	Learning Rate: 0.00209028
	LOSS [training: 0.060200059753837756 | validation: 0.05458584773020475]
	TIME [epoch: 6.54 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06156027731120819		[learning rate: 0.0020854]
	Learning Rate: 0.00208535
	LOSS [training: 0.06156027731120819 | validation: 0.04430844822133315]
	TIME [epoch: 6.55 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06724280331800289		[learning rate: 0.0020804]
	Learning Rate: 0.00208043
	LOSS [training: 0.06724280331800289 | validation: 0.0779362494279233]
	TIME [epoch: 6.55 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07850280806438308		[learning rate: 0.0020755]
	Learning Rate: 0.00207553
	LOSS [training: 0.07850280806438308 | validation: 0.060093051023426394]
	TIME [epoch: 6.58 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08565719497845385		[learning rate: 0.0020706]
	Learning Rate: 0.00207063
	LOSS [training: 0.08565719497845385 | validation: 0.053893234402239955]
	TIME [epoch: 6.55 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06130145661981433		[learning rate: 0.0020657]
	Learning Rate: 0.00206575
	LOSS [training: 0.06130145661981433 | validation: 0.04596961217200536]
	TIME [epoch: 6.54 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060542096919450415		[learning rate: 0.0020609]
	Learning Rate: 0.00206087
	LOSS [training: 0.060542096919450415 | validation: 0.08086173217875564]
	TIME [epoch: 6.54 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07939390765725032		[learning rate: 0.002056]
	Learning Rate: 0.00205601
	LOSS [training: 0.07939390765725032 | validation: 0.06400383847124175]
	TIME [epoch: 6.55 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.062290954981334926		[learning rate: 0.0020512]
	Learning Rate: 0.00205116
	LOSS [training: 0.062290954981334926 | validation: 0.041945327573710285]
	TIME [epoch: 6.57 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06862102376715397		[learning rate: 0.0020463]
	Learning Rate: 0.00204632
	LOSS [training: 0.06862102376715397 | validation: 0.07300725646205512]
	TIME [epoch: 6.57 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0669799598444624		[learning rate: 0.0020415]
	Learning Rate: 0.0020415
	LOSS [training: 0.0669799598444624 | validation: 0.04493714398294041]
	TIME [epoch: 6.55 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05857283762317221		[learning rate: 0.0020367]
	Learning Rate: 0.00203668
	LOSS [training: 0.05857283762317221 | validation: 0.044086668472232596]
	TIME [epoch: 6.54 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06190081907618554		[learning rate: 0.0020319]
	Learning Rate: 0.00203188
	LOSS [training: 0.06190081907618554 | validation: 0.06084534802133683]
	TIME [epoch: 6.55 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07281467323052354		[learning rate: 0.0020271]
	Learning Rate: 0.00202708
	LOSS [training: 0.07281467323052354 | validation: 0.055090861874633246]
	TIME [epoch: 6.55 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06321426161188021		[learning rate: 0.0020223]
	Learning Rate: 0.0020223
	LOSS [training: 0.06321426161188021 | validation: 0.0532114779930255]
	TIME [epoch: 6.59 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06036517572893553		[learning rate: 0.0020175]
	Learning Rate: 0.00201753
	LOSS [training: 0.06036517572893553 | validation: 0.06149009477410966]
	TIME [epoch: 6.55 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07506725660878248		[learning rate: 0.0020128]
	Learning Rate: 0.00201277
	LOSS [training: 0.07506725660878248 | validation: 0.040614540520093584]
	TIME [epoch: 6.55 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06115802274260407		[learning rate: 0.002008]
	Learning Rate: 0.00200803
	LOSS [training: 0.06115802274260407 | validation: 0.04958528936359438]
	TIME [epoch: 6.55 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05810141288400785		[learning rate: 0.0020033]
	Learning Rate: 0.00200329
	LOSS [training: 0.05810141288400785 | validation: 0.04544254791610022]
	TIME [epoch: 6.54 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06942980872510082		[learning rate: 0.0019986]
	Learning Rate: 0.00199856
	LOSS [training: 0.06942980872510082 | validation: 0.044514536408663666]
	TIME [epoch: 6.59 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06852572952626747		[learning rate: 0.0019938]
	Learning Rate: 0.00199385
	LOSS [training: 0.06852572952626747 | validation: 0.04704941514509732]
	TIME [epoch: 6.56 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059176992990478364		[learning rate: 0.0019891]
	Learning Rate: 0.00198915
	LOSS [training: 0.059176992990478364 | validation: 0.046501942477161586]
	TIME [epoch: 6.55 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07065070788929695		[learning rate: 0.0019845]
	Learning Rate: 0.00198445
	LOSS [training: 0.07065070788929695 | validation: 0.054539977258354216]
	TIME [epoch: 6.55 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060494300062079384		[learning rate: 0.0019798]
	Learning Rate: 0.00197977
	LOSS [training: 0.060494300062079384 | validation: 0.044556760955689195]
	TIME [epoch: 6.55 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06650177683612142		[learning rate: 0.0019751]
	Learning Rate: 0.0019751
	LOSS [training: 0.06650177683612142 | validation: 0.04860645082242222]
	TIME [epoch: 6.59 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05588855049920467		[learning rate: 0.0019704]
	Learning Rate: 0.00197044
	LOSS [training: 0.05588855049920467 | validation: 0.038556924558380834]
	TIME [epoch: 6.55 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06108934788624358		[learning rate: 0.0019658]
	Learning Rate: 0.0019658
	LOSS [training: 0.06108934788624358 | validation: 0.04493025631083765]
	TIME [epoch: 6.55 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06203349257709512		[learning rate: 0.0019612]
	Learning Rate: 0.00196116
	LOSS [training: 0.06203349257709512 | validation: 0.05941218482679382]
	TIME [epoch: 6.54 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06011828741150739		[learning rate: 0.0019565]
	Learning Rate: 0.00195653
	LOSS [training: 0.06011828741150739 | validation: 0.03644758639097519]
	TIME [epoch: 6.55 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05143805844652979		[learning rate: 0.0019519]
	Learning Rate: 0.00195192
	LOSS [training: 0.05143805844652979 | validation: 0.04600423752942665]
	TIME [epoch: 6.55 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05940387029768961		[learning rate: 0.0019473]
	Learning Rate: 0.00194731
	LOSS [training: 0.05940387029768961 | validation: 0.03156982242518773]
	TIME [epoch: 6.57 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0668055491783424		[learning rate: 0.0019427]
	Learning Rate: 0.00194272
	LOSS [training: 0.0668055491783424 | validation: 0.05934164266906937]
	TIME [epoch: 6.54 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06684620163140828		[learning rate: 0.0019381]
	Learning Rate: 0.00193814
	LOSS [training: 0.06684620163140828 | validation: 0.07409772515847832]
	TIME [epoch: 6.55 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09384889975522329		[learning rate: 0.0019336]
	Learning Rate: 0.00193357
	LOSS [training: 0.09384889975522329 | validation: 0.04639759904788447]
	TIME [epoch: 6.55 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06465280683973838		[learning rate: 0.001929]
	Learning Rate: 0.001929
	LOSS [training: 0.06465280683973838 | validation: 0.05050831289356669]
	TIME [epoch: 6.55 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061670358772658626		[learning rate: 0.0019245]
	Learning Rate: 0.00192445
	LOSS [training: 0.061670358772658626 | validation: 0.06127353915299755]
	TIME [epoch: 6.59 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06979704509586863		[learning rate: 0.0019199]
	Learning Rate: 0.00191992
	LOSS [training: 0.06979704509586863 | validation: 0.05063105798981569]
	TIME [epoch: 6.55 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06590452657534261		[learning rate: 0.0019154]
	Learning Rate: 0.00191539
	LOSS [training: 0.06590452657534261 | validation: 0.0683767987495381]
	TIME [epoch: 6.55 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07111591841780479		[learning rate: 0.0019109]
	Learning Rate: 0.00191087
	LOSS [training: 0.07111591841780479 | validation: 0.052268169603921846]
	TIME [epoch: 6.55 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07892879660331131		[learning rate: 0.0019064]
	Learning Rate: 0.00190636
	LOSS [training: 0.07892879660331131 | validation: 0.0552957999550281]
	TIME [epoch: 6.55 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07674875759223812		[learning rate: 0.0019019]
	Learning Rate: 0.00190186
	LOSS [training: 0.07674875759223812 | validation: 0.06461321093324743]
	TIME [epoch: 6.58 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11736058137369568		[learning rate: 0.0018974]
	Learning Rate: 0.00189738
	LOSS [training: 0.11736058137369568 | validation: 0.06028050368505189]
	TIME [epoch: 6.55 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0775818043205209		[learning rate: 0.0018929]
	Learning Rate: 0.0018929
	LOSS [training: 0.0775818043205209 | validation: 0.049018280627850463]
	TIME [epoch: 6.55 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06721923464002212		[learning rate: 0.0018884]
	Learning Rate: 0.00188844
	LOSS [training: 0.06721923464002212 | validation: 0.05317202622816018]
	TIME [epoch: 6.54 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06875088502163115		[learning rate: 0.001884]
	Learning Rate: 0.00188398
	LOSS [training: 0.06875088502163115 | validation: 0.05051798377414719]
	TIME [epoch: 6.54 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06431568820614017		[learning rate: 0.0018795]
	Learning Rate: 0.00187954
	LOSS [training: 0.06431568820614017 | validation: 0.047469516245206615]
	TIME [epoch: 6.57 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05879961842745747		[learning rate: 0.0018751]
	Learning Rate: 0.00187511
	LOSS [training: 0.05879961842745747 | validation: 0.05889508999308163]
	TIME [epoch: 6.56 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06768004185304476		[learning rate: 0.0018707]
	Learning Rate: 0.00187068
	LOSS [training: 0.06768004185304476 | validation: 0.039919293946421366]
	TIME [epoch: 6.54 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.052880596671003255		[learning rate: 0.0018663]
	Learning Rate: 0.00186627
	LOSS [training: 0.052880596671003255 | validation: 0.048602417998305725]
	TIME [epoch: 6.54 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055495917523627744		[learning rate: 0.0018619]
	Learning Rate: 0.00186187
	LOSS [training: 0.055495917523627744 | validation: 0.04353531493311473]
	TIME [epoch: 6.54 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06455303293552442		[learning rate: 0.0018575]
	Learning Rate: 0.00185748
	LOSS [training: 0.06455303293552442 | validation: 0.08313391985728691]
	TIME [epoch: 6.55 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07612711657483105		[learning rate: 0.0018531]
	Learning Rate: 0.00185309
	LOSS [training: 0.07612711657483105 | validation: 0.051662014083716026]
	TIME [epoch: 6.57 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0723258013929726		[learning rate: 0.0018487]
	Learning Rate: 0.00184872
	LOSS [training: 0.0723258013929726 | validation: 0.055116116031942525]
	TIME [epoch: 6.54 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06364942891005176		[learning rate: 0.0018444]
	Learning Rate: 0.00184436
	LOSS [training: 0.06364942891005176 | validation: 0.04800717620562453]
	TIME [epoch: 6.55 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06794418325524068		[learning rate: 0.00184]
	Learning Rate: 0.00184001
	LOSS [training: 0.06794418325524068 | validation: 0.04885631560005512]
	TIME [epoch: 6.55 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06673883072373518		[learning rate: 0.0018357]
	Learning Rate: 0.00183567
	LOSS [training: 0.06673883072373518 | validation: 0.05014844551089432]
	TIME [epoch: 6.55 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05378779479688774		[learning rate: 0.0018313]
	Learning Rate: 0.00183134
	LOSS [training: 0.05378779479688774 | validation: 0.048899946873176794]
	TIME [epoch: 6.58 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0554677492939741		[learning rate: 0.001827]
	Learning Rate: 0.00182702
	LOSS [training: 0.0554677492939741 | validation: 0.04974088805694879]
	TIME [epoch: 6.55 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058918422089373625		[learning rate: 0.0018227]
	Learning Rate: 0.00182271
	LOSS [training: 0.058918422089373625 | validation: 0.04459601892811153]
	TIME [epoch: 6.55 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07178377616094019		[learning rate: 0.0018184]
	Learning Rate: 0.00181841
	LOSS [training: 0.07178377616094019 | validation: 0.053639306396402506]
	TIME [epoch: 6.55 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060427542168520254		[learning rate: 0.0018141]
	Learning Rate: 0.00181412
	LOSS [training: 0.060427542168520254 | validation: 0.03612674375106216]
	TIME [epoch: 6.55 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0690371486846589		[learning rate: 0.0018098]
	Learning Rate: 0.00180984
	LOSS [training: 0.0690371486846589 | validation: 0.051126297538868694]
	TIME [epoch: 6.59 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058958043894250425		[learning rate: 0.0018056]
	Learning Rate: 0.00180557
	LOSS [training: 0.058958043894250425 | validation: 0.040882704165149636]
	TIME [epoch: 6.56 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07321415453616062		[learning rate: 0.0018013]
	Learning Rate: 0.00180132
	LOSS [training: 0.07321415453616062 | validation: 0.05255633017180753]
	TIME [epoch: 6.55 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06314848051514213		[learning rate: 0.0017971]
	Learning Rate: 0.00179707
	LOSS [training: 0.06314848051514213 | validation: 0.04782269144047886]
	TIME [epoch: 6.55 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07244581248085108		[learning rate: 0.0017928]
	Learning Rate: 0.00179283
	LOSS [training: 0.07244581248085108 | validation: 0.0702516538829268]
	TIME [epoch: 6.55 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06928426008950365		[learning rate: 0.0017886]
	Learning Rate: 0.0017886
	LOSS [training: 0.06928426008950365 | validation: 0.09197040708667414]
	TIME [epoch: 6.58 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08252331141994675		[learning rate: 0.0017844]
	Learning Rate: 0.00178438
	LOSS [training: 0.08252331141994675 | validation: 0.04568036781238294]
	TIME [epoch: 6.56 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06044222184995076		[learning rate: 0.0017802]
	Learning Rate: 0.00178017
	LOSS [training: 0.06044222184995076 | validation: 0.059926196837945485]
	TIME [epoch: 6.56 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0628313793403618		[learning rate: 0.001776]
	Learning Rate: 0.00177597
	LOSS [training: 0.0628313793403618 | validation: 0.04309591896396158]
	TIME [epoch: 6.55 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06403028048436626		[learning rate: 0.0017718]
	Learning Rate: 0.00177178
	LOSS [training: 0.06403028048436626 | validation: 0.043382430090983935]
	TIME [epoch: 6.55 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059970079167510335		[learning rate: 0.0017676]
	Learning Rate: 0.0017676
	LOSS [training: 0.059970079167510335 | validation: 0.09576471414497945]
	TIME [epoch: 6.56 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08178208393751912		[learning rate: 0.0017634]
	Learning Rate: 0.00176343
	LOSS [training: 0.08178208393751912 | validation: 0.04548037527397239]
	TIME [epoch: 6.58 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06081773708557231		[learning rate: 0.0017593]
	Learning Rate: 0.00175927
	LOSS [training: 0.06081773708557231 | validation: 0.06853932176309695]
	TIME [epoch: 6.55 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06918056225783521		[learning rate: 0.0017551]
	Learning Rate: 0.00175512
	LOSS [training: 0.06918056225783521 | validation: 0.055110199664577524]
	TIME [epoch: 6.55 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06317399712965556		[learning rate: 0.001751]
	Learning Rate: 0.00175098
	LOSS [training: 0.06317399712965556 | validation: 0.05724349448218932]
	TIME [epoch: 6.55 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061372855539240156		[learning rate: 0.0017469]
	Learning Rate: 0.00174685
	LOSS [training: 0.061372855539240156 | validation: 0.05283242390025658]
	TIME [epoch: 6.56 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05925950901394915		[learning rate: 0.0017427]
	Learning Rate: 0.00174273
	LOSS [training: 0.05925950901394915 | validation: 0.04049252111655669]
	TIME [epoch: 6.59 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05649777096208843		[learning rate: 0.0017386]
	Learning Rate: 0.00173862
	LOSS [training: 0.05649777096208843 | validation: 0.06606850760991942]
	TIME [epoch: 6.56 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07063215590291513		[learning rate: 0.0017345]
	Learning Rate: 0.00173452
	LOSS [training: 0.07063215590291513 | validation: 0.05981866233239078]
	TIME [epoch: 6.55 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06331928507131461		[learning rate: 0.0017304]
	Learning Rate: 0.00173043
	LOSS [training: 0.06331928507131461 | validation: 0.05398469752170029]
	TIME [epoch: 6.55 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07058031273824962		[learning rate: 0.0017263]
	Learning Rate: 0.00172635
	LOSS [training: 0.07058031273824962 | validation: 0.04982046937922317]
	TIME [epoch: 6.55 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06893633501792548		[learning rate: 0.0017223]
	Learning Rate: 0.00172228
	LOSS [training: 0.06893633501792548 | validation: 0.05452665731202211]
	TIME [epoch: 6.59 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08775165025765856		[learning rate: 0.0017182]
	Learning Rate: 0.00171821
	LOSS [training: 0.08775165025765856 | validation: 0.05530238394336247]
	TIME [epoch: 6.55 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0648915467692566		[learning rate: 0.0017142]
	Learning Rate: 0.00171416
	LOSS [training: 0.0648915467692566 | validation: 0.06397333678912939]
	TIME [epoch: 6.55 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06012979186590769		[learning rate: 0.0017101]
	Learning Rate: 0.00171012
	LOSS [training: 0.06012979186590769 | validation: 0.059291562576811244]
	TIME [epoch: 6.55 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06632203048951539		[learning rate: 0.0017061]
	Learning Rate: 0.00170608
	LOSS [training: 0.06632203048951539 | validation: 0.04887958420672639]
	TIME [epoch: 6.55 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05431111864044308		[learning rate: 0.0017021]
	Learning Rate: 0.00170206
	LOSS [training: 0.05431111864044308 | validation: 0.039906523833529946]
	TIME [epoch: 6.58 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07440735606769137		[learning rate: 0.001698]
	Learning Rate: 0.00169804
	LOSS [training: 0.07440735606769137 | validation: 0.15285752861704752]
	TIME [epoch: 6.56 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10954382831596113		[learning rate: 0.001694]
	Learning Rate: 0.00169404
	LOSS [training: 0.10954382831596113 | validation: 0.06140139035044613]
	TIME [epoch: 6.55 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05359205741234888		[learning rate: 0.00169]
	Learning Rate: 0.00169004
	LOSS [training: 0.05359205741234888 | validation: 0.05469367438390714]
	TIME [epoch: 6.55 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06614102368722552		[learning rate: 0.0016861]
	Learning Rate: 0.00168606
	LOSS [training: 0.06614102368722552 | validation: 0.0370497449995433]
	TIME [epoch: 6.56 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05705397081111918		[learning rate: 0.0016821]
	Learning Rate: 0.00168208
	LOSS [training: 0.05705397081111918 | validation: 0.05616098520943303]
	TIME [epoch: 6.56 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.066984515881787		[learning rate: 0.0016781]
	Learning Rate: 0.00167811
	LOSS [training: 0.066984515881787 | validation: 0.052869262376998766]
	TIME [epoch: 6.59 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05641416422881821		[learning rate: 0.0016742]
	Learning Rate: 0.00167415
	LOSS [training: 0.05641416422881821 | validation: 0.06356733370382073]
	TIME [epoch: 6.55 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07579774020052332		[learning rate: 0.0016702]
	Learning Rate: 0.0016702
	LOSS [training: 0.07579774020052332 | validation: 0.062274458226115284]
	TIME [epoch: 6.54 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07561521077415027		[learning rate: 0.0016663]
	Learning Rate: 0.00166626
	LOSS [training: 0.07561521077415027 | validation: 0.07304309920248596]
	TIME [epoch: 6.55 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07175296832172749		[learning rate: 0.0016623]
	Learning Rate: 0.00166233
	LOSS [training: 0.07175296832172749 | validation: 0.06134782693053356]
	TIME [epoch: 6.55 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05936473336956768		[learning rate: 0.0016584]
	Learning Rate: 0.00165841
	LOSS [training: 0.05936473336956768 | validation: 0.048248195547619645]
	TIME [epoch: 6.58 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0591980482659471		[learning rate: 0.0016545]
	Learning Rate: 0.0016545
	LOSS [training: 0.0591980482659471 | validation: 0.03527015343693031]
	TIME [epoch: 6.55 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0541962529351002		[learning rate: 0.0016506]
	Learning Rate: 0.0016506
	LOSS [training: 0.0541962529351002 | validation: 0.04762190686220223]
	TIME [epoch: 6.55 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05619705333403684		[learning rate: 0.0016467]
	Learning Rate: 0.0016467
	LOSS [training: 0.05619705333403684 | validation: 0.05602706559350877]
	TIME [epoch: 6.55 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0659797271019808		[learning rate: 0.0016428]
	Learning Rate: 0.00164282
	LOSS [training: 0.0659797271019808 | validation: 0.0488669762116061]
	TIME [epoch: 6.55 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053989073734108016		[learning rate: 0.0016389]
	Learning Rate: 0.00163894
	LOSS [training: 0.053989073734108016 | validation: 0.03409829236237714]
	TIME [epoch: 6.58 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06051936925508363		[learning rate: 0.0016351]
	Learning Rate: 0.00163508
	LOSS [training: 0.06051936925508363 | validation: 0.039273142000542646]
	TIME [epoch: 6.56 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0680311329665636		[learning rate: 0.0016312]
	Learning Rate: 0.00163122
	LOSS [training: 0.0680311329665636 | validation: 0.05182472912888278]
	TIME [epoch: 6.55 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0603453389881952		[learning rate: 0.0016274]
	Learning Rate: 0.00162737
	LOSS [training: 0.0603453389881952 | validation: 0.050607871175286825]
	TIME [epoch: 6.55 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06355520438249161		[learning rate: 0.0016235]
	Learning Rate: 0.00162353
	LOSS [training: 0.06355520438249161 | validation: 0.04937412162963737]
	TIME [epoch: 6.55 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05589569485173973		[learning rate: 0.0016197]
	Learning Rate: 0.0016197
	LOSS [training: 0.05589569485173973 | validation: 0.040501560636952746]
	TIME [epoch: 6.58 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0661413750834687		[learning rate: 0.0016159]
	Learning Rate: 0.00161588
	LOSS [training: 0.0661413750834687 | validation: 0.06868565184131196]
	TIME [epoch: 6.56 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06606431439478128		[learning rate: 0.0016121]
	Learning Rate: 0.00161207
	LOSS [training: 0.06606431439478128 | validation: 0.03706447220171017]
	TIME [epoch: 6.55 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07328730042611162		[learning rate: 0.0016083]
	Learning Rate: 0.00160827
	LOSS [training: 0.07328730042611162 | validation: 0.06326261685565916]
	TIME [epoch: 6.55 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061981145733309685		[learning rate: 0.0016045]
	Learning Rate: 0.00160448
	LOSS [training: 0.061981145733309685 | validation: 0.0527405971087486]
	TIME [epoch: 6.55 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06007491988020482		[learning rate: 0.0016007]
	Learning Rate: 0.00160069
	LOSS [training: 0.06007491988020482 | validation: 0.04468887155579599]
	TIME [epoch: 6.56 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05564994444035261		[learning rate: 0.0015969]
	Learning Rate: 0.00159692
	LOSS [training: 0.05564994444035261 | validation: 0.053055962570518214]
	TIME [epoch: 6.57 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05845862538511337		[learning rate: 0.0015931]
	Learning Rate: 0.00159315
	LOSS [training: 0.05845862538511337 | validation: 0.0326200391232416]
	TIME [epoch: 6.55 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06781552438371781		[learning rate: 0.0015894]
	Learning Rate: 0.00158939
	LOSS [training: 0.06781552438371781 | validation: 0.04492021812075488]
	TIME [epoch: 6.55 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05446764429784086		[learning rate: 0.0015856]
	Learning Rate: 0.00158564
	LOSS [training: 0.05446764429784086 | validation: 0.03414791761316843]
	TIME [epoch: 6.55 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07499771619908169		[learning rate: 0.0015819]
	Learning Rate: 0.0015819
	LOSS [training: 0.07499771619908169 | validation: 0.034364075247786875]
	TIME [epoch: 6.55 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05803038562144054		[learning rate: 0.0015782]
	Learning Rate: 0.00157817
	LOSS [training: 0.05803038562144054 | validation: 0.038036449838140175]
	TIME [epoch: 6.58 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05560033367019453		[learning rate: 0.0015744]
	Learning Rate: 0.00157445
	LOSS [training: 0.05560033367019453 | validation: 0.04632517125433222]
	TIME [epoch: 6.55 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05994994156407859		[learning rate: 0.0015707]
	Learning Rate: 0.00157073
	LOSS [training: 0.05994994156407859 | validation: 0.060712053250308304]
	TIME [epoch: 6.55 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08043832170910117		[learning rate: 0.001567]
	Learning Rate: 0.00156703
	LOSS [training: 0.08043832170910117 | validation: 0.05686473356177554]
	TIME [epoch: 6.55 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05534592345908688		[learning rate: 0.0015633]
	Learning Rate: 0.00156333
	LOSS [training: 0.05534592345908688 | validation: 0.03529189348083151]
	TIME [epoch: 6.55 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0555504545014926		[learning rate: 0.0015596]
	Learning Rate: 0.00155964
	LOSS [training: 0.0555504545014926 | validation: 0.03979076853016433]
	TIME [epoch: 6.59 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05698301660528349		[learning rate: 0.001556]
	Learning Rate: 0.00155597
	LOSS [training: 0.05698301660528349 | validation: 0.05899713194179818]
	TIME [epoch: 6.56 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05840753468752748		[learning rate: 0.0015523]
	Learning Rate: 0.0015523
	LOSS [training: 0.05840753468752748 | validation: 0.03407725454723722]
	TIME [epoch: 6.55 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.052010940331415276		[learning rate: 0.0015486]
	Learning Rate: 0.00154863
	LOSS [training: 0.052010940331415276 | validation: 0.04605127670196167]
	TIME [epoch: 6.55 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05625501717543598		[learning rate: 0.001545]
	Learning Rate: 0.00154498
	LOSS [training: 0.05625501717543598 | validation: 0.0403332584044787]
	TIME [epoch: 6.55 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0554474535240177		[learning rate: 0.0015413]
	Learning Rate: 0.00154134
	LOSS [training: 0.0554474535240177 | validation: 0.03486376171240257]
	TIME [epoch: 6.58 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05438899354979373		[learning rate: 0.0015377]
	Learning Rate: 0.0015377
	LOSS [training: 0.05438899354979373 | validation: 0.04787152402401121]
	TIME [epoch: 6.56 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06198020399841747		[learning rate: 0.0015341]
	Learning Rate: 0.00153407
	LOSS [training: 0.06198020399841747 | validation: 0.044343256911650836]
	TIME [epoch: 6.55 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05256374987839067		[learning rate: 0.0015305]
	Learning Rate: 0.00153045
	LOSS [training: 0.05256374987839067 | validation: 0.044448735366898785]
	TIME [epoch: 6.55 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07540788054852968		[learning rate: 0.0015268]
	Learning Rate: 0.00152684
	LOSS [training: 0.07540788054852968 | validation: 0.0409704193401522]
	TIME [epoch: 6.55 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07139956584519852		[learning rate: 0.0015232]
	Learning Rate: 0.00152324
	LOSS [training: 0.07139956584519852 | validation: 0.09541230338559467]
	TIME [epoch: 6.56 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10290111417885686		[learning rate: 0.0015196]
	Learning Rate: 0.00151965
	LOSS [training: 0.10290111417885686 | validation: 0.055342895636615444]
	TIME [epoch: 6.57 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06801531456831841		[learning rate: 0.0015161]
	Learning Rate: 0.00151607
	LOSS [training: 0.06801531456831841 | validation: 0.0579817903277868]
	TIME [epoch: 6.55 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0565115264212376		[learning rate: 0.0015125]
	Learning Rate: 0.00151249
	LOSS [training: 0.0565115264212376 | validation: 0.036518394824644196]
	TIME [epoch: 6.56 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0561052840098634		[learning rate: 0.0015089]
	Learning Rate: 0.00150892
	LOSS [training: 0.0561052840098634 | validation: 0.03727562902745621]
	TIME [epoch: 6.55 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.047383697214127746		[learning rate: 0.0015054]
	Learning Rate: 0.00150536
	LOSS [training: 0.047383697214127746 | validation: 0.044902456604228376]
	TIME [epoch: 6.55 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057391269338538		[learning rate: 0.0015018]
	Learning Rate: 0.00150181
	LOSS [training: 0.057391269338538 | validation: 0.04266837005787691]
	TIME [epoch: 6.6 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058974740120900405		[learning rate: 0.0014983]
	Learning Rate: 0.00149827
	LOSS [training: 0.058974740120900405 | validation: 0.045465209928047715]
	TIME [epoch: 6.55 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05829053527523707		[learning rate: 0.0014947]
	Learning Rate: 0.00149473
	LOSS [training: 0.05829053527523707 | validation: 0.0410887968180941]
	TIME [epoch: 6.55 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05565184259522288		[learning rate: 0.0014912]
	Learning Rate: 0.00149121
	LOSS [training: 0.05565184259522288 | validation: 0.040995437863095716]
	TIME [epoch: 6.55 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05244264569591152		[learning rate: 0.0014877]
	Learning Rate: 0.00148769
	LOSS [training: 0.05244264569591152 | validation: 0.04240118042842156]
	TIME [epoch: 6.55 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05021860712890682		[learning rate: 0.0014842]
	Learning Rate: 0.00148418
	LOSS [training: 0.05021860712890682 | validation: 0.05535447891823607]
	TIME [epoch: 6.59 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058093011645223305		[learning rate: 0.0014807]
	Learning Rate: 0.00148068
	LOSS [training: 0.058093011645223305 | validation: 0.037287868892778984]
	TIME [epoch: 6.56 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06428275556690287		[learning rate: 0.0014772]
	Learning Rate: 0.00147719
	LOSS [training: 0.06428275556690287 | validation: 0.0517894909980101]
	TIME [epoch: 6.55 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054206644571934824		[learning rate: 0.0014737]
	Learning Rate: 0.0014737
	LOSS [training: 0.054206644571934824 | validation: 0.0460235774351643]
	TIME [epoch: 6.55 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05461022627739161		[learning rate: 0.0014702]
	Learning Rate: 0.00147023
	LOSS [training: 0.05461022627739161 | validation: 0.04497708639365407]
	TIME [epoch: 6.55 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06075285877231225		[learning rate: 0.0014668]
	Learning Rate: 0.00146676
	LOSS [training: 0.06075285877231225 | validation: 0.04431677666459484]
	TIME [epoch: 6.57 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.056303171094140035		[learning rate: 0.0014633]
	Learning Rate: 0.0014633
	LOSS [training: 0.056303171094140035 | validation: 0.038405463134605425]
	TIME [epoch: 6.56 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04940417455092251		[learning rate: 0.0014598]
	Learning Rate: 0.00145985
	LOSS [training: 0.04940417455092251 | validation: 0.03637265354277812]
	TIME [epoch: 6.55 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06129484494568307		[learning rate: 0.0014564]
	Learning Rate: 0.0014564
	LOSS [training: 0.06129484494568307 | validation: 0.04024248218981162]
	TIME [epoch: 6.55 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05299551395420556		[learning rate: 0.001453]
	Learning Rate: 0.00145297
	LOSS [training: 0.05299551395420556 | validation: 0.0603287273691553]
	TIME [epoch: 6.55 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.071824288795685		[learning rate: 0.0014495]
	Learning Rate: 0.00144954
	LOSS [training: 0.071824288795685 | validation: 0.051967834993554604]
	TIME [epoch: 6.56 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06775997055496417		[learning rate: 0.0014461]
	Learning Rate: 0.00144612
	LOSS [training: 0.06775997055496417 | validation: 0.062054676109427775]
	TIME [epoch: 6.57 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.062459082852099314		[learning rate: 0.0014427]
	Learning Rate: 0.00144271
	LOSS [training: 0.062459082852099314 | validation: 0.04235379825419811]
	TIME [epoch: 6.55 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05132214311591241		[learning rate: 0.0014393]
	Learning Rate: 0.00143931
	LOSS [training: 0.05132214311591241 | validation: 0.03878939384019932]
	TIME [epoch: 6.55 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06448381744381645		[learning rate: 0.0014359]
	Learning Rate: 0.00143591
	LOSS [training: 0.06448381744381645 | validation: 0.06314531988881977]
	TIME [epoch: 6.55 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06578601617576806		[learning rate: 0.0014325]
	Learning Rate: 0.00143253
	LOSS [training: 0.06578601617576806 | validation: 0.047090058329497905]
	TIME [epoch: 6.55 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05509059197447582		[learning rate: 0.0014291]
	Learning Rate: 0.00142915
	LOSS [training: 0.05509059197447582 | validation: 0.0345280265236335]
	TIME [epoch: 6.59 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05381254044413257		[learning rate: 0.0014258]
	Learning Rate: 0.00142578
	LOSS [training: 0.05381254044413257 | validation: 0.03607355314730839]
	TIME [epoch: 6.55 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0610485785177749		[learning rate: 0.0014224]
	Learning Rate: 0.00142241
	LOSS [training: 0.0610485785177749 | validation: 0.0438244708419697]
	TIME [epoch: 6.55 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08791632550299422		[learning rate: 0.0014191]
	Learning Rate: 0.00141906
	LOSS [training: 0.08791632550299422 | validation: 0.06963336886593602]
	TIME [epoch: 6.54 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06940951832826639		[learning rate: 0.0014157]
	Learning Rate: 0.00141571
	LOSS [training: 0.06940951832826639 | validation: 0.05291492842563658]
	TIME [epoch: 6.55 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053069328426169196		[learning rate: 0.0014124]
	Learning Rate: 0.00141237
	LOSS [training: 0.053069328426169196 | validation: 0.03521389745576952]
	TIME [epoch: 6.58 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.052195643710189685		[learning rate: 0.001409]
	Learning Rate: 0.00140904
	LOSS [training: 0.052195643710189685 | validation: 0.048584063351848665]
	TIME [epoch: 6.56 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0598768956589157		[learning rate: 0.0014057]
	Learning Rate: 0.00140572
	LOSS [training: 0.0598768956589157 | validation: 0.044710612176323855]
	TIME [epoch: 6.55 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05358411887335096		[learning rate: 0.0014024]
	Learning Rate: 0.0014024
	LOSS [training: 0.05358411887335096 | validation: 0.05267194282233825]
	TIME [epoch: 6.55 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0485813546387299		[learning rate: 0.0013991]
	Learning Rate: 0.00139909
	LOSS [training: 0.0485813546387299 | validation: 0.042974319946728734]
	TIME [epoch: 6.55 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05241739304037838		[learning rate: 0.0013958]
	Learning Rate: 0.00139579
	LOSS [training: 0.05241739304037838 | validation: 0.03976968041061191]
	TIME [epoch: 6.58 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05245524439546908		[learning rate: 0.0013925]
	Learning Rate: 0.0013925
	LOSS [training: 0.05245524439546908 | validation: 0.0410270102591084]
	TIME [epoch: 6.56 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05650730914715922		[learning rate: 0.0013892]
	Learning Rate: 0.00138921
	LOSS [training: 0.05650730914715922 | validation: 0.051692663037940914]
	TIME [epoch: 6.55 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05647490746589721		[learning rate: 0.0013859]
	Learning Rate: 0.00138594
	LOSS [training: 0.05647490746589721 | validation: 0.06523265172744193]
	TIME [epoch: 6.55 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06902552629271701		[learning rate: 0.0013827]
	Learning Rate: 0.00138267
	LOSS [training: 0.06902552629271701 | validation: 0.04005222773465223]
	TIME [epoch: 6.54 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05575529854204855		[learning rate: 0.0013794]
	Learning Rate: 0.00137941
	LOSS [training: 0.05575529854204855 | validation: 0.03895879389511083]
	TIME [epoch: 6.56 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04729503613036453		[learning rate: 0.0013762]
	Learning Rate: 0.00137615
	LOSS [training: 0.04729503613036453 | validation: 0.03840703008884321]
	TIME [epoch: 6.57 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07286039317705821		[learning rate: 0.0013729]
	Learning Rate: 0.00137291
	LOSS [training: 0.07286039317705821 | validation: 0.04732871836058569]
	TIME [epoch: 6.55 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05846817595849154		[learning rate: 0.0013697]
	Learning Rate: 0.00136967
	LOSS [training: 0.05846817595849154 | validation: 0.04334154558778529]
	TIME [epoch: 6.54 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05879426664748548		[learning rate: 0.0013664]
	Learning Rate: 0.00136644
	LOSS [training: 0.05879426664748548 | validation: 0.06738253723763822]
	TIME [epoch: 6.54 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06017767600912546		[learning rate: 0.0013632]
	Learning Rate: 0.00136321
	LOSS [training: 0.06017767600912546 | validation: 0.03200374325638254]
	TIME [epoch: 6.54 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05189687654410193		[learning rate: 0.00136]
	Learning Rate: 0.00136
	LOSS [training: 0.05189687654410193 | validation: 0.0457312288166624]
	TIME [epoch: 6.58 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05574935190256519		[learning rate: 0.0013568]
	Learning Rate: 0.00135679
	LOSS [training: 0.05574935190256519 | validation: 0.037020796227811625]
	TIME [epoch: 6.55 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05035985045360094		[learning rate: 0.0013536]
	Learning Rate: 0.00135359
	LOSS [training: 0.05035985045360094 | validation: 0.05493537948576399]
	TIME [epoch: 6.55 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05572125394890894		[learning rate: 0.0013504]
	Learning Rate: 0.0013504
	LOSS [training: 0.05572125394890894 | validation: 0.0497994395359973]
	TIME [epoch: 6.54 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0563195508475382		[learning rate: 0.0013472]
	Learning Rate: 0.00134721
	LOSS [training: 0.0563195508475382 | validation: 0.03898591132802109]
	TIME [epoch: 6.54 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05957149163946392		[learning rate: 0.001344]
	Learning Rate: 0.00134403
	LOSS [training: 0.05957149163946392 | validation: 0.04005338792749197]
	TIME [epoch: 6.57 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.052372664118071524		[learning rate: 0.0013409]
	Learning Rate: 0.00134086
	LOSS [training: 0.052372664118071524 | validation: 0.049241947206535325]
	TIME [epoch: 6.55 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05067489101034718		[learning rate: 0.0013377]
	Learning Rate: 0.0013377
	LOSS [training: 0.05067489101034718 | validation: 0.03985452517964781]
	TIME [epoch: 6.54 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05258711904465825		[learning rate: 0.0013345]
	Learning Rate: 0.00133455
	LOSS [training: 0.05258711904465825 | validation: 0.041463811573397846]
	TIME [epoch: 6.54 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06755032522924856		[learning rate: 0.0013314]
	Learning Rate: 0.0013314
	LOSS [training: 0.06755032522924856 | validation: 0.0617282162953059]
	TIME [epoch: 6.54 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055427233570560674		[learning rate: 0.0013283]
	Learning Rate: 0.00132826
	LOSS [training: 0.055427233570560674 | validation: 0.04027078371444123]
	TIME [epoch: 6.56 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04835214169756214		[learning rate: 0.0013251]
	Learning Rate: 0.00132512
	LOSS [training: 0.04835214169756214 | validation: 0.04529738446665297]
	TIME [epoch: 6.56 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07439242609597371		[learning rate: 0.001322]
	Learning Rate: 0.001322
	LOSS [training: 0.07439242609597371 | validation: 0.04059305991601553]
	TIME [epoch: 6.54 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05958224197613156		[learning rate: 0.0013189]
	Learning Rate: 0.00131888
	LOSS [training: 0.05958224197613156 | validation: 0.044829902219121434]
	TIME [epoch: 6.54 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05209694859036486		[learning rate: 0.0013158]
	Learning Rate: 0.00131577
	LOSS [training: 0.05209694859036486 | validation: 0.0349488717175017]
	TIME [epoch: 6.55 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06422134223849191		[learning rate: 0.0013127]
	Learning Rate: 0.00131266
	LOSS [training: 0.06422134223849191 | validation: 0.033718280063523696]
	TIME [epoch: 6.55 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0545905410672299		[learning rate: 0.0013096]
	Learning Rate: 0.00130957
	LOSS [training: 0.0545905410672299 | validation: 0.036829746283519725]
	TIME [epoch: 6.59 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06484887147235127		[learning rate: 0.0013065]
	Learning Rate: 0.00130648
	LOSS [training: 0.06484887147235127 | validation: 0.03759797528557042]
	TIME [epoch: 6.55 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05027345031517745		[learning rate: 0.0013034]
	Learning Rate: 0.0013034
	LOSS [training: 0.05027345031517745 | validation: 0.04003243329771303]
	TIME [epoch: 6.55 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05551720439647338		[learning rate: 0.0013003]
	Learning Rate: 0.00130032
	LOSS [training: 0.05551720439647338 | validation: 0.04494844235604669]
	TIME [epoch: 6.55 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05881636670173092		[learning rate: 0.0012973]
	Learning Rate: 0.00129726
	LOSS [training: 0.05881636670173092 | validation: 0.05262939600157686]
	TIME [epoch: 6.54 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05229281698539018		[learning rate: 0.0012942]
	Learning Rate: 0.0012942
	LOSS [training: 0.05229281698539018 | validation: 0.04969896711169132]
	TIME [epoch: 6.58 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053736243588655266		[learning rate: 0.0012911]
	Learning Rate: 0.00129114
	LOSS [training: 0.053736243588655266 | validation: 0.0432368750292086]
	TIME [epoch: 6.55 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05109667664183345		[learning rate: 0.0012881]
	Learning Rate: 0.0012881
	LOSS [training: 0.05109667664183345 | validation: 0.04593165138820526]
	TIME [epoch: 6.55 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055403296644049735		[learning rate: 0.0012851]
	Learning Rate: 0.00128506
	LOSS [training: 0.055403296644049735 | validation: 0.04025506147159253]
	TIME [epoch: 6.54 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0557835781791407		[learning rate: 0.001282]
	Learning Rate: 0.00128203
	LOSS [training: 0.0557835781791407 | validation: 0.0422207556417121]
	TIME [epoch: 6.55 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05644681119372338		[learning rate: 0.001279]
	Learning Rate: 0.001279
	LOSS [training: 0.05644681119372338 | validation: 0.04477960928723215]
	TIME [epoch: 6.58 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05428283351264257		[learning rate: 0.001276]
	Learning Rate: 0.00127599
	LOSS [training: 0.05428283351264257 | validation: 0.03672062689515407]
	TIME [epoch: 6.56 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04509082403901136		[learning rate: 0.001273]
	Learning Rate: 0.00127298
	LOSS [training: 0.04509082403901136 | validation: 0.0330846225105563]
	TIME [epoch: 6.56 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04934988998974257		[learning rate: 0.00127]
	Learning Rate: 0.00126997
	LOSS [training: 0.04934988998974257 | validation: 0.04172262282619155]
	TIME [epoch: 6.55 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054066776979244335		[learning rate: 0.001267]
	Learning Rate: 0.00126698
	LOSS [training: 0.054066776979244335 | validation: 0.03706579352021468]
	TIME [epoch: 6.55 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05718430585625993		[learning rate: 0.001264]
	Learning Rate: 0.00126399
	LOSS [training: 0.05718430585625993 | validation: 0.025088482830076045]
	TIME [epoch: 6.57 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04916565113927055		[learning rate: 0.001261]
	Learning Rate: 0.00126101
	LOSS [training: 0.04916565113927055 | validation: 0.02966402019692229]
	TIME [epoch: 6.56 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04781703915498049		[learning rate: 0.001258]
	Learning Rate: 0.00125803
	LOSS [training: 0.04781703915498049 | validation: 0.03385862787869933]
	TIME [epoch: 6.54 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04686639549172415		[learning rate: 0.0012551]
	Learning Rate: 0.00125507
	LOSS [training: 0.04686639549172415 | validation: 0.04660675769826448]
	TIME [epoch: 6.55 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.047321527670349674		[learning rate: 0.0012521]
	Learning Rate: 0.00125211
	LOSS [training: 0.047321527670349674 | validation: 0.02853066658598217]
	TIME [epoch: 6.55 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.045758728064050264		[learning rate: 0.0012492]
	Learning Rate: 0.00124915
	LOSS [training: 0.045758728064050264 | validation: 0.034603689272316794]
	TIME [epoch: 6.55 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05017695914705265		[learning rate: 0.0012462]
	Learning Rate: 0.00124621
	LOSS [training: 0.05017695914705265 | validation: 0.035884584204977206]
	TIME [epoch: 6.58 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05903448453253326		[learning rate: 0.0012433]
	Learning Rate: 0.00124327
	LOSS [training: 0.05903448453253326 | validation: 0.039194490867280884]
	TIME [epoch: 6.55 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060087015785385126		[learning rate: 0.0012403]
	Learning Rate: 0.00124033
	LOSS [training: 0.060087015785385126 | validation: 0.06481650091446917]
	TIME [epoch: 6.54 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07135302531047563		[learning rate: 0.0012374]
	Learning Rate: 0.00123741
	LOSS [training: 0.07135302531047563 | validation: 0.044985614108071566]
	TIME [epoch: 6.54 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.046709012667661684		[learning rate: 0.0012345]
	Learning Rate: 0.00123449
	LOSS [training: 0.046709012667661684 | validation: 0.039506241891822266]
	TIME [epoch: 6.54 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05427345937109902		[learning rate: 0.0012316]
	Learning Rate: 0.00123158
	LOSS [training: 0.05427345937109902 | validation: 0.036973233794394246]
	TIME [epoch: 6.59 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05088898934688374		[learning rate: 0.0012287]
	Learning Rate: 0.00122867
	LOSS [training: 0.05088898934688374 | validation: 0.0420464288635178]
	TIME [epoch: 6.55 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04737371954881369		[learning rate: 0.0012258]
	Learning Rate: 0.00122577
	LOSS [training: 0.04737371954881369 | validation: 0.04143539344505908]
	TIME [epoch: 6.55 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04338660269477461		[learning rate: 0.0012229]
	Learning Rate: 0.00122288
	LOSS [training: 0.04338660269477461 | validation: 0.048494538501459]
	TIME [epoch: 6.55 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05290300093139272		[learning rate: 0.00122]
	Learning Rate: 0.00122
	LOSS [training: 0.05290300093139272 | validation: 0.05735953020765881]
	TIME [epoch: 6.55 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05668865572069807		[learning rate: 0.0012171]
	Learning Rate: 0.00121712
	LOSS [training: 0.05668865572069807 | validation: 0.030183620261603688]
	TIME [epoch: 6.59 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05398975525343015		[learning rate: 0.0012142]
	Learning Rate: 0.00121425
	LOSS [training: 0.05398975525343015 | validation: 0.05015218501960017]
	TIME [epoch: 6.56 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07310173860212496		[learning rate: 0.0012114]
	Learning Rate: 0.00121138
	LOSS [training: 0.07310173860212496 | validation: 0.06154174665382855]
	TIME [epoch: 6.55 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05849021866855063		[learning rate: 0.0012085]
	Learning Rate: 0.00120853
	LOSS [training: 0.05849021866855063 | validation: 0.04607647099093273]
	TIME [epoch: 6.55 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05248777875371831		[learning rate: 0.0012057]
	Learning Rate: 0.00120568
	LOSS [training: 0.05248777875371831 | validation: 0.04409629598489631]
	TIME [epoch: 6.55 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05288142845887252		[learning rate: 0.0012028]
	Learning Rate: 0.00120283
	LOSS [training: 0.05288142845887252 | validation: 0.03636032675239579]
	TIME [epoch: 6.56 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05285471512781646		[learning rate: 0.0012]
	Learning Rate: 0.0012
	LOSS [training: 0.05285471512781646 | validation: 0.034445914670083864]
	TIME [epoch: 6.58 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04298808089956392		[learning rate: 0.0011972]
	Learning Rate: 0.00119716
	LOSS [training: 0.04298808089956392 | validation: 0.05583276457674159]
	TIME [epoch: 6.55 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053906186471894525		[learning rate: 0.0011943]
	Learning Rate: 0.00119434
	LOSS [training: 0.053906186471894525 | validation: 0.032751044192028504]
	TIME [epoch: 6.54 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05670281244167448		[learning rate: 0.0011915]
	Learning Rate: 0.00119152
	LOSS [training: 0.05670281244167448 | validation: 0.037990986406135865]
	TIME [epoch: 6.55 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050236328626391866		[learning rate: 0.0011887]
	Learning Rate: 0.00118871
	LOSS [training: 0.050236328626391866 | validation: 0.05043415954486887]
	TIME [epoch: 6.55 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04805519053317426		[learning rate: 0.0011859]
	Learning Rate: 0.00118591
	LOSS [training: 0.04805519053317426 | validation: 0.035229537500429994]
	TIME [epoch: 6.58 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0727657874281366		[learning rate: 0.0011831]
	Learning Rate: 0.00118311
	LOSS [training: 0.0727657874281366 | validation: 0.039134543112590986]
	TIME [epoch: 6.55 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04690645778445924		[learning rate: 0.0011803]
	Learning Rate: 0.00118032
	LOSS [training: 0.04690645778445924 | validation: 0.04086173281450891]
	TIME [epoch: 6.54 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041232527544317575		[learning rate: 0.0011775]
	Learning Rate: 0.00117754
	LOSS [training: 0.041232527544317575 | validation: 0.037393190511861935]
	TIME [epoch: 6.54 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.049367399963461636		[learning rate: 0.0011748]
	Learning Rate: 0.00117476
	LOSS [training: 0.049367399963461636 | validation: 0.03687783004179444]
	TIME [epoch: 6.54 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04035465361669828		[learning rate: 0.001172]
	Learning Rate: 0.00117199
	LOSS [training: 0.04035465361669828 | validation: 0.03288543423483956]
	TIME [epoch: 6.59 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.043122646896439035		[learning rate: 0.0011692]
	Learning Rate: 0.00116922
	LOSS [training: 0.043122646896439035 | validation: 0.04789087527392101]
	TIME [epoch: 6.55 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0454438298093809		[learning rate: 0.0011665]
	Learning Rate: 0.00116646
	LOSS [training: 0.0454438298093809 | validation: 0.0227497265623788]
	TIME [epoch: 6.54 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0488527142029037		[learning rate: 0.0011637]
	Learning Rate: 0.00116371
	LOSS [training: 0.0488527142029037 | validation: 0.051750751809262335]
	TIME [epoch: 6.54 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053252228949335734		[learning rate: 0.001161]
	Learning Rate: 0.00116097
	LOSS [training: 0.053252228949335734 | validation: 0.02717950874544447]
	TIME [epoch: 6.54 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0433046955844298		[learning rate: 0.0011582]
	Learning Rate: 0.00115823
	LOSS [training: 0.0433046955844298 | validation: 0.02590550084558852]
	TIME [epoch: 6.58 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04549061634106231		[learning rate: 0.0011555]
	Learning Rate: 0.0011555
	LOSS [training: 0.04549061634106231 | validation: 0.04881848199097891]
	TIME [epoch: 6.56 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050694251880965734		[learning rate: 0.0011528]
	Learning Rate: 0.00115277
	LOSS [training: 0.050694251880965734 | validation: 0.040470212757612]
	TIME [epoch: 6.55 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04471361953665795		[learning rate: 0.0011501]
	Learning Rate: 0.00115005
	LOSS [training: 0.04471361953665795 | validation: 0.025959032035302806]
	TIME [epoch: 6.54 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04732538746131175		[learning rate: 0.0011473]
	Learning Rate: 0.00114734
	LOSS [training: 0.04732538746131175 | validation: 0.03530752993650429]
	TIME [epoch: 6.54 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04396419459238228		[learning rate: 0.0011446]
	Learning Rate: 0.00114463
	LOSS [training: 0.04396419459238228 | validation: 0.03386094571214829]
	TIME [epoch: 6.55 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03817878064150804		[learning rate: 0.0011419]
	Learning Rate: 0.00114193
	LOSS [training: 0.03817878064150804 | validation: 0.019333784450071726]
	TIME [epoch: 6.57 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041765866859339904		[learning rate: 0.0011392]
	Learning Rate: 0.00113924
	LOSS [training: 0.041765866859339904 | validation: 0.03597356075123242]
	TIME [epoch: 6.54 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042662012658424994		[learning rate: 0.0011366]
	Learning Rate: 0.00113655
	LOSS [training: 0.042662012658424994 | validation: 0.03348184233952128]
	TIME [epoch: 6.54 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054779632122887924		[learning rate: 0.0011339]
	Learning Rate: 0.00113387
	LOSS [training: 0.054779632122887924 | validation: 0.036351240622672684]
	TIME [epoch: 6.55 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.051351158089650184		[learning rate: 0.0011312]
	Learning Rate: 0.0011312
	LOSS [training: 0.051351158089650184 | validation: 0.03974170700862501]
	TIME [epoch: 6.55 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0370599904800024		[learning rate: 0.0011285]
	Learning Rate: 0.00112853
	LOSS [training: 0.0370599904800024 | validation: 0.02973744952945035]
	TIME [epoch: 6.59 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037132465624780744		[learning rate: 0.0011259]
	Learning Rate: 0.00112587
	LOSS [training: 0.037132465624780744 | validation: 0.02771145771264529]
	TIME [epoch: 6.54 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04626141938644049		[learning rate: 0.0011232]
	Learning Rate: 0.00112321
	LOSS [training: 0.04626141938644049 | validation: 0.03440485889901762]
	TIME [epoch: 6.54 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05046401223503031		[learning rate: 0.0011206]
	Learning Rate: 0.00112056
	LOSS [training: 0.05046401223503031 | validation: 0.054144952183245276]
	TIME [epoch: 6.54 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06036365166054634		[learning rate: 0.0011179]
	Learning Rate: 0.00111792
	LOSS [training: 0.06036365166054634 | validation: 0.03834974201504875]
	TIME [epoch: 6.54 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04627282690584644		[learning rate: 0.0011153]
	Learning Rate: 0.00111528
	LOSS [training: 0.04627282690584644 | validation: 0.033169356478199054]
	TIME [epoch: 6.59 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04581531448514724		[learning rate: 0.0011127]
	Learning Rate: 0.00111265
	LOSS [training: 0.04581531448514724 | validation: 0.027105574745826762]
	TIME [epoch: 6.56 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03543416916827662		[learning rate: 0.00111]
	Learning Rate: 0.00111003
	LOSS [training: 0.03543416916827662 | validation: 0.030729007236836206]
	TIME [epoch: 6.55 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04255944640549418		[learning rate: 0.0011074]
	Learning Rate: 0.00110741
	LOSS [training: 0.04255944640549418 | validation: 0.032616779429874204]
	TIME [epoch: 6.54 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04452944374682908		[learning rate: 0.0011048]
	Learning Rate: 0.0011048
	LOSS [training: 0.04452944374682908 | validation: 0.023396926645248096]
	TIME [epoch: 6.54 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03458999197014673		[learning rate: 0.0011022]
	Learning Rate: 0.00110219
	LOSS [training: 0.03458999197014673 | validation: 0.035400575047135965]
	TIME [epoch: 6.57 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03768224676703039		[learning rate: 0.0010996]
	Learning Rate: 0.00109959
	LOSS [training: 0.03768224676703039 | validation: 0.03743239015847945]
	TIME [epoch: 6.55 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037795826392468035		[learning rate: 0.001097]
	Learning Rate: 0.001097
	LOSS [training: 0.037795826392468035 | validation: 0.0289563787678024]
	TIME [epoch: 6.54 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041277994910452684		[learning rate: 0.0010944]
	Learning Rate: 0.00109441
	LOSS [training: 0.041277994910452684 | validation: 0.03697730039723627]
	TIME [epoch: 6.54 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07001657015289445		[learning rate: 0.0010918]
	Learning Rate: 0.00109183
	LOSS [training: 0.07001657015289445 | validation: 0.045182380150630225]
	TIME [epoch: 6.54 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05613803667344193		[learning rate: 0.0010893]
	Learning Rate: 0.00108925
	LOSS [training: 0.05613803667344193 | validation: 0.0336395038924258]
	TIME [epoch: 6.56 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041727714871001034		[learning rate: 0.0010867]
	Learning Rate: 0.00108668
	LOSS [training: 0.041727714871001034 | validation: 0.0258724997823808]
	TIME [epoch: 6.58 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03649718437577148		[learning rate: 0.0010841]
	Learning Rate: 0.00108412
	LOSS [training: 0.03649718437577148 | validation: 0.019929351394839607]
	TIME [epoch: 6.54 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02874185493720502		[learning rate: 0.0010816]
	Learning Rate: 0.00108156
	LOSS [training: 0.02874185493720502 | validation: 0.02409508563474372]
	TIME [epoch: 6.55 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03386214861432475		[learning rate: 0.001079]
	Learning Rate: 0.00107901
	LOSS [training: 0.03386214861432475 | validation: 0.018275816689740897]
	TIME [epoch: 6.54 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03262719817291359		[learning rate: 0.0010765]
	Learning Rate: 0.00107647
	LOSS [training: 0.03262719817291359 | validation: 0.021442127982810075]
	TIME [epoch: 6.55 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03094531361085524		[learning rate: 0.0010739]
	Learning Rate: 0.00107393
	LOSS [training: 0.03094531361085524 | validation: 0.01924274460777793]
	TIME [epoch: 6.59 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028161694907887606		[learning rate: 0.0010714]
	Learning Rate: 0.00107139
	LOSS [training: 0.028161694907887606 | validation: 0.02730966602814422]
	TIME [epoch: 6.55 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03222236772727827		[learning rate: 0.0010689]
	Learning Rate: 0.00106887
	LOSS [training: 0.03222236772727827 | validation: 0.03008840371336174]
	TIME [epoch: 6.55 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06494985394154527		[learning rate: 0.0010663]
	Learning Rate: 0.00106634
	LOSS [training: 0.06494985394154527 | validation: 0.02618261169262891]
	TIME [epoch: 6.55 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040654535205332715		[learning rate: 0.0010638]
	Learning Rate: 0.00106383
	LOSS [training: 0.040654535205332715 | validation: 0.030719453699964476]
	TIME [epoch: 6.55 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03462328250999781		[learning rate: 0.0010613]
	Learning Rate: 0.00106132
	LOSS [training: 0.03462328250999781 | validation: 0.03114132678113399]
	TIME [epoch: 6.59 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03561638814391396		[learning rate: 0.0010588]
	Learning Rate: 0.00105882
	LOSS [training: 0.03561638814391396 | validation: 0.028964617475637555]
	TIME [epoch: 6.55 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03924091443061435		[learning rate: 0.0010563]
	Learning Rate: 0.00105632
	LOSS [training: 0.03924091443061435 | validation: 0.052422736185446]
	TIME [epoch: 6.55 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05041602969970098		[learning rate: 0.0010538]
	Learning Rate: 0.00105383
	LOSS [training: 0.05041602969970098 | validation: 0.04180018589792238]
	TIME [epoch: 6.54 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0349652213260338		[learning rate: 0.0010513]
	Learning Rate: 0.00105134
	LOSS [training: 0.0349652213260338 | validation: 0.01662229038058067]
	TIME [epoch: 6.54 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_1004.pth
	Model improved!!!
EPOCH 1005/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03168117620454028		[learning rate: 0.0010489]
	Learning Rate: 0.00104886
	LOSS [training: 0.03168117620454028 | validation: 0.020936404212150973]
	TIME [epoch: 6.58 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024760494598849627		[learning rate: 0.0010464]
	Learning Rate: 0.00104639
	LOSS [training: 0.024760494598849627 | validation: 0.02267291120303189]
	TIME [epoch: 6.55 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03477390694054516		[learning rate: 0.0010439]
	Learning Rate: 0.00104392
	LOSS [training: 0.03477390694054516 | validation: 0.011400469130623151]
	TIME [epoch: 6.54 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_1007.pth
	Model improved!!!
EPOCH 1008/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05026767467199874		[learning rate: 0.0010415]
	Learning Rate: 0.00104146
	LOSS [training: 0.05026767467199874 | validation: 0.060132752081759264]
	TIME [epoch: 6.56 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03677702080198907		[learning rate: 0.001039]
	Learning Rate: 0.001039
	LOSS [training: 0.03677702080198907 | validation: 0.024992404058707906]
	TIME [epoch: 6.56 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026087591768332124		[learning rate: 0.0010365]
	Learning Rate: 0.00103655
	LOSS [training: 0.026087591768332124 | validation: 0.02063022212913578]
	TIME [epoch: 6.6 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036985311900391754		[learning rate: 0.0010341]
	Learning Rate: 0.0010341
	LOSS [training: 0.036985311900391754 | validation: 0.01639780398719843]
	TIME [epoch: 6.58 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03146143804135754		[learning rate: 0.0010317]
	Learning Rate: 0.00103166
	LOSS [training: 0.03146143804135754 | validation: 0.030173879267389344]
	TIME [epoch: 6.56 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03764702040040607		[learning rate: 0.0010292]
	Learning Rate: 0.00102923
	LOSS [training: 0.03764702040040607 | validation: 0.015114676270419304]
	TIME [epoch: 6.56 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0398964030578607		[learning rate: 0.0010268]
	Learning Rate: 0.0010268
	LOSS [training: 0.0398964030578607 | validation: 0.036809998076065165]
	TIME [epoch: 6.56 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04246774875791455		[learning rate: 0.0010244]
	Learning Rate: 0.00102438
	LOSS [training: 0.04246774875791455 | validation: 0.02781677508097323]
	TIME [epoch: 6.56 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0551327361103758		[learning rate: 0.001022]
	Learning Rate: 0.00102196
	LOSS [training: 0.0551327361103758 | validation: 0.032310330492318864]
	TIME [epoch: 6.59 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03602852746365928		[learning rate: 0.0010196]
	Learning Rate: 0.00101955
	LOSS [training: 0.03602852746365928 | validation: 0.05520859140721618]
	TIME [epoch: 6.56 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04006265559297571		[learning rate: 0.0010171]
	Learning Rate: 0.00101715
	LOSS [training: 0.04006265559297571 | validation: 0.016518672951235245]
	TIME [epoch: 6.56 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0349027694458281		[learning rate: 0.0010147]
	Learning Rate: 0.00101475
	LOSS [training: 0.0349027694458281 | validation: 0.0337051721891572]
	TIME [epoch: 6.56 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040050665576648194		[learning rate: 0.0010124]
	Learning Rate: 0.00101236
	LOSS [training: 0.040050665576648194 | validation: 0.019624668480338742]
	TIME [epoch: 6.56 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02767468546030809		[learning rate: 0.00101]
	Learning Rate: 0.00100997
	LOSS [training: 0.02767468546030809 | validation: 0.021639608744821674]
	TIME [epoch: 6.6 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027917541339367958		[learning rate: 0.0010076]
	Learning Rate: 0.00100759
	LOSS [training: 0.027917541339367958 | validation: 0.021905693378033317]
	TIME [epoch: 6.56 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03409054824564644		[learning rate: 0.0010052]
	Learning Rate: 0.00100521
	LOSS [training: 0.03409054824564644 | validation: 0.015275587315757774]
	TIME [epoch: 6.56 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030970330140790488		[learning rate: 0.0010028]
	Learning Rate: 0.00100284
	LOSS [training: 0.030970330140790488 | validation: 0.03544208481534209]
	TIME [epoch: 6.56 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.052320456136925084		[learning rate: 0.0010005]
	Learning Rate: 0.00100047
	LOSS [training: 0.052320456136925084 | validation: 0.024816524275717483]
	TIME [epoch: 6.56 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02943306545008307		[learning rate: 0.00099811]
	Learning Rate: 0.000998112
	LOSS [training: 0.02943306545008307 | validation: 0.0173299206532606]
	TIME [epoch: 6.6 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03078426470296311		[learning rate: 0.00099576]
	Learning Rate: 0.000995758
	LOSS [training: 0.03078426470296311 | validation: 0.032615371006363754]
	TIME [epoch: 6.57 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04852395015438605		[learning rate: 0.00099341]
	Learning Rate: 0.000993409
	LOSS [training: 0.04852395015438605 | validation: 0.040716069190234475]
	TIME [epoch: 6.56 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04299652608995301		[learning rate: 0.00099107]
	Learning Rate: 0.000991066
	LOSS [training: 0.04299652608995301 | validation: 0.031110806934951864]
	TIME [epoch: 6.57 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037905853980082546		[learning rate: 0.00098873]
	Learning Rate: 0.000988728
	LOSS [training: 0.037905853980082546 | validation: 0.029340824473464224]
	TIME [epoch: 6.56 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027796969103701403		[learning rate: 0.0009864]
	Learning Rate: 0.000986396
	LOSS [training: 0.027796969103701403 | validation: 0.01376181948450361]
	TIME [epoch: 6.6 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025440532460667558		[learning rate: 0.00098407]
	Learning Rate: 0.000984069
	LOSS [training: 0.025440532460667558 | validation: 0.01645755880329828]
	TIME [epoch: 6.58 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025389969925420624		[learning rate: 0.00098175]
	Learning Rate: 0.000981748
	LOSS [training: 0.025389969925420624 | validation: 0.0367126969713846]
	TIME [epoch: 6.57 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04917658938773716		[learning rate: 0.00097943]
	Learning Rate: 0.000979432
	LOSS [training: 0.04917658938773716 | validation: 0.03037622176664322]
	TIME [epoch: 6.56 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03765933601944642		[learning rate: 0.00097712]
	Learning Rate: 0.000977122
	LOSS [training: 0.03765933601944642 | validation: 0.022671908981942813]
	TIME [epoch: 6.56 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030209296299852036		[learning rate: 0.00097482]
	Learning Rate: 0.000974817
	LOSS [training: 0.030209296299852036 | validation: 0.03309986776827447]
	TIME [epoch: 6.57 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04539604007515682		[learning rate: 0.00097252]
	Learning Rate: 0.000972517
	LOSS [training: 0.04539604007515682 | validation: 0.028994049715548198]
	TIME [epoch: 6.59 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.043322499914926954		[learning rate: 0.00097022]
	Learning Rate: 0.000970224
	LOSS [training: 0.043322499914926954 | validation: 0.0435690155622793]
	TIME [epoch: 6.56 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038482028668709006		[learning rate: 0.00096793]
	Learning Rate: 0.000967935
	LOSS [training: 0.038482028668709006 | validation: 0.02204802749879185]
	TIME [epoch: 6.57 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027262900415309904		[learning rate: 0.00096565]
	Learning Rate: 0.000965652
	LOSS [training: 0.027262900415309904 | validation: 0.027504524579645223]
	TIME [epoch: 6.56 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037635561653739914		[learning rate: 0.00096337]
	Learning Rate: 0.000963374
	LOSS [training: 0.037635561653739914 | validation: 0.02959122309369939]
	TIME [epoch: 6.57 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032884015691943005		[learning rate: 0.0009611]
	Learning Rate: 0.000961101
	LOSS [training: 0.032884015691943005 | validation: 0.03473301902415679]
	TIME [epoch: 6.6 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02964164439465824		[learning rate: 0.00095883]
	Learning Rate: 0.000958834
	LOSS [training: 0.02964164439465824 | validation: 0.017239913374887054]
	TIME [epoch: 6.57 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03998294559374286		[learning rate: 0.00095657]
	Learning Rate: 0.000956572
	LOSS [training: 0.03998294559374286 | validation: 0.025799336777171392]
	TIME [epoch: 6.57 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029749466080863263		[learning rate: 0.00095432]
	Learning Rate: 0.000954316
	LOSS [training: 0.029749466080863263 | validation: 0.026854582927995994]
	TIME [epoch: 6.56 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03830018652150182		[learning rate: 0.00095207]
	Learning Rate: 0.000952065
	LOSS [training: 0.03830018652150182 | validation: 0.02895705942741841]
	TIME [epoch: 6.56 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.045614767192484335		[learning rate: 0.00094982]
	Learning Rate: 0.000949819
	LOSS [training: 0.045614767192484335 | validation: 0.02348248850285027]
	TIME [epoch: 6.61 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03702263672003295		[learning rate: 0.00094758]
	Learning Rate: 0.000947579
	LOSS [training: 0.03702263672003295 | validation: 0.02417420020762728]
	TIME [epoch: 6.57 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028197812196368095		[learning rate: 0.00094534]
	Learning Rate: 0.000945344
	LOSS [training: 0.028197812196368095 | validation: 0.021349118343756433]
	TIME [epoch: 6.56 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03269438305618037		[learning rate: 0.00094311]
	Learning Rate: 0.000943114
	LOSS [training: 0.03269438305618037 | validation: 0.031105514066873306]
	TIME [epoch: 6.57 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028831234043265742		[learning rate: 0.00094089]
	Learning Rate: 0.000940889
	LOSS [training: 0.028831234043265742 | validation: 0.03278986792044389]
	TIME [epoch: 6.57 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035364781956553994		[learning rate: 0.00093867]
	Learning Rate: 0.00093867
	LOSS [training: 0.035364781956553994 | validation: 0.038689725354611605]
	TIME [epoch: 6.6 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04039599830387618		[learning rate: 0.00093646]
	Learning Rate: 0.000936456
	LOSS [training: 0.04039599830387618 | validation: 0.022893518342691918]
	TIME [epoch: 6.58 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029093778006129372		[learning rate: 0.00093425]
	Learning Rate: 0.000934246
	LOSS [training: 0.029093778006129372 | validation: 0.030081046542465618]
	TIME [epoch: 6.56 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026903910857046975		[learning rate: 0.00093204]
	Learning Rate: 0.000932043
	LOSS [training: 0.026903910857046975 | validation: 0.02429841670459685]
	TIME [epoch: 6.56 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041095790651803146		[learning rate: 0.00092984]
	Learning Rate: 0.000929844
	LOSS [training: 0.041095790651803146 | validation: 0.03584731312345617]
	TIME [epoch: 6.56 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035971878176437315		[learning rate: 0.00092765]
	Learning Rate: 0.000927651
	LOSS [training: 0.035971878176437315 | validation: 0.01766690495240552]
	TIME [epoch: 6.58 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029492372274486763		[learning rate: 0.00092546]
	Learning Rate: 0.000925463
	LOSS [training: 0.029492372274486763 | validation: 0.02541257008817953]
	TIME [epoch: 6.59 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037791092159557685		[learning rate: 0.00092328]
	Learning Rate: 0.00092328
	LOSS [training: 0.037791092159557685 | validation: 0.02675078249119694]
	TIME [epoch: 6.57 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0468016899749609		[learning rate: 0.0009211]
	Learning Rate: 0.000921102
	LOSS [training: 0.0468016899749609 | validation: 0.03640867021449086]
	TIME [epoch: 6.57 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036929455392813136		[learning rate: 0.00091893]
	Learning Rate: 0.000918929
	LOSS [training: 0.036929455392813136 | validation: 0.029562486605178687]
	TIME [epoch: 6.56 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03799815124577059		[learning rate: 0.00091676]
	Learning Rate: 0.000916762
	LOSS [training: 0.03799815124577059 | validation: 0.04211131139370651]
	TIME [epoch: 6.57 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.049407091679929446		[learning rate: 0.0009146]
	Learning Rate: 0.000914599
	LOSS [training: 0.049407091679929446 | validation: 0.03506395236916202]
	TIME [epoch: 6.61 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0352038780605411		[learning rate: 0.00091244]
	Learning Rate: 0.000912442
	LOSS [training: 0.0352038780605411 | validation: 0.025834478876198764]
	TIME [epoch: 6.57 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03740599749884952		[learning rate: 0.00091029]
	Learning Rate: 0.000910289
	LOSS [training: 0.03740599749884952 | validation: 0.0294873681473401]
	TIME [epoch: 6.57 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0400491834130456		[learning rate: 0.00090814]
	Learning Rate: 0.000908142
	LOSS [training: 0.0400491834130456 | validation: 0.027478464785538118]
	TIME [epoch: 6.57 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04508337791087075		[learning rate: 0.000906]
	Learning Rate: 0.000906
	LOSS [training: 0.04508337791087075 | validation: 0.04538348006891506]
	TIME [epoch: 6.57 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03981147236101944		[learning rate: 0.00090386]
	Learning Rate: 0.000903863
	LOSS [training: 0.03981147236101944 | validation: 0.017631348140664378]
	TIME [epoch: 6.6 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03084193033883459		[learning rate: 0.00090173]
	Learning Rate: 0.000901731
	LOSS [training: 0.03084193033883459 | validation: 0.027408248015880172]
	TIME [epoch: 6.57 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026294468639351143		[learning rate: 0.0008996]
	Learning Rate: 0.000899604
	LOSS [training: 0.026294468639351143 | validation: 0.010301636874240606]
	TIME [epoch: 6.57 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_1070.pth
	Model improved!!!
EPOCH 1071/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0444155393623047		[learning rate: 0.00089748]
	Learning Rate: 0.000897482
	LOSS [training: 0.0444155393623047 | validation: 0.04408394734350311]
	TIME [epoch: 6.56 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04588112679036729		[learning rate: 0.00089536]
	Learning Rate: 0.000895365
	LOSS [training: 0.04588112679036729 | validation: 0.028537191511862625]
	TIME [epoch: 6.55 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032194947587630335		[learning rate: 0.00089325]
	Learning Rate: 0.000893253
	LOSS [training: 0.032194947587630335 | validation: 0.013808387378924898]
	TIME [epoch: 6.59 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02451360743924083		[learning rate: 0.00089115]
	Learning Rate: 0.000891146
	LOSS [training: 0.02451360743924083 | validation: 0.03246637271987732]
	TIME [epoch: 6.57 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04618018148946921		[learning rate: 0.00088904]
	Learning Rate: 0.000889044
	LOSS [training: 0.04618018148946921 | validation: 0.016533887072001797]
	TIME [epoch: 6.56 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032363027652462795		[learning rate: 0.00088695]
	Learning Rate: 0.000886946
	LOSS [training: 0.032363027652462795 | validation: 0.01752909317324418]
	TIME [epoch: 6.56 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03794647591545559		[learning rate: 0.00088485]
	Learning Rate: 0.000884854
	LOSS [training: 0.03794647591545559 | validation: 0.01190738738905439]
	TIME [epoch: 6.56 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022094985501697355		[learning rate: 0.00088277]
	Learning Rate: 0.000882767
	LOSS [training: 0.022094985501697355 | validation: 0.006322659483358309]
	TIME [epoch: 6.59 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_1078.pth
	Model improved!!!
EPOCH 1079/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025241943168926362		[learning rate: 0.00088068]
	Learning Rate: 0.000880685
	LOSS [training: 0.025241943168926362 | validation: 0.0061011773937608305]
	TIME [epoch: 6.57 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_1079.pth
	Model improved!!!
EPOCH 1080/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018893212440115464		[learning rate: 0.00087861]
	Learning Rate: 0.000878607
	LOSS [training: 0.018893212440115464 | validation: 0.014729476135674723]
	TIME [epoch: 6.55 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022460856264029265		[learning rate: 0.00087653]
	Learning Rate: 0.000876535
	LOSS [training: 0.022460856264029265 | validation: 0.014873031788296848]
	TIME [epoch: 6.55 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03720900144553642		[learning rate: 0.00087447]
	Learning Rate: 0.000874467
	LOSS [training: 0.03720900144553642 | validation: 0.04116840991021989]
	TIME [epoch: 6.55 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058040307985575135		[learning rate: 0.0008724]
	Learning Rate: 0.000872405
	LOSS [training: 0.058040307985575135 | validation: 0.02989942671755556]
	TIME [epoch: 6.58 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03702536635209139		[learning rate: 0.00087035]
	Learning Rate: 0.000870346
	LOSS [training: 0.03702536635209139 | validation: 0.026406143062933193]
	TIME [epoch: 6.57 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03916462129051802		[learning rate: 0.00086829]
	Learning Rate: 0.000868294
	LOSS [training: 0.03916462129051802 | validation: 0.017070776055246654]
	TIME [epoch: 6.55 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0345231036432091		[learning rate: 0.00086625]
	Learning Rate: 0.000866246
	LOSS [training: 0.0345231036432091 | validation: 0.011501759102942991]
	TIME [epoch: 6.54 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.020194998132140173		[learning rate: 0.0008642]
	Learning Rate: 0.000864202
	LOSS [training: 0.020194998132140173 | validation: 0.01829902677571024]
	TIME [epoch: 6.54 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054467978085226666		[learning rate: 0.00086216]
	Learning Rate: 0.000862164
	LOSS [training: 0.054467978085226666 | validation: 0.04462017455460746]
	TIME [epoch: 6.56 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05642585844874933		[learning rate: 0.00086013]
	Learning Rate: 0.00086013
	LOSS [training: 0.05642585844874933 | validation: 0.05176228826455058]
	TIME [epoch: 6.58 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041457760064550854		[learning rate: 0.0008581]
	Learning Rate: 0.000858101
	LOSS [training: 0.041457760064550854 | validation: 0.009354406098288429]
	TIME [epoch: 6.56 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04062670863147749		[learning rate: 0.00085608]
	Learning Rate: 0.000856077
	LOSS [training: 0.04062670863147749 | validation: 0.01285565404222085]
	TIME [epoch: 6.55 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021802287143540627		[learning rate: 0.00085406]
	Learning Rate: 0.000854058
	LOSS [training: 0.021802287143540627 | validation: 0.027897070989310175]
	TIME [epoch: 6.55 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042821664287110775		[learning rate: 0.00085204]
	Learning Rate: 0.000852043
	LOSS [training: 0.042821664287110775 | validation: 0.048907189319258165]
	TIME [epoch: 6.57 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04786460083412477		[learning rate: 0.00085003]
	Learning Rate: 0.000850033
	LOSS [training: 0.04786460083412477 | validation: 0.016592673804366923]
	TIME [epoch: 6.61 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02997844046794531		[learning rate: 0.00084803]
	Learning Rate: 0.000848028
	LOSS [training: 0.02997844046794531 | validation: 0.015013738292184364]
	TIME [epoch: 6.57 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0201330755341216		[learning rate: 0.00084603]
	Learning Rate: 0.000846028
	LOSS [training: 0.0201330755341216 | validation: 0.013410227744480066]
	TIME [epoch: 6.57 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0215739253844273		[learning rate: 0.00084403]
	Learning Rate: 0.000844032
	LOSS [training: 0.0215739253844273 | validation: 0.019155911766387146]
	TIME [epoch: 6.56 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024690932277468394		[learning rate: 0.00084204]
	Learning Rate: 0.000842041
	LOSS [training: 0.024690932277468394 | validation: 0.016870849416904712]
	TIME [epoch: 6.57 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023443955968750922		[learning rate: 0.00084005]
	Learning Rate: 0.000840055
	LOSS [training: 0.023443955968750922 | validation: 0.006426258251800254]
	TIME [epoch: 6.61 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02702260523032593		[learning rate: 0.00083807]
	Learning Rate: 0.000838073
	LOSS [training: 0.02702260523032593 | validation: 0.02082958516148609]
	TIME [epoch: 6.58 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025558599106589967		[learning rate: 0.0008361]
	Learning Rate: 0.000836096
	LOSS [training: 0.025558599106589967 | validation: 0.012715642396702781]
	TIME [epoch: 6.56 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02089926410799707		[learning rate: 0.00083412]
	Learning Rate: 0.000834124
	LOSS [training: 0.02089926410799707 | validation: 0.018337900993906864]
	TIME [epoch: 6.56 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027120903883825643		[learning rate: 0.00083216]
	Learning Rate: 0.000832157
	LOSS [training: 0.027120903883825643 | validation: 0.02866647356913645]
	TIME [epoch: 6.56 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039510753082559476		[learning rate: 0.00083019]
	Learning Rate: 0.000830194
	LOSS [training: 0.039510753082559476 | validation: 0.030113726671219365]
	TIME [epoch: 6.6 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03224354900439974		[learning rate: 0.00082824]
	Learning Rate: 0.000828236
	LOSS [training: 0.03224354900439974 | validation: 0.015566811572580988]
	TIME [epoch: 6.57 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021031554642897497		[learning rate: 0.00082628]
	Learning Rate: 0.000826282
	LOSS [training: 0.021031554642897497 | validation: 0.015019217366565963]
	TIME [epoch: 6.56 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031753986294681916		[learning rate: 0.00082433]
	Learning Rate: 0.000824333
	LOSS [training: 0.031753986294681916 | validation: 0.020142533856261507]
	TIME [epoch: 6.56 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029192080182752895		[learning rate: 0.00082239]
	Learning Rate: 0.000822388
	LOSS [training: 0.029192080182752895 | validation: 0.015437203134702992]
	TIME [epoch: 6.56 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02212620492034031		[learning rate: 0.00082045]
	Learning Rate: 0.000820448
	LOSS [training: 0.02212620492034031 | validation: 0.011733892770566627]
	TIME [epoch: 6.58 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033734293551271534		[learning rate: 0.00081851]
	Learning Rate: 0.000818513
	LOSS [training: 0.033734293551271534 | validation: 0.026629835586827275]
	TIME [epoch: 6.59 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039896373612574185		[learning rate: 0.00081658]
	Learning Rate: 0.000816582
	LOSS [training: 0.039896373612574185 | validation: 0.012445495100008804]
	TIME [epoch: 6.57 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021497196574245137		[learning rate: 0.00081466]
	Learning Rate: 0.000814656
	LOSS [training: 0.021497196574245137 | validation: 0.027885225763538156]
	TIME [epoch: 6.58 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05062879469719204		[learning rate: 0.00081273]
	Learning Rate: 0.000812734
	LOSS [training: 0.05062879469719204 | validation: 0.030670463697202534]
	TIME [epoch: 6.58 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06360751695529734		[learning rate: 0.00081082]
	Learning Rate: 0.000810817
	LOSS [training: 0.06360751695529734 | validation: 0.030507297327672246]
	TIME [epoch: 6.58 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03691070075353099		[learning rate: 0.0008089]
	Learning Rate: 0.000808905
	LOSS [training: 0.03691070075353099 | validation: 0.00909190005449678]
	TIME [epoch: 6.61 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024095037744556635		[learning rate: 0.000807]
	Learning Rate: 0.000806997
	LOSS [training: 0.024095037744556635 | validation: 0.017816029201857694]
	TIME [epoch: 6.57 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02126774099844174		[learning rate: 0.00080509]
	Learning Rate: 0.000805093
	LOSS [training: 0.02126774099844174 | validation: 0.022449649773237247]
	TIME [epoch: 6.56 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026567456379650356		[learning rate: 0.00080319]
	Learning Rate: 0.000803194
	LOSS [training: 0.026567456379650356 | validation: 0.011018662277741611]
	TIME [epoch: 6.57 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0394899982656447		[learning rate: 0.0008013]
	Learning Rate: 0.000801299
	LOSS [training: 0.0394899982656447 | validation: 0.03480683395312087]
	TIME [epoch: 6.57 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04740474673502356		[learning rate: 0.00079941]
	Learning Rate: 0.000799409
	LOSS [training: 0.04740474673502356 | validation: 0.026499644083704997]
	TIME [epoch: 6.61 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03864357337891838		[learning rate: 0.00079752]
	Learning Rate: 0.000797524
	LOSS [training: 0.03864357337891838 | validation: 0.025598811778181362]
	TIME [epoch: 6.57 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03582009371894153		[learning rate: 0.00079564]
	Learning Rate: 0.000795642
	LOSS [training: 0.03582009371894153 | validation: 0.029386761095281655]
	TIME [epoch: 6.57 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027837478395364195		[learning rate: 0.00079377]
	Learning Rate: 0.000793766
	LOSS [training: 0.027837478395364195 | validation: 0.01735895109906877]
	TIME [epoch: 6.57 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03430193117006124		[learning rate: 0.00079189]
	Learning Rate: 0.000791893
	LOSS [training: 0.03430193117006124 | validation: 0.032767306579406484]
	TIME [epoch: 6.56 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03019538484961507		[learning rate: 0.00079003]
	Learning Rate: 0.000790025
	LOSS [training: 0.03019538484961507 | validation: 0.012069631752355965]
	TIME [epoch: 6.59 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026082273114383638		[learning rate: 0.00078816]
	Learning Rate: 0.000788162
	LOSS [training: 0.026082273114383638 | validation: 0.015089457805412433]
	TIME [epoch: 6.58 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03601491320587548		[learning rate: 0.0007863]
	Learning Rate: 0.000786302
	LOSS [training: 0.03601491320587548 | validation: 0.032602728617312074]
	TIME [epoch: 6.56 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04701199330468865		[learning rate: 0.00078445]
	Learning Rate: 0.000784448
	LOSS [training: 0.04701199330468865 | validation: 0.019445190182986623]
	TIME [epoch: 6.56 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022991074640200563		[learning rate: 0.0007826]
	Learning Rate: 0.000782598
	LOSS [training: 0.022991074640200563 | validation: 0.011258841776332866]
	TIME [epoch: 6.56 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0304808041095355		[learning rate: 0.00078075]
	Learning Rate: 0.000780751
	LOSS [training: 0.0304808041095355 | validation: 0.03053339163673098]
	TIME [epoch: 6.57 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042273811192594005		[learning rate: 0.00077891]
	Learning Rate: 0.00077891
	LOSS [training: 0.042273811192594005 | validation: 0.02607595282417819]
	TIME [epoch: 6.6 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035629716908698414		[learning rate: 0.00077707]
	Learning Rate: 0.000777073
	LOSS [training: 0.035629716908698414 | validation: 0.026583365801338164]
	TIME [epoch: 6.56 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04498834918615881		[learning rate: 0.00077524]
	Learning Rate: 0.000775239
	LOSS [training: 0.04498834918615881 | validation: 0.015031633337619981]
	TIME [epoch: 6.57 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019979678601372963		[learning rate: 0.00077341]
	Learning Rate: 0.000773411
	LOSS [training: 0.019979678601372963 | validation: 0.014687194988205948]
	TIME [epoch: 6.56 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024089684918506205		[learning rate: 0.00077159]
	Learning Rate: 0.000771586
	LOSS [training: 0.024089684918506205 | validation: 0.02114961678474476]
	TIME [epoch: 6.57 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03251964738716906		[learning rate: 0.00076977]
	Learning Rate: 0.000769766
	LOSS [training: 0.03251964738716906 | validation: 0.019643539950096267]
	TIME [epoch: 6.61 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040908800521794526		[learning rate: 0.00076795]
	Learning Rate: 0.000767951
	LOSS [training: 0.040908800521794526 | validation: 0.037560598377126046]
	TIME [epoch: 6.57 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05297228037098871		[learning rate: 0.00076614]
	Learning Rate: 0.000766139
	LOSS [training: 0.05297228037098871 | validation: 0.023107545981752572]
	TIME [epoch: 6.57 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03952059006563952		[learning rate: 0.00076433]
	Learning Rate: 0.000764332
	LOSS [training: 0.03952059006563952 | validation: 0.014838088243457736]
	TIME [epoch: 6.55 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02831656198481024		[learning rate: 0.00076253]
	Learning Rate: 0.000762529
	LOSS [training: 0.02831656198481024 | validation: 0.020612853848797297]
	TIME [epoch: 6.56 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023827493004159997		[learning rate: 0.00076073]
	Learning Rate: 0.00076073
	LOSS [training: 0.023827493004159997 | validation: 0.009452000132555385]
	TIME [epoch: 6.6 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021323607556857603		[learning rate: 0.00075894]
	Learning Rate: 0.000758936
	LOSS [training: 0.021323607556857603 | validation: 0.012716412086328056]
	TIME [epoch: 6.57 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0242471336191284		[learning rate: 0.00075715]
	Learning Rate: 0.000757146
	LOSS [training: 0.0242471336191284 | validation: 0.020032775769383306]
	TIME [epoch: 6.56 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02512844466817732		[learning rate: 0.00075536]
	Learning Rate: 0.00075536
	LOSS [training: 0.02512844466817732 | validation: 0.027027719233974932]
	TIME [epoch: 6.56 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023876039039150056		[learning rate: 0.00075358]
	Learning Rate: 0.000753578
	LOSS [training: 0.023876039039150056 | validation: 0.010395134353998255]
	TIME [epoch: 6.55 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026092515533584715		[learning rate: 0.0007518]
	Learning Rate: 0.0007518
	LOSS [training: 0.026092515533584715 | validation: 0.021953282716083565]
	TIME [epoch: 6.6 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025435971868083336		[learning rate: 0.00075003]
	Learning Rate: 0.000750027
	LOSS [training: 0.025435971868083336 | validation: 0.021956279970182853]
	TIME [epoch: 6.57 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024884373078517118		[learning rate: 0.00074826]
	Learning Rate: 0.000748258
	LOSS [training: 0.024884373078517118 | validation: 0.012792518027922794]
	TIME [epoch: 6.56 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03499431835414275		[learning rate: 0.00074649]
	Learning Rate: 0.000746493
	LOSS [training: 0.03499431835414275 | validation: 0.047107384447259475]
	TIME [epoch: 6.55 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05431379180767568		[learning rate: 0.00074473]
	Learning Rate: 0.000744732
	LOSS [training: 0.05431379180767568 | validation: 0.015122544977487972]
	TIME [epoch: 6.55 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03998054095949126		[learning rate: 0.00074298]
	Learning Rate: 0.000742975
	LOSS [training: 0.03998054095949126 | validation: 0.05069196647648821]
	TIME [epoch: 6.57 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05676183854274558		[learning rate: 0.00074122]
	Learning Rate: 0.000741223
	LOSS [training: 0.05676183854274558 | validation: 0.04278090909126871]
	TIME [epoch: 6.59 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054167795777297155		[learning rate: 0.00073947]
	Learning Rate: 0.000739474
	LOSS [training: 0.054167795777297155 | validation: 0.03170626815876264]
	TIME [epoch: 6.56 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03219646512634735		[learning rate: 0.00073773]
	Learning Rate: 0.00073773
	LOSS [training: 0.03219646512634735 | validation: 0.026775178905610708]
	TIME [epoch: 6.56 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033856587256156936		[learning rate: 0.00073599]
	Learning Rate: 0.00073599
	LOSS [training: 0.033856587256156936 | validation: 0.014357148501907505]
	TIME [epoch: 6.56 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03429848446470589		[learning rate: 0.00073425]
	Learning Rate: 0.000734254
	LOSS [training: 0.03429848446470589 | validation: 0.021104542619232405]
	TIME [epoch: 6.56 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03341540296308192		[learning rate: 0.00073252]
	Learning Rate: 0.000732522
	LOSS [training: 0.03341540296308192 | validation: 0.01472101788603507]
	TIME [epoch: 6.6 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022216359656615052		[learning rate: 0.00073079]
	Learning Rate: 0.000730794
	LOSS [training: 0.022216359656615052 | validation: 0.01858603679651622]
	TIME [epoch: 6.56 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028644927289476835		[learning rate: 0.00072907]
	Learning Rate: 0.00072907
	LOSS [training: 0.028644927289476835 | validation: 0.01611446154497507]
	TIME [epoch: 6.56 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030755525102472103		[learning rate: 0.00072735]
	Learning Rate: 0.00072735
	LOSS [training: 0.030755525102472103 | validation: 0.02664018014554722]
	TIME [epoch: 6.56 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04178381996066706		[learning rate: 0.00072563]
	Learning Rate: 0.000725634
	LOSS [training: 0.04178381996066706 | validation: 0.02811847874482438]
	TIME [epoch: 6.56 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02824228552020334		[learning rate: 0.00072392]
	Learning Rate: 0.000723923
	LOSS [training: 0.02824228552020334 | validation: 0.010884568290548177]
	TIME [epoch: 6.6 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021829218881935997		[learning rate: 0.00072222]
	Learning Rate: 0.000722215
	LOSS [training: 0.021829218881935997 | validation: 0.01804430621517943]
	TIME [epoch: 6.56 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023718223792126677		[learning rate: 0.00072051]
	Learning Rate: 0.000720512
	LOSS [training: 0.023718223792126677 | validation: 0.025902531718742346]
	TIME [epoch: 6.56 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028124231925955246		[learning rate: 0.00071881]
	Learning Rate: 0.000718812
	LOSS [training: 0.028124231925955246 | validation: 0.02121986762276631]
	TIME [epoch: 6.56 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03179534739720865		[learning rate: 0.00071712]
	Learning Rate: 0.000717117
	LOSS [training: 0.03179534739720865 | validation: 0.007149710377826172]
	TIME [epoch: 6.55 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02565198621364791		[learning rate: 0.00071542]
	Learning Rate: 0.000715425
	LOSS [training: 0.02565198621364791 | validation: 0.020163271083560398]
	TIME [epoch: 6.6 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05230374869490613		[learning rate: 0.00071374]
	Learning Rate: 0.000713738
	LOSS [training: 0.05230374869490613 | validation: 0.02414567369900348]
	TIME [epoch: 6.58 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04954129414369938		[learning rate: 0.00071205]
	Learning Rate: 0.000712054
	LOSS [training: 0.04954129414369938 | validation: 0.038334675691196404]
	TIME [epoch: 6.57 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05770872809700563		[learning rate: 0.00071037]
	Learning Rate: 0.000710374
	LOSS [training: 0.05770872809700563 | validation: 0.032026495040897676]
	TIME [epoch: 6.57 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06512374341978316		[learning rate: 0.0007087]
	Learning Rate: 0.000708698
	LOSS [training: 0.06512374341978316 | validation: 0.0341425261558404]
	TIME [epoch: 6.56 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0633091985738361		[learning rate: 0.00070703]
	Learning Rate: 0.000707027
	LOSS [training: 0.0633091985738361 | validation: 0.013346228221704162]
	TIME [epoch: 6.59 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03582649869739155		[learning rate: 0.00070536]
	Learning Rate: 0.000705359
	LOSS [training: 0.03582649869739155 | validation: 0.013477399416438239]
	TIME [epoch: 6.58 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02386959268071961		[learning rate: 0.0007037]
	Learning Rate: 0.000703695
	LOSS [training: 0.02386959268071961 | validation: 0.021206094854904645]
	TIME [epoch: 6.56 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02247730142113767		[learning rate: 0.00070204]
	Learning Rate: 0.000702035
	LOSS [training: 0.02247730142113767 | validation: 0.012608302501288927]
	TIME [epoch: 6.56 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024930616892141932		[learning rate: 0.00070038]
	Learning Rate: 0.000700379
	LOSS [training: 0.024930616892141932 | validation: 0.011529569730825367]
	TIME [epoch: 6.56 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024811022669262713		[learning rate: 0.00069873]
	Learning Rate: 0.000698727
	LOSS [training: 0.024811022669262713 | validation: 0.020075329049449663]
	TIME [epoch: 6.57 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030675486663544416		[learning rate: 0.00069708]
	Learning Rate: 0.000697079
	LOSS [training: 0.030675486663544416 | validation: 0.009187962106903898]
	TIME [epoch: 6.6 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025104823554582628		[learning rate: 0.00069543]
	Learning Rate: 0.000695435
	LOSS [training: 0.025104823554582628 | validation: 0.018583811229268464]
	TIME [epoch: 6.56 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03792885507536753		[learning rate: 0.00069379]
	Learning Rate: 0.000693794
	LOSS [training: 0.03792885507536753 | validation: 0.03668165607161616]
	TIME [epoch: 6.56 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04522368521376246		[learning rate: 0.00069216]
	Learning Rate: 0.000692158
	LOSS [training: 0.04522368521376246 | validation: 0.0313254202608811]
	TIME [epoch: 6.56 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040228125224471396		[learning rate: 0.00069053]
	Learning Rate: 0.000690525
	LOSS [training: 0.040228125224471396 | validation: 0.026767640255501046]
	TIME [epoch: 6.56 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028646799058985283		[learning rate: 0.0006889]
	Learning Rate: 0.000688896
	LOSS [training: 0.028646799058985283 | validation: 0.010958887283283654]
	TIME [epoch: 6.6 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019341947610390355		[learning rate: 0.00068727]
	Learning Rate: 0.000687271
	LOSS [training: 0.019341947610390355 | validation: 0.012575834893248278]
	TIME [epoch: 6.57 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02473771198870131		[learning rate: 0.00068565]
	Learning Rate: 0.00068565
	LOSS [training: 0.02473771198870131 | validation: 0.03538867884142133]
	TIME [epoch: 6.56 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03608153113659127		[learning rate: 0.00068403]
	Learning Rate: 0.000684033
	LOSS [training: 0.03608153113659127 | validation: 0.00734948191356405]
	TIME [epoch: 6.56 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019178808728170352		[learning rate: 0.00068242]
	Learning Rate: 0.000682419
	LOSS [training: 0.019178808728170352 | validation: 0.012729181660493551]
	TIME [epoch: 6.55 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018126978102338744		[learning rate: 0.00068081]
	Learning Rate: 0.00068081
	LOSS [training: 0.018126978102338744 | validation: 0.017509413881153013]
	TIME [epoch: 6.59 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022438008006688208		[learning rate: 0.0006792]
	Learning Rate: 0.000679204
	LOSS [training: 0.022438008006688208 | validation: 0.001284143600203103]
	TIME [epoch: 6.56 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_1189.pth
	Model improved!!!
EPOCH 1190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030097145455894127		[learning rate: 0.0006776]
	Learning Rate: 0.000677601
	LOSS [training: 0.030097145455894127 | validation: 0.013377682296330077]
	TIME [epoch: 6.55 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023506887822814605		[learning rate: 0.000676]
	Learning Rate: 0.000676003
	LOSS [training: 0.023506887822814605 | validation: 0.017274604425869915]
	TIME [epoch: 6.54 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021794459531087024		[learning rate: 0.00067441]
	Learning Rate: 0.000674409
	LOSS [training: 0.021794459531087024 | validation: 0.013628061940481643]
	TIME [epoch: 6.55 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021893091226753824		[learning rate: 0.00067282]
	Learning Rate: 0.000672818
	LOSS [training: 0.021893091226753824 | validation: 0.009437678279836383]
	TIME [epoch: 6.58 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022925332515579634		[learning rate: 0.00067123]
	Learning Rate: 0.000671231
	LOSS [training: 0.022925332515579634 | validation: 0.016658949176862694]
	TIME [epoch: 6.56 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021678718299158246		[learning rate: 0.00066965]
	Learning Rate: 0.000669647
	LOSS [training: 0.021678718299158246 | validation: 0.013678198176594665]
	TIME [epoch: 6.54 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015718423066794746		[learning rate: 0.00066807]
	Learning Rate: 0.000668068
	LOSS [training: 0.015718423066794746 | validation: 0.012336497146293158]
	TIME [epoch: 6.55 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017566795141617		[learning rate: 0.00066649]
	Learning Rate: 0.000666492
	LOSS [training: 0.017566795141617 | validation: 0.01590132391197415]
	TIME [epoch: 6.55 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0222122592161969		[learning rate: 0.00066492]
	Learning Rate: 0.00066492
	LOSS [training: 0.0222122592161969 | validation: 0.009617010348036022]
	TIME [epoch: 6.56 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01952439428478854		[learning rate: 0.00066335]
	Learning Rate: 0.000663351
	LOSS [training: 0.01952439428478854 | validation: 0.01811952161662209]
	TIME [epoch: 6.58 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0236822695273738		[learning rate: 0.00066179]
	Learning Rate: 0.000661786
	LOSS [training: 0.0236822695273738 | validation: 0.011881870090045713]
	TIME [epoch: 6.54 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031850832410968664		[learning rate: 0.00066023]
	Learning Rate: 0.000660225
	LOSS [training: 0.031850832410968664 | validation: 0.014856419625879188]
	TIME [epoch: 6.54 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019932475399753416		[learning rate: 0.00065867]
	Learning Rate: 0.000658668
	LOSS [training: 0.019932475399753416 | validation: 0.005595294396115566]
	TIME [epoch: 6.54 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01469957384344352		[learning rate: 0.00065711]
	Learning Rate: 0.000657114
	LOSS [training: 0.01469957384344352 | validation: 0.0075296950962932315]
	TIME [epoch: 6.55 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0176716331007923		[learning rate: 0.00065556]
	Learning Rate: 0.000655564
	LOSS [training: 0.0176716331007923 | validation: 0.02010484284635883]
	TIME [epoch: 6.58 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03017858689728037		[learning rate: 0.00065402]
	Learning Rate: 0.000654018
	LOSS [training: 0.03017858689728037 | validation: 0.0156297311324595]
	TIME [epoch: 6.54 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01803464581815578		[learning rate: 0.00065248]
	Learning Rate: 0.000652475
	LOSS [training: 0.01803464581815578 | validation: 0.015374598242988629]
	TIME [epoch: 6.54 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017052921241788137		[learning rate: 0.00065094]
	Learning Rate: 0.000650936
	LOSS [training: 0.017052921241788137 | validation: 0.018255550843709396]
	TIME [epoch: 6.54 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03196012171357897		[learning rate: 0.0006494]
	Learning Rate: 0.000649401
	LOSS [training: 0.03196012171357897 | validation: 0.0228079387199762]
	TIME [epoch: 6.54 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029412384310465927		[learning rate: 0.00064787]
	Learning Rate: 0.000647869
	LOSS [training: 0.029412384310465927 | validation: 0.01871208697416257]
	TIME [epoch: 6.58 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027541042102457086		[learning rate: 0.00064634]
	Learning Rate: 0.000646341
	LOSS [training: 0.027541042102457086 | validation: 0.026028704159273067]
	TIME [epoch: 6.55 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028189550228138304		[learning rate: 0.00064482]
	Learning Rate: 0.000644816
	LOSS [training: 0.028189550228138304 | validation: 0.020499860938743085]
	TIME [epoch: 6.55 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04565734465635255		[learning rate: 0.0006433]
	Learning Rate: 0.000643295
	LOSS [training: 0.04565734465635255 | validation: 0.03610570165758172]
	TIME [epoch: 6.54 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028878365457759327		[learning rate: 0.00064178]
	Learning Rate: 0.000641778
	LOSS [training: 0.028878365457759327 | validation: 0.0092707370317993]
	TIME [epoch: 6.55 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02798697244624248		[learning rate: 0.00064026]
	Learning Rate: 0.000640264
	LOSS [training: 0.02798697244624248 | validation: 0.009614567861464652]
	TIME [epoch: 6.58 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026031191664926644		[learning rate: 0.00063875]
	Learning Rate: 0.000638754
	LOSS [training: 0.026031191664926644 | validation: 0.01968557131966658]
	TIME [epoch: 6.55 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027286781974107825		[learning rate: 0.00063725]
	Learning Rate: 0.000637247
	LOSS [training: 0.027286781974107825 | validation: 0.0364768213054774]
	TIME [epoch: 6.54 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04143094795976835		[learning rate: 0.00063574]
	Learning Rate: 0.000635744
	LOSS [training: 0.04143094795976835 | validation: 0.02994967301622356]
	TIME [epoch: 6.54 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02436325218657933		[learning rate: 0.00063424]
	Learning Rate: 0.000634244
	LOSS [training: 0.02436325218657933 | validation: 0.01692802715615643]
	TIME [epoch: 6.55 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.046860662134238756		[learning rate: 0.00063275]
	Learning Rate: 0.000632748
	LOSS [training: 0.046860662134238756 | validation: 0.03521726699130441]
	TIME [epoch: 6.56 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07701527627223115		[learning rate: 0.00063126]
	Learning Rate: 0.000631255
	LOSS [training: 0.07701527627223115 | validation: 0.05878713925007794]
	TIME [epoch: 6.58 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06908585225750814		[learning rate: 0.00062977]
	Learning Rate: 0.000629766
	LOSS [training: 0.06908585225750814 | validation: 0.02471053079390609]
	TIME [epoch: 6.55 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03387952434707085		[learning rate: 0.00062828]
	Learning Rate: 0.000628281
	LOSS [training: 0.03387952434707085 | validation: 0.004872232749952618]
	TIME [epoch: 6.54 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0275213623294711		[learning rate: 0.0006268]
	Learning Rate: 0.000626799
	LOSS [training: 0.0275213623294711 | validation: 0.03196088513251194]
	TIME [epoch: 6.54 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026797699980858847		[learning rate: 0.00062532]
	Learning Rate: 0.00062532
	LOSS [training: 0.026797699980858847 | validation: 0.02154382693268366]
	TIME [epoch: 6.54 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027298987687438166		[learning rate: 0.00062385]
	Learning Rate: 0.000623845
	LOSS [training: 0.027298987687438166 | validation: 0.011082465564831563]
	TIME [epoch: 6.58 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02280654110142833		[learning rate: 0.00062237]
	Learning Rate: 0.000622374
	LOSS [training: 0.02280654110142833 | validation: 0.003241684501647841]
	TIME [epoch: 6.55 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02057696369711521		[learning rate: 0.00062091]
	Learning Rate: 0.000620906
	LOSS [training: 0.02057696369711521 | validation: 0.016456769443602276]
	TIME [epoch: 6.55 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.020044153620538727		[learning rate: 0.00061944]
	Learning Rate: 0.000619441
	LOSS [training: 0.020044153620538727 | validation: 0.01832985614904677]
	TIME [epoch: 6.55 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026416556755988058		[learning rate: 0.00061798]
	Learning Rate: 0.00061798
	LOSS [training: 0.026416556755988058 | validation: 0.013229674673029743]
	TIME [epoch: 6.54 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02417882072209527		[learning rate: 0.00061652]
	Learning Rate: 0.000616522
	LOSS [training: 0.02417882072209527 | validation: 0.013756914081317895]
	TIME [epoch: 6.58 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023862351889845368		[learning rate: 0.00061507]
	Learning Rate: 0.000615068
	LOSS [training: 0.023862351889845368 | validation: 0.01034598795798794]
	TIME [epoch: 6.55 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021821850760856056		[learning rate: 0.00061362]
	Learning Rate: 0.000613617
	LOSS [training: 0.021821850760856056 | validation: 0.021516070560375883]
	TIME [epoch: 6.54 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024785550591709483		[learning rate: 0.00061217]
	Learning Rate: 0.00061217
	LOSS [training: 0.024785550591709483 | validation: 0.022589962943939418]
	TIME [epoch: 6.54 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021438767357492342		[learning rate: 0.00061073]
	Learning Rate: 0.000610726
	LOSS [training: 0.021438767357492342 | validation: 0.023607947185119632]
	TIME [epoch: 6.54 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023870341558767754		[learning rate: 0.00060929]
	Learning Rate: 0.000609285
	LOSS [training: 0.023870341558767754 | validation: 0.01704612076810299]
	TIME [epoch: 6.58 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01919701985671387		[learning rate: 0.00060785]
	Learning Rate: 0.000607848
	LOSS [training: 0.01919701985671387 | validation: 0.009623717796737348]
	TIME [epoch: 6.56 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012651841835889462		[learning rate: 0.00060641]
	Learning Rate: 0.000606414
	LOSS [training: 0.012651841835889462 | validation: 0.01086363738467467]
	TIME [epoch: 6.54 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02788307600674602		[learning rate: 0.00060498]
	Learning Rate: 0.000604983
	LOSS [training: 0.02788307600674602 | validation: 0.015426840345578143]
	TIME [epoch: 6.54 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01934886872551226		[learning rate: 0.00060356]
	Learning Rate: 0.000603557
	LOSS [training: 0.01934886872551226 | validation: 0.00699169855651518]
	TIME [epoch: 6.54 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03069172745312095		[learning rate: 0.00060213]
	Learning Rate: 0.000602133
	LOSS [training: 0.03069172745312095 | validation: 0.015233098783598943]
	TIME [epoch: 6.56 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023992524291009492		[learning rate: 0.00060071]
	Learning Rate: 0.000600712
	LOSS [training: 0.023992524291009492 | validation: 0.024882190621816107]
	TIME [epoch: 6.58 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026738994290652435		[learning rate: 0.0005993]
	Learning Rate: 0.000599296
	LOSS [training: 0.026738994290652435 | validation: 0.0134247033209903]
	TIME [epoch: 6.55 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03495437210034952		[learning rate: 0.00059788]
	Learning Rate: 0.000597882
	LOSS [training: 0.03495437210034952 | validation: 0.029128051642019443]
	TIME [epoch: 6.54 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02902850000056128		[learning rate: 0.00059647]
	Learning Rate: 0.000596471
	LOSS [training: 0.02902850000056128 | validation: 0.009658094314424716]
	TIME [epoch: 6.54 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02190708146785743		[learning rate: 0.00059506]
	Learning Rate: 0.000595065
	LOSS [training: 0.02190708146785743 | validation: 0.007095276710037923]
	TIME [epoch: 6.55 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02630443226282119		[learning rate: 0.00059366]
	Learning Rate: 0.000593661
	LOSS [training: 0.02630443226282119 | validation: 0.029799561215966268]
	TIME [epoch: 6.58 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022110970342474195		[learning rate: 0.00059226]
	Learning Rate: 0.000592261
	LOSS [training: 0.022110970342474195 | validation: 0.014947433874718]
	TIME [epoch: 6.54 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.020609117961113067		[learning rate: 0.00059086]
	Learning Rate: 0.000590863
	LOSS [training: 0.020609117961113067 | validation: 0.02089280506792854]
	TIME [epoch: 6.54 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0315768246257469		[learning rate: 0.00058947]
	Learning Rate: 0.00058947
	LOSS [training: 0.0315768246257469 | validation: 0.024586887714551496]
	TIME [epoch: 6.54 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02644146587475804		[learning rate: 0.00058808]
	Learning Rate: 0.000588079
	LOSS [training: 0.02644146587475804 | validation: 0.017052942460382546]
	TIME [epoch: 6.54 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02206907803652111		[learning rate: 0.00058669]
	Learning Rate: 0.000586692
	LOSS [training: 0.02206907803652111 | validation: 0.005658796770946322]
	TIME [epoch: 6.58 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016957756296091916		[learning rate: 0.00058531]
	Learning Rate: 0.000585308
	LOSS [training: 0.016957756296091916 | validation: 0.010666953516816121]
	TIME [epoch: 6.55 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01787299865749764		[learning rate: 0.00058393]
	Learning Rate: 0.000583927
	LOSS [training: 0.01787299865749764 | validation: 0.013250097690011467]
	TIME [epoch: 6.54 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02152171194396748		[learning rate: 0.00058255]
	Learning Rate: 0.00058255
	LOSS [training: 0.02152171194396748 | validation: 0.016103399395830345]
	TIME [epoch: 6.54 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024851574338912136		[learning rate: 0.00058118]
	Learning Rate: 0.000581176
	LOSS [training: 0.024851574338912136 | validation: 0.02463480100582048]
	TIME [epoch: 6.54 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0314963321832895		[learning rate: 0.00057981]
	Learning Rate: 0.000579805
	LOSS [training: 0.0314963321832895 | validation: 0.022047383528060918]
	TIME [epoch: 6.57 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02253999568963689		[learning rate: 0.00057844]
	Learning Rate: 0.000578437
	LOSS [training: 0.02253999568963689 | validation: 0.012774101127821388]
	TIME [epoch: 6.55 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022989403856621023		[learning rate: 0.00057707]
	Learning Rate: 0.000577073
	LOSS [training: 0.022989403856621023 | validation: 0.021603142975039773]
	TIME [epoch: 6.54 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015844515209818423		[learning rate: 0.00057571]
	Learning Rate: 0.000575712
	LOSS [training: 0.015844515209818423 | validation: 0.010254563562820696]
	TIME [epoch: 6.54 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021653533637866117		[learning rate: 0.00057435]
	Learning Rate: 0.000574354
	LOSS [training: 0.021653533637866117 | validation: 0.010137718240386978]
	TIME [epoch: 6.54 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01818180321895484		[learning rate: 0.000573]
	Learning Rate: 0.000572999
	LOSS [training: 0.01818180321895484 | validation: 0.010703499078366534]
	TIME [epoch: 6.55 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03910843347946276		[learning rate: 0.00057165]
	Learning Rate: 0.000571647
	LOSS [training: 0.03910843347946276 | validation: 0.012142367024671195]
	TIME [epoch: 6.58 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019437988585558504		[learning rate: 0.0005703]
	Learning Rate: 0.000570299
	LOSS [training: 0.019437988585558504 | validation: 0.015679388952013554]
	TIME [epoch: 6.54 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017182676950138247		[learning rate: 0.00056895]
	Learning Rate: 0.000568954
	LOSS [training: 0.017182676950138247 | validation: 0.012640146719268082]
	TIME [epoch: 6.54 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02143601379341397		[learning rate: 0.00056761]
	Learning Rate: 0.000567612
	LOSS [training: 0.02143601379341397 | validation: 0.009321495513459973]
	TIME [epoch: 6.54 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019384614962823805		[learning rate: 0.00056627]
	Learning Rate: 0.000566273
	LOSS [training: 0.019384614962823805 | validation: 0.004444650395146763]
	TIME [epoch: 6.54 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02879232351573502		[learning rate: 0.00056494]
	Learning Rate: 0.000564937
	LOSS [training: 0.02879232351573502 | validation: 0.018285251806747227]
	TIME [epoch: 6.58 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021567858490357285		[learning rate: 0.0005636]
	Learning Rate: 0.000563604
	LOSS [training: 0.021567858490357285 | validation: 0.009211320775949668]
	TIME [epoch: 6.54 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02695772221340794		[learning rate: 0.00056227]
	Learning Rate: 0.000562275
	LOSS [training: 0.02695772221340794 | validation: 0.029053578493528617]
	TIME [epoch: 6.55 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02474191975464645		[learning rate: 0.00056095]
	Learning Rate: 0.000560949
	LOSS [training: 0.02474191975464645 | validation: 0.012794815755021442]
	TIME [epoch: 6.54 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019937427906028087		[learning rate: 0.00055963]
	Learning Rate: 0.000559625
	LOSS [training: 0.019937427906028087 | validation: 0.01737981477670546]
	TIME [epoch: 6.55 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01630722864809659		[learning rate: 0.00055831]
	Learning Rate: 0.000558305
	LOSS [training: 0.01630722864809659 | validation: 0.009915645593413444]
	TIME [epoch: 6.58 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015967027355968822		[learning rate: 0.00055699]
	Learning Rate: 0.000556988
	LOSS [training: 0.015967027355968822 | validation: 0.005193729166206492]
	TIME [epoch: 6.55 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02040936697438901		[learning rate: 0.00055567]
	Learning Rate: 0.000555674
	LOSS [training: 0.02040936697438901 | validation: 0.0015971452829050894]
	TIME [epoch: 6.54 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01892961694537777		[learning rate: 0.00055436]
	Learning Rate: 0.000554364
	LOSS [training: 0.01892961694537777 | validation: 0.015680128142637934]
	TIME [epoch: 6.54 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041525369922653446		[learning rate: 0.00055306]
	Learning Rate: 0.000553056
	LOSS [training: 0.041525369922653446 | validation: 0.02727481005441533]
	TIME [epoch: 6.54 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027445265116379382		[learning rate: 0.00055175]
	Learning Rate: 0.000551752
	LOSS [training: 0.027445265116379382 | validation: 0.009456970685221172]
	TIME [epoch: 6.57 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019744108553120737		[learning rate: 0.00055045]
	Learning Rate: 0.00055045
	LOSS [training: 0.019744108553120737 | validation: 0.012102805953940572]
	TIME [epoch: 6.56 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028500502835998497		[learning rate: 0.00054915]
	Learning Rate: 0.000549152
	LOSS [training: 0.028500502835998497 | validation: 0.006691099006580268]
	TIME [epoch: 6.55 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0159712487755633		[learning rate: 0.00054786]
	Learning Rate: 0.000547856
	LOSS [training: 0.0159712487755633 | validation: 0.008901292423434137]
	TIME [epoch: 6.54 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03514793058663001		[learning rate: 0.00054656]
	Learning Rate: 0.000546564
	LOSS [training: 0.03514793058663001 | validation: 0.011647139604672197]
	TIME [epoch: 6.54 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02514582599366278		[learning rate: 0.00054527]
	Learning Rate: 0.000545275
	LOSS [training: 0.02514582599366278 | validation: 0.025875803010504492]
	TIME [epoch: 6.55 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03457636713732654		[learning rate: 0.00054399]
	Learning Rate: 0.000543988
	LOSS [training: 0.03457636713732654 | validation: 0.017620153217654345]
	TIME [epoch: 6.57 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029797682379410873		[learning rate: 0.00054271]
	Learning Rate: 0.000542705
	LOSS [training: 0.029797682379410873 | validation: 0.024575727864288282]
	TIME [epoch: 6.54 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028373125604723097		[learning rate: 0.00054143]
	Learning Rate: 0.000541425
	LOSS [training: 0.028373125604723097 | validation: 0.006129817089820956]
	TIME [epoch: 6.54 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031292001232664034		[learning rate: 0.00054015]
	Learning Rate: 0.000540148
	LOSS [training: 0.031292001232664034 | validation: 0.030631138195213445]
	TIME [epoch: 6.54 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0371729064557202		[learning rate: 0.00053887]
	Learning Rate: 0.000538874
	LOSS [training: 0.0371729064557202 | validation: 0.02212201885104563]
	TIME [epoch: 6.54 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033574957347930104		[learning rate: 0.0005376]
	Learning Rate: 0.000537603
	LOSS [training: 0.033574957347930104 | validation: 0.03123931847586048]
	TIME [epoch: 6.58 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05006903895443406		[learning rate: 0.00053633]
	Learning Rate: 0.000536335
	LOSS [training: 0.05006903895443406 | validation: 0.029048539288735447]
	TIME [epoch: 6.55 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034979737723163255		[learning rate: 0.00053507]
	Learning Rate: 0.00053507
	LOSS [training: 0.034979737723163255 | validation: 0.009391546246472059]
	TIME [epoch: 6.54 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021007070867291575		[learning rate: 0.00053381]
	Learning Rate: 0.000533807
	LOSS [training: 0.021007070867291575 | validation: 0.01626577935152382]
	TIME [epoch: 6.54 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019781109662155346		[learning rate: 0.00053255]
	Learning Rate: 0.000532548
	LOSS [training: 0.019781109662155346 | validation: 0.008404866230593666]
	TIME [epoch: 6.55 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02893081358531833		[learning rate: 0.00053129]
	Learning Rate: 0.000531292
	LOSS [training: 0.02893081358531833 | validation: 0.01648005760793973]
	TIME [epoch: 6.57 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.020188196545229204		[learning rate: 0.00053004]
	Learning Rate: 0.000530039
	LOSS [training: 0.020188196545229204 | validation: 0.0003093299045679133]
	TIME [epoch: 6.54 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_1294.pth
	Model improved!!!
EPOCH 1295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022882449498512		[learning rate: 0.00052879]
	Learning Rate: 0.000528789
	LOSS [training: 0.022882449498512 | validation: 0.015621608449581737]
	TIME [epoch: 6.54 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021612860087403526		[learning rate: 0.00052754]
	Learning Rate: 0.000527541
	LOSS [training: 0.021612860087403526 | validation: 0.0015908099921359466]
	TIME [epoch: 6.54 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02172685774812537		[learning rate: 0.0005263]
	Learning Rate: 0.000526297
	LOSS [training: 0.02172685774812537 | validation: -0.0008465809478808255]
	TIME [epoch: 6.54 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_1297.pth
	Model improved!!!
EPOCH 1298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027283768733141332		[learning rate: 0.00052506]
	Learning Rate: 0.000525055
	LOSS [training: 0.027283768733141332 | validation: 0.02431752669361452]
	TIME [epoch: 6.58 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032971334363008344		[learning rate: 0.00052382]
	Learning Rate: 0.000523817
	LOSS [training: 0.032971334363008344 | validation: 0.022845105407814995]
	TIME [epoch: 6.56 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023881102566640958		[learning rate: 0.00052258]
	Learning Rate: 0.000522581
	LOSS [training: 0.023881102566640958 | validation: 0.009108107209470551]
	TIME [epoch: 6.55 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02469708558687067		[learning rate: 0.00052135]
	Learning Rate: 0.000521348
	LOSS [training: 0.02469708558687067 | validation: 0.012367337203460197]
	TIME [epoch: 6.54 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02234396732420791		[learning rate: 0.00052012]
	Learning Rate: 0.000520119
	LOSS [training: 0.02234396732420791 | validation: 0.0216121061798707]
	TIME [epoch: 6.54 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03638152064079925		[learning rate: 0.00051889]
	Learning Rate: 0.000518892
	LOSS [training: 0.03638152064079925 | validation: 0.014272225804552487]
	TIME [epoch: 6.58 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018042173682328855		[learning rate: 0.00051767]
	Learning Rate: 0.000517668
	LOSS [training: 0.018042173682328855 | validation: 0.008790187535226084]
	TIME [epoch: 6.56 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016429881495688893		[learning rate: 0.00051645]
	Learning Rate: 0.000516447
	LOSS [training: 0.016429881495688893 | validation: 0.010710713970117337]
	TIME [epoch: 6.55 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01590332708343082		[learning rate: 0.00051523]
	Learning Rate: 0.000515229
	LOSS [training: 0.01590332708343082 | validation: 0.012998617426504102]
	TIME [epoch: 6.54 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0179120508817026		[learning rate: 0.00051401]
	Learning Rate: 0.000514013
	LOSS [training: 0.0179120508817026 | validation: 0.004777630752157522]
	TIME [epoch: 6.55 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025445207823572086		[learning rate: 0.0005128]
	Learning Rate: 0.000512801
	LOSS [training: 0.025445207823572086 | validation: 0.011217264601396684]
	TIME [epoch: 6.55 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018292157844734973		[learning rate: 0.00051159]
	Learning Rate: 0.000511591
	LOSS [training: 0.018292157844734973 | validation: 0.010590963800300633]
	TIME [epoch: 6.58 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02276122586587407		[learning rate: 0.00051038]
	Learning Rate: 0.000510384
	LOSS [training: 0.02276122586587407 | validation: 0.014369714181153175]
	TIME [epoch: 6.55 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01829794835048083		[learning rate: 0.00050918]
	Learning Rate: 0.00050918
	LOSS [training: 0.01829794835048083 | validation: 0.011834685337618748]
	TIME [epoch: 6.55 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021410423791565568		[learning rate: 0.00050798]
	Learning Rate: 0.000507979
	LOSS [training: 0.021410423791565568 | validation: 0.004656082903246958]
	TIME [epoch: 6.54 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01720002407507248		[learning rate: 0.00050678]
	Learning Rate: 0.000506781
	LOSS [training: 0.01720002407507248 | validation: 0.012374701606682406]
	TIME [epoch: 6.56 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013689415548428752		[learning rate: 0.00050559]
	Learning Rate: 0.000505586
	LOSS [training: 0.013689415548428752 | validation: 0.009528630871438406]
	TIME [epoch: 6.58 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01320408946448925		[learning rate: 0.00050439]
	Learning Rate: 0.000504393
	LOSS [training: 0.01320408946448925 | validation: 0.012410736342044043]
	TIME [epoch: 6.55 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02440507392705002		[learning rate: 0.0005032]
	Learning Rate: 0.000503203
	LOSS [training: 0.02440507392705002 | validation: 0.014563912117799307]
	TIME [epoch: 6.55 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014311063171073463		[learning rate: 0.00050202]
	Learning Rate: 0.000502016
	LOSS [training: 0.014311063171073463 | validation: 0.005584062801170861]
	TIME [epoch: 6.54 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016667689983681736		[learning rate: 0.00050083]
	Learning Rate: 0.000500832
	LOSS [training: 0.016667689983681736 | validation: 0.006592585720984457]
	TIME [epoch: 6.54 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01824450149926195		[learning rate: 0.00049965]
	Learning Rate: 0.000499651
	LOSS [training: 0.01824450149926195 | validation: 0.009625907380097354]
	TIME [epoch: 6.58 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01913602225563574		[learning rate: 0.00049847]
	Learning Rate: 0.000498472
	LOSS [training: 0.01913602225563574 | validation: 0.005917259538654488]
	TIME [epoch: 6.55 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015339021967807407		[learning rate: 0.0004973]
	Learning Rate: 0.000497296
	LOSS [training: 0.015339021967807407 | validation: 0.008088756935085694]
	TIME [epoch: 6.54 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01606364053391666		[learning rate: 0.00049612]
	Learning Rate: 0.000496123
	LOSS [training: 0.01606364053391666 | validation: 0.013587050177310368]
	TIME [epoch: 6.55 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02580056178908935		[learning rate: 0.00049495]
	Learning Rate: 0.000494953
	LOSS [training: 0.02580056178908935 | validation: 0.030043050090898284]
	TIME [epoch: 6.55 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03550455311123107		[learning rate: 0.00049379]
	Learning Rate: 0.000493786
	LOSS [training: 0.03550455311123107 | validation: 0.01431150444202659]
	TIME [epoch: 6.58 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017892127806551677		[learning rate: 0.00049262]
	Learning Rate: 0.000492621
	LOSS [training: 0.017892127806551677 | validation: 0.012006396063385359]
	TIME [epoch: 6.56 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03363484609303195		[learning rate: 0.00049146]
	Learning Rate: 0.000491459
	LOSS [training: 0.03363484609303195 | validation: 0.009309026233039839]
	TIME [epoch: 6.55 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02490594013140121		[learning rate: 0.0004903]
	Learning Rate: 0.0004903
	LOSS [training: 0.02490594013140121 | validation: 0.013312304771191354]
	TIME [epoch: 6.55 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02426812725032263		[learning rate: 0.00048914]
	Learning Rate: 0.000489143
	LOSS [training: 0.02426812725032263 | validation: 0.011867990140838922]
	TIME [epoch: 6.55 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026564040579685626		[learning rate: 0.00048799]
	Learning Rate: 0.000487989
	LOSS [training: 0.026564040579685626 | validation: 0.017163258580028977]
	TIME [epoch: 6.55 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022590467687942747		[learning rate: 0.00048684]
	Learning Rate: 0.000486838
	LOSS [training: 0.022590467687942747 | validation: 0.015410201384392355]
	TIME [epoch: 6.58 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023764232318843302		[learning rate: 0.00048569]
	Learning Rate: 0.00048569
	LOSS [training: 0.023764232318843302 | validation: 0.026014946648131726]
	TIME [epoch: 6.55 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03080349222275377		[learning rate: 0.00048454]
	Learning Rate: 0.000484544
	LOSS [training: 0.03080349222275377 | validation: 0.005907217601775637]
	TIME [epoch: 6.54 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018810087805718675		[learning rate: 0.0004834]
	Learning Rate: 0.000483401
	LOSS [training: 0.018810087805718675 | validation: 0.016083340615097762]
	TIME [epoch: 6.54 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023379074501675774		[learning rate: 0.00048226]
	Learning Rate: 0.000482261
	LOSS [training: 0.023379074501675774 | validation: 0.016053795182500677]
	TIME [epoch: 6.55 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021827144035320083		[learning rate: 0.00048112]
	Learning Rate: 0.000481123
	LOSS [training: 0.021827144035320083 | validation: 0.003940556953181666]
	TIME [epoch: 6.58 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02174216541390726		[learning rate: 0.00047999]
	Learning Rate: 0.000479988
	LOSS [training: 0.02174216541390726 | validation: 0.029699191738385106]
	TIME [epoch: 6.55 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03771371849886525		[learning rate: 0.00047886]
	Learning Rate: 0.000478856
	LOSS [training: 0.03771371849886525 | validation: 0.014419434057897751]
	TIME [epoch: 6.54 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018537329399844517		[learning rate: 0.00047773]
	Learning Rate: 0.000477727
	LOSS [training: 0.018537329399844517 | validation: 0.01062250438478353]
	TIME [epoch: 6.55 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01874513558965807		[learning rate: 0.0004766]
	Learning Rate: 0.0004766
	LOSS [training: 0.01874513558965807 | validation: 0.017024916037469265]
	TIME [epoch: 6.55 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024641764220110385		[learning rate: 0.00047548]
	Learning Rate: 0.000475476
	LOSS [training: 0.024641764220110385 | validation: 0.01936877483143893]
	TIME [epoch: 6.58 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026385228206408616		[learning rate: 0.00047435]
	Learning Rate: 0.000474354
	LOSS [training: 0.026385228206408616 | validation: 0.012109763006338831]
	TIME [epoch: 6.56 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01979675483414145		[learning rate: 0.00047324]
	Learning Rate: 0.000473235
	LOSS [training: 0.01979675483414145 | validation: 0.004634831527511105]
	TIME [epoch: 6.55 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02295573237423775		[learning rate: 0.00047212]
	Learning Rate: 0.000472119
	LOSS [training: 0.02295573237423775 | validation: 0.024015753265181856]
	TIME [epoch: 6.55 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031683375096598826		[learning rate: 0.00047101]
	Learning Rate: 0.000471005
	LOSS [training: 0.031683375096598826 | validation: 0.003822431507216499]
	TIME [epoch: 6.54 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01551814319017827		[learning rate: 0.00046989]
	Learning Rate: 0.000469894
	LOSS [training: 0.01551814319017827 | validation: 0.013066258536971026]
	TIME [epoch: 6.58 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019269620438395644		[learning rate: 0.00046879]
	Learning Rate: 0.000468786
	LOSS [training: 0.019269620438395644 | validation: 0.020981793107478924]
	TIME [epoch: 6.56 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03203368783806328		[learning rate: 0.00046768]
	Learning Rate: 0.00046768
	LOSS [training: 0.03203368783806328 | validation: 0.013750988463811493]
	TIME [epoch: 6.54 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02065415274282701		[learning rate: 0.00046658]
	Learning Rate: 0.000466577
	LOSS [training: 0.02065415274282701 | validation: 0.010823211991891134]
	TIME [epoch: 6.54 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03378023089968522		[learning rate: 0.00046548]
	Learning Rate: 0.000465476
	LOSS [training: 0.03378023089968522 | validation: 0.024880892871708717]
	TIME [epoch: 6.54 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021837814841331342		[learning rate: 0.00046438]
	Learning Rate: 0.000464378
	LOSS [training: 0.021837814841331342 | validation: 0.010169684427225732]
	TIME [epoch: 6.55 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019042107416160248		[learning rate: 0.00046328]
	Learning Rate: 0.000463283
	LOSS [training: 0.019042107416160248 | validation: 0.00909325014908071]
	TIME [epoch: 6.58 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015653391781740307		[learning rate: 0.00046219]
	Learning Rate: 0.00046219
	LOSS [training: 0.015653391781740307 | validation: 0.008844730290119876]
	TIME [epoch: 6.55 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02304061704684795		[learning rate: 0.0004611]
	Learning Rate: 0.0004611
	LOSS [training: 0.02304061704684795 | validation: 0.016725393026187748]
	TIME [epoch: 6.55 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036989476194059914		[learning rate: 0.00046001]
	Learning Rate: 0.000460012
	LOSS [training: 0.036989476194059914 | validation: 0.029071435615375663]
	TIME [epoch: 6.55 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05523677939540479		[learning rate: 0.00045893]
	Learning Rate: 0.000458927
	LOSS [training: 0.05523677939540479 | validation: 0.03941056526525492]
	TIME [epoch: 6.55 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041758179980885116		[learning rate: 0.00045784]
	Learning Rate: 0.000457844
	LOSS [training: 0.041758179980885116 | validation: 0.01989555561076452]
	TIME [epoch: 6.59 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016949926038816697		[learning rate: 0.00045676]
	Learning Rate: 0.000456764
	LOSS [training: 0.016949926038816697 | validation: 0.01435340378653291]
	TIME [epoch: 6.56 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017872791396636962		[learning rate: 0.00045569]
	Learning Rate: 0.000455687
	LOSS [training: 0.017872791396636962 | validation: 0.014789919883150255]
	TIME [epoch: 6.55 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02685783985245569		[learning rate: 0.00045461]
	Learning Rate: 0.000454612
	LOSS [training: 0.02685783985245569 | validation: 0.0068956486454065085]
	TIME [epoch: 6.55 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01965988509812846		[learning rate: 0.00045354]
	Learning Rate: 0.00045354
	LOSS [training: 0.01965988509812846 | validation: 0.019767380643413865]
	TIME [epoch: 6.54 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02539946735463136		[learning rate: 0.00045247]
	Learning Rate: 0.00045247
	LOSS [training: 0.02539946735463136 | validation: 0.01627652593801953]
	TIME [epoch: 6.59 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026092473896518233		[learning rate: 0.0004514]
	Learning Rate: 0.000451403
	LOSS [training: 0.026092473896518233 | validation: 0.00855265659587525]
	TIME [epoch: 6.56 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0205364775463101		[learning rate: 0.00045034]
	Learning Rate: 0.000450338
	LOSS [training: 0.0205364775463101 | validation: 0.0026160248567038222]
	TIME [epoch: 6.55 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02661888314130788		[learning rate: 0.00044928]
	Learning Rate: 0.000449276
	LOSS [training: 0.02661888314130788 | validation: 0.023582684802718343]
	TIME [epoch: 6.54 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0785743285420301		[learning rate: 0.00044822]
	Learning Rate: 0.000448216
	LOSS [training: 0.0785743285420301 | validation: 0.06471325803068301]
	TIME [epoch: 6.55 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0729587008771764		[learning rate: 0.00044716]
	Learning Rate: 0.000447159
	LOSS [training: 0.0729587008771764 | validation: 0.016494827308873413]
	TIME [epoch: 6.58 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023010331164276764		[learning rate: 0.0004461]
	Learning Rate: 0.000446104
	LOSS [training: 0.023010331164276764 | validation: 0.014914503607285405]
	TIME [epoch: 6.56 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018589555374380028		[learning rate: 0.00044505]
	Learning Rate: 0.000445051
	LOSS [training: 0.018589555374380028 | validation: 0.012960564736525314]
	TIME [epoch: 6.55 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0361742758860221		[learning rate: 0.000444]
	Learning Rate: 0.000444002
	LOSS [training: 0.0361742758860221 | validation: 0.017676960574830865]
	TIME [epoch: 6.55 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02712632472716725		[learning rate: 0.00044295]
	Learning Rate: 0.000442954
	LOSS [training: 0.02712632472716725 | validation: 0.010926447909892752]
	TIME [epoch: 6.55 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029406865970718767		[learning rate: 0.00044191]
	Learning Rate: 0.000441909
	LOSS [training: 0.029406865970718767 | validation: 0.01807510880461538]
	TIME [epoch: 6.56 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021494663273834477		[learning rate: 0.00044087]
	Learning Rate: 0.000440867
	LOSS [training: 0.021494663273834477 | validation: 0.013059136286303015]
	TIME [epoch: 6.58 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02114583889219355		[learning rate: 0.00043983]
	Learning Rate: 0.000439827
	LOSS [training: 0.02114583889219355 | validation: -0.0019490847772665743]
	TIME [epoch: 6.54 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_1373.pth
	Model improved!!!
EPOCH 1374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01724379146449151		[learning rate: 0.00043879]
	Learning Rate: 0.00043879
	LOSS [training: 0.01724379146449151 | validation: 0.016931943241011698]
	TIME [epoch: 6.55 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03619577158484961		[learning rate: 0.00043775]
	Learning Rate: 0.000437755
	LOSS [training: 0.03619577158484961 | validation: 0.008496215305775236]
	TIME [epoch: 6.55 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.020035771242970055		[learning rate: 0.00043672]
	Learning Rate: 0.000436722
	LOSS [training: 0.020035771242970055 | validation: 0.013050360134039995]
	TIME [epoch: 6.57 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030432229271800847		[learning rate: 0.00043569]
	Learning Rate: 0.000435692
	LOSS [training: 0.030432229271800847 | validation: 0.01712407342057389]
	TIME [epoch: 6.58 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01893830863002		[learning rate: 0.00043466]
	Learning Rate: 0.000434664
	LOSS [training: 0.01893830863002 | validation: 0.013780559370024018]
	TIME [epoch: 6.55 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03378823362702309		[learning rate: 0.00043364]
	Learning Rate: 0.000433639
	LOSS [training: 0.03378823362702309 | validation: -0.0001174906486965787]
	TIME [epoch: 6.55 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018221044278717867		[learning rate: 0.00043262]
	Learning Rate: 0.000432616
	LOSS [training: 0.018221044278717867 | validation: 0.006017890387036371]
	TIME [epoch: 6.55 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017709035873744637		[learning rate: 0.0004316]
	Learning Rate: 0.000431595
	LOSS [training: 0.017709035873744637 | validation: 0.008776479103175062]
	TIME [epoch: 6.55 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011778101333449083		[learning rate: 0.00043058]
	Learning Rate: 0.000430577
	LOSS [training: 0.011778101333449083 | validation: 0.010469948034906373]
	TIME [epoch: 6.58 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016518189651944338		[learning rate: 0.00042956]
	Learning Rate: 0.000429562
	LOSS [training: 0.016518189651944338 | validation: 0.017213618419962627]
	TIME [epoch: 6.55 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02313577586975647		[learning rate: 0.00042855]
	Learning Rate: 0.000428548
	LOSS [training: 0.02313577586975647 | validation: 0.01129417298300581]
	TIME [epoch: 6.55 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03468874392309146		[learning rate: 0.00042754]
	Learning Rate: 0.000427538
	LOSS [training: 0.03468874392309146 | validation: 0.009865959197273103]
	TIME [epoch: 6.55 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02833669954470691		[learning rate: 0.00042653]
	Learning Rate: 0.000426529
	LOSS [training: 0.02833669954470691 | validation: 0.01669824246248332]
	TIME [epoch: 6.54 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030109253830067954		[learning rate: 0.00042552]
	Learning Rate: 0.000425523
	LOSS [training: 0.030109253830067954 | validation: 0.008588613902969118]
	TIME [epoch: 6.59 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02591833847886647		[learning rate: 0.00042452]
	Learning Rate: 0.000424519
	LOSS [training: 0.02591833847886647 | validation: 0.021674717731679203]
	TIME [epoch: 6.56 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03799559575984297		[learning rate: 0.00042352]
	Learning Rate: 0.000423518
	LOSS [training: 0.03799559575984297 | validation: 0.016420733085932372]
	TIME [epoch: 6.55 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019534955383583665		[learning rate: 0.00042252]
	Learning Rate: 0.000422519
	LOSS [training: 0.019534955383583665 | validation: 0.009145173351446758]
	TIME [epoch: 6.55 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017186693982748268		[learning rate: 0.00042152]
	Learning Rate: 0.000421522
	LOSS [training: 0.017186693982748268 | validation: 0.0007943036095379727]
	TIME [epoch: 6.55 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017654871499524678		[learning rate: 0.00042053]
	Learning Rate: 0.000420528
	LOSS [training: 0.017654871499524678 | validation: 0.017117060102222987]
	TIME [epoch: 6.58 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01679155951767721		[learning rate: 0.00041954]
	Learning Rate: 0.000419536
	LOSS [training: 0.01679155951767721 | validation: 0.007534342373401878]
	TIME [epoch: 6.56 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016604946770938045		[learning rate: 0.00041855]
	Learning Rate: 0.000418546
	LOSS [training: 0.016604946770938045 | validation: 0.007464221763510236]
	TIME [epoch: 6.55 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014385804415475243		[learning rate: 0.00041756]
	Learning Rate: 0.000417559
	LOSS [training: 0.014385804415475243 | validation: 0.0108394759108368]
	TIME [epoch: 6.55 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.020300744890938312		[learning rate: 0.00041657]
	Learning Rate: 0.000416574
	LOSS [training: 0.020300744890938312 | validation: 0.015690706793354693]
	TIME [epoch: 6.55 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017384660536305486		[learning rate: 0.00041559]
	Learning Rate: 0.000415591
	LOSS [training: 0.017384660536305486 | validation: 0.009978314368028464]
	TIME [epoch: 6.56 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02786948871899158		[learning rate: 0.00041461]
	Learning Rate: 0.000414611
	LOSS [training: 0.02786948871899158 | validation: 0.022900071608853333]
	TIME [epoch: 6.57 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026337458500393825		[learning rate: 0.00041363]
	Learning Rate: 0.000413633
	LOSS [training: 0.026337458500393825 | validation: 0.01656499524014184]
	TIME [epoch: 6.55 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0224344874871284		[learning rate: 0.00041266]
	Learning Rate: 0.000412657
	LOSS [training: 0.0224344874871284 | validation: 0.01568475632497924]
	TIME [epoch: 6.55 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01902391378838401		[learning rate: 0.00041168]
	Learning Rate: 0.000411684
	LOSS [training: 0.01902391378838401 | validation: 0.010963229386869382]
	TIME [epoch: 6.54 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01777183810444087		[learning rate: 0.00041071]
	Learning Rate: 0.000410713
	LOSS [training: 0.01777183810444087 | validation: 0.015290259247558034]
	TIME [epoch: 6.55 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012290673690982374		[learning rate: 0.00040974]
	Learning Rate: 0.000409744
	LOSS [training: 0.012290673690982374 | validation: 0.010876568662101849]
	TIME [epoch: 6.58 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017959006809617494		[learning rate: 0.00040878]
	Learning Rate: 0.000408778
	LOSS [training: 0.017959006809617494 | validation: 0.008781031501830138]
	TIME [epoch: 6.55 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012426963795640528		[learning rate: 0.00040781]
	Learning Rate: 0.000407813
	LOSS [training: 0.012426963795640528 | validation: 0.009154284141654541]
	TIME [epoch: 6.55 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030089248607021123		[learning rate: 0.00040685]
	Learning Rate: 0.000406851
	LOSS [training: 0.030089248607021123 | validation: 0.03591280192572364]
	TIME [epoch: 6.55 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03172616824696271		[learning rate: 0.00040589]
	Learning Rate: 0.000405892
	LOSS [training: 0.03172616824696271 | validation: 0.007359979578678472]
	TIME [epoch: 6.55 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023808025161437506		[learning rate: 0.00040493]
	Learning Rate: 0.000404934
	LOSS [training: 0.023808025161437506 | validation: 0.026298752516273668]
	TIME [epoch: 6.59 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02147292675207261		[learning rate: 0.00040398]
	Learning Rate: 0.000403979
	LOSS [training: 0.02147292675207261 | validation: 0.010347142909028582]
	TIME [epoch: 6.56 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021018040362683232		[learning rate: 0.00040303]
	Learning Rate: 0.000403026
	LOSS [training: 0.021018040362683232 | validation: 0.017565011667678175]
	TIME [epoch: 6.55 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02752561902035001		[learning rate: 0.00040208]
	Learning Rate: 0.000402076
	LOSS [training: 0.02752561902035001 | validation: 0.019421522152463663]
	TIME [epoch: 6.55 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017135565923456563		[learning rate: 0.00040113]
	Learning Rate: 0.000401127
	LOSS [training: 0.017135565923456563 | validation: 0.003393532924324559]
	TIME [epoch: 6.55 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016579290064808735		[learning rate: 0.00040018]
	Learning Rate: 0.000400181
	LOSS [training: 0.016579290064808735 | validation: 0.0121985291019015]
	TIME [epoch: 6.58 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019799555393082757		[learning rate: 0.00039924]
	Learning Rate: 0.000399237
	LOSS [training: 0.019799555393082757 | validation: 0.0001730518530812103]
	TIME [epoch: 6.55 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016845812887156676		[learning rate: 0.0003983]
	Learning Rate: 0.000398295
	LOSS [training: 0.016845812887156676 | validation: 0.008107011657471276]
	TIME [epoch: 6.55 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015860036060670234		[learning rate: 0.00039736]
	Learning Rate: 0.000397356
	LOSS [training: 0.015860036060670234 | validation: 0.013985690761311722]
	TIME [epoch: 6.55 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021407983107196965		[learning rate: 0.00039642]
	Learning Rate: 0.000396418
	LOSS [training: 0.021407983107196965 | validation: 0.013084540878254652]
	TIME [epoch: 6.55 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022161759405874386		[learning rate: 0.00039548]
	Learning Rate: 0.000395483
	LOSS [training: 0.022161759405874386 | validation: 0.0047356416137601005]
	TIME [epoch: 6.56 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012789718331463706		[learning rate: 0.00039455]
	Learning Rate: 0.00039455
	LOSS [training: 0.012789718331463706 | validation: 0.00276433560674003]
	TIME [epoch: 6.58 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018279540700594937		[learning rate: 0.00039362]
	Learning Rate: 0.00039362
	LOSS [training: 0.018279540700594937 | validation: 0.008958131125633635]
	TIME [epoch: 6.55 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018721702717961117		[learning rate: 0.00039269]
	Learning Rate: 0.000392691
	LOSS [training: 0.018721702717961117 | validation: 0.002191194319402896]
	TIME [epoch: 6.55 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013209332425541509		[learning rate: 0.00039177]
	Learning Rate: 0.000391765
	LOSS [training: 0.013209332425541509 | validation: 0.010186605334471188]
	TIME [epoch: 6.55 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018032102575450418		[learning rate: 0.00039084]
	Learning Rate: 0.000390841
	LOSS [training: 0.018032102575450418 | validation: 0.011273928959378322]
	TIME [epoch: 6.55 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01800080057292532		[learning rate: 0.00038992]
	Learning Rate: 0.000389919
	LOSS [training: 0.01800080057292532 | validation: 0.012910699438491798]
	TIME [epoch: 6.58 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02067414334338589		[learning rate: 0.000389]
	Learning Rate: 0.000388999
	LOSS [training: 0.02067414334338589 | validation: -0.0005461685376210428]
	TIME [epoch: 6.55 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021659852723401582		[learning rate: 0.00038808]
	Learning Rate: 0.000388082
	LOSS [training: 0.021659852723401582 | validation: 0.010421039514127657]
	TIME [epoch: 6.55 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021185757160064673		[learning rate: 0.00038717]
	Learning Rate: 0.000387166
	LOSS [training: 0.021185757160064673 | validation: 0.011118474975239549]
	TIME [epoch: 6.55 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022590528750161577		[learning rate: 0.00038625]
	Learning Rate: 0.000386253
	LOSS [training: 0.022590528750161577 | validation: 0.014005991150720088]
	TIME [epoch: 6.55 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028337306411230657		[learning rate: 0.00038534]
	Learning Rate: 0.000385342
	LOSS [training: 0.028337306411230657 | validation: 0.02721331677353289]
	TIME [epoch: 6.58 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03561583062807765		[learning rate: 0.00038443]
	Learning Rate: 0.000384433
	LOSS [training: 0.03561583062807765 | validation: 0.021652703380212843]
	TIME [epoch: 6.56 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025950742428842977		[learning rate: 0.00038353]
	Learning Rate: 0.000383526
	LOSS [training: 0.025950742428842977 | validation: 0.009013342675547677]
	TIME [epoch: 6.55 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019203957808376988		[learning rate: 0.00038262]
	Learning Rate: 0.000382621
	LOSS [training: 0.019203957808376988 | validation: 0.010091600344678837]
	TIME [epoch: 6.55 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027492560981017412		[learning rate: 0.00038172]
	Learning Rate: 0.000381719
	LOSS [training: 0.027492560981017412 | validation: 0.026218526237577755]
	TIME [epoch: 6.55 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025241230186237317		[learning rate: 0.00038082]
	Learning Rate: 0.000380818
	LOSS [training: 0.025241230186237317 | validation: 0.009563291719140277]
	TIME [epoch: 6.58 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01569598811516213		[learning rate: 0.00037992]
	Learning Rate: 0.00037992
	LOSS [training: 0.01569598811516213 | validation: 0.008287976570456932]
	TIME [epoch: 6.56 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018809372300604546		[learning rate: 0.00037902]
	Learning Rate: 0.000379024
	LOSS [training: 0.018809372300604546 | validation: 0.014274124650989267]
	TIME [epoch: 6.55 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01713432707821029		[learning rate: 0.00037813]
	Learning Rate: 0.00037813
	LOSS [training: 0.01713432707821029 | validation: 0.00830923762199019]
	TIME [epoch: 6.55 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015378640659175966		[learning rate: 0.00037724]
	Learning Rate: 0.000377238
	LOSS [training: 0.015378640659175966 | validation: 0.0019245160630830885]
	TIME [epoch: 6.55 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017838913341485765		[learning rate: 0.00037635]
	Learning Rate: 0.000376348
	LOSS [training: 0.017838913341485765 | validation: 0.008785050789396811]
	TIME [epoch: 6.57 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02495252251608788		[learning rate: 0.00037546]
	Learning Rate: 0.00037546
	LOSS [training: 0.02495252251608788 | validation: 0.02933859614262315]
	TIME [epoch: 6.58 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04465376156471042		[learning rate: 0.00037457]
	Learning Rate: 0.000374575
	LOSS [training: 0.04465376156471042 | validation: 0.027192238496766573]
	TIME [epoch: 6.55 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02407386379108479		[learning rate: 0.00037369]
	Learning Rate: 0.000373691
	LOSS [training: 0.02407386379108479 | validation: 0.005234730187872411]
	TIME [epoch: 6.55 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01457016570165352		[learning rate: 0.00037281]
	Learning Rate: 0.00037281
	LOSS [training: 0.01457016570165352 | validation: 0.0008730000148032407]
	TIME [epoch: 6.55 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01695722294556844		[learning rate: 0.00037193]
	Learning Rate: 0.00037193
	LOSS [training: 0.01695722294556844 | validation: 0.002356294436044561]
	TIME [epoch: 6.55 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01441974814801636		[learning rate: 0.00037105]
	Learning Rate: 0.000371053
	LOSS [training: 0.01441974814801636 | validation: 0.007448638412064758]
	TIME [epoch: 6.59 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016429441754374267		[learning rate: 0.00037018]
	Learning Rate: 0.000370178
	LOSS [training: 0.016429441754374267 | validation: 0.0023214379445818173]
	TIME [epoch: 6.55 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014767300042029257		[learning rate: 0.0003693]
	Learning Rate: 0.000369305
	LOSS [training: 0.014767300042029257 | validation: 0.008683344711857255]
	TIME [epoch: 6.55 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019731731434742626		[learning rate: 0.00036843]
	Learning Rate: 0.000368433
	LOSS [training: 0.019731731434742626 | validation: 0.0071119756925660735]
	TIME [epoch: 6.55 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014180439316424404		[learning rate: 0.00036756]
	Learning Rate: 0.000367564
	LOSS [training: 0.014180439316424404 | validation: 0.0055384836820214]
	TIME [epoch: 6.55 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018174495312457156		[learning rate: 0.0003667]
	Learning Rate: 0.000366697
	LOSS [training: 0.018174495312457156 | validation: 0.016965875602434965]
	TIME [epoch: 6.59 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02234264012613755		[learning rate: 0.00036583]
	Learning Rate: 0.000365832
	LOSS [training: 0.02234264012613755 | validation: 0.010060029817506023]
	TIME [epoch: 6.55 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.008325206277592373		[learning rate: 0.00036497]
	Learning Rate: 0.000364969
	LOSS [training: 0.008325206277592373 | validation: 0.004645329198420558]
	TIME [epoch: 6.55 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01582618829886918		[learning rate: 0.00036411]
	Learning Rate: 0.000364108
	LOSS [training: 0.01582618829886918 | validation: 0.004501083374584726]
	TIME [epoch: 6.55 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011641287715995943		[learning rate: 0.00036325]
	Learning Rate: 0.00036325
	LOSS [training: 0.011641287715995943 | validation: 0.006700703441608322]
	TIME [epoch: 6.54 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023885393352091316		[learning rate: 0.00036239]
	Learning Rate: 0.000362393
	LOSS [training: 0.023885393352091316 | validation: 0.015495828102809625]
	TIME [epoch: 6.58 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029373853006191435		[learning rate: 0.00036154]
	Learning Rate: 0.000361538
	LOSS [training: 0.029373853006191435 | validation: 0.013411688422640575]
	TIME [epoch: 6.56 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02116797542742331		[learning rate: 0.00036069]
	Learning Rate: 0.000360685
	LOSS [training: 0.02116797542742331 | validation: 0.008530657915599076]
	TIME [epoch: 6.55 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017339029600904006		[learning rate: 0.00035983]
	Learning Rate: 0.000359834
	LOSS [training: 0.017339029600904006 | validation: 0.009288546756569658]
	TIME [epoch: 6.54 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02366519313903631		[learning rate: 0.00035899]
	Learning Rate: 0.000358986
	LOSS [training: 0.02366519313903631 | validation: 0.006837477301098461]
	TIME [epoch: 6.55 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016822492965839517		[learning rate: 0.00035814]
	Learning Rate: 0.000358139
	LOSS [training: 0.016822492965839517 | validation: 0.009000694594410568]
	TIME [epoch: 6.56 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012611691016971186		[learning rate: 0.00035729]
	Learning Rate: 0.000357294
	LOSS [training: 0.012611691016971186 | validation: 0.00033300806029254535]
	TIME [epoch: 6.58 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014790585120516165		[learning rate: 0.00035645]
	Learning Rate: 0.000356451
	LOSS [training: 0.014790585120516165 | validation: 0.007206317971105429]
	TIME [epoch: 6.54 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0174726954044202		[learning rate: 0.00035561]
	Learning Rate: 0.00035561
	LOSS [training: 0.0174726954044202 | validation: 0.014249720621658146]
	TIME [epoch: 6.55 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01878254618679252		[learning rate: 0.00035477]
	Learning Rate: 0.000354771
	LOSS [training: 0.01878254618679252 | validation: 0.008742969658639183]
	TIME [epoch: 6.55 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018118734693319698		[learning rate: 0.00035393]
	Learning Rate: 0.000353935
	LOSS [training: 0.018118734693319698 | validation: 0.009879457310759173]
	TIME [epoch: 6.55 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015233038933184565		[learning rate: 0.0003531]
	Learning Rate: 0.0003531
	LOSS [training: 0.015233038933184565 | validation: 0.009000595569168584]
	TIME [epoch: 6.59 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022582372976449168		[learning rate: 0.00035227]
	Learning Rate: 0.000352267
	LOSS [training: 0.022582372976449168 | validation: 0.007260465108157864]
	TIME [epoch: 6.55 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017176405474867006		[learning rate: 0.00035144]
	Learning Rate: 0.000351436
	LOSS [training: 0.017176405474867006 | validation: 0.00445092162663686]
	TIME [epoch: 6.54 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014683063851277618		[learning rate: 0.00035061]
	Learning Rate: 0.000350607
	LOSS [training: 0.014683063851277618 | validation: 0.013934575532306976]
	TIME [epoch: 6.54 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016264318920121		[learning rate: 0.00034978]
	Learning Rate: 0.00034978
	LOSS [training: 0.016264318920121 | validation: 0.004228854452606196]
	TIME [epoch: 6.54 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014549074592898042		[learning rate: 0.00034895]
	Learning Rate: 0.000348955
	LOSS [training: 0.014549074592898042 | validation: 0.012481695097351444]
	TIME [epoch: 6.58 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015109642184741406		[learning rate: 0.00034813]
	Learning Rate: 0.000348132
	LOSS [training: 0.015109642184741406 | validation: 0.0013881194598558333]
	TIME [epoch: 6.55 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021122458708401855		[learning rate: 0.00034731]
	Learning Rate: 0.000347311
	LOSS [training: 0.021122458708401855 | validation: 0.0161584917171406]
	TIME [epoch: 6.55 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02368081299092303		[learning rate: 0.00034649]
	Learning Rate: 0.000346491
	LOSS [training: 0.02368081299092303 | validation: 0.0062141984863324975]
	TIME [epoch: 6.55 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026880622181440723		[learning rate: 0.00034567]
	Learning Rate: 0.000345674
	LOSS [training: 0.026880622181440723 | validation: 0.011508517072878068]
	TIME [epoch: 6.55 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01641728704476051		[learning rate: 0.00034486]
	Learning Rate: 0.000344859
	LOSS [training: 0.01641728704476051 | validation: 0.004280961626834331]
	TIME [epoch: 6.58 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017737474489097398		[learning rate: 0.00034405]
	Learning Rate: 0.000344045
	LOSS [training: 0.017737474489097398 | validation: 0.008972554520821954]
	TIME [epoch: 6.56 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02194846044322865		[learning rate: 0.00034323]
	Learning Rate: 0.000343233
	LOSS [training: 0.02194846044322865 | validation: 0.020733145493109954]
	TIME [epoch: 6.55 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024871870493718796		[learning rate: 0.00034242]
	Learning Rate: 0.000342424
	LOSS [training: 0.024871870493718796 | validation: -0.0006170198014402032]
	TIME [epoch: 6.55 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017953859946042584		[learning rate: 0.00034162]
	Learning Rate: 0.000341616
	LOSS [training: 0.017953859946042584 | validation: 0.015834464511816967]
	TIME [epoch: 6.55 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.020433213487528246		[learning rate: 0.00034081]
	Learning Rate: 0.00034081
	LOSS [training: 0.020433213487528246 | validation: 0.013914328225566238]
	TIME [epoch: 6.56 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021711154482798735		[learning rate: 0.00034001]
	Learning Rate: 0.000340006
	LOSS [training: 0.021711154482798735 | validation: 0.01710041562514763]
	TIME [epoch: 6.59 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021359829956493014		[learning rate: 0.0003392]
	Learning Rate: 0.000339204
	LOSS [training: 0.021359829956493014 | validation: 0.012696681852711817]
	TIME [epoch: 6.55 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01824129749842703		[learning rate: 0.0003384]
	Learning Rate: 0.000338404
	LOSS [training: 0.01824129749842703 | validation: 0.0038648778237542394]
	TIME [epoch: 6.54 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013641627533869716		[learning rate: 0.00033761]
	Learning Rate: 0.000337606
	LOSS [training: 0.013641627533869716 | validation: 0.01433832673617192]
	TIME [epoch: 6.55 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01675078034631478		[learning rate: 0.00033681]
	Learning Rate: 0.00033681
	LOSS [training: 0.01675078034631478 | validation: 0.010291760431692786]
	TIME [epoch: 6.56 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015131140907794483		[learning rate: 0.00033602]
	Learning Rate: 0.000336015
	LOSS [training: 0.015131140907794483 | validation: 0.010218350166361212]
	TIME [epoch: 6.58 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01914086906032045		[learning rate: 0.00033522]
	Learning Rate: 0.000335223
	LOSS [training: 0.01914086906032045 | validation: 0.013553862698502651]
	TIME [epoch: 6.55 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0197345012764313		[learning rate: 0.00033443]
	Learning Rate: 0.000334432
	LOSS [training: 0.0197345012764313 | validation: 0.009430096575994612]
	TIME [epoch: 6.55 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015922056575752717		[learning rate: 0.00033364]
	Learning Rate: 0.000333643
	LOSS [training: 0.015922056575752717 | validation: 0.005931113962791576]
	TIME [epoch: 6.54 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014086256704373246		[learning rate: 0.00033286]
	Learning Rate: 0.000332856
	LOSS [training: 0.014086256704373246 | validation: 0.012542960772483682]
	TIME [epoch: 6.54 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025887304607694873		[learning rate: 0.00033207]
	Learning Rate: 0.000332071
	LOSS [training: 0.025887304607694873 | validation: 0.014427568486677051]
	TIME [epoch: 6.58 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022476586419051526		[learning rate: 0.00033129]
	Learning Rate: 0.000331288
	LOSS [training: 0.022476586419051526 | validation: 0.010179440639137434]
	TIME [epoch: 6.54 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.043250645262546836		[learning rate: 0.00033051]
	Learning Rate: 0.000330506
	LOSS [training: 0.043250645262546836 | validation: 0.019900253883464322]
	TIME [epoch: 6.54 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029574456561748973		[learning rate: 0.00032973]
	Learning Rate: 0.000329726
	LOSS [training: 0.029574456561748973 | validation: 0.017621428740976563]
	TIME [epoch: 6.55 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.020206692926749932		[learning rate: 0.00032895]
	Learning Rate: 0.000328949
	LOSS [training: 0.020206692926749932 | validation: 0.00790811279294659]
	TIME [epoch: 6.54 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022995038051543664		[learning rate: 0.00032817]
	Learning Rate: 0.000328173
	LOSS [training: 0.022995038051543664 | validation: 0.007156606539937068]
	TIME [epoch: 6.58 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023798223124653		[learning rate: 0.0003274]
	Learning Rate: 0.000327399
	LOSS [training: 0.023798223124653 | validation: 0.0038741942440938875]
	TIME [epoch: 6.55 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017021528528310285		[learning rate: 0.00032663]
	Learning Rate: 0.000326626
	LOSS [training: 0.017021528528310285 | validation: 0.01137469618204455]
	TIME [epoch: 6.55 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022812452589229214		[learning rate: 0.00032586]
	Learning Rate: 0.000325856
	LOSS [training: 0.022812452589229214 | validation: 0.003086014539712042]
	TIME [epoch: 6.54 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011864781034470629		[learning rate: 0.00032509]
	Learning Rate: 0.000325087
	LOSS [training: 0.011864781034470629 | validation: 0.0029879186440379415]
	TIME [epoch: 6.54 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019518656864858052		[learning rate: 0.00032432]
	Learning Rate: 0.00032432
	LOSS [training: 0.019518656864858052 | validation: 0.012454022315085881]
	TIME [epoch: 6.56 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02027732886870423		[learning rate: 0.00032356]
	Learning Rate: 0.000323555
	LOSS [training: 0.02027732886870423 | validation: 0.004418008507562338]
	TIME [epoch: 6.57 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016058742096782642		[learning rate: 0.00032279]
	Learning Rate: 0.000322792
	LOSS [training: 0.016058742096782642 | validation: 0.013147439525510401]
	TIME [epoch: 6.54 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0345185195486158		[learning rate: 0.00032203]
	Learning Rate: 0.000322031
	LOSS [training: 0.0345185195486158 | validation: 0.012542110988329951]
	TIME [epoch: 6.55 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035546655340154346		[learning rate: 0.00032127]
	Learning Rate: 0.000321271
	LOSS [training: 0.035546655340154346 | validation: 0.008730687703234668]
	TIME [epoch: 6.55 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02041394148583114		[learning rate: 0.00032051]
	Learning Rate: 0.000320513
	LOSS [training: 0.02041394148583114 | validation: 0.006136790091488388]
	TIME [epoch: 6.55 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01747403807165728		[learning rate: 0.00031976]
	Learning Rate: 0.000319757
	LOSS [training: 0.01747403807165728 | validation: 0.016083918091850818]
	TIME [epoch: 6.58 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019013563395310455		[learning rate: 0.000319]
	Learning Rate: 0.000319003
	LOSS [training: 0.019013563395310455 | validation: 0.01855707149010457]
	TIME [epoch: 6.56 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027804822640778583		[learning rate: 0.00031825]
	Learning Rate: 0.000318251
	LOSS [training: 0.027804822640778583 | validation: 0.009117654579524657]
	TIME [epoch: 6.55 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027302088383807804		[learning rate: 0.0003175]
	Learning Rate: 0.0003175
	LOSS [training: 0.027302088383807804 | validation: 0.020853501774138847]
	TIME [epoch: 6.55 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02439044971466702		[learning rate: 0.00031675]
	Learning Rate: 0.000316751
	LOSS [training: 0.02439044971466702 | validation: 0.01854795804079678]
	TIME [epoch: 6.55 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02358757763497573		[learning rate: 0.000316]
	Learning Rate: 0.000316004
	LOSS [training: 0.02358757763497573 | validation: 0.01879061975502111]
	TIME [epoch: 6.58 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017561545708135763		[learning rate: 0.00031526]
	Learning Rate: 0.000315258
	LOSS [training: 0.017561545708135763 | validation: 0.012254481913973337]
	TIME [epoch: 6.55 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017222168416725015		[learning rate: 0.00031451]
	Learning Rate: 0.000314515
	LOSS [training: 0.017222168416725015 | validation: 0.013564255481779513]
	TIME [epoch: 6.55 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01586085609041114		[learning rate: 0.00031377]
	Learning Rate: 0.000313773
	LOSS [training: 0.01586085609041114 | validation: 0.005769962402539542]
	TIME [epoch: 6.55 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023643241127821336		[learning rate: 0.00031303]
	Learning Rate: 0.000313033
	LOSS [training: 0.023643241127821336 | validation: 0.020807921314440384]
	TIME [epoch: 6.55 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03174413930162067		[learning rate: 0.00031229]
	Learning Rate: 0.000312294
	LOSS [training: 0.03174413930162067 | validation: 0.0146373990850695]
	TIME [epoch: 6.58 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.020545739256984046		[learning rate: 0.00031156]
	Learning Rate: 0.000311558
	LOSS [training: 0.020545739256984046 | validation: 0.012816797364766661]
	TIME [epoch: 6.56 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02379171859118446		[learning rate: 0.00031082]
	Learning Rate: 0.000310823
	LOSS [training: 0.02379171859118446 | validation: 0.0045192863936320896]
	TIME [epoch: 6.55 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01721686737391843		[learning rate: 0.00031009]
	Learning Rate: 0.00031009
	LOSS [training: 0.01721686737391843 | validation: 0.0018185244528106156]
	TIME [epoch: 6.55 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013160876688595382		[learning rate: 0.00030936]
	Learning Rate: 0.000309358
	LOSS [training: 0.013160876688595382 | validation: 0.0074879155653118585]
	TIME [epoch: 6.55 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02224174941876795		[learning rate: 0.00030863]
	Learning Rate: 0.000308628
	LOSS [training: 0.02224174941876795 | validation: 0.0038443341392826753]
	TIME [epoch: 6.56 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01990393430126009		[learning rate: 0.0003079]
	Learning Rate: 0.0003079
	LOSS [training: 0.01990393430126009 | validation: 0.0038000153845717194]
	TIME [epoch: 6.57 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.020750298194702903		[learning rate: 0.00030717]
	Learning Rate: 0.000307174
	LOSS [training: 0.020750298194702903 | validation: 0.007001057497999414]
	TIME [epoch: 6.54 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01696238597212346		[learning rate: 0.00030645]
	Learning Rate: 0.00030645
	LOSS [training: 0.01696238597212346 | validation: 0.017642211515424392]
	TIME [epoch: 6.54 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018639358146938255		[learning rate: 0.00030573]
	Learning Rate: 0.000305727
	LOSS [training: 0.018639358146938255 | validation: 0.005735761146646199]
	TIME [epoch: 6.54 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.020056647626413623		[learning rate: 0.00030501]
	Learning Rate: 0.000305005
	LOSS [training: 0.020056647626413623 | validation: 0.013397621682807071]
	TIME [epoch: 6.55 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02388092371994809		[learning rate: 0.00030429]
	Learning Rate: 0.000304286
	LOSS [training: 0.02388092371994809 | validation: 0.011108530004111992]
	TIME [epoch: 6.59 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01414776416415843		[learning rate: 0.00030357]
	Learning Rate: 0.000303568
	LOSS [training: 0.01414776416415843 | validation: 0.008389456956179753]
	TIME [epoch: 6.55 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01654916562658725		[learning rate: 0.00030285]
	Learning Rate: 0.000302852
	LOSS [training: 0.01654916562658725 | validation: 0.0120416373382869]
	TIME [epoch: 6.55 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018600143851828812		[learning rate: 0.00030214]
	Learning Rate: 0.000302138
	LOSS [training: 0.018600143851828812 | validation: 0.00030580765349694575]
	TIME [epoch: 6.54 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011352207420626547		[learning rate: 0.00030143]
	Learning Rate: 0.000301425
	LOSS [training: 0.011352207420626547 | validation: 0.011343095153175676]
	TIME [epoch: 6.55 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016001314847865277		[learning rate: 0.00030071]
	Learning Rate: 0.000300714
	LOSS [training: 0.016001314847865277 | validation: 0.00560970235270825]
	TIME [epoch: 6.58 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01068886158194057		[learning rate: 0.0003]
	Learning Rate: 0.000300005
	LOSS [training: 0.01068886158194057 | validation: 0.0015450361138487374]
	TIME [epoch: 6.55 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010815089079399065		[learning rate: 0.0002993]
	Learning Rate: 0.000299297
	LOSS [training: 0.010815089079399065 | validation: 0.008797505780883598]
	TIME [epoch: 6.55 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01952628336315087		[learning rate: 0.00029859]
	Learning Rate: 0.000298591
	LOSS [training: 0.01952628336315087 | validation: 0.01755530722799302]
	TIME [epoch: 6.55 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024124424822485842		[learning rate: 0.00029789]
	Learning Rate: 0.000297887
	LOSS [training: 0.024124424822485842 | validation: 0.017513695624905807]
	TIME [epoch: 6.54 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019348726868058115		[learning rate: 0.00029718]
	Learning Rate: 0.000297184
	LOSS [training: 0.019348726868058115 | validation: 0.0022339276899541365]
	TIME [epoch: 6.58 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014825503603999923		[learning rate: 0.00029648]
	Learning Rate: 0.000296483
	LOSS [training: 0.014825503603999923 | validation: 0.0033705101070998214]
	TIME [epoch: 6.55 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016530700821325118		[learning rate: 0.00029578]
	Learning Rate: 0.000295784
	LOSS [training: 0.016530700821325118 | validation: 0.009694116899795139]
	TIME [epoch: 6.55 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012469229665783458		[learning rate: 0.00029509]
	Learning Rate: 0.000295086
	LOSS [training: 0.012469229665783458 | validation: 0.0012038394896712488]
	TIME [epoch: 6.55 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013757665462878039		[learning rate: 0.00029439]
	Learning Rate: 0.00029439
	LOSS [training: 0.013757665462878039 | validation: 0.007863241521078087]
	TIME [epoch: 6.56 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.020421560143603256		[learning rate: 0.0002937]
	Learning Rate: 0.000293696
	LOSS [training: 0.020421560143603256 | validation: 0.00391401949111827]
	TIME [epoch: 6.59 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02094083729844834		[learning rate: 0.000293]
	Learning Rate: 0.000293003
	LOSS [training: 0.02094083729844834 | validation: 0.007030208971206839]
	TIME [epoch: 6.56 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011573221233321624		[learning rate: 0.00029231]
	Learning Rate: 0.000292312
	LOSS [training: 0.011573221233321624 | validation: 0.0038493813578440103]
	TIME [epoch: 6.55 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011836355850795862		[learning rate: 0.00029162]
	Learning Rate: 0.000291622
	LOSS [training: 0.011836355850795862 | validation: 0.015297503589155818]
	TIME [epoch: 6.55 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023195732518745304		[learning rate: 0.00029093]
	Learning Rate: 0.000290934
	LOSS [training: 0.023195732518745304 | validation: -0.006736784474251311]
	TIME [epoch: 6.55 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_1548.pth
	Model improved!!!
EPOCH 1549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01202607422461596		[learning rate: 0.00029025]
	Learning Rate: 0.000290248
	LOSS [training: 0.01202607422461596 | validation: 0.00968200921430359]
	TIME [epoch: 6.56 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016251886576811682		[learning rate: 0.00028956]
	Learning Rate: 0.000289563
	LOSS [training: 0.016251886576811682 | validation: -0.00028790986574617986]
	TIME [epoch: 6.58 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015033312779825687		[learning rate: 0.00028888]
	Learning Rate: 0.00028888
	LOSS [training: 0.015033312779825687 | validation: 0.011081008843975611]
	TIME [epoch: 6.55 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026056534468889725		[learning rate: 0.0002882]
	Learning Rate: 0.000288199
	LOSS [training: 0.026056534468889725 | validation: 0.006179290560751027]
	TIME [epoch: 6.54 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022924685331563176		[learning rate: 0.00028752]
	Learning Rate: 0.000287519
	LOSS [training: 0.022924685331563176 | validation: 0.007768936512054655]
	TIME [epoch: 6.55 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021383101560326277		[learning rate: 0.00028684]
	Learning Rate: 0.000286841
	LOSS [training: 0.021383101560326277 | validation: 0.0036206258887855796]
	TIME [epoch: 6.55 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014096784612289873		[learning rate: 0.00028616]
	Learning Rate: 0.000286164
	LOSS [training: 0.014096784612289873 | validation: 0.0030551069721812107]
	TIME [epoch: 6.59 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021231777907587703		[learning rate: 0.00028549]
	Learning Rate: 0.000285489
	LOSS [training: 0.021231777907587703 | validation: 0.012049804516724105]
	TIME [epoch: 6.55 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021368829604405372		[learning rate: 0.00028482]
	Learning Rate: 0.000284816
	LOSS [training: 0.021368829604405372 | validation: 0.002642203264740568]
	TIME [epoch: 6.55 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014849339603472695		[learning rate: 0.00028414]
	Learning Rate: 0.000284144
	LOSS [training: 0.014849339603472695 | validation: 0.006774702211291631]
	TIME [epoch: 6.54 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016214430851385717		[learning rate: 0.00028347]
	Learning Rate: 0.000283474
	LOSS [training: 0.016214430851385717 | validation: 0.010585014709581847]
	TIME [epoch: 6.55 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014162917025018823		[learning rate: 0.00028281]
	Learning Rate: 0.000282805
	LOSS [training: 0.014162917025018823 | validation: 0.0016215031293809468]
	TIME [epoch: 6.58 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012851432655814501		[learning rate: 0.00028214]
	Learning Rate: 0.000282138
	LOSS [training: 0.012851432655814501 | validation: 0.0003174709259900141]
	TIME [epoch: 6.55 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014481912388403276		[learning rate: 0.00028147]
	Learning Rate: 0.000281472
	LOSS [training: 0.014481912388403276 | validation: 0.003894581786349584]
	TIME [epoch: 6.55 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02111412336599609		[learning rate: 0.00028081]
	Learning Rate: 0.000280808
	LOSS [training: 0.02111412336599609 | validation: 0.011203398776729663]
	TIME [epoch: 6.55 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027748802914283534		[learning rate: 0.00028015]
	Learning Rate: 0.000280146
	LOSS [training: 0.027748802914283534 | validation: 0.014224992918347211]
	TIME [epoch: 6.55 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015041361067566372		[learning rate: 0.00027949]
	Learning Rate: 0.000279485
	LOSS [training: 0.015041361067566372 | validation: 0.009951970808129783]
	TIME [epoch: 6.57 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011466051750863368		[learning rate: 0.00027883]
	Learning Rate: 0.000278826
	LOSS [training: 0.011466051750863368 | validation: 0.010041876706929683]
	TIME [epoch: 6.56 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015612273233275983		[learning rate: 0.00027817]
	Learning Rate: 0.000278168
	LOSS [training: 0.015612273233275983 | validation: 0.010529712816660836]
	TIME [epoch: 6.54 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019164591617066577		[learning rate: 0.00027751]
	Learning Rate: 0.000277512
	LOSS [training: 0.019164591617066577 | validation: 0.011148189673945215]
	TIME [epoch: 6.55 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014358298220686194		[learning rate: 0.00027686]
	Learning Rate: 0.000276858
	LOSS [training: 0.014358298220686194 | validation: 0.005818698486084378]
	TIME [epoch: 6.54 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010479325217368596		[learning rate: 0.0002762]
	Learning Rate: 0.000276204
	LOSS [training: 0.010479325217368596 | validation: 0.008977811687981408]
	TIME [epoch: 6.56 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015249419179606049		[learning rate: 0.00027555]
	Learning Rate: 0.000275553
	LOSS [training: 0.015249419179606049 | validation: 0.01841038999495423]
	TIME [epoch: 6.58 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022926305284260994		[learning rate: 0.0002749]
	Learning Rate: 0.000274903
	LOSS [training: 0.022926305284260994 | validation: 0.006221675790306275]
	TIME [epoch: 6.54 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02384274918149626		[learning rate: 0.00027425]
	Learning Rate: 0.000274255
	LOSS [training: 0.02384274918149626 | validation: 0.01834095938018]
	TIME [epoch: 6.54 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025929653688553257		[learning rate: 0.00027361]
	Learning Rate: 0.000273608
	LOSS [training: 0.025929653688553257 | validation: 0.007594262360108326]
	TIME [epoch: 6.55 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015186583975031726		[learning rate: 0.00027296]
	Learning Rate: 0.000272962
	LOSS [training: 0.015186583975031726 | validation: 0.010880781850254179]
	TIME [epoch: 6.55 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02046311005664687		[learning rate: 0.00027232]
	Learning Rate: 0.000272318
	LOSS [training: 0.02046311005664687 | validation: 0.01149768457325654]
	TIME [epoch: 6.58 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01439439315317192		[learning rate: 0.00027168]
	Learning Rate: 0.000271676
	LOSS [training: 0.01439439315317192 | validation: 0.0080297968026754]
	TIME [epoch: 6.55 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015655035062721385		[learning rate: 0.00027104]
	Learning Rate: 0.000271035
	LOSS [training: 0.015655035062721385 | validation: 0.004932334782390119]
	TIME [epoch: 6.55 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013004659022863444		[learning rate: 0.0002704]
	Learning Rate: 0.000270396
	LOSS [training: 0.013004659022863444 | validation: 0.008285915791053195]
	TIME [epoch: 6.55 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01986553688378988		[learning rate: 0.00026976]
	Learning Rate: 0.000269758
	LOSS [training: 0.01986553688378988 | validation: 0.00836366744181296]
	TIME [epoch: 6.54 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013634960634936678		[learning rate: 0.00026912]
	Learning Rate: 0.000269122
	LOSS [training: 0.013634960634936678 | validation: 0.0010404749069654242]
	TIME [epoch: 6.58 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013420740789059782		[learning rate: 0.00026849]
	Learning Rate: 0.000268487
	LOSS [training: 0.013420740789059782 | validation: 0.0019480079598797563]
	TIME [epoch: 6.55 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011659608732073511		[learning rate: 0.00026785]
	Learning Rate: 0.000267854
	LOSS [training: 0.011659608732073511 | validation: 0.004258758787228241]
	TIME [epoch: 6.55 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015048301045143524		[learning rate: 0.00026722]
	Learning Rate: 0.000267222
	LOSS [training: 0.015048301045143524 | validation: 0.0031173819062913933]
	TIME [epoch: 6.55 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019311983474160133		[learning rate: 0.00026659]
	Learning Rate: 0.000266591
	LOSS [training: 0.019311983474160133 | validation: 0.008138046372095916]
	TIME [epoch: 6.54 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014101361389060364		[learning rate: 0.00026596]
	Learning Rate: 0.000265963
	LOSS [training: 0.014101361389060364 | validation: 0.00945859693331732]
	TIME [epoch: 6.58 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.00946639520869597		[learning rate: 0.00026534]
	Learning Rate: 0.000265335
	LOSS [training: 0.00946639520869597 | validation: -0.003730291073273908]
	TIME [epoch: 6.56 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014294734191017419		[learning rate: 0.00026471]
	Learning Rate: 0.000264709
	LOSS [training: 0.014294734191017419 | validation: 0.001735490523748641]
	TIME [epoch: 6.55 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012314654080158076		[learning rate: 0.00026408]
	Learning Rate: 0.000264085
	LOSS [training: 0.012314654080158076 | validation: -0.004029107992949327]
	TIME [epoch: 6.55 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013890651834200168		[learning rate: 0.00026346]
	Learning Rate: 0.000263462
	LOSS [training: 0.013890651834200168 | validation: 0.0026875372406739385]
	TIME [epoch: 6.55 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01007845303813092		[learning rate: 0.00026284]
	Learning Rate: 0.00026284
	LOSS [training: 0.01007845303813092 | validation: -0.004537903941523429]
	TIME [epoch: 6.57 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013575265827257432		[learning rate: 0.00026222]
	Learning Rate: 0.00026222
	LOSS [training: 0.013575265827257432 | validation: 0.0061914968624688675]
	TIME [epoch: 6.57 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01743677480659192		[learning rate: 0.0002616]
	Learning Rate: 0.000261602
	LOSS [training: 0.01743677480659192 | validation: 0.0011410975355075426]
	TIME [epoch: 6.55 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018439688193028277		[learning rate: 0.00026098]
	Learning Rate: 0.000260985
	LOSS [training: 0.018439688193028277 | validation: 0.0100501717682394]
	TIME [epoch: 6.55 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02092816985495728		[learning rate: 0.00026037]
	Learning Rate: 0.000260369
	LOSS [training: 0.02092816985495728 | validation: 0.013207739752995884]
	TIME [epoch: 6.55 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.020571696347881387		[learning rate: 0.00025976]
	Learning Rate: 0.000259755
	LOSS [training: 0.020571696347881387 | validation: 0.008717378926130993]
	TIME [epoch: 6.55 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015910679660427127		[learning rate: 0.00025914]
	Learning Rate: 0.000259142
	LOSS [training: 0.015910679660427127 | validation: 0.00485111820157667]
	TIME [epoch: 6.58 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014913233505983123		[learning rate: 0.00025853]
	Learning Rate: 0.000258531
	LOSS [training: 0.014913233505983123 | validation: 0.01040684030274093]
	TIME [epoch: 6.6 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019876981576429118		[learning rate: 0.00025792]
	Learning Rate: 0.000257921
	LOSS [training: 0.019876981576429118 | validation: -0.0003985635926804969]
	TIME [epoch: 6.55 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011189206557141479		[learning rate: 0.00025731]
	Learning Rate: 0.000257313
	LOSS [training: 0.011189206557141479 | validation: 0.004648344603483139]
	TIME [epoch: 6.55 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010916699853921038		[learning rate: 0.00025671]
	Learning Rate: 0.000256706
	LOSS [training: 0.010916699853921038 | validation: 0.00473956188028026]
	TIME [epoch: 6.54 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01674278814744996		[learning rate: 0.0002561]
	Learning Rate: 0.0002561
	LOSS [training: 0.01674278814744996 | validation: 0.00046009346899498083]
	TIME [epoch: 6.59 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01799672262046012		[learning rate: 0.0002555]
	Learning Rate: 0.000255496
	LOSS [training: 0.01799672262046012 | validation: 0.008466806871106103]
	TIME [epoch: 6.55 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017700506102034504		[learning rate: 0.00025489]
	Learning Rate: 0.000254894
	LOSS [training: 0.017700506102034504 | validation: 0.012618956719438567]
	TIME [epoch: 6.55 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.020189609217885724		[learning rate: 0.00025429]
	Learning Rate: 0.000254292
	LOSS [training: 0.020189609217885724 | validation: 0.013285566784185902]
	TIME [epoch: 6.55 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018264647706496138		[learning rate: 0.00025369]
	Learning Rate: 0.000253693
	LOSS [training: 0.018264647706496138 | validation: -0.0008344482105120338]
	TIME [epoch: 6.55 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021009905198538327		[learning rate: 0.00025309]
	Learning Rate: 0.000253094
	LOSS [training: 0.021009905198538327 | validation: 0.00307741996013201]
	TIME [epoch: 6.58 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01687348984151552		[learning rate: 0.0002525]
	Learning Rate: 0.000252497
	LOSS [training: 0.01687348984151552 | validation: 0.0059474125097656455]
	TIME [epoch: 6.56 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017683423821924747		[learning rate: 0.0002519]
	Learning Rate: 0.000251902
	LOSS [training: 0.017683423821924747 | validation: 0.0026366103820131977]
	TIME [epoch: 6.55 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013869896411279503		[learning rate: 0.00025131]
	Learning Rate: 0.000251307
	LOSS [training: 0.013869896411279503 | validation: 0.009585583815230343]
	TIME [epoch: 6.55 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016612555287512574		[learning rate: 0.00025071]
	Learning Rate: 0.000250714
	LOSS [training: 0.016612555287512574 | validation: 0.008375071716307605]
	TIME [epoch: 6.55 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011843703084427164		[learning rate: 0.00025012]
	Learning Rate: 0.000250123
	LOSS [training: 0.011843703084427164 | validation: 0.0030355079865710347]
	TIME [epoch: 6.58 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014711036745900413		[learning rate: 0.00024953]
	Learning Rate: 0.000249533
	LOSS [training: 0.014711036745900413 | validation: 0.0020649982744096306]
	TIME [epoch: 6.56 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011782303836626694		[learning rate: 0.00024894]
	Learning Rate: 0.000248945
	LOSS [training: 0.011782303836626694 | validation: 0.006021293564905495]
	TIME [epoch: 6.55 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016449383646246363		[learning rate: 0.00024836]
	Learning Rate: 0.000248357
	LOSS [training: 0.016449383646246363 | validation: -0.00030544647360938523]
	TIME [epoch: 6.55 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01490610091566692		[learning rate: 0.00024777]
	Learning Rate: 0.000247771
	LOSS [training: 0.01490610091566692 | validation: 0.009190443235462956]
	TIME [epoch: 6.55 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013988690395707964		[learning rate: 0.00024719]
	Learning Rate: 0.000247187
	LOSS [training: 0.013988690395707964 | validation: 0.00046127729060068626]
	TIME [epoch: 6.56 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01765464192115157		[learning rate: 0.0002466]
	Learning Rate: 0.000246604
	LOSS [training: 0.01765464192115157 | validation: 0.0035832950699296534]
	TIME [epoch: 6.58 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017276895579582376		[learning rate: 0.00024602]
	Learning Rate: 0.000246022
	LOSS [training: 0.017276895579582376 | validation: 0.007232489675972548]
	TIME [epoch: 6.55 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013311941395921007		[learning rate: 0.00024544]
	Learning Rate: 0.000245442
	LOSS [training: 0.013311941395921007 | validation: -0.0006702075947833093]
	TIME [epoch: 6.55 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013641459736149174		[learning rate: 0.00024486]
	Learning Rate: 0.000244863
	LOSS [training: 0.013641459736149174 | validation: 0.0017525014849216845]
	TIME [epoch: 6.55 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012669255266283824		[learning rate: 0.00024429]
	Learning Rate: 0.000244285
	LOSS [training: 0.012669255266283824 | validation: 0.007244680027027931]
	TIME [epoch: 6.55 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016522374195601576		[learning rate: 0.00024371]
	Learning Rate: 0.000243709
	LOSS [training: 0.016522374195601576 | validation: 0.0030777191131495995]
	TIME [epoch: 6.59 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013123853599931887		[learning rate: 0.00024313]
	Learning Rate: 0.000243134
	LOSS [training: 0.013123853599931887 | validation: 0.004757226885978398]
	TIME [epoch: 6.55 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016645055635090437		[learning rate: 0.00024256]
	Learning Rate: 0.000242561
	LOSS [training: 0.016645055635090437 | validation: -0.005293914028021318]
	TIME [epoch: 6.55 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012347974508185788		[learning rate: 0.00024199]
	Learning Rate: 0.000241989
	LOSS [training: 0.012347974508185788 | validation: 0.009998071253158103]
	TIME [epoch: 6.55 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02264747387170603		[learning rate: 0.00024142]
	Learning Rate: 0.000241418
	LOSS [training: 0.02264747387170603 | validation: 0.015846722569370277]
	TIME [epoch: 6.55 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031406741733089445		[learning rate: 0.00024085]
	Learning Rate: 0.000240848
	LOSS [training: 0.031406741733089445 | validation: 0.0088117581461969]
	TIME [epoch: 6.58 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029274764594365517		[learning rate: 0.00024028]
	Learning Rate: 0.00024028
	LOSS [training: 0.029274764594365517 | validation: 0.023265974528802393]
	TIME [epoch: 6.56 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024237378937685385		[learning rate: 0.00023971]
	Learning Rate: 0.000239713
	LOSS [training: 0.024237378937685385 | validation: 0.003499790664818229]
	TIME [epoch: 6.55 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015561419146028443		[learning rate: 0.00023915]
	Learning Rate: 0.000239148
	LOSS [training: 0.015561419146028443 | validation: 0.009465968201640165]
	TIME [epoch: 6.55 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01794006775828221		[learning rate: 0.00023858]
	Learning Rate: 0.000238584
	LOSS [training: 0.01794006775828221 | validation: 0.0054307737691145904]
	TIME [epoch: 6.55 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016121921017866563		[learning rate: 0.00023802]
	Learning Rate: 0.000238021
	LOSS [training: 0.016121921017866563 | validation: -0.0010627999993956024]
	TIME [epoch: 6.58 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0164407348285679		[learning rate: 0.00023746]
	Learning Rate: 0.00023746
	LOSS [training: 0.0164407348285679 | validation: 0.0009934696594155008]
	TIME [epoch: 6.56 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012200561930386756		[learning rate: 0.0002369]
	Learning Rate: 0.000236899
	LOSS [training: 0.012200561930386756 | validation: 0.0010721257371318176]
	TIME [epoch: 6.55 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011787543069842903		[learning rate: 0.00023634]
	Learning Rate: 0.000236341
	LOSS [training: 0.011787543069842903 | validation: 0.012353504825264037]
	TIME [epoch: 6.55 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019224651866901792		[learning rate: 0.00023578]
	Learning Rate: 0.000235783
	LOSS [training: 0.019224651866901792 | validation: 0.0018432961886452864]
	TIME [epoch: 6.55 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013940533952934642		[learning rate: 0.00023523]
	Learning Rate: 0.000235227
	LOSS [training: 0.013940533952934642 | validation: -0.0016927956024431383]
	TIME [epoch: 6.56 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013228009113506486		[learning rate: 0.00023467]
	Learning Rate: 0.000234672
	LOSS [training: 0.013228009113506486 | validation: -0.0008119267906994193]
	TIME [epoch: 6.59 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01374311439267037		[learning rate: 0.00023412]
	Learning Rate: 0.000234119
	LOSS [training: 0.01374311439267037 | validation: 0.004310758786759916]
	TIME [epoch: 6.55 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013324615382264603		[learning rate: 0.00023357]
	Learning Rate: 0.000233566
	LOSS [training: 0.013324615382264603 | validation: 0.0015365318993373362]
	TIME [epoch: 6.55 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012241522167816406		[learning rate: 0.00023302]
	Learning Rate: 0.000233015
	LOSS [training: 0.012241522167816406 | validation: 0.0073559809248443814]
	TIME [epoch: 6.55 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018650215368654088		[learning rate: 0.00023247]
	Learning Rate: 0.000232466
	LOSS [training: 0.018650215368654088 | validation: 0.006375388863487612]
	TIME [epoch: 6.55 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015242702907921794		[learning rate: 0.00023192]
	Learning Rate: 0.000231917
	LOSS [training: 0.015242702907921794 | validation: -0.00038623171290846567]
	TIME [epoch: 6.58 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010163718012153001		[learning rate: 0.00023137]
	Learning Rate: 0.00023137
	LOSS [training: 0.010163718012153001 | validation: -0.006056338867222233]
	TIME [epoch: 6.55 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014803871893020553		[learning rate: 0.00023082]
	Learning Rate: 0.000230825
	LOSS [training: 0.014803871893020553 | validation: -0.000677809937919209]
	TIME [epoch: 6.55 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014065275840451133		[learning rate: 0.00023028]
	Learning Rate: 0.00023028
	LOSS [training: 0.014065275840451133 | validation: 0.00453988032662941]
	TIME [epoch: 6.55 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01581194380055733		[learning rate: 0.00022974]
	Learning Rate: 0.000229737
	LOSS [training: 0.01581194380055733 | validation: -0.0002934817996550973]
	TIME [epoch: 6.55 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014112704093948908		[learning rate: 0.00022919]
	Learning Rate: 0.000229195
	LOSS [training: 0.014112704093948908 | validation: 0.0031885958410937595]
	TIME [epoch: 6.59 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011767488758384615		[learning rate: 0.00022865]
	Learning Rate: 0.000228654
	LOSS [training: 0.011767488758384615 | validation: 0.010683816623707855]
	TIME [epoch: 6.56 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015299974894495033		[learning rate: 0.00022811]
	Learning Rate: 0.000228115
	LOSS [training: 0.015299974894495033 | validation: 0.002291283727676126]
	TIME [epoch: 6.55 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015342523890172485		[learning rate: 0.00022758]
	Learning Rate: 0.000227577
	LOSS [training: 0.015342523890172485 | validation: 0.0021448808251262807]
	TIME [epoch: 6.54 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013658625498522018		[learning rate: 0.00022704]
	Learning Rate: 0.00022704
	LOSS [training: 0.013658625498522018 | validation: 0.013748305648006028]
	TIME [epoch: 6.54 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013413863483399341		[learning rate: 0.0002265]
	Learning Rate: 0.000226505
	LOSS [training: 0.013413863483399341 | validation: 0.005005254342394436]
	TIME [epoch: 6.58 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012530651295764117		[learning rate: 0.00022597]
	Learning Rate: 0.00022597
	LOSS [training: 0.012530651295764117 | validation: 0.008519550459345862]
	TIME [epoch: 6.56 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031611856948288865		[learning rate: 0.00022544]
	Learning Rate: 0.000225437
	LOSS [training: 0.031611856948288865 | validation: 0.017921092202929218]
	TIME [epoch: 6.55 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034561850039957154		[learning rate: 0.00022491]
	Learning Rate: 0.000224905
	LOSS [training: 0.034561850039957154 | validation: 0.02508283395299751]
	TIME [epoch: 6.55 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03215014922882013		[learning rate: 0.00022437]
	Learning Rate: 0.000224375
	LOSS [training: 0.03215014922882013 | validation: 0.011594205974610274]
	TIME [epoch: 6.54 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016646783046605877		[learning rate: 0.00022385]
	Learning Rate: 0.000223846
	LOSS [training: 0.016646783046605877 | validation: 0.011442689147530148]
	TIME [epoch: 6.56 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021871847224781676		[learning rate: 0.00022332]
	Learning Rate: 0.000223318
	LOSS [training: 0.021871847224781676 | validation: 0.018146202071372585]
	TIME [epoch: 6.57 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022290241256355453		[learning rate: 0.00022279]
	Learning Rate: 0.000222791
	LOSS [training: 0.022290241256355453 | validation: 0.02696359054611241]
	TIME [epoch: 6.55 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022945665421476684		[learning rate: 0.00022227]
	Learning Rate: 0.000222265
	LOSS [training: 0.022945665421476684 | validation: 0.016426556850508558]
	TIME [epoch: 6.55 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02790734536148056		[learning rate: 0.00022174]
	Learning Rate: 0.000221741
	LOSS [training: 0.02790734536148056 | validation: 0.018565242443079187]
	TIME [epoch: 6.55 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027513697892837967		[learning rate: 0.00022122]
	Learning Rate: 0.000221218
	LOSS [training: 0.027513697892837967 | validation: 0.022218365758915223]
	TIME [epoch: 6.55 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017694769913773667		[learning rate: 0.0002207]
	Learning Rate: 0.000220696
	LOSS [training: 0.017694769913773667 | validation: 0.018631545270761635]
	TIME [epoch: 6.58 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019530590663025076		[learning rate: 0.00022018]
	Learning Rate: 0.000220176
	LOSS [training: 0.019530590663025076 | validation: 0.013262515434173873]
	TIME [epoch: 6.55 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02090415850208578		[learning rate: 0.00021966]
	Learning Rate: 0.000219656
	LOSS [training: 0.02090415850208578 | validation: 0.005971833317855158]
	TIME [epoch: 6.54 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01798187153448106		[learning rate: 0.00021914]
	Learning Rate: 0.000219138
	LOSS [training: 0.01798187153448106 | validation: 0.011416727941892212]
	TIME [epoch: 6.54 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012957254507690013		[learning rate: 0.00021862]
	Learning Rate: 0.000218621
	LOSS [training: 0.012957254507690013 | validation: 0.005227231525699308]
	TIME [epoch: 6.55 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013934247240870643		[learning rate: 0.00021811]
	Learning Rate: 0.000218106
	LOSS [training: 0.013934247240870643 | validation: 0.0032067969248749948]
	TIME [epoch: 6.58 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011035821087291408		[learning rate: 0.00021759]
	Learning Rate: 0.000217591
	LOSS [training: 0.011035821087291408 | validation: 0.013353159667148838]
	TIME [epoch: 6.55 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012318720152204912		[learning rate: 0.00021708]
	Learning Rate: 0.000217078
	LOSS [training: 0.012318720152204912 | validation: 0.00433847920574131]
	TIME [epoch: 6.54 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010433048596495086		[learning rate: 0.00021657]
	Learning Rate: 0.000216566
	LOSS [training: 0.010433048596495086 | validation: 0.013100363440193982]
	TIME [epoch: 6.55 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01576389837344813		[learning rate: 0.00021605]
	Learning Rate: 0.000216055
	LOSS [training: 0.01576389837344813 | validation: 0.003656007633485956]
	TIME [epoch: 6.54 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016248115413971396		[learning rate: 0.00021555]
	Learning Rate: 0.000215545
	LOSS [training: 0.016248115413971396 | validation: 0.0077060799790638745]
	TIME [epoch: 6.58 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012540177251097167		[learning rate: 0.00021504]
	Learning Rate: 0.000215037
	LOSS [training: 0.012540177251097167 | validation: 0.005460410789146278]
	TIME [epoch: 6.55 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011566800545244874		[learning rate: 0.00021453]
	Learning Rate: 0.00021453
	LOSS [training: 0.011566800545244874 | validation: 0.0016654782602958957]
	TIME [epoch: 6.54 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013564672253355175		[learning rate: 0.00021402]
	Learning Rate: 0.000214024
	LOSS [training: 0.013564672253355175 | validation: 0.009346222912337547]
	TIME [epoch: 6.55 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009054974247715283		[learning rate: 0.00021352]
	Learning Rate: 0.000213519
	LOSS [training: 0.009054974247715283 | validation: 0.001001624301019079]
	TIME [epoch: 6.54 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014462023779895505		[learning rate: 0.00021302]
	Learning Rate: 0.000213015
	LOSS [training: 0.014462023779895505 | validation: 0.006368617387337679]
	TIME [epoch: 6.56 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011584912978141685		[learning rate: 0.00021251]
	Learning Rate: 0.000212513
	LOSS [training: 0.011584912978141685 | validation: 0.00523119116529754]
	TIME [epoch: 6.58 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011558514006894675		[learning rate: 0.00021201]
	Learning Rate: 0.000212011
	LOSS [training: 0.011558514006894675 | validation: 0.005919739212150659]
	TIME [epoch: 6.54 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.020664898401721025		[learning rate: 0.00021151]
	Learning Rate: 0.000211511
	LOSS [training: 0.020664898401721025 | validation: 0.010800204422930344]
	TIME [epoch: 6.55 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01271054702178572		[learning rate: 0.00021101]
	Learning Rate: 0.000211012
	LOSS [training: 0.01271054702178572 | validation: 0.0013298775306259608]
	TIME [epoch: 6.55 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011870020298806875		[learning rate: 0.00021051]
	Learning Rate: 0.000210514
	LOSS [training: 0.011870020298806875 | validation: 0.00631761649106846]
	TIME [epoch: 6.55 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010053126471907009		[learning rate: 0.00021002]
	Learning Rate: 0.000210018
	LOSS [training: 0.010053126471907009 | validation: 0.0013091270759045589]
	TIME [epoch: 6.59 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009735326855990172		[learning rate: 0.00020952]
	Learning Rate: 0.000209523
	LOSS [training: 0.009735326855990172 | validation: 0.003123619240347545]
	TIME [epoch: 6.55 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011054103811717366		[learning rate: 0.00020903]
	Learning Rate: 0.000209028
	LOSS [training: 0.011054103811717366 | validation: 0.0016846980134006895]
	TIME [epoch: 6.55 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010294585776771259		[learning rate: 0.00020854]
	Learning Rate: 0.000208535
	LOSS [training: 0.010294585776771259 | validation: 0.006802923242258795]
	TIME [epoch: 6.55 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012406668382217066		[learning rate: 0.00020804]
	Learning Rate: 0.000208043
	LOSS [training: 0.012406668382217066 | validation: 0.001050358937513659]
	TIME [epoch: 6.55 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01598523635505416		[learning rate: 0.00020755]
	Learning Rate: 0.000207553
	LOSS [training: 0.01598523635505416 | validation: 0.008905001752573858]
	TIME [epoch: 6.59 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02146729345448862		[learning rate: 0.00020706]
	Learning Rate: 0.000207063
	LOSS [training: 0.02146729345448862 | validation: 0.005780437143677142]
	TIME [epoch: 6.56 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01025682346470098		[learning rate: 0.00020657]
	Learning Rate: 0.000206575
	LOSS [training: 0.01025682346470098 | validation: 0.0011527275010774114]
	TIME [epoch: 6.55 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014339484153511375		[learning rate: 0.00020609]
	Learning Rate: 0.000206087
	LOSS [training: 0.014339484153511375 | validation: 0.005449331357390698]
	TIME [epoch: 6.55 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010091964440052498		[learning rate: 0.0002056]
	Learning Rate: 0.000205601
	LOSS [training: 0.010091964440052498 | validation: -0.0032628789774544692]
	TIME [epoch: 6.55 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.008891043951557848		[learning rate: 0.00020512]
	Learning Rate: 0.000205116
	LOSS [training: 0.008891043951557848 | validation: 0.005108069693801463]
	TIME [epoch: 6.59 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012244413009568644		[learning rate: 0.00020463]
	Learning Rate: 0.000204632
	LOSS [training: 0.012244413009568644 | validation: 0.006595698202950345]
	TIME [epoch: 6.55 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.008855779878383162		[learning rate: 0.00020415]
	Learning Rate: 0.00020415
	LOSS [training: 0.008855779878383162 | validation: 0.005152479547111835]
	TIME [epoch: 6.54 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017791757074833957		[learning rate: 0.00020367]
	Learning Rate: 0.000203668
	LOSS [training: 0.017791757074833957 | validation: 0.00514444671083379]
	TIME [epoch: 6.54 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012701620001962455		[learning rate: 0.00020319]
	Learning Rate: 0.000203188
	LOSS [training: 0.012701620001962455 | validation: 0.01113777572951821]
	TIME [epoch: 6.55 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01866671961777331		[learning rate: 0.00020271]
	Learning Rate: 0.000202708
	LOSS [training: 0.01866671961777331 | validation: 0.008215400180791064]
	TIME [epoch: 6.57 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011373611191962067		[learning rate: 0.00020223]
	Learning Rate: 0.00020223
	LOSS [training: 0.011373611191962067 | validation: 0.001511762157352525]
	TIME [epoch: 6.57 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013676710390415056		[learning rate: 0.00020175]
	Learning Rate: 0.000201753
	LOSS [training: 0.013676710390415056 | validation: 0.004152929453395804]
	TIME [epoch: 6.55 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013022950675189538		[learning rate: 0.00020128]
	Learning Rate: 0.000201277
	LOSS [training: 0.013022950675189538 | validation: 0.0007801901541714517]
	TIME [epoch: 6.55 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011310998321519257		[learning rate: 0.0002008]
	Learning Rate: 0.000200803
	LOSS [training: 0.011310998321519257 | validation: 0.0035840394430564308]
	TIME [epoch: 6.55 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017799788926488553		[learning rate: 0.00020033]
	Learning Rate: 0.000200329
	LOSS [training: 0.017799788926488553 | validation: 0.0017812603073873957]
	TIME [epoch: 6.56 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021834880440275466		[learning rate: 0.00019986]
	Learning Rate: 0.000199856
	LOSS [training: 0.021834880440275466 | validation: 0.0014559484633862247]
	TIME [epoch: 6.59 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014790314150177397		[learning rate: 0.00019938]
	Learning Rate: 0.000199385
	LOSS [training: 0.014790314150177397 | validation: -0.0015487791763651388]
	TIME [epoch: 6.56 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010263275641906681		[learning rate: 0.00019891]
	Learning Rate: 0.000198915
	LOSS [training: 0.010263275641906681 | validation: 0.005505252423394509]
	TIME [epoch: 6.55 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0147365531799554		[learning rate: 0.00019845]
	Learning Rate: 0.000198445
	LOSS [training: 0.0147365531799554 | validation: -0.0025960672492681292]
	TIME [epoch: 6.56 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016555639105879764		[learning rate: 0.00019798]
	Learning Rate: 0.000197977
	LOSS [training: 0.016555639105879764 | validation: 0.007145658218918596]
	TIME [epoch: 6.55 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019354369748411284		[learning rate: 0.00019751]
	Learning Rate: 0.00019751
	LOSS [training: 0.019354369748411284 | validation: 0.00700689243063835]
	TIME [epoch: 6.59 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01518044278835215		[learning rate: 0.00019704]
	Learning Rate: 0.000197044
	LOSS [training: 0.01518044278835215 | validation: 0.004031153390199021]
	TIME [epoch: 6.56 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015264911845499529		[learning rate: 0.00019658]
	Learning Rate: 0.00019658
	LOSS [training: 0.015264911845499529 | validation: 0.002270538876638914]
	TIME [epoch: 6.55 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012648764365404186		[learning rate: 0.00019612]
	Learning Rate: 0.000196116
	LOSS [training: 0.012648764365404186 | validation: 0.009243226272841666]
	TIME [epoch: 6.55 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016861343414532548		[learning rate: 0.00019565]
	Learning Rate: 0.000195653
	LOSS [training: 0.016861343414532548 | validation: 0.005551908596631168]
	TIME [epoch: 6.55 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02603323546874936		[learning rate: 0.00019519]
	Learning Rate: 0.000195192
	LOSS [training: 0.02603323546874936 | validation: 0.008653318394257311]
	TIME [epoch: 6.58 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031096614670443123		[learning rate: 0.00019473]
	Learning Rate: 0.000194731
	LOSS [training: 0.031096614670443123 | validation: 0.012231081075666195]
	TIME [epoch: 6.56 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023660873427606005		[learning rate: 0.00019427]
	Learning Rate: 0.000194272
	LOSS [training: 0.023660873427606005 | validation: 0.009832166116215107]
	TIME [epoch: 6.54 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017093706367782426		[learning rate: 0.00019381]
	Learning Rate: 0.000193814
	LOSS [training: 0.017093706367782426 | validation: 0.004745558748535489]
	TIME [epoch: 6.55 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011825516088796336		[learning rate: 0.00019336]
	Learning Rate: 0.000193357
	LOSS [training: 0.011825516088796336 | validation: 0.001715243081441175]
	TIME [epoch: 6.55 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01821058293648734		[learning rate: 0.0001929]
	Learning Rate: 0.0001929
	LOSS [training: 0.01821058293648734 | validation: 0.0016700599061017212]
	TIME [epoch: 6.58 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.007927360552275782		[learning rate: 0.00019245]
	Learning Rate: 0.000192445
	LOSS [training: 0.007927360552275782 | validation: -0.0004336353440246594]
	TIME [epoch: 6.56 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017006412161763285		[learning rate: 0.00019199]
	Learning Rate: 0.000191992
	LOSS [training: 0.017006412161763285 | validation: 0.011861787394118667]
	TIME [epoch: 6.55 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02482429908420162		[learning rate: 0.00019154]
	Learning Rate: 0.000191539
	LOSS [training: 0.02482429908420162 | validation: 0.003695078398021588]
	TIME [epoch: 6.55 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01611870902385824		[learning rate: 0.00019109]
	Learning Rate: 0.000191087
	LOSS [training: 0.01611870902385824 | validation: 0.005554026650349102]
	TIME [epoch: 6.54 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009113175284553406		[learning rate: 0.00019064]
	Learning Rate: 0.000190636
	LOSS [training: 0.009113175284553406 | validation: 0.006905048051756722]
	TIME [epoch: 6.56 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014408734124727696		[learning rate: 0.00019019]
	Learning Rate: 0.000190186
	LOSS [training: 0.014408734124727696 | validation: 0.002694032769236389]
	TIME [epoch: 6.58 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01174847386902166		[learning rate: 0.00018974]
	Learning Rate: 0.000189738
	LOSS [training: 0.01174847386902166 | validation: -0.0025230427941937052]
	TIME [epoch: 6.55 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01014045618277853		[learning rate: 0.00018929]
	Learning Rate: 0.00018929
	LOSS [training: 0.01014045618277853 | validation: 0.0025437797751968914]
	TIME [epoch: 6.54 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01386863841223552		[learning rate: 0.00018884]
	Learning Rate: 0.000188844
	LOSS [training: 0.01386863841223552 | validation: 0.0004517452408014013]
	TIME [epoch: 6.55 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012924370870485489		[learning rate: 0.0001884]
	Learning Rate: 0.000188398
	LOSS [training: 0.012924370870485489 | validation: 0.002686313202592236]
	TIME [epoch: 6.55 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01097587007452135		[learning rate: 0.00018795]
	Learning Rate: 0.000187954
	LOSS [training: 0.01097587007452135 | validation: 0.007686490226915264]
	TIME [epoch: 6.58 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.002800054158654522		[learning rate: 0.00018751]
	Learning Rate: 0.000187511
	LOSS [training: 0.002800054158654522 | validation: 2.0238239890598412e-05]
	TIME [epoch: 6.55 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.006040266057521837		[learning rate: 0.00018707]
	Learning Rate: 0.000187068
	LOSS [training: 0.006040266057521837 | validation: 0.006484408499486358]
	TIME [epoch: 6.55 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01237167843325736		[learning rate: 0.00018663]
	Learning Rate: 0.000186627
	LOSS [training: 0.01237167843325736 | validation: 0.004589891937119561]
	TIME [epoch: 6.55 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013046066627497212		[learning rate: 0.00018619]
	Learning Rate: 0.000186187
	LOSS [training: 0.013046066627497212 | validation: -0.004468047630902784]
	TIME [epoch: 6.54 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013487827200649578		[learning rate: 0.00018575]
	Learning Rate: 0.000185748
	LOSS [training: 0.013487827200649578 | validation: 0.0005133766321110205]
	TIME [epoch: 6.59 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.007379244222190199		[learning rate: 0.00018531]
	Learning Rate: 0.000185309
	LOSS [training: 0.007379244222190199 | validation: -0.0002573823952135984]
	TIME [epoch: 6.56 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01246091086128492		[learning rate: 0.00018487]
	Learning Rate: 0.000184872
	LOSS [training: 0.01246091086128492 | validation: 0.010476922694955565]
	TIME [epoch: 6.55 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016304803310200865		[learning rate: 0.00018444]
	Learning Rate: 0.000184436
	LOSS [training: 0.016304803310200865 | validation: 0.00046096673273896514]
	TIME [epoch: 6.55 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013609540368521095		[learning rate: 0.000184]
	Learning Rate: 0.000184001
	LOSS [training: 0.013609540368521095 | validation: 0.00828615594348287]
	TIME [epoch: 6.55 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018312410743426644		[learning rate: 0.00018357]
	Learning Rate: 0.000183567
	LOSS [training: 0.018312410743426644 | validation: 0.018447427797963024]
	TIME [epoch: 6.58 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019155766545000275		[learning rate: 0.00018313]
	Learning Rate: 0.000183134
	LOSS [training: 0.019155766545000275 | validation: 0.00812690081395003]
	TIME [epoch: 6.56 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012232952961873501		[learning rate: 0.0001827]
	Learning Rate: 0.000182702
	LOSS [training: 0.012232952961873501 | validation: 0.0034943474057722384]
	TIME [epoch: 6.54 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009488235221529206		[learning rate: 0.00018227]
	Learning Rate: 0.000182271
	LOSS [training: 0.009488235221529206 | validation: 0.008720931965063577]
	TIME [epoch: 6.55 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014061412785524335		[learning rate: 0.00018184]
	Learning Rate: 0.000181841
	LOSS [training: 0.014061412785524335 | validation: -0.00016258256975258158]
	TIME [epoch: 6.55 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.008723968723277761		[learning rate: 0.00018141]
	Learning Rate: 0.000181412
	LOSS [training: 0.008723968723277761 | validation: -0.002798441138760076]
	TIME [epoch: 6.55 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010267059449399787		[learning rate: 0.00018098]
	Learning Rate: 0.000180984
	LOSS [training: 0.010267059449399787 | validation: 0.003093819319276522]
	TIME [epoch: 6.58 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011823998571808648		[learning rate: 0.00018056]
	Learning Rate: 0.000180557
	LOSS [training: 0.011823998571808648 | validation: 0.0021781832456143416]
	TIME [epoch: 6.55 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009270108208535296		[learning rate: 0.00018013]
	Learning Rate: 0.000180132
	LOSS [training: 0.009270108208535296 | validation: 0.011715572591560669]
	TIME [epoch: 6.55 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011596761845480572		[learning rate: 0.00017971]
	Learning Rate: 0.000179707
	LOSS [training: 0.011596761845480572 | validation: 0.010293768549757073]
	TIME [epoch: 6.54 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01353524431920404		[learning rate: 0.00017928]
	Learning Rate: 0.000179283
	LOSS [training: 0.01353524431920404 | validation: 0.007970641860825294]
	TIME [epoch: 6.55 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011778928587907042		[learning rate: 0.00017886]
	Learning Rate: 0.00017886
	LOSS [training: 0.011778928587907042 | validation: 0.009988311598354182]
	TIME [epoch: 6.58 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011673946193692669		[learning rate: 0.00017844]
	Learning Rate: 0.000178438
	LOSS [training: 0.011673946193692669 | validation: -0.001318804236653432]
	TIME [epoch: 6.55 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014403531464601573		[learning rate: 0.00017802]
	Learning Rate: 0.000178017
	LOSS [training: 0.014403531464601573 | validation: 0.007216962597136063]
	TIME [epoch: 6.55 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012946762666538741		[learning rate: 0.0001776]
	Learning Rate: 0.000177597
	LOSS [training: 0.012946762666538741 | validation: 0.002968031359364162]
	TIME [epoch: 6.55 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011633740944250319		[learning rate: 0.00017718]
	Learning Rate: 0.000177178
	LOSS [training: 0.011633740944250319 | validation: 0.005113367848439311]
	TIME [epoch: 6.54 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010878823147695373		[learning rate: 0.00017676]
	Learning Rate: 0.00017676
	LOSS [training: 0.010878823147695373 | validation: 0.0029740921241254944]
	TIME [epoch: 6.58 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014085146928080144		[learning rate: 0.00017634]
	Learning Rate: 0.000176343
	LOSS [training: 0.014085146928080144 | validation: 0.00799694945763785]
	TIME [epoch: 6.55 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014493626480550095		[learning rate: 0.00017593]
	Learning Rate: 0.000175927
	LOSS [training: 0.014493626480550095 | validation: -0.0050673359893176435]
	TIME [epoch: 6.54 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012178333595791452		[learning rate: 0.00017551]
	Learning Rate: 0.000175512
	LOSS [training: 0.012178333595791452 | validation: 0.014067075206790451]
	TIME [epoch: 6.54 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013156464398736176		[learning rate: 0.0001751]
	Learning Rate: 0.000175098
	LOSS [training: 0.013156464398736176 | validation: 0.013799570872339288]
	TIME [epoch: 6.54 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015719777188491234		[learning rate: 0.00017469]
	Learning Rate: 0.000174685
	LOSS [training: 0.015719777188491234 | validation: 0.008237217398366381]
	TIME [epoch: 6.58 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010082631270728826		[learning rate: 0.00017427]
	Learning Rate: 0.000174273
	LOSS [training: 0.010082631270728826 | validation: 0.004762495684630979]
	TIME [epoch: 6.56 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013475274266262738		[learning rate: 0.00017386]
	Learning Rate: 0.000173862
	LOSS [training: 0.013475274266262738 | validation: 0.009252516535481415]
	TIME [epoch: 6.54 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014552921156816894		[learning rate: 0.00017345]
	Learning Rate: 0.000173452
	LOSS [training: 0.014552921156816894 | validation: 0.0066521634053447465]
	TIME [epoch: 6.55 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009939429917377349		[learning rate: 0.00017304]
	Learning Rate: 0.000173043
	LOSS [training: 0.009939429917377349 | validation: 0.0014971589899901577]
	TIME [epoch: 6.54 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0127744953990924		[learning rate: 0.00017263]
	Learning Rate: 0.000172635
	LOSS [training: 0.0127744953990924 | validation: 0.00801754159301089]
	TIME [epoch: 6.56 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011910331808609642		[learning rate: 0.00017223]
	Learning Rate: 0.000172228
	LOSS [training: 0.011910331808609642 | validation: 0.012280987602234018]
	TIME [epoch: 6.57 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.00894000054437522		[learning rate: 0.00017182]
	Learning Rate: 0.000171821
	LOSS [training: 0.00894000054437522 | validation: -0.0005239694746720317]
	TIME [epoch: 6.55 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009658086661745894		[learning rate: 0.00017142]
	Learning Rate: 0.000171416
	LOSS [training: 0.009658086661745894 | validation: -6.410180747083889e-05]
	TIME [epoch: 6.55 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.00800723793397556		[learning rate: 0.00017101]
	Learning Rate: 0.000171012
	LOSS [training: 0.00800723793397556 | validation: -0.0029493247447473607]
	TIME [epoch: 6.55 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.006095915069142763		[learning rate: 0.00017061]
	Learning Rate: 0.000170608
	LOSS [training: 0.006095915069142763 | validation: 0.00558223680265585]
	TIME [epoch: 6.55 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012229409101489855		[learning rate: 0.00017021]
	Learning Rate: 0.000170206
	LOSS [training: 0.012229409101489855 | validation: -0.002497565789773189]
	TIME [epoch: 6.59 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013505017742575606		[learning rate: 0.0001698]
	Learning Rate: 0.000169804
	LOSS [training: 0.013505017742575606 | validation: 0.004430218447811246]
	TIME [epoch: 6.56 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.008266405561946386		[learning rate: 0.0001694]
	Learning Rate: 0.000169404
	LOSS [training: 0.008266405561946386 | validation: 0.0051998694640922796]
	TIME [epoch: 6.54 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010209932045524502		[learning rate: 0.000169]
	Learning Rate: 0.000169004
	LOSS [training: 0.010209932045524502 | validation: -0.0003496599201522118]
	TIME [epoch: 6.54 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.008773874788355422		[learning rate: 0.00016861]
	Learning Rate: 0.000168606
	LOSS [training: 0.008773874788355422 | validation: -0.0006878982344921038]
	TIME [epoch: 6.54 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014358793232794589		[learning rate: 0.00016821]
	Learning Rate: 0.000168208
	LOSS [training: 0.014358793232794589 | validation: 0.0016438898668261403]
	TIME [epoch: 6.59 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009251610806021176		[learning rate: 0.00016781]
	Learning Rate: 0.000167811
	LOSS [training: 0.009251610806021176 | validation: 0.004032832334467421]
	TIME [epoch: 6.55 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011349618181558186		[learning rate: 0.00016742]
	Learning Rate: 0.000167415
	LOSS [training: 0.011349618181558186 | validation: -0.0008024283781349721]
	TIME [epoch: 6.55 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.008470436970572478		[learning rate: 0.00016702]
	Learning Rate: 0.00016702
	LOSS [training: 0.008470436970572478 | validation: 0.0022619542803566416]
	TIME [epoch: 6.55 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011799226494722693		[learning rate: 0.00016663]
	Learning Rate: 0.000166626
	LOSS [training: 0.011799226494722693 | validation: 0.008496705430508626]
	TIME [epoch: 6.55 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014288669104578502		[learning rate: 0.00016623]
	Learning Rate: 0.000166233
	LOSS [training: 0.014288669104578502 | validation: 0.009616003777240112]
	TIME [epoch: 6.58 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011068883198512713		[learning rate: 0.00016584]
	Learning Rate: 0.000165841
	LOSS [training: 0.011068883198512713 | validation: -0.001862624488737226]
	TIME [epoch: 6.55 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015145869791778488		[learning rate: 0.00016545]
	Learning Rate: 0.00016545
	LOSS [training: 0.015145869791778488 | validation: 0.004923016268579881]
	TIME [epoch: 6.55 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019336194870365024		[learning rate: 0.00016506]
	Learning Rate: 0.00016506
	LOSS [training: 0.019336194870365024 | validation: 0.004580159538746072]
	TIME [epoch: 6.54 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01444700423225021		[learning rate: 0.00016467]
	Learning Rate: 0.00016467
	LOSS [training: 0.01444700423225021 | validation: -0.006544818189021671]
	TIME [epoch: 6.55 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011153705679416476		[learning rate: 0.00016428]
	Learning Rate: 0.000164282
	LOSS [training: 0.011153705679416476 | validation: 0.0006394748328479513]
	TIME [epoch: 6.58 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017791618350727956		[learning rate: 0.00016389]
	Learning Rate: 0.000163894
	LOSS [training: 0.017791618350727956 | validation: 0.012278050372923639]
	TIME [epoch: 6.56 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027489304672705307		[learning rate: 0.00016351]
	Learning Rate: 0.000163508
	LOSS [training: 0.027489304672705307 | validation: 0.018403313580222715]
	TIME [epoch: 6.55 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02339583482179649		[learning rate: 0.00016312]
	Learning Rate: 0.000163122
	LOSS [training: 0.02339583482179649 | validation: 0.005227358250020224]
	TIME [epoch: 6.54 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017760581674117853		[learning rate: 0.00016274]
	Learning Rate: 0.000162737
	LOSS [training: 0.017760581674117853 | validation: 0.015440416648877086]
	TIME [epoch: 6.54 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015201546398366428		[learning rate: 0.00016235]
	Learning Rate: 0.000162353
	LOSS [training: 0.015201546398366428 | validation: 0.007686327020407091]
	TIME [epoch: 6.56 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016500630544093575		[learning rate: 0.00016197]
	Learning Rate: 0.00016197
	LOSS [training: 0.016500630544093575 | validation: 0.011551858027726987]
	TIME [epoch: 6.57 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01038600044914517		[learning rate: 0.00016159]
	Learning Rate: 0.000161588
	LOSS [training: 0.01038600044914517 | validation: 0.0011660427783776054]
	TIME [epoch: 6.55 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013765213011538602		[learning rate: 0.00016121]
	Learning Rate: 0.000161207
	LOSS [training: 0.013765213011538602 | validation: -0.0005146216818051209]
	TIME [epoch: 6.55 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010792561043365843		[learning rate: 0.00016083]
	Learning Rate: 0.000160827
	LOSS [training: 0.010792561043365843 | validation: 0.006087717175750983]
	TIME [epoch: 6.54 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01256774139367422		[learning rate: 0.00016045]
	Learning Rate: 0.000160448
	LOSS [training: 0.01256774139367422 | validation: -0.006714245707959984]
	TIME [epoch: 6.55 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011202159622723482		[learning rate: 0.00016007]
	Learning Rate: 0.000160069
	LOSS [training: 0.011202159622723482 | validation: 0.004304658787166042]
	TIME [epoch: 6.59 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014431487964063761		[learning rate: 0.00015969]
	Learning Rate: 0.000159692
	LOSS [training: 0.014431487964063761 | validation: 0.0051302882409316585]
	TIME [epoch: 6.55 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013345015954579995		[learning rate: 0.00015931]
	Learning Rate: 0.000159315
	LOSS [training: 0.013345015954579995 | validation: 0.006958071195324805]
	TIME [epoch: 6.55 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012063928957686411		[learning rate: 0.00015894]
	Learning Rate: 0.000158939
	LOSS [training: 0.012063928957686411 | validation: 0.0003066122709195285]
	TIME [epoch: 6.55 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014251004431894998		[learning rate: 0.00015856]
	Learning Rate: 0.000158564
	LOSS [training: 0.014251004431894998 | validation: 0.012278489135702527]
	TIME [epoch: 6.54 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01421436818515524		[learning rate: 0.00015819]
	Learning Rate: 0.00015819
	LOSS [training: 0.01421436818515524 | validation: -0.004195798480128116]
	TIME [epoch: 6.58 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009945839583330821		[learning rate: 0.00015782]
	Learning Rate: 0.000157817
	LOSS [training: 0.009945839583330821 | validation: 0.010215845386525618]
	TIME [epoch: 6.55 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010255520113235255		[learning rate: 0.00015744]
	Learning Rate: 0.000157445
	LOSS [training: 0.010255520113235255 | validation: 9.330157884780612e-05]
	TIME [epoch: 6.55 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011981088274023482		[learning rate: 0.00015707]
	Learning Rate: 0.000157073
	LOSS [training: 0.011981088274023482 | validation: -0.00031199285452881455]
	TIME [epoch: 6.54 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01191432441863674		[learning rate: 0.0001567]
	Learning Rate: 0.000156703
	LOSS [training: 0.01191432441863674 | validation: 0.013941769724311931]
	TIME [epoch: 6.54 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014219631672992736		[learning rate: 0.00015633]
	Learning Rate: 0.000156333
	LOSS [training: 0.014219631672992736 | validation: 0.00594779090940057]
	TIME [epoch: 6.58 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.020066008075535307		[learning rate: 0.00015596]
	Learning Rate: 0.000155964
	LOSS [training: 0.020066008075535307 | validation: 0.007638419368523563]
	TIME [epoch: 6.56 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014712406862369336		[learning rate: 0.0001556]
	Learning Rate: 0.000155597
	LOSS [training: 0.014712406862369336 | validation: 0.007401518084739121]
	TIME [epoch: 6.54 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016422195520772898		[learning rate: 0.00015523]
	Learning Rate: 0.00015523
	LOSS [training: 0.016422195520772898 | validation: 0.0159568218750719]
	TIME [epoch: 6.55 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01984939220555795		[learning rate: 0.00015486]
	Learning Rate: 0.000154863
	LOSS [training: 0.01984939220555795 | validation: 0.007189283905365556]
	TIME [epoch: 6.54 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017589574966076223		[learning rate: 0.0001545]
	Learning Rate: 0.000154498
	LOSS [training: 0.017589574966076223 | validation: 0.00397752553338464]
	TIME [epoch: 6.56 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018212657577587627		[learning rate: 0.00015413]
	Learning Rate: 0.000154134
	LOSS [training: 0.018212657577587627 | validation: 0.009440168828262516]
	TIME [epoch: 6.58 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01873578208775835		[learning rate: 0.00015377]
	Learning Rate: 0.00015377
	LOSS [training: 0.01873578208775835 | validation: 0.012601056901676474]
	TIME [epoch: 6.55 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018067704453764055		[learning rate: 0.00015341]
	Learning Rate: 0.000153407
	LOSS [training: 0.018067704453764055 | validation: 0.0127438510771302]
	TIME [epoch: 6.54 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026393191596098663		[learning rate: 0.00015305]
	Learning Rate: 0.000153045
	LOSS [training: 0.026393191596098663 | validation: 0.01308068387022071]
	TIME [epoch: 6.55 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019910642534024817		[learning rate: 0.00015268]
	Learning Rate: 0.000152684
	LOSS [training: 0.019910642534024817 | validation: 0.007575211204015956]
	TIME [epoch: 6.55 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019080989856829468		[learning rate: 0.00015232]
	Learning Rate: 0.000152324
	LOSS [training: 0.019080989856829468 | validation: 0.009502390302125015]
	TIME [epoch: 6.58 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013142010983652891		[learning rate: 0.00015196]
	Learning Rate: 0.000151965
	LOSS [training: 0.013142010983652891 | validation: 0.001656974164305331]
	TIME [epoch: 6.56 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010088616688952608		[learning rate: 0.00015161]
	Learning Rate: 0.000151607
	LOSS [training: 0.010088616688952608 | validation: 0.0011667437697698065]
	TIME [epoch: 6.55 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01040439468602233		[learning rate: 0.00015125]
	Learning Rate: 0.000151249
	LOSS [training: 0.01040439468602233 | validation: 0.0027227105670767438]
	TIME [epoch: 6.55 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.00968781466444837		[learning rate: 0.00015089]
	Learning Rate: 0.000150892
	LOSS [training: 0.00968781466444837 | validation: 0.0035156833961122467]
	TIME [epoch: 6.55 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011760553770004529		[learning rate: 0.00015054]
	Learning Rate: 0.000150536
	LOSS [training: 0.011760553770004529 | validation: 0.0007687352658515235]
	TIME [epoch: 6.59 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009422438003235485		[learning rate: 0.00015018]
	Learning Rate: 0.000150181
	LOSS [training: 0.009422438003235485 | validation: 0.004849007400834424]
	TIME [epoch: 6.56 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01018200043639654		[learning rate: 0.00014983]
	Learning Rate: 0.000149827
	LOSS [training: 0.01018200043639654 | validation: 0.0018954418328345256]
	TIME [epoch: 6.55 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018359006979085477		[learning rate: 0.00014947]
	Learning Rate: 0.000149473
	LOSS [training: 0.018359006979085477 | validation: 0.011171880962697096]
	TIME [epoch: 6.55 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010187359632701112		[learning rate: 0.00014912]
	Learning Rate: 0.000149121
	LOSS [training: 0.010187359632701112 | validation: -0.0006843608024307505]
	TIME [epoch: 6.55 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010571366301052718		[learning rate: 0.00014877]
	Learning Rate: 0.000148769
	LOSS [training: 0.010571366301052718 | validation: 0.006260123846054461]
	TIME [epoch: 6.58 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012280695737938574		[learning rate: 0.00014842]
	Learning Rate: 0.000148418
	LOSS [training: 0.012280695737938574 | validation: 0.012018286119094715]
	TIME [epoch: 6.56 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012533422363860399		[learning rate: 0.00014807]
	Learning Rate: 0.000148068
	LOSS [training: 0.012533422363860399 | validation: 0.00360836025073565]
	TIME [epoch: 6.55 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018001437637082875		[learning rate: 0.00014772]
	Learning Rate: 0.000147719
	LOSS [training: 0.018001437637082875 | validation: -0.006185639967217772]
	TIME [epoch: 6.55 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.008714918837105247		[learning rate: 0.00014737]
	Learning Rate: 0.00014737
	LOSS [training: 0.008714918837105247 | validation: 0.002633996903748502]
	TIME [epoch: 6.55 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015276864702750678		[learning rate: 0.00014702]
	Learning Rate: 0.000147023
	LOSS [training: 0.015276864702750678 | validation: 0.0011429929737380691]
	TIME [epoch: 6.55 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.007422450971803084		[learning rate: 0.00014668]
	Learning Rate: 0.000146676
	LOSS [training: 0.007422450971803084 | validation: -0.0005358685632501142]
	TIME [epoch: 6.58 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01328617018389657		[learning rate: 0.00014633]
	Learning Rate: 0.00014633
	LOSS [training: 0.01328617018389657 | validation: 0.007346764757000106]
	TIME [epoch: 6.55 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009462169765509301		[learning rate: 0.00014598]
	Learning Rate: 0.000145985
	LOSS [training: 0.009462169765509301 | validation: 0.004545810195605807]
	TIME [epoch: 6.55 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016293665173137163		[learning rate: 0.00014564]
	Learning Rate: 0.00014564
	LOSS [training: 0.016293665173137163 | validation: 0.001887087746195788]
	TIME [epoch: 6.55 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01401420931077386		[learning rate: 0.0001453]
	Learning Rate: 0.000145297
	LOSS [training: 0.01401420931077386 | validation: 0.0013891307980037904]
	TIME [epoch: 6.55 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014618087007623487		[learning rate: 0.00014495]
	Learning Rate: 0.000144954
	LOSS [training: 0.014618087007623487 | validation: -0.00385534658309128]
	TIME [epoch: 6.59 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01294639111696062		[learning rate: 0.00014461]
	Learning Rate: 0.000144612
	LOSS [training: 0.01294639111696062 | validation: 0.012566184298836262]
	TIME [epoch: 6.55 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010543050330142254		[learning rate: 0.00014427]
	Learning Rate: 0.000144271
	LOSS [training: 0.010543050330142254 | validation: -0.007037104766103722]
	TIME [epoch: 6.55 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240223_172814/states/model_phi2_1a_v1_1845.pth
	Model improved!!!
EPOCH 1846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012268073420382346		[learning rate: 0.00014393]
	Learning Rate: 0.000143931
	LOSS [training: 0.012268073420382346 | validation: 0.0038450110415655415]
	TIME [epoch: 6.56 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01783751648777219		[learning rate: 0.00014359]
	Learning Rate: 0.000143591
	LOSS [training: 0.01783751648777219 | validation: 0.004764240526157144]
	TIME [epoch: 6.57 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013596244381103299		[learning rate: 0.00014325]
	Learning Rate: 0.000143253
	LOSS [training: 0.013596244381103299 | validation: 0.0006008434605761946]
	TIME [epoch: 6.6 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011617301448467052		[learning rate: 0.00014291]
	Learning Rate: 0.000142915
	LOSS [training: 0.011617301448467052 | validation: 0.0014484023721741835]
	TIME [epoch: 6.57 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.00336135919683874		[learning rate: 0.00014258]
	Learning Rate: 0.000142578
	LOSS [training: 0.00336135919683874 | validation: -0.0019854492990046234]
	TIME [epoch: 6.57 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01256316616833478		[learning rate: 0.00014224]
	Learning Rate: 0.000142241
	LOSS [training: 0.01256316616833478 | validation: 0.0008666737805567391]
	TIME [epoch: 6.57 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0140069643631757		[learning rate: 0.00014191]
	Learning Rate: 0.000141906
	LOSS [training: 0.0140069643631757 | validation: 0.004438104011614397]
	TIME [epoch: 6.57 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011476341603357126		[learning rate: 0.00014157]
	Learning Rate: 0.000141571
	LOSS [training: 0.011476341603357126 | validation: 0.002954158996532348]
	TIME [epoch: 6.6 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014367007462431348		[learning rate: 0.00014124]
	Learning Rate: 0.000141237
	LOSS [training: 0.014367007462431348 | validation: 0.0015913661657623022]
	TIME [epoch: 6.57 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01143834396831299		[learning rate: 0.0001409]
	Learning Rate: 0.000140904
	LOSS [training: 0.01143834396831299 | validation: -0.005205924607684467]
	TIME [epoch: 6.57 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013128286534603028		[learning rate: 0.00014057]
	Learning Rate: 0.000140572
	LOSS [training: 0.013128286534603028 | validation: 0.009751829710529469]
	TIME [epoch: 6.57 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010783143145011328		[learning rate: 0.00014024]
	Learning Rate: 0.00014024
	LOSS [training: 0.010783143145011328 | validation: 0.007725866186453332]
	TIME [epoch: 6.57 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011806011817687546		[learning rate: 0.00013991]
	Learning Rate: 0.000139909
	LOSS [training: 0.011806011817687546 | validation: 0.004565898214584275]
	TIME [epoch: 6.6 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013868476845038216		[learning rate: 0.00013958]
	Learning Rate: 0.000139579
	LOSS [training: 0.013868476845038216 | validation: 0.001539650396865903]
	TIME [epoch: 6.58 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012770456956933147		[learning rate: 0.00013925]
	Learning Rate: 0.00013925
	LOSS [training: 0.012770456956933147 | validation: 0.005301592362200506]
	TIME [epoch: 6.57 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014956977932741797		[learning rate: 0.00013892]
	Learning Rate: 0.000138921
	LOSS [training: 0.014956977932741797 | validation: 0.005889059056000059]
	TIME [epoch: 6.57 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01347668107579598		[learning rate: 0.00013859]
	Learning Rate: 0.000138594
	LOSS [training: 0.01347668107579598 | validation: 0.0024902795330619385]
	TIME [epoch: 6.57 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011701533355401134		[learning rate: 0.00013827]
	Learning Rate: 0.000138267
	LOSS [training: 0.011701533355401134 | validation: 0.005182854003555874]
	TIME [epoch: 6.58 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010335612861155741		[learning rate: 0.00013794]
	Learning Rate: 0.000137941
	LOSS [training: 0.010335612861155741 | validation: 0.013661917883381596]
	TIME [epoch: 6.59 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011387405251941329		[learning rate: 0.00013762]
	Learning Rate: 0.000137615
	LOSS [training: 0.011387405251941329 | validation: 0.0058579858832980575]
	TIME [epoch: 6.57 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012358385850595685		[learning rate: 0.00013729]
	Learning Rate: 0.000137291
	LOSS [training: 0.012358385850595685 | validation: 0.00027063938317301896]
	TIME [epoch: 6.56 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011436746164263949		[learning rate: 0.00013697]
	Learning Rate: 0.000136967
	LOSS [training: 0.011436746164263949 | validation: 0.003531118311399832]
	TIME [epoch: 6.57 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.007210460253488232		[learning rate: 0.00013664]
	Learning Rate: 0.000136644
	LOSS [training: 0.007210460253488232 | validation: -0.004299321436514935]
	TIME [epoch: 6.57 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0062950809769545		[learning rate: 0.00013632]
	Learning Rate: 0.000136321
	LOSS [training: 0.0062950809769545 | validation: 0.0003901728771110516]
	TIME [epoch: 6.61 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012024272910937685		[learning rate: 0.000136]
	Learning Rate: 0.000136
	LOSS [training: 0.012024272910937685 | validation: 0.005288474982785358]
	TIME [epoch: 6.57 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011385415782541033		[learning rate: 0.00013568]
	Learning Rate: 0.000135679
	LOSS [training: 0.011385415782541033 | validation: 0.014020670931111449]
	TIME [epoch: 6.56 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01411292395875004		[learning rate: 0.00013536]
	Learning Rate: 0.000135359
	LOSS [training: 0.01411292395875004 | validation: 0.00299374095878621]
	TIME [epoch: 6.57 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015265518348925828		[learning rate: 0.00013504]
	Learning Rate: 0.00013504
	LOSS [training: 0.015265518348925828 | validation: 0.001407527741276414]
	TIME [epoch: 6.57 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.007516143403780569		[learning rate: 0.00013472]
	Learning Rate: 0.000134721
	LOSS [training: 0.007516143403780569 | validation: 0.0018184233843478005]
	TIME [epoch: 6.61 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.008166175849341402		[learning rate: 0.0001344]
	Learning Rate: 0.000134403
	LOSS [training: 0.008166175849341402 | validation: -0.0031037684064813007]
	TIME [epoch: 6.57 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0127689987529716		[learning rate: 0.00013409]
	Learning Rate: 0.000134086
	LOSS [training: 0.0127689987529716 | validation: 0.0018120943708570796]
	TIME [epoch: 6.56 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.007485131132470499		[learning rate: 0.00013377]
	Learning Rate: 0.00013377
	LOSS [training: 0.007485131132470499 | validation: 0.0024790929827303012]
	TIME [epoch: 6.56 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0059228047842495865		[learning rate: 0.00013345]
	Learning Rate: 0.000133455
	LOSS [training: 0.0059228047842495865 | validation: 0.005874196820270192]
	TIME [epoch: 6.56 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.00892070257671017		[learning rate: 0.00013314]
	Learning Rate: 0.00013314
	LOSS [training: 0.00892070257671017 | validation: 0.004444002027578064]
	TIME [epoch: 6.6 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009220813613702954		[learning rate: 0.00013283]
	Learning Rate: 0.000132826
	LOSS [training: 0.009220813613702954 | validation: 0.0032841536035295507]
	TIME [epoch: 6.58 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010862257084943755		[learning rate: 0.00013251]
	Learning Rate: 0.000132512
	LOSS [training: 0.010862257084943755 | validation: -0.0025985410933118316]
	TIME [epoch: 6.56 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010935488414668135		[learning rate: 0.0001322]
	Learning Rate: 0.0001322
	LOSS [training: 0.010935488414668135 | validation: 0.0008528713013182827]
	TIME [epoch: 6.57 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.00827397778109309		[learning rate: 0.00013189]
	Learning Rate: 0.000131888
	LOSS [training: 0.00827397778109309 | validation: -0.002767886505844699]
	TIME [epoch: 6.57 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012432362958943857		[learning rate: 0.00013158]
	Learning Rate: 0.000131577
	LOSS [training: 0.012432362958943857 | validation: 0.007590558074172377]
	TIME [epoch: 6.59 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01205828747962066		[learning rate: 0.00013127]
	Learning Rate: 0.000131266
	LOSS [training: 0.01205828747962066 | validation: -0.003860129292711072]
	TIME [epoch: 6.58 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009422790912895765		[learning rate: 0.00013096]
	Learning Rate: 0.000130957
	LOSS [training: 0.009422790912895765 | validation: 0.0015571725624399626]
	TIME [epoch: 6.57 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014489561966212091		[learning rate: 0.00013065]
	Learning Rate: 0.000130648
	LOSS [training: 0.014489561966212091 | validation: 0.0027133253332023146]
	TIME [epoch: 6.56 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011960916023158723		[learning rate: 0.00013034]
	Learning Rate: 0.00013034
	LOSS [training: 0.011960916023158723 | validation: 0.0017321791170573295]
	TIME [epoch: 6.57 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012986566272999798		[learning rate: 0.00013003]
	Learning Rate: 0.000130032
	LOSS [training: 0.012986566272999798 | validation: 0.00031040972530551377]
	TIME [epoch: 6.57 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011642490209724268		[learning rate: 0.00012973]
	Learning Rate: 0.000129726
	LOSS [training: 0.011642490209724268 | validation: -0.0019706860709802782]
	TIME [epoch: 6.6 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009780438156074786		[learning rate: 0.00012942]
	Learning Rate: 0.00012942
	LOSS [training: 0.009780438156074786 | validation: 0.0035555890912195185]
	TIME [epoch: 6.57 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010953442994496104		[learning rate: 0.00012911]
	Learning Rate: 0.000129114
	LOSS [training: 0.010953442994496104 | validation: 0.008811869301623497]
	TIME [epoch: 6.57 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009321394477560294		[learning rate: 0.00012881]
	Learning Rate: 0.00012881
	LOSS [training: 0.009321394477560294 | validation: 0.0037480832546528337]
	TIME [epoch: 6.56 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016015995334502507		[learning rate: 0.00012851]
	Learning Rate: 0.000128506
	LOSS [training: 0.016015995334502507 | validation: -0.0001605280524554515]
	TIME [epoch: 6.57 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010988210720211156		[learning rate: 0.0001282]
	Learning Rate: 0.000128203
	LOSS [training: 0.010988210720211156 | validation: 0.00919912725789325]
	TIME [epoch: 6.6 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013125235590842211		[learning rate: 0.0001279]
	Learning Rate: 0.0001279
	LOSS [training: 0.013125235590842211 | validation: 0.004941552921674433]
	TIME [epoch: 6.57 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013543188320244893		[learning rate: 0.0001276]
	Learning Rate: 0.000127599
	LOSS [training: 0.013543188320244893 | validation: -0.0014678856047520387]
	TIME [epoch: 6.57 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018536749217888226		[learning rate: 0.0001273]
	Learning Rate: 0.000127298
	LOSS [training: 0.018536749217888226 | validation: 0.006487429657896204]
	TIME [epoch: 6.56 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018584033242986027		[learning rate: 0.000127]
	Learning Rate: 0.000126997
	LOSS [training: 0.018584033242986027 | validation: 0.0036119519327981447]
	TIME [epoch: 6.56 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014954052712769858		[learning rate: 0.0001267]
	Learning Rate: 0.000126698
	LOSS [training: 0.014954052712769858 | validation: 0.005866557519617254]
	TIME [epoch: 6.61 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015030469549472694		[learning rate: 0.0001264]
	Learning Rate: 0.000126399
	LOSS [training: 0.015030469549472694 | validation: 0.006393443675867077]
	TIME [epoch: 6.57 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013746134501994805		[learning rate: 0.0001261]
	Learning Rate: 0.000126101
	LOSS [training: 0.013746134501994805 | validation: 0.0031044582747444902]
	TIME [epoch: 6.57 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.007669675669342624		[learning rate: 0.0001258]
	Learning Rate: 0.000125803
	LOSS [training: 0.007669675669342624 | validation: 0.011373688273742332]
	TIME [epoch: 6.57 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013776435030441075		[learning rate: 0.00012551]
	Learning Rate: 0.000125507
	LOSS [training: 0.013776435030441075 | validation: 0.008684903967085803]
	TIME [epoch: 6.56 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009350994130732553		[learning rate: 0.00012521]
	Learning Rate: 0.000125211
	LOSS [training: 0.009350994130732553 | validation: 0.006610322103557846]
	TIME [epoch: 6.6 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009140765690411529		[learning rate: 0.00012492]
	Learning Rate: 0.000124915
	LOSS [training: 0.009140765690411529 | validation: 0.0018814997322898989]
	TIME [epoch: 6.57 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.008562548173148147		[learning rate: 0.00012462]
	Learning Rate: 0.000124621
	LOSS [training: 0.008562548173148147 | validation: -0.0032530452104457827]
	TIME [epoch: 6.56 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012844387010513741		[learning rate: 0.00012433]
	Learning Rate: 0.000124327
	LOSS [training: 0.012844387010513741 | validation: -0.0018778837496974494]
	TIME [epoch: 6.56 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010608734316340162		[learning rate: 0.00012403]
	Learning Rate: 0.000124033
	LOSS [training: 0.010608734316340162 | validation: 0.0008992715422890141]
	TIME [epoch: 6.56 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.008374399203531276		[learning rate: 0.00012374]
	Learning Rate: 0.000123741
	LOSS [training: 0.008374399203531276 | validation: 0.000650681149847853]
	TIME [epoch: 6.58 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.005831940977279459		[learning rate: 0.00012345]
	Learning Rate: 0.000123449
	LOSS [training: 0.005831940977279459 | validation: 0.00995920120713144]
	TIME [epoch: 6.58 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009848044288553709		[learning rate: 0.00012316]
	Learning Rate: 0.000123158
	LOSS [training: 0.009848044288553709 | validation: 0.004694532903255853]
	TIME [epoch: 6.56 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014101664765772081		[learning rate: 0.00012287]
	Learning Rate: 0.000122867
	LOSS [training: 0.014101664765772081 | validation: -0.0030981872689846215]
	TIME [epoch: 6.56 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01395349882044385		[learning rate: 0.00012258]
	Learning Rate: 0.000122577
	LOSS [training: 0.01395349882044385 | validation: 0.011526042186104445]
	TIME [epoch: 6.56 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021180168438236606		[learning rate: 0.00012229]
	Learning Rate: 0.000122288
	LOSS [training: 0.021180168438236606 | validation: 0.0013262594980767775]
	TIME [epoch: 6.57 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015987101994281154		[learning rate: 0.000122]
	Learning Rate: 0.000122
	LOSS [training: 0.015987101994281154 | validation: 0.005635449194322553]
	TIME [epoch: 6.59 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017734480768657097		[learning rate: 0.00012171]
	Learning Rate: 0.000121712
	LOSS [training: 0.017734480768657097 | validation: 0.002798583375924038]
	TIME [epoch: 6.56 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01227714567190689		[learning rate: 0.00012142]
	Learning Rate: 0.000121425
	LOSS [training: 0.01227714567190689 | validation: 0.0034479391653149125]
	TIME [epoch: 6.56 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009398721164883198		[learning rate: 0.00012114]
	Learning Rate: 0.000121138
	LOSS [training: 0.009398721164883198 | validation: 0.003573427373289838]
	TIME [epoch: 6.56 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010713145039174862		[learning rate: 0.00012085]
	Learning Rate: 0.000120853
	LOSS [training: 0.010713145039174862 | validation: -0.003463072158251075]
	TIME [epoch: 6.56 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009572747501669787		[learning rate: 0.00012057]
	Learning Rate: 0.000120568
	LOSS [training: 0.009572747501669787 | validation: -0.0014713649069352155]
	TIME [epoch: 6.6 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.008613422440678383		[learning rate: 0.00012028]
	Learning Rate: 0.000120283
	LOSS [training: 0.008613422440678383 | validation: 0.0009569775936911834]
	TIME [epoch: 6.56 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011228479203913904		[learning rate: 0.00012]
	Learning Rate: 0.00012
	LOSS [training: 0.011228479203913904 | validation: -0.001414704581706454]
	TIME [epoch: 6.56 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015898850925906642		[learning rate: 0.00011972]
	Learning Rate: 0.000119716
	LOSS [training: 0.015898850925906642 | validation: -0.0028817826845343]
	TIME [epoch: 6.56 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.008653646050131317		[learning rate: 0.00011943]
	Learning Rate: 0.000119434
	LOSS [training: 0.008653646050131317 | validation: 0.012263495429442937]
	TIME [epoch: 6.56 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01001515289718237		[learning rate: 0.00011915]
	Learning Rate: 0.000119152
	LOSS [training: 0.01001515289718237 | validation: 0.002380068291863489]
	TIME [epoch: 6.6 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012348554883050079		[learning rate: 0.00011887]
	Learning Rate: 0.000118871
	LOSS [training: 0.012348554883050079 | validation: 0.004672933639530769]
	TIME [epoch: 6.57 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010594027448361343		[learning rate: 0.00011859]
	Learning Rate: 0.000118591
	LOSS [training: 0.010594027448361343 | validation: 0.0011751090964509424]
	TIME [epoch: 6.56 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011182634076437357		[learning rate: 0.00011831]
	Learning Rate: 0.000118311
	LOSS [training: 0.011182634076437357 | validation: 0.003265595645389947]
	TIME [epoch: 6.56 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.008177721280144526		[learning rate: 0.00011803]
	Learning Rate: 0.000118032
	LOSS [training: 0.008177721280144526 | validation: 0.012154718763638123]
	TIME [epoch: 6.56 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014102446330484197		[learning rate: 0.00011775]
	Learning Rate: 0.000117754
	LOSS [training: 0.014102446330484197 | validation: 0.011148244770014398]
	TIME [epoch: 6.59 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019394358137950825		[learning rate: 0.00011748]
	Learning Rate: 0.000117476
	LOSS [training: 0.019394358137950825 | validation: 0.01482880980226543]
	TIME [epoch: 6.57 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010438905152831386		[learning rate: 0.0001172]
	Learning Rate: 0.000117199
	LOSS [training: 0.010438905152831386 | validation: 0.006172351248078435]
	TIME [epoch: 6.56 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012830905501792328		[learning rate: 0.00011692]
	Learning Rate: 0.000116922
	LOSS [training: 0.012830905501792328 | validation: 0.0027642935386368904]
	TIME [epoch: 6.56 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009763090810178947		[learning rate: 0.00011665]
	Learning Rate: 0.000116647
	LOSS [training: 0.009763090810178947 | validation: 0.00692785685409603]
	TIME [epoch: 6.56 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013462780216240968		[learning rate: 0.00011637]
	Learning Rate: 0.000116371
	LOSS [training: 0.013462780216240968 | validation: 0.00040408487120469766]
	TIME [epoch: 6.57 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010367382255128246		[learning rate: 0.0001161]
	Learning Rate: 0.000116097
	LOSS [training: 0.010367382255128246 | validation: 0.007189744998685027]
	TIME [epoch: 6.59 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01819389633684396		[learning rate: 0.00011582]
	Learning Rate: 0.000115823
	LOSS [training: 0.01819389633684396 | validation: 0.010055510427241813]
	TIME [epoch: 6.56 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012646164892356366		[learning rate: 0.00011555]
	Learning Rate: 0.00011555
	LOSS [training: 0.012646164892356366 | validation: 0.01105896166074469]
	TIME [epoch: 6.56 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011294275400985033		[learning rate: 0.00011528]
	Learning Rate: 0.000115277
	LOSS [training: 0.011294275400985033 | validation: 0.012491429953713117]
	TIME [epoch: 6.56 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015243948689717304		[learning rate: 0.00011501]
	Learning Rate: 0.000115005
	LOSS [training: 0.015243948689717304 | validation: 0.011205927588462821]
	TIME [epoch: 6.56 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02268543792672016		[learning rate: 0.00011473]
	Learning Rate: 0.000114734
	LOSS [training: 0.02268543792672016 | validation: 0.005308945912364133]
	TIME [epoch: 6.59 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0135023590573821		[learning rate: 0.00011446]
	Learning Rate: 0.000114463
	LOSS [training: 0.0135023590573821 | validation: 0.012195538111568137]
	TIME [epoch: 6.56 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01754581329806966		[learning rate: 0.00011419]
	Learning Rate: 0.000114193
	LOSS [training: 0.01754581329806966 | validation: 0.00455416009872866]
	TIME [epoch: 6.56 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011006391052128186		[learning rate: 0.00011392]
	Learning Rate: 0.000113924
	LOSS [training: 0.011006391052128186 | validation: 0.00744279322632317]
	TIME [epoch: 6.56 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01084138150190268		[learning rate: 0.00011366]
	Learning Rate: 0.000113655
	LOSS [training: 0.01084138150190268 | validation: -0.0033517719856771375]
	TIME [epoch: 6.56 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01061322965256204		[learning rate: 0.00011339]
	Learning Rate: 0.000113387
	LOSS [training: 0.01061322965256204 | validation: 0.00726978688740063]
	TIME [epoch: 6.6 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011340218327564445		[learning rate: 0.00011312]
	Learning Rate: 0.00011312
	LOSS [training: 0.011340218327564445 | validation: 0.0015736393716940262]
	TIME [epoch: 6.57 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010115202549979756		[learning rate: 0.00011285]
	Learning Rate: 0.000112853
	LOSS [training: 0.010115202549979756 | validation: 0.002651044718896097]
	TIME [epoch: 6.56 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.008981701571471191		[learning rate: 0.00011259]
	Learning Rate: 0.000112587
	LOSS [training: 0.008981701571471191 | validation: 0.0060495785416845235]
	TIME [epoch: 6.56 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010432131318646499		[learning rate: 0.00011232]
	Learning Rate: 0.000112321
	LOSS [training: 0.010432131318646499 | validation: 0.005510189706186891]
	TIME [epoch: 6.56 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011426222911980356		[learning rate: 0.00011206]
	Learning Rate: 0.000112056
	LOSS [training: 0.011426222911980356 | validation: -0.00021153397515859783]
	TIME [epoch: 6.59 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010621169063149468		[learning rate: 0.00011179]
	Learning Rate: 0.000111792
	LOSS [training: 0.010621169063149468 | validation: 0.00379921558116613]
	TIME [epoch: 6.57 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012845430433696892		[learning rate: 0.00011153]
	Learning Rate: 0.000111528
	LOSS [training: 0.012845430433696892 | validation: 0.0094194001933764]
	TIME [epoch: 6.56 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013688127517415483		[learning rate: 0.00011127]
	Learning Rate: 0.000111265
	LOSS [training: 0.013688127517415483 | validation: 0.004020603495602328]
	TIME [epoch: 6.56 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010686342435741087		[learning rate: 0.000111]
	Learning Rate: 0.000111003
	LOSS [training: 0.010686342435741087 | validation: -0.0028424211673927354]
	TIME [epoch: 6.57 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.006158908819792827		[learning rate: 0.00011074]
	Learning Rate: 0.000110741
	LOSS [training: 0.006158908819792827 | validation: 0.004315880480652489]
	TIME [epoch: 6.59 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010970043393235703		[learning rate: 0.00011048]
	Learning Rate: 0.00011048
	LOSS [training: 0.010970043393235703 | validation: 0.001465720027117705]
	TIME [epoch: 6.59 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010870198447521465		[learning rate: 0.00011022]
	Learning Rate: 0.000110219
	LOSS [training: 0.010870198447521465 | validation: 0.00494895523159175]
	TIME [epoch: 6.57 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012261775231067449		[learning rate: 0.00010996]
	Learning Rate: 0.000109959
	LOSS [training: 0.012261775231067449 | validation: 0.0038198452872180407]
	TIME [epoch: 6.57 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009205469772151384		[learning rate: 0.0001097]
	Learning Rate: 0.0001097
	LOSS [training: 0.009205469772151384 | validation: -0.0034300949197566925]
	TIME [epoch: 6.56 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010348067490852979		[learning rate: 0.00010944]
	Learning Rate: 0.000109441
	LOSS [training: 0.010348067490852979 | validation: -0.00017780344139824242]
	TIME [epoch: 6.58 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009979692608070813		[learning rate: 0.00010918]
	Learning Rate: 0.000109183
	LOSS [training: 0.009979692608070813 | validation: 0.011892769915593189]
	TIME [epoch: 6.59 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013817094919444203		[learning rate: 0.00010893]
	Learning Rate: 0.000108925
	LOSS [training: 0.013817094919444203 | validation: 0.0015001192042460275]
	TIME [epoch: 6.57 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011178141909965477		[learning rate: 0.00010867]
	Learning Rate: 0.000108668
	LOSS [training: 0.011178141909965477 | validation: 0.011277725839159798]
	TIME [epoch: 6.57 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010479749128086134		[learning rate: 0.00010841]
	Learning Rate: 0.000108412
	LOSS [training: 0.010479749128086134 | validation: 0.011984167999163317]
	TIME [epoch: 6.56 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013291600778956237		[learning rate: 0.00010816]
	Learning Rate: 0.000108156
	LOSS [training: 0.013291600778956237 | validation: 0.013057433646483235]
	TIME [epoch: 6.57 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.00947000741559751		[learning rate: 0.0001079]
	Learning Rate: 0.000107901
	LOSS [training: 0.00947000741559751 | validation: 0.0014104490675530545]
	TIME [epoch: 6.61 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012282211489860872		[learning rate: 0.00010765]
	Learning Rate: 0.000107647
	LOSS [training: 0.012282211489860872 | validation: 0.0015548707123807983]
	TIME [epoch: 6.57 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009673261165819003		[learning rate: 0.00010739]
	Learning Rate: 0.000107393
	LOSS [training: 0.009673261165819003 | validation: 0.0005133229123281784]
	TIME [epoch: 6.56 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012452274834118255		[learning rate: 0.00010714]
	Learning Rate: 0.000107139
	LOSS [training: 0.012452274834118255 | validation: 0.0004925949328485587]
	TIME [epoch: 6.56 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010215783019341992		[learning rate: 0.00010689]
	Learning Rate: 0.000106887
	LOSS [training: 0.010215783019341992 | validation: 0.01067422061524489]
	TIME [epoch: 6.56 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010213316326177481		[learning rate: 0.00010663]
	Learning Rate: 0.000106634
	LOSS [training: 0.010213316326177481 | validation: 0.008186715137090041]
	TIME [epoch: 6.6 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012867297240621958		[learning rate: 0.00010638]
	Learning Rate: 0.000106383
	LOSS [training: 0.012867297240621958 | validation: 0.008944099294967343]
	TIME [epoch: 6.57 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011645577464356398		[learning rate: 0.00010613]
	Learning Rate: 0.000106132
	LOSS [training: 0.011645577464356398 | validation: 0.0020638819863081186]
	TIME [epoch: 6.56 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.008100838655466645		[learning rate: 0.00010588]
	Learning Rate: 0.000105882
	LOSS [training: 0.008100838655466645 | validation: 0.006590101231664662]
	TIME [epoch: 6.56 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010260438932893157		[learning rate: 0.00010563]
	Learning Rate: 0.000105632
	LOSS [training: 0.010260438932893157 | validation: 0.005544684686210151]
	TIME [epoch: 6.57 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009115130699333823		[learning rate: 0.00010538]
	Learning Rate: 0.000105383
	LOSS [training: 0.009115130699333823 | validation: -0.0032997884283955665]
	TIME [epoch: 6.6 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011221028591223866		[learning rate: 0.00010513]
	Learning Rate: 0.000105134
	LOSS [training: 0.011221028591223866 | validation: -0.002691189413216063]
	TIME [epoch: 6.58 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012964317684069795		[learning rate: 0.00010489]
	Learning Rate: 0.000104886
	LOSS [training: 0.012964317684069795 | validation: 0.0009190470553620492]
	TIME [epoch: 6.56 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.007626083929312112		[learning rate: 0.00010464]
	Learning Rate: 0.000104639
	LOSS [training: 0.007626083929312112 | validation: 0.009149045641830524]
	TIME [epoch: 6.57 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014436380664371482		[learning rate: 0.00010439]
	Learning Rate: 0.000104392
	LOSS [training: 0.014436380664371482 | validation: -0.002089165130522883]
	TIME [epoch: 6.56 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011360529582893778		[learning rate: 0.00010415]
	Learning Rate: 0.000104146
	LOSS [training: 0.011360529582893778 | validation: -0.004596443069947697]
	TIME [epoch: 6.58 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013348073747303		[learning rate: 0.0001039]
	Learning Rate: 0.0001039
	LOSS [training: 0.013348073747303 | validation: 0.0003010558345974577]
	TIME [epoch: 6.6 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01023676994436761		[learning rate: 0.00010365]
	Learning Rate: 0.000103655
	LOSS [training: 0.01023676994436761 | validation: 0.005239393457298409]
	TIME [epoch: 6.56 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011562584388191965		[learning rate: 0.00010341]
	Learning Rate: 0.00010341
	LOSS [training: 0.011562584388191965 | validation: -0.0012655494780064004]
	TIME [epoch: 6.56 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012044020641446499		[learning rate: 0.00010317]
	Learning Rate: 0.000103166
	LOSS [training: 0.012044020641446499 | validation: -0.0026238272652866464]
	TIME [epoch: 6.56 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012865980570009585		[learning rate: 0.00010292]
	Learning Rate: 0.000102923
	LOSS [training: 0.012865980570009585 | validation: 0.0011701375135797255]
	TIME [epoch: 6.56 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010224343698755271		[learning rate: 0.00010268]
	Learning Rate: 0.00010268
	LOSS [training: 0.010224343698755271 | validation: 0.0007152675512223784]
	TIME [epoch: 6.6 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011808471991214362		[learning rate: 0.00010244]
	Learning Rate: 0.000102438
	LOSS [training: 0.011808471991214362 | validation: 0.0034728311074958738]
	TIME [epoch: 6.56 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013976303026635235		[learning rate: 0.0001022]
	Learning Rate: 0.000102196
	LOSS [training: 0.013976303026635235 | validation: 0.006200318569941087]
	TIME [epoch: 6.56 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013435569567739888		[learning rate: 0.00010196]
	Learning Rate: 0.000101955
	LOSS [training: 0.013435569567739888 | validation: 4.952914525336357e-05]
	TIME [epoch: 6.56 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013005473249189502		[learning rate: 0.00010171]
	Learning Rate: 0.000101715
	LOSS [training: 0.013005473249189502 | validation: 0.009714247460190062]
	TIME [epoch: 6.56 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009570033733683321		[learning rate: 0.00010147]
	Learning Rate: 0.000101475
	LOSS [training: 0.009570033733683321 | validation: -0.00095045744607445]
	TIME [epoch: 6.6 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0132901632275012		[learning rate: 0.00010124]
	Learning Rate: 0.000101236
	LOSS [training: 0.0132901632275012 | validation: -0.00023286396607210928]
	TIME [epoch: 6.56 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013989950403206932		[learning rate: 0.000101]
	Learning Rate: 0.000100997
	LOSS [training: 0.013989950403206932 | validation: 0.008149005159783954]
	TIME [epoch: 6.56 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013129397182030596		[learning rate: 0.00010076]
	Learning Rate: 0.000100759
	LOSS [training: 0.013129397182030596 | validation: 0.0002455527630868138]
	TIME [epoch: 6.56 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014157873574939592		[learning rate: 0.00010052]
	Learning Rate: 0.000100521
	LOSS [training: 0.014157873574939592 | validation: 0.009076018044124862]
	TIME [epoch: 6.56 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011844933481687052		[learning rate: 0.00010028]
	Learning Rate: 0.000100284
	LOSS [training: 0.011844933481687052 | validation: 0.0015190619678820483]
	TIME [epoch: 6.6 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013970042049342981		[learning rate: 0.00010005]
	Learning Rate: 0.000100047
	LOSS [training: 0.013970042049342981 | validation: 0.000302038829631993]
	TIME [epoch: 6.57 sec]
Finished training in 13333.112 seconds.
