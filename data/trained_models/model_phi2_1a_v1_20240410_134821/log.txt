Args:
Namespace(name='model_phi2_1a_v1', outdir='out/model_training/model_phi2_1a_v1', training_data='data/training_data/data_phi2_1a/training', validation_data='data/training_data/data_phi2_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 343684350

Training model...

Saving initial model state to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.300822929160983		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.300822929160983 | validation: 9.36627790699136]
	TIME [epoch: 114 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.795861926126506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.795861926126506 | validation: 9.162629739070091]
	TIME [epoch: 6.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.403107861249127		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.403107861249127 | validation: 8.285988792149885]
	TIME [epoch: 6.32 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.396142075339723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.396142075339723 | validation: 7.036736026822405]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.404215485850906		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.404215485850906 | validation: 6.523318237482931]
	TIME [epoch: 6.29 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.96160538906855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.96160538906855 | validation: 8.4169324276141]
	TIME [epoch: 6.25 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.591142589491666		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.591142589491666 | validation: 6.445731999868507]
	TIME [epoch: 6.29 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.332428110094757		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.332428110094757 | validation: 3.671049248380445]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.382565209382575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.382565209382575 | validation: 3.8620537986933927]
	TIME [epoch: 6.3 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.47914012328705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.47914012328705 | validation: 3.1526122421821796]
	TIME [epoch: 6.24 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.058097452496441		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.058097452496441 | validation: 3.2383795538186577]
	TIME [epoch: 6.24 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.970354904937441		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.970354904937441 | validation: 2.6875759138840096]
	TIME [epoch: 6.24 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.624398164641017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.624398164641017 | validation: 4.515262674165939]
	TIME [epoch: 6.26 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4069019166295655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4069019166295655 | validation: 3.9500508301841792]
	TIME [epoch: 6.29 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.342168567561886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.342168567561886 | validation: 4.441653148193053]
	TIME [epoch: 6.24 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.271393567005958		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.271393567005958 | validation: 4.21756857431648]
	TIME [epoch: 6.24 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0909658636774187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0909658636774187 | validation: 2.040700294507289]
	TIME [epoch: 6.23 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.310440584704291		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.310440584704291 | validation: 2.4196991271452]
	TIME [epoch: 6.26 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.540694684372202		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.540694684372202 | validation: 2.245938435352154]
	TIME [epoch: 6.31 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6720139028681134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6720139028681134 | validation: 1.9604375896354362]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.334921977175503		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.334921977175503 | validation: 2.1057149198064353]
	TIME [epoch: 6.29 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.398712831215553		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.398712831215553 | validation: 1.9267519713871137]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.369179915526285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.369179915526285 | validation: 2.520039964271185]
	TIME [epoch: 6.25 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3723545476654833		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3723545476654833 | validation: 2.2544153485197262]
	TIME [epoch: 6.28 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5175424324468567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5175424324468567 | validation: 2.535425523877712]
	TIME [epoch: 6.26 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.235215070744355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.235215070744355 | validation: 2.405132703430395]
	TIME [epoch: 6.26 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3548445167336842		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3548445167336842 | validation: 1.8120554156326856]
	TIME [epoch: 6.24 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3283372775485427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3283372775485427 | validation: 1.9118029431127865]
	TIME [epoch: 6.24 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3832640870710073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3832640870710073 | validation: 1.9539905750018338]
	TIME [epoch: 6.26 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.230082638138189		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.230082638138189 | validation: 2.1819138327535024]
	TIME [epoch: 6.32 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3764892666867716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3764892666867716 | validation: 2.2876088908787273]
	TIME [epoch: 6.23 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3189641177225004		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3189641177225004 | validation: 8.462909173325741]
	TIME [epoch: 6.24 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.90837561441298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.90837561441298 | validation: 4.392994360367016]
	TIME [epoch: 6.23 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3781542210983933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3781542210983933 | validation: 2.374400419129204]
	TIME [epoch: 6.23 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5300024886040595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5300024886040595 | validation: 2.2702363771224467]
	TIME [epoch: 6.26 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.376433638472924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.376433638472924 | validation: 2.236365095979381]
	TIME [epoch: 6.26 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6197997555199795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6197997555199795 | validation: 2.3733879294248923]
	TIME [epoch: 6.25 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5945859959938904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5945859959938904 | validation: 1.8196706427043496]
	TIME [epoch: 6.24 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2394109097321557		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2394109097321557 | validation: 1.7498164603742101]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3499979664914887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3499979664914887 | validation: 1.9152365383645074]
	TIME [epoch: 6.25 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0172638099816393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0172638099816393 | validation: 2.0305478600290803]
	TIME [epoch: 6.29 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6011671812589285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6011671812589285 | validation: 1.75667540052698]
	TIME [epoch: 6.24 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3858337949120254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3858337949120254 | validation: 1.8196477949860574]
	TIME [epoch: 6.24 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.032419466353454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.032419466353454 | validation: 1.606555358008716]
	TIME [epoch: 6.24 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0193073666382966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0193073666382966 | validation: 2.1491559487507645]
	TIME [epoch: 6.29 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.176913392815228		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.176913392815228 | validation: 1.7866661287597294]
	TIME [epoch: 6.29 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9759981910540536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9759981910540536 | validation: 1.5914046944272315]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.730889248828523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.730889248828523 | validation: 1.4280113990972807]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9583973634644085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9583973634644085 | validation: 2.4461527566327668]
	TIME [epoch: 6.26 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8033167845002724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8033167845002724 | validation: 1.7218363404199222]
	TIME [epoch: 6.25 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7436550227249734		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 1.7436550227249734 | validation: 2.140499814443741]
	TIME [epoch: 6.27 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8828232924224966		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 1.8828232924224966 | validation: 1.5787511878760305]
	TIME [epoch: 6.27 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6510535775343527		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 1.6510535775343527 | validation: 1.55725589180881]
	TIME [epoch: 6.25 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4867988400961598		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 1.4867988400961598 | validation: 1.4920115838169485]
	TIME [epoch: 6.24 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7108743537852833		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 1.7108743537852833 | validation: 1.4790301701015092]
	TIME [epoch: 6.25 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7378052536680018		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 1.7378052536680018 | validation: 1.3637997181995014]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6077605576698144		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 1.6077605576698144 | validation: 1.7220737174845848]
	TIME [epoch: 6.3 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6122359914997568		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 1.6122359914997568 | validation: 1.3223431696461088]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5265768402048427		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 1.5265768402048427 | validation: 1.6369139427619344]
	TIME [epoch: 6.27 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4511261556697803		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 1.4511261556697803 | validation: 1.4809912457374848]
	TIME [epoch: 6.25 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5801319871221162		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 1.5801319871221162 | validation: 2.22396937898925]
	TIME [epoch: 6.28 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5390211026843836		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 1.5390211026843836 | validation: 1.2113697265962537]
	TIME [epoch: 6.28 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.411034702442271		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 1.411034702442271 | validation: 1.5935099964081854]
	TIME [epoch: 6.28 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4624581819504894		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 1.4624581819504894 | validation: 1.2404289238100006]
	TIME [epoch: 6.25 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3916711678001412		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 1.3916711678001412 | validation: 1.8035096216011168]
	TIME [epoch: 6.24 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4431793295883044		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 1.4431793295883044 | validation: 1.3947273550711379]
	TIME [epoch: 6.24 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4142447691761657		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 1.4142447691761657 | validation: 1.2449811297760176]
	TIME [epoch: 6.26 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5016790360631316		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 1.5016790360631316 | validation: 1.1485761903511746]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3766717093820273		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 1.3766717093820273 | validation: 1.0794013169353356]
	TIME [epoch: 6.28 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1439154606537314		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 1.1439154606537314 | validation: 1.3332998714308557]
	TIME [epoch: 6.27 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2992336821757526		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 1.2992336821757526 | validation: 1.866778276615714]
	TIME [epoch: 6.29 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2998885400246014		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 1.2998885400246014 | validation: 1.3360267549130649]
	TIME [epoch: 6.25 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.313012478850468		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 1.313012478850468 | validation: 1.0843466061272145]
	TIME [epoch: 6.3 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.156240519647986		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 1.156240519647986 | validation: 1.1020972661161332]
	TIME [epoch: 6.25 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2485763952692492		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 1.2485763952692492 | validation: 1.0011088263891128]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2233848568424057		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 1.2233848568424057 | validation: 0.9165950146884007]
	TIME [epoch: 6.24 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0651833760910197		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 1.0651833760910197 | validation: 0.8681188529002497]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.134749088113308		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 1.134749088113308 | validation: 0.8814111372157044]
	TIME [epoch: 6.29 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1340353773453093		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 1.1340353773453093 | validation: 0.9017290183441841]
	TIME [epoch: 6.27 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.137074758259438		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 1.137074758259438 | validation: 1.1855852841875518]
	TIME [epoch: 6.24 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6382440593664955		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 2.6382440593664955 | validation: 3.4995312262637976]
	TIME [epoch: 6.23 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9210970776218526		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 1.9210970776218526 | validation: 1.4763086555673353]
	TIME [epoch: 6.23 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1873857447640286		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 1.1873857447640286 | validation: 0.8304919114430862]
	TIME [epoch: 6.23 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9717091118617298		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.9717091118617298 | validation: 1.0290996539855821]
	TIME [epoch: 6.27 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9579960366179089		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.9579960366179089 | validation: 0.9543783096496167]
	TIME [epoch: 6.26 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.891652351398128		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.891652351398128 | validation: 1.1543867060475028]
	TIME [epoch: 6.3 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9913178890457552		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.9913178890457552 | validation: 0.7427265219117102]
	TIME [epoch: 6.22 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8729136811118527		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 0.8729136811118527 | validation: 0.8534294335003365]
	TIME [epoch: 6.23 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8567192414155419		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.8567192414155419 | validation: 1.4143808318686433]
	TIME [epoch: 6.27 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9945474797290951		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.9945474797290951 | validation: 0.8658226952871715]
	TIME [epoch: 6.27 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8085303819817831		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.8085303819817831 | validation: 0.7440749775036324]
	TIME [epoch: 6.25 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7871556052663923		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.7871556052663923 | validation: 0.6888847550496358]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8645096233696042		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 0.8645096233696042 | validation: 0.8134511425225909]
	TIME [epoch: 6.28 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8843657596550383		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.8843657596550383 | validation: 0.6599934679734081]
	TIME [epoch: 6.29 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7734892562714918		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.7734892562714918 | validation: 0.5741555485010743]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7296296303872964		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.7296296303872964 | validation: 1.9899925536522014]
	TIME [epoch: 6.24 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4029067793243284		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 1.4029067793243284 | validation: 0.8423952369106029]
	TIME [epoch: 6.24 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8011860541989402		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.8011860541989402 | validation: 0.7204685393547495]
	TIME [epoch: 6.23 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7262132891038456		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.7262132891038456 | validation: 0.5279140627594783]
	TIME [epoch: 6.23 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7192923573423406		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.7192923573423406 | validation: 0.5683040071233139]
	TIME [epoch: 6.28 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7792814252343261		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.7792814252343261 | validation: 0.8069388202534294]
	TIME [epoch: 6.24 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6832605011481643		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.6832605011481643 | validation: 0.8849761545617405]
	TIME [epoch: 6.24 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8358462931934255		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.8358462931934255 | validation: 0.607752868252663]
	TIME [epoch: 6.22 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2729497744908818		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.2729497744908818 | validation: 0.5457607158585988]
	TIME [epoch: 6.25 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6124899333967039		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.6124899333967039 | validation: 0.7492711734340651]
	TIME [epoch: 6.28 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6538455996642699		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.6538455996642699 | validation: 1.0287484905128534]
	TIME [epoch: 6.25 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7926894281317032		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.7926894281317032 | validation: 1.038066251198274]
	TIME [epoch: 6.25 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6820647694949314		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.6820647694949314 | validation: 0.9961831057613417]
	TIME [epoch: 6.25 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6336812171263084		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.6336812171263084 | validation: 0.7678327372753189]
	TIME [epoch: 6.26 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6078407933156087		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.6078407933156087 | validation: 0.5740177640728664]
	TIME [epoch: 6.24 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.588581477749117		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.588581477749117 | validation: 0.4458888152525744]
	TIME [epoch: 6.28 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_111.pth
	Model improved!!!
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6060921102298444		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.6060921102298444 | validation: 0.4354619786564238]
	TIME [epoch: 6.24 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_112.pth
	Model improved!!!
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5588407795642647		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.5588407795642647 | validation: 0.4138023139248547]
	TIME [epoch: 6.23 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_113.pth
	Model improved!!!
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5382781558519316		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.5382781558519316 | validation: 0.4840862350539603]
	TIME [epoch: 6.25 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5491035867101939		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.5491035867101939 | validation: 0.6287582077140149]
	TIME [epoch: 6.25 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.577922660989381		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.577922660989381 | validation: 0.4175686989774251]
	TIME [epoch: 6.3 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49910875089883305		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.49910875089883305 | validation: 0.4385699124653007]
	TIME [epoch: 6.28 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6269653467521924		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.6269653467521924 | validation: 0.4501138805029107]
	TIME [epoch: 6.27 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5690731839313924		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.5690731839313924 | validation: 0.6931813542217173]
	TIME [epoch: 6.24 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6400795280991349		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.6400795280991349 | validation: 0.5034951517186844]
	TIME [epoch: 6.25 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5385849417714575		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.5385849417714575 | validation: 0.3363418487092784]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48999882756972796		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.48999882756972796 | validation: 0.5095149424536534]
	TIME [epoch: 6.32 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46157539078066645		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.46157539078066645 | validation: 0.43197314497663514]
	TIME [epoch: 6.29 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5097745124037429		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.5097745124037429 | validation: 0.413581408531779]
	TIME [epoch: 6.3 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42412039893007236		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.42412039893007236 | validation: 0.3364850751070789]
	TIME [epoch: 6.29 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6423649959879556		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.6423649959879556 | validation: 0.3760573825698835]
	TIME [epoch: 6.3 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5270011617908762		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.5270011617908762 | validation: 0.418927337122742]
	TIME [epoch: 6.35 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5219793040828864		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.5219793040828864 | validation: 0.3655360131196618]
	TIME [epoch: 6.31 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5562961101998442		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.5562961101998442 | validation: 0.5789803903002883]
	TIME [epoch: 6.3 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48340316796559946		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.48340316796559946 | validation: 0.34567846407195946]
	TIME [epoch: 6.3 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5901741144969728		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.5901741144969728 | validation: 0.6495002050347654]
	TIME [epoch: 6.3 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5413724795843953		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.5413724795843953 | validation: 0.7807541500937583]
	TIME [epoch: 6.33 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6269442291809051		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.6269442291809051 | validation: 0.4370250416721285]
	TIME [epoch: 6.33 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4425941062411418		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.4425941062411418 | validation: 0.6072212626741628]
	TIME [epoch: 6.31 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4234354634533636		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.4234354634533636 | validation: 0.7287926949179221]
	TIME [epoch: 6.3 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.572138904170127		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.572138904170127 | validation: 0.5949249955479019]
	TIME [epoch: 6.3 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4878639454709051		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.4878639454709051 | validation: 0.3858711092410977]
	TIME [epoch: 6.31 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.476926242504048		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.476926242504048 | validation: 0.3685071130838097]
	TIME [epoch: 6.35 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4293675490372304		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.4293675490372304 | validation: 1.005322673206547]
	TIME [epoch: 6.31 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6336863210912235		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.6336863210912235 | validation: 0.34519630857276234]
	TIME [epoch: 6.31 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6138664962190824		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.6138664962190824 | validation: 0.43597109934730277]
	TIME [epoch: 6.3 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47008662639706955		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.47008662639706955 | validation: 0.3691706215061419]
	TIME [epoch: 6.31 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6946652200443207		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.6946652200443207 | validation: 0.3194394768096554]
	TIME [epoch: 6.34 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_143.pth
	Model improved!!!
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4788016127281321		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.4788016127281321 | validation: 0.39956077865750406]
	TIME [epoch: 6.32 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39625795272953357		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.39625795272953357 | validation: 0.3398476695859385]
	TIME [epoch: 6.31 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5807612771613788		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.5807612771613788 | validation: 1.0117071943771798]
	TIME [epoch: 6.31 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6519597011358957		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.6519597011358957 | validation: 0.31098251552698475]
	TIME [epoch: 6.31 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_147.pth
	Model improved!!!
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40394929381748074		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.40394929381748074 | validation: 0.517953565878733]
	TIME [epoch: 6.34 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4694973866266128		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.4694973866266128 | validation: 0.5898860180921317]
	TIME [epoch: 6.33 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7905773229842495		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.7905773229842495 | validation: 0.31707246240024367]
	TIME [epoch: 6.32 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4452836558718861		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.4452836558718861 | validation: 0.32898981702152624]
	TIME [epoch: 6.31 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32647977667581773		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.32647977667581773 | validation: 0.36754276084974746]
	TIME [epoch: 6.3 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5290804735136372		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.5290804735136372 | validation: 0.5938084002857553]
	TIME [epoch: 6.32 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4284960872237954		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.4284960872237954 | validation: 0.5273473287056111]
	TIME [epoch: 6.36 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4894423185677264		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.4894423185677264 | validation: 0.3323042236080395]
	TIME [epoch: 6.32 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39386121590792567		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.39386121590792567 | validation: 0.2723933218753862]
	TIME [epoch: 6.31 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_156.pth
	Model improved!!!
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3907004684459391		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.3907004684459391 | validation: 0.27764439083502557]
	TIME [epoch: 6.3 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3775893067003205		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.3775893067003205 | validation: 0.48253924867063813]
	TIME [epoch: 6.3 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3925717894955068		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.3925717894955068 | validation: 0.2878745552080536]
	TIME [epoch: 6.34 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.347580707386768		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.347580707386768 | validation: 0.37322347054572125]
	TIME [epoch: 6.32 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36939506138898104		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.36939506138898104 | validation: 0.26980519470577236]
	TIME [epoch: 6.31 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_161.pth
	Model improved!!!
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4712849783958969		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.4712849783958969 | validation: 0.33081441553092933]
	TIME [epoch: 6.31 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4257679166739955		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.4257679166739955 | validation: 0.2739539626071004]
	TIME [epoch: 6.31 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3429566527135376		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.3429566527135376 | validation: 0.5052971718744728]
	TIME [epoch: 6.32 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4226894916737755		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.4226894916737755 | validation: 0.27862434445869605]
	TIME [epoch: 6.34 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3810968903288213		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.3810968903288213 | validation: 0.5525377308464466]
	TIME [epoch: 6.32 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5342563912748964		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.5342563912748964 | validation: 0.3852240556490412]
	TIME [epoch: 6.32 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48339786565818715		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.48339786565818715 | validation: 0.3229907309879154]
	TIME [epoch: 6.31 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4046740316942011		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.4046740316942011 | validation: 0.2804132483246413]
	TIME [epoch: 6.32 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37480477804914747		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.37480477804914747 | validation: 0.25662971558341063]
	TIME [epoch: 6.35 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_170.pth
	Model improved!!!
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38167607350834754		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.38167607350834754 | validation: 0.33145396338297245]
	TIME [epoch: 6.32 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4145072704136141		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.4145072704136141 | validation: 0.2748066287741011]
	TIME [epoch: 6.3 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37776852195505517		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.37776852195505517 | validation: 0.3429693517399568]
	TIME [epoch: 6.3 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3925131976429294		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.3925131976429294 | validation: 0.468207967141954]
	TIME [epoch: 6.31 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47515477432260766		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.47515477432260766 | validation: 0.4202261985527332]
	TIME [epoch: 6.34 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3685193157892309		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.3685193157892309 | validation: 0.5756616560863459]
	TIME [epoch: 6.33 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6256106999444546		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.6256106999444546 | validation: 0.8769066788497157]
	TIME [epoch: 6.31 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5825140932900604		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.5825140932900604 | validation: 0.40966237934306765]
	TIME [epoch: 6.31 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44533746964525656		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.44533746964525656 | validation: 0.24333550038888502]
	TIME [epoch: 6.31 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_179.pth
	Model improved!!!
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2905615355611413		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.2905615355611413 | validation: 0.31268036431143126]
	TIME [epoch: 6.31 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3539274431889666		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.3539274431889666 | validation: 0.20936926130123035]
	TIME [epoch: 6.35 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_181.pth
	Model improved!!!
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3147812918035463		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.3147812918035463 | validation: 0.32364584611472075]
	TIME [epoch: 6.32 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47607760289539286		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.47607760289539286 | validation: 1.756226714855527]
	TIME [epoch: 6.31 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9163541660255172		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.9163541660255172 | validation: 0.29988380800517644]
	TIME [epoch: 6.31 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6604631220825793		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.6604631220825793 | validation: 0.39417924358419876]
	TIME [epoch: 6.31 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39744273299429206		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.39744273299429206 | validation: 0.25234014333524907]
	TIME [epoch: 6.35 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3776426630443074		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.3776426630443074 | validation: 0.3620357354165993]
	TIME [epoch: 6.32 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.532293172273693		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.532293172273693 | validation: 0.4407253947358982]
	TIME [epoch: 6.3 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4589527075922113		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.4589527075922113 | validation: 0.24959918225103722]
	TIME [epoch: 6.31 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29457061641895055		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.29457061641895055 | validation: 0.2486616423706532]
	TIME [epoch: 6.31 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3191681534196764		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.3191681534196764 | validation: 0.2734490666674466]
	TIME [epoch: 6.32 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3722068494795176		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.3722068494795176 | validation: 0.32432204960246397]
	TIME [epoch: 6.34 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37710987642565696		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.37710987642565696 | validation: 0.23920792810012464]
	TIME [epoch: 6.31 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2602885564945242		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.2602885564945242 | validation: 0.22680920210278782]
	TIME [epoch: 6.31 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4151134206744402		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.4151134206744402 | validation: 0.6609676578140179]
	TIME [epoch: 6.31 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.566913131781828		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.566913131781828 | validation: 0.32974902248223603]
	TIME [epoch: 6.31 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3811837543233863		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.3811837543233863 | validation: 0.545500874212885]
	TIME [epoch: 6.35 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46050040719297375		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.46050040719297375 | validation: 0.30513769326299106]
	TIME [epoch: 6.32 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2998060944917245		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.2998060944917245 | validation: 0.3199304592922577]
	TIME [epoch: 6.32 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3877626519883271		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.3877626519883271 | validation: 0.4421301632784772]
	TIME [epoch: 6.31 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36383887923383024		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.36383887923383024 | validation: 0.2641941769785011]
	TIME [epoch: 6.31 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25006681644846235		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.25006681644846235 | validation: 0.20925662006974216]
	TIME [epoch: 6.33 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_202.pth
	Model improved!!!
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26796008114144304		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.26796008114144304 | validation: 0.20823047714307663]
	TIME [epoch: 6.35 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_203.pth
	Model improved!!!
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7763937950115783		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.7763937950115783 | validation: 0.42912921951981736]
	TIME [epoch: 6.31 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40102834087791384		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.40102834087791384 | validation: 0.2104435913270743]
	TIME [epoch: 6.31 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2887897566273788		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.2887897566273788 | validation: 0.3131905345178203]
	TIME [epoch: 6.31 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3178940635999385		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.3178940635999385 | validation: 0.20840634516322173]
	TIME [epoch: 6.31 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6320016524145514		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.6320016524145514 | validation: 0.33579577658401394]
	TIME [epoch: 6.35 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3527318943531048		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.3527318943531048 | validation: 0.3335832165584892]
	TIME [epoch: 6.32 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1307737794249038		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 1.1307737794249038 | validation: 2.16900920058428]
	TIME [epoch: 6.31 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1447467993650309		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 1.1447467993650309 | validation: 0.5099788904447753]
	TIME [epoch: 6.31 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41568055580911467		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.41568055580911467 | validation: 0.46730862260814265]
	TIME [epoch: 6.31 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5626254061619507		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.5626254061619507 | validation: 0.29109484985987105]
	TIME [epoch: 6.36 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3663588371265024		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.3663588371265024 | validation: 0.28983967998806287]
	TIME [epoch: 6.31 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3340351229953012		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.3340351229953012 | validation: 0.7130365958737838]
	TIME [epoch: 6.31 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42416984875447006		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.42416984875447006 | validation: 0.21749906454030626]
	TIME [epoch: 6.31 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31300394007247456		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.31300394007247456 | validation: 0.21156808066317806]
	TIME [epoch: 6.31 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2837646386677132		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.2837646386677132 | validation: 0.24182322754498906]
	TIME [epoch: 6.33 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3423136177822574		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.3423136177822574 | validation: 0.26425165194766176]
	TIME [epoch: 6.35 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6502241088976678		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.6502241088976678 | validation: 0.309610061902281]
	TIME [epoch: 6.31 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3121188967329844		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.3121188967329844 | validation: 0.22790838248407064]
	TIME [epoch: 6.31 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29714399067171837		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.29714399067171837 | validation: 0.5018555092625399]
	TIME [epoch: 6.32 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5917428300246766		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.5917428300246766 | validation: 0.5190972934298277]
	TIME [epoch: 6.32 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39271312357217525		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.39271312357217525 | validation: 0.19918180681460773]
	TIME [epoch: 6.35 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_224.pth
	Model improved!!!
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4762342543731988		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.4762342543731988 | validation: 0.2562175772242886]
	TIME [epoch: 6.33 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2735070930573517		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.2735070930573517 | validation: 0.20608589180726167]
	TIME [epoch: 6.31 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.302137615972752		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.302137615972752 | validation: 0.3413806773884457]
	TIME [epoch: 6.32 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5458610083685008		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.5458610083685008 | validation: 0.33905911033079306]
	TIME [epoch: 6.31 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43613544085916706		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.43613544085916706 | validation: 0.2983949812023641]
	TIME [epoch: 6.35 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31224300616335204		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.31224300616335204 | validation: 0.224121270016732]
	TIME [epoch: 6.34 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35155552651118227		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.35155552651118227 | validation: 0.3248659184159769]
	TIME [epoch: 6.32 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3292939343303023		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.3292939343303023 | validation: 0.2553516248188498]
	TIME [epoch: 6.31 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25407081120494207		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.25407081120494207 | validation: 0.28544438088739044]
	TIME [epoch: 6.32 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4321881409606495		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.4321881409606495 | validation: 0.30932898407300646]
	TIME [epoch: 6.32 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3614101530220784		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.3614101530220784 | validation: 0.19932732030843034]
	TIME [epoch: 6.36 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29377585753563473		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.29377585753563473 | validation: 0.30130777125680575]
	TIME [epoch: 6.32 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30578187112090693		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.30578187112090693 | validation: 0.28493482818067684]
	TIME [epoch: 6.32 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36787906624839906		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.36787906624839906 | validation: 0.32517019469303776]
	TIME [epoch: 6.31 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4776951307883559		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.4776951307883559 | validation: 0.29686097660792354]
	TIME [epoch: 6.32 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36505861282943786		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.36505861282943786 | validation: 0.23161349280758964]
	TIME [epoch: 6.34 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3874286308779794		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.3874286308779794 | validation: 0.24681479160233755]
	TIME [epoch: 6.35 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37688032164713015		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.37688032164713015 | validation: 0.21277716965608262]
	TIME [epoch: 6.31 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27350470553457373		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.27350470553457373 | validation: 0.2423579192373346]
	TIME [epoch: 6.32 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4869396194621386		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.4869396194621386 | validation: 0.49616619914515464]
	TIME [epoch: 6.31 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4237228831375404		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.4237228831375404 | validation: 0.2627760261802884]
	TIME [epoch: 6.32 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35319659950607424		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.35319659950607424 | validation: 0.7060825910970077]
	TIME [epoch: 6.37 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.082344307531772		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 1.082344307531772 | validation: 1.063691351454833]
	TIME [epoch: 6.32 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7900700762158559		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.7900700762158559 | validation: 0.40686390655605564]
	TIME [epoch: 6.32 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31946906274001646		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.31946906274001646 | validation: 0.2292615310674061]
	TIME [epoch: 6.31 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24408753700377916		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.24408753700377916 | validation: 0.2104632658749466]
	TIME [epoch: 6.31 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2686479261491548		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.2686479261491548 | validation: 0.7312169925327476]
	TIME [epoch: 6.36 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7805863817382218		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.7805863817382218 | validation: 0.21272759673091882]
	TIME [epoch: 6.32 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31720339443767126		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.31720339443767126 | validation: 0.2509386256699826]
	TIME [epoch: 6.31 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2679367716159285		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.2679367716159285 | validation: 0.3397097558366732]
	TIME [epoch: 6.31 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.393038573847512		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.393038573847512 | validation: 0.44581516230384666]
	TIME [epoch: 6.31 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40591523127938023		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.40591523127938023 | validation: 0.29726742184154836]
	TIME [epoch: 6.33 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2922194253513523		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.2922194253513523 | validation: 0.4098794873339446]
	TIME [epoch: 6.35 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29311986189074896		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.29311986189074896 | validation: 0.17013517867328865]
	TIME [epoch: 6.31 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_258.pth
	Model improved!!!
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3191239255124085		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.3191239255124085 | validation: 0.29122659440050264]
	TIME [epoch: 6.32 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25251480725263753		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.25251480725263753 | validation: 0.18083893004787793]
	TIME [epoch: 6.31 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2592785836857338		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.2592785836857338 | validation: 0.24404186251414006]
	TIME [epoch: 6.31 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2729312311302219		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.2729312311302219 | validation: 0.18417740494908677]
	TIME [epoch: 6.36 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35141523220813786		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.35141523220813786 | validation: 0.3408770496289533]
	TIME [epoch: 6.31 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33254371732259014		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.33254371732259014 | validation: 0.2558391470176121]
	TIME [epoch: 6.31 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3681608598919242		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.3681608598919242 | validation: 0.18549851537749687]
	TIME [epoch: 6.31 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19572054675725348		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.19572054675725348 | validation: 0.16161776553043178]
	TIME [epoch: 6.31 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_266.pth
	Model improved!!!
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2989559897401368		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.2989559897401368 | validation: 0.18242890338366496]
	TIME [epoch: 6.34 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20520026299101024		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.20520026299101024 | validation: 0.21226298845184305]
	TIME [epoch: 6.34 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2831289373972488		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.2831289373972488 | validation: 0.31283052809825074]
	TIME [epoch: 6.32 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31135000082414455		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.31135000082414455 | validation: 0.17423771696483492]
	TIME [epoch: 6.31 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3245711164459509		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.3245711164459509 | validation: 0.36383696119064257]
	TIME [epoch: 6.32 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3623811490095737		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.3623811490095737 | validation: 0.35613690094402245]
	TIME [epoch: 6.31 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3443490988785953		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.3443490988785953 | validation: 0.21843815935595526]
	TIME [epoch: 6.37 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36105107452852814		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.36105107452852814 | validation: 0.7554313963746089]
	TIME [epoch: 6.32 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6125019206395188		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.6125019206395188 | validation: 0.4291982465107757]
	TIME [epoch: 6.32 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34749495006012654		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.34749495006012654 | validation: 0.22324420422746274]
	TIME [epoch: 6.31 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23325841073807496		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.23325841073807496 | validation: 0.18378051032398598]
	TIME [epoch: 6.31 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29729683493676573		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.29729683493676573 | validation: 0.45829495417189425]
	TIME [epoch: 6.36 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39199167282758807		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.39199167282758807 | validation: 0.20838225825600787]
	TIME [epoch: 6.33 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26799798149676274		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.26799798149676274 | validation: 0.21448253798967054]
	TIME [epoch: 6.32 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27208516375362746		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.27208516375362746 | validation: 0.46483786664500193]
	TIME [epoch: 6.32 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3774337717302264		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.3774337717302264 | validation: 0.25320342495478176]
	TIME [epoch: 6.31 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39140262480616217		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.39140262480616217 | validation: 0.28519360700892565]
	TIME [epoch: 6.33 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30429492661377133		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.30429492661377133 | validation: 0.29915064234503064]
	TIME [epoch: 6.36 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3048816554281488		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.3048816554281488 | validation: 0.28658900793578307]
	TIME [epoch: 6.32 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33260421876701385		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.33260421876701385 | validation: 0.21756754723767976]
	TIME [epoch: 6.31 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2300763596013567		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.2300763596013567 | validation: 0.24163318656524002]
	TIME [epoch: 6.32 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4121081202222574		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.4121081202222574 | validation: 0.2508648744617154]
	TIME [epoch: 6.32 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31869740497821203		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.31869740497821203 | validation: 0.2222963012705119]
	TIME [epoch: 6.36 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2985277563083575		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.2985277563083575 | validation: 0.22463613784877268]
	TIME [epoch: 6.33 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3398726140535512		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.3398726140535512 | validation: 0.3427879692118219]
	TIME [epoch: 6.32 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2871888795031971		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.2871888795031971 | validation: 0.21685296963743794]
	TIME [epoch: 6.32 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22541262385579686		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.22541262385579686 | validation: 0.36609296555175597]
	TIME [epoch: 6.32 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30870501918136617		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.30870501918136617 | validation: 0.22372921122611794]
	TIME [epoch: 6.33 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.386684571730639		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.386684571730639 | validation: 0.2181565035902938]
	TIME [epoch: 6.36 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4071209963123308		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.4071209963123308 | validation: 0.36340756357643655]
	TIME [epoch: 6.32 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2747651248932246		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.2747651248932246 | validation: 0.17227424832241472]
	TIME [epoch: 6.32 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23011226270989688		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.23011226270989688 | validation: 0.24183052360796564]
	TIME [epoch: 6.32 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23251719572080745		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.23251719572080745 | validation: 0.21289886137601904]
	TIME [epoch: 6.33 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18702296698430795		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.18702296698430795 | validation: 0.6888254103015699]
	TIME [epoch: 6.36 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4655807693501606		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.4655807693501606 | validation: 0.2309657413158991]
	TIME [epoch: 6.32 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21009029059460982		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.21009029059460982 | validation: 0.1833584452416635]
	TIME [epoch: 6.32 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29643231160048594		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.29643231160048594 | validation: 0.16490904340158508]
	TIME [epoch: 6.32 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28262311673211826		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.28262311673211826 | validation: 0.9746513631967725]
	TIME [epoch: 6.31 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9333359236603986		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.9333359236603986 | validation: 1.0582007353852574]
	TIME [epoch: 6.34 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9544163014607047		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.9544163014607047 | validation: 0.7079546130432804]
	TIME [epoch: 6.34 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4609350683294227		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.4609350683294227 | validation: 0.269829684687856]
	TIME [epoch: 6.32 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29659778626388		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.29659778626388 | validation: 0.2881142439450104]
	TIME [epoch: 6.32 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27156708744195474		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.27156708744195474 | validation: 0.18551849535625642]
	TIME [epoch: 6.32 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23648241239795237		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.23648241239795237 | validation: 0.19699862431765125]
	TIME [epoch: 6.31 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33018901079563		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.33018901079563 | validation: 0.5320504157242666]
	TIME [epoch: 6.36 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3831179024375466		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.3831179024375466 | validation: 0.24865949659764558]
	TIME [epoch: 6.32 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31538631668931705		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.31538631668931705 | validation: 0.22612806063043422]
	TIME [epoch: 6.32 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26176082194614547		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.26176082194614547 | validation: 0.2280989005664072]
	TIME [epoch: 6.32 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37374649008677485		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.37374649008677485 | validation: 0.24470865494569338]
	TIME [epoch: 6.31 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20654514569557897		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.20654514569557897 | validation: 0.19804480379698902]
	TIME [epoch: 6.33 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30335097587175763		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.30335097587175763 | validation: 0.29133770654771163]
	TIME [epoch: 6.34 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32237142264198543		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.32237142264198543 | validation: 0.2477255704827554]
	TIME [epoch: 6.32 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3404662537558537		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.3404662537558537 | validation: 0.27173507772410876]
	TIME [epoch: 6.31 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3758872773322055		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.3758872773322055 | validation: 0.19997593242884942]
	TIME [epoch: 6.31 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18366046792626917		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.18366046792626917 | validation: 0.22403621565871346]
	TIME [epoch: 6.32 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3252585429358895		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.3252585429358895 | validation: 0.16248659711318314]
	TIME [epoch: 6.36 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22547923468414774		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.22547923468414774 | validation: 0.2570230640956591]
	TIME [epoch: 6.32 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22071603102039283		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.22071603102039283 | validation: 0.1599762004375493]
	TIME [epoch: 6.32 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_324.pth
	Model improved!!!
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31434382826369717		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.31434382826369717 | validation: 0.20924653218639033]
	TIME [epoch: 6.31 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21234231218080873		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.21234231218080873 | validation: 0.15501797245504276]
	TIME [epoch: 6.31 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_326.pth
	Model improved!!!
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.258966611926132		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.258966611926132 | validation: 0.22676773282839296]
	TIME [epoch: 6.35 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25026029708439335		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.25026029708439335 | validation: 0.20026189400559796]
	TIME [epoch: 6.32 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2739535695648183		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.2739535695648183 | validation: 0.2799363764390434]
	TIME [epoch: 6.31 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2894457246992703		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.2894457246992703 | validation: 0.2763998558548597]
	TIME [epoch: 6.31 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22524021496614374		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.22524021496614374 | validation: 0.2874846461253793]
	TIME [epoch: 6.31 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31601100881251004		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.31601100881251004 | validation: 0.29979115388979355]
	TIME [epoch: 6.32 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23615224633983972		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.23615224633983972 | validation: 0.21141426085334808]
	TIME [epoch: 6.34 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5504974824596769		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.5504974824596769 | validation: 0.41723058536994745]
	TIME [epoch: 6.32 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5495477610311825		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.5495477610311825 | validation: 0.4241609273807593]
	TIME [epoch: 6.31 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26489921677113154		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.26489921677113154 | validation: 0.34652708008402755]
	TIME [epoch: 6.31 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31652183839976317		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.31652183839976317 | validation: 0.32283014793222853]
	TIME [epoch: 6.31 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31204033024905775		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.31204033024905775 | validation: 0.2778688418459147]
	TIME [epoch: 6.35 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25038415966331123		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.25038415966331123 | validation: 0.22739060093640168]
	TIME [epoch: 6.31 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2487579581527825		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.2487579581527825 | validation: 0.15700164328820126]
	TIME [epoch: 6.31 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20581032905796895		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.20581032905796895 | validation: 0.18563112476098662]
	TIME [epoch: 6.31 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19581672041284282		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.19581672041284282 | validation: 0.25045416122190123]
	TIME [epoch: 6.31 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21737382826451201		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.21737382826451201 | validation: 0.14657118754753748]
	TIME [epoch: 6.33 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_343.pth
	Model improved!!!
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20505399238776212		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.20505399238776212 | validation: 0.22818418583967834]
	TIME [epoch: 6.34 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21401515619974437		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.21401515619974437 | validation: 0.14725666391067546]
	TIME [epoch: 6.31 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2487337322776365		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.2487337322776365 | validation: 0.23271774236099702]
	TIME [epoch: 6.31 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37880503525703424		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.37880503525703424 | validation: 0.17460097729677995]
	TIME [epoch: 6.31 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2292431894487052		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.2292431894487052 | validation: 0.5622620683258504]
	TIME [epoch: 6.31 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4727812445225559		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.4727812445225559 | validation: 0.17299590992164698]
	TIME [epoch: 6.36 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17398371025020964		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.17398371025020964 | validation: 0.15675633354869636]
	TIME [epoch: 6.31 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1729159299506451		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.1729159299506451 | validation: 0.20576874339557405]
	TIME [epoch: 6.31 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2733200290200148		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.2733200290200148 | validation: 0.29626866569080795]
	TIME [epoch: 6.31 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1989855568168171		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.1989855568168171 | validation: 0.27693081515615436]
	TIME [epoch: 6.31 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23392614183035648		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.23392614183035648 | validation: 0.15000626159329994]
	TIME [epoch: 6.35 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.301432413476374		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.301432413476374 | validation: 0.15826133771647938]
	TIME [epoch: 6.32 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19262294752014378		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.19262294752014378 | validation: 0.2222997682006036]
	TIME [epoch: 6.31 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20305900037134209		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.20305900037134209 | validation: 0.14397843771296948]
	TIME [epoch: 6.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_357.pth
	Model improved!!!
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15339496417860443		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.15339496417860443 | validation: 0.15660392307688442]
	TIME [epoch: 6.32 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21475517463367005		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.21475517463367005 | validation: 0.22473161495015856]
	TIME [epoch: 6.32 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4156817652981638		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.4156817652981638 | validation: 0.5092535712815766]
	TIME [epoch: 6.35 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3277086234939288		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.3277086234939288 | validation: 0.1634430012497306]
	TIME [epoch: 6.31 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29152879248477137		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.29152879248477137 | validation: 0.16929225310029472]
	TIME [epoch: 6.31 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2546484280605798		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.2546484280605798 | validation: 0.1476245675873712]
	TIME [epoch: 6.31 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18568039378612633		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.18568039378612633 | validation: 0.14749077010042172]
	TIME [epoch: 6.31 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16095406540463994		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.16095406540463994 | validation: 0.1627555954933329]
	TIME [epoch: 6.36 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1633337505756674		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.1633337505756674 | validation: 0.15576231770808602]
	TIME [epoch: 6.32 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1974305970196991		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.1974305970196991 | validation: 0.25933501292588823]
	TIME [epoch: 6.31 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8821820682922188		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.8821820682922188 | validation: 0.921783664339056]
	TIME [epoch: 6.31 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8818641061680091		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.8818641061680091 | validation: 0.14924627559712528]
	TIME [epoch: 6.31 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1856170733774153		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.1856170733774153 | validation: 0.16409363147607364]
	TIME [epoch: 6.34 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2529776433551219		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.2529776433551219 | validation: 0.14892889716386]
	TIME [epoch: 6.33 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16722059680185436		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.16722059680185436 | validation: 0.17378013579947474]
	TIME [epoch: 6.31 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29118527802253996		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.29118527802253996 | validation: 0.1534286396670227]
	TIME [epoch: 6.31 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21891177910895082		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.21891177910895082 | validation: 0.19650512895622013]
	TIME [epoch: 6.31 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3329026699422908		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.3329026699422908 | validation: 0.20774309599548865]
	TIME [epoch: 6.31 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4137513310690472		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.4137513310690472 | validation: 0.2590296057437231]
	TIME [epoch: 6.35 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22720038976313564		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.22720038976313564 | validation: 0.21551283047031317]
	TIME [epoch: 6.32 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3447061503322559		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.3447061503322559 | validation: 0.23900524729512648]
	TIME [epoch: 6.31 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2257542942283914		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.2257542942283914 | validation: 0.33689366726334924]
	TIME [epoch: 6.31 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25929223306375093		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.25929223306375093 | validation: 0.12605146900670322]
	TIME [epoch: 6.31 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_380.pth
	Model improved!!!
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18653553401525094		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.18653553401525094 | validation: 0.23227073090653705]
	TIME [epoch: 6.36 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2502048272037149		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.2502048272037149 | validation: 0.15789690342725252]
	TIME [epoch: 6.32 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20343842993951328		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.20343842993951328 | validation: 0.2723923842301787]
	TIME [epoch: 6.32 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23706514285010896		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.23706514285010896 | validation: 0.1584810039166591]
	TIME [epoch: 6.31 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1785919293102483		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.1785919293102483 | validation: 0.14812236866595116]
	TIME [epoch: 6.31 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2112635156001882		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.2112635156001882 | validation: 0.4267056690749132]
	TIME [epoch: 6.32 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7332382112651146		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.7332382112651146 | validation: 0.6763720622953175]
	TIME [epoch: 6.35 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4314046275784403		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.4314046275784403 | validation: 0.22071616272287886]
	TIME [epoch: 6.32 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23510348576007056		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.23510348576007056 | validation: 0.17464822850067727]
	TIME [epoch: 6.31 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2398237707876569		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.2398237707876569 | validation: 0.16118634341435373]
	TIME [epoch: 6.31 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19548393664405916		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.19548393664405916 | validation: 0.13943752295158904]
	TIME [epoch: 6.31 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23257001682500478		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.23257001682500478 | validation: 0.2588889537467811]
	TIME [epoch: 6.35 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2359503614201247		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.2359503614201247 | validation: 0.3782979198860761]
	TIME [epoch: 6.32 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24814750217020035		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.24814750217020035 | validation: 0.1506894952093199]
	TIME [epoch: 6.31 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2058970405245094		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.2058970405245094 | validation: 0.20280724146986787]
	TIME [epoch: 6.31 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.252146315941084		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.252146315941084 | validation: 0.3544954796227987]
	TIME [epoch: 6.31 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2659360443076828		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.2659360443076828 | validation: 0.1647004400086027]
	TIME [epoch: 6.32 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33915389290860865		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.33915389290860865 | validation: 0.14530898126979178]
	TIME [epoch: 6.35 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21244412400435753		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.21244412400435753 | validation: 0.19162775739548782]
	TIME [epoch: 6.31 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30628512247410816		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.30628512247410816 | validation: 0.17453038526313808]
	TIME [epoch: 6.31 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2091356672013932		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.2091356672013932 | validation: 0.2152656096120732]
	TIME [epoch: 6.31 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2351743084243736		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.2351743084243736 | validation: 0.3422783595848875]
	TIME [epoch: 6.31 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2514035264597673		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.2514035264597673 | validation: 0.16604570656252174]
	TIME [epoch: 6.35 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19173367865684693		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.19173367865684693 | validation: 0.14714052184413334]
	TIME [epoch: 6.31 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16009989679044845		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.16009989679044845 | validation: 0.14315800422420555]
	TIME [epoch: 6.31 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2888866770259501		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.2888866770259501 | validation: 0.5506984593821075]
	TIME [epoch: 6.31 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3621175655499027		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.3621175655499027 | validation: 0.20699340396721655]
	TIME [epoch: 6.31 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23003718606256474		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.23003718606256474 | validation: 0.18422504568315085]
	TIME [epoch: 6.33 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17890404041259342		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.17890404041259342 | validation: 0.13589776223098043]
	TIME [epoch: 6.33 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24462230111166208		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.24462230111166208 | validation: 0.1632454839830045]
	TIME [epoch: 6.31 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18237344179412318		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.18237344179412318 | validation: 0.39052040277606415]
	TIME [epoch: 6.31 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28139725692831696		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.28139725692831696 | validation: 0.23687274719922397]
	TIME [epoch: 6.31 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20187382602155796		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.20187382602155796 | validation: 0.2065827953947882]
	TIME [epoch: 6.32 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21412481614319243		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.21412481614319243 | validation: 0.16005024053237904]
	TIME [epoch: 6.36 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2078227533561593		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.2078227533561593 | validation: 0.25884745794112685]
	TIME [epoch: 6.32 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20738805407591063		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.20738805407591063 | validation: 0.14903318249895986]
	TIME [epoch: 6.31 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18918370538419416		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.18918370538419416 | validation: 0.12746634657442182]
	TIME [epoch: 6.3 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20542464601369675		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.20542464601369675 | validation: 0.18961919333728833]
	TIME [epoch: 6.31 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19399776026552798		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.19399776026552798 | validation: 0.14218307098883193]
	TIME [epoch: 6.34 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3425842297778413		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.3425842297778413 | validation: 0.37549624932414016]
	TIME [epoch: 6.33 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27070566608089985		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.27070566608089985 | validation: 0.15230848846083406]
	TIME [epoch: 6.31 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17444957128176636		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.17444957128176636 | validation: 0.12344538663739307]
	TIME [epoch: 6.31 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_422.pth
	Model improved!!!
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17463848004766552		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.17463848004766552 | validation: 0.1873935002817219]
	TIME [epoch: 6.31 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1876822519865041		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.1876822519865041 | validation: 0.18777016524582338]
	TIME [epoch: 6.31 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20077114873630011		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.20077114873630011 | validation: 0.14143175838615857]
	TIME [epoch: 6.35 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16193601948303654		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.16193601948303654 | validation: 0.12421869503284474]
	TIME [epoch: 6.31 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14251917284444424		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.14251917284444424 | validation: 0.16691436740841514]
	TIME [epoch: 6.31 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16690270281269184		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.16690270281269184 | validation: 0.22959192649486534]
	TIME [epoch: 6.31 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32597976818194807		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.32597976818194807 | validation: 0.15739199933571105]
	TIME [epoch: 6.31 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26463417150198837		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.26463417150198837 | validation: 0.18957090532467574]
	TIME [epoch: 6.35 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18334252500049966		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.18334252500049966 | validation: 0.13596562725308572]
	TIME [epoch: 6.32 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.256900356947787		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.256900356947787 | validation: 0.3133328581166697]
	TIME [epoch: 6.31 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26275902503832516		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.26275902503832516 | validation: 0.20272705809407027]
	TIME [epoch: 6.31 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18862899640012976		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.18862899640012976 | validation: 0.11954892568011097]
	TIME [epoch: 6.31 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_434.pth
	Model improved!!!
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1623451762956348		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.1623451762956348 | validation: 0.13639093396714136]
	TIME [epoch: 6.32 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16381397350726146		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.16381397350726146 | validation: 0.18310281592647287]
	TIME [epoch: 6.35 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24182348057590136		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.24182348057590136 | validation: 0.1826908115471933]
	TIME [epoch: 6.32 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18008203365628972		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.18008203365628972 | validation: 0.13831597658893713]
	TIME [epoch: 6.31 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15148989833159907		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.15148989833159907 | validation: 0.16661600093644682]
	TIME [epoch: 6.31 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17859171227024961		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.17859171227024961 | validation: 0.11148610631675668]
	TIME [epoch: 6.31 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_440.pth
	Model improved!!!
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14063127164140685		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.14063127164140685 | validation: 0.10502991065691453]
	TIME [epoch: 6.35 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_441.pth
	Model improved!!!
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15335534402992157		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.15335534402992157 | validation: 0.11225716261140574]
	TIME [epoch: 6.32 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23249169257128285		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.23249169257128285 | validation: 0.39400922342821604]
	TIME [epoch: 6.31 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2668913156980425		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.2668913156980425 | validation: 0.11752557807811728]
	TIME [epoch: 6.31 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13518282581021832		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.13518282581021832 | validation: 0.1966342039258708]
	TIME [epoch: 6.31 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4263816630909605		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.4263816630909605 | validation: 0.6115446945666319]
	TIME [epoch: 6.36 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36753103663603504		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.36753103663603504 | validation: 0.3539242656665649]
	TIME [epoch: 6.32 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4746592673439566		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.4746592673439566 | validation: 0.38208768777831736]
	TIME [epoch: 6.31 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3774094900981097		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.3774094900981097 | validation: 0.3110232128709327]
	TIME [epoch: 6.31 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2070453858277155		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.2070453858277155 | validation: 0.14428407847032357]
	TIME [epoch: 6.31 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16717927598472795		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.16717927598472795 | validation: 0.1451776060797051]
	TIME [epoch: 6.32 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1455894799354031		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.1455894799354031 | validation: 0.13043222198143412]
	TIME [epoch: 6.35 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3597134550420317		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.3597134550420317 | validation: 0.1457102727774391]
	TIME [epoch: 6.32 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18206215016395055		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.18206215016395055 | validation: 0.16657664624811408]
	TIME [epoch: 6.31 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1699645671486322		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.1699645671486322 | validation: 0.14573238865587076]
	TIME [epoch: 6.31 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28271687410851976		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.28271687410851976 | validation: 0.32565860855715456]
	TIME [epoch: 6.31 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48096419866608886		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.48096419866608886 | validation: 0.33174474860150305]
	TIME [epoch: 6.35 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24538895800921282		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.24538895800921282 | validation: 0.14305913308596493]
	TIME [epoch: 6.32 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15747338319267187		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.15747338319267187 | validation: 0.1219493147937091]
	TIME [epoch: 6.31 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18775132516038823		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.18775132516038823 | validation: 0.2134583401592119]
	TIME [epoch: 6.31 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22572536770612797		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.22572536770612797 | validation: 0.1804354056087773]
	TIME [epoch: 6.31 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20584111687917767		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.20584111687917767 | validation: 0.15821297334200446]
	TIME [epoch: 6.32 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16367907366100204		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.16367907366100204 | validation: 0.12877223380769257]
	TIME [epoch: 6.36 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13683399987309336		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.13683399987309336 | validation: 0.14685099778876273]
	TIME [epoch: 6.32 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29881055905009035		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.29881055905009035 | validation: 0.2140174772689094]
	TIME [epoch: 6.32 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23192810616360662		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.23192810616360662 | validation: 0.15012268689297997]
	TIME [epoch: 6.31 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15721519480243418		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.15721519480243418 | validation: 0.12905128114600964]
	TIME [epoch: 6.32 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15090849344920892		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.15090849344920892 | validation: 0.12096009846329009]
	TIME [epoch: 6.36 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14793292955416718		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.14793292955416718 | validation: 0.16730001261894895]
	TIME [epoch: 6.32 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14830691743310803		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.14830691743310803 | validation: 0.1254679545209953]
	TIME [epoch: 6.31 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21872265699747806		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.21872265699747806 | validation: 0.4175915010538271]
	TIME [epoch: 6.31 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2946186218667567		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.2946186218667567 | validation: 0.14849086871664052]
	TIME [epoch: 6.31 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14607367123123216		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.14607367123123216 | validation: 0.11606449518270515]
	TIME [epoch: 6.34 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16347694067652907		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.16347694067652907 | validation: 0.14836839361686546]
	TIME [epoch: 6.34 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16086435691192233		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.16086435691192233 | validation: 0.14301910992273356]
	TIME [epoch: 6.31 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16507280036992747		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.16507280036992747 | validation: 0.12327097261255372]
	TIME [epoch: 6.32 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15157454418213706		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.15157454418213706 | validation: 0.10645567526828725]
	TIME [epoch: 6.31 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2318095132712345		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.2318095132712345 | validation: 0.29486476898883207]
	TIME [epoch: 6.31 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3269245868088875		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.3269245868088875 | validation: 0.2149890253674634]
	TIME [epoch: 6.36 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.230651847336711		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.230651847336711 | validation: 0.18738615928275162]
	TIME [epoch: 6.32 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17004383503084933		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.17004383503084933 | validation: 0.12662948276510547]
	TIME [epoch: 6.32 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28572422290033145		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.28572422290033145 | validation: 0.2201955328729483]
	TIME [epoch: 6.31 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21055202187121272		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.21055202187121272 | validation: 0.1078689020545263]
	TIME [epoch: 6.31 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18737151127787063		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.18737151127787063 | validation: 0.1312582705625036]
	TIME [epoch: 6.34 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16867104827948048		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.16867104827948048 | validation: 0.1250817955960044]
	TIME [epoch: 6.33 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14462870364190009		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.14462870364190009 | validation: 0.11924872905645581]
	TIME [epoch: 6.31 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13960360138279787		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.13960360138279787 | validation: 0.1064120507442424]
	TIME [epoch: 6.31 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1446327824702517		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.1446327824702517 | validation: 0.2152173204355731]
	TIME [epoch: 6.31 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18141577938378844		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.18141577938378844 | validation: 0.15913708836702745]
	TIME [epoch: 6.32 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28538695951218945		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.28538695951218945 | validation: 0.21100140208176207]
	TIME [epoch: 6.36 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22306234083094933		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.22306234083094933 | validation: 0.10775888194906472]
	TIME [epoch: 6.31 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21533915680388738		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.21533915680388738 | validation: 0.20523400165564898]
	TIME [epoch: 6.3 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2338958282480381		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.2338958282480381 | validation: 0.253304412270225]
	TIME [epoch: 6.31 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4877034747973827		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.4877034747973827 | validation: 0.3493694308558143]
	TIME [epoch: 6.31 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48998279675052214		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.48998279675052214 | validation: 0.1619499522110217]
	TIME [epoch: 6.35 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23884614521291303		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.23884614521291303 | validation: 0.2614596989140253]
	TIME [epoch: 6.32 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3517187000186159		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.3517187000186159 | validation: 0.32316402233395836]
	TIME [epoch: 6.32 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.276120391796133		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.276120391796133 | validation: 0.14870836831546916]
	TIME [epoch: 6.31 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1817458033713718		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.1817458033713718 | validation: 0.1688365147344756]
	TIME [epoch: 6.3 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26386459460261874		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.26386459460261874 | validation: 0.37647809207114746]
	TIME [epoch: 6.32 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28667619615578055		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.28667619615578055 | validation: 0.1537620337726773]
	TIME [epoch: 6.35 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22925192490902851		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.22925192490902851 | validation: 0.2789573032888263]
	TIME [epoch: 6.31 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2130865837550199		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.2130865837550199 | validation: 0.12563109060464372]
	TIME [epoch: 6.31 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24992162018064323		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.24992162018064323 | validation: 0.12487615334302524]
	TIME [epoch: 6.31 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15175839094875537		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.15175839094875537 | validation: 0.09962494118843687]
	TIME [epoch: 6.32 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_505.pth
	Model improved!!!
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1514183934706074		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.1514183934706074 | validation: 0.1367159828468713]
	TIME [epoch: 6.34 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15344352493725097		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.15344352493725097 | validation: 0.1907712999607329]
	TIME [epoch: 6.32 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32930727513524827		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.32930727513524827 | validation: 0.6361980205461677]
	TIME [epoch: 6.32 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7056609553061449		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.7056609553061449 | validation: 0.3326223575742733]
	TIME [epoch: 6.32 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2478149829611629		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.2478149829611629 | validation: 0.1717120871860104]
	TIME [epoch: 6.32 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21867213808624436		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.21867213808624436 | validation: 0.1611612070460896]
	TIME [epoch: 6.34 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19099685864947857		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.19099685864947857 | validation: 0.15214775135275294]
	TIME [epoch: 6.34 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.183686694592266		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.183686694592266 | validation: 0.16499195960603696]
	TIME [epoch: 6.31 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15031506197553324		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.15031506197553324 | validation: 0.11568021424519818]
	TIME [epoch: 6.23 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1770146181719857		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.1770146181719857 | validation: 0.22932228973408736]
	TIME [epoch: 6.26 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3184711269460527		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.3184711269460527 | validation: 0.14755849983573543]
	TIME [epoch: 6.32 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16299305323173063		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.16299305323173063 | validation: 0.11462077640874059]
	TIME [epoch: 6.36 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13614782929906896		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.13614782929906896 | validation: 0.10758215955152048]
	TIME [epoch: 6.32 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14357775453954644		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.14357775453954644 | validation: 0.11336388227116645]
	TIME [epoch: 6.31 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18344789177513032		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.18344789177513032 | validation: 0.13066121652456128]
	TIME [epoch: 6.31 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16076981150244307		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.16076981150244307 | validation: 0.1164351710995431]
	TIME [epoch: 6.31 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32498262839064174		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.32498262839064174 | validation: 0.21462055533215374]
	TIME [epoch: 6.29 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3035686444360863		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.3035686444360863 | validation: 0.20804513600189264]
	TIME [epoch: 6.27 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2984353990644288		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.2984353990644288 | validation: 0.16714339873510087]
	TIME [epoch: 6.25 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2154320840434314		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.2154320840434314 | validation: 0.34816522267285455]
	TIME [epoch: 6.27 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3792663184365721		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.3792663184365721 | validation: 0.22552019395671752]
	TIME [epoch: 6.26 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.219158621324541		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.219158621324541 | validation: 0.1508888040720522]
	TIME [epoch: 6.27 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1765624767773153		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.1765624767773153 | validation: 0.15988122752341596]
	TIME [epoch: 6.31 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2920744344398636		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.2920744344398636 | validation: 0.14194058965898665]
	TIME [epoch: 6.26 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16250506705385678		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.16250506705385678 | validation: 0.1728200816119183]
	TIME [epoch: 6.26 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17236633140969237		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.17236633140969237 | validation: 0.12849033328836265]
	TIME [epoch: 6.26 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17644884160255836		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.17644884160255836 | validation: 0.16155957922765032]
	TIME [epoch: 6.25 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2326654303684774		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.2326654303684774 | validation: 0.14592504694184816]
	TIME [epoch: 6.28 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17018669357205451		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.17018669357205451 | validation: 0.15422609720613917]
	TIME [epoch: 6.28 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1462945465672125		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.1462945465672125 | validation: 0.09503261370432323]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_535.pth
	Model improved!!!
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15428514874757282		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.15428514874757282 | validation: 0.1381578499307876]
	TIME [epoch: 6.25 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16765088322625388		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.16765088322625388 | validation: 0.11329151099343776]
	TIME [epoch: 6.31 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15475633322050653		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.15475633322050653 | validation: 0.14574585926291977]
	TIME [epoch: 6.32 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2313180839264108		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.2313180839264108 | validation: 0.17155895145466246]
	TIME [epoch: 6.34 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17963346269702135		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.17963346269702135 | validation: 0.08582899381901127]
	TIME [epoch: 6.32 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_540.pth
	Model improved!!!
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12188528797275269		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.12188528797275269 | validation: 0.10676750772224955]
	TIME [epoch: 6.3 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1301352787207868		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.1301352787207868 | validation: 0.09328183691141471]
	TIME [epoch: 6.31 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14784525551660083		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.14784525551660083 | validation: 0.1541991337953988]
	TIME [epoch: 6.3 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13650183030272828		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.13650183030272828 | validation: 0.10576660345302766]
	TIME [epoch: 6.35 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17848210817453275		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.17848210817453275 | validation: 0.1912166325850094]
	TIME [epoch: 6.31 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2788724584088529		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.2788724584088529 | validation: 0.14962897829571203]
	TIME [epoch: 6.3 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15501045040995307		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.15501045040995307 | validation: 0.12491061438103705]
	TIME [epoch: 6.3 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13205650977067393		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.13205650977067393 | validation: 0.10821032745063867]
	TIME [epoch: 6.3 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14138378225895348		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.14138378225895348 | validation: 0.09626453875854069]
	TIME [epoch: 6.32 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.130635848877042		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.130635848877042 | validation: 0.12762304769608318]
	TIME [epoch: 6.33 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17020531304174918		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.17020531304174918 | validation: 0.1256450239450327]
	TIME [epoch: 6.31 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14827079616803798		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.14827079616803798 | validation: 0.11530711231996302]
	TIME [epoch: 6.31 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15609893042294332		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.15609893042294332 | validation: 0.13331036469138313]
	TIME [epoch: 6.31 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2032734917667976		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.2032734917667976 | validation: 0.1096053031278328]
	TIME [epoch: 6.31 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14970217124700969		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.14970217124700969 | validation: 0.10873621561659472]
	TIME [epoch: 6.35 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21095748556794586		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.21095748556794586 | validation: 0.21655512899598253]
	TIME [epoch: 6.31 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18720558972546006		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.18720558972546006 | validation: 0.11106986638422443]
	TIME [epoch: 6.31 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15999823914796205		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.15999823914796205 | validation: 0.13876247100564285]
	TIME [epoch: 6.3 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1536493972936679		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.1536493972936679 | validation: 0.11311237945049044]
	TIME [epoch: 6.3 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1591853660827081		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.1591853660827081 | validation: 0.19833875695829623]
	TIME [epoch: 6.32 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1725728081366703		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.1725728081366703 | validation: 0.1276141040240638]
	TIME [epoch: 6.33 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15204592598974706		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.15204592598974706 | validation: 0.1379700998051238]
	TIME [epoch: 6.3 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2301284890298836		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.2301284890298836 | validation: 0.26873797936266075]
	TIME [epoch: 6.3 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23498445543373808		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.23498445543373808 | validation: 0.11885090928245771]
	TIME [epoch: 6.3 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1274387052092905		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.1274387052092905 | validation: 0.09145591000791992]
	TIME [epoch: 6.31 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11262405061814021		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.11262405061814021 | validation: 0.11687033358316101]
	TIME [epoch: 6.35 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14347702304225596		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.14347702304225596 | validation: 0.13930339326989738]
	TIME [epoch: 6.31 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20033988558554028		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.20033988558554028 | validation: 0.24237578231162799]
	TIME [epoch: 6.3 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1703727442666298		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.1703727442666298 | validation: 0.09779639945397513]
	TIME [epoch: 6.29 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.112691121243522		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.112691121243522 | validation: 0.13585013939247098]
	TIME [epoch: 6.3 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13646619920428962		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.13646619920428962 | validation: 0.09251357340818775]
	TIME [epoch: 6.34 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10319399572337012		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.10319399572337012 | validation: 0.07567918801091715]
	TIME [epoch: 6.31 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_572.pth
	Model improved!!!
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0985203069381311		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.0985203069381311 | validation: 0.14316122397395487]
	TIME [epoch: 6.32 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19959966971657112		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.19959966971657112 | validation: 0.11129027749121606]
	TIME [epoch: 6.32 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13955110351763597		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.13955110351763597 | validation: 0.10222149484752825]
	TIME [epoch: 6.32 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09770616117103931		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.09770616117103931 | validation: 0.07627046223085716]
	TIME [epoch: 6.32 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09755805601924059		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.09755805601924059 | validation: 0.08446740276465645]
	TIME [epoch: 6.35 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10152769711672892		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.10152769711672892 | validation: 0.08574931239554054]
	TIME [epoch: 6.32 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15109791893655164		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.15109791893655164 | validation: 0.14461590581239203]
	TIME [epoch: 6.3 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14648698055766868		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.14648698055766868 | validation: 0.11377095595637902]
	TIME [epoch: 6.31 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14684661776248914		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.14684661776248914 | validation: 0.1270952634368523]
	TIME [epoch: 6.31 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11979988062613892		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.11979988062613892 | validation: 0.11419890863931112]
	TIME [epoch: 6.35 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19855596179700857		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.19855596179700857 | validation: 0.12408724805227193]
	TIME [epoch: 6.32 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13730084816053698		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.13730084816053698 | validation: 0.08117853405479497]
	TIME [epoch: 6.31 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11107409290468212		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.11107409290468212 | validation: 0.07964323750959082]
	TIME [epoch: 6.31 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11097070762183031		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.11097070762183031 | validation: 0.19317692313475787]
	TIME [epoch: 6.31 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26517370324140416		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.26517370324140416 | validation: 0.16377982557315943]
	TIME [epoch: 6.33 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2163689311752181		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.2163689311752181 | validation: 0.1687950335244372]
	TIME [epoch: 6.34 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31118750296568076		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.31118750296568076 | validation: 0.19716909737669255]
	TIME [epoch: 6.31 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19044117260932852		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.19044117260932852 | validation: 0.09820778523078996]
	TIME [epoch: 6.31 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1215377422572823		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.1215377422572823 | validation: 0.14238892879236714]
	TIME [epoch: 6.31 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15666619458667955		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.15666619458667955 | validation: 0.15118759231388332]
	TIME [epoch: 6.31 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18688215075727502		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.18688215075727502 | validation: 0.12331078030634163]
	TIME [epoch: 6.36 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17465343165696343		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.17465343165696343 | validation: 0.18452286853331973]
	TIME [epoch: 6.31 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15168624103818518		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.15168624103818518 | validation: 0.1151257640220236]
	TIME [epoch: 6.3 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12519302015459327		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.12519302015459327 | validation: 0.14065861626970605]
	TIME [epoch: 6.31 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20788705368090643		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.20788705368090643 | validation: 0.14506644059403917]
	TIME [epoch: 6.31 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15775429957817794		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.15775429957817794 | validation: 0.10326863803184522]
	TIME [epoch: 6.31 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11856046352366813		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.11856046352366813 | validation: 0.08464426388032312]
	TIME [epoch: 6.31 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10556949821880657		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.10556949821880657 | validation: 0.10315806177145032]
	TIME [epoch: 6.3 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1067317578793196		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.1067317578793196 | validation: 0.0869963447313013]
	TIME [epoch: 6.29 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17668223565563393		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.17668223565563393 | validation: 0.13574491334048278]
	TIME [epoch: 6.28 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.135300654766489		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.135300654766489 | validation: 0.08870064785265619]
	TIME [epoch: 6.29 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10089588868817681		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.10089588868817681 | validation: 0.10320100726797465]
	TIME [epoch: 6.33 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10962964485102769		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.10962964485102769 | validation: 0.08421919893750654]
	TIME [epoch: 6.3 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1435840459266733		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.1435840459266733 | validation: 0.10017149242333427]
	TIME [epoch: 6.29 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15187032782923554		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.15187032782923554 | validation: 0.08950025245607324]
	TIME [epoch: 6.28 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10657634993994716		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.10657634993994716 | validation: 0.08991486631020408]
	TIME [epoch: 6.29 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11758350798599856		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.11758350798599856 | validation: 0.07905611099464091]
	TIME [epoch: 6.33 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09357606857300498		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.09357606857300498 | validation: 0.09031503189369995]
	TIME [epoch: 6.34 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14694428641366633		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.14694428641366633 | validation: 0.08846504266038974]
	TIME [epoch: 6.31 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15886817145247245		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.15886817145247245 | validation: 0.20953270516918582]
	TIME [epoch: 6.31 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19499924981833267		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.19499924981833267 | validation: 0.17661558628731733]
	TIME [epoch: 6.31 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23715511075027076		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.23715511075027076 | validation: 0.1577032056050398]
	TIME [epoch: 6.32 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13632867208756821		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.13632867208756821 | validation: 0.09582545032487327]
	TIME [epoch: 6.35 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1308220178177755		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.1308220178177755 | validation: 0.07708433345714678]
	TIME [epoch: 6.31 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10734898510944489		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.10734898510944489 | validation: 0.16030495298931016]
	TIME [epoch: 6.31 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19174826742057144		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.19174826742057144 | validation: 0.13398173217781117]
	TIME [epoch: 6.31 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13045624429834646		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.13045624429834646 | validation: 0.09667115380784842]
	TIME [epoch: 6.32 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17785704511069797		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.17785704511069797 | validation: 0.14919880826015747]
	TIME [epoch: 6.35 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2362860765000951		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.2362860765000951 | validation: 0.14668222264566327]
	TIME [epoch: 6.32 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19914451487053453		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.19914451487053453 | validation: 0.12562912364413925]
	TIME [epoch: 6.31 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16279852511175347		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.16279852511175347 | validation: 0.13920110172062156]
	TIME [epoch: 6.31 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21727498729801847		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.21727498729801847 | validation: 0.11202138016758408]
	TIME [epoch: 6.32 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16735070242701006		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.16735070242701006 | validation: 0.1625342094790216]
	TIME [epoch: 6.33 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23856722280734216		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.23856722280734216 | validation: 0.1548526335493341]
	TIME [epoch: 6.35 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19145805402462118		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.19145805402462118 | validation: 0.08886509035305645]
	TIME [epoch: 6.32 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12758666668464713		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.12758666668464713 | validation: 0.09159619682825013]
	TIME [epoch: 6.32 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15747314911423038		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.15747314911423038 | validation: 0.0927294336679215]
	TIME [epoch: 6.31 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12913390872282862		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.12913390872282862 | validation: 0.10171783683662997]
	TIME [epoch: 6.31 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12410634530542021		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.12410634530542021 | validation: 0.11180468151841941]
	TIME [epoch: 6.36 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1643636698308817		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.1643636698308817 | validation: 0.15809741510346725]
	TIME [epoch: 6.32 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13954602882511763		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.13954602882511763 | validation: 0.08378507054062992]
	TIME [epoch: 6.32 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11857762158620463		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.11857762158620463 | validation: 0.09377501443528521]
	TIME [epoch: 6.32 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11245655345371007		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.11245655345371007 | validation: 0.07702810286415956]
	TIME [epoch: 6.32 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10079752027169442		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.10079752027169442 | validation: 0.0795831433721412]
	TIME [epoch: 6.32 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10435293501845168		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.10435293501845168 | validation: 0.08395674357407926]
	TIME [epoch: 6.35 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11163370013071337		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.11163370013071337 | validation: 0.08214316832977492]
	TIME [epoch: 6.32 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11994476017912463		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.11994476017912463 | validation: 0.10070920861292272]
	TIME [epoch: 6.32 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1462020556339169		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.1462020556339169 | validation: 0.15458555686450642]
	TIME [epoch: 6.31 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16389519886638299		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.16389519886638299 | validation: 0.09562728941365295]
	TIME [epoch: 6.31 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12575438077576168		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.12575438077576168 | validation: 0.09384224152671564]
	TIME [epoch: 6.36 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1181617090653269		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.1181617090653269 | validation: 0.0633276772366989]
	TIME [epoch: 6.33 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_643.pth
	Model improved!!!
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09893908277686692		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.09893908277686692 | validation: 0.10860738372667565]
	TIME [epoch: 6.32 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20195425040959586		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.20195425040959586 | validation: 0.19032815480464188]
	TIME [epoch: 6.32 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15678459890845783		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.15678459890845783 | validation: 0.09252954431609439]
	TIME [epoch: 6.32 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12515325082281104		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.12515325082281104 | validation: 0.07700027181274112]
	TIME [epoch: 6.36 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11617991432226443		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.11617991432226443 | validation: 0.11789421215267887]
	TIME [epoch: 6.33 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1370676080183804		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.1370676080183804 | validation: 0.09174251712641168]
	TIME [epoch: 6.32 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10443036145082571		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.10443036145082571 | validation: 0.07472535449868631]
	TIME [epoch: 6.32 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09840052333724966		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.09840052333724966 | validation: 0.0659612806609382]
	TIME [epoch: 6.32 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1040791663903268		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.1040791663903268 | validation: 0.08723778732015332]
	TIME [epoch: 6.33 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26449008825644665		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.26449008825644665 | validation: 0.27424981416342353]
	TIME [epoch: 6.35 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28333718976002487		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.28333718976002487 | validation: 0.12921299480964663]
	TIME [epoch: 6.32 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13392589985824588		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.13392589985824588 | validation: 0.1042492627200341]
	TIME [epoch: 6.31 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11260222047796775		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.11260222047796775 | validation: 0.07457585195743824]
	TIME [epoch: 6.32 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11597094187631558		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.11597094187631558 | validation: 0.09039763918832075]
	TIME [epoch: 6.31 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10567861108629323		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.10567861108629323 | validation: 0.09203498961828405]
	TIME [epoch: 6.35 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09779070554648871		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.09779070554648871 | validation: 0.0833114788054207]
	TIME [epoch: 6.33 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09900352505527349		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.09900352505527349 | validation: 0.08364981489182922]
	TIME [epoch: 6.32 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10583873543231384		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.10583873543231384 | validation: 0.1086850165336718]
	TIME [epoch: 6.32 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10736609690132981		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.10736609690132981 | validation: 0.07192939716581839]
	TIME [epoch: 6.31 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11435206538010548		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.11435206538010548 | validation: 0.1305082880612304]
	TIME [epoch: 6.33 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21222010542910832		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.21222010542910832 | validation: 0.1093626299629048]
	TIME [epoch: 6.35 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12249011372920046		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.12249011372920046 | validation: 0.08437142268061551]
	TIME [epoch: 6.32 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11995572982172684		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.11995572982172684 | validation: 0.10090647712119091]
	TIME [epoch: 6.31 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10706470128112452		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.10706470128112452 | validation: 0.12053232031302612]
	TIME [epoch: 6.31 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12274118535649635		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.12274118535649635 | validation: 0.09147849549907328]
	TIME [epoch: 6.31 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10150044054546162		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.10150044054546162 | validation: 0.08960901187681097]
	TIME [epoch: 6.36 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11198829201719598		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.11198829201719598 | validation: 0.08985809047450752]
	TIME [epoch: 6.32 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09694687164524578		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.09694687164524578 | validation: 0.06876333652489063]
	TIME [epoch: 6.31 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08888988268963466		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.08888988268963466 | validation: 0.07127716019084603]
	TIME [epoch: 6.31 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09000116990844756		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.09000116990844756 | validation: 0.09117692594275184]
	TIME [epoch: 6.31 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11930350575299362		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.11930350575299362 | validation: 0.06280016856293283]
	TIME [epoch: 6.34 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_674.pth
	Model improved!!!
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09481419795442586		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.09481419795442586 | validation: 0.0771005821335767]
	TIME [epoch: 6.35 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08408256871437499		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.08408256871437499 | validation: 0.07639943959978907]
	TIME [epoch: 6.31 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10098301135008839		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.10098301135008839 | validation: 0.07930558404099716]
	TIME [epoch: 6.3 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08804838316456476		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.08804838316456476 | validation: 0.09599434233521102]
	TIME [epoch: 6.31 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10896600412710317		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.10896600412710317 | validation: 0.10548473977530048]
	TIME [epoch: 6.32 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1496401914984321		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.1496401914984321 | validation: 0.23985029316306444]
	TIME [epoch: 6.36 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23702468534271018		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.23702468534271018 | validation: 0.11685119433603039]
	TIME [epoch: 6.32 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1016291073304221		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.1016291073304221 | validation: 0.08111015773493005]
	TIME [epoch: 6.31 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08480106400045262		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.08480106400045262 | validation: 0.07777650145195791]
	TIME [epoch: 6.31 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09082124372945426		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.09082124372945426 | validation: 0.09156589009189481]
	TIME [epoch: 6.31 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14942424480775116		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.14942424480775116 | validation: 0.18395083281454994]
	TIME [epoch: 6.35 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15439672530584309		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.15439672530584309 | validation: 0.0676415711385353]
	TIME [epoch: 6.32 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07965556878934305		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.07965556878934305 | validation: 0.06608676538752017]
	TIME [epoch: 6.31 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09458016134385677		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.09458016134385677 | validation: 0.05813320587944822]
	TIME [epoch: 6.31 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_688.pth
	Model improved!!!
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08931884806890185		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.08931884806890185 | validation: 0.09104390578471727]
	TIME [epoch: 6.31 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12970606557624828		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.12970606557624828 | validation: 0.14399776105079795]
	TIME [epoch: 6.33 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1712930854593488		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.1712930854593488 | validation: 0.1307977343750721]
	TIME [epoch: 6.35 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12956540096581692		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.12956540096581692 | validation: 0.09232529191090541]
	TIME [epoch: 6.32 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14630284307824015		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.14630284307824015 | validation: 0.16473021014796752]
	TIME [epoch: 6.3 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16649273874749598		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.16649273874749598 | validation: 0.09110487775970076]
	TIME [epoch: 6.28 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11436034496877404		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.11436034496877404 | validation: 0.07645470555514597]
	TIME [epoch: 6.28 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09933957478701938		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.09933957478701938 | validation: 0.07569450918767283]
	TIME [epoch: 6.34 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08755980079806781		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.08755980079806781 | validation: 0.06903778607394555]
	TIME [epoch: 6.3 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09426860619905585		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.09426860619905585 | validation: 0.07414287943883098]
	TIME [epoch: 6.29 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11135454441473085		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.11135454441473085 | validation: 0.0684882210596724]
	TIME [epoch: 6.3 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10281338698157648		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.10281338698157648 | validation: 0.06677693722062056]
	TIME [epoch: 6.3 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07933889315232082		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.07933889315232082 | validation: 0.0785162655861321]
	TIME [epoch: 6.32 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18182949238520302		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.18182949238520302 | validation: 0.1601883729124396]
	TIME [epoch: 6.32 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17518352270543922		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.17518352270543922 | validation: 0.08394889904775935]
	TIME [epoch: 6.28 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09738522068403231		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.09738522068403231 | validation: 0.1061672795600137]
	TIME [epoch: 6.29 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11109836588948216		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.11109836588948216 | validation: 0.07926022161925536]
	TIME [epoch: 6.29 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09794645794080636		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.09794645794080636 | validation: 0.12883554405648345]
	TIME [epoch: 6.29 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21830675054592943		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.21830675054592943 | validation: 0.10962009265446908]
	TIME [epoch: 6.36 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13174108807028873		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.13174108807028873 | validation: 0.1361861942597088]
	TIME [epoch: 6.32 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14267139614095084		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.14267139614095084 | validation: 0.11510489087252157]
	TIME [epoch: 6.31 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09925184421268028		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.09925184421268028 | validation: 0.06676546771324383]
	TIME [epoch: 6.32 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08802370617836641		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.08802370617836641 | validation: 0.10840030727236026]
	TIME [epoch: 6.31 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11448586525394779		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.11448586525394779 | validation: 0.07691169460380792]
	TIME [epoch: 6.34 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10602811837892305		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.10602811837892305 | validation: 0.07916771989715914]
	TIME [epoch: 6.34 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10268654568284381		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.10268654568284381 | validation: 0.07337179311729566]
	TIME [epoch: 6.31 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11149796478782584		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.11149796478782584 | validation: 0.08183226921590389]
	TIME [epoch: 6.31 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13266933371341483		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.13266933371341483 | validation: 0.07633103725627871]
	TIME [epoch: 6.31 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10411152940209487		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.10411152940209487 | validation: 0.08499337477115099]
	TIME [epoch: 6.31 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10956336854369256		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.10956336854369256 | validation: 0.08199165397261235]
	TIME [epoch: 6.36 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10893466560835556		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.10893466560835556 | validation: 0.07268734279499602]
	TIME [epoch: 6.32 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09188094638382559		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.09188094638382559 | validation: 0.06770030612271255]
	TIME [epoch: 6.31 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08907517075949803		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.08907517075949803 | validation: 0.08210553420035029]
	TIME [epoch: 6.31 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11096716566169085		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.11096716566169085 | validation: 0.08959147563194259]
	TIME [epoch: 6.31 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11119738756160921		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.11119738756160921 | validation: 0.08884187820526421]
	TIME [epoch: 6.36 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10116330353443176		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.10116330353443176 | validation: 0.07507094519157342]
	TIME [epoch: 6.32 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09939212894302232		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.09939212894302232 | validation: 0.08667281057317154]
	TIME [epoch: 6.32 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12520172982287478		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.12520172982287478 | validation: 0.13051255736401768]
	TIME [epoch: 6.3 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17509883201304488		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.17509883201304488 | validation: 0.0903591140266058]
	TIME [epoch: 6.31 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14158974824947418		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.14158974824947418 | validation: 0.08932986313821947]
	TIME [epoch: 6.32 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10345930498040781		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.10345930498040781 | validation: 0.06977381547140676]
	TIME [epoch: 6.35 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10585894418179659		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.10585894418179659 | validation: 0.07202529129301033]
	TIME [epoch: 6.32 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08852570340151898		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.08852570340151898 | validation: 0.0715185276603099]
	TIME [epoch: 6.31 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0891982891172253		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.0891982891172253 | validation: 0.07269994370249862]
	TIME [epoch: 6.31 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12174259633438761		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.12174259633438761 | validation: 0.10667463072177238]
	TIME [epoch: 6.31 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11195281279492146		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.11195281279492146 | validation: 0.0689826326905596]
	TIME [epoch: 6.36 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08059496108157808		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.08059496108157808 | validation: 0.06570698220711146]
	TIME [epoch: 6.32 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07823922236798624		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.07823922236798624 | validation: 0.08392961763277448]
	TIME [epoch: 6.32 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09782295044506031		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.09782295044506031 | validation: 0.08249004919379313]
	TIME [epoch: 6.31 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12352676380096743		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.12352676380096743 | validation: 0.10071331641915346]
	TIME [epoch: 6.31 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13655756623252988		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.13655756623252988 | validation: 0.11152503179866388]
	TIME [epoch: 6.32 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1537900819842839		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.1537900819842839 | validation: 0.11024163852114861]
	TIME [epoch: 6.35 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11295951815627218		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.11295951815627218 | validation: 0.07028382432742186]
	TIME [epoch: 6.31 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08831888615340382		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.08831888615340382 | validation: 0.0772991289451225]
	TIME [epoch: 6.31 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0928688515197629		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.0928688515197629 | validation: 0.08072719048346663]
	TIME [epoch: 6.32 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10118467623507679		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.10118467623507679 | validation: 0.09545531905196954]
	TIME [epoch: 6.31 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1484924434085043		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.1484924434085043 | validation: 0.14474307490006644]
	TIME [epoch: 6.36 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2363736385312266		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.2363736385312266 | validation: 0.19465719976509693]
	TIME [epoch: 6.31 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2692622359835351		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.2692622359835351 | validation: 0.1208073189368098]
	TIME [epoch: 6.31 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11332151925495457		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.11332151925495457 | validation: 0.06954131571957756]
	TIME [epoch: 6.31 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08016488070575961		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.08016488070575961 | validation: 0.07885492801736192]
	TIME [epoch: 6.31 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09291459913931482		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.09291459913931482 | validation: 0.05907800820863869]
	TIME [epoch: 6.33 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09102965187207679		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.09102965187207679 | validation: 0.09873479840684501]
	TIME [epoch: 6.32 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11427286397980772		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.11427286397980772 | validation: 0.07977883383419082]
	TIME [epoch: 6.29 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07747258368726012		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.07747258368726012 | validation: 0.06956989575233447]
	TIME [epoch: 6.28 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12054821822401016		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.12054821822401016 | validation: 0.10473945451051245]
	TIME [epoch: 6.28 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12186812938815779		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.12186812938815779 | validation: 0.07581885542976308]
	TIME [epoch: 6.29 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10735158494050889		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.10735158494050889 | validation: 0.057836138389983444]
	TIME [epoch: 6.33 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_756.pth
	Model improved!!!
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09168906731286658		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.09168906731286658 | validation: 0.06171687297149588]
	TIME [epoch: 6.29 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08293242595899633		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.08293242595899633 | validation: 0.04538830904936463]
	TIME [epoch: 6.28 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_758.pth
	Model improved!!!
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07083994633475843		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.07083994633475843 | validation: 0.05891545906441267]
	TIME [epoch: 6.29 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08820537159176116		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.08820537159176116 | validation: 0.05841231140616811]
	TIME [epoch: 6.29 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06856558945901439		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.06856558945901439 | validation: 0.0586752939996353]
	TIME [epoch: 6.33 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08111816040346222		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.08111816040346222 | validation: 0.06208511643775717]
	TIME [epoch: 6.3 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07877976969210702		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.07877976969210702 | validation: 0.07675156936580678]
	TIME [epoch: 6.28 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07846718347251858		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.07846718347251858 | validation: 0.09352962050753472]
	TIME [epoch: 6.29 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08306491824436196		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.08306491824436196 | validation: 0.06572660415968393]
	TIME [epoch: 6.28 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07645741868075887		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.07645741868075887 | validation: 0.06872032813997436]
	TIME [epoch: 6.32 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08705024906474007		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.08705024906474007 | validation: 0.06744469322786815]
	TIME [epoch: 6.35 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08343237777310451		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.08343237777310451 | validation: 0.052094680143375094]
	TIME [epoch: 6.32 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08428230907044854		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.08428230907044854 | validation: 0.0642498534455873]
	TIME [epoch: 6.31 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09766575913199385		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.09766575913199385 | validation: 0.06509860004849258]
	TIME [epoch: 6.31 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08601067333792244		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.08601067333792244 | validation: 0.06836280336603268]
	TIME [epoch: 6.31 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08022497949747244		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.08022497949747244 | validation: 0.051730392764969456]
	TIME [epoch: 6.36 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07871237364713433		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.07871237364713433 | validation: 0.06936875633646325]
	TIME [epoch: 6.32 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14456162831508834		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.14456162831508834 | validation: 0.12870462942969274]
	TIME [epoch: 6.32 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2176829727977822		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.2176829727977822 | validation: 0.1448486612951605]
	TIME [epoch: 6.31 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23734230708148535		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.23734230708148535 | validation: 0.1558573130840043]
	TIME [epoch: 6.31 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19767223879810322		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.19767223879810322 | validation: 0.0947528643678711]
	TIME [epoch: 6.32 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21410913991881197		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.21410913991881197 | validation: 0.21640730132675706]
	TIME [epoch: 6.35 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3388405567051323		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.3388405567051323 | validation: 0.20889610226984523]
	TIME [epoch: 6.31 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23382520877420365		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.23382520877420365 | validation: 0.08995861792584428]
	TIME [epoch: 6.33 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10596026251344721		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.10596026251344721 | validation: 0.0699008008811435]
	TIME [epoch: 6.31 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11569404712691739		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.11569404712691739 | validation: 0.12374288062308023]
	TIME [epoch: 6.32 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12879986233832616		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.12879986233832616 | validation: 0.0695809776690187]
	TIME [epoch: 6.36 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09609997008426195		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.09609997008426195 | validation: 0.06000714396688918]
	TIME [epoch: 6.32 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.101229710656323		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.101229710656323 | validation: 0.06841064383923656]
	TIME [epoch: 6.32 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09463958656883256		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.09463958656883256 | validation: 0.060718715907572315]
	TIME [epoch: 6.32 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08730713602492046		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.08730713602492046 | validation: 0.07114635048773027]
	TIME [epoch: 6.31 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08914810562907458		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.08914810562907458 | validation: 0.06073951739314048]
	TIME [epoch: 6.35 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08266951575981951		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.08266951575981951 | validation: 0.05029542109788197]
	TIME [epoch: 6.34 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08323727898673457		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.08323727898673457 | validation: 0.0608674377769966]
	TIME [epoch: 6.31 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07894956278591911		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.07894956278591911 | validation: 0.07085233391828594]
	TIME [epoch: 6.32 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09939601617362814		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.09939601617362814 | validation: 0.0823553088526493]
	TIME [epoch: 6.31 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09100898317497799		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.09100898317497799 | validation: 0.0613032056320211]
	TIME [epoch: 6.32 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08561631627417046		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.08561631627417046 | validation: 0.05768898347652418]
	TIME [epoch: 6.37 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08963476204578807		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.08963476204578807 | validation: 0.06713235392270293]
	TIME [epoch: 6.31 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08822582265210215		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.08822582265210215 | validation: 0.062344914311642186]
	TIME [epoch: 6.32 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07708202943284408		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.07708202943284408 | validation: 0.052920311469347704]
	TIME [epoch: 6.33 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07866972398239871		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.07866972398239871 | validation: 0.06535651329199768]
	TIME [epoch: 6.31 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09567205567135238		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.09567205567135238 | validation: 0.050453205159661396]
	TIME [epoch: 6.36 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08469850648830946		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.08469850648830946 | validation: 0.09254461874773706]
	TIME [epoch: 6.32 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12625721570384546		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.12625721570384546 | validation: 0.07723562495666877]
	TIME [epoch: 6.32 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08594952587386008		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.08594952587386008 | validation: 0.056297803523969056]
	TIME [epoch: 6.31 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07784468717923643		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.07784468717923643 | validation: 0.10045352436842994]
	TIME [epoch: 6.32 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12029158450098937		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.12029158450098937 | validation: 0.09411084940882786]
	TIME [epoch: 6.32 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13340578251983295		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.13340578251983295 | validation: 0.10475669704390192]
	TIME [epoch: 6.35 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12034306146048272		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.12034306146048272 | validation: 0.11272786671769128]
	TIME [epoch: 6.31 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18104729273139814		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.18104729273139814 | validation: 0.25721597492532267]
	TIME [epoch: 6.31 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3333301949648477		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.3333301949648477 | validation: 0.2577564750093616]
	TIME [epoch: 6.31 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2525547422031844		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.2525547422031844 | validation: 0.1962046196548211]
	TIME [epoch: 6.32 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2708447824750796		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.2708447824750796 | validation: 0.2057835396795469]
	TIME [epoch: 6.36 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18728238176641962		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.18728238176641962 | validation: 0.10520782630726905]
	TIME [epoch: 6.33 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09581006919878943		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.09581006919878943 | validation: 0.06729785998006033]
	TIME [epoch: 6.31 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.083936105713278		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.083936105713278 | validation: 0.06505044148219014]
	TIME [epoch: 6.32 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10140547678521886		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.10140547678521886 | validation: 0.08417241054067737]
	TIME [epoch: 6.31 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1048649230987252		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.1048649230987252 | validation: 0.06664200426093911]
	TIME [epoch: 6.33 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08344518596736343		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.08344518596736343 | validation: 0.07467367876132552]
	TIME [epoch: 6.35 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10994064631883929		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.10994064631883929 | validation: 0.10266445899465529]
	TIME [epoch: 6.32 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12766148305511554		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.12766148305511554 | validation: 0.08353340446609847]
	TIME [epoch: 6.32 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11935156627676108		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.11935156627676108 | validation: 0.10721219725709678]
	TIME [epoch: 6.31 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10805967129338578		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.10805967129338578 | validation: 0.05655735950255815]
	TIME [epoch: 6.32 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08534852741020829		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.08534852741020829 | validation: 0.06539239488365708]
	TIME [epoch: 6.36 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07041221462831616		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.07041221462831616 | validation: 0.049704784572547706]
	TIME [epoch: 6.32 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07516866443535805		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.07516866443535805 | validation: 0.07084493912270232]
	TIME [epoch: 6.32 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09730045394426284		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.09730045394426284 | validation: 0.0776225454022998]
	TIME [epoch: 6.31 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10452124872019657		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.10452124872019657 | validation: 0.07992298022034097]
	TIME [epoch: 6.31 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09070229613429488		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.09070229613429488 | validation: 0.08127429559700483]
	TIME [epoch: 6.34 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07354554313972955		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.07354554313972955 | validation: 0.05412565583281498]
	TIME [epoch: 6.34 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0761331835080338		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.0761331835080338 | validation: 0.059488039243503966]
	TIME [epoch: 6.32 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07243357195974123		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.07243357195974123 | validation: 0.06456287146064767]
	TIME [epoch: 6.31 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09236452261875255		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.09236452261875255 | validation: 0.07853499654126572]
	TIME [epoch: 6.31 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11430037872184903		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.11430037872184903 | validation: 0.08527719202808498]
	TIME [epoch: 6.31 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15660688179391957		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.15660688179391957 | validation: 0.14269588474989023]
	TIME [epoch: 6.36 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1828087712550369		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.1828087712550369 | validation: 0.07970239386068269]
	TIME [epoch: 6.32 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11755105733084086		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.11755105733084086 | validation: 0.10463124176513725]
	TIME [epoch: 6.31 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11761573437539913		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.11761573437539913 | validation: 0.05711563177221015]
	TIME [epoch: 6.31 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08065599282893834		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.08065599282893834 | validation: 0.05237253217345251]
	TIME [epoch: 6.31 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07277844024552205		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.07277844024552205 | validation: 0.06426488990749732]
	TIME [epoch: 6.34 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07941729859822896		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.07941729859822896 | validation: 0.07188623538410548]
	TIME [epoch: 6.33 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08142511645225758		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.08142511645225758 | validation: 0.07252086894040088]
	TIME [epoch: 6.32 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09049702163490002		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.09049702163490002 | validation: 0.06396167457199393]
	TIME [epoch: 6.31 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07372150094956179		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.07372150094956179 | validation: 0.05750716335524521]
	TIME [epoch: 6.32 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07532574848508138		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.07532574848508138 | validation: 0.05430261908100459]
	TIME [epoch: 6.33 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07117898455551172		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.07117898455551172 | validation: 0.05828737263167419]
	TIME [epoch: 6.35 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10493256608403412		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.10493256608403412 | validation: 0.07520500928140411]
	TIME [epoch: 6.32 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09935423661643072		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.09935423661643072 | validation: 0.055583308266199206]
	TIME [epoch: 6.31 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.083753284879913		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.083753284879913 | validation: 0.06550754043976853]
	TIME [epoch: 6.31 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07877875129568383		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.07877875129568383 | validation: 0.043483982920885914]
	TIME [epoch: 6.31 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_847.pth
	Model improved!!!
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06913171746460138		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.06913171746460138 | validation: 0.05266561087938523]
	TIME [epoch: 6.36 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07814814525243456		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.07814814525243456 | validation: 0.04124267345030827]
	TIME [epoch: 6.32 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_849.pth
	Model improved!!!
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08611704178007329		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.08611704178007329 | validation: 0.06449531656479739]
	TIME [epoch: 6.31 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07181180243591578		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.07181180243591578 | validation: 0.06471694997545656]
	TIME [epoch: 6.3 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07522173959780451		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.07522173959780451 | validation: 0.06925676927476376]
	TIME [epoch: 6.31 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06888402148345717		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.06888402148345717 | validation: 0.047215314534417574]
	TIME [epoch: 6.33 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06975804046308556		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.06975804046308556 | validation: 0.05231432675092139]
	TIME [epoch: 6.34 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07716233540594215		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.07716233540594215 | validation: 0.06195697655138453]
	TIME [epoch: 6.31 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06978409032708235		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.06978409032708235 | validation: 0.05721381122470151]
	TIME [epoch: 6.31 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07299266041455361		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.07299266041455361 | validation: 0.05195396439726428]
	TIME [epoch: 6.31 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07809927262215412		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.07809927262215412 | validation: 0.06867159038482479]
	TIME [epoch: 6.32 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09405928876497832		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.09405928876497832 | validation: 0.061265282404275534]
	TIME [epoch: 6.36 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0832365305063327		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.0832365305063327 | validation: 0.04299036084843894]
	TIME [epoch: 6.32 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07510676307988853		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.07510676307988853 | validation: 0.05812146782777408]
	TIME [epoch: 6.31 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07883193809870723		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.07883193809870723 | validation: 0.06725966495021754]
	TIME [epoch: 6.31 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07440325555900232		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.07440325555900232 | validation: 0.07219796179861407]
	TIME [epoch: 6.31 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11564742282481452		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.11564742282481452 | validation: 0.0785589697797737]
	TIME [epoch: 6.35 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10679346936411965		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.10679346936411965 | validation: 0.05354133232164232]
	TIME [epoch: 6.32 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07624898393986604		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.07624898393986604 | validation: 0.04695039954347299]
	TIME [epoch: 6.31 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07023571261652453		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.07023571261652453 | validation: 0.05311610436815015]
	TIME [epoch: 6.31 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0729733123509794		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.0729733123509794 | validation: 0.05191911504667341]
	TIME [epoch: 6.31 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07291855479787568		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.07291855479787568 | validation: 0.0525064622385288]
	TIME [epoch: 6.32 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08813045597253734		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.08813045597253734 | validation: 0.07379854457276658]
	TIME [epoch: 6.34 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10510357981014068		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.10510357981014068 | validation: 0.0862179638510994]
	TIME [epoch: 6.3 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09607102389675377		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.09607102389675377 | validation: 0.050279043115093555]
	TIME [epoch: 6.31 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09381413877004591		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.09381413877004591 | validation: 0.07704479027554346]
	TIME [epoch: 6.3 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13945706205829025		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.13945706205829025 | validation: 0.10018329869489297]
	TIME [epoch: 6.31 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15141463568291472		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.15141463568291472 | validation: 0.0554855815925151]
	TIME [epoch: 6.35 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09578169067586412		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.09578169067586412 | validation: 0.05141725572264072]
	TIME [epoch: 6.32 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07349549003779539		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.07349549003779539 | validation: 0.05151003669830232]
	TIME [epoch: 6.31 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0761061018366444		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.0761061018366444 | validation: 0.06357977204679732]
	TIME [epoch: 6.31 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0928522751759108		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.0928522751759108 | validation: 0.052499593345734896]
	TIME [epoch: 6.31 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08285967464601018		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.08285967464601018 | validation: 0.06786550852447144]
	TIME [epoch: 6.32 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07589285862952369		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.07589285862952369 | validation: 0.04783565214802331]
	TIME [epoch: 6.34 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07852764805137336		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.07852764805137336 | validation: 0.0568077400142867]
	TIME [epoch: 6.31 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08200798598161518		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.08200798598161518 | validation: 0.055852216290489726]
	TIME [epoch: 6.31 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07783014909509473		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.07783014909509473 | validation: 0.045013721217209694]
	TIME [epoch: 6.31 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08611897907310921		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.08611897907310921 | validation: 0.045678869242108684]
	TIME [epoch: 6.31 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07587186807034466		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.07587186807034466 | validation: 0.06369780110879505]
	TIME [epoch: 6.36 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09171358508887517		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.09171358508887517 | validation: 0.08835796485244729]
	TIME [epoch: 6.32 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10982461715268757		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.10982461715268757 | validation: 0.07409358165214477]
	TIME [epoch: 6.31 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10499371154873316		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.10499371154873316 | validation: 0.0809911847369509]
	TIME [epoch: 6.32 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09433897728984597		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.09433897728984597 | validation: 0.05885777268593598]
	TIME [epoch: 6.31 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08182311443981877		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.08182311443981877 | validation: 0.06458078842266181]
	TIME [epoch: 6.34 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08249371349937701		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.08249371349937701 | validation: 0.0632316906247471]
	TIME [epoch: 6.34 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09085902823100801		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.09085902823100801 | validation: 0.08047327053098693]
	TIME [epoch: 6.32 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1662890817673136		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.1662890817673136 | validation: 0.14543175793673047]
	TIME [epoch: 6.32 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19254292238614262		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.19254292238614262 | validation: 0.08244714072119814]
	TIME [epoch: 6.32 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11137995136993328		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.11137995136993328 | validation: 0.06761985988231986]
	TIME [epoch: 6.32 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11238110905976574		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.11238110905976574 | validation: 0.07737144999210126]
	TIME [epoch: 6.36 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12023943439695918		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.12023943439695918 | validation: 0.0705916597544882]
	TIME [epoch: 6.32 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09015635642601766		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.09015635642601766 | validation: 0.06614403767710578]
	TIME [epoch: 6.32 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07597797734557435		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.07597797734557435 | validation: 0.05460243904648342]
	TIME [epoch: 6.31 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08948652670966904		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.08948652670966904 | validation: 0.06461373568124493]
	TIME [epoch: 6.31 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09505762546238193		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.09505762546238193 | validation: 0.08160372917059361]
	TIME [epoch: 6.34 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12121243397237207		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.12121243397237207 | validation: 0.06198870588670339]
	TIME [epoch: 6.33 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09306641779032718		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.09306641779032718 | validation: 0.05340247461502084]
	TIME [epoch: 6.31 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08200370472750362		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.08200370472750362 | validation: 0.06195675267271672]
	TIME [epoch: 6.31 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08512513427968692		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.08512513427968692 | validation: 0.06944933759606067]
	TIME [epoch: 6.31 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11716635895489938		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.11716635895489938 | validation: 0.09114113277513095]
	TIME [epoch: 6.33 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11933222068098068		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.11933222068098068 | validation: 0.08785459387495415]
	TIME [epoch: 6.35 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09549815622058282		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.09549815622058282 | validation: 0.04310301453292803]
	TIME [epoch: 6.31 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07835268622414898		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.07835268622414898 | validation: 0.0659028194451424]
	TIME [epoch: 6.31 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09483939187279128		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.09483939187279128 | validation: 0.06939308119125602]
	TIME [epoch: 6.31 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0994032878653612		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.0994032878653612 | validation: 0.06486035704942388]
	TIME [epoch: 6.32 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09825434451202888		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.09825434451202888 | validation: 0.06338596088250593]
	TIME [epoch: 6.35 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0927301965688629		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.0927301965688629 | validation: 0.06351991783244634]
	TIME [epoch: 6.33 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1163107003652164		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.1163107003652164 | validation: 0.08303915541105691]
	TIME [epoch: 6.31 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11925779255536743		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.11925779255536743 | validation: 0.07152435773514067]
	TIME [epoch: 6.32 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09791306336515894		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.09791306336515894 | validation: 0.06401611612749875]
	TIME [epoch: 6.31 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09890570797353662		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.09890570797353662 | validation: 0.05895954448527707]
	TIME [epoch: 6.32 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08461490018561954		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.08461490018561954 | validation: 0.06556074229083064]
	TIME [epoch: 6.35 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08840451952440923		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.08840451952440923 | validation: 0.06933567319249129]
	TIME [epoch: 6.32 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08486983626286186		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.08486983626286186 | validation: 0.06144128613644423]
	TIME [epoch: 6.32 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08414679664058443		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.08414679664058443 | validation: 0.05216791694621817]
	TIME [epoch: 6.31 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08391464799863985		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.08391464799863985 | validation: 0.05181623963928416]
	TIME [epoch: 6.31 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.076772746161074		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.076772746161074 | validation: 0.051872958463983605]
	TIME [epoch: 6.36 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0804073627689148		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.0804073627689148 | validation: 0.06521464108343789]
	TIME [epoch: 6.32 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0787087735044481		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.0787087735044481 | validation: 0.059101488741242825]
	TIME [epoch: 6.31 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0714375380858559		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.0714375380858559 | validation: 0.057958532776205204]
	TIME [epoch: 6.32 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08780507270789442		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.08780507270789442 | validation: 0.05529880438904546]
	TIME [epoch: 6.32 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08314878796710497		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.08314878796710497 | validation: 0.05318860292039891]
	TIME [epoch: 6.34 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09628055272303722		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.09628055272303722 | validation: 0.07004848825858112]
	TIME [epoch: 6.34 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11356159508439068		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.11356159508439068 | validation: 0.09619568180668878]
	TIME [epoch: 6.32 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11257964976257226		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.11257964976257226 | validation: 0.07077907624438898]
	TIME [epoch: 6.31 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08963266720496318		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.08963266720496318 | validation: 0.05464622162784395]
	TIME [epoch: 6.31 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09277213387274444		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.09277213387274444 | validation: 0.08522606791655411]
	TIME [epoch: 6.31 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0982902567341882		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.0982902567341882 | validation: 0.04522014639294038]
	TIME [epoch: 6.36 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07889488530240026		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.07889488530240026 | validation: 0.06266206570291684]
	TIME [epoch: 6.32 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08804316039131668		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.08804316039131668 | validation: 0.0522517548836562]
	TIME [epoch: 6.31 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0774651486176215		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.0774651486176215 | validation: 0.05062363396818087]
	TIME [epoch: 6.32 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07822301218487712		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.07822301218487712 | validation: 0.057874954801953454]
	TIME [epoch: 6.32 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08143316220924562		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.08143316220924562 | validation: 0.06529440502799881]
	TIME [epoch: 6.34 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09537621266640092		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.09537621266640092 | validation: 0.08039812780220965]
	TIME [epoch: 6.33 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10737651225564135		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.10737651225564135 | validation: 0.10330935337073778]
	TIME [epoch: 6.32 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14568332286965016		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.14568332286965016 | validation: 0.11906105951917872]
	TIME [epoch: 6.31 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14495979998183312		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.14495979998183312 | validation: 0.08042689466264479]
	TIME [epoch: 6.31 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09706590132338178		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.09706590132338178 | validation: 0.05921565723951033]
	TIME [epoch: 6.32 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07555560563849725		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.07555560563849725 | validation: 0.06606273920994421]
	TIME [epoch: 6.35 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0793583798095871		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.0793583798095871 | validation: 0.04767676872675867]
	TIME [epoch: 6.32 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07572440743930431		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.07572440743930431 | validation: 0.05110307079438858]
	TIME [epoch: 6.31 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09426535156488208		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.09426535156488208 | validation: 0.06956391294371778]
	TIME [epoch: 6.31 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1203469183119094		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.1203469183119094 | validation: 0.06936156599461195]
	TIME [epoch: 6.32 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10128473924211992		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.10128473924211992 | validation: 0.08801208772042586]
	TIME [epoch: 6.35 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13261775596411285		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.13261775596411285 | validation: 0.06980180696764052]
	TIME [epoch: 6.32 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09883750414751238		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.09883750414751238 | validation: 0.06253763060319362]
	TIME [epoch: 6.31 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09742082247166287		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.09742082247166287 | validation: 0.07809750562588028]
	TIME [epoch: 6.31 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10912116189125518		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.10912116189125518 | validation: 0.07318389517212137]
	TIME [epoch: 6.31 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12842359900839684		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.12842359900839684 | validation: 0.10328583796568538]
	TIME [epoch: 6.32 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14645955378646777		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.14645955378646777 | validation: 0.08661140953695856]
	TIME [epoch: 6.35 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11147930347500977		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.11147930347500977 | validation: 0.06703656360192073]
	TIME [epoch: 6.32 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09333135929114056		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.09333135929114056 | validation: 0.058697766528000656]
	TIME [epoch: 6.32 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09031619349913082		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.09031619349913082 | validation: 0.06494778334247894]
	TIME [epoch: 6.32 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08964110004792712		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.08964110004792712 | validation: 0.05454074400450555]
	TIME [epoch: 6.31 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09061174672339825		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.09061174672339825 | validation: 0.06112616015110306]
	TIME [epoch: 6.36 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1024637215975118		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.1024637215975118 | validation: 0.06789271289735156]
	TIME [epoch: 6.32 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09670816442585616		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.09670816442585616 | validation: 0.06515180709680528]
	TIME [epoch: 6.32 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08516426831271856		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.08516426831271856 | validation: 0.06710424771771324]
	TIME [epoch: 6.31 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08314282151297436		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.08314282151297436 | validation: 0.05763716080772137]
	TIME [epoch: 6.31 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0814189250027623		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.0814189250027623 | validation: 0.05673932467614702]
	TIME [epoch: 6.34 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0837971951047903		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.0837971951047903 | validation: 0.053439557249816305]
	TIME [epoch: 6.33 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07330914911910585		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.07330914911910585 | validation: 0.049695082411075925]
	TIME [epoch: 6.32 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07879635054802289		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.07879635054802289 | validation: 0.06403117899872937]
	TIME [epoch: 6.31 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07297739553747065		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.07297739553747065 | validation: 0.060751402925117326]
	TIME [epoch: 6.32 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07414321714441133		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.07414321714441133 | validation: 0.056183534129377294]
	TIME [epoch: 6.31 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08249074526007535		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.08249074526007535 | validation: 0.061493009984894424]
	TIME [epoch: 6.36 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08933563681486031		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.08933563681486031 | validation: 0.06540949904430299]
	TIME [epoch: 6.32 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08432463868569828		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.08432463868569828 | validation: 0.06290474794896783]
	TIME [epoch: 6.31 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07437736109171346		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.07437736109171346 | validation: 0.0512277605295552]
	TIME [epoch: 6.31 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06564527376507988		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.06564527376507988 | validation: 0.05697717431000296]
	TIME [epoch: 6.31 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0729682806524404		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.0729682806524404 | validation: 0.04368390730767538]
	TIME [epoch: 6.34 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06737673686376311		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.06737673686376311 | validation: 0.051728605252749915]
	TIME [epoch: 6.34 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07379534709817907		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.07379534709817907 | validation: 0.05363717758513682]
	TIME [epoch: 6.31 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07242862024184916		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.07242862024184916 | validation: 0.054722400622451386]
	TIME [epoch: 6.31 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06656700060214475		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.06656700060214475 | validation: 0.05299627583365915]
	TIME [epoch: 6.31 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07302620579654855		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.07302620579654855 | validation: 0.06832997048797095]
	TIME [epoch: 6.32 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06733506344342585		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.06733506344342585 | validation: 0.06398645064607762]
	TIME [epoch: 6.36 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07193070269736211		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.07193070269736211 | validation: 0.0714011976061136]
	TIME [epoch: 6.31 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08070926716623536		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.08070926716623536 | validation: 0.0684553450723841]
	TIME [epoch: 6.31 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06712325483986167		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.06712325483986167 | validation: 0.05906999847670968]
	TIME [epoch: 6.31 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06313187012016741		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.06313187012016741 | validation: 0.05140606050209521]
	TIME [epoch: 6.31 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06531296086604924		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.06531296086604924 | validation: 0.04048672856567198]
	TIME [epoch: 6.36 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_989.pth
	Model improved!!!
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06435002944276044		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.06435002944276044 | validation: 0.04819287314752371]
	TIME [epoch: 6.32 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07481448920273265		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.07481448920273265 | validation: 0.06843912272282479]
	TIME [epoch: 6.31 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08873678232093124		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.08873678232093124 | validation: 0.08039946939963305]
	TIME [epoch: 6.31 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10381267822378316		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.10381267822378316 | validation: 0.08845465017109622]
	TIME [epoch: 6.31 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11497986499349873		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.11497986499349873 | validation: 0.08013377231485104]
	TIME [epoch: 6.32 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1101922122640715		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.1101922122640715 | validation: 0.08667027913902646]
	TIME [epoch: 6.35 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13901323562845627		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.13901323562845627 | validation: 0.0837294429069485]
	TIME [epoch: 6.31 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16881008301033112		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.16881008301033112 | validation: 0.1126544052759456]
	TIME [epoch: 6.31 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16966486199223824		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.16966486199223824 | validation: 0.1043551213284937]
	TIME [epoch: 6.31 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1400834020601189		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.1400834020601189 | validation: 0.06894544920532561]
	TIME [epoch: 6.32 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08391104751177564		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.08391104751177564 | validation: 0.04986038480956773]
	TIME [epoch: 6.35 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07006418065527142		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.07006418065527142 | validation: 0.04932588853271577]
	TIME [epoch: 6.31 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06432507581841075		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.06432507581841075 | validation: 0.04642412633121211]
	TIME [epoch: 6.31 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062336410320084974		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.062336410320084974 | validation: 0.04976827869848962]
	TIME [epoch: 6.31 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06642359265024281		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.06642359265024281 | validation: 0.05204626641981239]
	TIME [epoch: 6.31 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06626847624510436		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.06626847624510436 | validation: 0.04897233673792269]
	TIME [epoch: 6.33 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.069794749455699		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.069794749455699 | validation: 0.0414112887575548]
	TIME [epoch: 6.33 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06542276141765435		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.06542276141765435 | validation: 0.0400170784742917]
	TIME [epoch: 6.31 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_1007.pth
	Model improved!!!
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08556344020270366		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.08556344020270366 | validation: 0.06579824043867018]
	TIME [epoch: 6.31 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09227061776165446		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.09227061776165446 | validation: 0.06411652266451418]
	TIME [epoch: 6.3 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08656690793536612		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.08656690793536612 | validation: 0.06714222557273014]
	TIME [epoch: 6.31 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08936186356425499		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.08936186356425499 | validation: 0.07040615350969112]
	TIME [epoch: 6.34 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10121148122895071		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.10121148122895071 | validation: 0.07089469617021127]
	TIME [epoch: 6.32 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10916528347568726		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.10916528347568726 | validation: 0.07428059176989654]
	TIME [epoch: 6.31 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09732263195641265		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.09732263195641265 | validation: 0.0726909356378995]
	TIME [epoch: 6.3 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09073473958964257		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.09073473958964257 | validation: 0.062251950455522495]
	TIME [epoch: 6.31 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07394207853387527		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.07394207853387527 | validation: 0.05086419844465631]
	TIME [epoch: 6.34 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08166662254250502		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.08166662254250502 | validation: 0.06519495846490417]
	TIME [epoch: 6.32 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08141659562353012		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.08141659562353012 | validation: 0.06618717792334383]
	TIME [epoch: 6.31 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08918663589244245		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.08918663589244245 | validation: 0.05980637615471618]
	TIME [epoch: 6.31 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06955371683692943		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.06955371683692943 | validation: 0.03643176176732067]
	TIME [epoch: 6.31 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_1020.pth
	Model improved!!!
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06096375506641562		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.06096375506641562 | validation: 0.04711419838160343]
	TIME [epoch: 6.32 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06304906278835343		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.06304906278835343 | validation: 0.056685171819469096]
	TIME [epoch: 6.35 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06232056406135158		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.06232056406135158 | validation: 0.059145647709554904]
	TIME [epoch: 6.31 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07116988717651523		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.07116988717651523 | validation: 0.04561627417123949]
	TIME [epoch: 6.31 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06639645000125675		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.06639645000125675 | validation: 0.052487578810822666]
	TIME [epoch: 6.31 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08738432564747498		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.08738432564747498 | validation: 0.06490896902905662]
	TIME [epoch: 6.31 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08570077044272839		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.08570077044272839 | validation: 0.05931642435182748]
	TIME [epoch: 6.36 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07910048377392102		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.07910048377392102 | validation: 0.07427662842697674]
	TIME [epoch: 6.32 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07067705215117635		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.07067705215117635 | validation: 0.0510604486450456]
	TIME [epoch: 6.31 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07286803154949897		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.07286803154949897 | validation: 0.0533120645570648]
	TIME [epoch: 6.31 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06799592583502052		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.06799592583502052 | validation: 0.05218929062359999]
	TIME [epoch: 6.31 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06147260227061831		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.06147260227061831 | validation: 0.05882957535944233]
	TIME [epoch: 6.34 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062156977226188986		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.062156977226188986 | validation: 0.05539143315615663]
	TIME [epoch: 6.34 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06984886209103118		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.06984886209103118 | validation: 0.044373809593092096]
	TIME [epoch: 6.31 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06830240032666571		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.06830240032666571 | validation: 0.03471398104937046]
	TIME [epoch: 6.31 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_1035.pth
	Model improved!!!
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06275152440484161		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.06275152440484161 | validation: 0.0470655962872208]
	TIME [epoch: 6.31 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07800150351137172		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.07800150351137172 | validation: 0.07761350187858382]
	TIME [epoch: 6.32 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11719318343966374		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.11719318343966374 | validation: 0.08767738329061929]
	TIME [epoch: 6.35 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09947460321231083		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.09947460321231083 | validation: 0.06996505523571604]
	TIME [epoch: 6.32 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08802752485214287		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.08802752485214287 | validation: 0.06896206143591542]
	TIME [epoch: 6.31 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07913770686096723		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.07913770686096723 | validation: 0.05759442234968691]
	TIME [epoch: 6.32 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06306951114199591		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.06306951114199591 | validation: 0.036030739680055573]
	TIME [epoch: 6.32 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06365528798306223		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.06365528798306223 | validation: 0.04357699711123315]
	TIME [epoch: 6.35 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07614196572903081		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.07614196572903081 | validation: 0.06888791480158214]
	TIME [epoch: 6.33 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08176839473107209		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.08176839473107209 | validation: 0.07884362745530218]
	TIME [epoch: 6.31 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09998026814671135		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.09998026814671135 | validation: 0.08720401692065272]
	TIME [epoch: 6.31 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10553379890949613		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.10553379890949613 | validation: 0.07920618384600994]
	TIME [epoch: 6.31 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08955795083051904		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.08955795083051904 | validation: 0.05854445302682766]
	TIME [epoch: 6.32 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07825700605081509		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.07825700605081509 | validation: 0.08566094736563692]
	TIME [epoch: 6.35 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10083075479462786		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.10083075479462786 | validation: 0.07320399707369718]
	TIME [epoch: 6.31 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09197234751725183		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.09197234751725183 | validation: 0.06418662168605332]
	TIME [epoch: 6.31 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08125385508964869		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.08125385508964869 | validation: 0.061378433195494575]
	TIME [epoch: 6.31 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06735632836642833		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.06735632836642833 | validation: 0.06287477941199074]
	TIME [epoch: 6.31 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06815595370435834		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.06815595370435834 | validation: 0.0548985528730455]
	TIME [epoch: 6.35 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06433778817425392		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.06433778817425392 | validation: 0.05318195897957541]
	TIME [epoch: 6.32 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06065832167720227		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.06065832167720227 | validation: 0.050877310149722375]
	TIME [epoch: 6.31 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07436574276453262		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.07436574276453262 | validation: 0.059485676909560393]
	TIME [epoch: 6.31 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07789482449018008		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.07789482449018008 | validation: 0.07546229552016584]
	TIME [epoch: 6.31 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09779317479946477		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.09779317479946477 | validation: 0.07017529535331617]
	TIME [epoch: 6.33 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0819392800550672		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.0819392800550672 | validation: 0.05424728242579492]
	TIME [epoch: 6.33 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08765183653487474		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.08765183653487474 | validation: 0.05908258649084051]
	TIME [epoch: 6.3 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07899298640899051		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.07899298640899051 | validation: 0.0565466238099673]
	TIME [epoch: 6.31 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06889128656654693		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.06889128656654693 | validation: 0.045275319564194075]
	TIME [epoch: 6.31 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07041058939625999		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.07041058939625999 | validation: 0.05152298787694842]
	TIME [epoch: 6.31 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07712137907733954		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.07712137907733954 | validation: 0.06512209363853719]
	TIME [epoch: 6.35 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06557941594522995		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.06557941594522995 | validation: 0.05933787465293071]
	TIME [epoch: 6.31 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06891749864066803		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.06891749864066803 | validation: 0.06295352882761863]
	TIME [epoch: 6.32 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06336255395877968		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.06336255395877968 | validation: 0.05391647221937622]
	TIME [epoch: 6.31 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06836493630538759		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.06836493630538759 | validation: 0.05976410888711771]
	TIME [epoch: 6.31 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05889645230865894		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.05889645230865894 | validation: 0.04567921637641617]
	TIME [epoch: 6.34 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06368991121184711		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.06368991121184711 | validation: 0.038236050143182876]
	TIME [epoch: 6.32 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060712780228402735		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.060712780228402735 | validation: 0.04103021042338637]
	TIME [epoch: 6.31 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06932026991834664		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.06932026991834664 | validation: 0.05012106871827879]
	TIME [epoch: 6.31 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0651384968991345		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.0651384968991345 | validation: 0.04973813300426604]
	TIME [epoch: 6.31 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06880685662084443		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.06880685662084443 | validation: 0.0558426212459992]
	TIME [epoch: 6.31 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06726190579414787		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.06726190579414787 | validation: 0.059709583284171766]
	TIME [epoch: 6.35 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06520531283362238		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.06520531283362238 | validation: 0.058170058075907825]
	TIME [epoch: 6.31 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07374327989029197		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.07374327989029197 | validation: 0.04541023795622156]
	TIME [epoch: 6.3 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07512250234103736		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.07512250234103736 | validation: 0.058052710627234994]
	TIME [epoch: 6.31 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07951749114360247		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.07951749114360247 | validation: 0.05504799006653198]
	TIME [epoch: 6.31 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06935971238125993		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.06935971238125993 | validation: 0.049922786118453744]
	TIME [epoch: 6.35 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0625843665212999		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.0625843665212999 | validation: 0.04458622482138469]
	TIME [epoch: 6.31 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0599696090165231		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.0599696090165231 | validation: 0.03785755465513152]
	TIME [epoch: 6.3 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06354709101754544		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.06354709101754544 | validation: 0.07053811109005222]
	TIME [epoch: 6.31 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05785773369227524		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.05785773369227524 | validation: 0.03565306738946539]
	TIME [epoch: 6.31 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057216059423330225		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.057216059423330225 | validation: 0.03559073074939226]
	TIME [epoch: 6.32 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06022507747040401		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.06022507747040401 | validation: 0.04744871455308797]
	TIME [epoch: 6.34 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060481862139443066		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.060481862139443066 | validation: 0.03996763632617141]
	TIME [epoch: 6.31 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05678180552336815		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.05678180552336815 | validation: 0.05634261478504727]
	TIME [epoch: 6.31 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05509690404682453		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.05509690404682453 | validation: 0.04238625921818073]
	TIME [epoch: 6.31 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06982107272553402		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.06982107272553402 | validation: 0.0480974727922007]
	TIME [epoch: 6.31 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06387970103305905		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.06387970103305905 | validation: 0.0523910539450648]
	TIME [epoch: 6.34 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06322444092747191		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.06322444092747191 | validation: 0.05390961797586394]
	TIME [epoch: 6.32 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07834322620415818		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.07834322620415818 | validation: 0.06093776123286277]
	TIME [epoch: 6.3 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10141661937405597		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.10141661937405597 | validation: 0.08826353595477907]
	TIME [epoch: 6.3 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11030742935282659		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.11030742935282659 | validation: 0.07940183148827176]
	TIME [epoch: 6.3 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1230362742481552		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.1230362742481552 | validation: 0.07127633221674506]
	TIME [epoch: 6.33 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09684125668083929		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.09684125668083929 | validation: 0.04967870104741152]
	TIME [epoch: 6.32 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07854510361486589		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.07854510361486589 | validation: 0.04534009986531809]
	TIME [epoch: 6.3 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06856844443332469		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.06856844443332469 | validation: 0.05820314950042989]
	TIME [epoch: 6.3 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07431456637280603		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.07431456637280603 | validation: 0.04895723457214753]
	TIME [epoch: 6.3 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06356118811765268		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.06356118811765268 | validation: 0.03846688408402834]
	TIME [epoch: 6.3 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05601241156662574		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.05601241156662574 | validation: 0.050343308695651415]
	TIME [epoch: 6.35 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06056691761259943		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.06056691761259943 | validation: 0.02919841367555152]
	TIME [epoch: 6.31 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_1104.pth
	Model improved!!!
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056568431443143205		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.056568431443143205 | validation: 0.04666831133859774]
	TIME [epoch: 6.32 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05767096411695305		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.05767096411695305 | validation: 0.04913304376459286]
	TIME [epoch: 6.31 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057812742439297474		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.057812742439297474 | validation: 0.04757117971159626]
	TIME [epoch: 6.31 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06430436126699174		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.06430436126699174 | validation: 0.04560851230309261]
	TIME [epoch: 6.35 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061752097515160864		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.061752097515160864 | validation: 0.04330544611659508]
	TIME [epoch: 6.32 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06387530510377726		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.06387530510377726 | validation: 0.045057272601187214]
	TIME [epoch: 6.31 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06211338230478218		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.06211338230478218 | validation: 0.04603440507655117]
	TIME [epoch: 6.31 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06090504580785677		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.06090504580785677 | validation: 0.04792991612683251]
	TIME [epoch: 6.32 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055931676891060864		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.055931676891060864 | validation: 0.04230414034149704]
	TIME [epoch: 6.32 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06295840232725067		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.06295840232725067 | validation: 0.05195577539480083]
	TIME [epoch: 6.35 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05701608384025833		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.05701608384025833 | validation: 0.0381297051714428]
	TIME [epoch: 6.32 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05788899994303459		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.05788899994303459 | validation: 0.048446289700980034]
	TIME [epoch: 6.31 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05682042419769451		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.05682042419769451 | validation: 0.04438807257098971]
	TIME [epoch: 6.32 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06807090797680265		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.06807090797680265 | validation: 0.0366119624211084]
	TIME [epoch: 6.31 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06350992752236072		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.06350992752236072 | validation: 0.042640069679200504]
	TIME [epoch: 6.35 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05705714670835313		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.05705714670835313 | validation: 0.04886850242634316]
	TIME [epoch: 6.32 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06008132701228183		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.06008132701228183 | validation: 0.046671830091397026]
	TIME [epoch: 6.31 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053857383375161966		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.053857383375161966 | validation: 0.04863351973141335]
	TIME [epoch: 6.31 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06123287884098252		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.06123287884098252 | validation: 0.04901463761147658]
	TIME [epoch: 6.31 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0672315433570047		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.0672315433570047 | validation: 0.053544772575018246]
	TIME [epoch: 6.33 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06839808764289444		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.06839808764289444 | validation: 0.06703710537652625]
	TIME [epoch: 6.35 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06939159927214841		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.06939159927214841 | validation: 0.056889026659100984]
	TIME [epoch: 6.31 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0684640297082437		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.0684640297082437 | validation: 0.052925027923406504]
	TIME [epoch: 6.31 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0728519454290157		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.0728519454290157 | validation: 0.05541252118471876]
	TIME [epoch: 6.31 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09864094466234419		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.09864094466234419 | validation: 0.06870595091244773]
	TIME [epoch: 6.31 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1119192072225026		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.1119192072225026 | validation: 0.09207503793792667]
	TIME [epoch: 6.36 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11915482858108316		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.11915482858108316 | validation: 0.05502553833992059]
	TIME [epoch: 6.32 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.084117150791893		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.084117150791893 | validation: 0.052196782281350246]
	TIME [epoch: 6.31 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07738019251844493		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.07738019251844493 | validation: 0.06565078340729749]
	TIME [epoch: 6.31 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08373688939745415		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.08373688939745415 | validation: 0.05720802045190665]
	TIME [epoch: 6.31 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0877288381961304		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.0877288381961304 | validation: 0.046994128923043166]
	TIME [epoch: 6.34 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0747529157117175		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.0747529157117175 | validation: 0.05598303436569991]
	TIME [epoch: 6.34 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07452303770117744		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.07452303770117744 | validation: 0.060613487026142526]
	TIME [epoch: 6.31 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0844501545121827		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.0844501545121827 | validation: 0.057478493326093255]
	TIME [epoch: 6.32 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07784764002732485		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.07784764002732485 | validation: 0.03743696473650192]
	TIME [epoch: 6.31 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06045812936091215		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.06045812936091215 | validation: 0.057373580170437644]
	TIME [epoch: 6.31 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059500130158074885		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.059500130158074885 | validation: 0.035279193697480914]
	TIME [epoch: 6.36 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059485599109063474		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.059485599109063474 | validation: 0.04193759116506819]
	TIME [epoch: 6.32 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0631372261764615		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.0631372261764615 | validation: 0.059260940260138395]
	TIME [epoch: 6.32 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0588958716381463		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.0588958716381463 | validation: 0.04327945909085387]
	TIME [epoch: 6.31 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055607720354241996		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.055607720354241996 | validation: 0.043092924728217914]
	TIME [epoch: 6.32 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056686182885077485		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.056686182885077485 | validation: 0.04726318792372379]
	TIME [epoch: 6.35 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06251345496087544		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.06251345496087544 | validation: 0.05028627817857389]
	TIME [epoch: 6.32 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059690235505810034		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.059690235505810034 | validation: 0.06158528025282939]
	TIME [epoch: 6.31 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06150713535904606		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.06150713535904606 | validation: 0.048388253088603506]
	TIME [epoch: 6.31 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05780234032480296		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.05780234032480296 | validation: 0.046327382272244366]
	TIME [epoch: 6.31 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06494875848823534		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.06494875848823534 | validation: 0.059005493999351455]
	TIME [epoch: 6.32 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08681305762374616		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.08681305762374616 | validation: 0.052178625423976985]
	TIME [epoch: 6.35 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07211684092386333		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.07211684092386333 | validation: 0.0427209385138058]
	TIME [epoch: 6.31 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06303621697944332		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.06303621697944332 | validation: 0.03813740936231317]
	TIME [epoch: 6.31 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07182251277745914		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.07182251277745914 | validation: 0.05700437128588014]
	TIME [epoch: 6.31 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07406669117318943		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.07406669117318943 | validation: 0.04998174633102806]
	TIME [epoch: 6.31 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06266279584488771		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.06266279584488771 | validation: 0.04273401593287354]
	TIME [epoch: 6.36 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059146430442163125		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.059146430442163125 | validation: 0.053442460801988015]
	TIME [epoch: 6.32 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0557303215160935		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.0557303215160935 | validation: 0.046891101925180395]
	TIME [epoch: 6.31 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0568507876407912		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.0568507876407912 | validation: 0.03696168178010527]
	TIME [epoch: 6.31 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05535770446548944		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.05535770446548944 | validation: 0.0406079257480437]
	TIME [epoch: 6.31 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05630972686938955		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.05630972686938955 | validation: 0.04596826361305071]
	TIME [epoch: 6.32 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060432611122766766		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.060432611122766766 | validation: 0.0532688186544467]
	TIME [epoch: 6.35 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051743213737324406		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.051743213737324406 | validation: 0.048523652859712794]
	TIME [epoch: 6.32 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057347493967889455		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.057347493967889455 | validation: 0.041045953034508226]
	TIME [epoch: 6.31 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0562093939849699		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.0562093939849699 | validation: 0.03086811042870455]
	TIME [epoch: 6.31 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053916808927769136		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.053916808927769136 | validation: 0.056642519204640286]
	TIME [epoch: 6.31 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0742484030181697		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.0742484030181697 | validation: 0.06066388603605613]
	TIME [epoch: 6.36 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07402220234410835		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.07402220234410835 | validation: 0.0725272553914476]
	TIME [epoch: 6.32 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08798473961932719		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.08798473961932719 | validation: 0.0770114066344463]
	TIME [epoch: 6.31 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11643712957344597		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.11643712957344597 | validation: 0.08055256987375858]
	TIME [epoch: 6.31 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10383385977965695		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.10383385977965695 | validation: 0.06443549378715818]
	TIME [epoch: 6.31 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08987417066445703		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.08987417066445703 | validation: 0.06806843150057271]
	TIME [epoch: 6.34 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07521526059717637		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.07521526059717637 | validation: 0.0669402136778096]
	TIME [epoch: 6.34 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07957592555970125		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.07957592555970125 | validation: 0.05591144959029125]
	TIME [epoch: 6.31 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06934786272439097		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.06934786272439097 | validation: 0.0558331987374004]
	TIME [epoch: 6.31 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07160038414462896		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.07160038414462896 | validation: 0.053111037071549703]
	TIME [epoch: 6.31 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07303440809028793		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.07303440809028793 | validation: 0.06341535620376129]
	TIME [epoch: 6.31 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.069401493158705		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.069401493158705 | validation: 0.060521452253302896]
	TIME [epoch: 6.36 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06389563427021763		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.06389563427021763 | validation: 0.0463618911962993]
	TIME [epoch: 6.32 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05574059663516413		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.05574059663516413 | validation: 0.04444962989266148]
	TIME [epoch: 6.31 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05584299581910471		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.05584299581910471 | validation: 0.049784006509443715]
	TIME [epoch: 6.31 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06462961084411586		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.06462961084411586 | validation: 0.04910695266543642]
	TIME [epoch: 6.31 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06397709025662277		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.06397709025662277 | validation: 0.05538824085719411]
	TIME [epoch: 6.35 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06831673102670886		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.06831673102670886 | validation: 0.05650280345107944]
	TIME [epoch: 6.32 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0642822633963163		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.0642822633963163 | validation: 0.04651023756340336]
	TIME [epoch: 6.31 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057169928982296905		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.057169928982296905 | validation: 0.050810027585442535]
	TIME [epoch: 6.31 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06035596220329125		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.06035596220329125 | validation: 0.046544722574946795]
	TIME [epoch: 6.31 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06283979068051138		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.06283979068051138 | validation: 0.05861148192506694]
	TIME [epoch: 6.32 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061586220008808715		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.061586220008808715 | validation: 0.05215314597386082]
	TIME [epoch: 6.35 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0569002047035642		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.0569002047035642 | validation: 0.05199105940873984]
	TIME [epoch: 6.32 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05286632133427921		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.05286632133427921 | validation: 0.04911666977831247]
	TIME [epoch: 6.31 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06319375569597532		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.06319375569597532 | validation: 0.049721531250921935]
	TIME [epoch: 6.31 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06450409278195943		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.06450409278195943 | validation: 0.05305840938074888]
	TIME [epoch: 6.31 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06869148585254914		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.06869148585254914 | validation: 0.0501596832480059]
	TIME [epoch: 6.36 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06891600558767426		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.06891600558767426 | validation: 0.058835347370092335]
	TIME [epoch: 6.32 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08311575669513488		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.08311575669513488 | validation: 0.06635766320503483]
	TIME [epoch: 6.31 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0728282932036987		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.0728282932036987 | validation: 0.04270581892597127]
	TIME [epoch: 6.31 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07270061117952158		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.07270061117952158 | validation: 0.060991238589623416]
	TIME [epoch: 6.32 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07161060317602044		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.07161060317602044 | validation: 0.03667742622618499]
	TIME [epoch: 6.32 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06557594100545655		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.06557594100545655 | validation: 0.03985301615039971]
	TIME [epoch: 6.35 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06872193387436423		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.06872193387436423 | validation: 0.048218819344045]
	TIME [epoch: 6.31 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0695942130982235		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.0695942130982235 | validation: 0.05838274356993261]
	TIME [epoch: 6.31 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06751949181480596		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.06751949181480596 | validation: 0.05342018081769946]
	TIME [epoch: 6.31 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07168780516702304		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.07168780516702304 | validation: 0.05588526554894274]
	TIME [epoch: 6.31 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07795635965587436		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.07795635965587436 | validation: 0.056719062131338746]
	TIME [epoch: 6.35 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08188328670466807		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.08188328670466807 | validation: 0.0666136017696741]
	TIME [epoch: 6.32 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08271510121203067		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.08271510121203067 | validation: 0.049350428850640525]
	TIME [epoch: 6.31 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07043506468077616		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.07043506468077616 | validation: 0.04832186354884325]
	TIME [epoch: 6.31 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0741385060791889		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.0741385060791889 | validation: 0.05707198962980811]
	TIME [epoch: 6.31 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07697607262115781		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.07697607262115781 | validation: 0.055428178257344224]
	TIME [epoch: 6.34 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07024831826885436		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.07024831826885436 | validation: 0.053355105952603274]
	TIME [epoch: 6.34 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059019381271066026		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.059019381271066026 | validation: 0.031712813095827644]
	TIME [epoch: 6.31 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05865447213306998		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.05865447213306998 | validation: 0.03696730773545983]
	TIME [epoch: 6.31 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052588289155984846		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.052588289155984846 | validation: 0.053706417553338666]
	TIME [epoch: 6.31 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05914389846151171		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.05914389846151171 | validation: 0.040764722871481696]
	TIME [epoch: 6.31 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05649647811345325		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.05649647811345325 | validation: 0.04292799012407025]
	TIME [epoch: 6.36 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056399524492720614		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.056399524492720614 | validation: 0.03615654997419502]
	TIME [epoch: 6.32 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05294248941540258		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.05294248941540258 | validation: 0.04088153171049703]
	TIME [epoch: 6.31 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05490801656255959		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.05490801656255959 | validation: 0.04803015427934908]
	TIME [epoch: 6.31 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056103882302773064		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.056103882302773064 | validation: 0.03957612628070867]
	TIME [epoch: 6.31 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053652080868272355		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.053652080868272355 | validation: 0.03523614769223898]
	TIME [epoch: 6.36 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05520456677657519		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.05520456677657519 | validation: 0.04235388740282606]
	TIME [epoch: 6.32 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060127962179965494		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.060127962179965494 | validation: 0.03561157008299834]
	TIME [epoch: 6.31 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055387213973249444		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.055387213973249444 | validation: 0.04204678868297835]
	TIME [epoch: 6.31 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05981292563296398		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.05981292563296398 | validation: 0.04616048940101691]
	TIME [epoch: 6.31 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05936961544871394		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.05936961544871394 | validation: 0.03889272236955624]
	TIME [epoch: 6.32 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06277423708490604		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.06277423708490604 | validation: 0.0491803284726495]
	TIME [epoch: 6.35 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07330994839761772		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.07330994839761772 | validation: 0.040850381546125435]
	TIME [epoch: 6.31 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06566171092887599		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.06566171092887599 | validation: 0.04380849652575932]
	TIME [epoch: 6.31 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05819322397489403		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.05819322397489403 | validation: 0.041142392364693164]
	TIME [epoch: 6.31 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05461403908026334		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.05461403908026334 | validation: 0.042541954014025815]
	TIME [epoch: 6.31 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06377554458082114		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.06377554458082114 | validation: 0.04807097724967306]
	TIME [epoch: 6.36 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06097903412542091		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.06097903412542091 | validation: 0.05105943950874081]
	TIME [epoch: 6.32 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053065250856175375		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.053065250856175375 | validation: 0.042635509466122795]
	TIME [epoch: 6.32 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053965019886008936		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.053965019886008936 | validation: 0.04358713297457506]
	TIME [epoch: 6.31 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05597394407800853		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.05597394407800853 | validation: 0.038422156655038016]
	TIME [epoch: 6.31 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05249588932675786		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.05249588932675786 | validation: 0.04154803163479788]
	TIME [epoch: 6.33 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05175480432993682		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.05175480432993682 | validation: 0.046538558611789314]
	TIME [epoch: 6.35 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0542370378751028		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.0542370378751028 | validation: 0.030360751036359795]
	TIME [epoch: 6.32 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048281567848213795		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.048281567848213795 | validation: 0.03086130442886454]
	TIME [epoch: 6.31 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05275395789188135		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.05275395789188135 | validation: 0.039597220442177436]
	TIME [epoch: 6.31 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055521703098122		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.055521703098122 | validation: 0.04386428735983396]
	TIME [epoch: 6.31 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05791638406381284		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.05791638406381284 | validation: 0.03783944165556471]
	TIME [epoch: 6.36 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05859420359643515		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.05859420359643515 | validation: 0.04596692087884522]
	TIME [epoch: 6.32 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05379513821007097		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.05379513821007097 | validation: 0.0367387658744166]
	TIME [epoch: 6.31 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058773200559237376		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.058773200559237376 | validation: 0.05113844848698473]
	TIME [epoch: 6.31 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06279134117471691		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.06279134117471691 | validation: 0.0496571391107391]
	TIME [epoch: 6.31 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06078973612339369		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.06078973612339369 | validation: 0.03977246784707087]
	TIME [epoch: 6.34 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05918135378616837		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.05918135378616837 | validation: 0.039468439958057246]
	TIME [epoch: 6.34 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05717499393984925		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.05717499393984925 | validation: 0.04718050091726873]
	TIME [epoch: 6.32 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05769007206084199		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.05769007206084199 | validation: 0.049998146275631754]
	TIME [epoch: 6.31 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05983359231535656		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.05983359231535656 | validation: 0.04015985507462644]
	TIME [epoch: 6.31 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06934959002671734		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.06934959002671734 | validation: 0.05194041317031299]
	TIME [epoch: 6.32 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07310562279872704		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.07310562279872704 | validation: 0.04623514752038062]
	TIME [epoch: 6.36 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07036179733758363		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.07036179733758363 | validation: 0.04805073769271927]
	TIME [epoch: 6.32 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07127168762172616		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.07127168762172616 | validation: 0.055448902346471776]
	TIME [epoch: 6.31 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06985009636553334		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.06985009636553334 | validation: 0.038698012081179255]
	TIME [epoch: 6.31 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06593896902747229		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.06593896902747229 | validation: 0.0472569813803391]
	TIME [epoch: 6.31 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06379485837550551		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.06379485837550551 | validation: 0.031803568864168553]
	TIME [epoch: 6.36 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05908558156475284		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.05908558156475284 | validation: 0.03912481177424508]
	TIME [epoch: 6.32 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06301414642169029		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.06301414642169029 | validation: 0.03465159659686007]
	TIME [epoch: 6.31 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06321827494195503		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.06321827494195503 | validation: 0.049454528636072956]
	TIME [epoch: 6.31 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0574105151049458		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.0574105151049458 | validation: 0.043596855355838154]
	TIME [epoch: 6.31 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0525231428031042		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.0525231428031042 | validation: 0.042465486959687736]
	TIME [epoch: 6.32 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0522035643642609		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.0522035643642609 | validation: 0.047519616287142054]
	TIME [epoch: 6.35 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0551659009304485		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.0551659009304485 | validation: 0.04508522525974015]
	TIME [epoch: 6.31 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06329509560544566		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.06329509560544566 | validation: 0.05573869829094438]
	TIME [epoch: 6.31 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07291700452464847		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.07291700452464847 | validation: 0.050704289393744474]
	TIME [epoch: 6.31 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07802125108583857		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.07802125108583857 | validation: 0.045489931208883914]
	TIME [epoch: 6.31 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07255264490153515		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.07255264490153515 | validation: 0.05123614768687233]
	TIME [epoch: 6.35 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06264880162979232		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.06264880162979232 | validation: 0.04385143025428215]
	TIME [epoch: 6.32 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06065122941158116		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.06065122941158116 | validation: 0.03843074530566279]
	TIME [epoch: 6.31 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06133789486789197		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.06133789486789197 | validation: 0.027747550089975936]
	TIME [epoch: 6.31 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_1274.pth
	Model improved!!!
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05580897776803318		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.05580897776803318 | validation: 0.05036835127799539]
	TIME [epoch: 6.31 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0541120990230452		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.0541120990230452 | validation: 0.03304100419365513]
	TIME [epoch: 6.34 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053454035173607764		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.053454035173607764 | validation: 0.04346916071683826]
	TIME [epoch: 6.34 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051841848048465894		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.051841848048465894 | validation: 0.05004027361298849]
	TIME [epoch: 6.31 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052860976446674174		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.052860976446674174 | validation: 0.03953495438533684]
	TIME [epoch: 6.31 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053966805766832576		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.053966805766832576 | validation: 0.04863282272143332]
	TIME [epoch: 6.31 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05551129530783681		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.05551129530783681 | validation: 0.03473836821712889]
	TIME [epoch: 6.31 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05808637942966331		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.05808637942966331 | validation: 0.046658435573493695]
	TIME [epoch: 6.36 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052140703415797206		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.052140703415797206 | validation: 0.03982090442668261]
	TIME [epoch: 6.31 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050766650361041665		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.050766650361041665 | validation: 0.041728163763670015]
	TIME [epoch: 6.31 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056795916845232323		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.056795916845232323 | validation: 0.041677405583980455]
	TIME [epoch: 6.31 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058116392688075884		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.058116392688075884 | validation: 0.040211457293332226]
	TIME [epoch: 6.31 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05505048932502256		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.05505048932502256 | validation: 0.0381006723772446]
	TIME [epoch: 6.35 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06583633917067208		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.06583633917067208 | validation: 0.05031612326190479]
	TIME [epoch: 6.32 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06845299131052891		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.06845299131052891 | validation: 0.04958017790306826]
	TIME [epoch: 6.31 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06781352212354146		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.06781352212354146 | validation: 0.05254979312090474]
	TIME [epoch: 6.31 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06972897650401748		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.06972897650401748 | validation: 0.0526643090785476]
	TIME [epoch: 6.31 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06436378951547811		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.06436378951547811 | validation: 0.046282502949350185]
	TIME [epoch: 6.32 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058496700284246334		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.058496700284246334 | validation: 0.04985759892061699]
	TIME [epoch: 6.35 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058868165996243144		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.058868165996243144 | validation: 0.05048168447502924]
	TIME [epoch: 6.31 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05714306263239691		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.05714306263239691 | validation: 0.041666238363593316]
	TIME [epoch: 6.31 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06227330451850211		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.06227330451850211 | validation: 0.041234630694672265]
	TIME [epoch: 6.31 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056916664588758874		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.056916664588758874 | validation: 0.04063904236802633]
	TIME [epoch: 6.31 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048764710431610826		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.048764710431610826 | validation: 0.03786641400481874]
	TIME [epoch: 6.35 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05239870186322309		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.05239870186322309 | validation: 0.029694036757381394]
	TIME [epoch: 6.32 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05036499103317389		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.05036499103317389 | validation: 0.03905959211559125]
	TIME [epoch: 6.31 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051536437655170325		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.051536437655170325 | validation: 0.04196357840650575]
	TIME [epoch: 6.31 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05323119033144458		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.05323119033144458 | validation: 0.03182144109827034]
	TIME [epoch: 6.31 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05738908871604845		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.05738908871604845 | validation: 0.04539736194968317]
	TIME [epoch: 6.32 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05440889915828644		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.05440889915828644 | validation: 0.037252721909161166]
	TIME [epoch: 6.34 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0556824521457327		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.0556824521457327 | validation: 0.0460451339257409]
	TIME [epoch: 6.31 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05416128501358589		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.05416128501358589 | validation: 0.048833362692192]
	TIME [epoch: 6.31 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05323225546356312		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.05323225546356312 | validation: 0.040257218278029985]
	TIME [epoch: 6.31 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05592776176012004		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.05592776176012004 | validation: 0.03840268128014178]
	TIME [epoch: 6.31 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05808442111526223		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.05808442111526223 | validation: 0.045060646484329364]
	TIME [epoch: 6.35 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06286474083836228		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.06286474083836228 | validation: 0.04080247640402433]
	TIME [epoch: 6.32 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057916403697671204		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.057916403697671204 | validation: 0.04621850996268164]
	TIME [epoch: 6.31 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05589671259070479		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.05589671259070479 | validation: 0.03924349397635725]
	TIME [epoch: 6.31 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05459157368878752		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.05459157368878752 | validation: 0.04025196061227714]
	TIME [epoch: 6.31 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05417014636132317		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.05417014636132317 | validation: 0.04083443211812163]
	TIME [epoch: 6.34 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05501823648094077		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.05501823648094077 | validation: 0.03828950352889958]
	TIME [epoch: 6.34 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05437775803769382		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.05437775803769382 | validation: 0.03844151706681388]
	TIME [epoch: 6.31 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05250306071984051		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.05250306071984051 | validation: 0.039609278438753275]
	TIME [epoch: 6.31 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05329376700095514		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.05329376700095514 | validation: 0.04206908450228821]
	TIME [epoch: 6.31 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05520019926627049		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.05520019926627049 | validation: 0.04880617883850517]
	TIME [epoch: 6.31 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06387775225226067		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.06387775225226067 | validation: 0.0438275334939887]
	TIME [epoch: 6.36 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06539767466394382		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.06539767466394382 | validation: 0.052229078460939264]
	TIME [epoch: 6.32 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0646094850893716		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.0646094850893716 | validation: 0.04735474116897342]
	TIME [epoch: 6.31 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06999062135083849		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.06999062135083849 | validation: 0.04884285458316989]
	TIME [epoch: 6.31 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06137614962733762		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.06137614962733762 | validation: 0.04117699840366995]
	TIME [epoch: 6.31 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060666836132937156		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.060666836132937156 | validation: 0.05272646621841297]
	TIME [epoch: 6.35 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06162579836166589		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.06162579836166589 | validation: 0.05588409970394011]
	TIME [epoch: 6.32 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06521451146569197		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.06521451146569197 | validation: 0.05838905069529892]
	TIME [epoch: 6.31 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06534146056411679		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.06534146056411679 | validation: 0.05548064598710359]
	TIME [epoch: 6.31 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0661890326481183		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.0661890326481183 | validation: 0.053931945432097436]
	TIME [epoch: 6.31 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06522396199585155		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.06522396199585155 | validation: 0.04683313468793282]
	TIME [epoch: 6.32 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06685995736761569		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.06685995736761569 | validation: 0.05139092496314806]
	TIME [epoch: 6.35 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06593561708264531		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.06593561708264531 | validation: 0.05365829902875045]
	TIME [epoch: 6.31 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06763458242923391		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.06763458242923391 | validation: 0.057614766536545944]
	TIME [epoch: 6.31 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06584301604930175		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.06584301604930175 | validation: 0.060133460561841726]
	TIME [epoch: 6.31 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05691548436607986		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.05691548436607986 | validation: 0.048458160629628176]
	TIME [epoch: 6.31 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05630165473859558		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.05630165473859558 | validation: 0.04271122700213939]
	TIME [epoch: 6.36 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05635298837845192		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.05635298837845192 | validation: 0.05164021222474723]
	TIME [epoch: 6.32 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060911032621415465		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.060911032621415465 | validation: 0.042912030159303435]
	TIME [epoch: 6.31 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06164976829759493		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.06164976829759493 | validation: 0.0510783808385311]
	TIME [epoch: 6.32 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058921154085571296		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.058921154085571296 | validation: 0.04301412371325708]
	TIME [epoch: 6.31 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05847176623293997		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.05847176623293997 | validation: 0.038798669463129654]
	TIME [epoch: 6.33 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0624456145928345		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.0624456145928345 | validation: 0.04480841972019314]
	TIME [epoch: 6.35 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059971239780641276		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.059971239780641276 | validation: 0.04268990794049167]
	TIME [epoch: 6.31 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05927926112558662		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.05927926112558662 | validation: 0.029669310513300767]
	TIME [epoch: 6.31 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05336756046175944		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.05336756046175944 | validation: 0.03391184297333402]
	TIME [epoch: 6.31 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05257569257210902		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.05257569257210902 | validation: 0.034421441047661136]
	TIME [epoch: 6.32 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0536924602799553		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.0536924602799553 | validation: 0.036465632875167284]
	TIME [epoch: 6.36 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05420958058909909		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.05420958058909909 | validation: 0.04448114838258413]
	TIME [epoch: 6.32 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05423785242081163		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.05423785242081163 | validation: 0.038336464247825365]
	TIME [epoch: 6.31 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05106528219111933		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.05106528219111933 | validation: 0.04066347993966089]
	TIME [epoch: 6.31 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051020618277602264		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.051020618277602264 | validation: 0.02651113340342228]
	TIME [epoch: 6.31 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_1351.pth
	Model improved!!!
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056938136914618014		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.056938136914618014 | validation: 0.03756654211952401]
	TIME [epoch: 6.35 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05774162768232277		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.05774162768232277 | validation: 0.03782172816845458]
	TIME [epoch: 6.32 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06261900817457204		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.06261900817457204 | validation: 0.027909285866860194]
	TIME [epoch: 6.31 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056138998974408744		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.056138998974408744 | validation: 0.03902751927102442]
	TIME [epoch: 6.31 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055661965898850085		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.055661965898850085 | validation: 0.03927981017336083]
	TIME [epoch: 6.31 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0608163518610965		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.0608163518610965 | validation: 0.03588852635655283]
	TIME [epoch: 6.32 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061498188856646166		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.061498188856646166 | validation: 0.03217493042943172]
	TIME [epoch: 6.35 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06399219360043769		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.06399219360043769 | validation: 0.04510304780537805]
	TIME [epoch: 6.31 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06448544140132183		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.06448544140132183 | validation: 0.04080306502897462]
	TIME [epoch: 6.31 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06539059623549322		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.06539059623549322 | validation: 0.042519866008484355]
	TIME [epoch: 6.31 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058472291859023265		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.058472291859023265 | validation: 0.03424311688348697]
	TIME [epoch: 6.31 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057284139699613705		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.057284139699613705 | validation: 0.04005905297250345]
	TIME [epoch: 6.35 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06220117369487778		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.06220117369487778 | validation: 0.02857579141959252]
	TIME [epoch: 6.32 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058330858776464566		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.058330858776464566 | validation: 0.03785314977479391]
	TIME [epoch: 6.31 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05797862756611578		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.05797862756611578 | validation: 0.04267849787033941]
	TIME [epoch: 6.31 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05883189573811876		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.05883189573811876 | validation: 0.03703674662918273]
	TIME [epoch: 6.31 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05798783731449879		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.05798783731449879 | validation: 0.04596379475286898]
	TIME [epoch: 6.33 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06165933099354039		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.06165933099354039 | validation: 0.04519468276594294]
	TIME [epoch: 6.35 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0659019192181402		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.0659019192181402 | validation: 0.04574836716627749]
	TIME [epoch: 6.31 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06925372664503646		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.06925372664503646 | validation: 0.05848749985446886]
	TIME [epoch: 6.31 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07311265932540212		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.07311265932540212 | validation: 0.045933587305285156]
	TIME [epoch: 6.31 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06720870049525873		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.06720870049525873 | validation: 0.05002724865364803]
	TIME [epoch: 6.31 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06252253007229105		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.06252253007229105 | validation: 0.04698904416881354]
	TIME [epoch: 6.35 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058081424571665444		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.058081424571665444 | validation: 0.042207351640509184]
	TIME [epoch: 6.32 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056464740002887065		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.056464740002887065 | validation: 0.04710125344750031]
	TIME [epoch: 6.31 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055169704627224425		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.055169704627224425 | validation: 0.03820695107772292]
	TIME [epoch: 6.31 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06055159724480702		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.06055159724480702 | validation: 0.03121891733903119]
	TIME [epoch: 6.31 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05935335997646665		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.05935335997646665 | validation: 0.0439004382555003]
	TIME [epoch: 6.34 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061539268793420296		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.061539268793420296 | validation: 0.05063011977816423]
	TIME [epoch: 6.34 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054248430224486804		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.054248430224486804 | validation: 0.04694277953306725]
	TIME [epoch: 6.31 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05382142349184843		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.05382142349184843 | validation: 0.04519580690867468]
	TIME [epoch: 6.31 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05700571667999277		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.05700571667999277 | validation: 0.04398382446664055]
	TIME [epoch: 6.31 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05736711050856289		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.05736711050856289 | validation: 0.038541715847696036]
	TIME [epoch: 6.31 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055044479462881796		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.055044479462881796 | validation: 0.0519250117981285]
	TIME [epoch: 6.36 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05735671215819979		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.05735671215819979 | validation: 0.04155405533179277]
	TIME [epoch: 6.31 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05609901868865092		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.05609901868865092 | validation: 0.0388478130449263]
	TIME [epoch: 6.31 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055643733310358594		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.055643733310358594 | validation: 0.038741682541344476]
	TIME [epoch: 6.31 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05831361175903854		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.05831361175903854 | validation: 0.039818981746071916]
	TIME [epoch: 6.31 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058380542918022804		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.058380542918022804 | validation: 0.034718851869182894]
	TIME [epoch: 6.36 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061442778616017234		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.061442778616017234 | validation: 0.0468048478699897]
	TIME [epoch: 6.32 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05850715486278088		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.05850715486278088 | validation: 0.03785741052813818]
	TIME [epoch: 6.31 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06045800365138802		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.06045800365138802 | validation: 0.041610933841112197]
	TIME [epoch: 6.31 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05346157365521575		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.05346157365521575 | validation: 0.04225590193738074]
	TIME [epoch: 6.31 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052005248334959314		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.052005248334959314 | validation: 0.03462296488422211]
	TIME [epoch: 6.32 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05603594705595105		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.05603594705595105 | validation: 0.03653121062608666]
	TIME [epoch: 6.35 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061648878409431326		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.061648878409431326 | validation: 0.046633061171877974]
	TIME [epoch: 6.32 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05788227113212309		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.05788227113212309 | validation: 0.04117355414731734]
	TIME [epoch: 6.31 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05694042617226218		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.05694042617226218 | validation: 0.03522528630901894]
	TIME [epoch: 6.31 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0530151895182504		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.0530151895182504 | validation: 0.03882480891077448]
	TIME [epoch: 6.31 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05708883989340398		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.05708883989340398 | validation: 0.03149006070989]
	TIME [epoch: 6.36 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05099232098027091		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.05099232098027091 | validation: 0.04518453649907671]
	TIME [epoch: 6.32 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05593093258168988		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.05593093258168988 | validation: 0.03475695065622601]
	TIME [epoch: 6.31 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05845378652699233		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.05845378652699233 | validation: 0.042439066607611174]
	TIME [epoch: 6.31 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06094701661257606		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.06094701661257606 | validation: 0.04310051897572132]
	TIME [epoch: 6.31 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05769684339995877		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.05769684339995877 | validation: 0.04079644396951752]
	TIME [epoch: 6.34 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05518767630033437		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.05518767630033437 | validation: 0.038840309635930714]
	TIME [epoch: 6.33 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05541011297160397		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.05541011297160397 | validation: 0.0428179399146235]
	TIME [epoch: 6.32 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05536185748350635		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.05536185748350635 | validation: 0.026650822011149284]
	TIME [epoch: 6.31 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05545631174428711		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.05545631174428711 | validation: 0.039526136431868]
	TIME [epoch: 6.31 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05509812805854156		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.05509812805854156 | validation: 0.035627265854373785]
	TIME [epoch: 6.32 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05456756888498431		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.05456756888498431 | validation: 0.03980230425122595]
	TIME [epoch: 6.36 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05828646396472367		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.05828646396472367 | validation: 0.03947477476677912]
	TIME [epoch: 6.32 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05495596792124035		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.05495596792124035 | validation: 0.032437991936764846]
	TIME [epoch: 6.31 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0548803264995082		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.0548803264995082 | validation: 0.036438628414435834]
	TIME [epoch: 6.31 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05741923842903042		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.05741923842903042 | validation: 0.035010380225058674]
	TIME [epoch: 6.31 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05584159452411873		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.05584159452411873 | validation: 0.02865655344255338]
	TIME [epoch: 6.35 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05452577600319995		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.05452577600319995 | validation: 0.03246194441159382]
	TIME [epoch: 6.33 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05365540657499179		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.05365540657499179 | validation: 0.037673139643363815]
	TIME [epoch: 6.31 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05434092493805691		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.05434092493805691 | validation: 0.04629120086367698]
	TIME [epoch: 6.31 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052700603664640036		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.052700603664640036 | validation: 0.04221002570417139]
	TIME [epoch: 6.31 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04997077694996433		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.04997077694996433 | validation: 0.03142722571495221]
	TIME [epoch: 6.32 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05582086732743521		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.05582086732743521 | validation: 0.03524010318845032]
	TIME [epoch: 6.36 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06057993056115124		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.06057993056115124 | validation: 0.048172549345398455]
	TIME [epoch: 6.31 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05330525795976435		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.05330525795976435 | validation: 0.04437380696537502]
	TIME [epoch: 6.31 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058137879699546535		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.058137879699546535 | validation: 0.041664250490770965]
	TIME [epoch: 6.31 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0527512732866927		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.0527512732866927 | validation: 0.04097926269371059]
	TIME [epoch: 6.31 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052302736012932644		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.052302736012932644 | validation: 0.04479095027269425]
	TIME [epoch: 6.36 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05604739414784991		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.05604739414784991 | validation: 0.04087787679579652]
	TIME [epoch: 6.32 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05837321755028173		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.05837321755028173 | validation: 0.03627800571103511]
	TIME [epoch: 6.32 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05617101877711507		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.05617101877711507 | validation: 0.03939972981604745]
	TIME [epoch: 6.31 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05423130530892992		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.05423130530892992 | validation: 0.03849486100018022]
	TIME [epoch: 6.31 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05845506601131103		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.05845506601131103 | validation: 0.04016550207945366]
	TIME [epoch: 6.32 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05925856638005551		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.05925856638005551 | validation: 0.04544868730876342]
	TIME [epoch: 6.35 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060887481106063346		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.060887481106063346 | validation: 0.0454091228000411]
	TIME [epoch: 6.32 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06155399061738747		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.06155399061738747 | validation: 0.04527176989676592]
	TIME [epoch: 6.31 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05443894603523636		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.05443894603523636 | validation: 0.04393359390254714]
	TIME [epoch: 6.31 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05196321439728285		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.05196321439728285 | validation: 0.038718797475121275]
	TIME [epoch: 6.31 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057412623933633736		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.057412623933633736 | validation: 0.03699676515776825]
	TIME [epoch: 6.36 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055690462027126963		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.055690462027126963 | validation: 0.03253290167792105]
	TIME [epoch: 6.32 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05594011416697571		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.05594011416697571 | validation: 0.033286688156426825]
	TIME [epoch: 6.31 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053222663872417024		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.053222663872417024 | validation: 0.04237281798110096]
	TIME [epoch: 6.31 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05459401509441396		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.05459401509441396 | validation: 0.03599395376723685]
	TIME [epoch: 6.31 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05522667217306129		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.05522667217306129 | validation: 0.03518059181468488]
	TIME [epoch: 6.34 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0551657550972192		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.0551657550972192 | validation: 0.041882517394502286]
	TIME [epoch: 6.33 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05780231291824099		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.05780231291824099 | validation: 0.039771739934505286]
	TIME [epoch: 6.31 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06277298940848096		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.06277298940848096 | validation: 0.03987565515294369]
	TIME [epoch: 6.31 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06274919331061238		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.06274919331061238 | validation: 0.03858888949862016]
	TIME [epoch: 6.31 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06583694683461444		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.06583694683461444 | validation: 0.048744494683627224]
	TIME [epoch: 6.32 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07102686818683678		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.07102686818683678 | validation: 0.03725618423996263]
	TIME [epoch: 6.36 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061228757046941286		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.061228757046941286 | validation: 0.049921909928920746]
	TIME [epoch: 6.32 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06659479990376964		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.06659479990376964 | validation: 0.04735252710456043]
	TIME [epoch: 6.31 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06748695552005483		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.06748695552005483 | validation: 0.04857364095873788]
	TIME [epoch: 6.31 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06363067562164831		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.06363067562164831 | validation: 0.03499913917201046]
	TIME [epoch: 6.31 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06554630836879596		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.06554630836879596 | validation: 0.04862101584031121]
	TIME [epoch: 6.36 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06730501564118055		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.06730501564118055 | validation: 0.046002762541708306]
	TIME [epoch: 6.32 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06583682304439036		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.06583682304439036 | validation: 0.04719307391030698]
	TIME [epoch: 6.31 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06328055091941086		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.06328055091941086 | validation: 0.044726585106423626]
	TIME [epoch: 6.31 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06182528057932906		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.06182528057932906 | validation: 0.0386119603543741]
	TIME [epoch: 6.31 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06621808510978006		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.06621808510978006 | validation: 0.03890218845678048]
	TIME [epoch: 6.32 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06189310909581459		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.06189310909581459 | validation: 0.04454098393124056]
	TIME [epoch: 6.35 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05936422311762732		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.05936422311762732 | validation: 0.03544863781635818]
	TIME [epoch: 6.32 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06239454635016488		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.06239454635016488 | validation: 0.04505159353844722]
	TIME [epoch: 6.31 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06583068795144642		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.06583068795144642 | validation: 0.03779988804182462]
	TIME [epoch: 6.31 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0605406688045074		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.0605406688045074 | validation: 0.04356233584064342]
	TIME [epoch: 6.31 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06326901162540241		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.06326901162540241 | validation: 0.039482742234952434]
	TIME [epoch: 6.35 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06511305244806855		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.06511305244806855 | validation: 0.05605585478593361]
	TIME [epoch: 6.32 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06363924007647069		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.06363924007647069 | validation: 0.036176561179890765]
	TIME [epoch: 6.31 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05784437976480836		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.05784437976480836 | validation: 0.046695000292982486]
	TIME [epoch: 6.31 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057416350306201056		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.057416350306201056 | validation: 0.03545989307165489]
	TIME [epoch: 6.31 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060319551740600164		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.060319551740600164 | validation: 0.0380674919598303]
	TIME [epoch: 6.33 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06512534504737329		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.06512534504737329 | validation: 0.04031679771971363]
	TIME [epoch: 6.35 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059230146683581904		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.059230146683581904 | validation: 0.034570022655163526]
	TIME [epoch: 6.32 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054132459942775865		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.054132459942775865 | validation: 0.04629842120448092]
	TIME [epoch: 6.31 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05561473009491411		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.05561473009491411 | validation: 0.041180416052467986]
	TIME [epoch: 6.31 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05762852926979757		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.05762852926979757 | validation: 0.045213854886868764]
	TIME [epoch: 6.32 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055365853381355704		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.055365853381355704 | validation: 0.045556633331158974]
	TIME [epoch: 6.36 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05496619047044432		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.05496619047044432 | validation: 0.04082060848642793]
	TIME [epoch: 6.32 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052215547131542285		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.052215547131542285 | validation: 0.039516515137054384]
	TIME [epoch: 6.31 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051895967426256004		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.051895967426256004 | validation: 0.035945451926438936]
	TIME [epoch: 6.31 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05236582817088352		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.05236582817088352 | validation: 0.03306812428969921]
	TIME [epoch: 6.31 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056768542970183536		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.056768542970183536 | validation: 0.04949092458766036]
	TIME [epoch: 6.34 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05928089005466544		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.05928089005466544 | validation: 0.035242078835334686]
	TIME [epoch: 6.34 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05952377487950033		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.05952377487950033 | validation: 0.040625850327031976]
	TIME [epoch: 6.31 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05565673048378179		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.05565673048378179 | validation: 0.035471858267109774]
	TIME [epoch: 6.32 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05584063585561527		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.05584063585561527 | validation: 0.03804526821426167]
	TIME [epoch: 6.31 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05333093332293762		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.05333093332293762 | validation: 0.046442983394499864]
	TIME [epoch: 6.32 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056629643472874594		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.056629643472874594 | validation: 0.041543726522448914]
	TIME [epoch: 6.36 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059660583132519665		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.059660583132519665 | validation: 0.04508234684055447]
	TIME [epoch: 6.32 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06184054452283702		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.06184054452283702 | validation: 0.031154110103201883]
	TIME [epoch: 6.31 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055429855626812505		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.055429855626812505 | validation: 0.045499612296151445]
	TIME [epoch: 6.31 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05284272505054273		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.05284272505054273 | validation: 0.03140435135425266]
	TIME [epoch: 6.31 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05280011919742368		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.05280011919742368 | validation: 0.03952896562279972]
	TIME [epoch: 6.36 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05171287561781859		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.05171287561781859 | validation: 0.03664711557794079]
	TIME [epoch: 6.32 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05723186994668705		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.05723186994668705 | validation: 0.047965425104122814]
	TIME [epoch: 6.31 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05418597075133891		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.05418597075133891 | validation: 0.03334787884315303]
	TIME [epoch: 6.31 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05351328592625001		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.05351328592625001 | validation: 0.04253506476668192]
	TIME [epoch: 6.31 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05818384791099677		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.05818384791099677 | validation: 0.04118793946427995]
	TIME [epoch: 6.32 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056944651088029055		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.056944651088029055 | validation: 0.04413902093723501]
	TIME [epoch: 6.35 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0522912368305569		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.0522912368305569 | validation: 0.03435510596151525]
	TIME [epoch: 6.31 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05323669679217877		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.05323669679217877 | validation: 0.04137022306295756]
	TIME [epoch: 6.31 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05303599555452079		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.05303599555452079 | validation: 0.04494498018520746]
	TIME [epoch: 6.31 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05088651655302389		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.05088651655302389 | validation: 0.04905662817935546]
	TIME [epoch: 6.32 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054822545709851095		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.054822545709851095 | validation: 0.035808625046681766]
	TIME [epoch: 6.36 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05396213509267731		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.05396213509267731 | validation: 0.03898728598178914]
	TIME [epoch: 6.32 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0570546505312208		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.0570546505312208 | validation: 0.038462118548374474]
	TIME [epoch: 6.31 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05262089263842598		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.05262089263842598 | validation: 0.03852095258482613]
	TIME [epoch: 6.31 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055821975818488606		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.055821975818488606 | validation: 0.0350560586868907]
	TIME [epoch: 6.31 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0538200007789429		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.0538200007789429 | validation: 0.03388904469222837]
	TIME [epoch: 6.34 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050857520370764416		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.050857520370764416 | validation: 0.03376700266309192]
	TIME [epoch: 6.34 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0533498923968077		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.0533498923968077 | validation: 0.036404134168540395]
	TIME [epoch: 6.32 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05013376557950495		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.05013376557950495 | validation: 0.04227652353151495]
	TIME [epoch: 6.32 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05385935139822647		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.05385935139822647 | validation: 0.047519069992883606]
	TIME [epoch: 6.31 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055515636438480884		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.055515636438480884 | validation: 0.0393311516353976]
	TIME [epoch: 6.31 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056236494996802236		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.056236494996802236 | validation: 0.043442310707715]
	TIME [epoch: 6.37 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056097310920655966		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.056097310920655966 | validation: 0.04524431208992438]
	TIME [epoch: 6.32 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054721114904111495		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.054721114904111495 | validation: 0.042131826422369505]
	TIME [epoch: 6.31 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06034682203144194		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.06034682203144194 | validation: 0.04790699256383135]
	TIME [epoch: 6.31 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0556756899884147		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.0556756899884147 | validation: 0.03532870211798392]
	TIME [epoch: 6.31 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057161807664388734		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.057161807664388734 | validation: 0.0474638371468124]
	TIME [epoch: 6.35 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0543410014948389		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.0543410014948389 | validation: 0.03412693328822664]
	TIME [epoch: 6.33 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05206564071910931		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.05206564071910931 | validation: 0.041076856233230985]
	TIME [epoch: 6.32 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05458846278232523		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.05458846278232523 | validation: 0.032969066685706205]
	TIME [epoch: 6.31 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05480807540212486		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.05480807540212486 | validation: 0.04215185706996235]
	TIME [epoch: 6.31 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055064312263237464		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.055064312263237464 | validation: 0.04008115272986812]
	TIME [epoch: 6.33 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04924601599849379		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.04924601599849379 | validation: 0.04335481103103709]
	TIME [epoch: 6.35 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055533192184150225		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.055533192184150225 | validation: 0.04408985570750233]
	TIME [epoch: 6.32 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05418621900423278		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.05418621900423278 | validation: 0.045513004120917244]
	TIME [epoch: 6.31 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053882566112656		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.053882566112656 | validation: 0.03389235397834715]
	TIME [epoch: 6.31 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05649266742249885		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.05649266742249885 | validation: 0.03927652597451693]
	TIME [epoch: 6.31 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053324819213634064		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.053324819213634064 | validation: 0.037995796994163084]
	TIME [epoch: 6.36 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05378237118999736		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.05378237118999736 | validation: 0.037263309306736665]
	TIME [epoch: 6.32 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0529423982231519		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.0529423982231519 | validation: 0.03121595847131927]
	TIME [epoch: 6.31 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05311748301777114		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.05311748301777114 | validation: 0.04380094737848533]
	TIME [epoch: 6.32 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049345124939661505		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.049345124939661505 | validation: 0.027850087426452064]
	TIME [epoch: 6.31 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04998601632061722		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.04998601632061722 | validation: 0.044199923752885714]
	TIME [epoch: 6.32 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04856068640267082		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.04856068640267082 | validation: 0.03805113755285569]
	TIME [epoch: 6.35 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049279506730486373		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.049279506730486373 | validation: 0.03473327621180187]
	TIME [epoch: 6.32 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050471872768668054		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.050471872768668054 | validation: 0.039703583982504065]
	TIME [epoch: 6.31 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05378697632512805		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.05378697632512805 | validation: 0.03964231958570929]
	TIME [epoch: 6.31 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04800059193463397		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.04800059193463397 | validation: 0.03417167771604675]
	TIME [epoch: 6.32 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05440502436780511		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.05440502436780511 | validation: 0.03943940486256369]
	TIME [epoch: 6.36 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05363165094451572		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.05363165094451572 | validation: 0.03330111393701466]
	TIME [epoch: 6.32 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050442241366910265		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.050442241366910265 | validation: 0.03770079670453681]
	TIME [epoch: 6.31 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04970404674254673		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.04970404674254673 | validation: 0.041789672468799034]
	TIME [epoch: 6.31 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05117355074676603		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.05117355074676603 | validation: 0.02941504275131693]
	TIME [epoch: 6.31 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052069454323607586		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.052069454323607586 | validation: 0.03041327643122474]
	TIME [epoch: 6.34 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047813767429271056		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.047813767429271056 | validation: 0.023488748325732067]
	TIME [epoch: 6.34 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_1548.pth
	Model improved!!!
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05026024964778879		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.05026024964778879 | validation: 0.04380712728053209]
	TIME [epoch: 6.31 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05337820664211268		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.05337820664211268 | validation: 0.04336429214089501]
	TIME [epoch: 6.31 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05110664112703502		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.05110664112703502 | validation: 0.03304494697803993]
	TIME [epoch: 6.31 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050848256291004805		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.050848256291004805 | validation: 0.037561421621732594]
	TIME [epoch: 6.32 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05329858408867902		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.05329858408867902 | validation: 0.03408268087993948]
	TIME [epoch: 6.35 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04862247244228998		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.04862247244228998 | validation: 0.045784651805234736]
	TIME [epoch: 6.32 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05349845942906285		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.05349845942906285 | validation: 0.028160325516183787]
	TIME [epoch: 6.31 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053029967463075964		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.053029967463075964 | validation: 0.03897265957926243]
	TIME [epoch: 6.31 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0530487424089227		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.0530487424089227 | validation: 0.03919899241322843]
	TIME [epoch: 6.31 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05134527121688738		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.05134527121688738 | validation: 0.03339071808784397]
	TIME [epoch: 6.36 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04850548744752024		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.04850548744752024 | validation: 0.040238230947959974]
	TIME [epoch: 6.32 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04768775610526823		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.04768775610526823 | validation: 0.03557983838522365]
	TIME [epoch: 6.31 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04864485895561367		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.04864485895561367 | validation: 0.035332479561324494]
	TIME [epoch: 6.31 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05408857714074392		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.05408857714074392 | validation: 0.04479085156313879]
	TIME [epoch: 6.32 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052252618259912814		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.052252618259912814 | validation: 0.03373393869054127]
	TIME [epoch: 6.33 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049217803661792875		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.049217803661792875 | validation: 0.036487629299418504]
	TIME [epoch: 6.35 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052648142780973455		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.052648142780973455 | validation: 0.03921697506672185]
	TIME [epoch: 6.32 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05288063622370186		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.05288063622370186 | validation: 0.04137219402226258]
	TIME [epoch: 6.31 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05428433477176085		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.05428433477176085 | validation: 0.0395499810500519]
	TIME [epoch: 6.31 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0496980123441656		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.0496980123441656 | validation: 0.037225578736925606]
	TIME [epoch: 6.31 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05151405373817594		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.05151405373817594 | validation: 0.04234642371849929]
	TIME [epoch: 6.36 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04851905909935553		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.04851905909935553 | validation: 0.03567898007259462]
	TIME [epoch: 6.32 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04786805348814327		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.04786805348814327 | validation: 0.040944537720990944]
	TIME [epoch: 6.31 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052168995977321844		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.052168995977321844 | validation: 0.033530321153181226]
	TIME [epoch: 6.31 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04861534334912446		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.04861534334912446 | validation: 0.03645273734116386]
	TIME [epoch: 6.31 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052038372074302605		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.052038372074302605 | validation: 0.03693246339772778]
	TIME [epoch: 6.34 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05286516587113588		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.05286516587113588 | validation: 0.02599597404879109]
	TIME [epoch: 6.34 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052537400426279295		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.052537400426279295 | validation: 0.03475859365257119]
	TIME [epoch: 6.31 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04774831057477114		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.04774831057477114 | validation: 0.043120126396514684]
	TIME [epoch: 6.32 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050706398991759466		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.050706398991759466 | validation: 0.037320177461715225]
	TIME [epoch: 6.31 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05433679392614366		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.05433679392614366 | validation: 0.025441696413966156]
	TIME [epoch: 6.35 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05156015779160968		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.05156015779160968 | validation: 0.03994065489763667]
	TIME [epoch: 6.36 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05117836527038154		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.05117836527038154 | validation: 0.0290348912511926]
	TIME [epoch: 6.31 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051601713392977464		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.051601713392977464 | validation: 0.046317836506092655]
	TIME [epoch: 6.31 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05143105047628004		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.05143105047628004 | validation: 0.033318007824340835]
	TIME [epoch: 6.31 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05138331198189137		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.05138331198189137 | validation: 0.033276732480887736]
	TIME [epoch: 6.31 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05094401261376363		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.05094401261376363 | validation: 0.038377465428076414]
	TIME [epoch: 6.36 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04896643255621949		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.04896643255621949 | validation: 0.03424374281287033]
	TIME [epoch: 6.32 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04974927764956539		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.04974927764956539 | validation: 0.04217935655043745]
	TIME [epoch: 6.31 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049939442724600144		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.049939442724600144 | validation: 0.04102950381778715]
	TIME [epoch: 6.31 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053099459402125494		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.053099459402125494 | validation: 0.03063557203888724]
	TIME [epoch: 6.31 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05152351036691881		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.05152351036691881 | validation: 0.03669330524663458]
	TIME [epoch: 6.33 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053095032187281045		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.053095032187281045 | validation: 0.03270289457079071]
	TIME [epoch: 6.35 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054873082582800534		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.054873082582800534 | validation: 0.03722982142374217]
	TIME [epoch: 6.31 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05144116424612084		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.05144116424612084 | validation: 0.035153064382561994]
	TIME [epoch: 6.31 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05046722117315132		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.05046722117315132 | validation: 0.04191715236900495]
	TIME [epoch: 6.31 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05106927499542942		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.05106927499542942 | validation: 0.043469611983268944]
	TIME [epoch: 6.31 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050948431128897215		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.050948431128897215 | validation: 0.043321975237574264]
	TIME [epoch: 6.36 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05332919865176786		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.05332919865176786 | validation: 0.054336455660560806]
	TIME [epoch: 6.32 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053872118085891235		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.053872118085891235 | validation: 0.04069588217038901]
	TIME [epoch: 6.31 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050759579577973814		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.050759579577973814 | validation: 0.03928942884411406]
	TIME [epoch: 6.32 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050371161693119934		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.050371161693119934 | validation: 0.040557840183368006]
	TIME [epoch: 6.31 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05103355290241436		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.05103355290241436 | validation: 0.041575991362307385]
	TIME [epoch: 6.34 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0553260088001032		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.0553260088001032 | validation: 0.04234729174481352]
	TIME [epoch: 6.34 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048670448066937474		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.048670448066937474 | validation: 0.04069753379266661]
	TIME [epoch: 6.31 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05443235203510174		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.05443235203510174 | validation: 0.03308819063849188]
	TIME [epoch: 6.31 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058435218844935924		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.058435218844935924 | validation: 0.0359030155093373]
	TIME [epoch: 6.31 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051330625327598925		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.051330625327598925 | validation: 0.045596445225816934]
	TIME [epoch: 6.32 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05314517269923942		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.05314517269923942 | validation: 0.03787821769990544]
	TIME [epoch: 6.36 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05268228326497387		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.05268228326497387 | validation: 0.03768794010086465]
	TIME [epoch: 6.32 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051842604155236095		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.051842604155236095 | validation: 0.04315141863523239]
	TIME [epoch: 6.31 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04958957391578266		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.04958957391578266 | validation: 0.039649920591280315]
	TIME [epoch: 6.31 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05392352442639104		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.05392352442639104 | validation: 0.043429342661958234]
	TIME [epoch: 6.32 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05603197348014802		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.05603197348014802 | validation: 0.05140882163637456]
	TIME [epoch: 6.35 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06011737850794448		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.06011737850794448 | validation: 0.04233723629920523]
	TIME [epoch: 6.33 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05200183313952862		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.05200183313952862 | validation: 0.03278906205591453]
	TIME [epoch: 6.32 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05676723321622396		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.05676723321622396 | validation: 0.038812039784718096]
	TIME [epoch: 6.31 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05747971430454584		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.05747971430454584 | validation: 0.03246852419720458]
	TIME [epoch: 6.3 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049837068326905265		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.049837068326905265 | validation: 0.04352248011540806]
	TIME [epoch: 6.31 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05479392050140067		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.05479392050140067 | validation: 0.04370462684581434]
	TIME [epoch: 6.34 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05082501271395627		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.05082501271395627 | validation: 0.03492700158963305]
	TIME [epoch: 6.31 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0507694776314809		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.0507694776314809 | validation: 0.03969347663001233]
	TIME [epoch: 6.3 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05206894738162571		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.05206894738162571 | validation: 0.03547229965105286]
	TIME [epoch: 6.31 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050472816477940996		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.050472816477940996 | validation: 0.03283032956146109]
	TIME [epoch: 6.3 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05197537104878431		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.05197537104878431 | validation: 0.03911136192682423]
	TIME [epoch: 6.35 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05011898229885878		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.05011898229885878 | validation: 0.02820286942489261]
	TIME [epoch: 6.32 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05146767251431868		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.05146767251431868 | validation: 0.046187264586795715]
	TIME [epoch: 6.3 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048910709725002124		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.048910709725002124 | validation: 0.042085553627791684]
	TIME [epoch: 6.31 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04817223114713116		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.04817223114713116 | validation: 0.0400394828433262]
	TIME [epoch: 6.31 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048845581687976376		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.048845581687976376 | validation: 0.037214519843718964]
	TIME [epoch: 6.32 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05277852975690215		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.05277852975690215 | validation: 0.035391896645875984]
	TIME [epoch: 6.35 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05289671750780007		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.05289671750780007 | validation: 0.043070500920220994]
	TIME [epoch: 6.31 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050874566816770064		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.050874566816770064 | validation: 0.046847462310886545]
	TIME [epoch: 6.3 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054747950150514306		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.054747950150514306 | validation: 0.037442100833771995]
	TIME [epoch: 6.31 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055277343120200835		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.055277343120200835 | validation: 0.040200391972760395]
	TIME [epoch: 6.31 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04957362498909516		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.04957362498909516 | validation: 0.026788272355647104]
	TIME [epoch: 6.35 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05244350976194552		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.05244350976194552 | validation: 0.037288800770864466]
	TIME [epoch: 6.31 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049796098186277546		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.049796098186277546 | validation: 0.041742092805716266]
	TIME [epoch: 6.3 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05109924831163544		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.05109924831163544 | validation: 0.03782098235817867]
	TIME [epoch: 6.31 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05073420106871211		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.05073420106871211 | validation: 0.05005272379241259]
	TIME [epoch: 6.31 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04814826744964869		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.04814826744964869 | validation: 0.030760492664141527]
	TIME [epoch: 6.33 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054754086884683695		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.054754086884683695 | validation: 0.03120113441604331]
	TIME [epoch: 6.34 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05200039203113111		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.05200039203113111 | validation: 0.03607301084252744]
	TIME [epoch: 6.31 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04820644027601052		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.04820644027601052 | validation: 0.03774863834827571]
	TIME [epoch: 6.31 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0496185715187185		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.0496185715187185 | validation: 0.030338074622427817]
	TIME [epoch: 6.3 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04827200316764588		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.04827200316764588 | validation: 0.03269855340064555]
	TIME [epoch: 6.31 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05089904957654133		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.05089904957654133 | validation: 0.040526332129369916]
	TIME [epoch: 6.35 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0518808801533894		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.0518808801533894 | validation: 0.024461969840327537]
	TIME [epoch: 6.31 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05437584230043825		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.05437584230043825 | validation: 0.024827294983604444]
	TIME [epoch: 6.31 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052642102959615175		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.052642102959615175 | validation: 0.04474043442050106]
	TIME [epoch: 6.3 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05240133771321175		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.05240133771321175 | validation: 0.04045148783626146]
	TIME [epoch: 6.31 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05089966910007782		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.05089966910007782 | validation: 0.03826708096320626]
	TIME [epoch: 6.35 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04976649075255046		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.04976649075255046 | validation: 0.04453572252216313]
	TIME [epoch: 6.33 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05274092704185913		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.05274092704185913 | validation: 0.031148040681454194]
	TIME [epoch: 6.3 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05213090636431504		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.05213090636431504 | validation: 0.042621561226684895]
	TIME [epoch: 6.3 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05258303431942436		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.05258303431942436 | validation: 0.042244363908360436]
	TIME [epoch: 6.31 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05342143052376365		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.05342143052376365 | validation: 0.05439634635035473]
	TIME [epoch: 6.31 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052928628345268534		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.052928628345268534 | validation: 0.03287537683099226]
	TIME [epoch: 6.35 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056950050999537774		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.056950050999537774 | validation: 0.04820119274109185]
	TIME [epoch: 6.31 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051640283785133814		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.051640283785133814 | validation: 0.03691710691984364]
	TIME [epoch: 6.31 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0537651071712311		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.0537651071712311 | validation: 0.04526435586593329]
	TIME [epoch: 6.3 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04819905077922838		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.04819905077922838 | validation: 0.04089451029082896]
	TIME [epoch: 6.3 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05048998105442706		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.05048998105442706 | validation: 0.03918245923167295]
	TIME [epoch: 6.35 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05367638701903427		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.05367638701903427 | validation: 0.03309618412923956]
	TIME [epoch: 6.31 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050021717783815256		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.050021717783815256 | validation: 0.04066205320710578]
	TIME [epoch: 6.31 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05100679058194294		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.05100679058194294 | validation: 0.03329813219280773]
	TIME [epoch: 6.3 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053133665399901865		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.053133665399901865 | validation: 0.03401390115521259]
	TIME [epoch: 6.31 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05066119558979571		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.05066119558979571 | validation: 0.035737581399646036]
	TIME [epoch: 6.33 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05055603119416281		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.05055603119416281 | validation: 0.045457755324624385]
	TIME [epoch: 6.33 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05247377873495658		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.05247377873495658 | validation: 0.040332562976485686]
	TIME [epoch: 6.31 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052931581689920404		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.052931581689920404 | validation: 0.029033749946489065]
	TIME [epoch: 6.3 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05307338557955306		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.05307338557955306 | validation: 0.04720031815959058]
	TIME [epoch: 6.31 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05044074829490405		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.05044074829490405 | validation: 0.04456980900542838]
	TIME [epoch: 6.3 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049297668096740244		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.049297668096740244 | validation: 0.037343196112831364]
	TIME [epoch: 6.35 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05102949162512118		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.05102949162512118 | validation: 0.035749436689983406]
	TIME [epoch: 6.31 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05128761646516693		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.05128761646516693 | validation: 0.030203213427334702]
	TIME [epoch: 6.3 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05184562463122403		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.05184562463122403 | validation: 0.04850485644953288]
	TIME [epoch: 6.31 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05115335645788509		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.05115335645788509 | validation: 0.04336034311346331]
	TIME [epoch: 6.3 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04930387069969898		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.04930387069969898 | validation: 0.0368166280460027]
	TIME [epoch: 6.33 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04945103247355128		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.04945103247355128 | validation: 0.038264086587254165]
	TIME [epoch: 6.33 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05128145424575098		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.05128145424575098 | validation: 0.027369853041460192]
	TIME [epoch: 6.31 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051191456043742534		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.051191456043742534 | validation: 0.03734226251026541]
	TIME [epoch: 6.31 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05051251790022089		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.05051251790022089 | validation: 0.03305659414863164]
	TIME [epoch: 6.3 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05347728335197367		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.05347728335197367 | validation: 0.042699748969257205]
	TIME [epoch: 6.31 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05008736665692625		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.05008736665692625 | validation: 0.034847127509913485]
	TIME [epoch: 6.35 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04676667691061955		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.04676667691061955 | validation: 0.046595111360947176]
	TIME [epoch: 6.31 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047622257996208145		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.047622257996208145 | validation: 0.04328484922360056]
	TIME [epoch: 6.31 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05304793234286955		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.05304793234286955 | validation: 0.0334004201595981]
	TIME [epoch: 6.3 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05078475714352825		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.05078475714352825 | validation: 0.03894019258236037]
	TIME [epoch: 6.3 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051129956209693066		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.051129956209693066 | validation: 0.039251313310310856]
	TIME [epoch: 6.34 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04813634017885619		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.04813634017885619 | validation: 0.02882097828582164]
	TIME [epoch: 6.31 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052049144809103075		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.052049144809103075 | validation: 0.036561102534384424]
	TIME [epoch: 6.3 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054622975918435		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.054622975918435 | validation: 0.030700806776551657]
	TIME [epoch: 6.31 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053503846983042724		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.053503846983042724 | validation: 0.04023025454000491]
	TIME [epoch: 6.31 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0563764659930542		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.0563764659930542 | validation: 0.048846842987112456]
	TIME [epoch: 6.32 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05516510741848871		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.05516510741848871 | validation: 0.03857887968502682]
	TIME [epoch: 6.34 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04693026481472978		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.04693026481472978 | validation: 0.043814423830524266]
	TIME [epoch: 6.31 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04947675803967949		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.04947675803967949 | validation: 0.033808417547612914]
	TIME [epoch: 6.31 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04714885392096015		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.04714885392096015 | validation: 0.0380681840248521]
	TIME [epoch: 6.3 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05478715261989078		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.05478715261989078 | validation: 0.043316784859111654]
	TIME [epoch: 6.31 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05028895383586507		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.05028895383586507 | validation: 0.028639042833338638]
	TIME [epoch: 6.35 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05072580885756374		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.05072580885756374 | validation: 0.03218416338173393]
	TIME [epoch: 6.31 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056533472433658485		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.056533472433658485 | validation: 0.038439225761711555]
	TIME [epoch: 6.3 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05562275132308468		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.05562275132308468 | validation: 0.04063488363611042]
	TIME [epoch: 6.3 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051917356117950994		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.051917356117950994 | validation: 0.04132242667756067]
	TIME [epoch: 6.31 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04951435661064224		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.04951435661064224 | validation: 0.031090397882323765]
	TIME [epoch: 6.33 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05400110533155235		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.05400110533155235 | validation: 0.04120862288474217]
	TIME [epoch: 6.33 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048290736624359384		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.048290736624359384 | validation: 0.035612662701591254]
	TIME [epoch: 6.3 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05183613920732269		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.05183613920732269 | validation: 0.029876687832233642]
	TIME [epoch: 6.3 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04943503102024967		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.04943503102024967 | validation: 0.03751209312442214]
	TIME [epoch: 6.31 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05127085911220376		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.05127085911220376 | validation: 0.03816518299931532]
	TIME [epoch: 6.31 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05120115273899779		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.05120115273899779 | validation: 0.04100982288237996]
	TIME [epoch: 6.36 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049545848806783255		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.049545848806783255 | validation: 0.035054267173695294]
	TIME [epoch: 6.3 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05025786274541835		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.05025786274541835 | validation: 0.03198469628274387]
	TIME [epoch: 6.31 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04946526980880812		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.04946526980880812 | validation: 0.03781903048305099]
	TIME [epoch: 6.3 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053982497317646434		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.053982497317646434 | validation: 0.03476268469904383]
	TIME [epoch: 6.3 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054107389058849015		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.054107389058849015 | validation: 0.04430215024736611]
	TIME [epoch: 6.34 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05286795241200244		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.05286795241200244 | validation: 0.033105546334499636]
	TIME [epoch: 6.32 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05008927458343296		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.05008927458343296 | validation: 0.045240617433066815]
	TIME [epoch: 6.31 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048233232237039916		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.048233232237039916 | validation: 0.03426986318718737]
	TIME [epoch: 6.3 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051857145668563066		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.051857145668563066 | validation: 0.04375573117973276]
	TIME [epoch: 6.31 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04907625005873275		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.04907625005873275 | validation: 0.04229350338911525]
	TIME [epoch: 6.32 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04996894420482069		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.04996894420482069 | validation: 0.033227766001696385]
	TIME [epoch: 6.34 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05192312995498512		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.05192312995498512 | validation: 0.03539603543091571]
	TIME [epoch: 6.31 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051725296237314616		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.051725296237314616 | validation: 0.04745498543276015]
	TIME [epoch: 6.3 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049359600480915554		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.049359600480915554 | validation: 0.03212575106348937]
	TIME [epoch: 6.31 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049199311053565016		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.049199311053565016 | validation: 0.030916067094619006]
	TIME [epoch: 6.3 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05336992599328309		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.05336992599328309 | validation: 0.0448921609398351]
	TIME [epoch: 6.35 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053022382346783324		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.053022382346783324 | validation: 0.03251083435997635]
	TIME [epoch: 6.32 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05407274576737933		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.05407274576737933 | validation: 0.04034955003493533]
	TIME [epoch: 6.3 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05262559274005202		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.05262559274005202 | validation: 0.03465348790802833]
	TIME [epoch: 6.31 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05126980224210234		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.05126980224210234 | validation: 0.030043239017793814]
	TIME [epoch: 6.3 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052220941438849325		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.052220941438849325 | validation: 0.036602521853943394]
	TIME [epoch: 6.32 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049859292328945704		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.049859292328945704 | validation: 0.03951160719962349]
	TIME [epoch: 6.34 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05042869958490148		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.05042869958490148 | validation: 0.034508876659155786]
	TIME [epoch: 6.31 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049486214294005515		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.049486214294005515 | validation: 0.040269038460036564]
	TIME [epoch: 6.31 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0484324339951495		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.0484324339951495 | validation: 0.031168847194117173]
	TIME [epoch: 6.3 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04993799806266488		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.04993799806266488 | validation: 0.03849007981387288]
	TIME [epoch: 6.3 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0527465536839929		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.0527465536839929 | validation: 0.03760604267564563]
	TIME [epoch: 6.35 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0477382460670827		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.0477382460670827 | validation: 0.03639816596841382]
	TIME [epoch: 6.31 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04896180052556607		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.04896180052556607 | validation: 0.04106472382858826]
	TIME [epoch: 6.31 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04937461656288143		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.04937461656288143 | validation: 0.036951458857062344]
	TIME [epoch: 6.31 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05130258625503854		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.05130258625503854 | validation: 0.04368679030714506]
	TIME [epoch: 6.3 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05343742790248682		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.05343742790248682 | validation: 0.03351172339194866]
	TIME [epoch: 6.33 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051571688207144285		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.051571688207144285 | validation: 0.032732159520282605]
	TIME [epoch: 6.33 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052286137109237796		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.052286137109237796 | validation: 0.028987484045912323]
	TIME [epoch: 6.3 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05159544332437483		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.05159544332437483 | validation: 0.04135402643840209]
	TIME [epoch: 6.31 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05081148895336868		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.05081148895336868 | validation: 0.03152337600863503]
	TIME [epoch: 6.31 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056959497268907595		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.056959497268907595 | validation: 0.0478934335383905]
	TIME [epoch: 6.3 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04852599282369095		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.04852599282369095 | validation: 0.04022810835992019]
	TIME [epoch: 6.35 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05204604313468772		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.05204604313468772 | validation: 0.03941880737515643]
	TIME [epoch: 6.31 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0540526381413453		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.0540526381413453 | validation: 0.04640303688483126]
	TIME [epoch: 6.31 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0535698315158365		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.0535698315158365 | validation: 0.044899592915908074]
	TIME [epoch: 6.3 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05216643561096937		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.05216643561096937 | validation: 0.037199305221315294]
	TIME [epoch: 6.31 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0484767876302399		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.0484767876302399 | validation: 0.043227035676307]
	TIME [epoch: 6.34 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05064926622153825		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.05064926622153825 | validation: 0.034126562928579615]
	TIME [epoch: 6.32 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05090820878551468		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.05090820878551468 | validation: 0.042013648539232624]
	TIME [epoch: 6.31 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04745353534299348		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.04745353534299348 | validation: 0.03879640547731962]
	TIME [epoch: 6.3 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0509193350640357		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.0509193350640357 | validation: 0.03868993044945798]
	TIME [epoch: 6.3 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047809452687865586		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.047809452687865586 | validation: 0.043864024278647676]
	TIME [epoch: 6.32 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047893204423626906		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.047893204423626906 | validation: 0.03410624848964004]
	TIME [epoch: 6.34 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05403813672972349		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.05403813672972349 | validation: 0.03738199207809666]
	TIME [epoch: 6.31 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05304474409004614		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.05304474409004614 | validation: 0.029608774890175896]
	TIME [epoch: 6.3 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04902511948518774		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.04902511948518774 | validation: 0.0415092339073906]
	TIME [epoch: 6.3 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04818078737970083		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.04818078737970083 | validation: 0.03886080346714511]
	TIME [epoch: 6.3 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04994764933759112		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.04994764933759112 | validation: 0.04088500173434074]
	TIME [epoch: 6.35 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05314431059628012		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.05314431059628012 | validation: 0.025547157229210218]
	TIME [epoch: 6.31 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050882262053844905		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.050882262053844905 | validation: 0.03481747657921673]
	TIME [epoch: 6.31 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05196698415170707		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.05196698415170707 | validation: 0.026623674370272087]
	TIME [epoch: 6.3 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054557990071341225		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.054557990071341225 | validation: 0.03774283119946893]
	TIME [epoch: 6.3 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05212530232753026		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.05212530232753026 | validation: 0.0355169429681929]
	TIME [epoch: 6.33 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04758740926288967		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.04758740926288967 | validation: 0.027889044963548573]
	TIME [epoch: 6.33 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05005227231947413		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.05005227231947413 | validation: 0.03854395861061802]
	TIME [epoch: 6.31 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049253039286178205		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.049253039286178205 | validation: 0.04307167165150164]
	TIME [epoch: 6.3 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05050538542418172		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.05050538542418172 | validation: 0.03604277658055998]
	TIME [epoch: 6.3 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050089316086011346		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.050089316086011346 | validation: 0.03351226858561221]
	TIME [epoch: 6.31 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051343615356559374		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.051343615356559374 | validation: 0.04662956788773345]
	TIME [epoch: 6.35 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04853749186240214		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.04853749186240214 | validation: 0.040790170738677294]
	TIME [epoch: 6.31 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05251395317335868		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.05251395317335868 | validation: 0.03232524239285693]
	TIME [epoch: 6.3 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05250044988755476		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.05250044988755476 | validation: 0.03552809861897694]
	TIME [epoch: 6.31 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05663243973214826		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.05663243973214826 | validation: 0.04014620772928393]
	TIME [epoch: 6.31 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051550386463865894		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.051550386463865894 | validation: 0.044082473179988785]
	TIME [epoch: 6.34 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049546797231241516		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.049546797231241516 | validation: 0.037778550667675756]
	TIME [epoch: 6.32 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04843752541175525		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.04843752541175525 | validation: 0.045203979854308886]
	TIME [epoch: 6.3 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0503732128222603		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.0503732128222603 | validation: 0.04450255744475919]
	TIME [epoch: 6.31 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04912641659752655		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.04912641659752655 | validation: 0.039195016073568074]
	TIME [epoch: 6.31 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0490299834761548		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.0490299834761548 | validation: 0.04916438856735046]
	TIME [epoch: 6.31 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053096535251603405		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.053096535251603405 | validation: 0.03476784017514946]
	TIME [epoch: 6.35 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05159599748896297		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.05159599748896297 | validation: 0.037149125164162994]
	TIME [epoch: 6.31 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05182067197225819		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.05182067197225819 | validation: 0.036106334311067884]
	TIME [epoch: 6.3 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04956835264676328		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.04956835264676328 | validation: 0.04036096986846267]
	TIME [epoch: 6.3 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04730966432251035		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.04730966432251035 | validation: 0.02193819673980775]
	TIME [epoch: 6.31 sec]
	Saving model to: out/model_training/model_phi2_1a_v1_20240410_134821/states/model_phi2_1a_v1_1790.pth
	Model improved!!!
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0524952529032286		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.0524952529032286 | validation: 0.04181889401324479]
	TIME [epoch: 6.35 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04987851556703451		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.04987851556703451 | validation: 0.03938216527818621]
	TIME [epoch: 6.31 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04958219009728235		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.04958219009728235 | validation: 0.03804153531606326]
	TIME [epoch: 6.3 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04979312006254656		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.04979312006254656 | validation: 0.04077698080824182]
	TIME [epoch: 6.3 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05002518832159529		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.05002518832159529 | validation: 0.0436522881538203]
	TIME [epoch: 6.3 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05102301906192418		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.05102301906192418 | validation: 0.037651204483176416]
	TIME [epoch: 6.32 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05417472024396153		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.05417472024396153 | validation: 0.03813744502879351]
	TIME [epoch: 6.33 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05075305772051967		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.05075305772051967 | validation: 0.029220976098233764]
	TIME [epoch: 6.3 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052768344027787475		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.052768344027787475 | validation: 0.037336278204282064]
	TIME [epoch: 6.3 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04507376378211909		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.04507376378211909 | validation: 0.03346608682842185]
	TIME [epoch: 6.3 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0462967014878362		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.0462967014878362 | validation: 0.03147270369513509]
	TIME [epoch: 6.31 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04836348197619854		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.04836348197619854 | validation: 0.027755454100638025]
	TIME [epoch: 6.35 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05108497670815602		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.05108497670815602 | validation: 0.03836802715540981]
	TIME [epoch: 6.31 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04839362947426423		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.04839362947426423 | validation: 0.03886475528556555]
	TIME [epoch: 6.3 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05087334684636299		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.05087334684636299 | validation: 0.03973619240314623]
	TIME [epoch: 6.3 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04611166240892495		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.04611166240892495 | validation: 0.03548044507601209]
	TIME [epoch: 6.3 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046701965001228356		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.046701965001228356 | validation: 0.03123564222001401]
	TIME [epoch: 6.34 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05452688853244379		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.05452688853244379 | validation: 0.03552114533086602]
	TIME [epoch: 6.32 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05001078784940645		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.05001078784940645 | validation: 0.038351305647628106]
	TIME [epoch: 6.31 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05239694043352177		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.05239694043352177 | validation: 0.039053300961538195]
	TIME [epoch: 6.3 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053294042573035404		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.053294042573035404 | validation: 0.035373730375492046]
	TIME [epoch: 6.31 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05194680725742873		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.05194680725742873 | validation: 0.03602374279205901]
	TIME [epoch: 6.32 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050176102219873085		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.050176102219873085 | validation: 0.03250910132395148]
	TIME [epoch: 6.34 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048675996153946896		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.048675996153946896 | validation: 0.035865937175566534]
	TIME [epoch: 6.31 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04798025818687499		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.04798025818687499 | validation: 0.028518345824083496]
	TIME [epoch: 6.3 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055330312340954806		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.055330312340954806 | validation: 0.040337123755136636]
	TIME [epoch: 6.31 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04990283041986626		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.04990283041986626 | validation: 0.04408466291398783]
	TIME [epoch: 6.3 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04783948332910569		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.04783948332910569 | validation: 0.03853825011134834]
	TIME [epoch: 6.35 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050167386259661474		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.050167386259661474 | validation: 0.046710886081223375]
	TIME [epoch: 6.32 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05333034854541771		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.05333034854541771 | validation: 0.0462360213018128]
	TIME [epoch: 6.31 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050703943390183394		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.050703943390183394 | validation: 0.040818349055680075]
	TIME [epoch: 6.31 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05121497680864379		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.05121497680864379 | validation: 0.043285546588296274]
	TIME [epoch: 6.31 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050359290569369664		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.050359290569369664 | validation: 0.03769100068231633]
	TIME [epoch: 6.33 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050297524035633284		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.050297524035633284 | validation: 0.04266961266645399]
	TIME [epoch: 6.35 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04944172449272328		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.04944172449272328 | validation: 0.04427760362024402]
	TIME [epoch: 6.32 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05084536862902729		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.05084536862902729 | validation: 0.04076250760668017]
	TIME [epoch: 6.31 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05028816981852982		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.05028816981852982 | validation: 0.04139932984131374]
	TIME [epoch: 6.31 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055006854671038295		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.055006854671038295 | validation: 0.03470150346687157]
	TIME [epoch: 6.31 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04796362115576329		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.04796362115576329 | validation: 0.036254318529853585]
	TIME [epoch: 6.36 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053493688284560754		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.053493688284560754 | validation: 0.04365625848702408]
	TIME [epoch: 6.32 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048015607892176584		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.048015607892176584 | validation: 0.030348328297502898]
	TIME [epoch: 6.31 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048501514777995726		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.048501514777995726 | validation: 0.03726958052294141]
	TIME [epoch: 6.31 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05460972833777365		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.05460972833777365 | validation: 0.04054460138343356]
	TIME [epoch: 6.31 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05037242202240005		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.05037242202240005 | validation: 0.045162246955547866]
	TIME [epoch: 6.34 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0525152574913638		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.0525152574913638 | validation: 0.03955463208578979]
	TIME [epoch: 6.34 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04939203372592467		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.04939203372592467 | validation: 0.03175900680200962]
	TIME [epoch: 6.31 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05266965178856901		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.05266965178856901 | validation: 0.033369182556627755]
	TIME [epoch: 6.31 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05021692088127817		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.05021692088127817 | validation: 0.037454538220018305]
	TIME [epoch: 6.31 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04990801958247915		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.04990801958247915 | validation: 0.04156164261372966]
	TIME [epoch: 6.33 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04721831489159332		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.04721831489159332 | validation: 0.039965031988273884]
	TIME [epoch: 6.36 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047607412511565		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.047607412511565 | validation: 0.04157670746974607]
	TIME [epoch: 6.32 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052469815365836066		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.052469815365836066 | validation: 0.039657845178430906]
	TIME [epoch: 6.32 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049583656774763514		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.049583656774763514 | validation: 0.04390345496369084]
	TIME [epoch: 6.31 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04850952685504254		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.04850952685504254 | validation: 0.03222381450454986]
	TIME [epoch: 6.32 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04789886787275335		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.04789886787275335 | validation: 0.03699351979208585]
	TIME [epoch: 6.36 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05216880425539912		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.05216880425539912 | validation: 0.040986264321976267]
	TIME [epoch: 6.33 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04973512773720597		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.04973512773720597 | validation: 0.03991827557520487]
	TIME [epoch: 6.32 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05244189588515045		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.05244189588515045 | validation: 0.029494657660030656]
	TIME [epoch: 6.32 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05491069153848611		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.05491069153848611 | validation: 0.03255700962586698]
	TIME [epoch: 6.32 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05176596486479709		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.05176596486479709 | validation: 0.048979844656175504]
	TIME [epoch: 6.32 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05187624750764124		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.05187624750764124 | validation: 0.04326113991549531]
	TIME [epoch: 6.36 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05459976525478428		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.05459976525478428 | validation: 0.0434298306708227]
	TIME [epoch: 6.32 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05254244872342236		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.05254244872342236 | validation: 0.03348722220807502]
	TIME [epoch: 6.32 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05611677422810348		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.05611677422810348 | validation: 0.03210430368941453]
	TIME [epoch: 6.31 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05308073119498887		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.05308073119498887 | validation: 0.032951722414872014]
	TIME [epoch: 6.31 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05294697961739739		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.05294697961739739 | validation: 0.0414227057671743]
	TIME [epoch: 6.37 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054657332675553054		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.054657332675553054 | validation: 0.030988483343834486]
	TIME [epoch: 6.32 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04666025994016993		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.04666025994016993 | validation: 0.03895559761772194]
	TIME [epoch: 6.32 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04706007998734204		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.04706007998734204 | validation: 0.04877314708973053]
	TIME [epoch: 6.32 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051128194127528545		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.051128194127528545 | validation: 0.041968077359648276]
	TIME [epoch: 6.31 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05243427970278087		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.05243427970278087 | validation: 0.0389557172022901]
	TIME [epoch: 6.34 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04770032717796477		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.04770032717796477 | validation: 0.037193752991120335]
	TIME [epoch: 6.34 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047124892319018445		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.047124892319018445 | validation: 0.037075076648203975]
	TIME [epoch: 6.32 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05348807195472305		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.05348807195472305 | validation: 0.03858226510692049]
	TIME [epoch: 6.31 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04708442148421242		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.04708442148421242 | validation: 0.047114622072112824]
	TIME [epoch: 6.32 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05035189976387191		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.05035189976387191 | validation: 0.031635134228636175]
	TIME [epoch: 6.32 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052912220717141634		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.052912220717141634 | validation: 0.029528347735369824]
	TIME [epoch: 6.36 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0521401259317253		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.0521401259317253 | validation: 0.024969894629303897]
	TIME [epoch: 6.32 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05286326413103762		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.05286326413103762 | validation: 0.04315263623131367]
	TIME [epoch: 6.31 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04701880950073164		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.04701880950073164 | validation: 0.03671311886575733]
	TIME [epoch: 6.32 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04601738359918945		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.04601738359918945 | validation: 0.03824137503099144]
	TIME [epoch: 6.32 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04805221329026403		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.04805221329026403 | validation: 0.03541272572515321]
	TIME [epoch: 6.36 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0510007511212715		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.0510007511212715 | validation: 0.039738376757511185]
	TIME [epoch: 6.32 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0478180188446816		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.0478180188446816 | validation: 0.040519034809325574]
	TIME [epoch: 6.31 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05021811404013424		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.05021811404013424 | validation: 0.03772777060283147]
	TIME [epoch: 6.32 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0446284234143628		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.0446284234143628 | validation: 0.03997986643810062]
	TIME [epoch: 6.31 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050041320109881396		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.050041320109881396 | validation: 0.028542028930223763]
	TIME [epoch: 6.33 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050320474710602484		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.050320474710602484 | validation: 0.034804944253756596]
	TIME [epoch: 6.35 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049032418558385006		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.049032418558385006 | validation: 0.037923424515154444]
	TIME [epoch: 6.32 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05244412479528991		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.05244412479528991 | validation: 0.036036923752618716]
	TIME [epoch: 6.31 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052727334017817484		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.052727334017817484 | validation: 0.03932776273762757]
	TIME [epoch: 6.31 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04973243307381312		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.04973243307381312 | validation: 0.035775329615265555]
	TIME [epoch: 6.31 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050357653648170464		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.050357653648170464 | validation: 0.04810201650629361]
	TIME [epoch: 6.36 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052749017817402766		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.052749017817402766 | validation: 0.056001645045753695]
	TIME [epoch: 6.32 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048745764892195176		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.048745764892195176 | validation: 0.03983950558048571]
	TIME [epoch: 6.31 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05093886476349363		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.05093886476349363 | validation: 0.03889348633790754]
	TIME [epoch: 6.32 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05006397069217831		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.05006397069217831 | validation: 0.03242982873731]
	TIME [epoch: 6.31 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051374472330773926		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.051374472330773926 | validation: 0.04045178301573398]
	TIME [epoch: 6.34 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05301812180386864		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.05301812180386864 | validation: 0.03599307722530518]
	TIME [epoch: 6.34 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04798566641761415		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.04798566641761415 | validation: 0.027015186610189774]
	TIME [epoch: 6.32 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0503641716459236		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.0503641716459236 | validation: 0.041393324169007185]
	TIME [epoch: 6.32 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05286811881982332		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.05286811881982332 | validation: 0.03964196481825218]
	TIME [epoch: 6.31 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04821813167341006		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.04821813167341006 | validation: 0.04208684882004881]
	TIME [epoch: 6.32 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04852248555038379		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.04852248555038379 | validation: 0.03623695143775346]
	TIME [epoch: 6.36 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04841382483383737		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.04841382483383737 | validation: 0.05126966441646419]
	TIME [epoch: 6.32 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049736928461922784		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.049736928461922784 | validation: 0.04779569862276639]
	TIME [epoch: 6.32 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05328415923132134		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.05328415923132134 | validation: 0.03940092232839558]
	TIME [epoch: 6.31 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04855211123667441		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.04855211123667441 | validation: 0.029670577378008347]
	TIME [epoch: 6.32 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04952521351455297		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.04952521351455297 | validation: 0.04122333072432583]
	TIME [epoch: 6.36 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047060761078940305		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.047060761078940305 | validation: 0.04821389781730385]
	TIME [epoch: 6.32 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050212379453673295		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.050212379453673295 | validation: 0.03833139589540158]
	TIME [epoch: 6.31 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052116726584589074		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.052116726584589074 | validation: 0.03443339612597522]
	TIME [epoch: 6.31 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05152770338117019		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.05152770338117019 | validation: 0.03702835546319637]
	TIME [epoch: 6.32 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049981762079672705		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.049981762079672705 | validation: 0.035506723834765615]
	TIME [epoch: 6.32 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05506808862904056		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.05506808862904056 | validation: 0.035479716910363376]
	TIME [epoch: 6.35 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04875962902419401		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.04875962902419401 | validation: 0.04889862011590577]
	TIME [epoch: 6.32 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0473947857537864		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.0473947857537864 | validation: 0.040711361734487035]
	TIME [epoch: 6.31 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05170032277191443		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.05170032277191443 | validation: 0.036311992418964364]
	TIME [epoch: 6.31 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046551680484874916		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.046551680484874916 | validation: 0.031335262409209544]
	TIME [epoch: 6.31 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04769114336716729		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.04769114336716729 | validation: 0.041547541962610596]
	TIME [epoch: 6.36 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04517634172944657		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.04517634172944657 | validation: 0.027891411039601164]
	TIME [epoch: 6.32 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050618465010969046		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.050618465010969046 | validation: 0.044172872456906105]
	TIME [epoch: 6.32 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04898972646179767		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.04898972646179767 | validation: 0.045937378684701914]
	TIME [epoch: 6.31 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04892833033531364		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.04892833033531364 | validation: 0.03880074583723264]
	TIME [epoch: 6.31 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049287069550989854		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.049287069550989854 | validation: 0.026882633487330897]
	TIME [epoch: 6.34 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0504557968367469		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.0504557968367469 | validation: 0.039649780854455946]
	TIME [epoch: 6.34 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04870001070052968		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.04870001070052968 | validation: 0.038978323013712075]
	TIME [epoch: 6.32 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050979158620963416		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.050979158620963416 | validation: 0.03037519623507491]
	TIME [epoch: 6.31 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0498521812758243		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.0498521812758243 | validation: 0.04454275776380697]
	TIME [epoch: 6.32 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0521524599963103		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.0521524599963103 | validation: 0.03390715907084522]
	TIME [epoch: 6.31 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049788788301767466		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.049788788301767466 | validation: 0.02869347166256509]
	TIME [epoch: 6.36 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04544890621901906		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.04544890621901906 | validation: 0.035501956125695525]
	TIME [epoch: 6.32 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04865347253148251		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.04865347253148251 | validation: 0.04422271795693711]
	TIME [epoch: 6.31 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05056464334823383		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.05056464334823383 | validation: 0.03158710073257928]
	TIME [epoch: 6.32 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04678633386892896		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.04678633386892896 | validation: 0.03507064953872966]
	TIME [epoch: 6.31 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04943418477717128		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.04943418477717128 | validation: 0.035048758820382754]
	TIME [epoch: 6.35 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0485021836043527		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.0485021836043527 | validation: 0.0327490383518675]
	TIME [epoch: 6.33 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048501374982673234		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.048501374982673234 | validation: 0.030176322569627177]
	TIME [epoch: 6.32 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051677848945711626		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.051677848945711626 | validation: 0.02663623545905428]
	TIME [epoch: 6.32 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04863600126836065		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.04863600126836065 | validation: 0.03186617700742089]
	TIME [epoch: 6.32 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04798279982650672		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.04798279982650672 | validation: 0.03725443919323827]
	TIME [epoch: 6.33 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04805727707418997		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.04805727707418997 | validation: 0.04346407285613372]
	TIME [epoch: 6.35 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04886774734161091		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.04886774734161091 | validation: 0.035015177963219686]
	TIME [epoch: 6.32 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04626284655014613		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.04626284655014613 | validation: 0.04220725562245099]
	TIME [epoch: 6.32 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04813946144827522		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.04813946144827522 | validation: 0.03829776384327575]
	TIME [epoch: 6.32 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04774429514124719		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.04774429514124719 | validation: 0.03657654489612949]
	TIME [epoch: 6.32 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05171371469313857		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.05171371469313857 | validation: 0.03311110201027866]
	TIME [epoch: 6.36 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04730117156880104		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.04730117156880104 | validation: 0.036710533967522635]
	TIME [epoch: 6.33 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04542046894143563		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.04542046894143563 | validation: 0.04521102459243777]
	TIME [epoch: 6.32 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046116901552993785		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.046116901552993785 | validation: 0.028520776834371545]
	TIME [epoch: 6.32 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04932644180585516		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.04932644180585516 | validation: 0.03904118533491519]
	TIME [epoch: 6.31 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04629139595002383		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.04629139595002383 | validation: 0.04186449067850169]
	TIME [epoch: 6.33 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04754806589103088		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.04754806589103088 | validation: 0.03905022572470117]
	TIME [epoch: 6.36 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043549368389075346		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.043549368389075346 | validation: 0.04302449152509816]
	TIME [epoch: 6.32 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046207536165214114		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.046207536165214114 | validation: 0.03796169434947193]
	TIME [epoch: 6.32 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05062455018003008		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.05062455018003008 | validation: 0.04287098240470938]
	TIME [epoch: 6.31 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05062097037368298		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.05062097037368298 | validation: 0.03357594508206655]
	TIME [epoch: 6.32 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04926500464944114		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.04926500464944114 | validation: 0.03616785564722621]
	TIME [epoch: 6.36 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04566487548747368		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.04566487548747368 | validation: 0.03178658549378004]
	TIME [epoch: 6.32 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04636828571254394		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.04636828571254394 | validation: 0.027976325820294426]
	TIME [epoch: 6.31 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05316330102332511		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.05316330102332511 | validation: 0.039142869658781]
	TIME [epoch: 6.31 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050046501168946426		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.050046501168946426 | validation: 0.03463914962920869]
	TIME [epoch: 6.32 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047086580482308786		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.047086580482308786 | validation: 0.04197287832020007]
	TIME [epoch: 6.35 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04723391614398964		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.04723391614398964 | validation: 0.031205559061996044]
	TIME [epoch: 6.34 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04880848484406793		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.04880848484406793 | validation: 0.03138090862911161]
	TIME [epoch: 6.31 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046354407121568936		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.046354407121568936 | validation: 0.0329152053569465]
	TIME [epoch: 6.31 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04584312107203094		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.04584312107203094 | validation: 0.028680988965352927]
	TIME [epoch: 6.32 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04641317181357672		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.04641317181357672 | validation: 0.03371858458992078]
	TIME [epoch: 6.32 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04806938512862191		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.04806938512862191 | validation: 0.0341656643223446]
	TIME [epoch: 6.36 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051152533646175044		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.051152533646175044 | validation: 0.04024538762717178]
	TIME [epoch: 6.32 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052212651853814344		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.052212651853814344 | validation: 0.036072737201583896]
	TIME [epoch: 6.32 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047425292854591		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.047425292854591 | validation: 0.03754169804410858]
	TIME [epoch: 6.31 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05116130559466276		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.05116130559466276 | validation: 0.034860026070608424]
	TIME [epoch: 6.31 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04618250220735892		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.04618250220735892 | validation: 0.04102042259846915]
	TIME [epoch: 6.36 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048852097701147984		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.048852097701147984 | validation: 0.0300603952235858]
	TIME [epoch: 6.33 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04775848039844511		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.04775848039844511 | validation: 0.03098393296952618]
	TIME [epoch: 6.32 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042141325367317156		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.042141325367317156 | validation: 0.04235836048554342]
	TIME [epoch: 6.31 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0493607764086436		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.0493607764086436 | validation: 0.03418758068726601]
	TIME [epoch: 6.31 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05031862267584164		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.05031862267584164 | validation: 0.03275102029935607]
	TIME [epoch: 6.33 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05015377683857292		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.05015377683857292 | validation: 0.04253555267468065]
	TIME [epoch: 6.35 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050300620484303046		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.050300620484303046 | validation: 0.030430776513817946]
	TIME [epoch: 6.32 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04586594649938497		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.04586594649938497 | validation: 0.03629435903000548]
	TIME [epoch: 6.31 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04585071512055142		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.04585071512055142 | validation: 0.05134619366453562]
	TIME [epoch: 6.32 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04656143225445105		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.04656143225445105 | validation: 0.045929096935519914]
	TIME [epoch: 6.31 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05041607865546352		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.05041607865546352 | validation: 0.0470880205337762]
	TIME [epoch: 6.36 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04847322260188294		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.04847322260188294 | validation: 0.03224880007948089]
	TIME [epoch: 6.32 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05139637532535134		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.05139637532535134 | validation: 0.034462129797678376]
	TIME [epoch: 6.31 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05116575410705787		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.05116575410705787 | validation: 0.02474578861906777]
	TIME [epoch: 6.32 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05304918130057294		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.05304918130057294 | validation: 0.03320670282192811]
	TIME [epoch: 6.31 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04900247439653559		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.04900247439653559 | validation: 0.03579223562978341]
	TIME [epoch: 6.34 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051493210337050226		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.051493210337050226 | validation: 0.02971786467313889]
	TIME [epoch: 6.34 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0521700802899175		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.0521700802899175 | validation: 0.0450945949457066]
	TIME [epoch: 6.31 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05058459294383033		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.05058459294383033 | validation: 0.025093980058229222]
	TIME [epoch: 6.31 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051487268138959305		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.051487268138959305 | validation: 0.03788578718924425]
	TIME [epoch: 6.31 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04953920190811032		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.04953920190811032 | validation: 0.044994515164800304]
	TIME [epoch: 6.32 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05010350580977783		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.05010350580977783 | validation: 0.0410936583518693]
	TIME [epoch: 6.36 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051114965032105025		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.051114965032105025 | validation: 0.03714805001800051]
	TIME [epoch: 6.32 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05059294390513272		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.05059294390513272 | validation: 0.04351393177178518]
	TIME [epoch: 6.31 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04853076529919133		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.04853076529919133 | validation: 0.03825494872314144]
	TIME [epoch: 6.31 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04917905410591243		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.04917905410591243 | validation: 0.03505136362451075]
	TIME [epoch: 6.32 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05065741282995017		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.05065741282995017 | validation: 0.03464857046584468]
	TIME [epoch: 6.36 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04841991398439255		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.04841991398439255 | validation: 0.03450336326487644]
	TIME [epoch: 6.33 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052302116763440036		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.052302116763440036 | validation: 0.03754477779408549]
	TIME [epoch: 6.31 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05081682310050362		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.05081682310050362 | validation: 0.03545884835960715]
	TIME [epoch: 6.32 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04934933965415719		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.04934933965415719 | validation: 0.04465318195286173]
	TIME [epoch: 6.31 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049309689310957694		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.049309689310957694 | validation: 0.03491130146656041]
	TIME [epoch: 6.33 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04810578605541008		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.04810578605541008 | validation: 0.04242140475905591]
	TIME [epoch: 6.36 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04336451612987594		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.04336451612987594 | validation: 0.04056624941633431]
	TIME [epoch: 6.32 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04486936951051773		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.04486936951051773 | validation: 0.030102893387192707]
	TIME [epoch: 6.32 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053664415368492265		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.053664415368492265 | validation: 0.032961942285617656]
	TIME [epoch: 6.31 sec]
Finished training in 12861.692 seconds.
