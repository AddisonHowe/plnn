Args:
Namespace(name='model_phi1_1a_v_mmd4', outdir='out/model_training/model_phi1_1a_v_mmd4', training_data='data/training_data/data_phi1_1a/training', validation_data='data/training_data/data_phi1_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.1, weight_decay=0.9, clip=1.0, lr_schedule='warmup_cosine_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2102537857

Training model...

Saving initial model state to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.948327455320715		[learning rate: 0.01015]
	Learning Rate: 0.01015
	LOSS [training: 5.948327455320715 | validation: 5.177693096590353]
	TIME [epoch: 105 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.497089304526755		[learning rate: 0.01035]
	Learning Rate: 0.01035
	LOSS [training: 5.497089304526755 | validation: 4.6951579050690455]
	TIME [epoch: 8.38 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.102703344505432		[learning rate: 0.01055]
	Learning Rate: 0.01055
	LOSS [training: 5.102703344505432 | validation: 4.299276640290447]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.896254910441995		[learning rate: 0.01075]
	Learning Rate: 0.01075
	LOSS [training: 4.896254910441995 | validation: 4.383956564853931]
	TIME [epoch: 8.32 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.648441602971093		[learning rate: 0.01095]
	Learning Rate: 0.01095
	LOSS [training: 4.648441602971093 | validation: 3.984883012238367]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.540115585463617		[learning rate: 0.01115]
	Learning Rate: 0.01115
	LOSS [training: 4.540115585463617 | validation: 4.42821218321362]
	TIME [epoch: 8.37 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.468103509466141		[learning rate: 0.01135]
	Learning Rate: 0.01135
	LOSS [training: 4.468103509466141 | validation: 3.46294380667989]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.147804776648712		[learning rate: 0.01155]
	Learning Rate: 0.01155
	LOSS [training: 4.147804776648712 | validation: 3.255190972723401]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.279233592425664		[learning rate: 0.01175]
	Learning Rate: 0.01175
	LOSS [training: 4.279233592425664 | validation: 3.0971407048346005]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.840374304768321		[learning rate: 0.01195]
	Learning Rate: 0.01195
	LOSS [training: 3.840374304768321 | validation: 3.5265933291067246]
	TIME [epoch: 8.32 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.028870562109013		[learning rate: 0.01215]
	Learning Rate: 0.01215
	LOSS [training: 4.028870562109013 | validation: 3.381312455997654]
	TIME [epoch: 8.36 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7825567948945142		[learning rate: 0.01235]
	Learning Rate: 0.01235
	LOSS [training: 3.7825567948945142 | validation: 3.93484170174567]
	TIME [epoch: 8.34 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.900662697448824		[learning rate: 0.01255]
	Learning Rate: 0.01255
	LOSS [training: 3.900662697448824 | validation: 2.809880122669468]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6682760656798634		[learning rate: 0.01275]
	Learning Rate: 0.01275
	LOSS [training: 3.6682760656798634 | validation: 2.841634252886033]
	TIME [epoch: 8.33 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.749913071637831		[learning rate: 0.01295]
	Learning Rate: 0.01295
	LOSS [training: 3.749913071637831 | validation: 2.9965542454736864]
	TIME [epoch: 8.32 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.621052185128949		[learning rate: 0.01315]
	Learning Rate: 0.01315
	LOSS [training: 3.621052185128949 | validation: 2.8151059625571166]
	TIME [epoch: 8.35 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5491952830219646		[learning rate: 0.01335]
	Learning Rate: 0.01335
	LOSS [training: 3.5491952830219646 | validation: 2.822050378667567]
	TIME [epoch: 8.36 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.380590589561568		[learning rate: 0.01355]
	Learning Rate: 0.01355
	LOSS [training: 3.380590589561568 | validation: 2.693105377618922]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2569970837325437		[learning rate: 0.01375]
	Learning Rate: 0.01375
	LOSS [training: 3.2569970837325437 | validation: 2.8380646703705708]
	TIME [epoch: 8.34 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2269892327749927		[learning rate: 0.01395]
	Learning Rate: 0.01395
	LOSS [training: 3.2269892327749927 | validation: 2.76580563869342]
	TIME [epoch: 8.33 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.193232645815467		[learning rate: 0.01415]
	Learning Rate: 0.01415
	LOSS [training: 3.193232645815467 | validation: 2.569542593787896]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0200920829321802		[learning rate: 0.01435]
	Learning Rate: 0.01435
	LOSS [training: 3.0200920829321802 | validation: 2.1549913821506896]
	TIME [epoch: 8.37 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8984329006800893		[learning rate: 0.01455]
	Learning Rate: 0.01455
	LOSS [training: 2.8984329006800893 | validation: 2.248283932898986]
	TIME [epoch: 8.34 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.95507820111583		[learning rate: 0.01475]
	Learning Rate: 0.01475
	LOSS [training: 2.95507820111583 | validation: 2.244939183862261]
	TIME [epoch: 8.33 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.81677610725724		[learning rate: 0.01495]
	Learning Rate: 0.01495
	LOSS [training: 2.81677610725724 | validation: 1.9240960710128214]
	TIME [epoch: 8.62 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6860134111851135		[learning rate: 0.01515]
	Learning Rate: 0.01515
	LOSS [training: 2.6860134111851135 | validation: 2.2118152514362492]
	TIME [epoch: 8.34 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.678460486802887		[learning rate: 0.01535]
	Learning Rate: 0.01535
	LOSS [training: 2.678460486802887 | validation: 1.9080568524028862]
	TIME [epoch: 8.38 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5614027323876463		[learning rate: 0.01555]
	Learning Rate: 0.01555
	LOSS [training: 2.5614027323876463 | validation: 1.7301321649385504]
	TIME [epoch: 8.35 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4726146740160133		[learning rate: 0.01575]
	Learning Rate: 0.01575
	LOSS [training: 2.4726146740160133 | validation: 1.6358792584513357]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4703358961338067		[learning rate: 0.01595]
	Learning Rate: 0.01595
	LOSS [training: 2.4703358961338067 | validation: 1.6454985881286244]
	TIME [epoch: 8.33 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3770111747207054		[learning rate: 0.01615]
	Learning Rate: 0.01615
	LOSS [training: 2.3770111747207054 | validation: 1.6112713726574444]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1846848970278936		[learning rate: 0.01635]
	Learning Rate: 0.01635
	LOSS [training: 2.1846848970278936 | validation: 1.4575216995948435]
	TIME [epoch: 8.35 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1670047937390766		[learning rate: 0.01655]
	Learning Rate: 0.01655
	LOSS [training: 2.1670047937390766 | validation: 2.1210477094590834]
	TIME [epoch: 8.36 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2242289770151746		[learning rate: 0.01675]
	Learning Rate: 0.01675
	LOSS [training: 2.2242289770151746 | validation: 1.405746182658155]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.006320240960538		[learning rate: 0.01695]
	Learning Rate: 0.01695
	LOSS [training: 2.006320240960538 | validation: 1.7877440868811518]
	TIME [epoch: 8.34 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.932273713484459		[learning rate: 0.01715]
	Learning Rate: 0.01715
	LOSS [training: 1.932273713484459 | validation: 1.8230270334675036]
	TIME [epoch: 8.33 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9289401781466902		[learning rate: 0.01735]
	Learning Rate: 0.01735
	LOSS [training: 1.9289401781466902 | validation: 1.4526608405614923]
	TIME [epoch: 8.34 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8262244312613878		[learning rate: 0.01755]
	Learning Rate: 0.01755
	LOSS [training: 1.8262244312613878 | validation: 1.537995632059927]
	TIME [epoch: 8.38 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7920872895164597		[learning rate: 0.01775]
	Learning Rate: 0.01775
	LOSS [training: 1.7920872895164597 | validation: 1.579547752841254]
	TIME [epoch: 8.33 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.839996880122885		[learning rate: 0.01795]
	Learning Rate: 0.01795
	LOSS [training: 1.839996880122885 | validation: 1.422439184809305]
	TIME [epoch: 8.34 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7203648093938604		[learning rate: 0.01815]
	Learning Rate: 0.01815
	LOSS [training: 1.7203648093938604 | validation: 1.3016115059172284]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.015538236567238		[learning rate: 0.01835]
	Learning Rate: 0.01835
	LOSS [training: 2.015538236567238 | validation: 4.416534614413375]
	TIME [epoch: 8.35 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0933337944254315		[learning rate: 0.01855]
	Learning Rate: 0.01855
	LOSS [training: 4.0933337944254315 | validation: 2.9991960460779743]
	TIME [epoch: 8.37 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.214115623587263		[learning rate: 0.01875]
	Learning Rate: 0.01875
	LOSS [training: 3.214115623587263 | validation: 2.027373562198735]
	TIME [epoch: 8.36 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9579459920126583		[learning rate: 0.01895]
	Learning Rate: 0.01895
	LOSS [training: 2.9579459920126583 | validation: 2.054134467008009]
	TIME [epoch: 8.33 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.384225395942645		[learning rate: 0.01915]
	Learning Rate: 0.01915
	LOSS [training: 2.384225395942645 | validation: 1.7842926137044866]
	TIME [epoch: 8.35 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1645570511795293		[learning rate: 0.01935]
	Learning Rate: 0.01935
	LOSS [training: 2.1645570511795293 | validation: 1.7131360926656618]
	TIME [epoch: 8.33 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0752638580803353		[learning rate: 0.01955]
	Learning Rate: 0.01955
	LOSS [training: 2.0752638580803353 | validation: 1.708432090936097]
	TIME [epoch: 8.35 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.024631506580647		[learning rate: 0.01975]
	Learning Rate: 0.01975
	LOSS [training: 2.024631506580647 | validation: 1.6497914178161852]
	TIME [epoch: 8.38 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9727513278542927		[learning rate: 0.01995]
	Learning Rate: 0.01995
	LOSS [training: 1.9727513278542927 | validation: 1.6015613328336036]
	TIME [epoch: 8.35 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8471531902290041		[learning rate: 0.02]
	Learning Rate: 0.02
	LOSS [training: 1.8471531902290041 | validation: 1.579027760344606]
	TIME [epoch: 8.34 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8214451337091688		[learning rate: 0.02]
	Learning Rate: 0.02
	LOSS [training: 1.8214451337091688 | validation: 1.4796201028475453]
	TIME [epoch: 8.34 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6332201431129605		[learning rate: 0.02]
	Learning Rate: 0.0199999
	LOSS [training: 1.6332201431129605 | validation: 1.456758431557966]
	TIME [epoch: 8.35 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8468259323937908		[learning rate: 0.02]
	Learning Rate: 0.0199998
	LOSS [training: 1.8468259323937908 | validation: 1.5030048924569466]
	TIME [epoch: 8.35 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.145587855246006		[learning rate: 0.02]
	Learning Rate: 0.0199997
	LOSS [training: 2.145587855246006 | validation: 2.1310881836741915]
	TIME [epoch: 8.37 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7757120186721642		[learning rate: 0.02]
	Learning Rate: 0.0199995
	LOSS [training: 1.7757120186721642 | validation: 1.6027180789518778]
	TIME [epoch: 8.34 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5882891974419202		[learning rate: 0.019999]
	Learning Rate: 0.0199994
	LOSS [training: 1.5882891974419202 | validation: 1.546945954734725]
	TIME [epoch: 8.35 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1963129403644155		[learning rate: 0.019999]
	Learning Rate: 0.0199992
	LOSS [training: 2.1963129403644155 | validation: 2.586130259049705]
	TIME [epoch: 8.34 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0524258797606483		[learning rate: 0.019999]
	Learning Rate: 0.019999
	LOSS [training: 2.0524258797606483 | validation: 2.422576706343816]
	TIME [epoch: 8.34 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9944097380841104		[learning rate: 0.019999]
	Learning Rate: 0.0199987
	LOSS [training: 1.9944097380841104 | validation: 2.333178173928453]
	TIME [epoch: 8.39 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9610199684435436		[learning rate: 0.019998]
	Learning Rate: 0.0199984
	LOSS [training: 1.9610199684435436 | validation: 1.9728933471246886]
	TIME [epoch: 8.34 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5651159582623415		[learning rate: 0.019998]
	Learning Rate: 0.0199981
	LOSS [training: 1.5651159582623415 | validation: 1.8916867336844612]
	TIME [epoch: 8.35 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6335193928297864		[learning rate: 0.019998]
	Learning Rate: 0.0199978
	LOSS [training: 1.6335193928297864 | validation: 1.699045305083982]
	TIME [epoch: 8.34 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.511865381971472		[learning rate: 0.019997]
	Learning Rate: 0.0199974
	LOSS [training: 1.511865381971472 | validation: 1.679133520398495]
	TIME [epoch: 8.33 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4619862595216098		[learning rate: 0.019997]
	Learning Rate: 0.019997
	LOSS [training: 1.4619862595216098 | validation: 1.5676822887372903]
	TIME [epoch: 8.36 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.450520856918343		[learning rate: 0.019997]
	Learning Rate: 0.0199966
	LOSS [training: 1.450520856918343 | validation: 1.4847415542580797]
	TIME [epoch: 8.37 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.488166345954029		[learning rate: 0.019996]
	Learning Rate: 0.0199962
	LOSS [training: 1.488166345954029 | validation: 1.6894202223366293]
	TIME [epoch: 8.33 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5700965751794247		[learning rate: 0.019996]
	Learning Rate: 0.0199957
	LOSS [training: 1.5700965751794247 | validation: 1.470741813149687]
	TIME [epoch: 8.33 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2773542163838396		[learning rate: 0.019995]
	Learning Rate: 0.0199952
	LOSS [training: 1.2773542163838396 | validation: 1.2905604281268779]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2641603394433862		[learning rate: 0.019995]
	Learning Rate: 0.0199947
	LOSS [training: 1.2641603394433862 | validation: 1.6505866321113634]
	TIME [epoch: 8.34 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6540722716101353		[learning rate: 0.019994]
	Learning Rate: 0.0199941
	LOSS [training: 1.6540722716101353 | validation: 1.4877130350661238]
	TIME [epoch: 8.38 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4528530060240161		[learning rate: 0.019994]
	Learning Rate: 0.0199935
	LOSS [training: 1.4528530060240161 | validation: 1.3697173685398538]
	TIME [epoch: 8.34 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.354097468996272		[learning rate: 0.019993]
	Learning Rate: 0.0199929
	LOSS [training: 1.354097468996272 | validation: 1.24166298675178]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3107636047602786		[learning rate: 0.019992]
	Learning Rate: 0.0199923
	LOSS [training: 1.3107636047602786 | validation: 1.2603949787465796]
	TIME [epoch: 8.33 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3147536136673694		[learning rate: 0.019992]
	Learning Rate: 0.0199916
	LOSS [training: 1.3147536136673694 | validation: 1.9402048929724545]
	TIME [epoch: 8.33 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.648906869845306		[learning rate: 0.019991]
	Learning Rate: 0.0199909
	LOSS [training: 1.648906869845306 | validation: 1.1874814979767192]
	TIME [epoch: 8.36 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2577386625632012		[learning rate: 0.01999]
	Learning Rate: 0.0199902
	LOSS [training: 1.2577386625632012 | validation: 1.1421403623069097]
	TIME [epoch: 8.35 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1822717992519702		[learning rate: 0.019989]
	Learning Rate: 0.0199895
	LOSS [training: 1.1822717992519702 | validation: 2.4679185537919874]
	TIME [epoch: 8.34 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.185565812649475		[learning rate: 0.019989]
	Learning Rate: 0.0199887
	LOSS [training: 3.185565812649475 | validation: 4.0652167666217425]
	TIME [epoch: 8.33 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.898909365216456		[learning rate: 0.019988]
	Learning Rate: 0.0199879
	LOSS [training: 3.898909365216456 | validation: 3.789130988616538]
	TIME [epoch: 8.33 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.539129532903605		[learning rate: 0.019987]
	Learning Rate: 0.0199871
	LOSS [training: 3.539129532903605 | validation: 3.028491741876101]
	TIME [epoch: 8.34 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7364074886544634		[learning rate: 0.019986]
	Learning Rate: 0.0199862
	LOSS [training: 2.7364074886544634 | validation: 2.5813698768494335]
	TIME [epoch: 8.38 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0717331489818225		[learning rate: 0.019985]
	Learning Rate: 0.0199853
	LOSS [training: 2.0717331489818225 | validation: 1.8658477128683097]
	TIME [epoch: 8.33 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6397924489942166		[learning rate: 0.019984]
	Learning Rate: 0.0199844
	LOSS [training: 1.6397924489942166 | validation: 1.8565197730941378]
	TIME [epoch: 8.33 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.665889328184935		[learning rate: 0.019984]
	Learning Rate: 0.0199835
	LOSS [training: 1.665889328184935 | validation: 1.8006850050844985]
	TIME [epoch: 8.33 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4715717253007154		[learning rate: 0.019983]
	Learning Rate: 0.0199825
	LOSS [training: 1.4715717253007154 | validation: 1.4586308054175627]
	TIME [epoch: 8.33 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3237726536021934		[learning rate: 0.019982]
	Learning Rate: 0.0199816
	LOSS [training: 1.3237726536021934 | validation: 1.3865639531418812]
	TIME [epoch: 8.37 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3704685776255736		[learning rate: 0.019981]
	Learning Rate: 0.0199805
	LOSS [training: 1.3704685776255736 | validation: 2.009150472959276]
	TIME [epoch: 8.34 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.557090335987432		[learning rate: 0.019979]
	Learning Rate: 0.0199795
	LOSS [training: 1.557090335987432 | validation: 1.7367371099771958]
	TIME [epoch: 8.32 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.354825562712254		[learning rate: 0.019978]
	Learning Rate: 0.0199784
	LOSS [training: 1.354825562712254 | validation: 1.4221665851153602]
	TIME [epoch: 8.32 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3271968184553935		[learning rate: 0.019977]
	Learning Rate: 0.0199773
	LOSS [training: 1.3271968184553935 | validation: 1.363217865386775]
	TIME [epoch: 8.33 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1465475730576413		[learning rate: 0.019976]
	Learning Rate: 0.0199762
	LOSS [training: 1.1465475730576413 | validation: 1.708129788742546]
	TIME [epoch: 8.32 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2859588347767241		[learning rate: 0.019975]
	Learning Rate: 0.019975
	LOSS [training: 1.2859588347767241 | validation: 1.5206178006595348]
	TIME [epoch: 8.37 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.133995290080046		[learning rate: 0.019974]
	Learning Rate: 0.0199739
	LOSS [training: 3.133995290080046 | validation: 5.051442982885023]
	TIME [epoch: 8.32 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9754921795845948		[learning rate: 0.019973]
	Learning Rate: 0.0199727
	LOSS [training: 3.9754921795845948 | validation: 2.0777976590461225]
	TIME [epoch: 8.32 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4983697402238922		[learning rate: 0.019971]
	Learning Rate: 0.0199714
	LOSS [training: 2.4983697402238922 | validation: 1.8247968186567447]
	TIME [epoch: 8.33 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.162953085048312		[learning rate: 0.01997]
	Learning Rate: 0.0199702
	LOSS [training: 2.162953085048312 | validation: 1.6613305057861218]
	TIME [epoch: 8.33 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.020492875320621		[learning rate: 0.019969]
	Learning Rate: 0.0199689
	LOSS [training: 2.020492875320621 | validation: 1.5695088580412135]
	TIME [epoch: 8.35 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9838669125148347		[learning rate: 0.019968]
	Learning Rate: 0.0199675
	LOSS [training: 1.9838669125148347 | validation: 1.5593207603495705]
	TIME [epoch: 8.36 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9568521682175108		[learning rate: 0.019966]
	Learning Rate: 0.0199662
	LOSS [training: 1.9568521682175108 | validation: 1.5548603544276556]
	TIME [epoch: 8.33 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.913931307505178		[learning rate: 0.019965]
	Learning Rate: 0.0199648
	LOSS [training: 1.913931307505178 | validation: 1.5253736811989285]
	TIME [epoch: 8.33 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8628902299954402		[learning rate: 0.019963]
	Learning Rate: 0.0199634
	LOSS [training: 1.8628902299954402 | validation: 1.5027760707423432]
	TIME [epoch: 8.33 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.673830134122001		[learning rate: 0.019962]
	Learning Rate: 0.019962
	LOSS [training: 1.673830134122001 | validation: 1.5171593814293007]
	TIME [epoch: 8.33 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.943983800348883		[learning rate: 0.019961]
	Learning Rate: 0.0199606
	LOSS [training: 1.943983800348883 | validation: 2.2089251744664518]
	TIME [epoch: 8.37 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6749855015003443		[learning rate: 0.019959]
	Learning Rate: 0.0199591
	LOSS [training: 2.6749855015003443 | validation: 5.356172447739198]
	TIME [epoch: 8.33 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.43881776771345		[learning rate: 0.019958]
	Learning Rate: 0.0199576
	LOSS [training: 5.43881776771345 | validation: 4.03884002696517]
	TIME [epoch: 8.33 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9620842408399106		[learning rate: 0.019956]
	Learning Rate: 0.019956
	LOSS [training: 2.9620842408399106 | validation: 1.953928710854753]
	TIME [epoch: 8.33 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6871947778485923		[learning rate: 0.019954]
	Learning Rate: 0.0199545
	LOSS [training: 1.6871947778485923 | validation: 1.4953074274771787]
	TIME [epoch: 8.32 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4582625023932736		[learning rate: 0.019953]
	Learning Rate: 0.0199529
	LOSS [training: 1.4582625023932736 | validation: 1.663917183402303]
	TIME [epoch: 8.35 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4844722976672073		[learning rate: 0.019951]
	Learning Rate: 0.0199513
	LOSS [training: 1.4844722976672073 | validation: 1.340686557096579]
	TIME [epoch: 8.36 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2917460262006601		[learning rate: 0.01995]
	Learning Rate: 0.0199496
	LOSS [training: 1.2917460262006601 | validation: 1.4536231602886678]
	TIME [epoch: 8.32 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2831782470190594		[learning rate: 0.019948]
	Learning Rate: 0.0199479
	LOSS [training: 1.2831782470190594 | validation: 1.2391095860519508]
	TIME [epoch: 8.32 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.216869252203335		[learning rate: 0.019946]
	Learning Rate: 0.0199462
	LOSS [training: 3.216869252203335 | validation: 4.461366541457855]
	TIME [epoch: 8.32 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.344408643618774		[learning rate: 0.019945]
	Learning Rate: 0.0199445
	LOSS [training: 5.344408643618774 | validation: 4.742674025170674]
	TIME [epoch: 8.32 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.244054769933697		[learning rate: 0.019943]
	Learning Rate: 0.0199428
	LOSS [training: 4.244054769933697 | validation: 2.594298227939265]
	TIME [epoch: 8.37 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.912813236185742		[learning rate: 0.019941]
	Learning Rate: 0.019941
	LOSS [training: 2.912813236185742 | validation: 2.504199047335816]
	TIME [epoch: 8.34 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.583067584109977		[learning rate: 0.019939]
	Learning Rate: 0.0199392
	LOSS [training: 2.583067584109977 | validation: 2.1090839082630914]
	TIME [epoch: 8.33 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.343650818959225		[learning rate: 0.019937]
	Learning Rate: 0.0199374
	LOSS [training: 2.343650818959225 | validation: 1.8424356326724545]
	TIME [epoch: 8.33 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.090323493415207		[learning rate: 0.019935]
	Learning Rate: 0.0199355
	LOSS [training: 2.090323493415207 | validation: 1.772986342358756]
	TIME [epoch: 8.33 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.935359237503534		[learning rate: 0.019934]
	Learning Rate: 0.0199336
	LOSS [training: 1.935359237503534 | validation: 1.772646184953782]
	TIME [epoch: 8.35 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8752932895953784		[learning rate: 0.019932]
	Learning Rate: 0.0199317
	LOSS [training: 1.8752932895953784 | validation: 1.740456425669529]
	TIME [epoch: 8.35 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8338644958002157		[learning rate: 0.01993]
	Learning Rate: 0.0199297
	LOSS [training: 1.8338644958002157 | validation: 1.7439438692125235]
	TIME [epoch: 8.32 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7770306400759033		[learning rate: 0.019928]
	Learning Rate: 0.0199278
	LOSS [training: 1.7770306400759033 | validation: 1.6505463412638148]
	TIME [epoch: 8.33 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6517493106029202		[learning rate: 0.019926]
	Learning Rate: 0.0199258
	LOSS [training: 1.6517493106029202 | validation: 1.5401715401621499]
	TIME [epoch: 8.33 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5649070277334263		[learning rate: 0.019924]
	Learning Rate: 0.0199238
	LOSS [training: 1.5649070277334263 | validation: 1.5121467218891835]
	TIME [epoch: 8.32 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4749783382670978		[learning rate: 0.019922]
	Learning Rate: 0.0199217
	LOSS [training: 1.4749783382670978 | validation: 1.3883585449929092]
	TIME [epoch: 8.37 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3562580738837346		[learning rate: 0.01992]
	Learning Rate: 0.0199196
	LOSS [training: 1.3562580738837346 | validation: 1.3733664763292985]
	TIME [epoch: 8.33 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3504612132121592		[learning rate: 0.019918]
	Learning Rate: 0.0199175
	LOSS [training: 1.3504612132121592 | validation: 1.3874475407593208]
	TIME [epoch: 8.32 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2739647768229851		[learning rate: 0.019915]
	Learning Rate: 0.0199154
	LOSS [training: 1.2739647768229851 | validation: 1.3547411342364817]
	TIME [epoch: 8.33 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2231671107878113		[learning rate: 0.019913]
	Learning Rate: 0.0199132
	LOSS [training: 1.2231671107878113 | validation: 1.4287416839120044]
	TIME [epoch: 8.32 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.27445823584803		[learning rate: 0.019911]
	Learning Rate: 0.019911
	LOSS [training: 1.27445823584803 | validation: 1.3673611932915255]
	TIME [epoch: 8.34 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2129551519928514		[learning rate: 0.019909]
	Learning Rate: 0.0199088
	LOSS [training: 1.2129551519928514 | validation: 1.1971008806549306]
	TIME [epoch: 8.37 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.084990992723398		[learning rate: 0.019907]
	Learning Rate: 0.0199066
	LOSS [training: 1.084990992723398 | validation: 1.076053991076476]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_133.pth
	Model improved!!!
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0086595407743144		[learning rate: 0.019904]
	Learning Rate: 0.0199043
	LOSS [training: 1.0086595407743144 | validation: 1.2566125151024998]
	TIME [epoch: 8.34 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1201629481988853		[learning rate: 0.019902]
	Learning Rate: 0.019902
	LOSS [training: 1.1201629481988853 | validation: 1.1766810767603149]
	TIME [epoch: 8.33 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.005721888479549		[learning rate: 0.0199]
	Learning Rate: 0.0198997
	LOSS [training: 1.005721888479549 | validation: 1.0744884912899875]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_136.pth
	Model improved!!!
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9781949468812109		[learning rate: 0.019897]
	Learning Rate: 0.0198974
	LOSS [training: 0.9781949468812109 | validation: 1.4228570839074823]
	TIME [epoch: 8.38 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9892229660681602		[learning rate: 0.019895]
	Learning Rate: 0.019895
	LOSS [training: 0.9892229660681602 | validation: 1.049644746585906]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_138.pth
	Model improved!!!
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8897997644345502		[learning rate: 0.019893]
	Learning Rate: 0.0198926
	LOSS [training: 0.8897997644345502 | validation: 0.9258810231347177]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_139.pth
	Model improved!!!
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9123489418779467		[learning rate: 0.01989]
	Learning Rate: 0.0198901
	LOSS [training: 0.9123489418779467 | validation: 0.831643819946842]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_140.pth
	Model improved!!!
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7877882240264379		[learning rate: 0.019888]
	Learning Rate: 0.0198877
	LOSS [training: 0.7877882240264379 | validation: 0.7697612087222467]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8226984253863199		[learning rate: 0.019885]
	Learning Rate: 0.0198852
	LOSS [training: 0.8226984253863199 | validation: 0.7463051778471774]
	TIME [epoch: 8.36 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_142.pth
	Model improved!!!
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.766618027273165		[learning rate: 0.019883]
	Learning Rate: 0.0198827
	LOSS [training: 0.766618027273165 | validation: 0.829882917506314]
	TIME [epoch: 8.35 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7774232503024122		[learning rate: 0.01988]
	Learning Rate: 0.0198802
	LOSS [training: 0.7774232503024122 | validation: 1.1625357611261729]
	TIME [epoch: 8.33 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9613546330974567		[learning rate: 0.019878]
	Learning Rate: 0.0198776
	LOSS [training: 0.9613546330974567 | validation: 0.65985269755795]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_145.pth
	Model improved!!!
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7704064111524868		[learning rate: 0.019875]
	Learning Rate: 0.019875
	LOSS [training: 0.7704064111524868 | validation: 0.7605640338242776]
	TIME [epoch: 8.33 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6863014813561308		[learning rate: 0.019872]
	Learning Rate: 0.0198724
	LOSS [training: 0.6863014813561308 | validation: 0.6801602680619865]
	TIME [epoch: 8.34 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7481173780274073		[learning rate: 0.01987]
	Learning Rate: 0.0198697
	LOSS [training: 0.7481173780274073 | validation: 0.6668259337713014]
	TIME [epoch: 8.36 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7482833193575618		[learning rate: 0.019867]
	Learning Rate: 0.0198671
	LOSS [training: 0.7482833193575618 | validation: 0.6115968590817416]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_149.pth
	Model improved!!!
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.89116349346708		[learning rate: 0.019864]
	Learning Rate: 0.0198644
	LOSS [training: 0.89116349346708 | validation: 0.6267475860277096]
	TIME [epoch: 8.33 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7020584282642605		[learning rate: 0.019862]
	Learning Rate: 0.0198616
	LOSS [training: 0.7020584282642605 | validation: 0.5359821519366712]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5804376855127443		[learning rate: 0.019859]
	Learning Rate: 0.0198589
	LOSS [training: 0.5804376855127443 | validation: 0.634074422168657]
	TIME [epoch: 8.34 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8325465421899707		[learning rate: 0.019856]
	Learning Rate: 0.0198561
	LOSS [training: 0.8325465421899707 | validation: 0.6908475345600474]
	TIME [epoch: 8.38 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7565868215651621		[learning rate: 0.019853]
	Learning Rate: 0.0198533
	LOSS [training: 0.7565868215651621 | validation: 0.559105537021382]
	TIME [epoch: 8.35 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6760770329620934		[learning rate: 0.01985]
	Learning Rate: 0.0198505
	LOSS [training: 0.6760770329620934 | validation: 0.5749716720438148]
	TIME [epoch: 8.34 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5748115630020091		[learning rate: 0.019848]
	Learning Rate: 0.0198476
	LOSS [training: 0.5748115630020091 | validation: 0.6944401990493185]
	TIME [epoch: 8.35 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5687334961025757		[learning rate: 0.019845]
	Learning Rate: 0.0198447
	LOSS [training: 0.5687334961025757 | validation: 0.7931021956014885]
	TIME [epoch: 8.35 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8782880526780847		[learning rate: 0.019842]
	Learning Rate: 0.0198418
	LOSS [training: 0.8782880526780847 | validation: 0.5588495677875515]
	TIME [epoch: 8.36 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5697532446106439		[learning rate: 0.019839]
	Learning Rate: 0.0198388
	LOSS [training: 0.5697532446106439 | validation: 0.49145886698818575]
	TIME [epoch: 8.37 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_159.pth
	Model improved!!!
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8737878820284832		[learning rate: 0.019836]
	Learning Rate: 0.0198359
	LOSS [training: 0.8737878820284832 | validation: 0.7774924016359129]
	TIME [epoch: 8.34 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6905448896029516		[learning rate: 0.019833]
	Learning Rate: 0.0198329
	LOSS [training: 0.6905448896029516 | validation: 0.48138599359196127]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_161.pth
	Model improved!!!
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.544779153689225		[learning rate: 0.01983]
	Learning Rate: 0.0198299
	LOSS [training: 0.544779153689225 | validation: 0.4223971043242582]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_162.pth
	Model improved!!!
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5174110088177178		[learning rate: 0.019827]
	Learning Rate: 0.0198268
	LOSS [training: 0.5174110088177178 | validation: 0.5162081362659656]
	TIME [epoch: 8.34 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7853694262542182		[learning rate: 0.019824]
	Learning Rate: 0.0198237
	LOSS [training: 0.7853694262542182 | validation: 0.5939904540854752]
	TIME [epoch: 8.36 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5573970728088484		[learning rate: 0.019821]
	Learning Rate: 0.0198206
	LOSS [training: 0.5573970728088484 | validation: 0.5118763902853927]
	TIME [epoch: 8.33 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4934208473954569		[learning rate: 0.019818]
	Learning Rate: 0.0198175
	LOSS [training: 0.4934208473954569 | validation: 0.5615587368656039]
	TIME [epoch: 8.33 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6570849436336959		[learning rate: 0.019814]
	Learning Rate: 0.0198143
	LOSS [training: 0.6570849436336959 | validation: 0.5887818561482169]
	TIME [epoch: 8.33 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.619248929266283		[learning rate: 0.019811]
	Learning Rate: 0.0198112
	LOSS [training: 0.619248929266283 | validation: 0.4814846670531179]
	TIME [epoch: 8.33 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5877572605319685		[learning rate: 0.019808]
	Learning Rate: 0.0198079
	LOSS [training: 0.5877572605319685 | validation: 0.442626616474062]
	TIME [epoch: 8.36 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5378241903669034		[learning rate: 0.019805]
	Learning Rate: 0.0198047
	LOSS [training: 0.5378241903669034 | validation: 0.4924310985272671]
	TIME [epoch: 8.3 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5643750598263957		[learning rate: 0.019801]
	Learning Rate: 0.0198014
	LOSS [training: 0.5643750598263957 | validation: 0.49902872992812825]
	TIME [epoch: 8.33 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5671321409930212		[learning rate: 0.019798]
	Learning Rate: 0.0197982
	LOSS [training: 0.5671321409930212 | validation: 0.4373979838946779]
	TIME [epoch: 8.33 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4582775107851884		[learning rate: 0.019795]
	Learning Rate: 0.0197948
	LOSS [training: 0.4582775107851884 | validation: 0.5771309344124703]
	TIME [epoch: 8.32 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6575454498361677		[learning rate: 0.019791]
	Learning Rate: 0.0197915
	LOSS [training: 0.6575454498361677 | validation: 0.5336624631934443]
	TIME [epoch: 8.33 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48546988223011134		[learning rate: 0.019788]
	Learning Rate: 0.0197881
	LOSS [training: 0.48546988223011134 | validation: 0.5278548711261313]
	TIME [epoch: 8.36 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4917526963698869		[learning rate: 0.019785]
	Learning Rate: 0.0197847
	LOSS [training: 0.4917526963698869 | validation: 0.4493683834997145]
	TIME [epoch: 8.33 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5392491003583976		[learning rate: 0.019781]
	Learning Rate: 0.0197813
	LOSS [training: 0.5392491003583976 | validation: 0.3757957505724449]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_177.pth
	Model improved!!!
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.494199840664046		[learning rate: 0.019778]
	Learning Rate: 0.0197778
	LOSS [training: 0.494199840664046 | validation: 0.4544260714813926]
	TIME [epoch: 8.33 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4849402327240643		[learning rate: 0.019774]
	Learning Rate: 0.0197744
	LOSS [training: 0.4849402327240643 | validation: 0.8026519887112091]
	TIME [epoch: 8.32 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5534128154282		[learning rate: 0.019771]
	Learning Rate: 0.0197709
	LOSS [training: 0.5534128154282 | validation: 0.5083986999607973]
	TIME [epoch: 8.36 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5640681088925308		[learning rate: 0.019767]
	Learning Rate: 0.0197673
	LOSS [training: 0.5640681088925308 | validation: 0.44691931899945914]
	TIME [epoch: 8.34 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5060687205477288		[learning rate: 0.019764]
	Learning Rate: 0.0197638
	LOSS [training: 0.5060687205477288 | validation: 0.7192270279458475]
	TIME [epoch: 8.33 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5774892046231399		[learning rate: 0.01976]
	Learning Rate: 0.0197602
	LOSS [training: 0.5774892046231399 | validation: 0.3519492211657011]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_183.pth
	Model improved!!!
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5323736819700271		[learning rate: 0.019757]
	Learning Rate: 0.0197566
	LOSS [training: 0.5323736819700271 | validation: 0.32335124122989106]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_184.pth
	Model improved!!!
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5748310122972805		[learning rate: 0.019753]
	Learning Rate: 0.0197529
	LOSS [training: 0.5748310122972805 | validation: 0.45430415170208777]
	TIME [epoch: 8.34 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4580670741545918		[learning rate: 0.019749]
	Learning Rate: 0.0197493
	LOSS [training: 0.4580670741545918 | validation: 0.6206602168006188]
	TIME [epoch: 8.37 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5458571322556725		[learning rate: 0.019746]
	Learning Rate: 0.0197456
	LOSS [training: 0.5458571322556725 | validation: 0.5666916514295797]
	TIME [epoch: 8.34 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46089430967111494		[learning rate: 0.019742]
	Learning Rate: 0.0197419
	LOSS [training: 0.46089430967111494 | validation: 0.35848149300193055]
	TIME [epoch: 8.32 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4323743085422046		[learning rate: 0.019738]
	Learning Rate: 0.0197381
	LOSS [training: 0.4323743085422046 | validation: 0.287068163718961]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_189.pth
	Model improved!!!
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38751301444113095		[learning rate: 0.019734]
	Learning Rate: 0.0197343
	LOSS [training: 0.38751301444113095 | validation: 0.435901438738465]
	TIME [epoch: 8.32 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.652205847382704		[learning rate: 0.019731]
	Learning Rate: 0.0197305
	LOSS [training: 0.652205847382704 | validation: 0.6278041745922904]
	TIME [epoch: 8.36 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5578757261399495		[learning rate: 0.019727]
	Learning Rate: 0.0197267
	LOSS [training: 0.5578757261399495 | validation: 0.35074415230215344]
	TIME [epoch: 8.33 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4163068219117614		[learning rate: 0.019723]
	Learning Rate: 0.0197229
	LOSS [training: 0.4163068219117614 | validation: 0.3421642346921584]
	TIME [epoch: 8.33 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3596601166240104		[learning rate: 0.019719]
	Learning Rate: 0.019719
	LOSS [training: 0.3596601166240104 | validation: 0.41462378186969195]
	TIME [epoch: 8.33 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.571925710682534		[learning rate: 0.019715]
	Learning Rate: 0.0197151
	LOSS [training: 0.571925710682534 | validation: 0.6041849704543232]
	TIME [epoch: 8.34 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48704588176247343		[learning rate: 0.019711]
	Learning Rate: 0.0197112
	LOSS [training: 0.48704588176247343 | validation: 0.7894115526370331]
	TIME [epoch: 8.33 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5163143284385814		[learning rate: 0.019707]
	Learning Rate: 0.0197072
	LOSS [training: 0.5163143284385814 | validation: 0.29581899512253895]
	TIME [epoch: 8.37 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3634231387298848		[learning rate: 0.019703]
	Learning Rate: 0.0197032
	LOSS [training: 0.3634231387298848 | validation: 0.28973573880352266]
	TIME [epoch: 8.33 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4565217854159736		[learning rate: 0.019699]
	Learning Rate: 0.0196992
	LOSS [training: 0.4565217854159736 | validation: 0.41349956742676375]
	TIME [epoch: 8.33 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4598910570560945		[learning rate: 0.019695]
	Learning Rate: 0.0196952
	LOSS [training: 0.4598910570560945 | validation: 0.44017005188987524]
	TIME [epoch: 8.33 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3822620222697762		[learning rate: 0.019691]
	Learning Rate: 0.0196911
	LOSS [training: 0.3822620222697762 | validation: 0.3549712641185213]
	TIME [epoch: 8.34 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44113003678142404		[learning rate: 0.019687]
	Learning Rate: 0.019687
	LOSS [training: 0.44113003678142404 | validation: 0.39632749364282793]
	TIME [epoch: 8.39 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42429277421630524		[learning rate: 0.019683]
	Learning Rate: 0.0196829
	LOSS [training: 0.42429277421630524 | validation: 0.6699741784790594]
	TIME [epoch: 8.35 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5526719022953477		[learning rate: 0.019679]
	Learning Rate: 0.0196788
	LOSS [training: 0.5526719022953477 | validation: 0.29613237637627954]
	TIME [epoch: 8.34 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3577283831173929		[learning rate: 0.019675]
	Learning Rate: 0.0196746
	LOSS [training: 0.3577283831173929 | validation: 0.39614937303636033]
	TIME [epoch: 8.34 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.386057119967397		[learning rate: 0.01967]
	Learning Rate: 0.0196704
	LOSS [training: 0.386057119967397 | validation: 0.5759535761676702]
	TIME [epoch: 8.34 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4955149204892635		[learning rate: 0.019666]
	Learning Rate: 0.0196662
	LOSS [training: 0.4955149204892635 | validation: 0.2891761424699378]
	TIME [epoch: 8.35 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4076499558230035		[learning rate: 0.019662]
	Learning Rate: 0.0196619
	LOSS [training: 0.4076499558230035 | validation: 0.5761060203553574]
	TIME [epoch: 8.38 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38393048452137746		[learning rate: 0.019658]
	Learning Rate: 0.0196576
	LOSS [training: 0.38393048452137746 | validation: 0.2467835119786978]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_209.pth
	Model improved!!!
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43124342816872585		[learning rate: 0.019653]
	Learning Rate: 0.0196533
	LOSS [training: 0.43124342816872585 | validation: 0.23156081473200946]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_210.pth
	Model improved!!!
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7605979788678059		[learning rate: 0.019649]
	Learning Rate: 0.019649
	LOSS [training: 0.7605979788678059 | validation: 0.23978350454487596]
	TIME [epoch: 8.33 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.382927953503359		[learning rate: 0.019645]
	Learning Rate: 0.0196447
	LOSS [training: 0.382927953503359 | validation: 0.22458621991640842]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_212.pth
	Model improved!!!
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31764085278768284		[learning rate: 0.01964]
	Learning Rate: 0.0196403
	LOSS [training: 0.31764085278768284 | validation: 0.5457720086256053]
	TIME [epoch: 8.37 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4151391570011612		[learning rate: 0.019636]
	Learning Rate: 0.0196359
	LOSS [training: 0.4151391570011612 | validation: 0.2660995194583242]
	TIME [epoch: 8.34 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3646055121934051		[learning rate: 0.019631]
	Learning Rate: 0.0196314
	LOSS [training: 0.3646055121934051 | validation: 0.532958229064904]
	TIME [epoch: 8.32 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3665701789895103		[learning rate: 0.019627]
	Learning Rate: 0.019627
	LOSS [training: 0.3665701789895103 | validation: 0.28379306378544344]
	TIME [epoch: 8.33 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4335433287545582		[learning rate: 0.019622]
	Learning Rate: 0.0196225
	LOSS [training: 0.4335433287545582 | validation: 0.2510388112964507]
	TIME [epoch: 8.34 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35613345066991314		[learning rate: 0.019618]
	Learning Rate: 0.019618
	LOSS [training: 0.35613345066991314 | validation: 0.3665722607344017]
	TIME [epoch: 8.35 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3372356175645716		[learning rate: 0.019613]
	Learning Rate: 0.0196134
	LOSS [training: 0.3372356175645716 | validation: 0.8189098156897807]
	TIME [epoch: 8.36 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41813926723285827		[learning rate: 0.019609]
	Learning Rate: 0.0196089
	LOSS [training: 0.41813926723285827 | validation: 0.38223963521867244]
	TIME [epoch: 8.33 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34864110221442685		[learning rate: 0.019604]
	Learning Rate: 0.0196043
	LOSS [training: 0.34864110221442685 | validation: 0.3815863941727159]
	TIME [epoch: 8.33 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33596209896106977		[learning rate: 0.0196]
	Learning Rate: 0.0195997
	LOSS [training: 0.33596209896106977 | validation: 0.3203324989568188]
	TIME [epoch: 8.33 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37925587152396345		[learning rate: 0.019595]
	Learning Rate: 0.019595
	LOSS [training: 0.37925587152396345 | validation: 0.6200242198813444]
	TIME [epoch: 8.32 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4487263045734		[learning rate: 0.01959]
	Learning Rate: 0.0195904
	LOSS [training: 0.4487263045734 | validation: 0.573331045418234]
	TIME [epoch: 8.37 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4369052275253399		[learning rate: 0.019586]
	Learning Rate: 0.0195857
	LOSS [training: 0.4369052275253399 | validation: 0.5905130392036351]
	TIME [epoch: 8.34 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4269059779692904		[learning rate: 0.019581]
	Learning Rate: 0.0195809
	LOSS [training: 0.4269059779692904 | validation: 0.34192383924481135]
	TIME [epoch: 8.33 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3981223449461704		[learning rate: 0.019576]
	Learning Rate: 0.0195762
	LOSS [training: 0.3981223449461704 | validation: 0.26561444119977173]
	TIME [epoch: 8.33 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3189222008477798		[learning rate: 0.019571]
	Learning Rate: 0.0195714
	LOSS [training: 0.3189222008477798 | validation: 0.3298728371200519]
	TIME [epoch: 8.33 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32395729522656097		[learning rate: 0.019567]
	Learning Rate: 0.0195666
	LOSS [training: 0.32395729522656097 | validation: 0.4058471968381067]
	TIME [epoch: 8.34 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39273000957922233		[learning rate: 0.019562]
	Learning Rate: 0.0195618
	LOSS [training: 0.39273000957922233 | validation: 0.24042387208703814]
	TIME [epoch: 8.38 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30919699111563326		[learning rate: 0.019557]
	Learning Rate: 0.0195569
	LOSS [training: 0.30919699111563326 | validation: 0.3554623073001413]
	TIME [epoch: 8.33 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3635054546146844		[learning rate: 0.019552]
	Learning Rate: 0.0195521
	LOSS [training: 0.3635054546146844 | validation: 0.6905055317989639]
	TIME [epoch: 8.33 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42534731706169626		[learning rate: 0.019547]
	Learning Rate: 0.0195472
	LOSS [training: 0.42534731706169626 | validation: 0.3113462561709438]
	TIME [epoch: 8.33 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28774192332938475		[learning rate: 0.019542]
	Learning Rate: 0.0195422
	LOSS [training: 0.28774192332938475 | validation: 0.4261270968576064]
	TIME [epoch: 8.34 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4046793758276105		[learning rate: 0.019537]
	Learning Rate: 0.0195373
	LOSS [training: 0.4046793758276105 | validation: 0.265205334908046]
	TIME [epoch: 8.38 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3576527466545027		[learning rate: 0.019532]
	Learning Rate: 0.0195323
	LOSS [training: 0.3576527466545027 | validation: 0.22213947716828739]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_236.pth
	Model improved!!!
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.292160306315523		[learning rate: 0.019527]
	Learning Rate: 0.0195273
	LOSS [training: 0.292160306315523 | validation: 0.2972664307397902]
	TIME [epoch: 8.33 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30350181006291516		[learning rate: 0.019522]
	Learning Rate: 0.0195222
	LOSS [training: 0.30350181006291516 | validation: 0.2166803628281363]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_238.pth
	Model improved!!!
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.410943070497886		[learning rate: 0.019517]
	Learning Rate: 0.0195172
	LOSS [training: 0.410943070497886 | validation: 0.24445104386090197]
	TIME [epoch: 8.33 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32240577125099895		[learning rate: 0.019512]
	Learning Rate: 0.0195121
	LOSS [training: 0.32240577125099895 | validation: 0.38222431083784486]
	TIME [epoch: 8.34 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29476667901041015		[learning rate: 0.019507]
	Learning Rate: 0.019507
	LOSS [training: 0.29476667901041015 | validation: 0.2362696506646319]
	TIME [epoch: 8.36 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32931897421801537		[learning rate: 0.019502]
	Learning Rate: 0.0195018
	LOSS [training: 0.32931897421801537 | validation: 0.20820683089038255]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_242.pth
	Model improved!!!
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25516059609641184		[learning rate: 0.019497]
	Learning Rate: 0.0194967
	LOSS [training: 0.25516059609641184 | validation: 0.3911941594630607]
	TIME [epoch: 8.33 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46777969818286397		[learning rate: 0.019491]
	Learning Rate: 0.0194915
	LOSS [training: 0.46777969818286397 | validation: 0.18097477190196037]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_244.pth
	Model improved!!!
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3085602968010975		[learning rate: 0.019486]
	Learning Rate: 0.0194863
	LOSS [training: 0.3085602968010975 | validation: 0.19245119664432253]
	TIME [epoch: 8.33 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3252500608097956		[learning rate: 0.019481]
	Learning Rate: 0.019481
	LOSS [training: 0.3252500608097956 | validation: 0.19296932787305415]
	TIME [epoch: 8.38 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32799992070802897		[learning rate: 0.019476]
	Learning Rate: 0.0194757
	LOSS [training: 0.32799992070802897 | validation: 0.17498886392116136]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_247.pth
	Model improved!!!
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2895794595991612		[learning rate: 0.01947]
	Learning Rate: 0.0194705
	LOSS [training: 0.2895794595991612 | validation: 0.30798431922434244]
	TIME [epoch: 8.34 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.312603875096727		[learning rate: 0.019465]
	Learning Rate: 0.0194651
	LOSS [training: 0.312603875096727 | validation: 0.1984304448463903]
	TIME [epoch: 8.33 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2864873156726546		[learning rate: 0.01946]
	Learning Rate: 0.0194598
	LOSS [training: 0.2864873156726546 | validation: 0.31536783893171144]
	TIME [epoch: 8.33 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3132638161240027		[learning rate: 0.019454]
	Learning Rate: 0.0194544
	LOSS [training: 0.3132638161240027 | validation: 0.2674949742050179]
	TIME [epoch: 8.37 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31097415700315967		[learning rate: 0.019449]
	Learning Rate: 0.019449
	LOSS [training: 0.31097415700315967 | validation: 0.30777000531781795]
	TIME [epoch: 8.34 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.363990907585376		[learning rate: 0.019444]
	Learning Rate: 0.0194436
	LOSS [training: 0.363990907585376 | validation: 0.2109925623385845]
	TIME [epoch: 8.33 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2444220001743561		[learning rate: 0.019438]
	Learning Rate: 0.0194381
	LOSS [training: 0.2444220001743561 | validation: 0.25916690058711234]
	TIME [epoch: 8.32 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2894654439774727		[learning rate: 0.019433]
	Learning Rate: 0.0194327
	LOSS [training: 0.2894654439774727 | validation: 0.343970218805845]
	TIME [epoch: 8.33 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3292376950019095		[learning rate: 0.019427]
	Learning Rate: 0.0194272
	LOSS [training: 0.3292376950019095 | validation: 0.21814431249720556]
	TIME [epoch: 8.32 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36307935694343485		[learning rate: 0.019422]
	Learning Rate: 0.0194216
	LOSS [training: 0.36307935694343485 | validation: 0.1994850758166279]
	TIME [epoch: 8.37 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28519937931376		[learning rate: 0.019416]
	Learning Rate: 0.0194161
	LOSS [training: 0.28519937931376 | validation: 0.17323050173693702]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_258.pth
	Model improved!!!
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2399501483108557		[learning rate: 0.019411]
	Learning Rate: 0.0194105
	LOSS [training: 0.2399501483108557 | validation: 0.2702742201389981]
	TIME [epoch: 8.33 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31107168339907254		[learning rate: 0.019405]
	Learning Rate: 0.0194049
	LOSS [training: 0.31107168339907254 | validation: 0.31678164202820114]
	TIME [epoch: 8.33 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.281434346256468		[learning rate: 0.019399]
	Learning Rate: 0.0193993
	LOSS [training: 0.281434346256468 | validation: 0.3872779577085784]
	TIME [epoch: 8.33 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4233724191639123		[learning rate: 0.019394]
	Learning Rate: 0.0193936
	LOSS [training: 0.4233724191639123 | validation: 0.3734139661916157]
	TIME [epoch: 8.36 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3253231740032196		[learning rate: 0.019388]
	Learning Rate: 0.0193879
	LOSS [training: 0.3253231740032196 | validation: 0.2486874707329882]
	TIME [epoch: 8.34 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22275813843892545		[learning rate: 0.019382]
	Learning Rate: 0.0193822
	LOSS [training: 0.22275813843892545 | validation: 0.21885558699707075]
	TIME [epoch: 8.32 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3623098948570185		[learning rate: 0.019376]
	Learning Rate: 0.0193765
	LOSS [training: 0.3623098948570185 | validation: 0.1442670394537548]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_265.pth
	Model improved!!!
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2379090680301579		[learning rate: 0.019371]
	Learning Rate: 0.0193707
	LOSS [training: 0.2379090680301579 | validation: 0.3744015670768923]
	TIME [epoch: 8.33 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28584834715977236		[learning rate: 0.019365]
	Learning Rate: 0.0193649
	LOSS [training: 0.28584834715977236 | validation: 0.4265208771571233]
	TIME [epoch: 8.34 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.288038763962927		[learning rate: 0.019359]
	Learning Rate: 0.0193591
	LOSS [training: 0.288038763962927 | validation: 0.3836993004694136]
	TIME [epoch: 8.37 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40372602234142196		[learning rate: 0.019353]
	Learning Rate: 0.0193533
	LOSS [training: 0.40372602234142196 | validation: 0.36890103570035115]
	TIME [epoch: 8.34 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33966935888615113		[learning rate: 0.019347]
	Learning Rate: 0.0193474
	LOSS [training: 0.33966935888615113 | validation: 0.3745595602127899]
	TIME [epoch: 8.33 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24528714997216672		[learning rate: 0.019342]
	Learning Rate: 0.0193416
	LOSS [training: 0.24528714997216672 | validation: 0.1808298606154398]
	TIME [epoch: 8.33 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20999282602422764		[learning rate: 0.019336]
	Learning Rate: 0.0193356
	LOSS [training: 0.20999282602422764 | validation: 0.2748368914575223]
	TIME [epoch: 8.32 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2519630575054256		[learning rate: 0.01933]
	Learning Rate: 0.0193297
	LOSS [training: 0.2519630575054256 | validation: 0.2776269457450664]
	TIME [epoch: 8.37 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32141314605862137		[learning rate: 0.019324]
	Learning Rate: 0.0193237
	LOSS [training: 0.32141314605862137 | validation: 0.268187616884603]
	TIME [epoch: 8.34 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3468307949020073		[learning rate: 0.019318]
	Learning Rate: 0.0193178
	LOSS [training: 0.3468307949020073 | validation: 0.19939946066065378]
	TIME [epoch: 8.32 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21827700018188634		[learning rate: 0.019312]
	Learning Rate: 0.0193117
	LOSS [training: 0.21827700018188634 | validation: 0.34677905064318604]
	TIME [epoch: 8.32 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3354740063132851		[learning rate: 0.019306]
	Learning Rate: 0.0193057
	LOSS [training: 0.3354740063132851 | validation: 0.1985239512946806]
	TIME [epoch: 8.33 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24040659833968198		[learning rate: 0.0193]
	Learning Rate: 0.0192996
	LOSS [training: 0.24040659833968198 | validation: 0.22931120156451595]
	TIME [epoch: 8.32 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2591193132121463		[learning rate: 0.019294]
	Learning Rate: 0.0192935
	LOSS [training: 0.2591193132121463 | validation: 0.30915376066082767]
	TIME [epoch: 8.37 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2534066338330241		[learning rate: 0.019287]
	Learning Rate: 0.0192874
	LOSS [training: 0.2534066338330241 | validation: 0.1837048999826728]
	TIME [epoch: 8.32 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21552919731880416		[learning rate: 0.019281]
	Learning Rate: 0.0192813
	LOSS [training: 0.21552919731880416 | validation: 0.4221074650810168]
	TIME [epoch: 8.33 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3765888147055872		[learning rate: 0.019275]
	Learning Rate: 0.0192751
	LOSS [training: 0.3765888147055872 | validation: 0.29821283495890627]
	TIME [epoch: 8.32 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4209559486094777		[learning rate: 0.019269]
	Learning Rate: 0.0192689
	LOSS [training: 0.4209559486094777 | validation: 0.22155736276402987]
	TIME [epoch: 8.33 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2396018272876046		[learning rate: 0.019263]
	Learning Rate: 0.0192627
	LOSS [training: 0.2396018272876046 | validation: 0.22452967132797436]
	TIME [epoch: 8.35 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2651709297912255		[learning rate: 0.019256]
	Learning Rate: 0.0192565
	LOSS [training: 0.2651709297912255 | validation: 0.2596723782863508]
	TIME [epoch: 8.36 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2569727478293917		[learning rate: 0.01925]
	Learning Rate: 0.0192502
	LOSS [training: 0.2569727478293917 | validation: 0.20889668283202217]
	TIME [epoch: 8.33 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26079860283145667		[learning rate: 0.019244]
	Learning Rate: 0.0192439
	LOSS [training: 0.26079860283145667 | validation: 0.19751835498692805]
	TIME [epoch: 8.33 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23845564602175734		[learning rate: 0.019238]
	Learning Rate: 0.0192376
	LOSS [training: 0.23845564602175734 | validation: 0.1721472352727465]
	TIME [epoch: 8.33 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26018106645748573		[learning rate: 0.019231]
	Learning Rate: 0.0192313
	LOSS [training: 0.26018106645748573 | validation: 0.2018462587683118]
	TIME [epoch: 8.33 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2834948377607368		[learning rate: 0.019225]
	Learning Rate: 0.0192249
	LOSS [training: 0.2834948377607368 | validation: 0.18611513882784253]
	TIME [epoch: 8.38 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1975767285469697		[learning rate: 0.019218]
	Learning Rate: 0.0192185
	LOSS [training: 0.1975767285469697 | validation: 0.34427080514171393]
	TIME [epoch: 8.33 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2825267607776546		[learning rate: 0.019212]
	Learning Rate: 0.0192121
	LOSS [training: 0.2825267607776546 | validation: 0.31170193357895515]
	TIME [epoch: 8.33 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2996744931851403		[learning rate: 0.019206]
	Learning Rate: 0.0192056
	LOSS [training: 0.2996744931851403 | validation: 0.3958585833517012]
	TIME [epoch: 8.33 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2367800672400045		[learning rate: 0.019199]
	Learning Rate: 0.0191992
	LOSS [training: 0.2367800672400045 | validation: 0.2070277208065558]
	TIME [epoch: 8.33 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24981697438281142		[learning rate: 0.019193]
	Learning Rate: 0.0191927
	LOSS [training: 0.24981697438281142 | validation: 0.1647464343460197]
	TIME [epoch: 8.35 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3482611332045565		[learning rate: 0.019186]
	Learning Rate: 0.0191861
	LOSS [training: 0.3482611332045565 | validation: 0.21066854970396978]
	TIME [epoch: 8.36 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26993936508270044		[learning rate: 0.01918]
	Learning Rate: 0.0191796
	LOSS [training: 0.26993936508270044 | validation: 0.3024479258809183]
	TIME [epoch: 8.32 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24661760947017475		[learning rate: 0.019173]
	Learning Rate: 0.019173
	LOSS [training: 0.24661760947017475 | validation: 0.18296817911938756]
	TIME [epoch: 8.34 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1983571344800683		[learning rate: 0.019166]
	Learning Rate: 0.0191664
	LOSS [training: 0.1983571344800683 | validation: 0.2412061577228322]
	TIME [epoch: 8.33 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34684216593526085		[learning rate: 0.01916]
	Learning Rate: 0.0191598
	LOSS [training: 0.34684216593526085 | validation: 0.17682246563126264]
	TIME [epoch: 8.33 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21190631840296242		[learning rate: 0.019153]
	Learning Rate: 0.0191532
	LOSS [training: 0.21190631840296242 | validation: 0.37384110700316864]
	TIME [epoch: 8.39 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25387609571981806		[learning rate: 0.019146]
	Learning Rate: 0.0191465
	LOSS [training: 0.25387609571981806 | validation: 0.20408958610181854]
	TIME [epoch: 8.33 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22974071358863454		[learning rate: 0.01914]
	Learning Rate: 0.0191398
	LOSS [training: 0.22974071358863454 | validation: 0.18775747471544346]
	TIME [epoch: 8.33 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21799960734805243		[learning rate: 0.019133]
	Learning Rate: 0.0191331
	LOSS [training: 0.21799960734805243 | validation: 0.2869895275935529]
	TIME [epoch: 8.33 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22855114141837854		[learning rate: 0.019126]
	Learning Rate: 0.0191263
	LOSS [training: 0.22855114141837854 | validation: 0.22632998878099087]
	TIME [epoch: 8.33 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16693856107104377		[learning rate: 0.01912]
	Learning Rate: 0.0191196
	LOSS [training: 0.16693856107104377 | validation: 0.20420765083694187]
	TIME [epoch: 8.34 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3297648779835709		[learning rate: 0.019113]
	Learning Rate: 0.0191128
	LOSS [training: 0.3297648779835709 | validation: 0.1783347244289111]
	TIME [epoch: 8.36 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2160236444442319		[learning rate: 0.019106]
	Learning Rate: 0.019106
	LOSS [training: 0.2160236444442319 | validation: 0.12935641129877667]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_308.pth
	Model improved!!!
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23723597097206311		[learning rate: 0.019099]
	Learning Rate: 0.0190991
	LOSS [training: 0.23723597097206311 | validation: 0.1335532640513959]
	TIME [epoch: 8.33 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19780826260644988		[learning rate: 0.019092]
	Learning Rate: 0.0190922
	LOSS [training: 0.19780826260644988 | validation: 0.26802071605853023]
	TIME [epoch: 8.33 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2734421446509444		[learning rate: 0.019085]
	Learning Rate: 0.0190853
	LOSS [training: 0.2734421446509444 | validation: 0.3907094715118841]
	TIME [epoch: 8.33 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29149186058940313		[learning rate: 0.019078]
	Learning Rate: 0.0190784
	LOSS [training: 0.29149186058940313 | validation: 0.27821887779063553]
	TIME [epoch: 8.39 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20066389695496184		[learning rate: 0.019071]
	Learning Rate: 0.0190715
	LOSS [training: 0.20066389695496184 | validation: 0.11985287213776993]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_313.pth
	Model improved!!!
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21257745251679233		[learning rate: 0.019065]
	Learning Rate: 0.0190645
	LOSS [training: 0.21257745251679233 | validation: 0.1676678277120246]
	TIME [epoch: 8.34 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2697520788495808		[learning rate: 0.019058]
	Learning Rate: 0.0190575
	LOSS [training: 0.2697520788495808 | validation: 0.22180458599227362]
	TIME [epoch: 8.33 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2863815172785253		[learning rate: 0.019051]
	Learning Rate: 0.0190505
	LOSS [training: 0.2863815172785253 | validation: 0.11102379022251399]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_316.pth
	Model improved!!!
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15948716401519086		[learning rate: 0.019043]
	Learning Rate: 0.0190435
	LOSS [training: 0.15948716401519086 | validation: 0.21169004732376892]
	TIME [epoch: 8.37 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24017772592532088		[learning rate: 0.019036]
	Learning Rate: 0.0190364
	LOSS [training: 0.24017772592532088 | validation: 0.21413331530296292]
	TIME [epoch: 8.35 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23650518742812124		[learning rate: 0.019029]
	Learning Rate: 0.0190293
	LOSS [training: 0.23650518742812124 | validation: 0.2590043106201514]
	TIME [epoch: 8.33 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24500425301678563		[learning rate: 0.019022]
	Learning Rate: 0.0190222
	LOSS [training: 0.24500425301678563 | validation: 0.2378588786966499]
	TIME [epoch: 8.33 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31315927339327815		[learning rate: 0.019015]
	Learning Rate: 0.019015
	LOSS [training: 0.31315927339327815 | validation: 0.20162010673791028]
	TIME [epoch: 8.34 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20442672710094384		[learning rate: 0.019008]
	Learning Rate: 0.0190079
	LOSS [training: 0.20442672710094384 | validation: 0.1776954665919011]
	TIME [epoch: 8.34 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23241390201898937		[learning rate: 0.019001]
	Learning Rate: 0.0190007
	LOSS [training: 0.23241390201898937 | validation: 0.16152953513457174]
	TIME [epoch: 8.39 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18675863836876877		[learning rate: 0.018993]
	Learning Rate: 0.0189935
	LOSS [training: 0.18675863836876877 | validation: 0.1639001949947615]
	TIME [epoch: 8.34 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20172411057933118		[learning rate: 0.018986]
	Learning Rate: 0.0189862
	LOSS [training: 0.20172411057933118 | validation: 0.1395976473359204]
	TIME [epoch: 8.33 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.254595280873662		[learning rate: 0.018979]
	Learning Rate: 0.018979
	LOSS [training: 0.254595280873662 | validation: 0.1376917924956289]
	TIME [epoch: 8.33 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1854849625956827		[learning rate: 0.018972]
	Learning Rate: 0.0189717
	LOSS [training: 0.1854849625956827 | validation: 0.16756896084164125]
	TIME [epoch: 8.33 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20612173855163246		[learning rate: 0.018964]
	Learning Rate: 0.0189644
	LOSS [training: 0.20612173855163246 | validation: 0.2827627288076771]
	TIME [epoch: 8.37 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19652893023491674		[learning rate: 0.018957]
	Learning Rate: 0.018957
	LOSS [training: 0.19652893023491674 | validation: 0.23387707543390174]
	TIME [epoch: 8.34 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22742027636711948		[learning rate: 0.01895]
	Learning Rate: 0.0189497
	LOSS [training: 0.22742027636711948 | validation: 0.13018822020265824]
	TIME [epoch: 8.34 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3301095376859605		[learning rate: 0.018942]
	Learning Rate: 0.0189423
	LOSS [training: 0.3301095376859605 | validation: 0.14981214293307912]
	TIME [epoch: 8.34 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24365288570700494		[learning rate: 0.018935]
	Learning Rate: 0.0189349
	LOSS [training: 0.24365288570700494 | validation: 0.1965760133678766]
	TIME [epoch: 8.33 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38700745760824706		[learning rate: 0.018927]
	Learning Rate: 0.0189274
	LOSS [training: 0.38700745760824706 | validation: 0.5306784339438648]
	TIME [epoch: 8.33 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2607613718786998		[learning rate: 0.01892]
	Learning Rate: 0.01892
	LOSS [training: 0.2607613718786998 | validation: 0.12577985033171207]
	TIME [epoch: 8.39 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14846353288357433		[learning rate: 0.018912]
	Learning Rate: 0.0189125
	LOSS [training: 0.14846353288357433 | validation: 0.09944302069961548]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_335.pth
	Model improved!!!
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1579516188897787		[learning rate: 0.018905]
	Learning Rate: 0.018905
	LOSS [training: 0.1579516188897787 | validation: 0.19127237134571978]
	TIME [epoch: 8.32 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16764837552853146		[learning rate: 0.018897]
	Learning Rate: 0.0188974
	LOSS [training: 0.16764837552853146 | validation: 0.1925221826386446]
	TIME [epoch: 8.34 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21042464082853984		[learning rate: 0.01889]
	Learning Rate: 0.0188899
	LOSS [training: 0.21042464082853984 | validation: 0.17192830424740274]
	TIME [epoch: 8.34 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1989817767028007		[learning rate: 0.018882]
	Learning Rate: 0.0188823
	LOSS [training: 0.1989817767028007 | validation: 0.17033436413846523]
	TIME [epoch: 8.38 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25467774324605047		[learning rate: 0.018875]
	Learning Rate: 0.0188747
	LOSS [training: 0.25467774324605047 | validation: 0.21129884228574142]
	TIME [epoch: 8.35 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2537728863369048		[learning rate: 0.018867]
	Learning Rate: 0.0188671
	LOSS [training: 0.2537728863369048 | validation: 0.13513281488661968]
	TIME [epoch: 8.34 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15325783389626524		[learning rate: 0.018859]
	Learning Rate: 0.0188594
	LOSS [training: 0.15325783389626524 | validation: 0.16995311562678894]
	TIME [epoch: 8.34 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1727690031711795		[learning rate: 0.018852]
	Learning Rate: 0.0188517
	LOSS [training: 0.1727690031711795 | validation: 0.280408823762547]
	TIME [epoch: 8.34 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2534976633621274		[learning rate: 0.018844]
	Learning Rate: 0.018844
	LOSS [training: 0.2534976633621274 | validation: 0.23726929480809056]
	TIME [epoch: 8.34 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2648255097948461		[learning rate: 0.018836]
	Learning Rate: 0.0188363
	LOSS [training: 0.2648255097948461 | validation: 0.11558436897912819]
	TIME [epoch: 8.38 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10992998099907808		[learning rate: 0.018829]
	Learning Rate: 0.0188286
	LOSS [training: 0.10992998099907808 | validation: 0.12053254139080821]
	TIME [epoch: 8.35 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24450205909740153		[learning rate: 0.018821]
	Learning Rate: 0.0188208
	LOSS [training: 0.24450205909740153 | validation: 0.17677583610313835]
	TIME [epoch: 8.34 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18260594315844675		[learning rate: 0.018813]
	Learning Rate: 0.018813
	LOSS [training: 0.18260594315844675 | validation: 0.18641528305781688]
	TIME [epoch: 8.34 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20283000110260924		[learning rate: 0.018805]
	Learning Rate: 0.0188052
	LOSS [training: 0.20283000110260924 | validation: 0.24055796491923748]
	TIME [epoch: 8.34 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24241188356892573		[learning rate: 0.018797]
	Learning Rate: 0.0187973
	LOSS [training: 0.24241188356892573 | validation: 0.25552529431417537]
	TIME [epoch: 8.38 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20846119250475798		[learning rate: 0.018789]
	Learning Rate: 0.0187894
	LOSS [training: 0.20846119250475798 | validation: 0.18386709759312497]
	TIME [epoch: 8.35 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16922646268054278		[learning rate: 0.018782]
	Learning Rate: 0.0187815
	LOSS [training: 0.16922646268054278 | validation: 0.12718193686777454]
	TIME [epoch: 8.35 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1675326072327545		[learning rate: 0.018774]
	Learning Rate: 0.0187736
	LOSS [training: 0.1675326072327545 | validation: 0.2633485031791649]
	TIME [epoch: 8.35 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31184059644095613		[learning rate: 0.018766]
	Learning Rate: 0.0187657
	LOSS [training: 0.31184059644095613 | validation: 0.14435105398839027]
	TIME [epoch: 8.34 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1314161767710413		[learning rate: 0.018758]
	Learning Rate: 0.0187577
	LOSS [training: 0.1314161767710413 | validation: 0.1070515332364586]
	TIME [epoch: 8.34 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18031237514029125		[learning rate: 0.01875]
	Learning Rate: 0.0187497
	LOSS [training: 0.18031237514029125 | validation: 0.2335234686015673]
	TIME [epoch: 8.39 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21020368673790069		[learning rate: 0.018742]
	Learning Rate: 0.0187417
	LOSS [training: 0.21020368673790069 | validation: 0.1643616246452071]
	TIME [epoch: 8.35 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17324178261765488		[learning rate: 0.018734]
	Learning Rate: 0.0187337
	LOSS [training: 0.17324178261765488 | validation: 0.26952286222587307]
	TIME [epoch: 8.34 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19286628591432253		[learning rate: 0.018726]
	Learning Rate: 0.0187256
	LOSS [training: 0.19286628591432253 | validation: 0.23175531852234754]
	TIME [epoch: 8.34 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17296896711163556		[learning rate: 0.018718]
	Learning Rate: 0.0187175
	LOSS [training: 0.17296896711163556 | validation: 0.30367307139670213]
	TIME [epoch: 8.34 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2975192318727857		[learning rate: 0.018709]
	Learning Rate: 0.0187094
	LOSS [training: 0.2975192318727857 | validation: 0.1667421936785271]
	TIME [epoch: 8.36 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20294046155173126		[learning rate: 0.018701]
	Learning Rate: 0.0187013
	LOSS [training: 0.20294046155173126 | validation: 0.13988637913017693]
	TIME [epoch: 8.37 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17721288716743455		[learning rate: 0.018693]
	Learning Rate: 0.0186931
	LOSS [training: 0.17721288716743455 | validation: 0.19622420952396602]
	TIME [epoch: 8.34 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1632219002912087		[learning rate: 0.018685]
	Learning Rate: 0.0186849
	LOSS [training: 0.1632219002912087 | validation: 0.08477713929887132]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_364.pth
	Model improved!!!
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13119437261378974		[learning rate: 0.018677]
	Learning Rate: 0.0186767
	LOSS [training: 0.13119437261378974 | validation: 0.26560037566457984]
	TIME [epoch: 8.34 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20777319478229064		[learning rate: 0.018668]
	Learning Rate: 0.0186685
	LOSS [training: 0.20777319478229064 | validation: 0.2318907750180999]
	TIME [epoch: 8.34 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16252184054247398		[learning rate: 0.01866]
	Learning Rate: 0.0186602
	LOSS [training: 0.16252184054247398 | validation: 0.26493351614994726]
	TIME [epoch: 8.38 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19777935398700708		[learning rate: 0.018652]
	Learning Rate: 0.018652
	LOSS [training: 0.19777935398700708 | validation: 0.31056424519974446]
	TIME [epoch: 8.33 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2502297432396138		[learning rate: 0.018644]
	Learning Rate: 0.0186437
	LOSS [training: 0.2502297432396138 | validation: 0.21939689503780152]
	TIME [epoch: 8.34 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18884068347304767		[learning rate: 0.018635]
	Learning Rate: 0.0186353
	LOSS [training: 0.18884068347304767 | validation: 0.15626108751600165]
	TIME [epoch: 8.34 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17793955860919183		[learning rate: 0.018627]
	Learning Rate: 0.018627
	LOSS [training: 0.17793955860919183 | validation: 0.1746821940274747]
	TIME [epoch: 8.34 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2346938333861454		[learning rate: 0.018619]
	Learning Rate: 0.0186186
	LOSS [training: 0.2346938333861454 | validation: 0.5095437707109959]
	TIME [epoch: 8.36 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23456802852264502		[learning rate: 0.01861]
	Learning Rate: 0.0186102
	LOSS [training: 0.23456802852264502 | validation: 0.06529491195152515]
	TIME [epoch: 8.37 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_373.pth
	Model improved!!!
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1484216871452373		[learning rate: 0.018602]
	Learning Rate: 0.0186018
	LOSS [training: 0.1484216871452373 | validation: 0.07846919741313708]
	TIME [epoch: 8.33 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2076020156686869		[learning rate: 0.018593]
	Learning Rate: 0.0185934
	LOSS [training: 0.2076020156686869 | validation: 0.5060599764631546]
	TIME [epoch: 8.33 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26983873423554394		[learning rate: 0.018585]
	Learning Rate: 0.0185849
	LOSS [training: 0.26983873423554394 | validation: 0.09065449371110043]
	TIME [epoch: 8.34 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09384596286690457		[learning rate: 0.018576]
	Learning Rate: 0.0185764
	LOSS [training: 0.09384596286690457 | validation: 0.11130222155791705]
	TIME [epoch: 8.34 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12504959309828362		[learning rate: 0.018568]
	Learning Rate: 0.0185679
	LOSS [training: 0.12504959309828362 | validation: 0.14346945305600572]
	TIME [epoch: 8.38 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15164295096583102		[learning rate: 0.018559]
	Learning Rate: 0.0185594
	LOSS [training: 0.15164295096583102 | validation: 0.14026954638030292]
	TIME [epoch: 8.33 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14475697469660778		[learning rate: 0.018551]
	Learning Rate: 0.0185508
	LOSS [training: 0.14475697469660778 | validation: 0.12382652756878618]
	TIME [epoch: 8.34 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19360076584651126		[learning rate: 0.018542]
	Learning Rate: 0.0185422
	LOSS [training: 0.19360076584651126 | validation: 0.1331665432455045]
	TIME [epoch: 8.34 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13186429826248483		[learning rate: 0.018534]
	Learning Rate: 0.0185336
	LOSS [training: 0.13186429826248483 | validation: 0.12201953499018435]
	TIME [epoch: 8.34 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14610923271502724		[learning rate: 0.018525]
	Learning Rate: 0.018525
	LOSS [training: 0.14610923271502724 | validation: 0.09417636416933402]
	TIME [epoch: 8.37 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1733683990659965		[learning rate: 0.018516]
	Learning Rate: 0.0185163
	LOSS [training: 0.1733683990659965 | validation: 0.21647614855577182]
	TIME [epoch: 8.35 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17110450511632064		[learning rate: 0.018508]
	Learning Rate: 0.0185077
	LOSS [training: 0.17110450511632064 | validation: 0.13097286445923073]
	TIME [epoch: 8.34 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16041683640019583		[learning rate: 0.018499]
	Learning Rate: 0.018499
	LOSS [training: 0.16041683640019583 | validation: 0.2346707470666388]
	TIME [epoch: 8.34 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18267369943464856		[learning rate: 0.01849]
	Learning Rate: 0.0184902
	LOSS [training: 0.18267369943464856 | validation: 0.26434103787659535]
	TIME [epoch: 8.34 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17460788879151906		[learning rate: 0.018481]
	Learning Rate: 0.0184815
	LOSS [training: 0.17460788879151906 | validation: 0.17861045870567055]
	TIME [epoch: 8.34 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15250341431558548		[learning rate: 0.018473]
	Learning Rate: 0.0184727
	LOSS [training: 0.15250341431558548 | validation: 0.2482116339015418]
	TIME [epoch: 8.39 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3200662462694941		[learning rate: 0.018464]
	Learning Rate: 0.0184639
	LOSS [training: 0.3200662462694941 | validation: 0.11969699405051984]
	TIME [epoch: 8.34 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13983675460502726		[learning rate: 0.018455]
	Learning Rate: 0.0184551
	LOSS [training: 0.13983675460502726 | validation: 0.18470533737786338]
	TIME [epoch: 8.34 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1484941570608575		[learning rate: 0.018446]
	Learning Rate: 0.0184463
	LOSS [training: 0.1484941570608575 | validation: 0.19984728591761886]
	TIME [epoch: 8.34 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16047288491282788		[learning rate: 0.018437]
	Learning Rate: 0.0184374
	LOSS [training: 0.16047288491282788 | validation: 0.1726071573812104]
	TIME [epoch: 8.34 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20583217279490554		[learning rate: 0.018429]
	Learning Rate: 0.0184285
	LOSS [training: 0.20583217279490554 | validation: 0.5320152695551235]
	TIME [epoch: 8.36 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2642056503201315		[learning rate: 0.01842]
	Learning Rate: 0.0184196
	LOSS [training: 0.2642056503201315 | validation: 0.16194355406351169]
	TIME [epoch: 8.36 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16465539944948251		[learning rate: 0.018411]
	Learning Rate: 0.0184107
	LOSS [training: 0.16465539944948251 | validation: 0.15365091582370627]
	TIME [epoch: 8.34 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12612767686645487		[learning rate: 0.018402]
	Learning Rate: 0.0184017
	LOSS [training: 0.12612767686645487 | validation: 0.14569798665668146]
	TIME [epoch: 8.34 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14564825939404705		[learning rate: 0.018393]
	Learning Rate: 0.0183928
	LOSS [training: 0.14564825939404705 | validation: 0.20007442030763212]
	TIME [epoch: 8.34 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19464162284529957		[learning rate: 0.018384]
	Learning Rate: 0.0183838
	LOSS [training: 0.19464162284529957 | validation: 0.2022185952402053]
	TIME [epoch: 8.34 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23269862144846093		[learning rate: 0.018375]
	Learning Rate: 0.0183747
	LOSS [training: 0.23269862144846093 | validation: 0.18096941504614783]
	TIME [epoch: 8.38 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14604139251412782		[learning rate: 0.018366]
	Learning Rate: 0.0183657
	LOSS [training: 0.14604139251412782 | validation: 0.22719620011397584]
	TIME [epoch: 8.34 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14614938015942394		[learning rate: 0.018357]
	Learning Rate: 0.0183566
	LOSS [training: 0.14614938015942394 | validation: 0.4924237970794183]
	TIME [epoch: 8.33 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2161098348093129		[learning rate: 0.018348]
	Learning Rate: 0.0183475
	LOSS [training: 0.2161098348093129 | validation: 0.14920395984159407]
	TIME [epoch: 8.34 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1736059575250307		[learning rate: 0.018338]
	Learning Rate: 0.0183384
	LOSS [training: 0.1736059575250307 | validation: 0.16434442588792372]
	TIME [epoch: 8.33 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17080397888684815		[learning rate: 0.018329]
	Learning Rate: 0.0183293
	LOSS [training: 0.17080397888684815 | validation: 0.12873162084102008]
	TIME [epoch: 8.35 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1777625609922248		[learning rate: 0.01832]
	Learning Rate: 0.0183201
	LOSS [training: 0.1777625609922248 | validation: 0.21667131916209664]
	TIME [epoch: 8.36 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12766103533823875		[learning rate: 0.018311]
	Learning Rate: 0.0183109
	LOSS [training: 0.12766103533823875 | validation: 0.1932482013956483]
	TIME [epoch: 8.33 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1777907604102088		[learning rate: 0.018302]
	Learning Rate: 0.0183017
	LOSS [training: 0.1777907604102088 | validation: 0.1420329335208868]
	TIME [epoch: 8.33 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14210777067634434		[learning rate: 0.018293]
	Learning Rate: 0.0182925
	LOSS [training: 0.14210777067634434 | validation: 0.2850205429911865]
	TIME [epoch: 8.33 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34160911753276857		[learning rate: 0.018283]
	Learning Rate: 0.0182833
	LOSS [training: 0.34160911753276857 | validation: 0.13598027150665704]
	TIME [epoch: 8.33 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13000567282938208		[learning rate: 0.018274]
	Learning Rate: 0.018274
	LOSS [training: 0.13000567282938208 | validation: 0.16980663374019128]
	TIME [epoch: 8.38 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19198935494214875		[learning rate: 0.018265]
	Learning Rate: 0.0182647
	LOSS [training: 0.19198935494214875 | validation: 0.16603112231949788]
	TIME [epoch: 8.33 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12228935954222087		[learning rate: 0.018255]
	Learning Rate: 0.0182554
	LOSS [training: 0.12228935954222087 | validation: 0.17363520099158816]
	TIME [epoch: 8.33 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13757867975676613		[learning rate: 0.018246]
	Learning Rate: 0.018246
	LOSS [training: 0.13757867975676613 | validation: 0.10259125313692027]
	TIME [epoch: 8.34 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12559101478740042		[learning rate: 0.018237]
	Learning Rate: 0.0182367
	LOSS [training: 0.12559101478740042 | validation: 0.19601942156857455]
	TIME [epoch: 8.33 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1253302068231026		[learning rate: 0.018227]
	Learning Rate: 0.0182273
	LOSS [training: 0.1253302068231026 | validation: 0.17464331511544023]
	TIME [epoch: 8.35 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2023541541110015		[learning rate: 0.018218]
	Learning Rate: 0.0182179
	LOSS [training: 0.2023541541110015 | validation: 0.1992183720962263]
	TIME [epoch: 8.36 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17200533702949472		[learning rate: 0.018208]
	Learning Rate: 0.0182085
	LOSS [training: 0.17200533702949472 | validation: 0.2185548406289938]
	TIME [epoch: 8.33 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15632786213979952		[learning rate: 0.018199]
	Learning Rate: 0.018199
	LOSS [training: 0.15632786213979952 | validation: 0.1702965581923328]
	TIME [epoch: 8.29 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15485277514621534		[learning rate: 0.01819]
	Learning Rate: 0.0181895
	LOSS [training: 0.15485277514621534 | validation: 0.13068076963808353]
	TIME [epoch: 8.27 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18698920911403877		[learning rate: 0.01818]
	Learning Rate: 0.01818
	LOSS [training: 0.18698920911403877 | validation: 0.11110064561957911]
	TIME [epoch: 8.28 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13757588720184388		[learning rate: 0.018171]
	Learning Rate: 0.0181705
	LOSS [training: 0.13757588720184388 | validation: 0.15064936069134646]
	TIME [epoch: 8.33 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1388732471792536		[learning rate: 0.018161]
	Learning Rate: 0.018161
	LOSS [training: 0.1388732471792536 | validation: 0.17975430432064038]
	TIME [epoch: 8.28 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13770787811188415		[learning rate: 0.018151]
	Learning Rate: 0.0181514
	LOSS [training: 0.13770787811188415 | validation: 0.2456890992969105]
	TIME [epoch: 8.28 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1283754853819695		[learning rate: 0.018142]
	Learning Rate: 0.0181418
	LOSS [training: 0.1283754853819695 | validation: 0.05943326093780971]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_425.pth
	Model improved!!!
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12572968094790024		[learning rate: 0.018132]
	Learning Rate: 0.0181322
	LOSS [training: 0.12572968094790024 | validation: 0.17464650465606368]
	TIME [epoch: 8.28 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24743811711238944		[learning rate: 0.018123]
	Learning Rate: 0.0181226
	LOSS [training: 0.24743811711238944 | validation: 0.15634690290487946]
	TIME [epoch: 8.28 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13104911316429774		[learning rate: 0.018113]
	Learning Rate: 0.0181129
	LOSS [training: 0.13104911316429774 | validation: 0.1630593111867441]
	TIME [epoch: 8.3 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12049009451147699		[learning rate: 0.018103]
	Learning Rate: 0.0181032
	LOSS [training: 0.12049009451147699 | validation: 0.1349845143698551]
	TIME [epoch: 8.27 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1369623967583694		[learning rate: 0.018094]
	Learning Rate: 0.0180936
	LOSS [training: 0.1369623967583694 | validation: 0.1304939749961828]
	TIME [epoch: 8.27 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1588009786812459		[learning rate: 0.018084]
	Learning Rate: 0.0180838
	LOSS [training: 0.1588009786812459 | validation: 0.10274447123392863]
	TIME [epoch: 8.27 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14656618897587448		[learning rate: 0.018074]
	Learning Rate: 0.0180741
	LOSS [training: 0.14656618897587448 | validation: 0.2464514943390012]
	TIME [epoch: 8.28 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17027001067775926		[learning rate: 0.018064]
	Learning Rate: 0.0180643
	LOSS [training: 0.17027001067775926 | validation: 0.13333617464282788]
	TIME [epoch: 8.32 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15225607381748357		[learning rate: 0.018055]
	Learning Rate: 0.0180545
	LOSS [training: 0.15225607381748357 | validation: 0.24662247766852985]
	TIME [epoch: 8.29 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16573923073276428		[learning rate: 0.018045]
	Learning Rate: 0.0180447
	LOSS [training: 0.16573923073276428 | validation: 0.12704687262265577]
	TIME [epoch: 8.27 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13906415891775897		[learning rate: 0.018035]
	Learning Rate: 0.0180349
	LOSS [training: 0.13906415891775897 | validation: 0.3630119836186547]
	TIME [epoch: 8.28 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1764286086923563		[learning rate: 0.018025]
	Learning Rate: 0.0180251
	LOSS [training: 0.1764286086923563 | validation: 0.08653872128849802]
	TIME [epoch: 8.28 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3374549149112568		[learning rate: 0.018015]
	Learning Rate: 0.0180152
	LOSS [training: 0.3374549149112568 | validation: 0.2491571791542082]
	TIME [epoch: 8.28 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1906569180029525		[learning rate: 0.018005]
	Learning Rate: 0.0180053
	LOSS [training: 0.1906569180029525 | validation: 0.10149906419805102]
	TIME [epoch: 8.32 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10386276357224185		[learning rate: 0.017995]
	Learning Rate: 0.0179954
	LOSS [training: 0.10386276357224185 | validation: 0.0937959025254294]
	TIME [epoch: 8.28 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11078486340446274		[learning rate: 0.017985]
	Learning Rate: 0.0179854
	LOSS [training: 0.11078486340446274 | validation: 0.11052027250352375]
	TIME [epoch: 8.3 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14983486041937852		[learning rate: 0.017975]
	Learning Rate: 0.0179755
	LOSS [training: 0.14983486041937852 | validation: 0.0934733326394019]
	TIME [epoch: 8.3 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10670047626041984		[learning rate: 0.017965]
	Learning Rate: 0.0179655
	LOSS [training: 0.10670047626041984 | validation: 0.15476830307058087]
	TIME [epoch: 8.34 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.139392885874437		[learning rate: 0.017955]
	Learning Rate: 0.0179555
	LOSS [training: 0.139392885874437 | validation: 0.20323263599835792]
	TIME [epoch: 8.37 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13562608672975787		[learning rate: 0.017945]
	Learning Rate: 0.0179455
	LOSS [training: 0.13562608672975787 | validation: 0.10874413703678423]
	TIME [epoch: 8.36 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16643822341997067		[learning rate: 0.017935]
	Learning Rate: 0.0179354
	LOSS [training: 0.16643822341997067 | validation: 0.11775676876539981]
	TIME [epoch: 8.35 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13342760164197284		[learning rate: 0.017925]
	Learning Rate: 0.0179253
	LOSS [training: 0.13342760164197284 | validation: 0.17765972037381483]
	TIME [epoch: 8.33 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14972086600606788		[learning rate: 0.017915]
	Learning Rate: 0.0179152
	LOSS [training: 0.14972086600606788 | validation: 0.09128347752749272]
	TIME [epoch: 8.33 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13629418704977986		[learning rate: 0.017905]
	Learning Rate: 0.0179051
	LOSS [training: 0.13629418704977986 | validation: 0.1839499323882417]
	TIME [epoch: 8.34 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1504669874432321		[learning rate: 0.017895]
	Learning Rate: 0.017895
	LOSS [training: 0.1504669874432321 | validation: 0.08841784547946209]
	TIME [epoch: 8.36 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10999688085776249		[learning rate: 0.017885]
	Learning Rate: 0.0178848
	LOSS [training: 0.10999688085776249 | validation: 0.19952416340871137]
	TIME [epoch: 8.33 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20987531452628239		[learning rate: 0.017875]
	Learning Rate: 0.0178747
	LOSS [training: 0.20987531452628239 | validation: 0.1253219213623698]
	TIME [epoch: 8.34 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08309149630735471		[learning rate: 0.017864]
	Learning Rate: 0.0178645
	LOSS [training: 0.08309149630735471 | validation: 0.9880443874676659]
	TIME [epoch: 8.33 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.401717046790522		[learning rate: 0.017854]
	Learning Rate: 0.0178542
	LOSS [training: 0.401717046790522 | validation: 0.10863807379044418]
	TIME [epoch: 8.33 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13052200286672244		[learning rate: 0.017844]
	Learning Rate: 0.017844
	LOSS [training: 0.13052200286672244 | validation: 0.17421569600814543]
	TIME [epoch: 8.37 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13473294992146065		[learning rate: 0.017834]
	Learning Rate: 0.0178337
	LOSS [training: 0.13473294992146065 | validation: 0.13649519687080636]
	TIME [epoch: 8.35 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10267957310735622		[learning rate: 0.017823]
	Learning Rate: 0.0178235
	LOSS [training: 0.10267957310735622 | validation: 0.16842400604671554]
	TIME [epoch: 8.33 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14870529005303199		[learning rate: 0.017813]
	Learning Rate: 0.0178131
	LOSS [training: 0.14870529005303199 | validation: 0.1432409521772278]
	TIME [epoch: 8.33 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13491481308017952		[learning rate: 0.017803]
	Learning Rate: 0.0178028
	LOSS [training: 0.13491481308017952 | validation: 0.14823499879427388]
	TIME [epoch: 8.32 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1637810543265495		[learning rate: 0.017792]
	Learning Rate: 0.0177925
	LOSS [training: 0.1637810543265495 | validation: 0.11121228810984857]
	TIME [epoch: 8.33 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11667220639360931		[learning rate: 0.017782]
	Learning Rate: 0.0177821
	LOSS [training: 0.11667220639360931 | validation: 0.19450210773731932]
	TIME [epoch: 8.38 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16425226659059858		[learning rate: 0.017772]
	Learning Rate: 0.0177717
	LOSS [training: 0.16425226659059858 | validation: 0.09969373762076075]
	TIME [epoch: 8.33 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1603357448892434		[learning rate: 0.017761]
	Learning Rate: 0.0177613
	LOSS [training: 0.1603357448892434 | validation: 0.09595039545284918]
	TIME [epoch: 8.34 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10591458344219817		[learning rate: 0.017751]
	Learning Rate: 0.0177509
	LOSS [training: 0.10591458344219817 | validation: 0.15842769465792977]
	TIME [epoch: 8.33 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13804982339824232		[learning rate: 0.01774]
	Learning Rate: 0.0177404
	LOSS [training: 0.13804982339824232 | validation: 0.10203697189493563]
	TIME [epoch: 8.33 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1628898166204794		[learning rate: 0.01773]
	Learning Rate: 0.0177299
	LOSS [training: 0.1628898166204794 | validation: 0.6718081092870438]
	TIME [epoch: 8.37 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36019432370466953		[learning rate: 0.017719]
	Learning Rate: 0.0177194
	LOSS [training: 0.36019432370466953 | validation: 0.06436448137033415]
	TIME [epoch: 8.34 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09718255856917536		[learning rate: 0.017709]
	Learning Rate: 0.0177089
	LOSS [training: 0.09718255856917536 | validation: 0.12096214782861103]
	TIME [epoch: 8.32 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10886175791481968		[learning rate: 0.017698]
	Learning Rate: 0.0176984
	LOSS [training: 0.10886175791481968 | validation: 0.15522744253112358]
	TIME [epoch: 8.33 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1261166658000758		[learning rate: 0.017688]
	Learning Rate: 0.0176878
	LOSS [training: 0.1261166658000758 | validation: 0.1365161213027461]
	TIME [epoch: 8.31 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12629817017828165		[learning rate: 0.017677]
	Learning Rate: 0.0176772
	LOSS [training: 0.12629817017828165 | validation: 0.09676828643353116]
	TIME [epoch: 8.33 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1394178896135373		[learning rate: 0.017667]
	Learning Rate: 0.0176666
	LOSS [training: 0.1394178896135373 | validation: 0.2252910416825108]
	TIME [epoch: 8.37 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2423612505073913		[learning rate: 0.017656]
	Learning Rate: 0.017656
	LOSS [training: 0.2423612505073913 | validation: 0.11576517722031693]
	TIME [epoch: 8.33 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14181565004115493		[learning rate: 0.017645]
	Learning Rate: 0.0176454
	LOSS [training: 0.14181565004115493 | validation: 0.1218240266610236]
	TIME [epoch: 8.33 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10912097294739424		[learning rate: 0.017635]
	Learning Rate: 0.0176347
	LOSS [training: 0.10912097294739424 | validation: 0.09998474426322243]
	TIME [epoch: 8.32 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11676508142960951		[learning rate: 0.017624]
	Learning Rate: 0.017624
	LOSS [training: 0.11676508142960951 | validation: 0.11711352020505572]
	TIME [epoch: 8.33 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11312577644826274		[learning rate: 0.017613]
	Learning Rate: 0.0176133
	LOSS [training: 0.11312577644826274 | validation: 0.1150923766132252]
	TIME [epoch: 8.34 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16310288833494013		[learning rate: 0.017603]
	Learning Rate: 0.0176026
	LOSS [training: 0.16310288833494013 | validation: 0.12941516253300783]
	TIME [epoch: 8.36 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11333750374900778		[learning rate: 0.017592]
	Learning Rate: 0.0175918
	LOSS [training: 0.11333750374900778 | validation: 0.1170772594106559]
	TIME [epoch: 8.34 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11849272889315005		[learning rate: 0.017581]
	Learning Rate: 0.0175811
	LOSS [training: 0.11849272889315005 | validation: 0.22610068073323505]
	TIME [epoch: 8.34 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1304504971399808		[learning rate: 0.01757]
	Learning Rate: 0.0175703
	LOSS [training: 0.1304504971399808 | validation: 0.12302352763713849]
	TIME [epoch: 8.33 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15325993519353248		[learning rate: 0.017559]
	Learning Rate: 0.0175595
	LOSS [training: 0.15325993519353248 | validation: 0.10467148404931544]
	TIME [epoch: 8.33 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1224872613229283		[learning rate: 0.017549]
	Learning Rate: 0.0175486
	LOSS [training: 0.1224872613229283 | validation: 0.13163706567196568]
	TIME [epoch: 8.37 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1314784882941115		[learning rate: 0.017538]
	Learning Rate: 0.0175378
	LOSS [training: 0.1314784882941115 | validation: 0.5307187499337093]
	TIME [epoch: 8.33 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21884479469207507		[learning rate: 0.017527]
	Learning Rate: 0.0175269
	LOSS [training: 0.21884479469207507 | validation: 0.13502915011999264]
	TIME [epoch: 8.32 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12757746314962495		[learning rate: 0.017516]
	Learning Rate: 0.017516
	LOSS [training: 0.12757746314962495 | validation: 0.1402556771522248]
	TIME [epoch: 8.32 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12964072013097938		[learning rate: 0.017505]
	Learning Rate: 0.0175051
	LOSS [training: 0.12964072013097938 | validation: 0.12011786271690983]
	TIME [epoch: 8.33 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12301250043020151		[learning rate: 0.017494]
	Learning Rate: 0.0174942
	LOSS [training: 0.12301250043020151 | validation: 0.1449933821260328]
	TIME [epoch: 8.35 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1925651647481672		[learning rate: 0.017483]
	Learning Rate: 0.0174832
	LOSS [training: 0.1925651647481672 | validation: 0.1490081474943095]
	TIME [epoch: 8.36 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13624581275353917		[learning rate: 0.017472]
	Learning Rate: 0.0174722
	LOSS [training: 0.13624581275353917 | validation: 0.1050773357692017]
	TIME [epoch: 8.32 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09269755013297427		[learning rate: 0.017461]
	Learning Rate: 0.0174612
	LOSS [training: 0.09269755013297427 | validation: 0.10965490938191255]
	TIME [epoch: 8.32 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1240993344405798		[learning rate: 0.01745]
	Learning Rate: 0.0174502
	LOSS [training: 0.1240993344405798 | validation: 0.11927718560595885]
	TIME [epoch: 8.32 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1466861326191433		[learning rate: 0.017439]
	Learning Rate: 0.0174392
	LOSS [training: 0.1466861326191433 | validation: 0.19981506300167223]
	TIME [epoch: 8.33 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1374116291513716		[learning rate: 0.017428]
	Learning Rate: 0.0174281
	LOSS [training: 0.1374116291513716 | validation: 0.1830193790600823]
	TIME [epoch: 8.36 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13910001238621794		[learning rate: 0.017417]
	Learning Rate: 0.017417
	LOSS [training: 0.13910001238621794 | validation: 0.18759450518981494]
	TIME [epoch: 8.33 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1186766918545559		[learning rate: 0.017406]
	Learning Rate: 0.0174059
	LOSS [training: 0.1186766918545559 | validation: 0.10127817181860352]
	TIME [epoch: 8.34 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11164451746203778		[learning rate: 0.017395]
	Learning Rate: 0.0173948
	LOSS [training: 0.11164451746203778 | validation: 0.08780773305889797]
	TIME [epoch: 8.35 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09524188983690467		[learning rate: 0.017384]
	Learning Rate: 0.0173837
	LOSS [training: 0.09524188983690467 | validation: 0.1444808492760689]
	TIME [epoch: 8.33 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12170192570782341		[learning rate: 0.017373]
	Learning Rate: 0.0173725
	LOSS [training: 0.12170192570782341 | validation: 0.11495680471073594]
	TIME [epoch: 8.34 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13341277200500704		[learning rate: 0.017361]
	Learning Rate: 0.0173614
	LOSS [training: 0.13341277200500704 | validation: 0.30892511162184616]
	TIME [epoch: 8.36 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17323950703814947		[learning rate: 0.01735]
	Learning Rate: 0.0173502
	LOSS [training: 0.17323950703814947 | validation: 0.15739272139432547]
	TIME [epoch: 8.32 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11930939576004827		[learning rate: 0.017339]
	Learning Rate: 0.0173389
	LOSS [training: 0.11930939576004827 | validation: 0.1392458006487433]
	TIME [epoch: 8.33 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12446518806534251		[learning rate: 0.017328]
	Learning Rate: 0.0173277
	LOSS [training: 0.12446518806534251 | validation: 0.08103030376459405]
	TIME [epoch: 8.32 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11394974843228489		[learning rate: 0.017316]
	Learning Rate: 0.0173164
	LOSS [training: 0.11394974843228489 | validation: 0.14170024321828834]
	TIME [epoch: 8.33 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12071655640310097		[learning rate: 0.017305]
	Learning Rate: 0.0173052
	LOSS [training: 0.12071655640310097 | validation: 0.1537349546870565]
	TIME [epoch: 8.36 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1539306325171605		[learning rate: 0.017294]
	Learning Rate: 0.0172939
	LOSS [training: 0.1539306325171605 | validation: 0.10432487186541183]
	TIME [epoch: 8.33 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10733305614080589		[learning rate: 0.017283]
	Learning Rate: 0.0172826
	LOSS [training: 0.10733305614080589 | validation: 0.16888461643035307]
	TIME [epoch: 8.32 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12947973104675808		[learning rate: 0.017271]
	Learning Rate: 0.0172712
	LOSS [training: 0.12947973104675808 | validation: 0.09885845559202563]
	TIME [epoch: 8.32 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10640435991704024		[learning rate: 0.01726]
	Learning Rate: 0.0172599
	LOSS [training: 0.10640435991704024 | validation: 0.1372050459855418]
	TIME [epoch: 8.32 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12905917028330804		[learning rate: 0.017248]
	Learning Rate: 0.0172485
	LOSS [training: 0.12905917028330804 | validation: 0.13363650711088007]
	TIME [epoch: 8.34 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13112283611645864		[learning rate: 0.017237]
	Learning Rate: 0.0172371
	LOSS [training: 0.13112283611645864 | validation: 0.10277848818453783]
	TIME [epoch: 8.36 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12435423515673473		[learning rate: 0.017226]
	Learning Rate: 0.0172257
	LOSS [training: 0.12435423515673473 | validation: 0.18600296225603308]
	TIME [epoch: 8.32 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21860537981238376		[learning rate: 0.017214]
	Learning Rate: 0.0172142
	LOSS [training: 0.21860537981238376 | validation: 0.23396516702822223]
	TIME [epoch: 8.33 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10024944013871831		[learning rate: 0.017203]
	Learning Rate: 0.0172028
	LOSS [training: 0.10024944013871831 | validation: 0.08270502439748145]
	TIME [epoch: 8.33 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09387429969741053		[learning rate: 0.017191]
	Learning Rate: 0.0171913
	LOSS [training: 0.09387429969741053 | validation: 0.11337674984372131]
	TIME [epoch: 8.33 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13672355456595592		[learning rate: 0.01718]
	Learning Rate: 0.0171798
	LOSS [training: 0.13672355456595592 | validation: 0.08346189055900874]
	TIME [epoch: 8.37 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1027565979675153		[learning rate: 0.017168]
	Learning Rate: 0.0171683
	LOSS [training: 0.1027565979675153 | validation: 0.161264625059045]
	TIME [epoch: 8.33 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11255348177940708		[learning rate: 0.017157]
	Learning Rate: 0.0171567
	LOSS [training: 0.11255348177940708 | validation: 0.1275953117781225]
	TIME [epoch: 8.31 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11747430149157637		[learning rate: 0.017145]
	Learning Rate: 0.0171452
	LOSS [training: 0.11747430149157637 | validation: 0.14360030980792443]
	TIME [epoch: 8.32 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14106025154327187		[learning rate: 0.017134]
	Learning Rate: 0.0171336
	LOSS [training: 0.14106025154327187 | validation: 0.15583406927426963]
	TIME [epoch: 8.32 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09002602203433957		[learning rate: 0.017122]
	Learning Rate: 0.017122
	LOSS [training: 0.09002602203433957 | validation: 0.14767039062006232]
	TIME [epoch: 8.32 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1238293827120045		[learning rate: 0.01711]
	Learning Rate: 0.0171104
	LOSS [training: 0.1238293827120045 | validation: 0.13457120939752232]
	TIME [epoch: 8.36 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15452400203606775		[learning rate: 0.017099]
	Learning Rate: 0.0170988
	LOSS [training: 0.15452400203606775 | validation: 0.1667872375099962]
	TIME [epoch: 8.32 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10467116627603737		[learning rate: 0.017087]
	Learning Rate: 0.0170871
	LOSS [training: 0.10467116627603737 | validation: 0.1328606443989554]
	TIME [epoch: 8.31 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1183250065892513		[learning rate: 0.017075]
	Learning Rate: 0.0170755
	LOSS [training: 0.1183250065892513 | validation: 0.1055049238566582]
	TIME [epoch: 8.32 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12226510162385681		[learning rate: 0.017064]
	Learning Rate: 0.0170638
	LOSS [training: 0.12226510162385681 | validation: 0.13897035345845776]
	TIME [epoch: 8.32 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17521280078777837		[learning rate: 0.017052]
	Learning Rate: 0.0170521
	LOSS [training: 0.17521280078777837 | validation: 0.1854337895695785]
	TIME [epoch: 8.36 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12841961005576394		[learning rate: 0.01704]
	Learning Rate: 0.0170403
	LOSS [training: 0.12841961005576394 | validation: 0.11679085690722991]
	TIME [epoch: 8.34 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10023821890901473		[learning rate: 0.017029]
	Learning Rate: 0.0170286
	LOSS [training: 0.10023821890901473 | validation: 0.15623350974552608]
	TIME [epoch: 8.32 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10978229633667731		[learning rate: 0.017017]
	Learning Rate: 0.0170168
	LOSS [training: 0.10978229633667731 | validation: 0.08435048982079278]
	TIME [epoch: 8.33 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10215328423358414		[learning rate: 0.017005]
	Learning Rate: 0.017005
	LOSS [training: 0.10215328423358414 | validation: 0.09332216811498656]
	TIME [epoch: 8.33 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09081482355994375		[learning rate: 0.016993]
	Learning Rate: 0.0169932
	LOSS [training: 0.09081482355994375 | validation: 0.12960686367994445]
	TIME [epoch: 8.33 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12927091477893593		[learning rate: 0.016981]
	Learning Rate: 0.0169814
	LOSS [training: 0.12927091477893593 | validation: 0.14446955621279722]
	TIME [epoch: 8.36 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1009120191436095		[learning rate: 0.01697]
	Learning Rate: 0.0169695
	LOSS [training: 0.1009120191436095 | validation: 0.09054608324451702]
	TIME [epoch: 8.33 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.110807156718852		[learning rate: 0.016958]
	Learning Rate: 0.0169577
	LOSS [training: 0.110807156718852 | validation: 0.19161921813590244]
	TIME [epoch: 8.33 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13470491571867063		[learning rate: 0.016946]
	Learning Rate: 0.0169458
	LOSS [training: 0.13470491571867063 | validation: 0.10737010088027119]
	TIME [epoch: 8.32 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19331581720475968		[learning rate: 0.016934]
	Learning Rate: 0.0169339
	LOSS [training: 0.19331581720475968 | validation: 0.12955666781269826]
	TIME [epoch: 8.32 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10156486481705074		[learning rate: 0.016922]
	Learning Rate: 0.016922
	LOSS [training: 0.10156486481705074 | validation: 0.10757747635491732]
	TIME [epoch: 8.36 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09915595658330639		[learning rate: 0.01691]
	Learning Rate: 0.01691
	LOSS [training: 0.09915595658330639 | validation: 0.16281961516342458]
	TIME [epoch: 8.34 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10735969634110576		[learning rate: 0.016898]
	Learning Rate: 0.0168981
	LOSS [training: 0.10735969634110576 | validation: 0.13146304464831998]
	TIME [epoch: 8.32 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12731361476812064		[learning rate: 0.016886]
	Learning Rate: 0.0168861
	LOSS [training: 0.12731361476812064 | validation: 0.07117658967640822]
	TIME [epoch: 8.32 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09355036942829846		[learning rate: 0.016874]
	Learning Rate: 0.0168741
	LOSS [training: 0.09355036942829846 | validation: 0.16636014499916116]
	TIME [epoch: 8.32 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16697418915549916		[learning rate: 0.016862]
	Learning Rate: 0.0168621
	LOSS [training: 0.16697418915549916 | validation: 0.29073664798163545]
	TIME [epoch: 8.33 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11626331497800052		[learning rate: 0.01685]
	Learning Rate: 0.0168501
	LOSS [training: 0.11626331497800052 | validation: 0.08649544584958094]
	TIME [epoch: 8.36 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09098228465243278		[learning rate: 0.016838]
	Learning Rate: 0.016838
	LOSS [training: 0.09098228465243278 | validation: 0.1908012703361638]
	TIME [epoch: 8.33 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09931667731957206		[learning rate: 0.016826]
	Learning Rate: 0.0168259
	LOSS [training: 0.09931667731957206 | validation: 0.07198008909926842]
	TIME [epoch: 8.32 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09009537241111713		[learning rate: 0.016814]
	Learning Rate: 0.0168138
	LOSS [training: 0.09009537241111713 | validation: 0.07978892183117678]
	TIME [epoch: 8.33 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10798228971724348		[learning rate: 0.016802]
	Learning Rate: 0.0168017
	LOSS [training: 0.10798228971724348 | validation: 0.1326721715045778]
	TIME [epoch: 8.34 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09131314341916565		[learning rate: 0.01679]
	Learning Rate: 0.0167896
	LOSS [training: 0.09131314341916565 | validation: 0.11065644508060156]
	TIME [epoch: 8.36 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1210482517063608		[learning rate: 0.016777]
	Learning Rate: 0.0167775
	LOSS [training: 0.1210482517063608 | validation: 0.06366491559651119]
	TIME [epoch: 8.34 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10293772681886995		[learning rate: 0.016765]
	Learning Rate: 0.0167653
	LOSS [training: 0.10293772681886995 | validation: 0.110662615767076]
	TIME [epoch: 8.32 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10397802211417592		[learning rate: 0.016753]
	Learning Rate: 0.0167531
	LOSS [training: 0.10397802211417592 | validation: 0.16701139999904563]
	TIME [epoch: 8.32 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10010590430888408		[learning rate: 0.016741]
	Learning Rate: 0.0167409
	LOSS [training: 0.10010590430888408 | validation: 0.22293031348026426]
	TIME [epoch: 8.32 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18728332818376037		[learning rate: 0.016729]
	Learning Rate: 0.0167287
	LOSS [training: 0.18728332818376037 | validation: 0.11252132718790704]
	TIME [epoch: 8.32 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0878618264897525		[learning rate: 0.016716]
	Learning Rate: 0.0167165
	LOSS [training: 0.0878618264897525 | validation: 0.11819252371540295]
	TIME [epoch: 8.37 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09962651036176778		[learning rate: 0.016704]
	Learning Rate: 0.0167042
	LOSS [training: 0.09962651036176778 | validation: 0.08419207997407605]
	TIME [epoch: 8.32 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08472941660691263		[learning rate: 0.016692]
	Learning Rate: 0.0166919
	LOSS [training: 0.08472941660691263 | validation: 0.17382441119646524]
	TIME [epoch: 8.32 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11508940435661441		[learning rate: 0.01668]
	Learning Rate: 0.0166796
	LOSS [training: 0.11508940435661441 | validation: 0.09232068878534093]
	TIME [epoch: 8.32 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13241427366218617		[learning rate: 0.016667]
	Learning Rate: 0.0166673
	LOSS [training: 0.13241427366218617 | validation: 0.11719673714980529]
	TIME [epoch: 8.32 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12931997434751888		[learning rate: 0.016655]
	Learning Rate: 0.016655
	LOSS [training: 0.12931997434751888 | validation: 0.07257496886564238]
	TIME [epoch: 8.34 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10567768530633909		[learning rate: 0.016643]
	Learning Rate: 0.0166427
	LOSS [training: 0.10567768530633909 | validation: 0.10004322446114816]
	TIME [epoch: 8.36 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08512357988562749		[learning rate: 0.01663]
	Learning Rate: 0.0166303
	LOSS [training: 0.08512357988562749 | validation: 0.08651704851897378]
	TIME [epoch: 8.33 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09415129960766608		[learning rate: 0.016618]
	Learning Rate: 0.0166179
	LOSS [training: 0.09415129960766608 | validation: 0.10401585073592598]
	TIME [epoch: 8.33 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10295775087173151		[learning rate: 0.016606]
	Learning Rate: 0.0166055
	LOSS [training: 0.10295775087173151 | validation: 0.06555639035022195]
	TIME [epoch: 8.33 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09250138075432568		[learning rate: 0.016593]
	Learning Rate: 0.0165931
	LOSS [training: 0.09250138075432568 | validation: 0.10571527351387683]
	TIME [epoch: 8.33 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09936556591733217		[learning rate: 0.016581]
	Learning Rate: 0.0165807
	LOSS [training: 0.09936556591733217 | validation: 0.12133154908078406]
	TIME [epoch: 8.36 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1064055633168712		[learning rate: 0.016568]
	Learning Rate: 0.0165682
	LOSS [training: 0.1064055633168712 | validation: 0.12616798980423197]
	TIME [epoch: 8.32 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10917943672118638		[learning rate: 0.016556]
	Learning Rate: 0.0165557
	LOSS [training: 0.10917943672118638 | validation: 0.146845571756909]
	TIME [epoch: 8.32 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10820460402627946		[learning rate: 0.016543]
	Learning Rate: 0.0165432
	LOSS [training: 0.10820460402627946 | validation: 0.13326797130149975]
	TIME [epoch: 8.32 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08360914117057663		[learning rate: 0.016531]
	Learning Rate: 0.0165307
	LOSS [training: 0.08360914117057663 | validation: 0.09144770113766643]
	TIME [epoch: 8.32 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07557427113335215		[learning rate: 0.016518]
	Learning Rate: 0.0165182
	LOSS [training: 0.07557427113335215 | validation: 0.06267259576828121]
	TIME [epoch: 8.34 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0812226946209296		[learning rate: 0.016506]
	Learning Rate: 0.0165057
	LOSS [training: 0.0812226946209296 | validation: 0.15886325402503382]
	TIME [epoch: 8.35 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22370096695347608		[learning rate: 0.016493]
	Learning Rate: 0.0164931
	LOSS [training: 0.22370096695347608 | validation: 0.12494190420436]
	TIME [epoch: 8.32 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11068022150449315		[learning rate: 0.016481]
	Learning Rate: 0.0164805
	LOSS [training: 0.11068022150449315 | validation: 0.09297228979342659]
	TIME [epoch: 8.32 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09265951981400505		[learning rate: 0.016468]
	Learning Rate: 0.0164679
	LOSS [training: 0.09265951981400505 | validation: 0.06533371297474816]
	TIME [epoch: 8.32 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07323938712343701		[learning rate: 0.016455]
	Learning Rate: 0.0164553
	LOSS [training: 0.07323938712343701 | validation: 0.09759839923938998]
	TIME [epoch: 8.32 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08702552075233021		[learning rate: 0.016443]
	Learning Rate: 0.0164427
	LOSS [training: 0.08702552075233021 | validation: 0.09507128662842512]
	TIME [epoch: 8.36 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10903870409777555		[learning rate: 0.01643]
	Learning Rate: 0.01643
	LOSS [training: 0.10903870409777555 | validation: 0.155188533229855]
	TIME [epoch: 8.32 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1077457879506912		[learning rate: 0.016417]
	Learning Rate: 0.0164173
	LOSS [training: 0.1077457879506912 | validation: 0.06309034308058957]
	TIME [epoch: 8.33 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11869954369288474		[learning rate: 0.016405]
	Learning Rate: 0.0164047
	LOSS [training: 0.11869954369288474 | validation: 0.15408882526533574]
	TIME [epoch: 8.33 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10477314240178456		[learning rate: 0.016392]
	Learning Rate: 0.016392
	LOSS [training: 0.10477314240178456 | validation: 0.0974972446392452]
	TIME [epoch: 8.34 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11683137655293863		[learning rate: 0.016379]
	Learning Rate: 0.0163792
	LOSS [training: 0.11683137655293863 | validation: 0.21254168105981058]
	TIME [epoch: 8.34 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.105320515891705		[learning rate: 0.016366]
	Learning Rate: 0.0163665
	LOSS [training: 0.105320515891705 | validation: 0.07119110789953917]
	TIME [epoch: 8.35 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2063335083146552		[learning rate: 0.016354]
	Learning Rate: 0.0163537
	LOSS [training: 0.2063335083146552 | validation: 0.12294043174958694]
	TIME [epoch: 8.31 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09770778770204397		[learning rate: 0.016341]
	Learning Rate: 0.016341
	LOSS [training: 0.09770778770204397 | validation: 0.09075974853724696]
	TIME [epoch: 8.32 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08323806240710643		[learning rate: 0.016328]
	Learning Rate: 0.0163282
	LOSS [training: 0.08323806240710643 | validation: 0.1028144429621597]
	TIME [epoch: 8.31 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09984945063784594		[learning rate: 0.016315]
	Learning Rate: 0.0163154
	LOSS [training: 0.09984945063784594 | validation: 0.10277450888356343]
	TIME [epoch: 8.32 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07677920905710317		[learning rate: 0.016303]
	Learning Rate: 0.0163025
	LOSS [training: 0.07677920905710317 | validation: 0.1323127222372084]
	TIME [epoch: 8.36 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11621953255418126		[learning rate: 0.01629]
	Learning Rate: 0.0162897
	LOSS [training: 0.11621953255418126 | validation: 0.07259468188077041]
	TIME [epoch: 8.33 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09898781552894595		[learning rate: 0.016277]
	Learning Rate: 0.0162768
	LOSS [training: 0.09898781552894595 | validation: 0.08787571007575422]
	TIME [epoch: 8.32 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10443286562467677		[learning rate: 0.016264]
	Learning Rate: 0.016264
	LOSS [training: 0.10443286562467677 | validation: 0.06350815573789398]
	TIME [epoch: 8.32 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.091192685781985		[learning rate: 0.016251]
	Learning Rate: 0.0162511
	LOSS [training: 0.091192685781985 | validation: 0.08615239537542736]
	TIME [epoch: 8.31 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1909241272399786		[learning rate: 0.016238]
	Learning Rate: 0.0162382
	LOSS [training: 0.1909241272399786 | validation: 0.16193376223648195]
	TIME [epoch: 8.33 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10590484123471701		[learning rate: 0.016225]
	Learning Rate: 0.0162252
	LOSS [training: 0.10590484123471701 | validation: 0.052513978004800496]
	TIME [epoch: 8.36 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_594.pth
	Model improved!!!
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06262302866640607		[learning rate: 0.016212]
	Learning Rate: 0.0162123
	LOSS [training: 0.06262302866640607 | validation: 0.07279659858421114]
	TIME [epoch: 8.33 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09181905384361647		[learning rate: 0.016199]
	Learning Rate: 0.0161993
	LOSS [training: 0.09181905384361647 | validation: 0.09786674642966722]
	TIME [epoch: 8.33 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08015715793581787		[learning rate: 0.016186]
	Learning Rate: 0.0161864
	LOSS [training: 0.08015715793581787 | validation: 0.07023724323426896]
	TIME [epoch: 8.34 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09896201093732027		[learning rate: 0.016173]
	Learning Rate: 0.0161734
	LOSS [training: 0.09896201093732027 | validation: 0.1765558352531571]
	TIME [epoch: 8.33 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1364566842289308		[learning rate: 0.01616]
	Learning Rate: 0.0161603
	LOSS [training: 0.1364566842289308 | validation: 0.11397683166370363]
	TIME [epoch: 8.36 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08413943626983587		[learning rate: 0.016147]
	Learning Rate: 0.0161473
	LOSS [training: 0.08413943626983587 | validation: 0.15371664600627918]
	TIME [epoch: 8.33 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09885049089223724		[learning rate: 0.016134]
	Learning Rate: 0.0161343
	LOSS [training: 0.09885049089223724 | validation: 0.09339229273447144]
	TIME [epoch: 8.34 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10071399040682004		[learning rate: 0.016121]
	Learning Rate: 0.0161212
	LOSS [training: 0.10071399040682004 | validation: 0.08150953402816993]
	TIME [epoch: 8.33 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09512561986169873		[learning rate: 0.016108]
	Learning Rate: 0.0161081
	LOSS [training: 0.09512561986169873 | validation: 0.13390705866576888]
	TIME [epoch: 8.34 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08843048102930262		[learning rate: 0.016095]
	Learning Rate: 0.016095
	LOSS [training: 0.08843048102930262 | validation: 0.07463629952143833]
	TIME [epoch: 8.35 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07826116248091565		[learning rate: 0.016082]
	Learning Rate: 0.0160819
	LOSS [training: 0.07826116248091565 | validation: 0.15100577017473504]
	TIME [epoch: 8.37 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12436467210258421		[learning rate: 0.016069]
	Learning Rate: 0.0160688
	LOSS [training: 0.12436467210258421 | validation: 0.09222753477998313]
	TIME [epoch: 8.33 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08569725439632334		[learning rate: 0.016056]
	Learning Rate: 0.0160556
	LOSS [training: 0.08569725439632334 | validation: 0.10486453754034594]
	TIME [epoch: 8.34 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09870114726020607		[learning rate: 0.016042]
	Learning Rate: 0.0160425
	LOSS [training: 0.09870114726020607 | validation: 0.10204648059981988]
	TIME [epoch: 8.33 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07929806596827547		[learning rate: 0.016029]
	Learning Rate: 0.0160293
	LOSS [training: 0.07929806596827547 | validation: 0.10690599767822248]
	TIME [epoch: 8.34 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10576383618664036		[learning rate: 0.016016]
	Learning Rate: 0.0160161
	LOSS [training: 0.10576383618664036 | validation: 0.12066455137297352]
	TIME [epoch: 8.38 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12357210762212208		[learning rate: 0.016003]
	Learning Rate: 0.0160029
	LOSS [training: 0.12357210762212208 | validation: 0.11752544808053939]
	TIME [epoch: 8.33 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07634441414618634		[learning rate: 0.01599]
	Learning Rate: 0.0159897
	LOSS [training: 0.07634441414618634 | validation: 0.06182118917023016]
	TIME [epoch: 8.33 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09000769958189471		[learning rate: 0.015976]
	Learning Rate: 0.0159764
	LOSS [training: 0.09000769958189471 | validation: 0.14652471197768288]
	TIME [epoch: 8.33 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11092633975272845		[learning rate: 0.015963]
	Learning Rate: 0.0159632
	LOSS [training: 0.11092633975272845 | validation: 0.10728903722469116]
	TIME [epoch: 8.32 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11731185832347324		[learning rate: 0.01595]
	Learning Rate: 0.0159499
	LOSS [training: 0.11731185832347324 | validation: 0.10702455193742325]
	TIME [epoch: 8.36 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09157305950875208		[learning rate: 0.015937]
	Learning Rate: 0.0159366
	LOSS [training: 0.09157305950875208 | validation: 0.06293573225669927]
	TIME [epoch: 8.38 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22095357924093145		[learning rate: 0.015923]
	Learning Rate: 0.0159233
	LOSS [training: 0.22095357924093145 | validation: 0.13291299341505633]
	TIME [epoch: 8.33 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13095092097301386		[learning rate: 0.01591]
	Learning Rate: 0.01591
	LOSS [training: 0.13095092097301386 | validation: 0.10641951557376989]
	TIME [epoch: 8.33 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0915022636735997		[learning rate: 0.015897]
	Learning Rate: 0.0158966
	LOSS [training: 0.0915022636735997 | validation: 0.08358277577979825]
	TIME [epoch: 8.34 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08294198653495385		[learning rate: 0.015883]
	Learning Rate: 0.0158833
	LOSS [training: 0.08294198653495385 | validation: 0.07768027027356295]
	TIME [epoch: 8.36 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06208280227936165		[learning rate: 0.01587]
	Learning Rate: 0.0158699
	LOSS [training: 0.06208280227936165 | validation: 0.12103579576679471]
	TIME [epoch: 8.38 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07626455598123016		[learning rate: 0.015856]
	Learning Rate: 0.0158565
	LOSS [training: 0.07626455598123016 | validation: 0.0983029623832436]
	TIME [epoch: 8.35 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11692495041739923		[learning rate: 0.015843]
	Learning Rate: 0.0158431
	LOSS [training: 0.11692495041739923 | validation: 0.12809370336264242]
	TIME [epoch: 8.34 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07664059219996487		[learning rate: 0.01583]
	Learning Rate: 0.0158297
	LOSS [training: 0.07664059219996487 | validation: 0.07783342703058987]
	TIME [epoch: 8.34 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06689185940644887		[learning rate: 0.015816]
	Learning Rate: 0.0158162
	LOSS [training: 0.06689185940644887 | validation: 0.10540849506537767]
	TIME [epoch: 8.34 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10521975964485913		[learning rate: 0.015803]
	Learning Rate: 0.0158028
	LOSS [training: 0.10521975964485913 | validation: 0.10470422320241549]
	TIME [epoch: 8.34 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10900983670638814		[learning rate: 0.015789]
	Learning Rate: 0.0157893
	LOSS [training: 0.10900983670638814 | validation: 0.15771431282792975]
	TIME [epoch: 8.39 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10072270704984153		[learning rate: 0.015776]
	Learning Rate: 0.0157758
	LOSS [training: 0.10072270704984153 | validation: 0.1295257346730858]
	TIME [epoch: 8.33 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08063700135359622		[learning rate: 0.015762]
	Learning Rate: 0.0157623
	LOSS [training: 0.08063700135359622 | validation: 0.14169318872929076]
	TIME [epoch: 8.34 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10992165358436319		[learning rate: 0.015749]
	Learning Rate: 0.0157488
	LOSS [training: 0.10992165358436319 | validation: 0.10707683828063899]
	TIME [epoch: 8.34 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09114268538802728		[learning rate: 0.015735]
	Learning Rate: 0.0157353
	LOSS [training: 0.09114268538802728 | validation: 0.09117543614919077]
	TIME [epoch: 8.33 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08335592486485205		[learning rate: 0.015722]
	Learning Rate: 0.0157217
	LOSS [training: 0.08335592486485205 | validation: 0.08827774299946428]
	TIME [epoch: 8.38 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0886257556451717		[learning rate: 0.015708]
	Learning Rate: 0.0157082
	LOSS [training: 0.0886257556451717 | validation: 0.1145858834313085]
	TIME [epoch: 8.35 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10900020841092542		[learning rate: 0.015695]
	Learning Rate: 0.0156946
	LOSS [training: 0.10900020841092542 | validation: 0.08679439395164906]
	TIME [epoch: 8.34 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0736917384266107		[learning rate: 0.015681]
	Learning Rate: 0.015681
	LOSS [training: 0.0736917384266107 | validation: 0.10608467926472824]
	TIME [epoch: 8.33 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06792873087894001		[learning rate: 0.015667]
	Learning Rate: 0.0156674
	LOSS [training: 0.06792873087894001 | validation: 0.08419563935598309]
	TIME [epoch: 8.33 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0981969189986692		[learning rate: 0.015654]
	Learning Rate: 0.0156537
	LOSS [training: 0.0981969189986692 | validation: 0.10858921631464531]
	TIME [epoch: 8.34 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1822588724159392		[learning rate: 0.01564]
	Learning Rate: 0.0156401
	LOSS [training: 0.1822588724159392 | validation: 0.14654817726434705]
	TIME [epoch: 8.37 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12105593141312257		[learning rate: 0.015626]
	Learning Rate: 0.0156264
	LOSS [training: 0.12105593141312257 | validation: 0.046536667533257935]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_639.pth
	Model improved!!!
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06595390636963086		[learning rate: 0.015613]
	Learning Rate: 0.0156128
	LOSS [training: 0.06595390636963086 | validation: 0.07470931439329931]
	TIME [epoch: 8.33 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08105380068710949		[learning rate: 0.015599]
	Learning Rate: 0.0155991
	LOSS [training: 0.08105380068710949 | validation: 0.09303405662263184]
	TIME [epoch: 8.33 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07016920377687617		[learning rate: 0.015585]
	Learning Rate: 0.0155854
	LOSS [training: 0.07016920377687617 | validation: 0.057104224515427966]
	TIME [epoch: 8.32 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06849648015585699		[learning rate: 0.015572]
	Learning Rate: 0.0155717
	LOSS [training: 0.06849648015585699 | validation: 0.1005536721411453]
	TIME [epoch: 8.37 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08651754464090229		[learning rate: 0.015558]
	Learning Rate: 0.0155579
	LOSS [training: 0.08651754464090229 | validation: 0.039364635444336805]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_644.pth
	Model improved!!!
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0617241690101756		[learning rate: 0.015544]
	Learning Rate: 0.0155442
	LOSS [training: 0.0617241690101756 | validation: 0.05316016591785766]
	TIME [epoch: 8.32 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11726512587001986		[learning rate: 0.01553]
	Learning Rate: 0.0155304
	LOSS [training: 0.11726512587001986 | validation: 0.06715848263635471]
	TIME [epoch: 8.33 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09105317541339354		[learning rate: 0.015517]
	Learning Rate: 0.0155166
	LOSS [training: 0.09105317541339354 | validation: 0.11946392804828429]
	TIME [epoch: 8.34 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09270414508474865		[learning rate: 0.015503]
	Learning Rate: 0.0155028
	LOSS [training: 0.09270414508474865 | validation: 0.1896747272783174]
	TIME [epoch: 8.35 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09682232795544479		[learning rate: 0.015489]
	Learning Rate: 0.015489
	LOSS [training: 0.09682232795544479 | validation: 0.12065359395031933]
	TIME [epoch: 8.36 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09655667738069215		[learning rate: 0.015475]
	Learning Rate: 0.0154752
	LOSS [training: 0.09655667738069215 | validation: 0.06885223981644722]
	TIME [epoch: 8.32 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09054178303617835		[learning rate: 0.015461]
	Learning Rate: 0.0154614
	LOSS [training: 0.09054178303617835 | validation: 0.07515606591012161]
	TIME [epoch: 8.32 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09464374608502965		[learning rate: 0.015448]
	Learning Rate: 0.0154475
	LOSS [training: 0.09464374608502965 | validation: 0.04785344402921579]
	TIME [epoch: 8.42 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06852495542291279		[learning rate: 0.015434]
	Learning Rate: 0.0154336
	LOSS [training: 0.06852495542291279 | validation: 0.07702884833282819]
	TIME [epoch: 8.32 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07226993568781934		[learning rate: 0.01542]
	Learning Rate: 0.0154198
	LOSS [training: 0.07226993568781934 | validation: 0.07459075926509769]
	TIME [epoch: 8.36 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09016299568015723		[learning rate: 0.015406]
	Learning Rate: 0.0154059
	LOSS [training: 0.09016299568015723 | validation: 0.04760410890563473]
	TIME [epoch: 8.32 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12514194041092275		[learning rate: 0.015392]
	Learning Rate: 0.0153919
	LOSS [training: 0.12514194041092275 | validation: 0.12781816509374494]
	TIME [epoch: 8.31 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09775225061619444		[learning rate: 0.015378]
	Learning Rate: 0.015378
	LOSS [training: 0.09775225061619444 | validation: 0.12430330988505114]
	TIME [epoch: 8.32 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0861420904000888		[learning rate: 0.015364]
	Learning Rate: 0.0153641
	LOSS [training: 0.0861420904000888 | validation: 0.06812371566800832]
	TIME [epoch: 8.32 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06260962217673999		[learning rate: 0.01535]
	Learning Rate: 0.0153501
	LOSS [training: 0.06260962217673999 | validation: 0.08105542024638339]
	TIME [epoch: 8.32 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0818039827092939		[learning rate: 0.015336]
	Learning Rate: 0.0153361
	LOSS [training: 0.0818039827092939 | validation: 0.08511795957411172]
	TIME [epoch: 8.37 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08345204541367951		[learning rate: 0.015322]
	Learning Rate: 0.0153222
	LOSS [training: 0.08345204541367951 | validation: 0.08744079366715846]
	TIME [epoch: 8.33 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.115279128635179		[learning rate: 0.015308]
	Learning Rate: 0.0153082
	LOSS [training: 0.115279128635179 | validation: 0.12428393414691935]
	TIME [epoch: 8.33 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0664596051001317		[learning rate: 0.015294]
	Learning Rate: 0.0152941
	LOSS [training: 0.0664596051001317 | validation: 0.13323373281980946]
	TIME [epoch: 8.32 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11210932221395885		[learning rate: 0.01528]
	Learning Rate: 0.0152801
	LOSS [training: 0.11210932221395885 | validation: 0.0910520067499529]
	TIME [epoch: 8.33 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09659439988673381		[learning rate: 0.015266]
	Learning Rate: 0.0152661
	LOSS [training: 0.09659439988673381 | validation: 0.06393306448143746]
	TIME [epoch: 8.37 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0634519040920122		[learning rate: 0.015252]
	Learning Rate: 0.015252
	LOSS [training: 0.0634519040920122 | validation: 0.05588000910919837]
	TIME [epoch: 8.33 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0704077169534135		[learning rate: 0.015238]
	Learning Rate: 0.0152379
	LOSS [training: 0.0704077169534135 | validation: 0.06733319161575002]
	TIME [epoch: 8.33 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09927697154184567		[learning rate: 0.015224]
	Learning Rate: 0.0152238
	LOSS [training: 0.09927697154184567 | validation: 0.07253482522594171]
	TIME [epoch: 8.32 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09389203486987123		[learning rate: 0.01521]
	Learning Rate: 0.0152097
	LOSS [training: 0.09389203486987123 | validation: 0.06034459536221079]
	TIME [epoch: 8.32 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06427984284309163		[learning rate: 0.015196]
	Learning Rate: 0.0151956
	LOSS [training: 0.06427984284309163 | validation: 0.07143767507957091]
	TIME [epoch: 8.33 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11178364646132335		[learning rate: 0.015182]
	Learning Rate: 0.0151815
	LOSS [training: 0.11178364646132335 | validation: 0.10079178178898121]
	TIME [epoch: 8.37 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07969918998109998		[learning rate: 0.015167]
	Learning Rate: 0.0151674
	LOSS [training: 0.07969918998109998 | validation: 0.06124429364923254]
	TIME [epoch: 8.33 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07030063503338627		[learning rate: 0.015153]
	Learning Rate: 0.0151532
	LOSS [training: 0.07030063503338627 | validation: 0.09104210088432692]
	TIME [epoch: 8.33 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08691700594789649		[learning rate: 0.015139]
	Learning Rate: 0.015139
	LOSS [training: 0.08691700594789649 | validation: 0.07252925414017769]
	TIME [epoch: 8.32 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07627636652183496		[learning rate: 0.015125]
	Learning Rate: 0.0151248
	LOSS [training: 0.07627636652183496 | validation: 0.10197895759425976]
	TIME [epoch: 8.32 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06552827017033382		[learning rate: 0.015111]
	Learning Rate: 0.0151106
	LOSS [training: 0.06552827017033382 | validation: 0.049026506687681735]
	TIME [epoch: 8.35 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06676626361907995		[learning rate: 0.015096]
	Learning Rate: 0.0150964
	LOSS [training: 0.06676626361907995 | validation: 0.07005403422335404]
	TIME [epoch: 8.33 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07372186169030817		[learning rate: 0.015082]
	Learning Rate: 0.0150822
	LOSS [training: 0.07372186169030817 | validation: 0.08338173805546426]
	TIME [epoch: 8.33 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09338904837135376		[learning rate: 0.015068]
	Learning Rate: 0.015068
	LOSS [training: 0.09338904837135376 | validation: 0.12563722663405275]
	TIME [epoch: 8.33 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16703181925873367		[learning rate: 0.015054]
	Learning Rate: 0.0150537
	LOSS [training: 0.16703181925873367 | validation: 0.08874512673925905]
	TIME [epoch: 8.33 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07235188784938494		[learning rate: 0.015039]
	Learning Rate: 0.0150394
	LOSS [training: 0.07235188784938494 | validation: 0.061581625018201185]
	TIME [epoch: 8.35 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06619718144528923		[learning rate: 0.015025]
	Learning Rate: 0.0150251
	LOSS [training: 0.06619718144528923 | validation: 0.10843025927557648]
	TIME [epoch: 8.37 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07451539702496447		[learning rate: 0.015011]
	Learning Rate: 0.0150108
	LOSS [training: 0.07451539702496447 | validation: 0.057458434932677244]
	TIME [epoch: 8.33 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06273263366427573		[learning rate: 0.014997]
	Learning Rate: 0.0149965
	LOSS [training: 0.06273263366427573 | validation: 0.07726986557599116]
	TIME [epoch: 8.33 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07448209363378938		[learning rate: 0.014982]
	Learning Rate: 0.0149822
	LOSS [training: 0.07448209363378938 | validation: 0.04802725294182867]
	TIME [epoch: 8.32 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07849716357942944		[learning rate: 0.014968]
	Learning Rate: 0.0149679
	LOSS [training: 0.07849716357942944 | validation: 0.07622915974396528]
	TIME [epoch: 8.33 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08339082217900282		[learning rate: 0.014954]
	Learning Rate: 0.0149535
	LOSS [training: 0.08339082217900282 | validation: 0.07342007522492414]
	TIME [epoch: 8.35 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07423334105929605		[learning rate: 0.014939]
	Learning Rate: 0.0149392
	LOSS [training: 0.07423334105929605 | validation: 0.0812504406102422]
	TIME [epoch: 8.34 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07287036455176397		[learning rate: 0.014925]
	Learning Rate: 0.0149248
	LOSS [training: 0.07287036455176397 | validation: 0.06427075128364199]
	TIME [epoch: 8.33 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06907852697663204		[learning rate: 0.01491]
	Learning Rate: 0.0149104
	LOSS [training: 0.06907852697663204 | validation: 0.07395677276433923]
	TIME [epoch: 8.32 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08948716987517687		[learning rate: 0.014896]
	Learning Rate: 0.014896
	LOSS [training: 0.08948716987517687 | validation: 0.05101951729633426]
	TIME [epoch: 8.33 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07842692427834172		[learning rate: 0.014882]
	Learning Rate: 0.0148816
	LOSS [training: 0.07842692427834172 | validation: 0.08210709157188104]
	TIME [epoch: 8.33 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07686155872555966		[learning rate: 0.014867]
	Learning Rate: 0.0148671
	LOSS [training: 0.07686155872555966 | validation: 0.07586719727755596]
	TIME [epoch: 8.37 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05983607674339973		[learning rate: 0.014853]
	Learning Rate: 0.0148527
	LOSS [training: 0.05983607674339973 | validation: 0.04991364403993092]
	TIME [epoch: 8.32 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08425782772581436		[learning rate: 0.014838]
	Learning Rate: 0.0148382
	LOSS [training: 0.08425782772581436 | validation: 0.10543401018580514]
	TIME [epoch: 8.33 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07757371769512864		[learning rate: 0.014824]
	Learning Rate: 0.0148237
	LOSS [training: 0.07757371769512864 | validation: 0.06734294634209943]
	TIME [epoch: 8.33 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07493700574876727		[learning rate: 0.014809]
	Learning Rate: 0.0148093
	LOSS [training: 0.07493700574876727 | validation: 0.0833288918123746]
	TIME [epoch: 8.34 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06714531030595988		[learning rate: 0.014795]
	Learning Rate: 0.0147948
	LOSS [training: 0.06714531030595988 | validation: 0.11920345825646983]
	TIME [epoch: 8.37 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09500523054796271		[learning rate: 0.01478]
	Learning Rate: 0.0147803
	LOSS [training: 0.09500523054796271 | validation: 0.05182323860959881]
	TIME [epoch: 8.34 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06945151471106212		[learning rate: 0.014766]
	Learning Rate: 0.0147657
	LOSS [training: 0.06945151471106212 | validation: 0.08031263592437503]
	TIME [epoch: 8.33 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07055785473328778		[learning rate: 0.014751]
	Learning Rate: 0.0147512
	LOSS [training: 0.07055785473328778 | validation: 0.07391140491651915]
	TIME [epoch: 8.32 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06592221773470508		[learning rate: 0.014737]
	Learning Rate: 0.0147366
	LOSS [training: 0.06592221773470508 | validation: 0.09078318574666128]
	TIME [epoch: 8.32 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07563710811277806		[learning rate: 0.014722]
	Learning Rate: 0.0147221
	LOSS [training: 0.07563710811277806 | validation: 0.07310175561156271]
	TIME [epoch: 8.33 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06427150378805654		[learning rate: 0.014707]
	Learning Rate: 0.0147075
	LOSS [training: 0.06427150378805654 | validation: 0.06452289307030115]
	TIME [epoch: 8.37 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06984791816709453		[learning rate: 0.014693]
	Learning Rate: 0.0146929
	LOSS [training: 0.06984791816709453 | validation: 0.0788413085570637]
	TIME [epoch: 8.32 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09445511218204469		[learning rate: 0.014678]
	Learning Rate: 0.0146783
	LOSS [training: 0.09445511218204469 | validation: 0.14193387583965128]
	TIME [epoch: 8.33 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.146275179513982		[learning rate: 0.014664]
	Learning Rate: 0.0146637
	LOSS [training: 0.146275179513982 | validation: 0.07142694245432893]
	TIME [epoch: 8.32 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07641270130644254		[learning rate: 0.014649]
	Learning Rate: 0.0146491
	LOSS [training: 0.07641270130644254 | validation: 0.06995013800159795]
	TIME [epoch: 8.33 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06781752465895396		[learning rate: 0.014634]
	Learning Rate: 0.0146344
	LOSS [training: 0.06781752465895396 | validation: 0.0489351329252471]
	TIME [epoch: 8.36 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06752416759785675		[learning rate: 0.01462]
	Learning Rate: 0.0146198
	LOSS [training: 0.06752416759785675 | validation: 0.05462644392578085]
	TIME [epoch: 8.34 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0597905587203354		[learning rate: 0.014605]
	Learning Rate: 0.0146051
	LOSS [training: 0.0597905587203354 | validation: 0.07919292910133643]
	TIME [epoch: 8.33 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08871514161678896		[learning rate: 0.01459]
	Learning Rate: 0.0145904
	LOSS [training: 0.08871514161678896 | validation: 0.05517934360724926]
	TIME [epoch: 8.33 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049780448437936706		[learning rate: 0.014576]
	Learning Rate: 0.0145757
	LOSS [training: 0.049780448437936706 | validation: 0.05693288406909193]
	TIME [epoch: 8.33 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06034162209432774		[learning rate: 0.014561]
	Learning Rate: 0.014561
	LOSS [training: 0.06034162209432774 | validation: 0.09143030132764667]
	TIME [epoch: 8.33 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08259882307600011		[learning rate: 0.014546]
	Learning Rate: 0.0145463
	LOSS [training: 0.08259882307600011 | validation: 0.06571471420467376]
	TIME [epoch: 8.37 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14037570344646685		[learning rate: 0.014532]
	Learning Rate: 0.0145316
	LOSS [training: 0.14037570344646685 | validation: 0.10939521102358585]
	TIME [epoch: 8.32 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06981036789052414		[learning rate: 0.014517]
	Learning Rate: 0.0145168
	LOSS [training: 0.06981036789052414 | validation: 0.04805644362790319]
	TIME [epoch: 8.33 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06611287111157932		[learning rate: 0.014502]
	Learning Rate: 0.0145021
	LOSS [training: 0.06611287111157932 | validation: 0.07188801433110317]
	TIME [epoch: 8.33 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1951068540014904		[learning rate: 0.014487]
	Learning Rate: 0.0144873
	LOSS [training: 0.1951068540014904 | validation: 0.1926762150005636]
	TIME [epoch: 8.31 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1789930852562021		[learning rate: 0.014473]
	Learning Rate: 0.0144726
	LOSS [training: 0.1789930852562021 | validation: 0.041283738338814144]
	TIME [epoch: 8.34 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07686248152795548		[learning rate: 0.014458]
	Learning Rate: 0.0144578
	LOSS [training: 0.07686248152795548 | validation: 0.04265183258302045]
	TIME [epoch: 8.35 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05900736378429132		[learning rate: 0.014443]
	Learning Rate: 0.014443
	LOSS [training: 0.05900736378429132 | validation: 0.06329571814521105]
	TIME [epoch: 8.31 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0659466225338583		[learning rate: 0.014428]
	Learning Rate: 0.0144281
	LOSS [training: 0.0659466225338583 | validation: 0.0625089859808463]
	TIME [epoch: 8.32 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058666993256763084		[learning rate: 0.014413]
	Learning Rate: 0.0144133
	LOSS [training: 0.058666993256763084 | validation: 0.09318625752030245]
	TIME [epoch: 8.32 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06455663264031149		[learning rate: 0.014398]
	Learning Rate: 0.0143985
	LOSS [training: 0.06455663264031149 | validation: 0.06789302538857005]
	TIME [epoch: 8.32 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05983009307442925		[learning rate: 0.014384]
	Learning Rate: 0.0143836
	LOSS [training: 0.05983009307442925 | validation: 0.045652534364185135]
	TIME [epoch: 8.38 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12373306417259176		[learning rate: 0.014369]
	Learning Rate: 0.0143688
	LOSS [training: 0.12373306417259176 | validation: 0.12356642160309123]
	TIME [epoch: 8.32 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07835526314008157		[learning rate: 0.014354]
	Learning Rate: 0.0143539
	LOSS [training: 0.07835526314008157 | validation: 0.040189000661713076]
	TIME [epoch: 8.33 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07018254367595111		[learning rate: 0.014339]
	Learning Rate: 0.014339
	LOSS [training: 0.07018254367595111 | validation: 0.07050825777921366]
	TIME [epoch: 8.32 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06708647706216238		[learning rate: 0.014324]
	Learning Rate: 0.0143241
	LOSS [training: 0.06708647706216238 | validation: 0.056868401770241495]
	TIME [epoch: 8.33 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06080730100599556		[learning rate: 0.014309]
	Learning Rate: 0.0143092
	LOSS [training: 0.06080730100599556 | validation: 0.06596880485252182]
	TIME [epoch: 8.35 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09138002726352323		[learning rate: 0.014294]
	Learning Rate: 0.0142943
	LOSS [training: 0.09138002726352323 | validation: 0.05686824341060434]
	TIME [epoch: 8.37 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05513608647211493		[learning rate: 0.014279]
	Learning Rate: 0.0142793
	LOSS [training: 0.05513608647211493 | validation: 0.055507235378962405]
	TIME [epoch: 8.33 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06060336314533864		[learning rate: 0.014264]
	Learning Rate: 0.0142644
	LOSS [training: 0.06060336314533864 | validation: 0.09586784336653785]
	TIME [epoch: 8.32 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07248986625114218		[learning rate: 0.014249]
	Learning Rate: 0.0142494
	LOSS [training: 0.07248986625114218 | validation: 0.08017519350531058]
	TIME [epoch: 8.32 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05466205014086285		[learning rate: 0.014234]
	Learning Rate: 0.0142345
	LOSS [training: 0.05466205014086285 | validation: 0.05532660149114152]
	TIME [epoch: 8.32 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06144413915663709		[learning rate: 0.014219]
	Learning Rate: 0.0142195
	LOSS [training: 0.06144413915663709 | validation: 0.06741259819257873]
	TIME [epoch: 8.36 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10036177403201235		[learning rate: 0.014205]
	Learning Rate: 0.0142045
	LOSS [training: 0.10036177403201235 | validation: 0.06578713100321887]
	TIME [epoch: 8.32 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07774504403068382		[learning rate: 0.01419]
	Learning Rate: 0.0141895
	LOSS [training: 0.07774504403068382 | validation: 0.05883382554772231]
	TIME [epoch: 8.32 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07944924659214794		[learning rate: 0.014174]
	Learning Rate: 0.0141745
	LOSS [training: 0.07944924659214794 | validation: 0.0777679511082708]
	TIME [epoch: 8.31 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0690577427394238		[learning rate: 0.014159]
	Learning Rate: 0.0141595
	LOSS [training: 0.0690577427394238 | validation: 0.06379066717516621]
	TIME [epoch: 8.32 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06287420854121997		[learning rate: 0.014144]
	Learning Rate: 0.0141444
	LOSS [training: 0.06287420854121997 | validation: 0.0629830717645368]
	TIME [epoch: 8.33 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07851891562188011		[learning rate: 0.014129]
	Learning Rate: 0.0141294
	LOSS [training: 0.07851891562188011 | validation: 0.11739298576053257]
	TIME [epoch: 8.35 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07538434938451356		[learning rate: 0.014114]
	Learning Rate: 0.0141143
	LOSS [training: 0.07538434938451356 | validation: 0.08021327238624035]
	TIME [epoch: 8.31 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06629526529795784		[learning rate: 0.014099]
	Learning Rate: 0.0140992
	LOSS [training: 0.06629526529795784 | validation: 0.06774167474360347]
	TIME [epoch: 8.32 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05560315352152275		[learning rate: 0.014084]
	Learning Rate: 0.0140842
	LOSS [training: 0.05560315352152275 | validation: 0.08271537379150809]
	TIME [epoch: 8.32 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06489192085847434		[learning rate: 0.014069]
	Learning Rate: 0.0140691
	LOSS [training: 0.06489192085847434 | validation: 0.07773717389676509]
	TIME [epoch: 8.33 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08661118810318881		[learning rate: 0.014054]
	Learning Rate: 0.014054
	LOSS [training: 0.08661118810318881 | validation: 0.08144509595439584]
	TIME [epoch: 8.37 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07239502150337414		[learning rate: 0.014039]
	Learning Rate: 0.0140389
	LOSS [training: 0.07239502150337414 | validation: 0.06051656650598168]
	TIME [epoch: 8.33 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04748548738520634		[learning rate: 0.014024]
	Learning Rate: 0.0140237
	LOSS [training: 0.04748548738520634 | validation: 0.08662503084072568]
	TIME [epoch: 8.32 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1340929524406812		[learning rate: 0.014009]
	Learning Rate: 0.0140086
	LOSS [training: 0.1340929524406812 | validation: 0.05280166828769924]
	TIME [epoch: 8.32 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03434898170124615		[learning rate: 0.013993]
	Learning Rate: 0.0139934
	LOSS [training: 0.03434898170124615 | validation: 0.06732229343765153]
	TIME [epoch: 8.32 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06446688265118772		[learning rate: 0.013978]
	Learning Rate: 0.0139783
	LOSS [training: 0.06446688265118772 | validation: 0.09501925560186493]
	TIME [epoch: 8.32 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09928835897110741		[learning rate: 0.013963]
	Learning Rate: 0.0139631
	LOSS [training: 0.09928835897110741 | validation: 0.0423309799787851]
	TIME [epoch: 8.37 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048770154654605394		[learning rate: 0.013948]
	Learning Rate: 0.0139479
	LOSS [training: 0.048770154654605394 | validation: 0.05250613207915596]
	TIME [epoch: 8.31 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06954977885478998		[learning rate: 0.013933]
	Learning Rate: 0.0139327
	LOSS [training: 0.06954977885478998 | validation: 0.08907229339462461]
	TIME [epoch: 8.31 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07319836684895253		[learning rate: 0.013918]
	Learning Rate: 0.0139175
	LOSS [training: 0.07319836684895253 | validation: 0.07711903178980098]
	TIME [epoch: 8.31 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0933958673418067		[learning rate: 0.013902]
	Learning Rate: 0.0139023
	LOSS [training: 0.0933958673418067 | validation: 0.10172581473905863]
	TIME [epoch: 8.31 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06150268161013216		[learning rate: 0.013887]
	Learning Rate: 0.0138871
	LOSS [training: 0.06150268161013216 | validation: 0.050653199241733914]
	TIME [epoch: 8.35 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05220349749897123		[learning rate: 0.013872]
	Learning Rate: 0.0138719
	LOSS [training: 0.05220349749897123 | validation: 0.09651114569837074]
	TIME [epoch: 8.32 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0740025444968118		[learning rate: 0.013857]
	Learning Rate: 0.0138566
	LOSS [training: 0.0740025444968118 | validation: 0.07863193208040163]
	TIME [epoch: 8.31 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07093131095998656		[learning rate: 0.013841]
	Learning Rate: 0.0138414
	LOSS [training: 0.07093131095998656 | validation: 0.05301211434074979]
	TIME [epoch: 8.31 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057587058386997375		[learning rate: 0.013826]
	Learning Rate: 0.0138261
	LOSS [training: 0.057587058386997375 | validation: 0.06866495927512331]
	TIME [epoch: 8.32 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09080237943294066		[learning rate: 0.013811]
	Learning Rate: 0.0138108
	LOSS [training: 0.09080237943294066 | validation: 0.05426013145803877]
	TIME [epoch: 8.39 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05295892169282532		[learning rate: 0.013796]
	Learning Rate: 0.0137955
	LOSS [training: 0.05295892169282532 | validation: 0.06732305430597836]
	TIME [epoch: 8.36 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06073121449096694		[learning rate: 0.01378]
	Learning Rate: 0.0137802
	LOSS [training: 0.06073121449096694 | validation: 0.06356807137335851]
	TIME [epoch: 8.32 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059119698324815825		[learning rate: 0.013765]
	Learning Rate: 0.0137649
	LOSS [training: 0.059119698324815825 | validation: 0.04710935868849819]
	TIME [epoch: 8.32 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05228405546746751		[learning rate: 0.01375]
	Learning Rate: 0.0137496
	LOSS [training: 0.05228405546746751 | validation: 0.06164933003340327]
	TIME [epoch: 8.32 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09003938504046738		[learning rate: 0.013734]
	Learning Rate: 0.0137343
	LOSS [training: 0.09003938504046738 | validation: 0.08995999722455039]
	TIME [epoch: 8.31 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10036437008440446		[learning rate: 0.013719]
	Learning Rate: 0.013719
	LOSS [training: 0.10036437008440446 | validation: 0.11384053791789572]
	TIME [epoch: 8.35 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07552141110652537		[learning rate: 0.013704]
	Learning Rate: 0.0137036
	LOSS [training: 0.07552141110652537 | validation: 0.0543463148894901]
	TIME [epoch: 8.32 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0576721841942234		[learning rate: 0.013688]
	Learning Rate: 0.0136882
	LOSS [training: 0.0576721841942234 | validation: 0.06992339441376653]
	TIME [epoch: 8.31 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05195187802354952		[learning rate: 0.013673]
	Learning Rate: 0.0136729
	LOSS [training: 0.05195187802354952 | validation: 0.05261833328396749]
	TIME [epoch: 8.32 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05580593168831189		[learning rate: 0.013657]
	Learning Rate: 0.0136575
	LOSS [training: 0.05580593168831189 | validation: 0.058143628359606736]
	TIME [epoch: 8.31 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059507307093921366		[learning rate: 0.013642]
	Learning Rate: 0.0136421
	LOSS [training: 0.059507307093921366 | validation: 0.05490449955608888]
	TIME [epoch: 8.32 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05934154091952455		[learning rate: 0.013627]
	Learning Rate: 0.0136267
	LOSS [training: 0.05934154091952455 | validation: 0.09540752553551625]
	TIME [epoch: 8.36 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09752841642995161		[learning rate: 0.013611]
	Learning Rate: 0.0136113
	LOSS [training: 0.09752841642995161 | validation: 0.03913750742274337]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_777.pth
	Model improved!!!
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04677722339434813		[learning rate: 0.013596]
	Learning Rate: 0.0135959
	LOSS [training: 0.04677722339434813 | validation: 0.06320718270538665]
	TIME [epoch: 8.31 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05206122043828096		[learning rate: 0.01358]
	Learning Rate: 0.0135805
	LOSS [training: 0.05206122043828096 | validation: 0.05028005153502378]
	TIME [epoch: 8.32 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0642910105514354		[learning rate: 0.013565]
	Learning Rate: 0.013565
	LOSS [training: 0.0642910105514354 | validation: 0.05530257627028533]
	TIME [epoch: 8.32 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0665447975098052		[learning rate: 0.01355]
	Learning Rate: 0.0135496
	LOSS [training: 0.0665447975098052 | validation: 0.04848167392978266]
	TIME [epoch: 8.34 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06296182319141587		[learning rate: 0.013534]
	Learning Rate: 0.0135341
	LOSS [training: 0.06296182319141587 | validation: 0.06666842550759974]
	TIME [epoch: 8.33 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054629392341102354		[learning rate: 0.013519]
	Learning Rate: 0.0135186
	LOSS [training: 0.054629392341102354 | validation: 0.065752965522771]
	TIME [epoch: 8.32 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05926854500058421		[learning rate: 0.013503]
	Learning Rate: 0.0135032
	LOSS [training: 0.05926854500058421 | validation: 0.04130696302280425]
	TIME [epoch: 8.32 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06265778813267224		[learning rate: 0.013488]
	Learning Rate: 0.0134877
	LOSS [training: 0.06265778813267224 | validation: 0.09060604985391812]
	TIME [epoch: 8.3 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0621256846591499		[learning rate: 0.013472]
	Learning Rate: 0.0134722
	LOSS [training: 0.0621256846591499 | validation: 0.07052216099297041]
	TIME [epoch: 8.31 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062223134206949686		[learning rate: 0.013457]
	Learning Rate: 0.0134567
	LOSS [training: 0.062223134206949686 | validation: 0.056667450342400436]
	TIME [epoch: 8.35 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05799102272638222		[learning rate: 0.013441]
	Learning Rate: 0.0134412
	LOSS [training: 0.05799102272638222 | validation: 0.05314054442481814]
	TIME [epoch: 8.31 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05447882045707897		[learning rate: 0.013426]
	Learning Rate: 0.0134256
	LOSS [training: 0.05447882045707897 | validation: 0.06835926881962877]
	TIME [epoch: 8.3 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06794331932175914		[learning rate: 0.01341]
	Learning Rate: 0.0134101
	LOSS [training: 0.06794331932175914 | validation: 0.04466050693791927]
	TIME [epoch: 8.31 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06054949898993131		[learning rate: 0.013395]
	Learning Rate: 0.0133946
	LOSS [training: 0.06054949898993131 | validation: 0.07058301060906388]
	TIME [epoch: 8.32 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07580756204432165		[learning rate: 0.013379]
	Learning Rate: 0.013379
	LOSS [training: 0.07580756204432165 | validation: 0.0513020225265759]
	TIME [epoch: 8.34 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042572545337970134		[learning rate: 0.013363]
	Learning Rate: 0.0133635
	LOSS [training: 0.042572545337970134 | validation: 0.05462351355674433]
	TIME [epoch: 8.32 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10366491361270444		[learning rate: 0.013348]
	Learning Rate: 0.0133479
	LOSS [training: 0.10366491361270444 | validation: 0.055809939772814135]
	TIME [epoch: 8.31 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04568816942523628		[learning rate: 0.013332]
	Learning Rate: 0.0133323
	LOSS [training: 0.04568816942523628 | validation: 0.08426646034932277]
	TIME [epoch: 8.31 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06296671223794051		[learning rate: 0.013317]
	Learning Rate: 0.0133167
	LOSS [training: 0.06296671223794051 | validation: 0.06954749169877773]
	TIME [epoch: 8.31 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05242060695991853		[learning rate: 0.013301]
	Learning Rate: 0.0133011
	LOSS [training: 0.05242060695991853 | validation: 0.05202580172084765]
	TIME [epoch: 8.32 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061811830881424126		[learning rate: 0.013286]
	Learning Rate: 0.0132855
	LOSS [training: 0.061811830881424126 | validation: 0.08426285906473616]
	TIME [epoch: 8.36 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07906678713119676		[learning rate: 0.01327]
	Learning Rate: 0.0132699
	LOSS [training: 0.07906678713119676 | validation: 0.03724027918308087]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_799.pth
	Model improved!!!
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0425551283604228		[learning rate: 0.013254]
	Learning Rate: 0.0132543
	LOSS [training: 0.0425551283604228 | validation: 0.06658040559023301]
	TIME [epoch: 8.32 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06508260561241087		[learning rate: 0.013239]
	Learning Rate: 0.0132386
	LOSS [training: 0.06508260561241087 | validation: 0.056083873779467136]
	TIME [epoch: 8.31 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05046396275693955		[learning rate: 0.013223]
	Learning Rate: 0.013223
	LOSS [training: 0.05046396275693955 | validation: 0.04357666072578009]
	TIME [epoch: 8.3 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04885242719823496		[learning rate: 0.013207]
	Learning Rate: 0.0132074
	LOSS [training: 0.04885242719823496 | validation: 0.043674297909858495]
	TIME [epoch: 8.35 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06583682990497214		[learning rate: 0.013192]
	Learning Rate: 0.0131917
	LOSS [training: 0.06583682990497214 | validation: 0.09494202917228681]
	TIME [epoch: 8.33 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0728510516822695		[learning rate: 0.013176]
	Learning Rate: 0.013176
	LOSS [training: 0.0728510516822695 | validation: 0.05226144400775001]
	TIME [epoch: 8.31 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04894147742492504		[learning rate: 0.01316]
	Learning Rate: 0.0131603
	LOSS [training: 0.04894147742492504 | validation: 0.041625897649954335]
	TIME [epoch: 8.31 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05552847103204934		[learning rate: 0.013145]
	Learning Rate: 0.0131447
	LOSS [training: 0.05552847103204934 | validation: 0.07392848685506453]
	TIME [epoch: 8.3 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044276988854867014		[learning rate: 0.013129]
	Learning Rate: 0.013129
	LOSS [training: 0.044276988854867014 | validation: 0.04980593182008369]
	TIME [epoch: 8.32 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053990640776893306		[learning rate: 0.013113]
	Learning Rate: 0.0131133
	LOSS [training: 0.053990640776893306 | validation: 0.039897315826210256]
	TIME [epoch: 8.44 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06642736880154904		[learning rate: 0.013098]
	Learning Rate: 0.0130976
	LOSS [training: 0.06642736880154904 | validation: 0.10076233138098592]
	TIME [epoch: 8.31 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08299822242293826		[learning rate: 0.013082]
	Learning Rate: 0.0130818
	LOSS [training: 0.08299822242293826 | validation: 0.04871161010959824]
	TIME [epoch: 8.31 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056326107564247704		[learning rate: 0.013066]
	Learning Rate: 0.0130661
	LOSS [training: 0.056326107564247704 | validation: 0.05320454925834403]
	TIME [epoch: 8.32 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04666214894394154		[learning rate: 0.01305]
	Learning Rate: 0.0130504
	LOSS [training: 0.04666214894394154 | validation: 0.042842618155206125]
	TIME [epoch: 8.32 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0461570897979442		[learning rate: 0.013035]
	Learning Rate: 0.0130346
	LOSS [training: 0.0461570897979442 | validation: 0.054021280460698]
	TIME [epoch: 8.36 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07722523058328364		[learning rate: 0.013019]
	Learning Rate: 0.0130189
	LOSS [training: 0.07722523058328364 | validation: 0.040664106175409984]
	TIME [epoch: 8.33 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047287263940991614		[learning rate: 0.013003]
	Learning Rate: 0.0130031
	LOSS [training: 0.047287263940991614 | validation: 0.07075689556417433]
	TIME [epoch: 8.32 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11443810153100348		[learning rate: 0.012987]
	Learning Rate: 0.0129873
	LOSS [training: 0.11443810153100348 | validation: 0.033987925057674964]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_817.pth
	Model improved!!!
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03358896804890404		[learning rate: 0.012972]
	Learning Rate: 0.0129716
	LOSS [training: 0.03358896804890404 | validation: 0.04882871119096485]
	TIME [epoch: 8.32 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0562415462922016		[learning rate: 0.012956]
	Learning Rate: 0.0129558
	LOSS [training: 0.0562415462922016 | validation: 0.04171369366378298]
	TIME [epoch: 8.65 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04188970445196719		[learning rate: 0.01294]
	Learning Rate: 0.01294
	LOSS [training: 0.04188970445196719 | validation: 0.05711747490503756]
	TIME [epoch: 8.37 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05974633364797924		[learning rate: 0.012924]
	Learning Rate: 0.0129242
	LOSS [training: 0.05974633364797924 | validation: 0.04999045811896559]
	TIME [epoch: 8.34 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04708258438233286		[learning rate: 0.012908]
	Learning Rate: 0.0129084
	LOSS [training: 0.04708258438233286 | validation: 0.04241660678879988]
	TIME [epoch: 8.33 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0697144905469067		[learning rate: 0.012893]
	Learning Rate: 0.0128926
	LOSS [training: 0.0697144905469067 | validation: 0.039717609575805154]
	TIME [epoch: 8.33 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04964661646032109		[learning rate: 0.012877]
	Learning Rate: 0.0128767
	LOSS [training: 0.04964661646032109 | validation: 0.05323537758601088]
	TIME [epoch: 8.33 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05548622065903336		[learning rate: 0.012861]
	Learning Rate: 0.0128609
	LOSS [training: 0.05548622065903336 | validation: 0.05469212157398633]
	TIME [epoch: 8.37 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045485179350013054		[learning rate: 0.012845]
	Learning Rate: 0.0128451
	LOSS [training: 0.045485179350013054 | validation: 0.0468109856067859]
	TIME [epoch: 8.35 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0724927555553376		[learning rate: 0.012829]
	Learning Rate: 0.0128292
	LOSS [training: 0.0724927555553376 | validation: 0.043847983542576525]
	TIME [epoch: 8.34 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033834477789746006		[learning rate: 0.012813]
	Learning Rate: 0.0128133
	LOSS [training: 0.033834477789746006 | validation: 0.04393730200839997]
	TIME [epoch: 8.34 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04623494943957563		[learning rate: 0.012797]
	Learning Rate: 0.0127975
	LOSS [training: 0.04623494943957563 | validation: 0.08414733972918412]
	TIME [epoch: 8.34 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05795429295221789		[learning rate: 0.012782]
	Learning Rate: 0.0127816
	LOSS [training: 0.05795429295221789 | validation: 0.03944714509171345]
	TIME [epoch: 8.35 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0727306445163037		[learning rate: 0.012766]
	Learning Rate: 0.0127657
	LOSS [training: 0.0727306445163037 | validation: 0.05598715630897122]
	TIME [epoch: 8.39 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05138725120794284		[learning rate: 0.01275]
	Learning Rate: 0.0127498
	LOSS [training: 0.05138725120794284 | validation: 0.03931691158781542]
	TIME [epoch: 8.34 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04909253128192416		[learning rate: 0.012734]
	Learning Rate: 0.0127339
	LOSS [training: 0.04909253128192416 | validation: 0.05966770418738973]
	TIME [epoch: 8.34 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06089964326726603		[learning rate: 0.012718]
	Learning Rate: 0.012718
	LOSS [training: 0.06089964326726603 | validation: 0.06640334016848003]
	TIME [epoch: 8.33 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05446752327313136		[learning rate: 0.012702]
	Learning Rate: 0.0127021
	LOSS [training: 0.05446752327313136 | validation: 0.04973473001532442]
	TIME [epoch: 8.34 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043905013985724356		[learning rate: 0.012686]
	Learning Rate: 0.0126862
	LOSS [training: 0.043905013985724356 | validation: 0.06247660792055085]
	TIME [epoch: 8.38 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08640878981291616		[learning rate: 0.01267]
	Learning Rate: 0.0126703
	LOSS [training: 0.08640878981291616 | validation: 0.05801867592575245]
	TIME [epoch: 8.35 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046410805570992975		[learning rate: 0.012654]
	Learning Rate: 0.0126544
	LOSS [training: 0.046410805570992975 | validation: 0.05388858346506893]
	TIME [epoch: 8.33 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04513751206410227		[learning rate: 0.012638]
	Learning Rate: 0.0126384
	LOSS [training: 0.04513751206410227 | validation: 0.04262110169908881]
	TIME [epoch: 8.33 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054779796068428324		[learning rate: 0.012622]
	Learning Rate: 0.0126225
	LOSS [training: 0.054779796068428324 | validation: 0.04202083450847939]
	TIME [epoch: 8.33 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04275481318202499		[learning rate: 0.012607]
	Learning Rate: 0.0126065
	LOSS [training: 0.04275481318202499 | validation: 0.07971683437592428]
	TIME [epoch: 8.34 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07304185663641148		[learning rate: 0.012591]
	Learning Rate: 0.0125906
	LOSS [training: 0.07304185663641148 | validation: 0.048189411174103]
	TIME [epoch: 8.38 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04878601234119639		[learning rate: 0.012575]
	Learning Rate: 0.0125746
	LOSS [training: 0.04878601234119639 | validation: 0.054982399647307764]
	TIME [epoch: 8.34 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06188943388226999		[learning rate: 0.012559]
	Learning Rate: 0.0125586
	LOSS [training: 0.06188943388226999 | validation: 0.10817889935294914]
	TIME [epoch: 8.33 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06410374370329834		[learning rate: 0.012543]
	Learning Rate: 0.0125426
	LOSS [training: 0.06410374370329834 | validation: 0.09130630123362049]
	TIME [epoch: 8.33 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06586019555550995		[learning rate: 0.012527]
	Learning Rate: 0.0125267
	LOSS [training: 0.06586019555550995 | validation: 0.03412854786635089]
	TIME [epoch: 8.34 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04693182477714623		[learning rate: 0.012511]
	Learning Rate: 0.0125107
	LOSS [training: 0.04693182477714623 | validation: 0.04689702571046393]
	TIME [epoch: 8.38 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05857856764757097		[learning rate: 0.012495]
	Learning Rate: 0.0124947
	LOSS [training: 0.05857856764757097 | validation: 0.0400840765785191]
	TIME [epoch: 8.36 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04015461608255377		[learning rate: 0.012479]
	Learning Rate: 0.0124786
	LOSS [training: 0.04015461608255377 | validation: 0.060511519554717584]
	TIME [epoch: 8.33 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06801071675784034		[learning rate: 0.012463]
	Learning Rate: 0.0124626
	LOSS [training: 0.06801071675784034 | validation: 0.03466760232996596]
	TIME [epoch: 8.32 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036326919192877234		[learning rate: 0.012447]
	Learning Rate: 0.0124466
	LOSS [training: 0.036326919192877234 | validation: 0.05359756048758543]
	TIME [epoch: 8.33 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05197381438065625		[learning rate: 0.012431]
	Learning Rate: 0.0124306
	LOSS [training: 0.05197381438065625 | validation: 0.037583473575579125]
	TIME [epoch: 8.34 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05149930166713938		[learning rate: 0.012415]
	Learning Rate: 0.0124145
	LOSS [training: 0.05149930166713938 | validation: 0.038371598628342635]
	TIME [epoch: 8.38 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04432400092166005		[learning rate: 0.012399]
	Learning Rate: 0.0123985
	LOSS [training: 0.04432400092166005 | validation: 0.04738013010114275]
	TIME [epoch: 8.33 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04024669000409982		[learning rate: 0.012382]
	Learning Rate: 0.0123825
	LOSS [training: 0.04024669000409982 | validation: 0.04984233052825238]
	TIME [epoch: 8.33 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04802622463391347		[learning rate: 0.012366]
	Learning Rate: 0.0123664
	LOSS [training: 0.04802622463391347 | validation: 0.04329462927742721]
	TIME [epoch: 8.33 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03899904553853698		[learning rate: 0.01235]
	Learning Rate: 0.0123503
	LOSS [training: 0.03899904553853698 | validation: 0.05470765619426886]
	TIME [epoch: 8.33 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053650872527201514		[learning rate: 0.012334]
	Learning Rate: 0.0123343
	LOSS [training: 0.053650872527201514 | validation: 0.0633762963624468]
	TIME [epoch: 8.37 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053120051207447075		[learning rate: 0.012318]
	Learning Rate: 0.0123182
	LOSS [training: 0.053120051207447075 | validation: 0.04204008675171646]
	TIME [epoch: 8.35 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04847174266102294		[learning rate: 0.012302]
	Learning Rate: 0.0123021
	LOSS [training: 0.04847174266102294 | validation: 0.04694764986329492]
	TIME [epoch: 8.33 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0492127787988446		[learning rate: 0.012286]
	Learning Rate: 0.012286
	LOSS [training: 0.0492127787988446 | validation: 0.030432396908259454]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_861.pth
	Model improved!!!
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040943478367574525		[learning rate: 0.01227]
	Learning Rate: 0.0122699
	LOSS [training: 0.040943478367574525 | validation: 0.06569774515998796]
	TIME [epoch: 8.33 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04852324967374797		[learning rate: 0.012254]
	Learning Rate: 0.0122538
	LOSS [training: 0.04852324967374797 | validation: 0.04022638095237298]
	TIME [epoch: 8.33 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040660263756574534		[learning rate: 0.012238]
	Learning Rate: 0.0122377
	LOSS [training: 0.040660263756574534 | validation: 0.10279079999913066]
	TIME [epoch: 8.38 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0827313303924967		[learning rate: 0.012222]
	Learning Rate: 0.0122216
	LOSS [training: 0.0827313303924967 | validation: 0.02510423583640229]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_865.pth
	Model improved!!!
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04142485222992054		[learning rate: 0.012205]
	Learning Rate: 0.0122055
	LOSS [training: 0.04142485222992054 | validation: 0.0530434464532932]
	TIME [epoch: 8.32 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07540687152269254		[learning rate: 0.012189]
	Learning Rate: 0.0121894
	LOSS [training: 0.07540687152269254 | validation: 0.043925416816402926]
	TIME [epoch: 8.32 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03264611414979657		[learning rate: 0.012173]
	Learning Rate: 0.0121732
	LOSS [training: 0.03264611414979657 | validation: 0.02799053305703586]
	TIME [epoch: 8.31 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04136809468459968		[learning rate: 0.012157]
	Learning Rate: 0.0121571
	LOSS [training: 0.04136809468459968 | validation: 0.03016037879897182]
	TIME [epoch: 8.36 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04060403861516169		[learning rate: 0.012141]
	Learning Rate: 0.012141
	LOSS [training: 0.04060403861516169 | validation: 0.05998299623168898]
	TIME [epoch: 8.33 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048687709351299		[learning rate: 0.012125]
	Learning Rate: 0.0121248
	LOSS [training: 0.048687709351299 | validation: 0.04579054589064523]
	TIME [epoch: 8.31 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048373874129546565		[learning rate: 0.012109]
	Learning Rate: 0.0121087
	LOSS [training: 0.048373874129546565 | validation: 0.03367121686009096]
	TIME [epoch: 8.32 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0363406045201934		[learning rate: 0.012093]
	Learning Rate: 0.0120925
	LOSS [training: 0.0363406045201934 | validation: 0.05890682648474665]
	TIME [epoch: 8.32 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04763964871087702		[learning rate: 0.012076]
	Learning Rate: 0.0120763
	LOSS [training: 0.04763964871087702 | validation: 0.05897209052440622]
	TIME [epoch: 8.32 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052042784936089395		[learning rate: 0.01206]
	Learning Rate: 0.0120602
	LOSS [training: 0.052042784936089395 | validation: 0.07087320070757083]
	TIME [epoch: 8.36 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04417201523704546		[learning rate: 0.012044]
	Learning Rate: 0.012044
	LOSS [training: 0.04417201523704546 | validation: 0.03253788245133281]
	TIME [epoch: 8.32 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04735712714939924		[learning rate: 0.012028]
	Learning Rate: 0.0120278
	LOSS [training: 0.04735712714939924 | validation: 0.06736170859903845]
	TIME [epoch: 8.32 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059832695140767854		[learning rate: 0.012012]
	Learning Rate: 0.0120116
	LOSS [training: 0.059832695140767854 | validation: 0.05157837473502451]
	TIME [epoch: 8.32 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04859049063632759		[learning rate: 0.011995]
	Learning Rate: 0.0119954
	LOSS [training: 0.04859049063632759 | validation: 0.038026828176228517]
	TIME [epoch: 8.32 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0355014827043974		[learning rate: 0.011979]
	Learning Rate: 0.0119792
	LOSS [training: 0.0355014827043974 | validation: 0.05709588770201239]
	TIME [epoch: 8.36 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04742962749754459		[learning rate: 0.011963]
	Learning Rate: 0.011963
	LOSS [training: 0.04742962749754459 | validation: 0.04471048372384782]
	TIME [epoch: 8.34 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033364286565829335		[learning rate: 0.011947]
	Learning Rate: 0.0119468
	LOSS [training: 0.033364286565829335 | validation: 0.03986402526355493]
	TIME [epoch: 8.32 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03872594912437473		[learning rate: 0.011931]
	Learning Rate: 0.0119306
	LOSS [training: 0.03872594912437473 | validation: 0.028407690003190225]
	TIME [epoch: 8.32 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037652148374121744		[learning rate: 0.011914]
	Learning Rate: 0.0119144
	LOSS [training: 0.037652148374121744 | validation: 0.07100315814508687]
	TIME [epoch: 8.32 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06401435011191707		[learning rate: 0.011898]
	Learning Rate: 0.0118982
	LOSS [training: 0.06401435011191707 | validation: 0.03159994739938082]
	TIME [epoch: 8.32 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0568748841664755		[learning rate: 0.011882]
	Learning Rate: 0.0118819
	LOSS [training: 0.0568748841664755 | validation: 0.027756681723528562]
	TIME [epoch: 8.36 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025215339505602397		[learning rate: 0.011866]
	Learning Rate: 0.0118657
	LOSS [training: 0.025215339505602397 | validation: 0.07100913173237106]
	TIME [epoch: 8.33 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06535132478404759		[learning rate: 0.011849]
	Learning Rate: 0.0118495
	LOSS [training: 0.06535132478404759 | validation: 0.042561175626400605]
	TIME [epoch: 8.32 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04557927990267649		[learning rate: 0.011833]
	Learning Rate: 0.0118332
	LOSS [training: 0.04557927990267649 | validation: 0.03258602968929525]
	TIME [epoch: 8.32 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03780222492990543		[learning rate: 0.011817]
	Learning Rate: 0.011817
	LOSS [training: 0.03780222492990543 | validation: 0.04191671989029842]
	TIME [epoch: 8.32 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04489095615736022		[learning rate: 0.011801]
	Learning Rate: 0.0118007
	LOSS [training: 0.04489095615736022 | validation: 0.04158223628997623]
	TIME [epoch: 8.34 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037586135503095225		[learning rate: 0.011784]
	Learning Rate: 0.0117844
	LOSS [training: 0.037586135503095225 | validation: 0.048591968743718926]
	TIME [epoch: 8.35 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05281703800709751		[learning rate: 0.011768]
	Learning Rate: 0.0117682
	LOSS [training: 0.05281703800709751 | validation: 0.04709429658688443]
	TIME [epoch: 8.31 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04081533410972906		[learning rate: 0.011752]
	Learning Rate: 0.0117519
	LOSS [training: 0.04081533410972906 | validation: 0.05142724327256736]
	TIME [epoch: 8.32 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052807982866609995		[learning rate: 0.011736]
	Learning Rate: 0.0117356
	LOSS [training: 0.052807982866609995 | validation: 0.04413509228934197]
	TIME [epoch: 8.32 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03160335626543139		[learning rate: 0.011719]
	Learning Rate: 0.0117194
	LOSS [training: 0.03160335626543139 | validation: 0.042537865069889574]
	TIME [epoch: 8.33 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05243246512634017		[learning rate: 0.011703]
	Learning Rate: 0.0117031
	LOSS [training: 0.05243246512634017 | validation: 0.15066425955924834]
	TIME [epoch: 8.37 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10666620853293027		[learning rate: 0.011687]
	Learning Rate: 0.0116868
	LOSS [training: 0.10666620853293027 | validation: 0.026086547791520677]
	TIME [epoch: 8.33 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025599052368652373		[learning rate: 0.01167]
	Learning Rate: 0.0116705
	LOSS [training: 0.025599052368652373 | validation: 0.01899249300604502]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_899.pth
	Model improved!!!
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028364065270850808		[learning rate: 0.011654]
	Learning Rate: 0.0116542
	LOSS [training: 0.028364065270850808 | validation: 0.0399768023386078]
	TIME [epoch: 8.32 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04139149649976222		[learning rate: 0.011638]
	Learning Rate: 0.0116379
	LOSS [training: 0.04139149649976222 | validation: 0.04989704637907124]
	TIME [epoch: 8.32 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03902480340165749		[learning rate: 0.011622]
	Learning Rate: 0.0116216
	LOSS [training: 0.03902480340165749 | validation: 0.029874115673125173]
	TIME [epoch: 8.34 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03976465511480663		[learning rate: 0.011605]
	Learning Rate: 0.0116053
	LOSS [training: 0.03976465511480663 | validation: 0.04604858450882495]
	TIME [epoch: 8.32 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04138258419431729		[learning rate: 0.011589]
	Learning Rate: 0.011589
	LOSS [training: 0.04138258419431729 | validation: 0.035071122432498145]
	TIME [epoch: 8.31 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07675909644506027		[learning rate: 0.011573]
	Learning Rate: 0.0115726
	LOSS [training: 0.07675909644506027 | validation: 0.040585650849678814]
	TIME [epoch: 8.3 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04471443912789587		[learning rate: 0.011556]
	Learning Rate: 0.0115563
	LOSS [training: 0.04471443912789587 | validation: 0.040117488248437486]
	TIME [epoch: 8.3 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041497617677992746		[learning rate: 0.01154]
	Learning Rate: 0.01154
	LOSS [training: 0.041497617677992746 | validation: 0.054846272431620435]
	TIME [epoch: 8.31 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034236006580872995		[learning rate: 0.011524]
	Learning Rate: 0.0115237
	LOSS [training: 0.034236006580872995 | validation: 0.05545768941572016]
	TIME [epoch: 8.36 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04498778550135287		[learning rate: 0.011507]
	Learning Rate: 0.0115073
	LOSS [training: 0.04498778550135287 | validation: 0.03016095172518715]
	TIME [epoch: 8.31 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03544352552489106		[learning rate: 0.011491]
	Learning Rate: 0.011491
	LOSS [training: 0.03544352552489106 | validation: 0.04550301463348025]
	TIME [epoch: 8.31 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04892639435104665		[learning rate: 0.011475]
	Learning Rate: 0.0114746
	LOSS [training: 0.04892639435104665 | validation: 0.05832498276910125]
	TIME [epoch: 8.31 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03655123545299739		[learning rate: 0.011458]
	Learning Rate: 0.0114583
	LOSS [training: 0.03655123545299739 | validation: 0.04835861597151685]
	TIME [epoch: 8.31 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034103095284828557		[learning rate: 0.011442]
	Learning Rate: 0.0114419
	LOSS [training: 0.034103095284828557 | validation: 0.05545989678533776]
	TIME [epoch: 8.34 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04556889894233053		[learning rate: 0.011426]
	Learning Rate: 0.0114256
	LOSS [training: 0.04556889894233053 | validation: 0.054971256280454614]
	TIME [epoch: 8.34 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03403098389665772		[learning rate: 0.011409]
	Learning Rate: 0.0114092
	LOSS [training: 0.03403098389665772 | validation: 0.02987545764867538]
	TIME [epoch: 8.31 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035070739676660176		[learning rate: 0.011393]
	Learning Rate: 0.0113929
	LOSS [training: 0.035070739676660176 | validation: 0.05322069089971217]
	TIME [epoch: 8.31 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05282451544285403		[learning rate: 0.011376]
	Learning Rate: 0.0113765
	LOSS [training: 0.05282451544285403 | validation: 0.03524431225861993]
	TIME [epoch: 8.31 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03661368062919599		[learning rate: 0.01136]
	Learning Rate: 0.0113601
	LOSS [training: 0.03661368062919599 | validation: 0.042295080105090546]
	TIME [epoch: 8.31 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04865026050880032		[learning rate: 0.011344]
	Learning Rate: 0.0113437
	LOSS [training: 0.04865026050880032 | validation: 0.058105410714676065]
	TIME [epoch: 8.36 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03970956126117836		[learning rate: 0.011327]
	Learning Rate: 0.0113274
	LOSS [training: 0.03970956126117836 | validation: 0.04218788904533764]
	TIME [epoch: 8.31 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0402111748557205		[learning rate: 0.011311]
	Learning Rate: 0.011311
	LOSS [training: 0.0402111748557205 | validation: 0.06492881137858392]
	TIME [epoch: 8.32 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12123691159523708		[learning rate: 0.011295]
	Learning Rate: 0.0112946
	LOSS [training: 0.12123691159523708 | validation: 0.10182451656396257]
	TIME [epoch: 8.31 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09312787254322465		[learning rate: 0.011278]
	Learning Rate: 0.0112782
	LOSS [training: 0.09312787254322465 | validation: 0.06187956894450235]
	TIME [epoch: 8.31 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03635120037248028		[learning rate: 0.011262]
	Learning Rate: 0.0112618
	LOSS [training: 0.03635120037248028 | validation: 0.021947875119827334]
	TIME [epoch: 8.32 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021563217192017457		[learning rate: 0.011245]
	Learning Rate: 0.0112454
	LOSS [training: 0.021563217192017457 | validation: 0.04167825316952417]
	TIME [epoch: 8.34 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04593183835012918		[learning rate: 0.011229]
	Learning Rate: 0.011229
	LOSS [training: 0.04593183835012918 | validation: 0.03845725991637551]
	TIME [epoch: 8.31 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036585304836068686		[learning rate: 0.011213]
	Learning Rate: 0.0112126
	LOSS [training: 0.036585304836068686 | validation: 0.03284206612029146]
	TIME [epoch: 8.31 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029993073494461356		[learning rate: 0.011196]
	Learning Rate: 0.0111962
	LOSS [training: 0.029993073494461356 | validation: 0.03185901194927718]
	TIME [epoch: 8.31 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03510815371741559		[learning rate: 0.01118]
	Learning Rate: 0.0111798
	LOSS [training: 0.03510815371741559 | validation: 0.030285686888434436]
	TIME [epoch: 8.31 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028163655283151148		[learning rate: 0.011163]
	Learning Rate: 0.0111634
	LOSS [training: 0.028163655283151148 | validation: 0.03199649501224337]
	TIME [epoch: 8.35 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033795023702638136		[learning rate: 0.011147]
	Learning Rate: 0.011147
	LOSS [training: 0.033795023702638136 | validation: 0.0587868111664622]
	TIME [epoch: 8.32 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04509951563365379		[learning rate: 0.011131]
	Learning Rate: 0.0111305
	LOSS [training: 0.04509951563365379 | validation: 0.0428680745619263]
	TIME [epoch: 8.31 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03873721850479997		[learning rate: 0.011114]
	Learning Rate: 0.0111141
	LOSS [training: 0.03873721850479997 | validation: 0.05111433160388934]
	TIME [epoch: 8.3 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030109528958109495		[learning rate: 0.011098]
	Learning Rate: 0.0110977
	LOSS [training: 0.030109528958109495 | validation: 0.033635753654826184]
	TIME [epoch: 8.31 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05232928495382026		[learning rate: 0.011081]
	Learning Rate: 0.0110813
	LOSS [training: 0.05232928495382026 | validation: 0.058999443279302455]
	TIME [epoch: 8.33 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041278328191750153		[learning rate: 0.011065]
	Learning Rate: 0.0110648
	LOSS [training: 0.041278328191750153 | validation: 0.05561931035094922]
	TIME [epoch: 8.34 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031410567806247604		[learning rate: 0.011048]
	Learning Rate: 0.0110484
	LOSS [training: 0.031410567806247604 | validation: 0.02770941201841915]
	TIME [epoch: 8.31 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04412465749009826		[learning rate: 0.011032]
	Learning Rate: 0.011032
	LOSS [training: 0.04412465749009826 | validation: 0.03999006003474899]
	TIME [epoch: 8.29 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039071715481203674		[learning rate: 0.011016]
	Learning Rate: 0.0110155
	LOSS [training: 0.039071715481203674 | validation: 0.03483065795030996]
	TIME [epoch: 8.32 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04360670687598442		[learning rate: 0.010999]
	Learning Rate: 0.0109991
	LOSS [training: 0.04360670687598442 | validation: 0.03282899722087765]
	TIME [epoch: 8.31 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02373709232601504		[learning rate: 0.010983]
	Learning Rate: 0.0109826
	LOSS [training: 0.02373709232601504 | validation: 0.034548596791980815]
	TIME [epoch: 8.35 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05284639918014703		[learning rate: 0.010966]
	Learning Rate: 0.0109662
	LOSS [training: 0.05284639918014703 | validation: 0.036765992220162025]
	TIME [epoch: 8.32 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03648517433397976		[learning rate: 0.01095]
	Learning Rate: 0.0109497
	LOSS [training: 0.03648517433397976 | validation: 0.03782238153396333]
	TIME [epoch: 8.31 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03229538582104282		[learning rate: 0.010933]
	Learning Rate: 0.0109333
	LOSS [training: 0.03229538582104282 | validation: 0.06077015857455109]
	TIME [epoch: 8.31 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04456527441750137		[learning rate: 0.010917]
	Learning Rate: 0.0109168
	LOSS [training: 0.04456527441750137 | validation: 0.05112905677498321]
	TIME [epoch: 8.31 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044905325166035834		[learning rate: 0.0109]
	Learning Rate: 0.0109004
	LOSS [training: 0.044905325166035834 | validation: 0.03914742083309389]
	TIME [epoch: 8.32 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03611548335883214		[learning rate: 0.010884]
	Learning Rate: 0.0108839
	LOSS [training: 0.03611548335883214 | validation: 0.02965524797855772]
	TIME [epoch: 8.35 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03605915554615758		[learning rate: 0.010867]
	Learning Rate: 0.0108674
	LOSS [training: 0.03605915554615758 | validation: 0.054621897157686734]
	TIME [epoch: 8.32 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041612605408622105		[learning rate: 0.010851]
	Learning Rate: 0.010851
	LOSS [training: 0.041612605408622105 | validation: 0.028727752524605465]
	TIME [epoch: 8.32 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03156124227916171		[learning rate: 0.010834]
	Learning Rate: 0.0108345
	LOSS [training: 0.03156124227916171 | validation: 0.046132910051208134]
	TIME [epoch: 8.31 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04421852311837428		[learning rate: 0.010818]
	Learning Rate: 0.010818
	LOSS [training: 0.04421852311837428 | validation: 0.045066557719051145]
	TIME [epoch: 8.31 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03134439102942515		[learning rate: 0.010802]
	Learning Rate: 0.0108016
	LOSS [training: 0.03134439102942515 | validation: 0.04104280025837327]
	TIME [epoch: 8.35 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04510529137657106		[learning rate: 0.010785]
	Learning Rate: 0.0107851
	LOSS [training: 0.04510529137657106 | validation: 0.029535593752653896]
	TIME [epoch: 8.32 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037404327132629284		[learning rate: 0.010769]
	Learning Rate: 0.0107686
	LOSS [training: 0.037404327132629284 | validation: 0.03532759588380571]
	TIME [epoch: 8.3 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03249268567634453		[learning rate: 0.010752]
	Learning Rate: 0.0107521
	LOSS [training: 0.03249268567634453 | validation: 0.043555595733978936]
	TIME [epoch: 8.31 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03612824690640786		[learning rate: 0.010736]
	Learning Rate: 0.0107356
	LOSS [training: 0.03612824690640786 | validation: 0.059717140779095415]
	TIME [epoch: 8.31 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05256395082596816		[learning rate: 0.010719]
	Learning Rate: 0.0107192
	LOSS [training: 0.05256395082596816 | validation: 0.03498755239123096]
	TIME [epoch: 8.32 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032767744460601		[learning rate: 0.010703]
	Learning Rate: 0.0107027
	LOSS [training: 0.032767744460601 | validation: 0.04394514674941561]
	TIME [epoch: 8.36 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04713321501108281		[learning rate: 0.010686]
	Learning Rate: 0.0106862
	LOSS [training: 0.04713321501108281 | validation: 0.028268068653053164]
	TIME [epoch: 8.31 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034465598543561606		[learning rate: 0.01067]
	Learning Rate: 0.0106697
	LOSS [training: 0.034465598543561606 | validation: 0.02173622791425852]
	TIME [epoch: 8.32 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029236708599918247		[learning rate: 0.010653]
	Learning Rate: 0.0106532
	LOSS [training: 0.029236708599918247 | validation: 0.039845552121171524]
	TIME [epoch: 8.32 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035814964555672055		[learning rate: 0.010637]
	Learning Rate: 0.0106367
	LOSS [training: 0.035814964555672055 | validation: 0.030288503112049097]
	TIME [epoch: 8.32 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03476403084684008		[learning rate: 0.01062]
	Learning Rate: 0.0106202
	LOSS [training: 0.03476403084684008 | validation: 0.041917305608885354]
	TIME [epoch: 8.35 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03447358434382977		[learning rate: 0.010604]
	Learning Rate: 0.0106037
	LOSS [training: 0.03447358434382977 | validation: 0.034585839924105896]
	TIME [epoch: 8.33 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030143685237270595		[learning rate: 0.010587]
	Learning Rate: 0.0105872
	LOSS [training: 0.030143685237270595 | validation: 0.045051171627807925]
	TIME [epoch: 8.32 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0373328033940363		[learning rate: 0.010571]
	Learning Rate: 0.0105707
	LOSS [training: 0.0373328033940363 | validation: 0.036961911220025]
	TIME [epoch: 8.32 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042123878616439105		[learning rate: 0.010554]
	Learning Rate: 0.0105542
	LOSS [training: 0.042123878616439105 | validation: 0.0636835761514834]
	TIME [epoch: 8.32 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05148522078652662		[learning rate: 0.010538]
	Learning Rate: 0.0105377
	LOSS [training: 0.05148522078652662 | validation: 0.022221251348462753]
	TIME [epoch: 8.32 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02265644775319285		[learning rate: 0.010521]
	Learning Rate: 0.0105212
	LOSS [training: 0.02265644775319285 | validation: 0.031842719050455]
	TIME [epoch: 8.35 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032965368065064976		[learning rate: 0.010505]
	Learning Rate: 0.0105047
	LOSS [training: 0.032965368065064976 | validation: 0.04080197578718578]
	TIME [epoch: 8.31 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03383260245622806		[learning rate: 0.010488]
	Learning Rate: 0.0104882
	LOSS [training: 0.03383260245622806 | validation: 0.032975324404360115]
	TIME [epoch: 8.31 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04946661564821339		[learning rate: 0.010472]
	Learning Rate: 0.0104717
	LOSS [training: 0.04946661564821339 | validation: 0.04819269560495576]
	TIME [epoch: 8.31 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05808095819227965		[learning rate: 0.010455]
	Learning Rate: 0.0104552
	LOSS [training: 0.05808095819227965 | validation: 0.01656395056059347]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_973.pth
	Model improved!!!
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018751166645290675		[learning rate: 0.010439]
	Learning Rate: 0.0104387
	LOSS [training: 0.018751166645290675 | validation: 0.03075731852074421]
	TIME [epoch: 8.35 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031537257905155		[learning rate: 0.010422]
	Learning Rate: 0.0104222
	LOSS [training: 0.031537257905155 | validation: 0.0310917933511325]
	TIME [epoch: 8.32 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03529614977925467		[learning rate: 0.010406]
	Learning Rate: 0.0104057
	LOSS [training: 0.03529614977925467 | validation: 0.043755950320247]
	TIME [epoch: 8.31 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03655803658223535		[learning rate: 0.010389]
	Learning Rate: 0.0103891
	LOSS [training: 0.03655803658223535 | validation: 0.028118071283268417]
	TIME [epoch: 8.31 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04365846184578499		[learning rate: 0.010373]
	Learning Rate: 0.0103726
	LOSS [training: 0.04365846184578499 | validation: 0.01825941144365882]
	TIME [epoch: 8.31 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031861873771198965		[learning rate: 0.010356]
	Learning Rate: 0.0103561
	LOSS [training: 0.031861873771198965 | validation: 0.037546295009512926]
	TIME [epoch: 8.32 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04276969558111418		[learning rate: 0.01034]
	Learning Rate: 0.0103396
	LOSS [training: 0.04276969558111418 | validation: 0.045066443409270754]
	TIME [epoch: 8.34 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03630447619111656		[learning rate: 0.010323]
	Learning Rate: 0.0103231
	LOSS [training: 0.03630447619111656 | validation: 0.03275909084411107]
	TIME [epoch: 8.31 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027493656901422463		[learning rate: 0.010307]
	Learning Rate: 0.0103066
	LOSS [training: 0.027493656901422463 | validation: 0.025370454147573974]
	TIME [epoch: 8.32 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03481530215927975		[learning rate: 0.01029]
	Learning Rate: 0.01029
	LOSS [training: 0.03481530215927975 | validation: 0.041009950706480336]
	TIME [epoch: 8.33 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033333827087698685		[learning rate: 0.010274]
	Learning Rate: 0.0102735
	LOSS [training: 0.033333827087698685 | validation: 0.046368284504978485]
	TIME [epoch: 8.31 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07600070793521457		[learning rate: 0.010257]
	Learning Rate: 0.010257
	LOSS [training: 0.07600070793521457 | validation: 0.05370029580996705]
	TIME [epoch: 8.35 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030544579509318274		[learning rate: 0.01024]
	Learning Rate: 0.0102405
	LOSS [training: 0.030544579509318274 | validation: 0.019751323353672655]
	TIME [epoch: 8.33 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021692632144589597		[learning rate: 0.010224]
	Learning Rate: 0.010224
	LOSS [training: 0.021692632144589597 | validation: 0.019962404225163998]
	TIME [epoch: 8.31 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019008304715876438		[learning rate: 0.010207]
	Learning Rate: 0.0102074
	LOSS [training: 0.019008304715876438 | validation: 0.030351021461840183]
	TIME [epoch: 8.31 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0413948305973896		[learning rate: 0.010191]
	Learning Rate: 0.0101909
	LOSS [training: 0.0413948305973896 | validation: 0.028063855288900597]
	TIME [epoch: 8.31 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029089127110710933		[learning rate: 0.010174]
	Learning Rate: 0.0101744
	LOSS [training: 0.029089127110710933 | validation: 0.018492210960535473]
	TIME [epoch: 8.32 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024078802620907808		[learning rate: 0.010158]
	Learning Rate: 0.0101579
	LOSS [training: 0.024078802620907808 | validation: 0.027587447271415443]
	TIME [epoch: 8.36 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03605445488832069		[learning rate: 0.010141]
	Learning Rate: 0.0101413
	LOSS [training: 0.03605445488832069 | validation: 0.02097895169301251]
	TIME [epoch: 8.31 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030112366773492064		[learning rate: 0.010125]
	Learning Rate: 0.0101248
	LOSS [training: 0.030112366773492064 | validation: 0.03572609378015864]
	TIME [epoch: 8.31 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03598183921082723		[learning rate: 0.010108]
	Learning Rate: 0.0101083
	LOSS [training: 0.03598183921082723 | validation: 0.046103194432409136]
	TIME [epoch: 8.32 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037554965046121644		[learning rate: 0.010092]
	Learning Rate: 0.0100918
	LOSS [training: 0.037554965046121644 | validation: 0.01892069527394838]
	TIME [epoch: 8.3 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02378427643673692		[learning rate: 0.010075]
	Learning Rate: 0.0100752
	LOSS [training: 0.02378427643673692 | validation: 0.02466164669512467]
	TIME [epoch: 8.33 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031370668538438916		[learning rate: 0.010059]
	Learning Rate: 0.0100587
	LOSS [training: 0.031370668538438916 | validation: 0.036506512848374556]
	TIME [epoch: 8.34 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042781045575409876		[learning rate: 0.010042]
	Learning Rate: 0.0100422
	LOSS [training: 0.042781045575409876 | validation: 0.05851366737583003]
	TIME [epoch: 8.32 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02873204248690276		[learning rate: 0.010026]
	Learning Rate: 0.0100257
	LOSS [training: 0.02873204248690276 | validation: 0.01312165207068464]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_999.pth
	Model improved!!!
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028419282563897426		[learning rate: 0.010009]
	Learning Rate: 0.0100091
	LOSS [training: 0.028419282563897426 | validation: 0.03599214203450617]
	TIME [epoch: 8.32 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0357242940996153		[learning rate: 0.0099926]
	Learning Rate: 0.00999261
	LOSS [training: 0.0357242940996153 | validation: 0.0598186950583776]
	TIME [epoch: 8.32 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04276646676333648		[learning rate: 0.0099761]
	Learning Rate: 0.00997608
	LOSS [training: 0.04276646676333648 | validation: 0.019000467349449678]
	TIME [epoch: 8.64 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024050381976803148		[learning rate: 0.0099596]
	Learning Rate: 0.00995955
	LOSS [training: 0.024050381976803148 | validation: 0.034063050270180785]
	TIME [epoch: 8.34 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035498944648089954		[learning rate: 0.009943]
	Learning Rate: 0.00994303
	LOSS [training: 0.035498944648089954 | validation: 0.032840471274841104]
	TIME [epoch: 8.34 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029185677501060967		[learning rate: 0.0099265]
	Learning Rate: 0.0099265
	LOSS [training: 0.029185677501060967 | validation: 0.02940121386363727]
	TIME [epoch: 8.34 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02979336586869349		[learning rate: 0.00991]
	Learning Rate: 0.00990997
	LOSS [training: 0.02979336586869349 | validation: 0.05767970127836182]
	TIME [epoch: 8.34 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0437579389387794		[learning rate: 0.0098934]
	Learning Rate: 0.00989345
	LOSS [training: 0.0437579389387794 | validation: 0.019439346062825248]
	TIME [epoch: 8.38 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02694621555333891		[learning rate: 0.0098769]
	Learning Rate: 0.00987692
	LOSS [training: 0.02694621555333891 | validation: 0.027256086122477135]
	TIME [epoch: 11.1 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024939241495608222		[learning rate: 0.0098604]
	Learning Rate: 0.0098604
	LOSS [training: 0.024939241495608222 | validation: 0.04505345738769172]
	TIME [epoch: 8.34 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034980232632548944		[learning rate: 0.0098439]
	Learning Rate: 0.00984387
	LOSS [training: 0.034980232632548944 | validation: 0.03603261267935726]
	TIME [epoch: 8.34 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03240827511758039		[learning rate: 0.0098274]
	Learning Rate: 0.00982735
	LOSS [training: 0.03240827511758039 | validation: 0.022339226306421725]
	TIME [epoch: 8.34 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02249413255728482		[learning rate: 0.0098108]
	Learning Rate: 0.00981083
	LOSS [training: 0.02249413255728482 | validation: 0.037142263960266264]
	TIME [epoch: 8.34 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04121541865582065		[learning rate: 0.0097943]
	Learning Rate: 0.0097943
	LOSS [training: 0.04121541865582065 | validation: 0.036317837712825846]
	TIME [epoch: 8.37 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024790325976509764		[learning rate: 0.0097778]
	Learning Rate: 0.00977778
	LOSS [training: 0.024790325976509764 | validation: 0.02623592064166047]
	TIME [epoch: 8.34 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03913819399710848		[learning rate: 0.0097613]
	Learning Rate: 0.00976126
	LOSS [training: 0.03913819399710848 | validation: 0.04052300703897428]
	TIME [epoch: 15.1 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028961689152069554		[learning rate: 0.0097447]
	Learning Rate: 0.00974474
	LOSS [training: 0.028961689152069554 | validation: 0.02497134025672544]
	TIME [epoch: 8.34 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022011864650711418		[learning rate: 0.0097282]
	Learning Rate: 0.00972822
	LOSS [training: 0.022011864650711418 | validation: 0.028899482406716647]
	TIME [epoch: 8.33 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02441867734841053		[learning rate: 0.0097117]
	Learning Rate: 0.0097117
	LOSS [training: 0.02441867734841053 | validation: 0.033964181807107384]
	TIME [epoch: 8.38 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0366384164879412		[learning rate: 0.0096952]
	Learning Rate: 0.00969518
	LOSS [training: 0.0366384164879412 | validation: 0.027043674635323756]
	TIME [epoch: 8.34 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029967169707906034		[learning rate: 0.0096787]
	Learning Rate: 0.00967866
	LOSS [training: 0.029967169707906034 | validation: 0.10251622982935371]
	TIME [epoch: 8.33 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04841451092651221		[learning rate: 0.0096621]
	Learning Rate: 0.00966214
	LOSS [training: 0.04841451092651221 | validation: 0.02026352807438953]
	TIME [epoch: 8.33 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02398693351689212		[learning rate: 0.0096456]
	Learning Rate: 0.00964563
	LOSS [training: 0.02398693351689212 | validation: 0.031347609669038136]
	TIME [epoch: 8.34 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026882870270007925		[learning rate: 0.0096291]
	Learning Rate: 0.00962911
	LOSS [training: 0.026882870270007925 | validation: 0.03172387467789881]
	TIME [epoch: 8.34 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031030963833151577		[learning rate: 0.0096126]
	Learning Rate: 0.0096126
	LOSS [training: 0.031030963833151577 | validation: 0.02994658426307658]
	TIME [epoch: 8.37 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024593822096391695		[learning rate: 0.0095961]
	Learning Rate: 0.00959609
	LOSS [training: 0.024593822096391695 | validation: 0.022967086452263696]
	TIME [epoch: 8.34 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02473686980982822		[learning rate: 0.0095796]
	Learning Rate: 0.00957957
	LOSS [training: 0.02473686980982822 | validation: 0.02620184286262494]
	TIME [epoch: 8.34 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05304797374913828		[learning rate: 0.0095631]
	Learning Rate: 0.00956306
	LOSS [training: 0.05304797374913828 | validation: 0.038124942288724435]
	TIME [epoch: 8.34 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027641491226249322		[learning rate: 0.0095466]
	Learning Rate: 0.00954655
	LOSS [training: 0.027641491226249322 | validation: 0.035232566345018895]
	TIME [epoch: 8.33 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027999023969813946		[learning rate: 0.00953]
	Learning Rate: 0.00953004
	LOSS [training: 0.027999023969813946 | validation: 0.023003060925517113]
	TIME [epoch: 8.38 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030426869589898833		[learning rate: 0.0095135]
	Learning Rate: 0.00951354
	LOSS [training: 0.030426869589898833 | validation: 0.02989794646166823]
	TIME [epoch: 8.36 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02442598985010248		[learning rate: 0.009497]
	Learning Rate: 0.00949703
	LOSS [training: 0.02442598985010248 | validation: 0.0212861188492703]
	TIME [epoch: 8.34 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02373065131419142		[learning rate: 0.0094805]
	Learning Rate: 0.00948053
	LOSS [training: 0.02373065131419142 | validation: 0.032426636938537624]
	TIME [epoch: 8.34 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02755109564696384		[learning rate: 0.009464]
	Learning Rate: 0.00946402
	LOSS [training: 0.02755109564696384 | validation: 0.026287693808013712]
	TIME [epoch: 8.33 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04110159459098752		[learning rate: 0.0094475]
	Learning Rate: 0.00944752
	LOSS [training: 0.04110159459098752 | validation: 0.06100158603883306]
	TIME [epoch: 9.93 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053999522637359604		[learning rate: 0.009431]
	Learning Rate: 0.00943102
	LOSS [training: 0.053999522637359604 | validation: 0.03094307645151221]
	TIME [epoch: 8.38 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017821896700480386		[learning rate: 0.0094145]
	Learning Rate: 0.00941452
	LOSS [training: 0.017821896700480386 | validation: 0.011374948402232764]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_1036.pth
	Model improved!!!
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018149540996043087		[learning rate: 0.009398]
	Learning Rate: 0.00939803
	LOSS [training: 0.018149540996043087 | validation: 0.02507575654013839]
	TIME [epoch: 8.33 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03413482306063533		[learning rate: 0.0093815]
	Learning Rate: 0.00938153
	LOSS [training: 0.03413482306063533 | validation: 0.021159344912853352]
	TIME [epoch: 8.33 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016765962981895272		[learning rate: 0.009365]
	Learning Rate: 0.00936504
	LOSS [training: 0.016765962981895272 | validation: 0.017808345367444172]
	TIME [epoch: 8.33 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026832649879051908		[learning rate: 0.0093485]
	Learning Rate: 0.00934855
	LOSS [training: 0.026832649879051908 | validation: 0.06647635335205909]
	TIME [epoch: 8.37 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08161046681072925		[learning rate: 0.0093321]
	Learning Rate: 0.00933206
	LOSS [training: 0.08161046681072925 | validation: 0.04837189467588323]
	TIME [epoch: 8.34 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03207140288206055		[learning rate: 0.0093156]
	Learning Rate: 0.00931557
	LOSS [training: 0.03207140288206055 | validation: 0.01657454523580814]
	TIME [epoch: 8.33 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022109350821525972		[learning rate: 0.0092991]
	Learning Rate: 0.00929908
	LOSS [training: 0.022109350821525972 | validation: 0.024783563751401234]
	TIME [epoch: 8.33 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022280259145809708		[learning rate: 0.0092826]
	Learning Rate: 0.0092826
	LOSS [training: 0.022280259145809708 | validation: 0.021001965577812302]
	TIME [epoch: 8.33 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028380234235997257		[learning rate: 0.0092661]
	Learning Rate: 0.00926612
	LOSS [training: 0.028380234235997257 | validation: 0.025516591830115534]
	TIME [epoch: 8.34 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02735455502783449		[learning rate: 0.0092496]
	Learning Rate: 0.00924964
	LOSS [training: 0.02735455502783449 | validation: 0.011559494529393746]
	TIME [epoch: 8.39 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018172393258424		[learning rate: 0.0092332]
	Learning Rate: 0.00923316
	LOSS [training: 0.018172393258424 | validation: 0.04800002620640134]
	TIME [epoch: 8.33 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03220531657070435		[learning rate: 0.0092167]
	Learning Rate: 0.00921668
	LOSS [training: 0.03220531657070435 | validation: 0.01513950046586655]
	TIME [epoch: 8.33 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021468142636527125		[learning rate: 0.0092002]
	Learning Rate: 0.00920021
	LOSS [training: 0.021468142636527125 | validation: 0.03715066396242389]
	TIME [epoch: 8.33 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08263501762615534		[learning rate: 0.0091837]
	Learning Rate: 0.00918374
	LOSS [training: 0.08263501762615534 | validation: 0.03998302383571167]
	TIME [epoch: 8.33 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02529362612584255		[learning rate: 0.0091673]
	Learning Rate: 0.00916727
	LOSS [training: 0.02529362612584255 | validation: 0.023438504443571546]
	TIME [epoch: 8.36 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027720639246385875		[learning rate: 0.0091508]
	Learning Rate: 0.0091508
	LOSS [training: 0.027720639246385875 | validation: 0.021400199251888106]
	TIME [epoch: 8.35 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02495460427468995		[learning rate: 0.0091343]
	Learning Rate: 0.00913434
	LOSS [training: 0.02495460427468995 | validation: 0.034431092547189415]
	TIME [epoch: 8.33 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02458224852839483		[learning rate: 0.0091179]
	Learning Rate: 0.00911787
	LOSS [training: 0.02458224852839483 | validation: 0.0377289236278967]
	TIME [epoch: 8.33 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029514578786956767		[learning rate: 0.0091014]
	Learning Rate: 0.00910141
	LOSS [training: 0.029514578786956767 | validation: 0.01103705980361398]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_1055.pth
	Model improved!!!
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01200508139399242		[learning rate: 0.009085]
	Learning Rate: 0.00908496
	LOSS [training: 0.01200508139399242 | validation: 0.01603881800741894]
	TIME [epoch: 8.33 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025883723208793917		[learning rate: 0.0090685]
	Learning Rate: 0.0090685
	LOSS [training: 0.025883723208793917 | validation: 0.028297152365342776]
	TIME [epoch: 8.36 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025893739797257523		[learning rate: 0.009052]
	Learning Rate: 0.00905205
	LOSS [training: 0.025893739797257523 | validation: 0.026803154177495177]
	TIME [epoch: 8.32 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027235843656224293		[learning rate: 0.0090356]
	Learning Rate: 0.0090356
	LOSS [training: 0.027235843656224293 | validation: 0.028440514878670883]
	TIME [epoch: 8.32 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031296115597513		[learning rate: 0.0090192]
	Learning Rate: 0.00901915
	LOSS [training: 0.031296115597513 | validation: 0.02676199307041826]
	TIME [epoch: 8.32 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028832518938095922		[learning rate: 0.0090027]
	Learning Rate: 0.00900271
	LOSS [training: 0.028832518938095922 | validation: 0.020533466087658825]
	TIME [epoch: 8.32 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01315255179224074		[learning rate: 0.0089863]
	Learning Rate: 0.00898627
	LOSS [training: 0.01315255179224074 | validation: 0.02427226292739642]
	TIME [epoch: 8.35 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04328268005918877		[learning rate: 0.0089698]
	Learning Rate: 0.00896983
	LOSS [training: 0.04328268005918877 | validation: 0.02227016119759329]
	TIME [epoch: 8.34 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021947335646930622		[learning rate: 0.0089534]
	Learning Rate: 0.00895339
	LOSS [training: 0.021947335646930622 | validation: 0.047187803462806106]
	TIME [epoch: 8.33 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04849259913685314		[learning rate: 0.008937]
	Learning Rate: 0.00893696
	LOSS [training: 0.04849259913685314 | validation: 0.025022417467031332]
	TIME [epoch: 8.32 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016938204406689233		[learning rate: 0.0089205]
	Learning Rate: 0.00892053
	LOSS [training: 0.016938204406689233 | validation: 0.023018664236743817]
	TIME [epoch: 8.32 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03493193836483759		[learning rate: 0.0089041]
	Learning Rate: 0.0089041
	LOSS [training: 0.03493193836483759 | validation: 0.02227495849683246]
	TIME [epoch: 8.32 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022563084082119475		[learning rate: 0.0088877]
	Learning Rate: 0.00888767
	LOSS [training: 0.022563084082119475 | validation: 0.022592351548118242]
	TIME [epoch: 8.36 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01822073494632445		[learning rate: 0.0088713]
	Learning Rate: 0.00887125
	LOSS [training: 0.01822073494632445 | validation: 0.019890960560020043]
	TIME [epoch: 8.32 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020314160781846377		[learning rate: 0.0088548]
	Learning Rate: 0.00885484
	LOSS [training: 0.020314160781846377 | validation: 0.052494224118053316]
	TIME [epoch: 8.32 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0266839553804991		[learning rate: 0.0088384]
	Learning Rate: 0.00883842
	LOSS [training: 0.0266839553804991 | validation: 0.016071218602102123]
	TIME [epoch: 8.32 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01946394838065551		[learning rate: 0.008822]
	Learning Rate: 0.00882201
	LOSS [training: 0.01946394838065551 | validation: 0.02139767935226263]
	TIME [epoch: 8.33 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037569753230291845		[learning rate: 0.0088056]
	Learning Rate: 0.0088056
	LOSS [training: 0.037569753230291845 | validation: 0.02238042346572782]
	TIME [epoch: 8.36 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02261145617236432		[learning rate: 0.0087892]
	Learning Rate: 0.00878919
	LOSS [training: 0.02261145617236432 | validation: 0.02087600047982247]
	TIME [epoch: 8.34 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022740783741121387		[learning rate: 0.0087728]
	Learning Rate: 0.00877279
	LOSS [training: 0.022740783741121387 | validation: 0.06388780617481213]
	TIME [epoch: 8.33 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02915402346238561		[learning rate: 0.0087564]
	Learning Rate: 0.00875639
	LOSS [training: 0.02915402346238561 | validation: 0.017201798719045147]
	TIME [epoch: 8.32 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025690250178085253		[learning rate: 0.00874]
	Learning Rate: 0.00874
	LOSS [training: 0.025690250178085253 | validation: 0.03371254312137802]
	TIME [epoch: 8.32 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028713784133386114		[learning rate: 0.0087236]
	Learning Rate: 0.00872361
	LOSS [training: 0.028713784133386114 | validation: 0.024613750531653593]
	TIME [epoch: 8.32 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01797086773850536		[learning rate: 0.0087072]
	Learning Rate: 0.00870722
	LOSS [training: 0.01797086773850536 | validation: 0.022385253935813358]
	TIME [epoch: 8.37 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02283294124333494		[learning rate: 0.0086908]
	Learning Rate: 0.00869083
	LOSS [training: 0.02283294124333494 | validation: 0.029902292255396153]
	TIME [epoch: 8.32 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027173167204544556		[learning rate: 0.0086745]
	Learning Rate: 0.00867445
	LOSS [training: 0.027173167204544556 | validation: 0.03853843935220705]
	TIME [epoch: 8.32 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041129058313071544		[learning rate: 0.0086581]
	Learning Rate: 0.00865807
	LOSS [training: 0.041129058313071544 | validation: 0.018609371180639683]
	TIME [epoch: 8.32 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014102353885165328		[learning rate: 0.0086417]
	Learning Rate: 0.0086417
	LOSS [training: 0.014102353885165328 | validation: 0.013611009743473367]
	TIME [epoch: 8.32 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01987551667896861		[learning rate: 0.0086253]
	Learning Rate: 0.00862533
	LOSS [training: 0.01987551667896861 | validation: 0.03721448232824038]
	TIME [epoch: 8.34 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027544150237060396		[learning rate: 0.008609]
	Learning Rate: 0.00860896
	LOSS [training: 0.027544150237060396 | validation: 0.0234718988715293]
	TIME [epoch: 8.34 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0300024001184955		[learning rate: 0.0085926]
	Learning Rate: 0.0085926
	LOSS [training: 0.0300024001184955 | validation: 0.01505264117398654]
	TIME [epoch: 8.31 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009247002421917921		[learning rate: 0.0085762]
	Learning Rate: 0.00857624
	LOSS [training: 0.009247002421917921 | validation: 0.006687917740536974]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_1087.pth
	Model improved!!!
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00920899202620344		[learning rate: 0.0085599]
	Learning Rate: 0.00855989
	LOSS [training: 0.00920899202620344 | validation: 0.012977857060661558]
	TIME [epoch: 8.3 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033820673725616056		[learning rate: 0.0085435]
	Learning Rate: 0.00854354
	LOSS [training: 0.033820673725616056 | validation: 0.05549950457076544]
	TIME [epoch: 8.31 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03734279848083701		[learning rate: 0.0085272]
	Learning Rate: 0.00852719
	LOSS [training: 0.03734279848083701 | validation: 0.02864545769310877]
	TIME [epoch: 8.35 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030571640664749898		[learning rate: 0.0085108]
	Learning Rate: 0.00851085
	LOSS [training: 0.030571640664749898 | validation: 0.013623821893803744]
	TIME [epoch: 8.31 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014770675914956927		[learning rate: 0.0084945]
	Learning Rate: 0.00849451
	LOSS [training: 0.014770675914956927 | validation: 0.020248561193538336]
	TIME [epoch: 8.31 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021583411917155595		[learning rate: 0.0084782]
	Learning Rate: 0.00847817
	LOSS [training: 0.021583411917155595 | validation: 0.015912272228331553]
	TIME [epoch: 8.31 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023170660696861804		[learning rate: 0.0084618]
	Learning Rate: 0.00846184
	LOSS [training: 0.023170660696861804 | validation: 0.022666040062502786]
	TIME [epoch: 8.31 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02589554605511974		[learning rate: 0.0084455]
	Learning Rate: 0.00844552
	LOSS [training: 0.02589554605511974 | validation: 0.026378617431726526]
	TIME [epoch: 8.33 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021604502737457912		[learning rate: 0.0084292]
	Learning Rate: 0.0084292
	LOSS [training: 0.021604502737457912 | validation: 0.012769770264689544]
	TIME [epoch: 8.34 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025379196963503964		[learning rate: 0.0084129]
	Learning Rate: 0.00841288
	LOSS [training: 0.025379196963503964 | validation: 0.034151168211868546]
	TIME [epoch: 8.31 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032693107524986054		[learning rate: 0.0083966]
	Learning Rate: 0.00839657
	LOSS [training: 0.032693107524986054 | validation: 0.023670338745604813]
	TIME [epoch: 8.31 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01768401799741441		[learning rate: 0.0083803]
	Learning Rate: 0.00838026
	LOSS [training: 0.01768401799741441 | validation: 0.015581534436914238]
	TIME [epoch: 8.31 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01677654426302385		[learning rate: 0.008364]
	Learning Rate: 0.00836395
	LOSS [training: 0.01677654426302385 | validation: 0.021985104753509482]
	TIME [epoch: 8.31 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022041149513895325		[learning rate: 0.0083477]
	Learning Rate: 0.00834765
	LOSS [training: 0.022041149513895325 | validation: 0.022237701506783707]
	TIME [epoch: 8.36 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020225958206000986		[learning rate: 0.0083314]
	Learning Rate: 0.00833136
	LOSS [training: 0.020225958206000986 | validation: 0.030507635966226694]
	TIME [epoch: 8.31 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035222567383442455		[learning rate: 0.0083151]
	Learning Rate: 0.00831507
	LOSS [training: 0.035222567383442455 | validation: 0.01312851116720792]
	TIME [epoch: 8.32 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01326665552756991		[learning rate: 0.0082988]
	Learning Rate: 0.00829878
	LOSS [training: 0.01326665552756991 | validation: 0.01417890097612971]
	TIME [epoch: 8.31 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026020184055293945		[learning rate: 0.0082825]
	Learning Rate: 0.0082825
	LOSS [training: 0.026020184055293945 | validation: 0.02191462974321199]
	TIME [epoch: 8.3 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018811217354780908		[learning rate: 0.0082662]
	Learning Rate: 0.00826622
	LOSS [training: 0.018811217354780908 | validation: 0.02642526859242559]
	TIME [epoch: 8.35 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026260476549934145		[learning rate: 0.0082499]
	Learning Rate: 0.00824995
	LOSS [training: 0.026260476549934145 | validation: 0.015709047350349732]
	TIME [epoch: 8.32 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01900351150568732		[learning rate: 0.0082337]
	Learning Rate: 0.00823368
	LOSS [training: 0.01900351150568732 | validation: 0.022125857822211957]
	TIME [epoch: 8.31 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018666969913664733		[learning rate: 0.0082174]
	Learning Rate: 0.00821742
	LOSS [training: 0.018666969913664733 | validation: 0.02006216160100229]
	TIME [epoch: 8.31 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022936674422714246		[learning rate: 0.0082012]
	Learning Rate: 0.00820116
	LOSS [training: 0.022936674422714246 | validation: 0.03597229159383483]
	TIME [epoch: 8.31 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02502059174970638		[learning rate: 0.0081849]
	Learning Rate: 0.00818491
	LOSS [training: 0.02502059174970638 | validation: 0.019780879845278255]
	TIME [epoch: 8.31 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02042709931531196		[learning rate: 0.0081687]
	Learning Rate: 0.00816866
	LOSS [training: 0.02042709931531196 | validation: 0.01873519711041437]
	TIME [epoch: 8.36 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01797381088441011		[learning rate: 0.0081524]
	Learning Rate: 0.00815242
	LOSS [training: 0.01797381088441011 | validation: 0.016824001410649797]
	TIME [epoch: 8.31 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02681430276549534		[learning rate: 0.0081362]
	Learning Rate: 0.00813618
	LOSS [training: 0.02681430276549534 | validation: 0.02635820134080783]
	TIME [epoch: 8.31 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020242235013450384		[learning rate: 0.00812]
	Learning Rate: 0.00811995
	LOSS [training: 0.020242235013450384 | validation: 0.021657820878089457]
	TIME [epoch: 8.31 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03043741889190784		[learning rate: 0.0081037]
	Learning Rate: 0.00810372
	LOSS [training: 0.03043741889190784 | validation: 0.037681903268548145]
	TIME [epoch: 8.31 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026304481380299963		[learning rate: 0.0080875]
	Learning Rate: 0.0080875
	LOSS [training: 0.026304481380299963 | validation: 0.017144703845449735]
	TIME [epoch: 8.33 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02077120997509241		[learning rate: 0.0080713]
	Learning Rate: 0.00807128
	LOSS [training: 0.02077120997509241 | validation: 0.016549151146280035]
	TIME [epoch: 8.34 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014936981827730128		[learning rate: 0.0080551]
	Learning Rate: 0.00805507
	LOSS [training: 0.014936981827730128 | validation: 0.022982116383133775]
	TIME [epoch: 8.31 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023384975864753573		[learning rate: 0.0080389]
	Learning Rate: 0.00803887
	LOSS [training: 0.023384975864753573 | validation: 0.01984389702950256]
	TIME [epoch: 8.32 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017134926259753647		[learning rate: 0.0080227]
	Learning Rate: 0.00802267
	LOSS [training: 0.017134926259753647 | validation: 0.016929491018259107]
	TIME [epoch: 8.31 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015512669468676613		[learning rate: 0.0080065]
	Learning Rate: 0.00800647
	LOSS [training: 0.015512669468676613 | validation: 0.018021847241165553]
	TIME [epoch: 8.31 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014239260435141177		[learning rate: 0.0079903]
	Learning Rate: 0.00799028
	LOSS [training: 0.014239260435141177 | validation: 0.021789603501968936]
	TIME [epoch: 8.35 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03392554799555163		[learning rate: 0.0079741]
	Learning Rate: 0.0079741
	LOSS [training: 0.03392554799555163 | validation: 0.03803977147403747]
	TIME [epoch: 8.31 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028112889534804196		[learning rate: 0.0079579]
	Learning Rate: 0.00795792
	LOSS [training: 0.028112889534804196 | validation: 0.014048440131904927]
	TIME [epoch: 8.31 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014016010144664373		[learning rate: 0.0079417]
	Learning Rate: 0.00794174
	LOSS [training: 0.014016010144664373 | validation: 0.017260087269419876]
	TIME [epoch: 8.3 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015332386749599119		[learning rate: 0.0079256]
	Learning Rate: 0.00792558
	LOSS [training: 0.015332386749599119 | validation: 0.023905997293198998]
	TIME [epoch: 8.31 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029625698812212307		[learning rate: 0.0079094]
	Learning Rate: 0.00790941
	LOSS [training: 0.029625698812212307 | validation: 0.019533757405118726]
	TIME [epoch: 8.32 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01773683005267206		[learning rate: 0.0078933]
	Learning Rate: 0.00789326
	LOSS [training: 0.01773683005267206 | validation: 0.02439331301576958]
	TIME [epoch: 8.35 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023443049289940853		[learning rate: 0.0078771]
	Learning Rate: 0.00787711
	LOSS [training: 0.023443049289940853 | validation: 0.012854373517524643]
	TIME [epoch: 8.31 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01149237547415944		[learning rate: 0.007861]
	Learning Rate: 0.00786096
	LOSS [training: 0.01149237547415944 | validation: 0.010690151643206965]
	TIME [epoch: 8.3 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013007889500213948		[learning rate: 0.0078448]
	Learning Rate: 0.00784482
	LOSS [training: 0.013007889500213948 | validation: 0.03285922629545676]
	TIME [epoch: 8.31 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027846321919515037		[learning rate: 0.0078287]
	Learning Rate: 0.00782869
	LOSS [training: 0.027846321919515037 | validation: 0.021064324457321516]
	TIME [epoch: 8.31 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016200736228989265		[learning rate: 0.0078126]
	Learning Rate: 0.00781256
	LOSS [training: 0.016200736228989265 | validation: 0.011567161290545597]
	TIME [epoch: 8.35 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010656374336742394		[learning rate: 0.0077964]
	Learning Rate: 0.00779644
	LOSS [training: 0.010656374336742394 | validation: 0.03146659950089151]
	TIME [epoch: 8.32 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03712087279016059		[learning rate: 0.0077803]
	Learning Rate: 0.00778033
	LOSS [training: 0.03712087279016059 | validation: 0.026820875707762905]
	TIME [epoch: 8.32 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025207681770982298		[learning rate: 0.0077642]
	Learning Rate: 0.00776422
	LOSS [training: 0.025207681770982298 | validation: 0.019310033008410794]
	TIME [epoch: 8.31 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018072178003112303		[learning rate: 0.0077481]
	Learning Rate: 0.00774812
	LOSS [training: 0.018072178003112303 | validation: 0.013879408751222216]
	TIME [epoch: 8.3 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017188054051176176		[learning rate: 0.007732]
	Learning Rate: 0.00773202
	LOSS [training: 0.017188054051176176 | validation: 0.0208129035683743]
	TIME [epoch: 8.32 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01900475146935859		[learning rate: 0.0077159]
	Learning Rate: 0.00771593
	LOSS [training: 0.01900475146935859 | validation: 0.03152767807914107]
	TIME [epoch: 8.34 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022813342131880722		[learning rate: 0.0076998]
	Learning Rate: 0.00769985
	LOSS [training: 0.022813342131880722 | validation: 0.08068714431092341]
	TIME [epoch: 8.3 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04379626209457527		[learning rate: 0.0076838]
	Learning Rate: 0.00768377
	LOSS [training: 0.04379626209457527 | validation: 0.014266384681715177]
	TIME [epoch: 8.3 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012949856889205618		[learning rate: 0.0076677]
	Learning Rate: 0.0076677
	LOSS [training: 0.012949856889205618 | validation: 0.010156990825795416]
	TIME [epoch: 8.32 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009267253816615903		[learning rate: 0.0076516]
	Learning Rate: 0.00765163
	LOSS [training: 0.009267253816615903 | validation: 0.01903020149969865]
	TIME [epoch: 8.31 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02263057184314888		[learning rate: 0.0076356]
	Learning Rate: 0.00763557
	LOSS [training: 0.02263057184314888 | validation: 0.020740990424431734]
	TIME [epoch: 8.35 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022569152626345096		[learning rate: 0.0076195]
	Learning Rate: 0.00761952
	LOSS [training: 0.022569152626345096 | validation: 0.019410250105012114]
	TIME [epoch: 8.31 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014759578399532562		[learning rate: 0.0076035]
	Learning Rate: 0.00760347
	LOSS [training: 0.014759578399532562 | validation: 0.01571750134575631]
	TIME [epoch: 8.3 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015447997632687335		[learning rate: 0.0075874]
	Learning Rate: 0.00758744
	LOSS [training: 0.015447997632687335 | validation: 0.019219806555067658]
	TIME [epoch: 8.31 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021691452981316035		[learning rate: 0.0075714]
	Learning Rate: 0.0075714
	LOSS [training: 0.021691452981316035 | validation: 0.0390000808213722]
	TIME [epoch: 8.32 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024800936827103805		[learning rate: 0.0075554]
	Learning Rate: 0.00755538
	LOSS [training: 0.024800936827103805 | validation: 0.014440512521904349]
	TIME [epoch: 8.31 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011132137962111415		[learning rate: 0.0075394]
	Learning Rate: 0.00753936
	LOSS [training: 0.011132137962111415 | validation: 0.022576613747595356]
	TIME [epoch: 8.36 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02871728977229308		[learning rate: 0.0075233]
	Learning Rate: 0.00752335
	LOSS [training: 0.02871728977229308 | validation: 0.026268035715696414]
	TIME [epoch: 8.31 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013691727840030529		[learning rate: 0.0075073]
	Learning Rate: 0.00750734
	LOSS [training: 0.013691727840030529 | validation: 0.009589077656679719]
	TIME [epoch: 8.3 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015622097367599223		[learning rate: 0.0074913]
	Learning Rate: 0.00749134
	LOSS [training: 0.015622097367599223 | validation: 0.025258108430922896]
	TIME [epoch: 8.31 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023547270044327325		[learning rate: 0.0074754]
	Learning Rate: 0.00747535
	LOSS [training: 0.023547270044327325 | validation: 0.03869606870231099]
	TIME [epoch: 8.31 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027909945308191485		[learning rate: 0.0074594]
	Learning Rate: 0.00745937
	LOSS [training: 0.027909945308191485 | validation: 0.012528570024334934]
	TIME [epoch: 8.35 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011773084272176734		[learning rate: 0.0074434]
	Learning Rate: 0.00744339
	LOSS [training: 0.011773084272176734 | validation: 0.009186959339724195]
	TIME [epoch: 8.32 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015921389721559757		[learning rate: 0.0074274]
	Learning Rate: 0.00742742
	LOSS [training: 0.015921389721559757 | validation: 0.0335815499796312]
	TIME [epoch: 8.31 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023522830015528542		[learning rate: 0.0074115]
	Learning Rate: 0.00741145
	LOSS [training: 0.023522830015528542 | validation: 0.013170403851973725]
	TIME [epoch: 8.31 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014795790774341799		[learning rate: 0.0073955]
	Learning Rate: 0.0073955
	LOSS [training: 0.014795790774341799 | validation: 0.02363919483914046]
	TIME [epoch: 8.31 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01939687861329089		[learning rate: 0.0073795]
	Learning Rate: 0.00737955
	LOSS [training: 0.01939687861329089 | validation: 0.019830610392513725]
	TIME [epoch: 8.31 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025154127312182497		[learning rate: 0.0073636]
	Learning Rate: 0.0073636
	LOSS [training: 0.025154127312182497 | validation: 0.013679219609566463]
	TIME [epoch: 8.35 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011281051980697112		[learning rate: 0.0073477]
	Learning Rate: 0.00734767
	LOSS [training: 0.011281051980697112 | validation: 0.014729723932465022]
	TIME [epoch: 8.32 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01671458956234437		[learning rate: 0.0073317]
	Learning Rate: 0.00733174
	LOSS [training: 0.01671458956234437 | validation: 0.0550829159061238]
	TIME [epoch: 8.31 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03200778222569452		[learning rate: 0.0073158]
	Learning Rate: 0.00731582
	LOSS [training: 0.03200778222569452 | validation: 0.011756148466981064]
	TIME [epoch: 8.31 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009308975965295927		[learning rate: 0.0072999]
	Learning Rate: 0.00729991
	LOSS [training: 0.009308975965295927 | validation: 0.01054167869832718]
	TIME [epoch: 8.31 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015074526516082105		[learning rate: 0.007284]
	Learning Rate: 0.007284
	LOSS [training: 0.015074526516082105 | validation: 0.040638457043239935]
	TIME [epoch: 8.35 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027602873642579333		[learning rate: 0.0072681]
	Learning Rate: 0.0072681
	LOSS [training: 0.027602873642579333 | validation: 0.012309749913271181]
	TIME [epoch: 8.33 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011790776977518892		[learning rate: 0.0072522]
	Learning Rate: 0.00725221
	LOSS [training: 0.011790776977518892 | validation: 0.00945966978509492]
	TIME [epoch: 8.31 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012489239949837257		[learning rate: 0.0072363]
	Learning Rate: 0.00723633
	LOSS [training: 0.012489239949837257 | validation: 0.026326072752205935]
	TIME [epoch: 8.31 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01905624643854139		[learning rate: 0.0072205]
	Learning Rate: 0.00722045
	LOSS [training: 0.01905624643854139 | validation: 0.019499504334702464]
	TIME [epoch: 8.32 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02156248297622447		[learning rate: 0.0072046]
	Learning Rate: 0.00720458
	LOSS [training: 0.02156248297622447 | validation: 0.025245826661744818]
	TIME [epoch: 8.32 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015689123388728115		[learning rate: 0.0071887]
	Learning Rate: 0.00718872
	LOSS [training: 0.015689123388728115 | validation: 0.007986077870415146]
	TIME [epoch: 8.35 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013638915990211801		[learning rate: 0.0071729]
	Learning Rate: 0.00717287
	LOSS [training: 0.013638915990211801 | validation: 0.02332325870912708]
	TIME [epoch: 8.31 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023446702011926425		[learning rate: 0.007157]
	Learning Rate: 0.00715702
	LOSS [training: 0.023446702011926425 | validation: 0.015536318043714999]
	TIME [epoch: 8.31 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020749141973985023		[learning rate: 0.0071412]
	Learning Rate: 0.00714119
	LOSS [training: 0.020749141973985023 | validation: 0.01483300572477736]
	TIME [epoch: 8.3 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01307543534353364		[learning rate: 0.0071254]
	Learning Rate: 0.00712536
	LOSS [training: 0.01307543534353364 | validation: 0.016540148438101625]
	TIME [epoch: 8.31 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01745119212647426		[learning rate: 0.0071095]
	Learning Rate: 0.00710954
	LOSS [training: 0.01745119212647426 | validation: 0.009732204110815584]
	TIME [epoch: 8.35 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013362764912501227		[learning rate: 0.0070937]
	Learning Rate: 0.00709372
	LOSS [training: 0.013362764912501227 | validation: 0.02242851062125003]
	TIME [epoch: 8.33 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025293081929200198		[learning rate: 0.0070779]
	Learning Rate: 0.00707792
	LOSS [training: 0.025293081929200198 | validation: 0.019661879101496294]
	TIME [epoch: 8.31 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01631725046129957		[learning rate: 0.0070621]
	Learning Rate: 0.00706212
	LOSS [training: 0.01631725046129957 | validation: 0.013136621013663169]
	TIME [epoch: 8.31 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015693349930678842		[learning rate: 0.0070463]
	Learning Rate: 0.00704633
	LOSS [training: 0.015693349930678842 | validation: 0.010425838640527763]
	TIME [epoch: 8.32 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013410297886699375		[learning rate: 0.0070305]
	Learning Rate: 0.00703055
	LOSS [training: 0.013410297886699375 | validation: 0.02375579133652237]
	TIME [epoch: 8.32 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020770510836628498		[learning rate: 0.0070148]
	Learning Rate: 0.00701477
	LOSS [training: 0.020770510836628498 | validation: 0.012518667060563652]
	TIME [epoch: 8.36 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03599975371803108		[learning rate: 0.006999]
	Learning Rate: 0.00699901
	LOSS [training: 0.03599975371803108 | validation: 0.04213948669424288]
	TIME [epoch: 8.32 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022171377906566182		[learning rate: 0.0069833]
	Learning Rate: 0.00698325
	LOSS [training: 0.022171377906566182 | validation: 0.010687427707844794]
	TIME [epoch: 8.31 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00882901510363546		[learning rate: 0.0069675]
	Learning Rate: 0.0069675
	LOSS [training: 0.00882901510363546 | validation: 0.010253336194636453]
	TIME [epoch: 8.31 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013243783347470055		[learning rate: 0.0069518]
	Learning Rate: 0.00695176
	LOSS [training: 0.013243783347470055 | validation: 0.04030753471203363]
	TIME [epoch: 8.32 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030135920760537654		[learning rate: 0.006936]
	Learning Rate: 0.00693603
	LOSS [training: 0.030135920760537654 | validation: 0.015441101639082331]
	TIME [epoch: 8.34 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010225708524200183		[learning rate: 0.0069203]
	Learning Rate: 0.0069203
	LOSS [training: 0.010225708524200183 | validation: 0.010798584301643719]
	TIME [epoch: 8.34 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012245930802011749		[learning rate: 0.0069046]
	Learning Rate: 0.00690459
	LOSS [training: 0.012245930802011749 | validation: 0.010910721524318604]
	TIME [epoch: 8.31 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01578525218128057		[learning rate: 0.0068889]
	Learning Rate: 0.00688888
	LOSS [training: 0.01578525218128057 | validation: 0.021541518128835823]
	TIME [epoch: 8.31 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021385881832781346		[learning rate: 0.0068732]
	Learning Rate: 0.00687318
	LOSS [training: 0.021385881832781346 | validation: 0.010572489807118782]
	TIME [epoch: 8.31 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012482566741734088		[learning rate: 0.0068575]
	Learning Rate: 0.00685749
	LOSS [training: 0.012482566741734088 | validation: 0.015515774887358193]
	TIME [epoch: 8.3 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01286762745616332		[learning rate: 0.0068418]
	Learning Rate: 0.00684181
	LOSS [training: 0.01286762745616332 | validation: 0.010487152617531182]
	TIME [epoch: 8.36 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01825167561505133		[learning rate: 0.0068261]
	Learning Rate: 0.00682614
	LOSS [training: 0.01825167561505133 | validation: 0.022637053844796404]
	TIME [epoch: 8.32 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020498375575025818		[learning rate: 0.0068105]
	Learning Rate: 0.00681048
	LOSS [training: 0.020498375575025818 | validation: 0.01619930935298402]
	TIME [epoch: 8.3 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013251194877563263		[learning rate: 0.0067948]
	Learning Rate: 0.00679482
	LOSS [training: 0.013251194877563263 | validation: 0.007074481297660503]
	TIME [epoch: 8.31 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010253679491259084		[learning rate: 0.0067792]
	Learning Rate: 0.00677917
	LOSS [training: 0.010253679491259084 | validation: 0.01266607157948413]
	TIME [epoch: 8.31 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019085097988814453		[learning rate: 0.0067635]
	Learning Rate: 0.00676354
	LOSS [training: 0.019085097988814453 | validation: 0.02536803818743915]
	TIME [epoch: 8.33 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024581265966124248		[learning rate: 0.0067479]
	Learning Rate: 0.00674791
	LOSS [training: 0.024581265966124248 | validation: 0.008059650206002265]
	TIME [epoch: 8.35 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011103370738606561		[learning rate: 0.0067323]
	Learning Rate: 0.00673229
	LOSS [training: 0.011103370738606561 | validation: 0.01094264430258815]
	TIME [epoch: 8.31 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012543315458573866		[learning rate: 0.0067167]
	Learning Rate: 0.00671668
	LOSS [training: 0.012543315458573866 | validation: 0.022303327644915365]
	TIME [epoch: 8.31 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020841967739340272		[learning rate: 0.0067011]
	Learning Rate: 0.00670108
	LOSS [training: 0.020841967739340272 | validation: 0.016874198807386574]
	TIME [epoch: 8.3 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01429670015794694		[learning rate: 0.0066855]
	Learning Rate: 0.00668548
	LOSS [training: 0.01429670015794694 | validation: 0.018204874657432264]
	TIME [epoch: 8.3 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016599070957274822		[learning rate: 0.0066699]
	Learning Rate: 0.0066699
	LOSS [training: 0.016599070957274822 | validation: 0.019311968927244887]
	TIME [epoch: 8.36 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015158734853354939		[learning rate: 0.0066543]
	Learning Rate: 0.00665432
	LOSS [training: 0.015158734853354939 | validation: 0.018613355372448983]
	TIME [epoch: 8.31 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014212621864923418		[learning rate: 0.0066388]
	Learning Rate: 0.00663876
	LOSS [training: 0.014212621864923418 | validation: 0.009457535389511851]
	TIME [epoch: 8.3 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014835062450476116		[learning rate: 0.0066232]
	Learning Rate: 0.0066232
	LOSS [training: 0.014835062450476116 | validation: 0.022327479071576208]
	TIME [epoch: 8.31 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021839948269091067		[learning rate: 0.0066077]
	Learning Rate: 0.00660765
	LOSS [training: 0.021839948269091067 | validation: 0.008682992346107504]
	TIME [epoch: 8.31 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011330938575855133		[learning rate: 0.0065921]
	Learning Rate: 0.00659212
	LOSS [training: 0.011330938575855133 | validation: 0.01106376025293251]
	TIME [epoch: 8.32 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016956138297268834		[learning rate: 0.0065766]
	Learning Rate: 0.00657659
	LOSS [training: 0.016956138297268834 | validation: 0.015418507368084153]
	TIME [epoch: 8.34 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014124479230803117		[learning rate: 0.0065611]
	Learning Rate: 0.00656107
	LOSS [training: 0.014124479230803117 | validation: 0.010123329866763765]
	TIME [epoch: 8.31 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013574432855416095		[learning rate: 0.0065456]
	Learning Rate: 0.00654556
	LOSS [training: 0.013574432855416095 | validation: 0.009695083256145261]
	TIME [epoch: 8.3 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00849033021499228		[learning rate: 0.0065301]
	Learning Rate: 0.00653006
	LOSS [training: 0.00849033021499228 | validation: 0.013370740996982964]
	TIME [epoch: 8.31 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023786990540488533		[learning rate: 0.0065146]
	Learning Rate: 0.00651457
	LOSS [training: 0.023786990540488533 | validation: 0.022731121318572717]
	TIME [epoch: 8.3 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02019923078053324		[learning rate: 0.0064991]
	Learning Rate: 0.00649909
	LOSS [training: 0.02019923078053324 | validation: 0.013786560588195888]
	TIME [epoch: 8.35 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01554500807203702		[learning rate: 0.0064836]
	Learning Rate: 0.00648362
	LOSS [training: 0.01554500807203702 | validation: 0.01718414850270724]
	TIME [epoch: 8.32 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015639863874518226		[learning rate: 0.0064682]
	Learning Rate: 0.00646815
	LOSS [training: 0.015639863874518226 | validation: 0.0354367851894758]
	TIME [epoch: 8.31 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02098542424429195		[learning rate: 0.0064527]
	Learning Rate: 0.0064527
	LOSS [training: 0.02098542424429195 | validation: 0.008915267811460518]
	TIME [epoch: 8.3 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006674376120390059		[learning rate: 0.0064373]
	Learning Rate: 0.00643726
	LOSS [training: 0.006674376120390059 | validation: 0.008677748856732198]
	TIME [epoch: 8.31 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010930929614058425		[learning rate: 0.0064218]
	Learning Rate: 0.00642183
	LOSS [training: 0.010930929614058425 | validation: 0.0296831640174232]
	TIME [epoch: 8.32 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022410264159511792		[learning rate: 0.0064064]
	Learning Rate: 0.0064064
	LOSS [training: 0.022410264159511792 | validation: 0.014469397996491728]
	TIME [epoch: 8.35 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009269164812026588		[learning rate: 0.006391]
	Learning Rate: 0.00639099
	LOSS [training: 0.009269164812026588 | validation: 0.021881726874164044]
	TIME [epoch: 8.31 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01942826429006861		[learning rate: 0.0063756]
	Learning Rate: 0.00637559
	LOSS [training: 0.01942826429006861 | validation: 0.02397473595791987]
	TIME [epoch: 8.31 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012073854200404759		[learning rate: 0.0063602]
	Learning Rate: 0.00636019
	LOSS [training: 0.012073854200404759 | validation: 0.023799028378204266]
	TIME [epoch: 8.31 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016109146244877606		[learning rate: 0.0063448]
	Learning Rate: 0.00634481
	LOSS [training: 0.016109146244877606 | validation: 0.011534865856779764]
	TIME [epoch: 8.31 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015646364681808207		[learning rate: 0.0063294]
	Learning Rate: 0.00632944
	LOSS [training: 0.015646364681808207 | validation: 0.014574656767959883]
	TIME [epoch: 8.34 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016042466580418715		[learning rate: 0.0063141]
	Learning Rate: 0.00631407
	LOSS [training: 0.016042466580418715 | validation: 0.006854801527344741]
	TIME [epoch: 8.32 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00766122873038289		[learning rate: 0.0062987]
	Learning Rate: 0.00629872
	LOSS [training: 0.00766122873038289 | validation: 0.014313946577409503]
	TIME [epoch: 8.31 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02392396521200482		[learning rate: 0.0062834]
	Learning Rate: 0.00628338
	LOSS [training: 0.02392396521200482 | validation: 0.02425801561664144]
	TIME [epoch: 8.3 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016254916868924208		[learning rate: 0.006268]
	Learning Rate: 0.00626804
	LOSS [training: 0.016254916868924208 | validation: 0.012273857235941082]
	TIME [epoch: 8.3 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010558552822306068		[learning rate: 0.0062527]
	Learning Rate: 0.00625272
	LOSS [training: 0.010558552822306068 | validation: 0.011978963312141967]
	TIME [epoch: 8.31 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012078770441963057		[learning rate: 0.0062374]
	Learning Rate: 0.00623741
	LOSS [training: 0.012078770441963057 | validation: 0.022275006534085075]
	TIME [epoch: 8.36 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014000490485083164		[learning rate: 0.0062221]
	Learning Rate: 0.00622211
	LOSS [training: 0.014000490485083164 | validation: 0.014905576046536907]
	TIME [epoch: 8.31 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014963741627920671		[learning rate: 0.0062068]
	Learning Rate: 0.00620681
	LOSS [training: 0.014963741627920671 | validation: 0.012801069653299793]
	TIME [epoch: 8.3 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01148642101507269		[learning rate: 0.0061915]
	Learning Rate: 0.00619153
	LOSS [training: 0.01148642101507269 | validation: 0.019895820079539366]
	TIME [epoch: 8.31 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014985329688272864		[learning rate: 0.0061763]
	Learning Rate: 0.00617626
	LOSS [training: 0.014985329688272864 | validation: 0.03845973467346707]
	TIME [epoch: 8.31 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014514684954960399		[learning rate: 0.006161]
	Learning Rate: 0.006161
	LOSS [training: 0.014514684954960399 | validation: 0.008651917099120318]
	TIME [epoch: 8.35 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015349767288273626		[learning rate: 0.0061458]
	Learning Rate: 0.00614575
	LOSS [training: 0.015349767288273626 | validation: 0.03252673858641736]
	TIME [epoch: 8.34 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021724822019840224		[learning rate: 0.0061305]
	Learning Rate: 0.00613051
	LOSS [training: 0.021724822019840224 | validation: 0.008090901228464356]
	TIME [epoch: 8.31 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00807670526947664		[learning rate: 0.0061153]
	Learning Rate: 0.00611528
	LOSS [training: 0.00807670526947664 | validation: 0.006828046024721281]
	TIME [epoch: 8.31 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0123769318564545		[learning rate: 0.0061001]
	Learning Rate: 0.00610007
	LOSS [training: 0.0123769318564545 | validation: 0.014490213769494581]
	TIME [epoch: 8.31 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018732327801654854		[learning rate: 0.0060849]
	Learning Rate: 0.00608486
	LOSS [training: 0.018732327801654854 | validation: 0.017055173986367703]
	TIME [epoch: 8.32 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011505564890309851		[learning rate: 0.0060697]
	Learning Rate: 0.00606966
	LOSS [training: 0.011505564890309851 | validation: 0.006844257285896535]
	TIME [epoch: 8.36 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009124737061375432		[learning rate: 0.0060545]
	Learning Rate: 0.00605447
	LOSS [training: 0.009124737061375432 | validation: 0.01614286247447257]
	TIME [epoch: 8.31 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01626557138298136		[learning rate: 0.0060393]
	Learning Rate: 0.0060393
	LOSS [training: 0.01626557138298136 | validation: 0.029084802356194782]
	TIME [epoch: 8.31 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016738545835558522		[learning rate: 0.0060241]
	Learning Rate: 0.00602413
	LOSS [training: 0.016738545835558522 | validation: 0.01019192471548605]
	TIME [epoch: 8.31 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04524597395683229		[learning rate: 0.006009]
	Learning Rate: 0.00600898
	LOSS [training: 0.04524597395683229 | validation: 0.011121405784600026]
	TIME [epoch: 8.31 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009292286830503926		[learning rate: 0.0059938]
	Learning Rate: 0.00599384
	LOSS [training: 0.009292286830503926 | validation: 0.006870630903032264]
	TIME [epoch: 8.35 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006893192865750412		[learning rate: 0.0059787]
	Learning Rate: 0.00597871
	LOSS [training: 0.006893192865750412 | validation: 0.007521474700246242]
	TIME [epoch: 8.32 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00655375371406921		[learning rate: 0.0059636]
	Learning Rate: 0.00596359
	LOSS [training: 0.00655375371406921 | validation: 0.006429543641727913]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_1252.pth
	Model improved!!!
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008804657843946722		[learning rate: 0.0059485]
	Learning Rate: 0.00594848
	LOSS [training: 0.008804657843946722 | validation: 0.014232866027783984]
	TIME [epoch: 8.3 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023800974750971718		[learning rate: 0.0059334]
	Learning Rate: 0.00593338
	LOSS [training: 0.023800974750971718 | validation: 0.01156851016500908]
	TIME [epoch: 8.3 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010000226075434458		[learning rate: 0.0059183]
	Learning Rate: 0.00591829
	LOSS [training: 0.010000226075434458 | validation: 0.011143022528591385]
	TIME [epoch: 8.31 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0097988265286529		[learning rate: 0.0059032]
	Learning Rate: 0.00590321
	LOSS [training: 0.0097988265286529 | validation: 0.010133927307131585]
	TIME [epoch: 8.35 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010531748527108909		[learning rate: 0.0058881]
	Learning Rate: 0.00588815
	LOSS [training: 0.010531748527108909 | validation: 0.014859963214874407]
	TIME [epoch: 8.31 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018187891674398403		[learning rate: 0.0058731]
	Learning Rate: 0.00587309
	LOSS [training: 0.018187891674398403 | validation: 0.008492646045541575]
	TIME [epoch: 8.31 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014465018659771962		[learning rate: 0.0058581]
	Learning Rate: 0.00585805
	LOSS [training: 0.014465018659771962 | validation: 0.021458161362387228]
	TIME [epoch: 8.3 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01622583397511092		[learning rate: 0.005843]
	Learning Rate: 0.00584302
	LOSS [training: 0.01622583397511092 | validation: 0.008301542054760021]
	TIME [epoch: 8.31 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010301705080716676		[learning rate: 0.005828]
	Learning Rate: 0.005828
	LOSS [training: 0.010301705080716676 | validation: 0.007452450732449515]
	TIME [epoch: 8.35 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00875385791888322		[learning rate: 0.005813]
	Learning Rate: 0.00581299
	LOSS [training: 0.00875385791888322 | validation: 0.010576401832447657]
	TIME [epoch: 8.33 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017090189119857897		[learning rate: 0.005798]
	Learning Rate: 0.005798
	LOSS [training: 0.017090189119857897 | validation: 0.010638383962364785]
	TIME [epoch: 8.31 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01038080115581174		[learning rate: 0.005783]
	Learning Rate: 0.00578301
	LOSS [training: 0.01038080115581174 | validation: 0.014650838708032871]
	TIME [epoch: 8.31 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013558643341429946		[learning rate: 0.005768]
	Learning Rate: 0.00576804
	LOSS [training: 0.013558643341429946 | validation: 0.01216215155965081]
	TIME [epoch: 8.31 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010627789770952772		[learning rate: 0.0057531]
	Learning Rate: 0.00575307
	LOSS [training: 0.010627789770952772 | validation: 0.013394329862007226]
	TIME [epoch: 8.31 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012320819167432554		[learning rate: 0.0057381]
	Learning Rate: 0.00573812
	LOSS [training: 0.012320819167432554 | validation: 0.011757643624869358]
	TIME [epoch: 8.32 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014967255895251635		[learning rate: 0.0057232]
	Learning Rate: 0.00572318
	LOSS [training: 0.014967255895251635 | validation: 0.006416733232268669]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_1268.pth
	Model improved!!!
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011054456635486432		[learning rate: 0.0057083]
	Learning Rate: 0.00570826
	LOSS [training: 0.011054456635486432 | validation: 0.015878207906168878]
	TIME [epoch: 8.32 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013158089786943649		[learning rate: 0.0056933]
	Learning Rate: 0.00569334
	LOSS [training: 0.013158089786943649 | validation: 0.01346899949125942]
	TIME [epoch: 8.33 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009177234436488692		[learning rate: 0.0056784]
	Learning Rate: 0.00567844
	LOSS [training: 0.009177234436488692 | validation: 0.032474451912549204]
	TIME [epoch: 8.34 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018846102512842237		[learning rate: 0.0056635]
	Learning Rate: 0.00566355
	LOSS [training: 0.018846102512842237 | validation: 0.009115888431298508]
	TIME [epoch: 8.37 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008609061427843748		[learning rate: 0.0056487]
	Learning Rate: 0.00564867
	LOSS [training: 0.008609061427843748 | validation: 0.01998439839354842]
	TIME [epoch: 8.35 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01892766504669059		[learning rate: 0.0056338]
	Learning Rate: 0.0056338
	LOSS [training: 0.01892766504669059 | validation: 0.015567707787094234]
	TIME [epoch: 8.43 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01079691841756586		[learning rate: 0.0056189]
	Learning Rate: 0.00561894
	LOSS [training: 0.01079691841756586 | validation: 0.006383658191019241]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_1275.pth
	Model improved!!!
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007584450966523516		[learning rate: 0.0056041]
	Learning Rate: 0.0056041
	LOSS [training: 0.007584450966523516 | validation: 0.013918011969088276]
	TIME [epoch: 8.33 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01579108292311726		[learning rate: 0.0055893]
	Learning Rate: 0.00558927
	LOSS [training: 0.01579108292311726 | validation: 0.017507850882141664]
	TIME [epoch: 8.33 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01183696240063841		[learning rate: 0.0055744]
	Learning Rate: 0.00557445
	LOSS [training: 0.01183696240063841 | validation: 0.009005824432273761]
	TIME [epoch: 8.37 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012144080914121476		[learning rate: 0.0055596]
	Learning Rate: 0.00555964
	LOSS [training: 0.012144080914121476 | validation: 0.011469201290742904]
	TIME [epoch: 8.33 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01166617538609858		[learning rate: 0.0055448]
	Learning Rate: 0.00554484
	LOSS [training: 0.01166617538609858 | validation: 0.012373307764844655]
	TIME [epoch: 8.32 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011943946792935704		[learning rate: 0.0055301]
	Learning Rate: 0.00553006
	LOSS [training: 0.011943946792935704 | validation: 0.021403517323179893]
	TIME [epoch: 8.33 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01115214628890036		[learning rate: 0.0055153]
	Learning Rate: 0.00551529
	LOSS [training: 0.01115214628890036 | validation: 0.009729375256755983]
	TIME [epoch: 8.33 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010911555239297342		[learning rate: 0.0055005]
	Learning Rate: 0.00550053
	LOSS [training: 0.010911555239297342 | validation: 0.008960634131235646]
	TIME [epoch: 8.37 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009996821428973846		[learning rate: 0.0054858]
	Learning Rate: 0.00548578
	LOSS [training: 0.009996821428973846 | validation: 0.007308791120456876]
	TIME [epoch: 8.34 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011374057498019344		[learning rate: 0.005471]
	Learning Rate: 0.00547105
	LOSS [training: 0.011374057498019344 | validation: 0.01317841958892824]
	TIME [epoch: 8.33 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01761584715973636		[learning rate: 0.0054563]
	Learning Rate: 0.00545632
	LOSS [training: 0.01761584715973636 | validation: 0.009492709566880671]
	TIME [epoch: 8.32 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013573588413310926		[learning rate: 0.0054416]
	Learning Rate: 0.00544161
	LOSS [training: 0.013573588413310926 | validation: 0.011176775429129229]
	TIME [epoch: 8.32 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007371790787993213		[learning rate: 0.0054269]
	Learning Rate: 0.00542692
	LOSS [training: 0.007371790787993213 | validation: 0.0048996546572093085]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_1288.pth
	Model improved!!!
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006064912218117597		[learning rate: 0.0054122]
	Learning Rate: 0.00541223
	LOSS [training: 0.006064912218117597 | validation: 0.03138196523902996]
	TIME [epoch: 8.36 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02353048688460207		[learning rate: 0.0053976]
	Learning Rate: 0.00539756
	LOSS [training: 0.02353048688460207 | validation: 0.00841705944615296]
	TIME [epoch: 8.31 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0071015657068046086		[learning rate: 0.0053829]
	Learning Rate: 0.0053829
	LOSS [training: 0.0071015657068046086 | validation: 0.007634939403090544]
	TIME [epoch: 8.31 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008127611803484253		[learning rate: 0.0053683]
	Learning Rate: 0.00536825
	LOSS [training: 0.008127611803484253 | validation: 0.011841920142036937]
	TIME [epoch: 8.31 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01169731958514536		[learning rate: 0.0053536]
	Learning Rate: 0.00535362
	LOSS [training: 0.01169731958514536 | validation: 0.018329254101273968]
	TIME [epoch: 8.31 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011778669523387231		[learning rate: 0.005339]
	Learning Rate: 0.005339
	LOSS [training: 0.011778669523387231 | validation: 0.009652495510146375]
	TIME [epoch: 8.35 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010401020912451703		[learning rate: 0.0053244]
	Learning Rate: 0.00532439
	LOSS [training: 0.010401020912451703 | validation: 0.017847309555640713]
	TIME [epoch: 8.32 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014148190855074148		[learning rate: 0.0053098]
	Learning Rate: 0.00530979
	LOSS [training: 0.014148190855074148 | validation: 0.008005131660080192]
	TIME [epoch: 8.32 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00990697382905411		[learning rate: 0.0052952]
	Learning Rate: 0.00529521
	LOSS [training: 0.00990697382905411 | validation: 0.012685700167300452]
	TIME [epoch: 8.32 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010730936107010989		[learning rate: 0.0052806]
	Learning Rate: 0.00528064
	LOSS [training: 0.010730936107010989 | validation: 0.009801174862682803]
	TIME [epoch: 8.31 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011063684712061563		[learning rate: 0.0052661]
	Learning Rate: 0.00526608
	LOSS [training: 0.011063684712061563 | validation: 0.010635484965821607]
	TIME [epoch: 8.33 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014174764535547585		[learning rate: 0.0052515]
	Learning Rate: 0.00525154
	LOSS [training: 0.014174764535547585 | validation: 0.007897839973016973]
	TIME [epoch: 8.36 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009328599325539977		[learning rate: 0.005237]
	Learning Rate: 0.00523701
	LOSS [training: 0.009328599325539977 | validation: 0.008758641913573981]
	TIME [epoch: 8.32 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009676734099692642		[learning rate: 0.0052225]
	Learning Rate: 0.00522249
	LOSS [training: 0.009676734099692642 | validation: 0.006785851484632679]
	TIME [epoch: 8.31 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00822149249953541		[learning rate: 0.005208]
	Learning Rate: 0.00520799
	LOSS [training: 0.00822149249953541 | validation: 0.01117072307306204]
	TIME [epoch: 8.31 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017041697591543767		[learning rate: 0.0051935]
	Learning Rate: 0.00519349
	LOSS [training: 0.017041697591543767 | validation: 0.010510303691586285]
	TIME [epoch: 8.3 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00968822301779177		[learning rate: 0.005179]
	Learning Rate: 0.00517901
	LOSS [training: 0.00968822301779177 | validation: 0.005596659607838353]
	TIME [epoch: 8.35 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01415833890317926		[learning rate: 0.0051645]
	Learning Rate: 0.00516455
	LOSS [training: 0.01415833890317926 | validation: 0.01897876486956135]
	TIME [epoch: 8.32 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014479165464457844		[learning rate: 0.0051501]
	Learning Rate: 0.0051501
	LOSS [training: 0.014479165464457844 | validation: 0.007540269374376799]
	TIME [epoch: 8.31 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006160898822569433		[learning rate: 0.0051357]
	Learning Rate: 0.00513566
	LOSS [training: 0.006160898822569433 | validation: 0.006446823558374197]
	TIME [epoch: 8.31 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011589539609447745		[learning rate: 0.0051212]
	Learning Rate: 0.00512123
	LOSS [training: 0.011589539609447745 | validation: 0.01764136203123296]
	TIME [epoch: 8.31 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010836936373728658		[learning rate: 0.0051068]
	Learning Rate: 0.00510682
	LOSS [training: 0.010836936373728658 | validation: 0.00826436690486624]
	TIME [epoch: 8.31 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007555567028814587		[learning rate: 0.0050924]
	Learning Rate: 0.00509242
	LOSS [training: 0.007555567028814587 | validation: 0.006296234688728487]
	TIME [epoch: 8.35 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007942626218243563		[learning rate: 0.005078]
	Learning Rate: 0.00507803
	LOSS [training: 0.007942626218243563 | validation: 0.011274368718023182]
	TIME [epoch: 8.31 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0138508013385055		[learning rate: 0.0050637]
	Learning Rate: 0.00506366
	LOSS [training: 0.0138508013385055 | validation: 0.011077695060040381]
	TIME [epoch: 8.32 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00952354450478013		[learning rate: 0.0050493]
	Learning Rate: 0.0050493
	LOSS [training: 0.00952354450478013 | validation: 0.017035925292678108]
	TIME [epoch: 8.32 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013685119388371914		[learning rate: 0.005035]
	Learning Rate: 0.00503496
	LOSS [training: 0.013685119388371914 | validation: 0.007415797554019718]
	TIME [epoch: 8.31 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006397422835411157		[learning rate: 0.0050206]
	Learning Rate: 0.00502063
	LOSS [training: 0.006397422835411157 | validation: 0.007136938156719726]
	TIME [epoch: 8.36 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014813827720651429		[learning rate: 0.0050063]
	Learning Rate: 0.00500631
	LOSS [training: 0.014813827720651429 | validation: 0.014702680232416759]
	TIME [epoch: 8.32 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014486315621673612		[learning rate: 0.004992]
	Learning Rate: 0.004992
	LOSS [training: 0.014486315621673612 | validation: 0.01146529352157803]
	TIME [epoch: 8.31 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008396301598989162		[learning rate: 0.0049777]
	Learning Rate: 0.00497771
	LOSS [training: 0.008396301598989162 | validation: 0.008667124384608167]
	TIME [epoch: 8.32 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011065537338027738		[learning rate: 0.0049634]
	Learning Rate: 0.00496344
	LOSS [training: 0.011065537338027738 | validation: 0.012310002752683336]
	TIME [epoch: 8.31 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009886101928573542		[learning rate: 0.0049492]
	Learning Rate: 0.00494917
	LOSS [training: 0.009886101928573542 | validation: 0.00884766071818202]
	TIME [epoch: 8.32 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009256067253646208		[learning rate: 0.0049349]
	Learning Rate: 0.00493492
	LOSS [training: 0.009256067253646208 | validation: 0.008122293320992735]
	TIME [epoch: 8.36 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006720406853673364		[learning rate: 0.0049207]
	Learning Rate: 0.00492069
	LOSS [training: 0.006720406853673364 | validation: 0.006663767291547985]
	TIME [epoch: 8.31 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008242115296758803		[learning rate: 0.0049065]
	Learning Rate: 0.00490647
	LOSS [training: 0.008242115296758803 | validation: 0.014601443464431242]
	TIME [epoch: 8.32 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013505596406829072		[learning rate: 0.0048923]
	Learning Rate: 0.00489226
	LOSS [training: 0.013505596406829072 | validation: 0.010394261774635252]
	TIME [epoch: 8.31 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007126215507894849		[learning rate: 0.0048781]
	Learning Rate: 0.00487807
	LOSS [training: 0.007126215507894849 | validation: 0.006366162602990557]
	TIME [epoch: 8.32 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011254883294869275		[learning rate: 0.0048639]
	Learning Rate: 0.00486389
	LOSS [training: 0.011254883294869275 | validation: 0.014398964105859249]
	TIME [epoch: 8.35 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011487617659310095		[learning rate: 0.0048497]
	Learning Rate: 0.00484972
	LOSS [training: 0.011487617659310095 | validation: 0.007899188380073217]
	TIME [epoch: 8.32 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021036487415254407		[learning rate: 0.0048356]
	Learning Rate: 0.00483557
	LOSS [training: 0.021036487415254407 | validation: 0.017614546975630356]
	TIME [epoch: 8.32 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009822832427577546		[learning rate: 0.0048214]
	Learning Rate: 0.00482143
	LOSS [training: 0.009822832427577546 | validation: 0.007136468163140196]
	TIME [epoch: 8.32 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0060283231317040074		[learning rate: 0.0048073]
	Learning Rate: 0.00480731
	LOSS [training: 0.0060283231317040074 | validation: 0.006255909780967073]
	TIME [epoch: 8.32 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009107435409332374		[learning rate: 0.0047932]
	Learning Rate: 0.0047932
	LOSS [training: 0.009107435409332374 | validation: 0.010270566794305012]
	TIME [epoch: 8.32 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01158463213871155		[learning rate: 0.0047791]
	Learning Rate: 0.0047791
	LOSS [training: 0.01158463213871155 | validation: 0.00856853937199468]
	TIME [epoch: 8.36 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007089207975789488		[learning rate: 0.004765]
	Learning Rate: 0.00476502
	LOSS [training: 0.007089207975789488 | validation: 0.00716626901020522]
	TIME [epoch: 8.31 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008524995239452172		[learning rate: 0.004751]
	Learning Rate: 0.00475096
	LOSS [training: 0.008524995239452172 | validation: 0.009397146904732506]
	TIME [epoch: 8.31 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009869189758879914		[learning rate: 0.0047369]
	Learning Rate: 0.00473691
	LOSS [training: 0.009869189758879914 | validation: 0.006690233988611247]
	TIME [epoch: 8.31 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007936236926961646		[learning rate: 0.0047229]
	Learning Rate: 0.00472287
	LOSS [training: 0.007936236926961646 | validation: 0.006447833390467607]
	TIME [epoch: 8.31 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007751280030308983		[learning rate: 0.0047088]
	Learning Rate: 0.00470885
	LOSS [training: 0.007751280030308983 | validation: 0.01064206016917258]
	TIME [epoch: 8.35 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011809262960043494		[learning rate: 0.0046948]
	Learning Rate: 0.00469484
	LOSS [training: 0.011809262960043494 | validation: 0.011163668077624695]
	TIME [epoch: 8.33 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017445875723112212		[learning rate: 0.0046808]
	Learning Rate: 0.00468084
	LOSS [training: 0.017445875723112212 | validation: 0.032154825320164115]
	TIME [epoch: 8.31 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018923951672764984		[learning rate: 0.0046669]
	Learning Rate: 0.00466686
	LOSS [training: 0.018923951672764984 | validation: 0.005998394713467973]
	TIME [epoch: 8.31 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004579460272473187		[learning rate: 0.0046529]
	Learning Rate: 0.0046529
	LOSS [training: 0.004579460272473187 | validation: 0.004574348558796054]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_1342.pth
	Model improved!!!
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0071394487609042915		[learning rate: 0.0046389]
	Learning Rate: 0.00463895
	LOSS [training: 0.0071394487609042915 | validation: 0.00746366540641687]
	TIME [epoch: 8.32 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004790619214486931		[learning rate: 0.004625]
	Learning Rate: 0.00462501
	LOSS [training: 0.004790619214486931 | validation: 0.008064062520360436]
	TIME [epoch: 8.34 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010678349615293597		[learning rate: 0.0046111]
	Learning Rate: 0.00461109
	LOSS [training: 0.010678349615293597 | validation: 0.015185063732623544]
	TIME [epoch: 8.27 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011618806135298702		[learning rate: 0.0045972]
	Learning Rate: 0.00459719
	LOSS [training: 0.011618806135298702 | validation: 0.00848955126843347]
	TIME [epoch: 8.26 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007221255604055576		[learning rate: 0.0045833]
	Learning Rate: 0.0045833
	LOSS [training: 0.007221255604055576 | validation: 0.007871567367400394]
	TIME [epoch: 8.26 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008542191259496033		[learning rate: 0.0045694]
	Learning Rate: 0.00456942
	LOSS [training: 0.008542191259496033 | validation: 0.01517060046343624]
	TIME [epoch: 8.26 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00995438470813826		[learning rate: 0.0045556]
	Learning Rate: 0.00455556
	LOSS [training: 0.00995438470813826 | validation: 0.00567397761649486]
	TIME [epoch: 8.29 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005763287247717514		[learning rate: 0.0045417]
	Learning Rate: 0.00454171
	LOSS [training: 0.005763287247717514 | validation: 0.00602274724590998]
	TIME [epoch: 8.27 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008319907746615018		[learning rate: 0.0045279]
	Learning Rate: 0.00452788
	LOSS [training: 0.008319907746615018 | validation: 0.010488813349205778]
	TIME [epoch: 8.25 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013224562817016353		[learning rate: 0.0045141]
	Learning Rate: 0.00451406
	LOSS [training: 0.013224562817016353 | validation: 0.009045893016852997]
	TIME [epoch: 8.26 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008284593731049297		[learning rate: 0.0045003]
	Learning Rate: 0.00450026
	LOSS [training: 0.008284593731049297 | validation: 0.006811937108062298]
	TIME [epoch: 8.25 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009797425596820423		[learning rate: 0.0044865]
	Learning Rate: 0.00448648
	LOSS [training: 0.009797425596820423 | validation: 0.014650995303488738]
	TIME [epoch: 8.26 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01228116937952467		[learning rate: 0.0044727]
	Learning Rate: 0.0044727
	LOSS [training: 0.01228116937952467 | validation: 0.008866304288346307]
	TIME [epoch: 8.32 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007647362709786247		[learning rate: 0.0044589]
	Learning Rate: 0.00445895
	LOSS [training: 0.007647362709786247 | validation: 0.010156944451396381]
	TIME [epoch: 8.26 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010296259565013122		[learning rate: 0.0044452]
	Learning Rate: 0.00444521
	LOSS [training: 0.010296259565013122 | validation: 0.00871432833282216]
	TIME [epoch: 8.25 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005693670396621037		[learning rate: 0.0044315]
	Learning Rate: 0.00443148
	LOSS [training: 0.005693670396621037 | validation: 0.00560426106712107]
	TIME [epoch: 8.26 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0067007102164126035		[learning rate: 0.0044178]
	Learning Rate: 0.00441777
	LOSS [training: 0.0067007102164126035 | validation: 0.012167744197346887]
	TIME [epoch: 8.26 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013686098864301582		[learning rate: 0.0044041]
	Learning Rate: 0.00440407
	LOSS [training: 0.013686098864301582 | validation: 0.008259101609812004]
	TIME [epoch: 8.28 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007128564865217631		[learning rate: 0.0043904]
	Learning Rate: 0.00439039
	LOSS [training: 0.007128564865217631 | validation: 0.0064347170409966]
	TIME [epoch: 8.29 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007380018672818524		[learning rate: 0.0043767]
	Learning Rate: 0.00437673
	LOSS [training: 0.007380018672818524 | validation: 0.009339986943886549]
	TIME [epoch: 8.26 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008585851212305142		[learning rate: 0.0043631]
	Learning Rate: 0.00436308
	LOSS [training: 0.008585851212305142 | validation: 0.009061064578390173]
	TIME [epoch: 8.26 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007587036456591616		[learning rate: 0.0043494]
	Learning Rate: 0.00434945
	LOSS [training: 0.007587036456591616 | validation: 0.007993498731987375]
	TIME [epoch: 8.27 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007647075587751889		[learning rate: 0.0043358]
	Learning Rate: 0.00433583
	LOSS [training: 0.007647075587751889 | validation: 0.008356338334827613]
	TIME [epoch: 8.26 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024713148533571906		[learning rate: 0.0043222]
	Learning Rate: 0.00432222
	LOSS [training: 0.024713148533571906 | validation: 0.01809174757981252]
	TIME [epoch: 8.3 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008798744848751426		[learning rate: 0.0043086]
	Learning Rate: 0.00430864
	LOSS [training: 0.008798744848751426 | validation: 0.007211805848825291]
	TIME [epoch: 8.26 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006533929990241595		[learning rate: 0.0042951]
	Learning Rate: 0.00429506
	LOSS [training: 0.006533929990241595 | validation: 0.00922472263933087]
	TIME [epoch: 8.26 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013122932478658		[learning rate: 0.0042815]
	Learning Rate: 0.00428151
	LOSS [training: 0.013122932478658 | validation: 0.008211431772266839]
	TIME [epoch: 8.27 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006786564308792988		[learning rate: 0.004268]
	Learning Rate: 0.00426797
	LOSS [training: 0.006786564308792988 | validation: 0.005905012033247513]
	TIME [epoch: 8.25 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005759393802125969		[learning rate: 0.0042544]
	Learning Rate: 0.00425444
	LOSS [training: 0.005759393802125969 | validation: 0.007111550338474022]
	TIME [epoch: 8.29 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0071521215153074295		[learning rate: 0.0042409]
	Learning Rate: 0.00424093
	LOSS [training: 0.0071521215153074295 | validation: 0.00792823554677475]
	TIME [epoch: 8.31 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007361989326494048		[learning rate: 0.0042274]
	Learning Rate: 0.00422744
	LOSS [training: 0.007361989326494048 | validation: 0.009161378982597817]
	TIME [epoch: 8.28 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011564349971276514		[learning rate: 0.004214]
	Learning Rate: 0.00421396
	LOSS [training: 0.011564349971276514 | validation: 0.010329384910784303]
	TIME [epoch: 8.29 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00880942852712263		[learning rate: 0.0042005]
	Learning Rate: 0.0042005
	LOSS [training: 0.00880942852712263 | validation: 0.011445295266346921]
	TIME [epoch: 8.27 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00953180867422		[learning rate: 0.0041871]
	Learning Rate: 0.00418705
	LOSS [training: 0.00953180867422 | validation: 0.015407540767562357]
	TIME [epoch: 8.27 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010044002955882573		[learning rate: 0.0041736]
	Learning Rate: 0.00417362
	LOSS [training: 0.010044002955882573 | validation: 0.011096073863688567]
	TIME [epoch: 8.29 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006712876648058907		[learning rate: 0.0041602]
	Learning Rate: 0.00416021
	LOSS [training: 0.006712876648058907 | validation: 0.005307331915481552]
	TIME [epoch: 8.27 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0075477061060017486		[learning rate: 0.0041468]
	Learning Rate: 0.00414681
	LOSS [training: 0.0075477061060017486 | validation: 0.012446844337638312]
	TIME [epoch: 8.25 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010314392506459378		[learning rate: 0.0041334]
	Learning Rate: 0.00413343
	LOSS [training: 0.010314392506459378 | validation: 0.008015527729052726]
	TIME [epoch: 8.26 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006802339787845163		[learning rate: 0.0041201]
	Learning Rate: 0.00412006
	LOSS [training: 0.006802339787845163 | validation: 0.0073858860120462385]
	TIME [epoch: 8.26 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008675305561267273		[learning rate: 0.0041067]
	Learning Rate: 0.00410671
	LOSS [training: 0.008675305561267273 | validation: 0.01491729692867907]
	TIME [epoch: 8.27 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011100870761202976		[learning rate: 0.0040934]
	Learning Rate: 0.00409338
	LOSS [training: 0.011100870761202976 | validation: 0.010709827977686203]
	TIME [epoch: 8.3 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005974175035619212		[learning rate: 0.0040801]
	Learning Rate: 0.00408006
	LOSS [training: 0.005974175035619212 | validation: 0.004103317934628399]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_1384.pth
	Model improved!!!
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005754492662557285		[learning rate: 0.0040668]
	Learning Rate: 0.00406676
	LOSS [training: 0.005754492662557285 | validation: 0.00811630031386152]
	TIME [epoch: 8.28 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008113110601283918		[learning rate: 0.0040535]
	Learning Rate: 0.00405347
	LOSS [training: 0.008113110601283918 | validation: 0.010181994195784663]
	TIME [epoch: 8.27 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010213929535833341		[learning rate: 0.0040402]
	Learning Rate: 0.00404021
	LOSS [training: 0.010213929535833341 | validation: 0.007056428888331066]
	TIME [epoch: 8.26 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009977819665497531		[learning rate: 0.004027]
	Learning Rate: 0.00402695
	LOSS [training: 0.009977819665497531 | validation: 0.00969041068490665]
	TIME [epoch: 8.3 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007183019803966084		[learning rate: 0.0040137]
	Learning Rate: 0.00401372
	LOSS [training: 0.007183019803966084 | validation: 0.007726850487765659]
	TIME [epoch: 8.26 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007246438432961759		[learning rate: 0.0040005]
	Learning Rate: 0.0040005
	LOSS [training: 0.007246438432961759 | validation: 0.007991561662422287]
	TIME [epoch: 8.26 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0071945570643809865		[learning rate: 0.0039873]
	Learning Rate: 0.00398729
	LOSS [training: 0.0071945570643809865 | validation: 0.008082081778113714]
	TIME [epoch: 8.25 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010087968173765482		[learning rate: 0.0039741]
	Learning Rate: 0.00397411
	LOSS [training: 0.010087968173765482 | validation: 0.010089505595833334]
	TIME [epoch: 8.25 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007031450381127095		[learning rate: 0.0039609]
	Learning Rate: 0.00396093
	LOSS [training: 0.007031450381127095 | validation: 0.0060762554216127005]
	TIME [epoch: 8.26 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005703991217495219		[learning rate: 0.0039478]
	Learning Rate: 0.00394778
	LOSS [training: 0.005703991217495219 | validation: 0.006189763581614322]
	TIME [epoch: 8.3 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008969621439826955		[learning rate: 0.0039346]
	Learning Rate: 0.00393464
	LOSS [training: 0.008969621439826955 | validation: 0.012151454942482435]
	TIME [epoch: 8.27 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008585633830578187		[learning rate: 0.0039215]
	Learning Rate: 0.00392152
	LOSS [training: 0.008585633830578187 | validation: 0.010550516912627811]
	TIME [epoch: 8.26 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030869162334635394		[learning rate: 0.0039084]
	Learning Rate: 0.00390842
	LOSS [training: 0.030869162334635394 | validation: 0.020364553991059547]
	TIME [epoch: 8.26 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011687774576330889		[learning rate: 0.0038953]
	Learning Rate: 0.00389533
	LOSS [training: 0.011687774576330889 | validation: 0.00663803299277803]
	TIME [epoch: 8.25 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006497616614022296		[learning rate: 0.0038823]
	Learning Rate: 0.00388226
	LOSS [training: 0.006497616614022296 | validation: 0.005886111188740864]
	TIME [epoch: 8.29 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005796535287331638		[learning rate: 0.0038692]
	Learning Rate: 0.0038692
	LOSS [training: 0.005796535287331638 | validation: 0.004879503416833362]
	TIME [epoch: 8.34 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007286839255523897		[learning rate: 0.0038562]
	Learning Rate: 0.00385617
	LOSS [training: 0.007286839255523897 | validation: 0.00831730863927866]
	TIME [epoch: 8.27 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006066732937575525		[learning rate: 0.0038431]
	Learning Rate: 0.00384315
	LOSS [training: 0.006066732937575525 | validation: 0.01651817038894018]
	TIME [epoch: 8.26 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00821754111640186		[learning rate: 0.0038301]
	Learning Rate: 0.00383014
	LOSS [training: 0.00821754111640186 | validation: 0.005304941006370054]
	TIME [epoch: 8.25 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005036454168873941		[learning rate: 0.0038172]
	Learning Rate: 0.00381716
	LOSS [training: 0.005036454168873941 | validation: 0.009384419579239352]
	TIME [epoch: 8.27 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010273948890567229		[learning rate: 0.0038042]
	Learning Rate: 0.00380419
	LOSS [training: 0.010273948890567229 | validation: 0.006429042155672292]
	TIME [epoch: 8.31 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006132826721298593		[learning rate: 0.0037912]
	Learning Rate: 0.00379123
	LOSS [training: 0.006132826721298593 | validation: 0.006357638892200974]
	TIME [epoch: 8.27 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006184866147528877		[learning rate: 0.0037783]
	Learning Rate: 0.0037783
	LOSS [training: 0.006184866147528877 | validation: 0.0058796142075086405]
	TIME [epoch: 8.26 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0062879445565147815		[learning rate: 0.0037654]
	Learning Rate: 0.00376538
	LOSS [training: 0.0062879445565147815 | validation: 0.006649322152275572]
	TIME [epoch: 8.25 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011566939074840903		[learning rate: 0.0037525]
	Learning Rate: 0.00375248
	LOSS [training: 0.011566939074840903 | validation: 0.012556606735949513]
	TIME [epoch: 8.25 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006655027473104012		[learning rate: 0.0037396]
	Learning Rate: 0.00373959
	LOSS [training: 0.006655027473104012 | validation: 0.005127951934630422]
	TIME [epoch: 8.29 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0059247492607056055		[learning rate: 0.0037267]
	Learning Rate: 0.00372672
	LOSS [training: 0.0059247492607056055 | validation: 0.007150442724369982]
	TIME [epoch: 8.27 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006621649148302955		[learning rate: 0.0037139]
	Learning Rate: 0.00371387
	LOSS [training: 0.006621649148302955 | validation: 0.006666066642664818]
	TIME [epoch: 8.26 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007126863459163607		[learning rate: 0.003701]
	Learning Rate: 0.00370104
	LOSS [training: 0.007126863459163607 | validation: 0.006761969841546792]
	TIME [epoch: 8.25 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005139124219963741		[learning rate: 0.0036882]
	Learning Rate: 0.00368822
	LOSS [training: 0.005139124219963741 | validation: 0.007911604348007964]
	TIME [epoch: 8.26 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0063252843618194325		[learning rate: 0.0036754]
	Learning Rate: 0.00367542
	LOSS [training: 0.0063252843618194325 | validation: 0.01091167544378358]
	TIME [epoch: 8.26 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01422764546955399		[learning rate: 0.0036626]
	Learning Rate: 0.00366264
	LOSS [training: 0.01422764546955399 | validation: 0.006363381262940297]
	TIME [epoch: 8.31 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005340265938758234		[learning rate: 0.0036499]
	Learning Rate: 0.00364988
	LOSS [training: 0.005340265938758234 | validation: 0.004505465121157773]
	TIME [epoch: 8.26 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004969169434474161		[learning rate: 0.0036371]
	Learning Rate: 0.00363713
	LOSS [training: 0.004969169434474161 | validation: 0.0067813210247085086]
	TIME [epoch: 8.26 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007590235287460081		[learning rate: 0.0036244]
	Learning Rate: 0.0036244
	LOSS [training: 0.007590235287460081 | validation: 0.006811393986350735]
	TIME [epoch: 8.26 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005612531633655765		[learning rate: 0.0036117]
	Learning Rate: 0.00361169
	LOSS [training: 0.005612531633655765 | validation: 0.010845476480304851]
	TIME [epoch: 8.27 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008185471707551165		[learning rate: 0.003599]
	Learning Rate: 0.003599
	LOSS [training: 0.008185471707551165 | validation: 0.008339468597448404]
	TIME [epoch: 8.27 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005696623867746527		[learning rate: 0.0035863]
	Learning Rate: 0.00358632
	LOSS [training: 0.005696623867746527 | validation: 0.007520336062311495]
	TIME [epoch: 8.29 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006646284806239841		[learning rate: 0.0035737]
	Learning Rate: 0.00357366
	LOSS [training: 0.006646284806239841 | validation: 0.005646919287938784]
	TIME [epoch: 8.26 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00836252476234492		[learning rate: 0.003561]
	Learning Rate: 0.00356102
	LOSS [training: 0.00836252476234492 | validation: 0.020166379196926987]
	TIME [epoch: 8.26 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010756104474887975		[learning rate: 0.0035484]
	Learning Rate: 0.00354839
	LOSS [training: 0.010756104474887975 | validation: 0.011076010635913963]
	TIME [epoch: 8.26 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00871543218812218		[learning rate: 0.0035358]
	Learning Rate: 0.00353579
	LOSS [training: 0.00871543218812218 | validation: 0.005251719093817702]
	TIME [epoch: 8.26 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0045713372548183305		[learning rate: 0.0035232]
	Learning Rate: 0.0035232
	LOSS [training: 0.0045713372548183305 | validation: 0.01054540539245545]
	TIME [epoch: 8.3 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0058045036334182926		[learning rate: 0.0035106]
	Learning Rate: 0.00351063
	LOSS [training: 0.0058045036334182926 | validation: 0.007810395132369621]
	TIME [epoch: 8.26 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007343065275201284		[learning rate: 0.0034981]
	Learning Rate: 0.00349807
	LOSS [training: 0.007343065275201284 | validation: 0.0052115448769959214]
	TIME [epoch: 8.25 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006811801243597336		[learning rate: 0.0034855]
	Learning Rate: 0.00348554
	LOSS [training: 0.006811801243597336 | validation: 0.00846925834581117]
	TIME [epoch: 8.25 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005525837602546418		[learning rate: 0.003473]
	Learning Rate: 0.00347302
	LOSS [training: 0.005525837602546418 | validation: 0.005439437034644355]
	TIME [epoch: 8.25 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004813526801369773		[learning rate: 0.0034605]
	Learning Rate: 0.00346052
	LOSS [training: 0.004813526801369773 | validation: 0.011880896095937853]
	TIME [epoch: 8.28 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010623015831443594		[learning rate: 0.003448]
	Learning Rate: 0.00344804
	LOSS [training: 0.010623015831443594 | validation: 0.006884677040357877]
	TIME [epoch: 8.29 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007283971829959671		[learning rate: 0.0034356]
	Learning Rate: 0.00343557
	LOSS [training: 0.007283971829959671 | validation: 0.006471606648478803]
	TIME [epoch: 8.25 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006060730708283995		[learning rate: 0.0034231]
	Learning Rate: 0.00342313
	LOSS [training: 0.006060730708283995 | validation: 0.004355349566653828]
	TIME [epoch: 8.26 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006363639009082156		[learning rate: 0.0034107]
	Learning Rate: 0.0034107
	LOSS [training: 0.006363639009082156 | validation: 0.008487793906957253]
	TIME [epoch: 8.25 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006813244487142163		[learning rate: 0.0033983]
	Learning Rate: 0.00339829
	LOSS [training: 0.006813244487142163 | validation: 0.007554567406677043]
	TIME [epoch: 8.25 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005763272906786431		[learning rate: 0.0033859]
	Learning Rate: 0.0033859
	LOSS [training: 0.005763272906786431 | validation: 0.005001423412009395]
	TIME [epoch: 8.3 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005420843179324235		[learning rate: 0.0033735]
	Learning Rate: 0.00337352
	LOSS [training: 0.005420843179324235 | validation: 0.008109185148245709]
	TIME [epoch: 8.26 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005506542150222129		[learning rate: 0.0033612]
	Learning Rate: 0.00336117
	LOSS [training: 0.005506542150222129 | validation: 0.008925945368097469]
	TIME [epoch: 8.25 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010006411839070035		[learning rate: 0.0033488]
	Learning Rate: 0.00334883
	LOSS [training: 0.010006411839070035 | validation: 0.006778946818290401]
	TIME [epoch: 8.26 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005376128227885639		[learning rate: 0.0033365]
	Learning Rate: 0.00333651
	LOSS [training: 0.005376128227885639 | validation: 0.005104395014125183]
	TIME [epoch: 8.26 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005495471473466697		[learning rate: 0.0033242]
	Learning Rate: 0.00332421
	LOSS [training: 0.005495471473466697 | validation: 0.009338407604560041]
	TIME [epoch: 8.26 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006315779250678833		[learning rate: 0.0033119]
	Learning Rate: 0.00331192
	LOSS [training: 0.006315779250678833 | validation: 0.006872844142683516]
	TIME [epoch: 8.31 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0058166322855740795		[learning rate: 0.0032997]
	Learning Rate: 0.00329966
	LOSS [training: 0.0058166322855740795 | validation: 0.005389415879800288]
	TIME [epoch: 8.27 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00878200012824495		[learning rate: 0.0032874]
	Learning Rate: 0.00328741
	LOSS [training: 0.00878200012824495 | validation: 0.005745035282875304]
	TIME [epoch: 8.26 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005670267096987442		[learning rate: 0.0032752]
	Learning Rate: 0.00327518
	LOSS [training: 0.005670267096987442 | validation: 0.008059736257006945]
	TIME [epoch: 8.26 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005629851786341871		[learning rate: 0.003263]
	Learning Rate: 0.00326298
	LOSS [training: 0.005629851786341871 | validation: 0.005354813523298797]
	TIME [epoch: 8.26 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0046634916244166795		[learning rate: 0.0032508]
	Learning Rate: 0.00325078
	LOSS [training: 0.0046634916244166795 | validation: 0.006427889318471148]
	TIME [epoch: 8.29 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00958207025166729		[learning rate: 0.0032386]
	Learning Rate: 0.00323861
	LOSS [training: 0.00958207025166729 | validation: 0.006708962858508409]
	TIME [epoch: 8.27 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005600904788725186		[learning rate: 0.0032265]
	Learning Rate: 0.00322646
	LOSS [training: 0.005600904788725186 | validation: 0.00427180489032271]
	TIME [epoch: 8.26 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007148462931648083		[learning rate: 0.0032143]
	Learning Rate: 0.00321432
	LOSS [training: 0.007148462931648083 | validation: 0.008047811550897035]
	TIME [epoch: 8.26 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006013651830368687		[learning rate: 0.0032022]
	Learning Rate: 0.0032022
	LOSS [training: 0.006013651830368687 | validation: 0.0066080520952089255]
	TIME [epoch: 8.26 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008655665852652622		[learning rate: 0.0031901]
	Learning Rate: 0.00319011
	LOSS [training: 0.008655665852652622 | validation: 0.005931058275099462]
	TIME [epoch: 8.27 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005672368818752435		[learning rate: 0.003178]
	Learning Rate: 0.00317803
	LOSS [training: 0.005672368818752435 | validation: 0.005173374508631989]
	TIME [epoch: 8.3 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005926178145823957		[learning rate: 0.003166]
	Learning Rate: 0.00316596
	LOSS [training: 0.005926178145823957 | validation: 0.0067373294179824215]
	TIME [epoch: 8.26 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0054681715113588875		[learning rate: 0.0031539]
	Learning Rate: 0.00315392
	LOSS [training: 0.0054681715113588875 | validation: 0.007853010410209768]
	TIME [epoch: 8.26 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004648151664178064		[learning rate: 0.0031419]
	Learning Rate: 0.0031419
	LOSS [training: 0.004648151664178064 | validation: 0.013219988243148932]
	TIME [epoch: 8.26 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007568883793062326		[learning rate: 0.0031299]
	Learning Rate: 0.00312989
	LOSS [training: 0.007568883793062326 | validation: 0.004720698125021765]
	TIME [epoch: 8.26 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011434585625799711		[learning rate: 0.0031179]
	Learning Rate: 0.00311791
	LOSS [training: 0.011434585625799711 | validation: 0.012610640280374154]
	TIME [epoch: 8.27 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006596733133571655		[learning rate: 0.0031059]
	Learning Rate: 0.00310594
	LOSS [training: 0.006596733133571655 | validation: 0.0035806725730715937]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_1461.pth
	Model improved!!!
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0047939562995650605		[learning rate: 0.003094]
	Learning Rate: 0.00309399
	LOSS [training: 0.0047939562995650605 | validation: 0.005542460663223187]
	TIME [epoch: 8.28 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004783378679063263		[learning rate: 0.0030821]
	Learning Rate: 0.00308206
	LOSS [training: 0.004783378679063263 | validation: 0.004879092831516496]
	TIME [epoch: 8.27 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004317297988452004		[learning rate: 0.0030701]
	Learning Rate: 0.00307015
	LOSS [training: 0.004317297988452004 | validation: 0.004523778918022534]
	TIME [epoch: 8.28 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00458256733064523		[learning rate: 0.0030583]
	Learning Rate: 0.00305826
	LOSS [training: 0.00458256733064523 | validation: 0.006371541926465106]
	TIME [epoch: 8.28 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0067536248117369664		[learning rate: 0.0030464]
	Learning Rate: 0.00304639
	LOSS [training: 0.0067536248117369664 | validation: 0.008456726380561615]
	TIME [epoch: 8.32 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008257268489213734		[learning rate: 0.0030345]
	Learning Rate: 0.00303453
	LOSS [training: 0.008257268489213734 | validation: 0.007184319486601443]
	TIME [epoch: 8.27 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006048675980010789		[learning rate: 0.0030227]
	Learning Rate: 0.0030227
	LOSS [training: 0.006048675980010789 | validation: 0.004752352847242356]
	TIME [epoch: 8.27 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004742368721373205		[learning rate: 0.0030109]
	Learning Rate: 0.00301088
	LOSS [training: 0.004742368721373205 | validation: 0.006402884134803185]
	TIME [epoch: 8.28 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006752117661252938		[learning rate: 0.0029991]
	Learning Rate: 0.00299908
	LOSS [training: 0.006752117661252938 | validation: 0.005528789974671159]
	TIME [epoch: 8.27 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00487456944818655		[learning rate: 0.0029873]
	Learning Rate: 0.00298731
	LOSS [training: 0.00487456944818655 | validation: 0.004237851864086969]
	TIME [epoch: 8.3 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038535109008190982		[learning rate: 0.0029755]
	Learning Rate: 0.00297555
	LOSS [training: 0.0038535109008190982 | validation: 0.006421356457944397]
	TIME [epoch: 8.3 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0075310114191163915		[learning rate: 0.0029638]
	Learning Rate: 0.00296381
	LOSS [training: 0.0075310114191163915 | validation: 0.00799920281640143]
	TIME [epoch: 8.27 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0058967484276723076		[learning rate: 0.0029521]
	Learning Rate: 0.00295209
	LOSS [training: 0.0058967484276723076 | validation: 0.008187406448826614]
	TIME [epoch: 8.28 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006305319468875642		[learning rate: 0.0029404]
	Learning Rate: 0.00294039
	LOSS [training: 0.006305319468875642 | validation: 0.0056713557105478474]
	TIME [epoch: 8.27 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005560962532699456		[learning rate: 0.0029287]
	Learning Rate: 0.00292871
	LOSS [training: 0.005560962532699456 | validation: 0.004406547529451741]
	TIME [epoch: 8.28 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004755912748731497		[learning rate: 0.002917]
	Learning Rate: 0.00291705
	LOSS [training: 0.004755912748731497 | validation: 0.005231183765219669]
	TIME [epoch: 8.32 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005037523242128987		[learning rate: 0.0029054]
	Learning Rate: 0.0029054
	LOSS [training: 0.005037523242128987 | validation: 0.008889998550117982]
	TIME [epoch: 8.27 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0067022542032777336		[learning rate: 0.0028938]
	Learning Rate: 0.00289378
	LOSS [training: 0.0067022542032777336 | validation: 0.00665355730699811]
	TIME [epoch: 8.27 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004957610509766807		[learning rate: 0.0028822]
	Learning Rate: 0.00288218
	LOSS [training: 0.004957610509766807 | validation: 0.008842004803979326]
	TIME [epoch: 8.28 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0056575528177358995		[learning rate: 0.0028706]
	Learning Rate: 0.00287059
	LOSS [training: 0.0056575528177358995 | validation: 0.006312337888907833]
	TIME [epoch: 8.28 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005438973779486477		[learning rate: 0.002859]
	Learning Rate: 0.00285903
	LOSS [training: 0.005438973779486477 | validation: 0.009421494318688717]
	TIME [epoch: 8.31 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006401782492195737		[learning rate: 0.0028475]
	Learning Rate: 0.00284748
	LOSS [training: 0.006401782492195737 | validation: 0.00493828224212417]
	TIME [epoch: 8.31 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003852095165156462		[learning rate: 0.002836]
	Learning Rate: 0.00283596
	LOSS [training: 0.003852095165156462 | validation: 0.005097397663018643]
	TIME [epoch: 8.27 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004266232817577807		[learning rate: 0.0028245]
	Learning Rate: 0.00282445
	LOSS [training: 0.004266232817577807 | validation: 0.012026493932096595]
	TIME [epoch: 8.27 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007503483222756416		[learning rate: 0.002813]
	Learning Rate: 0.00281297
	LOSS [training: 0.007503483222756416 | validation: 0.00950328885440305]
	TIME [epoch: 8.27 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006532105950022823		[learning rate: 0.0028015]
	Learning Rate: 0.0028015
	LOSS [training: 0.006532105950022823 | validation: 0.00814590917760842]
	TIME [epoch: 8.27 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004880763772462263		[learning rate: 0.0027901]
	Learning Rate: 0.00279005
	LOSS [training: 0.004880763772462263 | validation: 0.0080170748719293]
	TIME [epoch: 8.31 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006285140776751264		[learning rate: 0.0027786]
	Learning Rate: 0.00277863
	LOSS [training: 0.006285140776751264 | validation: 0.00446960780948218]
	TIME [epoch: 8.28 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00517559233570282		[learning rate: 0.0027672]
	Learning Rate: 0.00276722
	LOSS [training: 0.00517559233570282 | validation: 0.006512604420515869]
	TIME [epoch: 8.27 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006600792291611795		[learning rate: 0.0027558]
	Learning Rate: 0.00275583
	LOSS [training: 0.006600792291611795 | validation: 0.0048131186696763785]
	TIME [epoch: 8.27 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004534233151851176		[learning rate: 0.0027445]
	Learning Rate: 0.00274446
	LOSS [training: 0.004534233151851176 | validation: 0.005076114581274115]
	TIME [epoch: 8.27 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006018861585102356		[learning rate: 0.0027331]
	Learning Rate: 0.00273312
	LOSS [training: 0.006018861585102356 | validation: 0.010813916806810877]
	TIME [epoch: 8.28 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006170023530852211		[learning rate: 0.0027218]
	Learning Rate: 0.00272179
	LOSS [training: 0.006170023530852211 | validation: 0.005872013491937278]
	TIME [epoch: 8.32 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003735288520866378		[learning rate: 0.0027105]
	Learning Rate: 0.00271048
	LOSS [training: 0.003735288520866378 | validation: 0.005445496562621065]
	TIME [epoch: 8.28 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0070037682733203165		[learning rate: 0.0026992]
	Learning Rate: 0.00269919
	LOSS [training: 0.0070037682733203165 | validation: 0.009923101340391413]
	TIME [epoch: 8.27 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0055500939999064665		[learning rate: 0.0026879]
	Learning Rate: 0.00268792
	LOSS [training: 0.0055500939999064665 | validation: 0.005365667182592495]
	TIME [epoch: 8.28 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007781934705574957		[learning rate: 0.0026767]
	Learning Rate: 0.00267667
	LOSS [training: 0.007781934705574957 | validation: 0.005992583823131082]
	TIME [epoch: 8.27 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004304441533107901		[learning rate: 0.0026654]
	Learning Rate: 0.00266545
	LOSS [training: 0.004304441533107901 | validation: 0.003404511823140106]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_1499.pth
	Model improved!!!
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005182148744267066		[learning rate: 0.0026542]
	Learning Rate: 0.00265424
	LOSS [training: 0.005182148744267066 | validation: 0.004785624632060734]
	TIME [epoch: 8.28 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004188328526893444		[learning rate: 0.0026431]
	Learning Rate: 0.00264305
	LOSS [training: 0.004188328526893444 | validation: 0.004616548378782389]
	TIME [epoch: 8.26 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006005804169256295		[learning rate: 0.0026319]
	Learning Rate: 0.00263188
	LOSS [training: 0.006005804169256295 | validation: 0.004252600012159239]
	TIME [epoch: 8.27 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037286421593657167		[learning rate: 0.0026207]
	Learning Rate: 0.00262073
	LOSS [training: 0.0037286421593657167 | validation: 0.006511444985497789]
	TIME [epoch: 8.26 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006122512679049724		[learning rate: 0.0026096]
	Learning Rate: 0.00260961
	LOSS [training: 0.006122512679049724 | validation: 0.007399489493851096]
	TIME [epoch: 8.27 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004494151597940706		[learning rate: 0.0025985]
	Learning Rate: 0.0025985
	LOSS [training: 0.004494151597940706 | validation: 0.005484098750473168]
	TIME [epoch: 8.31 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011405821069127428		[learning rate: 0.0025874]
	Learning Rate: 0.00258741
	LOSS [training: 0.011405821069127428 | validation: 0.024635498567267336]
	TIME [epoch: 8.27 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010874337492243466		[learning rate: 0.0025763]
	Learning Rate: 0.00257635
	LOSS [training: 0.010874337492243466 | validation: 0.00999680394630013]
	TIME [epoch: 8.26 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00499193234458382		[learning rate: 0.0025653]
	Learning Rate: 0.0025653
	LOSS [training: 0.00499193234458382 | validation: 0.006646877023255355]
	TIME [epoch: 8.26 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004275705595456487		[learning rate: 0.0025543]
	Learning Rate: 0.00255427
	LOSS [training: 0.004275705595456487 | validation: 0.0056221138894200235]
	TIME [epoch: 8.26 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004578656485597524		[learning rate: 0.0025433]
	Learning Rate: 0.00254327
	LOSS [training: 0.004578656485597524 | validation: 0.004676231510565641]
	TIME [epoch: 8.3 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004376799579490354		[learning rate: 0.0025323]
	Learning Rate: 0.00253228
	LOSS [training: 0.004376799579490354 | validation: 0.008713557264878236]
	TIME [epoch: 8.27 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004504019054963869		[learning rate: 0.0025213]
	Learning Rate: 0.00252132
	LOSS [training: 0.004504019054963869 | validation: 0.005839041168900833]
	TIME [epoch: 8.31 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004614336164795548		[learning rate: 0.0025104]
	Learning Rate: 0.00251037
	LOSS [training: 0.004614336164795548 | validation: 0.005098207431212748]
	TIME [epoch: 8.26 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003984369097635227		[learning rate: 0.0024994]
	Learning Rate: 0.00249945
	LOSS [training: 0.003984369097635227 | validation: 0.005813085657283305]
	TIME [epoch: 8.26 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004540965797991252		[learning rate: 0.0024885]
	Learning Rate: 0.00248855
	LOSS [training: 0.004540965797991252 | validation: 0.004077368579489945]
	TIME [epoch: 8.27 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0054580780682181185		[learning rate: 0.0024777]
	Learning Rate: 0.00247766
	LOSS [training: 0.0054580780682181185 | validation: 0.005229502751189708]
	TIME [epoch: 8.3 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005561093373429339		[learning rate: 0.0024668]
	Learning Rate: 0.0024668
	LOSS [training: 0.005561093373429339 | validation: 0.006362226013630986]
	TIME [epoch: 8.27 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004441429103930975		[learning rate: 0.002456]
	Learning Rate: 0.00245596
	LOSS [training: 0.004441429103930975 | validation: 0.006187201907188661]
	TIME [epoch: 8.26 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0054239474198725275		[learning rate: 0.0024451]
	Learning Rate: 0.00244514
	LOSS [training: 0.0054239474198725275 | validation: 0.0053705616081126655]
	TIME [epoch: 8.27 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005184924738803723		[learning rate: 0.0024343]
	Learning Rate: 0.00243434
	LOSS [training: 0.005184924738803723 | validation: 0.006433045452856508]
	TIME [epoch: 8.26 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005485538551656189		[learning rate: 0.0024236]
	Learning Rate: 0.00242356
	LOSS [training: 0.005485538551656189 | validation: 0.004865626513899246]
	TIME [epoch: 8.31 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003946569052121548		[learning rate: 0.0024128]
	Learning Rate: 0.0024128
	LOSS [training: 0.003946569052121548 | validation: 0.00414490572287647]
	TIME [epoch: 8.27 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004048495328268194		[learning rate: 0.0024021]
	Learning Rate: 0.00240206
	LOSS [training: 0.004048495328268194 | validation: 0.010553100428193768]
	TIME [epoch: 8.27 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0062299507054424386		[learning rate: 0.0023913]
	Learning Rate: 0.00239134
	LOSS [training: 0.0062299507054424386 | validation: 0.00906003671620012]
	TIME [epoch: 8.26 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005283017111222115		[learning rate: 0.0023806]
	Learning Rate: 0.00238065
	LOSS [training: 0.005283017111222115 | validation: 0.00447478406572885]
	TIME [epoch: 8.27 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00417597442188951		[learning rate: 0.00237]
	Learning Rate: 0.00236997
	LOSS [training: 0.00417597442188951 | validation: 0.005590854060348066]
	TIME [epoch: 8.26 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004175566995019068		[learning rate: 0.0023593]
	Learning Rate: 0.00235931
	LOSS [training: 0.004175566995019068 | validation: 0.006015401370794723]
	TIME [epoch: 8.31 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003595306838065291		[learning rate: 0.0023487]
	Learning Rate: 0.00234868
	LOSS [training: 0.003595306838065291 | validation: 0.004780007806457216]
	TIME [epoch: 8.26 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005347390164805153		[learning rate: 0.0023381]
	Learning Rate: 0.00233807
	LOSS [training: 0.005347390164805153 | validation: 0.004982048337661131]
	TIME [epoch: 8.27 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004851663549703089		[learning rate: 0.0023275]
	Learning Rate: 0.00232748
	LOSS [training: 0.004851663549703089 | validation: 0.004659724129131661]
	TIME [epoch: 8.26 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003991273347054402		[learning rate: 0.0023169]
	Learning Rate: 0.0023169
	LOSS [training: 0.003991273347054402 | validation: 0.005137918947598666]
	TIME [epoch: 8.25 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004829532440477631		[learning rate: 0.0023064]
	Learning Rate: 0.00230635
	LOSS [training: 0.004829532440477631 | validation: 0.004331615634989518]
	TIME [epoch: 8.29 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036725916268664028		[learning rate: 0.0022958]
	Learning Rate: 0.00229583
	LOSS [training: 0.0036725916268664028 | validation: 0.0049618758031427235]
	TIME [epoch: 8.28 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004767867164090316		[learning rate: 0.0022853]
	Learning Rate: 0.00228532
	LOSS [training: 0.004767867164090316 | validation: 0.006024034218691875]
	TIME [epoch: 8.26 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005488663249223538		[learning rate: 0.0022748]
	Learning Rate: 0.00227483
	LOSS [training: 0.005488663249223538 | validation: 0.00505130925457364]
	TIME [epoch: 8.28 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004118781971907092		[learning rate: 0.0022644]
	Learning Rate: 0.00226436
	LOSS [training: 0.004118781971907092 | validation: 0.0052572865860897]
	TIME [epoch: 8.26 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005374504952500195		[learning rate: 0.0022539]
	Learning Rate: 0.00225392
	LOSS [training: 0.005374504952500195 | validation: 0.009493388199774157]
	TIME [epoch: 8.26 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005357963512993519		[learning rate: 0.0022435]
	Learning Rate: 0.0022435
	LOSS [training: 0.005357963512993519 | validation: 0.0037944964041026186]
	TIME [epoch: 8.31 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003695157120915979		[learning rate: 0.0022331]
	Learning Rate: 0.00223309
	LOSS [training: 0.003695157120915979 | validation: 0.004519060079525482]
	TIME [epoch: 8.27 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004389162652457292		[learning rate: 0.0022227]
	Learning Rate: 0.00222271
	LOSS [training: 0.004389162652457292 | validation: 0.005416800983813694]
	TIME [epoch: 8.25 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003785901114163339		[learning rate: 0.0022124]
	Learning Rate: 0.00221235
	LOSS [training: 0.003785901114163339 | validation: 0.003927147985258954]
	TIME [epoch: 8.26 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005280714765289781		[learning rate: 0.002202]
	Learning Rate: 0.00220202
	LOSS [training: 0.005280714765289781 | validation: 0.0041943163003953145]
	TIME [epoch: 8.26 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036911692174290867		[learning rate: 0.0021917]
	Learning Rate: 0.0021917
	LOSS [training: 0.0036911692174290867 | validation: 0.005133966863763112]
	TIME [epoch: 8.27 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0050060666180371145		[learning rate: 0.0021814]
	Learning Rate: 0.0021814
	LOSS [training: 0.0050060666180371145 | validation: 0.004632243378765489]
	TIME [epoch: 8.3 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004037962673061055		[learning rate: 0.0021711]
	Learning Rate: 0.00217113
	LOSS [training: 0.004037962673061055 | validation: 0.007101873714147788]
	TIME [epoch: 8.26 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005578484918139801		[learning rate: 0.0021609]
	Learning Rate: 0.00216088
	LOSS [training: 0.005578484918139801 | validation: 0.004164823145273385]
	TIME [epoch: 8.26 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003758885853645016		[learning rate: 0.0021506]
	Learning Rate: 0.00215064
	LOSS [training: 0.003758885853645016 | validation: 0.0051235524279452]
	TIME [epoch: 8.26 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0065373888701155776		[learning rate: 0.0021404]
	Learning Rate: 0.00214043
	LOSS [training: 0.0065373888701155776 | validation: 0.020296208596309432]
	TIME [epoch: 8.25 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00946695777154186		[learning rate: 0.0021302]
	Learning Rate: 0.00213025
	LOSS [training: 0.00946695777154186 | validation: 0.0032935447803884516]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_1549.pth
	Model improved!!!
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00396453671223225		[learning rate: 0.0021201]
	Learning Rate: 0.00212008
	LOSS [training: 0.00396453671223225 | validation: 0.004397527689824584]
	TIME [epoch: 8.26 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003473753169594021		[learning rate: 0.0021099]
	Learning Rate: 0.00210993
	LOSS [training: 0.003473753169594021 | validation: 0.003598619196610053]
	TIME [epoch: 8.25 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004583849595099718		[learning rate: 0.0020998]
	Learning Rate: 0.00209981
	LOSS [training: 0.004583849595099718 | validation: 0.004399896082244835]
	TIME [epoch: 8.26 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00561651026888276		[learning rate: 0.0020897]
	Learning Rate: 0.00208971
	LOSS [training: 0.00561651026888276 | validation: 0.006247236001211646]
	TIME [epoch: 8.26 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004695401705297332		[learning rate: 0.0020796]
	Learning Rate: 0.00207963
	LOSS [training: 0.004695401705297332 | validation: 0.004829811872009666]
	TIME [epoch: 8.27 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003917142676356026		[learning rate: 0.0020696]
	Learning Rate: 0.00206957
	LOSS [training: 0.003917142676356026 | validation: 0.006098107974425039]
	TIME [epoch: 8.29 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00345064876150394		[learning rate: 0.0020595]
	Learning Rate: 0.00205953
	LOSS [training: 0.00345064876150394 | validation: 0.0038492964674566163]
	TIME [epoch: 8.25 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003943117692229486		[learning rate: 0.0020495]
	Learning Rate: 0.00204952
	LOSS [training: 0.003943117692229486 | validation: 0.00418692207293268]
	TIME [epoch: 8.26 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004134772552785105		[learning rate: 0.0020395]
	Learning Rate: 0.00203952
	LOSS [training: 0.004134772552785105 | validation: 0.007379015726482865]
	TIME [epoch: 8.25 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005097774061134235		[learning rate: 0.0020296]
	Learning Rate: 0.00202955
	LOSS [training: 0.005097774061134235 | validation: 0.0037830526718497684]
	TIME [epoch: 8.26 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003403487065172544		[learning rate: 0.0020196]
	Learning Rate: 0.0020196
	LOSS [training: 0.003403487065172544 | validation: 0.004296344763093872]
	TIME [epoch: 8.3 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035100228293606303		[learning rate: 0.0020097]
	Learning Rate: 0.00200967
	LOSS [training: 0.0035100228293606303 | validation: 0.005440666797351891]
	TIME [epoch: 8.27 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0049787449593357465		[learning rate: 0.0019998]
	Learning Rate: 0.00199977
	LOSS [training: 0.0049787449593357465 | validation: 0.0037610658599418695]
	TIME [epoch: 8.26 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003446491048912736		[learning rate: 0.0019899]
	Learning Rate: 0.00198988
	LOSS [training: 0.003446491048912736 | validation: 0.005649373001034666]
	TIME [epoch: 8.26 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005167616655525268		[learning rate: 0.00198]
	Learning Rate: 0.00198002
	LOSS [training: 0.005167616655525268 | validation: 0.006551607175942928]
	TIME [epoch: 8.25 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004401354488865357		[learning rate: 0.0019702]
	Learning Rate: 0.00197018
	LOSS [training: 0.004401354488865357 | validation: 0.003259131560899255]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_1565.pth
	Model improved!!!
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038178791369692907		[learning rate: 0.0019604]
	Learning Rate: 0.00196036
	LOSS [training: 0.0038178791369692907 | validation: 0.0032285122527424964]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_1566.pth
	Model improved!!!
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0039056717377504552		[learning rate: 0.0019506]
	Learning Rate: 0.00195056
	LOSS [training: 0.0039056717377504552 | validation: 0.004451770587315238]
	TIME [epoch: 8.25 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004141119996107827		[learning rate: 0.0019408]
	Learning Rate: 0.00194079
	LOSS [training: 0.004141119996107827 | validation: 0.003982012817651305]
	TIME [epoch: 8.26 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003986551538872746		[learning rate: 0.001931]
	Learning Rate: 0.00193103
	LOSS [training: 0.003986551538872746 | validation: 0.0032313987414108033]
	TIME [epoch: 8.25 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00370696806675424		[learning rate: 0.0019213]
	Learning Rate: 0.0019213
	LOSS [training: 0.00370696806675424 | validation: 0.004697943049776179]
	TIME [epoch: 8.26 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003493915447430553		[learning rate: 0.0019116]
	Learning Rate: 0.0019116
	LOSS [training: 0.003493915447430553 | validation: 0.0038586991111731377]
	TIME [epoch: 8.29 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004121529803182358		[learning rate: 0.0019019]
	Learning Rate: 0.00190191
	LOSS [training: 0.004121529803182358 | validation: 0.004803621956311001]
	TIME [epoch: 8.26 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004424740091031051		[learning rate: 0.0018922]
	Learning Rate: 0.00189225
	LOSS [training: 0.004424740091031051 | validation: 0.004311139633793036]
	TIME [epoch: 8.25 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034075171454711695		[learning rate: 0.0018826]
	Learning Rate: 0.0018826
	LOSS [training: 0.0034075171454711695 | validation: 0.010855870981735908]
	TIME [epoch: 8.26 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004617204899991766		[learning rate: 0.001873]
	Learning Rate: 0.00187298
	LOSS [training: 0.004617204899991766 | validation: 0.0028005315136245875]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_1575.pth
	Model improved!!!
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003797461097152604		[learning rate: 0.0018634]
	Learning Rate: 0.00186339
	LOSS [training: 0.003797461097152604 | validation: 0.0036776253536882574]
	TIME [epoch: 8.26 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0043336946844903		[learning rate: 0.0018538]
	Learning Rate: 0.00185381
	LOSS [training: 0.0043336946844903 | validation: 0.005176360702280191]
	TIME [epoch: 8.3 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037524949984835986		[learning rate: 0.0018443]
	Learning Rate: 0.00184426
	LOSS [training: 0.0037524949984835986 | validation: 0.005000981263175507]
	TIME [epoch: 8.25 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036999358787534672		[learning rate: 0.0018347]
	Learning Rate: 0.00183473
	LOSS [training: 0.0036999358787534672 | validation: 0.004086931233981798]
	TIME [epoch: 8.26 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037595087957176254		[learning rate: 0.0018252]
	Learning Rate: 0.00182522
	LOSS [training: 0.0037595087957176254 | validation: 0.007313343546503931]
	TIME [epoch: 8.25 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003670987942845152		[learning rate: 0.0018157]
	Learning Rate: 0.00181573
	LOSS [training: 0.003670987942845152 | validation: 0.0037385313584370724]
	TIME [epoch: 8.25 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004256434094536017		[learning rate: 0.0018063]
	Learning Rate: 0.00180627
	LOSS [training: 0.004256434094536017 | validation: 0.00444364235361179]
	TIME [epoch: 8.29 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037036733097005814		[learning rate: 0.0017968]
	Learning Rate: 0.00179683
	LOSS [training: 0.0037036733097005814 | validation: 0.004586450333686305]
	TIME [epoch: 8.26 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002892834992088611		[learning rate: 0.0017874]
	Learning Rate: 0.00178741
	LOSS [training: 0.002892834992088611 | validation: 0.003972844619815629]
	TIME [epoch: 8.26 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036799303569020956		[learning rate: 0.001778]
	Learning Rate: 0.00177801
	LOSS [training: 0.0036799303569020956 | validation: 0.009889926148848259]
	TIME [epoch: 8.25 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004599200756417289		[learning rate: 0.0017686]
	Learning Rate: 0.00176864
	LOSS [training: 0.004599200756417289 | validation: 0.0039295874525892855]
	TIME [epoch: 8.25 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002962688018583845		[learning rate: 0.0017593]
	Learning Rate: 0.00175929
	LOSS [training: 0.002962688018583845 | validation: 0.004460236668736636]
	TIME [epoch: 8.26 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003921767266082475		[learning rate: 0.00175]
	Learning Rate: 0.00174996
	LOSS [training: 0.003921767266082475 | validation: 0.004197958136678185]
	TIME [epoch: 8.3 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003321535448897392		[learning rate: 0.0017407]
	Learning Rate: 0.00174065
	LOSS [training: 0.003321535448897392 | validation: 0.005365365375561933]
	TIME [epoch: 8.25 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004836382312390049		[learning rate: 0.0017314]
	Learning Rate: 0.00173137
	LOSS [training: 0.004836382312390049 | validation: 0.004095846137358977]
	TIME [epoch: 8.26 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032833469047374338		[learning rate: 0.0017221]
	Learning Rate: 0.00172211
	LOSS [training: 0.0032833469047374338 | validation: 0.005022658353850759]
	TIME [epoch: 8.24 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030459155862875877		[learning rate: 0.0017129]
	Learning Rate: 0.00171287
	LOSS [training: 0.0030459155862875877 | validation: 0.004903654444731596]
	TIME [epoch: 8.26 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004460881258059317		[learning rate: 0.0017037]
	Learning Rate: 0.00170365
	LOSS [training: 0.004460881258059317 | validation: 0.0038017315714321655]
	TIME [epoch: 8.29 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031760255398428396		[learning rate: 0.0016945]
	Learning Rate: 0.00169446
	LOSS [training: 0.0031760255398428396 | validation: 0.0037331282071995284]
	TIME [epoch: 8.27 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004397950855379644		[learning rate: 0.0016853]
	Learning Rate: 0.00168529
	LOSS [training: 0.004397950855379644 | validation: 0.003991381707760009]
	TIME [epoch: 8.25 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035080833511102754		[learning rate: 0.0016761]
	Learning Rate: 0.00167614
	LOSS [training: 0.0035080833511102754 | validation: 0.005144785840797482]
	TIME [epoch: 8.26 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003244720758358329		[learning rate: 0.001667]
	Learning Rate: 0.00166702
	LOSS [training: 0.003244720758358329 | validation: 0.003721378134463561]
	TIME [epoch: 8.25 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003505522119568807		[learning rate: 0.0016579]
	Learning Rate: 0.00165792
	LOSS [training: 0.003505522119568807 | validation: 0.010410844665549174]
	TIME [epoch: 8.25 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004273102960530252		[learning rate: 0.0016488]
	Learning Rate: 0.00164884
	LOSS [training: 0.004273102960530252 | validation: 0.004129106160292065]
	TIME [epoch: 8.29 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003283480385130753		[learning rate: 0.0016398]
	Learning Rate: 0.00163978
	LOSS [training: 0.003283480385130753 | validation: 0.004341574485839929]
	TIME [epoch: 8.25 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004635846438631657		[learning rate: 0.0016307]
	Learning Rate: 0.00163075
	LOSS [training: 0.004635846438631657 | validation: 0.004312623825235467]
	TIME [epoch: 8.27 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034037259507575753		[learning rate: 0.0016217]
	Learning Rate: 0.00162174
	LOSS [training: 0.0034037259507575753 | validation: 0.0034885895475355155]
	TIME [epoch: 8.28 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0044733535502890455		[learning rate: 0.0016128]
	Learning Rate: 0.00161275
	LOSS [training: 0.0044733535502890455 | validation: 0.004069148279136292]
	TIME [epoch: 8.27 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003516356579644523		[learning rate: 0.0016038]
	Learning Rate: 0.00160379
	LOSS [training: 0.003516356579644523 | validation: 0.004392935204807368]
	TIME [epoch: 8.31 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028444478780153713		[learning rate: 0.0015948]
	Learning Rate: 0.00159484
	LOSS [training: 0.0028444478780153713 | validation: 0.003822008852745757]
	TIME [epoch: 8.28 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003045366057245446		[learning rate: 0.0015859]
	Learning Rate: 0.00158593
	LOSS [training: 0.003045366057245446 | validation: 0.004965512426656223]
	TIME [epoch: 8.27 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036093989162141998		[learning rate: 0.001577]
	Learning Rate: 0.00157703
	LOSS [training: 0.0036093989162141998 | validation: 0.004067777715062805]
	TIME [epoch: 8.27 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003933209818306588		[learning rate: 0.0015682]
	Learning Rate: 0.00156816
	LOSS [training: 0.003933209818306588 | validation: 0.006032020079434992]
	TIME [epoch: 8.27 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034560128289349737		[learning rate: 0.0015593]
	Learning Rate: 0.00155931
	LOSS [training: 0.0034560128289349737 | validation: 0.0035427983649805998]
	TIME [epoch: 8.27 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034358394493464125		[learning rate: 0.0015505]
	Learning Rate: 0.00155048
	LOSS [training: 0.0034358394493464125 | validation: 0.0034756292859459493]
	TIME [epoch: 8.32 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031484669773346116		[learning rate: 0.0015417]
	Learning Rate: 0.00154168
	LOSS [training: 0.0031484669773346116 | validation: 0.005237094622184779]
	TIME [epoch: 8.27 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004127279857885327		[learning rate: 0.0015329]
	Learning Rate: 0.0015329
	LOSS [training: 0.004127279857885327 | validation: 0.003482627567032507]
	TIME [epoch: 8.27 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030459179987909197		[learning rate: 0.0015241]
	Learning Rate: 0.00152414
	LOSS [training: 0.0030459179987909197 | validation: 0.004222267844142182]
	TIME [epoch: 8.26 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032084489293323928		[learning rate: 0.0015154]
	Learning Rate: 0.00151541
	LOSS [training: 0.0032084489293323928 | validation: 0.0043120420616384785]
	TIME [epoch: 8.28 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003953367908632242		[learning rate: 0.0015067]
	Learning Rate: 0.0015067
	LOSS [training: 0.003953367908632242 | validation: 0.005624233530145409]
	TIME [epoch: 8.3 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033825607067049387		[learning rate: 0.001498]
	Learning Rate: 0.00149801
	LOSS [training: 0.0033825607067049387 | validation: 0.00446544317667208]
	TIME [epoch: 8.32 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00436608763717883		[learning rate: 0.0014893]
	Learning Rate: 0.00148934
	LOSS [training: 0.00436608763717883 | validation: 0.010201356469489687]
	TIME [epoch: 8.27 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003086455347848383		[learning rate: 0.0014807]
	Learning Rate: 0.0014807
	LOSS [training: 0.003086455347848383 | validation: 0.003609412664930142]
	TIME [epoch: 8.27 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003121778905831872		[learning rate: 0.0014721]
	Learning Rate: 0.00147209
	LOSS [training: 0.003121778905831872 | validation: 0.004088646659484651]
	TIME [epoch: 8.27 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031198879920885957		[learning rate: 0.0014635]
	Learning Rate: 0.00146349
	LOSS [training: 0.0031198879920885957 | validation: 0.003795505563435073]
	TIME [epoch: 8.29 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003920353689667879		[learning rate: 0.0014549]
	Learning Rate: 0.00145492
	LOSS [training: 0.003920353689667879 | validation: 0.003258370648498304]
	TIME [epoch: 8.32 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003108132505143027		[learning rate: 0.0014464]
	Learning Rate: 0.00144637
	LOSS [training: 0.003108132505143027 | validation: 0.004289869157708118]
	TIME [epoch: 8.28 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034165783253175923		[learning rate: 0.0014378]
	Learning Rate: 0.00143785
	LOSS [training: 0.0034165783253175923 | validation: 0.0033432785316743125]
	TIME [epoch: 8.27 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030113891113820413		[learning rate: 0.0014293]
	Learning Rate: 0.00142935
	LOSS [training: 0.0030113891113820413 | validation: 0.005266309620557837]
	TIME [epoch: 8.27 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003355820832451158		[learning rate: 0.0014209]
	Learning Rate: 0.00142087
	LOSS [training: 0.003355820832451158 | validation: 0.004269120892061822]
	TIME [epoch: 8.27 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032157391563185436		[learning rate: 0.0014124]
	Learning Rate: 0.00141242
	LOSS [training: 0.0032157391563185436 | validation: 0.003165406458593793]
	TIME [epoch: 8.29 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002566835144920653		[learning rate: 0.001404]
	Learning Rate: 0.00140399
	LOSS [training: 0.002566835144920653 | validation: 0.0038471280024714657]
	TIME [epoch: 8.3 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003267027200885766		[learning rate: 0.0013956]
	Learning Rate: 0.00139558
	LOSS [training: 0.003267027200885766 | validation: 0.004068706850795037]
	TIME [epoch: 8.27 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004245160928676159		[learning rate: 0.0013872]
	Learning Rate: 0.0013872
	LOSS [training: 0.004245160928676159 | validation: 0.003590091948339424]
	TIME [epoch: 8.27 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030901315494181666		[learning rate: 0.0013788]
	Learning Rate: 0.00137884
	LOSS [training: 0.0030901315494181666 | validation: 0.004441922515560485]
	TIME [epoch: 8.27 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004261050899244189		[learning rate: 0.0013705]
	Learning Rate: 0.0013705
	LOSS [training: 0.004261050899244189 | validation: 0.0031716515721976453]
	TIME [epoch: 8.27 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029162366500660106		[learning rate: 0.0013622]
	Learning Rate: 0.00136219
	LOSS [training: 0.0029162366500660106 | validation: 0.0034280786055404964]
	TIME [epoch: 8.31 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029615919846548433		[learning rate: 0.0013539]
	Learning Rate: 0.0013539
	LOSS [training: 0.0029615919846548433 | validation: 0.0032227854512300426]
	TIME [epoch: 8.28 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003586109477280712		[learning rate: 0.0013456]
	Learning Rate: 0.00134564
	LOSS [training: 0.003586109477280712 | validation: 0.008690899877373679]
	TIME [epoch: 8.27 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003614356238682937		[learning rate: 0.0013374]
	Learning Rate: 0.00133739
	LOSS [training: 0.003614356238682937 | validation: 0.0031964100090753275]
	TIME [epoch: 8.27 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002620919351743368		[learning rate: 0.0013292]
	Learning Rate: 0.00132918
	LOSS [training: 0.002620919351743368 | validation: 0.003897930399673017]
	TIME [epoch: 8.27 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037918901145969613		[learning rate: 0.001321]
	Learning Rate: 0.00132098
	LOSS [training: 0.0037918901145969613 | validation: 0.003737202570566124]
	TIME [epoch: 8.26 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030324810557938293		[learning rate: 0.0013128]
	Learning Rate: 0.00131281
	LOSS [training: 0.0030324810557938293 | validation: 0.0034770922056494725]
	TIME [epoch: 8.32 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002596917610343557		[learning rate: 0.0013047]
	Learning Rate: 0.00130466
	LOSS [training: 0.002596917610343557 | validation: 0.003597031526045163]
	TIME [epoch: 8.27 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033321742615203655		[learning rate: 0.0012965]
	Learning Rate: 0.00129654
	LOSS [training: 0.0033321742615203655 | validation: 0.0033442554974921954]
	TIME [epoch: 8.27 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027461221813636343		[learning rate: 0.0012884]
	Learning Rate: 0.00128844
	LOSS [training: 0.0027461221813636343 | validation: 0.0041033905843029725]
	TIME [epoch: 8.27 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033680370061400493		[learning rate: 0.0012804]
	Learning Rate: 0.00128037
	LOSS [training: 0.0033680370061400493 | validation: 0.0038802109665739574]
	TIME [epoch: 8.29 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029819704892714246		[learning rate: 0.0012723]
	Learning Rate: 0.00127232
	LOSS [training: 0.0029819704892714246 | validation: 0.005091057019971556]
	TIME [epoch: 8.3 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026538488147174197		[learning rate: 0.0012643]
	Learning Rate: 0.00126429
	LOSS [training: 0.0026538488147174197 | validation: 0.0033298534918378194]
	TIME [epoch: 8.29 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003362998638372647		[learning rate: 0.0012563]
	Learning Rate: 0.00125629
	LOSS [training: 0.003362998638372647 | validation: 0.0038038415075024785]
	TIME [epoch: 8.28 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029928706530013252		[learning rate: 0.0012483]
	Learning Rate: 0.00124831
	LOSS [training: 0.0029928706530013252 | validation: 0.005498102326513205]
	TIME [epoch: 8.27 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037640812890249007		[learning rate: 0.0012404]
	Learning Rate: 0.00124035
	LOSS [training: 0.0037640812890249007 | validation: 0.004927532828719713]
	TIME [epoch: 8.27 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030949523408462867		[learning rate: 0.0012324]
	Learning Rate: 0.00123242
	LOSS [training: 0.0030949523408462867 | validation: 0.003659238501983764]
	TIME [epoch: 8.28 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002642107810401621		[learning rate: 0.0012245]
	Learning Rate: 0.00122451
	LOSS [training: 0.002642107810401621 | validation: 0.005130284522234909]
	TIME [epoch: 8.32 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035201619554449033		[learning rate: 0.0012166]
	Learning Rate: 0.00121663
	LOSS [training: 0.0035201619554449033 | validation: 0.003633297058890857]
	TIME [epoch: 8.27 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028747590055209172		[learning rate: 0.0012088]
	Learning Rate: 0.00120877
	LOSS [training: 0.0028747590055209172 | validation: 0.002986975054748336]
	TIME [epoch: 8.28 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027128435318352065		[learning rate: 0.0012009]
	Learning Rate: 0.00120093
	LOSS [training: 0.0027128435318352065 | validation: 0.00375244039160448]
	TIME [epoch: 8.27 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004026604515933701		[learning rate: 0.0011931]
	Learning Rate: 0.00119312
	LOSS [training: 0.004026604515933701 | validation: 0.003965382882582202]
	TIME [epoch: 8.27 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028088855773656394		[learning rate: 0.0011853]
	Learning Rate: 0.00118533
	LOSS [training: 0.0028088855773656394 | validation: 0.003730539280040787]
	TIME [epoch: 8.31 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025448971679093687		[learning rate: 0.0011776]
	Learning Rate: 0.00117757
	LOSS [training: 0.0025448971679093687 | validation: 0.0039039922088536768]
	TIME [epoch: 8.29 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023708660774370265		[learning rate: 0.0011698]
	Learning Rate: 0.00116983
	LOSS [training: 0.0023708660774370265 | validation: 0.0030624198649325434]
	TIME [epoch: 8.27 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002708850680489318		[learning rate: 0.0011621]
	Learning Rate: 0.00116211
	LOSS [training: 0.002708850680489318 | validation: 0.0037222146880012837]
	TIME [epoch: 8.27 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031815799625638163		[learning rate: 0.0011544]
	Learning Rate: 0.00115442
	LOSS [training: 0.0031815799625638163 | validation: 0.003908100198040439]
	TIME [epoch: 8.27 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003693241037120849		[learning rate: 0.0011468]
	Learning Rate: 0.00114676
	LOSS [training: 0.003693241037120849 | validation: 0.0031694160658518166]
	TIME [epoch: 8.27 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004062812834778884		[learning rate: 0.0011391]
	Learning Rate: 0.00113911
	LOSS [training: 0.004062812834778884 | validation: 0.0056768416356249105]
	TIME [epoch: 8.32 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027749912588453662		[learning rate: 0.0011315]
	Learning Rate: 0.0011315
	LOSS [training: 0.0027749912588453662 | validation: 0.0036122295202626917]
	TIME [epoch: 8.27 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002606012318646433		[learning rate: 0.0011239]
	Learning Rate: 0.0011239
	LOSS [training: 0.002606012318646433 | validation: 0.0037834668909763336]
	TIME [epoch: 8.27 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023870401658544734		[learning rate: 0.0011163]
	Learning Rate: 0.00111633
	LOSS [training: 0.0023870401658544734 | validation: 0.0031618351863500213]
	TIME [epoch: 8.28 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002474700204959902		[learning rate: 0.0011088]
	Learning Rate: 0.00110879
	LOSS [training: 0.002474700204959902 | validation: 0.0069927012365116215]
	TIME [epoch: 8.27 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003150325650375672		[learning rate: 0.0011013]
	Learning Rate: 0.00110127
	LOSS [training: 0.003150325650375672 | validation: 0.0034146003605007086]
	TIME [epoch: 8.3 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004510008415576563		[learning rate: 0.0010938]
	Learning Rate: 0.00109377
	LOSS [training: 0.004510008415576563 | validation: 0.00499465933202862]
	TIME [epoch: 8.3 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030287109465803336		[learning rate: 0.0010863]
	Learning Rate: 0.0010863
	LOSS [training: 0.0030287109465803336 | validation: 0.003298269695606181]
	TIME [epoch: 8.27 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027725985908916145		[learning rate: 0.0010788]
	Learning Rate: 0.00107885
	LOSS [training: 0.0027725985908916145 | validation: 0.0031069027172602385]
	TIME [epoch: 8.27 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024080131392125365		[learning rate: 0.0010714]
	Learning Rate: 0.00107143
	LOSS [training: 0.0024080131392125365 | validation: 0.0037733544656302267]
	TIME [epoch: 8.28 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002699056371844814		[learning rate: 0.001064]
	Learning Rate: 0.00106403
	LOSS [training: 0.002699056371844814 | validation: 0.004121912527624879]
	TIME [epoch: 8.27 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028936489039795153		[learning rate: 0.0010567]
	Learning Rate: 0.00105665
	LOSS [training: 0.0028936489039795153 | validation: 0.003780205143819809]
	TIME [epoch: 8.32 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028284473793929086		[learning rate: 0.0010493]
	Learning Rate: 0.0010493
	LOSS [training: 0.0028284473793929086 | validation: 0.00549032450448624]
	TIME [epoch: 8.27 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002716576561731795		[learning rate: 0.001042]
	Learning Rate: 0.00104198
	LOSS [training: 0.002716576561731795 | validation: 0.003083278354534781]
	TIME [epoch: 8.27 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027014856200988967		[learning rate: 0.0010347]
	Learning Rate: 0.00103467
	LOSS [training: 0.0027014856200988967 | validation: 0.003920940145410877]
	TIME [epoch: 8.27 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002990149879402398		[learning rate: 0.0010274]
	Learning Rate: 0.0010274
	LOSS [training: 0.002990149879402398 | validation: 0.004106597474190132]
	TIME [epoch: 8.27 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024949191018869637		[learning rate: 0.0010201]
	Learning Rate: 0.00102015
	LOSS [training: 0.0024949191018869637 | validation: 0.003055616242469199]
	TIME [epoch: 8.28 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026379296038264895		[learning rate: 0.0010129]
	Learning Rate: 0.00101292
	LOSS [training: 0.0026379296038264895 | validation: 0.0036187897570844653]
	TIME [epoch: 8.3 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033582747393608448		[learning rate: 0.0010057]
	Learning Rate: 0.00100571
	LOSS [training: 0.0033582747393608448 | validation: 0.0035408285489436798]
	TIME [epoch: 8.27 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002894639244146366		[learning rate: 0.00099854]
	Learning Rate: 0.000998536
	LOSS [training: 0.002894639244146366 | validation: 0.004438680662812274]
	TIME [epoch: 8.27 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002881069768674845		[learning rate: 0.00099138]
	Learning Rate: 0.000991382
	LOSS [training: 0.002881069768674845 | validation: 0.007165082280135876]
	TIME [epoch: 8.27 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026706310352945075		[learning rate: 0.00098425]
	Learning Rate: 0.000984253
	LOSS [training: 0.0026706310352945075 | validation: 0.0036902674845822065]
	TIME [epoch: 8.27 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002582016794861639		[learning rate: 0.00097715]
	Learning Rate: 0.000977149
	LOSS [training: 0.002582016794861639 | validation: 0.0026788318370049523]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_1682.pth
	Model improved!!!
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030272997183728844		[learning rate: 0.00097007]
	Learning Rate: 0.000970069
	LOSS [training: 0.0030272997183728844 | validation: 0.0033447390038801013]
	TIME [epoch: 8.28 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025402251710245063		[learning rate: 0.00096301]
	Learning Rate: 0.000963014
	LOSS [training: 0.0025402251710245063 | validation: 0.004136142163313205]
	TIME [epoch: 8.28 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024757503596022296		[learning rate: 0.00095598]
	Learning Rate: 0.000955983
	LOSS [training: 0.0024757503596022296 | validation: 0.003897130804120212]
	TIME [epoch: 8.26 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002598262670571225		[learning rate: 0.00094898]
	Learning Rate: 0.000948977
	LOSS [training: 0.002598262670571225 | validation: 0.0033783314236454512]
	TIME [epoch: 8.26 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007168188686592072		[learning rate: 0.000942]
	Learning Rate: 0.000941996
	LOSS [training: 0.007168188686592072 | validation: 0.01075098070718786]
	TIME [epoch: 8.28 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004016592137121702		[learning rate: 0.00093504]
	Learning Rate: 0.00093504
	LOSS [training: 0.004016592137121702 | validation: 0.00409871496514452]
	TIME [epoch: 8.3 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003911521744439086		[learning rate: 0.00092811]
	Learning Rate: 0.000928109
	LOSS [training: 0.003911521744439086 | validation: 0.006993566853036904]
	TIME [epoch: 8.26 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004196494510302124		[learning rate: 0.0009212]
	Learning Rate: 0.000921202
	LOSS [training: 0.004196494510302124 | validation: 0.003924942539330529]
	TIME [epoch: 8.27 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002752850434279607		[learning rate: 0.00091432]
	Learning Rate: 0.000914321
	LOSS [training: 0.002752850434279607 | validation: 0.003535049206308118]
	TIME [epoch: 8.26 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027610236714080342		[learning rate: 0.00090746]
	Learning Rate: 0.000907464
	LOSS [training: 0.0027610236714080342 | validation: 0.0034102640555548607]
	TIME [epoch: 8.27 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002414596190771632		[learning rate: 0.00090063]
	Learning Rate: 0.000900632
	LOSS [training: 0.002414596190771632 | validation: 0.0044755277989292006]
	TIME [epoch: 8.3 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023762389861644436		[learning rate: 0.00089382]
	Learning Rate: 0.000893825
	LOSS [training: 0.0023762389861644436 | validation: 0.004015339091898659]
	TIME [epoch: 8.28 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002227927960796529		[learning rate: 0.00088704]
	Learning Rate: 0.000887043
	LOSS [training: 0.002227927960796529 | validation: 0.004409434209010853]
	TIME [epoch: 8.26 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002585882031326631		[learning rate: 0.00088029]
	Learning Rate: 0.000880285
	LOSS [training: 0.002585882031326631 | validation: 0.0033032679255902923]
	TIME [epoch: 8.26 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002522029242140819		[learning rate: 0.00087355]
	Learning Rate: 0.000873553
	LOSS [training: 0.002522029242140819 | validation: 0.0036814102457308267]
	TIME [epoch: 8.26 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028228975919102556		[learning rate: 0.00086685]
	Learning Rate: 0.000866846
	LOSS [training: 0.0028228975919102556 | validation: 0.0035309514918897174]
	TIME [epoch: 8.27 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002613532564339918		[learning rate: 0.00086016]
	Learning Rate: 0.000860163
	LOSS [training: 0.002613532564339918 | validation: 0.0045312942746093925]
	TIME [epoch: 8.3 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024615412805948818		[learning rate: 0.00085351]
	Learning Rate: 0.000853506
	LOSS [training: 0.0024615412805948818 | validation: 0.003004234704304701]
	TIME [epoch: 8.27 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022525587012739968		[learning rate: 0.00084687]
	Learning Rate: 0.000846874
	LOSS [training: 0.0022525587012739968 | validation: 0.0031637485981267817]
	TIME [epoch: 8.26 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028036965719318327		[learning rate: 0.00084027]
	Learning Rate: 0.000840266
	LOSS [training: 0.0028036965719318327 | validation: 0.0026713262306615315]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_1702.pth
	Model improved!!!
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025078195044022995		[learning rate: 0.00083368]
	Learning Rate: 0.000833684
	LOSS [training: 0.0025078195044022995 | validation: 0.004115894965498708]
	TIME [epoch: 8.26 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026290862873977984		[learning rate: 0.00082713]
	Learning Rate: 0.000827127
	LOSS [training: 0.0026290862873977984 | validation: 0.003226672211189623]
	TIME [epoch: 8.3 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026539813827050184		[learning rate: 0.00082059]
	Learning Rate: 0.000820595
	LOSS [training: 0.0026539813827050184 | validation: 0.004667935932136037]
	TIME [epoch: 8.27 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002566714070100183		[learning rate: 0.00081409]
	Learning Rate: 0.000814088
	LOSS [training: 0.002566714070100183 | validation: 0.003111862628671181]
	TIME [epoch: 8.26 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023752208603393006		[learning rate: 0.00080761]
	Learning Rate: 0.000807606
	LOSS [training: 0.0023752208603393006 | validation: 0.0030995945770139937]
	TIME [epoch: 8.26 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023710829976767143		[learning rate: 0.00080115]
	Learning Rate: 0.000801149
	LOSS [training: 0.0023710829976767143 | validation: 0.0038522821190356705]
	TIME [epoch: 8.25 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023490450354633086		[learning rate: 0.00079472]
	Learning Rate: 0.000794718
	LOSS [training: 0.0023490450354633086 | validation: 0.005605326413864424]
	TIME [epoch: 8.26 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003291419990892594		[learning rate: 0.00078831]
	Learning Rate: 0.000788312
	LOSS [training: 0.003291419990892594 | validation: 0.003292130936841752]
	TIME [epoch: 8.3 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025685627860552976		[learning rate: 0.00078193]
	Learning Rate: 0.00078193
	LOSS [training: 0.0025685627860552976 | validation: 0.0035636012458855034]
	TIME [epoch: 8.26 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002674360107533356		[learning rate: 0.00077557]
	Learning Rate: 0.000775574
	LOSS [training: 0.002674360107533356 | validation: 0.0032446237630552027]
	TIME [epoch: 8.25 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024869683923497165		[learning rate: 0.00076924]
	Learning Rate: 0.000769244
	LOSS [training: 0.0024869683923497165 | validation: 0.002590276282440536]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_1713.pth
	Model improved!!!
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002573429495057884		[learning rate: 0.00076294]
	Learning Rate: 0.000762938
	LOSS [training: 0.002573429495057884 | validation: 0.003392023516352936]
	TIME [epoch: 8.26 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002537303281633081		[learning rate: 0.00075666]
	Learning Rate: 0.000756658
	LOSS [training: 0.002537303281633081 | validation: 0.00400340242888707]
	TIME [epoch: 8.3 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002516114979018806		[learning rate: 0.0007504]
	Learning Rate: 0.000750403
	LOSS [training: 0.002516114979018806 | validation: 0.0026425361443398287]
	TIME [epoch: 8.27 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025619760899660165		[learning rate: 0.00074417]
	Learning Rate: 0.000744174
	LOSS [training: 0.0025619760899660165 | validation: 0.003948581295881143]
	TIME [epoch: 8.26 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002291120868164365		[learning rate: 0.00073797]
	Learning Rate: 0.000737969
	LOSS [training: 0.002291120868164365 | validation: 0.002928496329165766]
	TIME [epoch: 8.26 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029032052162634835		[learning rate: 0.00073179]
	Learning Rate: 0.00073179
	LOSS [training: 0.0029032052162634835 | validation: 0.004319028172135977]
	TIME [epoch: 8.26 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027596815019317483		[learning rate: 0.00072564]
	Learning Rate: 0.000725637
	LOSS [training: 0.0027596815019317483 | validation: 0.0035480123147037467]
	TIME [epoch: 8.26 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021788896931126942		[learning rate: 0.00071951]
	Learning Rate: 0.000719509
	LOSS [training: 0.0021788896931126942 | validation: 0.0033903672517452427]
	TIME [epoch: 8.31 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024745828025453448		[learning rate: 0.00071341]
	Learning Rate: 0.000713406
	LOSS [training: 0.0024745828025453448 | validation: 0.0034601780559125935]
	TIME [epoch: 8.27 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021661319706818994		[learning rate: 0.00070733]
	Learning Rate: 0.000707328
	LOSS [training: 0.0021661319706818994 | validation: 0.003052868952579666]
	TIME [epoch: 8.26 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002504341420887841		[learning rate: 0.00070128]
	Learning Rate: 0.000701276
	LOSS [training: 0.002504341420887841 | validation: 0.003752433841108547]
	TIME [epoch: 8.26 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002521833701697369		[learning rate: 0.00069525]
	Learning Rate: 0.00069525
	LOSS [training: 0.002521833701697369 | validation: 0.002568606183584393]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_1725.pth
	Model improved!!!
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002632136575065313		[learning rate: 0.00068925]
	Learning Rate: 0.000689249
	LOSS [training: 0.002632136575065313 | validation: 0.002842119751783036]
	TIME [epoch: 8.3 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002474559663877742		[learning rate: 0.00068327]
	Learning Rate: 0.000683273
	LOSS [training: 0.002474559663877742 | validation: 0.005516454713873295]
	TIME [epoch: 8.27 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032374160440120808		[learning rate: 0.00067732]
	Learning Rate: 0.000677323
	LOSS [training: 0.0032374160440120808 | validation: 0.003153395099999002]
	TIME [epoch: 8.26 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002532065609051568		[learning rate: 0.0006714]
	Learning Rate: 0.000671398
	LOSS [training: 0.002532065609051568 | validation: 0.003330018364443422]
	TIME [epoch: 8.26 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002222296566052514		[learning rate: 0.0006655]
	Learning Rate: 0.000665499
	LOSS [training: 0.002222296566052514 | validation: 0.0028013901369711037]
	TIME [epoch: 8.26 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025105973095345168		[learning rate: 0.00065963]
	Learning Rate: 0.000659625
	LOSS [training: 0.0025105973095345168 | validation: 0.004004020923609271]
	TIME [epoch: 8.27 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002666450791619912		[learning rate: 0.00065378]
	Learning Rate: 0.000653777
	LOSS [training: 0.002666450791619912 | validation: 0.0027366375408422795]
	TIME [epoch: 8.29 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023981714848266703		[learning rate: 0.00064795]
	Learning Rate: 0.000647955
	LOSS [training: 0.0023981714848266703 | validation: 0.00411627891305907]
	TIME [epoch: 8.25 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020188848584825505		[learning rate: 0.00064216]
	Learning Rate: 0.000642158
	LOSS [training: 0.0020188848584825505 | validation: 0.003307154301648692]
	TIME [epoch: 8.26 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025866388430083632		[learning rate: 0.00063639]
	Learning Rate: 0.000636387
	LOSS [training: 0.0025866388430083632 | validation: 0.0035935062769683725]
	TIME [epoch: 8.25 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023925552466314503		[learning rate: 0.00063064]
	Learning Rate: 0.000630641
	LOSS [training: 0.0023925552466314503 | validation: 0.0034532643234435573]
	TIME [epoch: 8.26 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023243411472739966		[learning rate: 0.00062492]
	Learning Rate: 0.000624921
	LOSS [training: 0.0023243411472739966 | validation: 0.0026138540018503893]
	TIME [epoch: 8.3 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024882955906775604		[learning rate: 0.00061923]
	Learning Rate: 0.000619226
	LOSS [training: 0.0024882955906775604 | validation: 0.0036611232450306144]
	TIME [epoch: 8.27 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002399458070163664		[learning rate: 0.00061356]
	Learning Rate: 0.000613558
	LOSS [training: 0.002399458070163664 | validation: 0.0033849091022411545]
	TIME [epoch: 8.25 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023862115411622995		[learning rate: 0.00060791]
	Learning Rate: 0.000607914
	LOSS [training: 0.0023862115411622995 | validation: 0.004182375330828635]
	TIME [epoch: 8.25 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021911010298843237		[learning rate: 0.0006023]
	Learning Rate: 0.000602297
	LOSS [training: 0.0021911010298843237 | validation: 0.002955785810241138]
	TIME [epoch: 8.25 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031354078664533143		[learning rate: 0.00059671]
	Learning Rate: 0.000596705
	LOSS [training: 0.0031354078664533143 | validation: 0.003985619276063041]
	TIME [epoch: 8.25 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00261431803257857		[learning rate: 0.00059114]
	Learning Rate: 0.000591139
	LOSS [training: 0.00261431803257857 | validation: 0.0032385992480700827]
	TIME [epoch: 8.3 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023321564253472784		[learning rate: 0.0005856]
	Learning Rate: 0.000585599
	LOSS [training: 0.0023321564253472784 | validation: 0.0034210736496953667]
	TIME [epoch: 8.26 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021843505880909304		[learning rate: 0.00058008]
	Learning Rate: 0.000580085
	LOSS [training: 0.0021843505880909304 | validation: 0.0031152230248276762]
	TIME [epoch: 8.26 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021336062751837804		[learning rate: 0.0005746]
	Learning Rate: 0.000574596
	LOSS [training: 0.0021336062751837804 | validation: 0.0037671382242509786]
	TIME [epoch: 8.26 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002329527050631745		[learning rate: 0.00056913]
	Learning Rate: 0.000569133
	LOSS [training: 0.002329527050631745 | validation: 0.0036545867976076852]
	TIME [epoch: 8.25 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021758793270584297		[learning rate: 0.0005637]
	Learning Rate: 0.000563696
	LOSS [training: 0.0021758793270584297 | validation: 0.0038549115122903004]
	TIME [epoch: 8.27 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002465586676737195		[learning rate: 0.00055828]
	Learning Rate: 0.000558285
	LOSS [training: 0.002465586676737195 | validation: 0.003264779888620624]
	TIME [epoch: 8.29 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002384824253402716		[learning rate: 0.0005529]
	Learning Rate: 0.000552899
	LOSS [training: 0.002384824253402716 | validation: 0.003129713296663948]
	TIME [epoch: 8.25 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002285328953660559		[learning rate: 0.00054754]
	Learning Rate: 0.000547539
	LOSS [training: 0.002285328953660559 | validation: 0.0030727392555466226]
	TIME [epoch: 8.26 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002289339466079762		[learning rate: 0.00054221]
	Learning Rate: 0.000542206
	LOSS [training: 0.002289339466079762 | validation: 0.0035990772434352316]
	TIME [epoch: 8.26 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002322256813277554		[learning rate: 0.0005369]
	Learning Rate: 0.000536898
	LOSS [training: 0.002322256813277554 | validation: 0.0032067527646907406]
	TIME [epoch: 8.26 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024962837003624024		[learning rate: 0.00053162]
	Learning Rate: 0.000531616
	LOSS [training: 0.0024962837003624024 | validation: 0.003174447880858172]
	TIME [epoch: 8.31 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023336511670353846		[learning rate: 0.00052636]
	Learning Rate: 0.000526359
	LOSS [training: 0.0023336511670353846 | validation: 0.0034355547965079477]
	TIME [epoch: 8.26 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002095078671099408		[learning rate: 0.00052113]
	Learning Rate: 0.000521129
	LOSS [training: 0.002095078671099408 | validation: 0.004001491723612333]
	TIME [epoch: 8.26 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022781288704869567		[learning rate: 0.00051592]
	Learning Rate: 0.000515925
	LOSS [training: 0.0022781288704869567 | validation: 0.004064265703379144]
	TIME [epoch: 8.26 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002549427193674571		[learning rate: 0.00051075]
	Learning Rate: 0.000510746
	LOSS [training: 0.002549427193674571 | validation: 0.004162695341764539]
	TIME [epoch: 8.26 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001946000390510209		[learning rate: 0.00050559]
	Learning Rate: 0.000505594
	LOSS [training: 0.001946000390510209 | validation: 0.0034156926758001126]
	TIME [epoch: 8.28 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021929876638572274		[learning rate: 0.00050047]
	Learning Rate: 0.000500468
	LOSS [training: 0.0021929876638572274 | validation: 0.002749900509523373]
	TIME [epoch: 8.3 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002546437548022758		[learning rate: 0.00049537]
	Learning Rate: 0.000495367
	LOSS [training: 0.002546437548022758 | validation: 0.0024250217866230352]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_1761.pth
	Model improved!!!
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023776897554473367		[learning rate: 0.00049029]
	Learning Rate: 0.000490293
	LOSS [training: 0.0023776897554473367 | validation: 0.004109905183483115]
	TIME [epoch: 8.26 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023448292375370314		[learning rate: 0.00048524]
	Learning Rate: 0.000485244
	LOSS [training: 0.0023448292375370314 | validation: 0.0026895247149675517]
	TIME [epoch: 8.26 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002272158482172287		[learning rate: 0.00048022]
	Learning Rate: 0.000480222
	LOSS [training: 0.002272158482172287 | validation: 0.0033018635852323447]
	TIME [epoch: 8.27 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020927184996822777		[learning rate: 0.00047523]
	Learning Rate: 0.000475226
	LOSS [training: 0.0020927184996822777 | validation: 0.0029073588468807327]
	TIME [epoch: 8.32 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026521593152271468		[learning rate: 0.00047026]
	Learning Rate: 0.000470255
	LOSS [training: 0.0026521593152271468 | validation: 0.002894567564759381]
	TIME [epoch: 8.26 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019926689946819873		[learning rate: 0.00046531]
	Learning Rate: 0.000465311
	LOSS [training: 0.0019926689946819873 | validation: 0.0031292539560716114]
	TIME [epoch: 8.26 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002061164078894492		[learning rate: 0.00046039]
	Learning Rate: 0.000460393
	LOSS [training: 0.002061164078894492 | validation: 0.0032560575875604032]
	TIME [epoch: 8.26 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021176004896465246		[learning rate: 0.0004555]
	Learning Rate: 0.000455501
	LOSS [training: 0.0021176004896465246 | validation: 0.0029788098943075653]
	TIME [epoch: 8.26 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002383266360236357		[learning rate: 0.00045063]
	Learning Rate: 0.000450635
	LOSS [training: 0.002383266360236357 | validation: 0.0029466419864838615]
	TIME [epoch: 8.28 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026079921239637134		[learning rate: 0.00044579]
	Learning Rate: 0.000445795
	LOSS [training: 0.0026079921239637134 | validation: 0.0037183020804713307]
	TIME [epoch: 8.3 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022807065637026535		[learning rate: 0.00044098]
	Learning Rate: 0.000440981
	LOSS [training: 0.0022807065637026535 | validation: 0.0028256243563157383]
	TIME [epoch: 8.26 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002220850385852888		[learning rate: 0.00043619]
	Learning Rate: 0.000436194
	LOSS [training: 0.002220850385852888 | validation: 0.0035947007790124727]
	TIME [epoch: 8.26 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021770314914018843		[learning rate: 0.00043143]
	Learning Rate: 0.000431432
	LOSS [training: 0.0021770314914018843 | validation: 0.0031266940836924668]
	TIME [epoch: 8.26 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002297581394302313		[learning rate: 0.0004267]
	Learning Rate: 0.000426697
	LOSS [training: 0.002297581394302313 | validation: 0.0034935796976468645]
	TIME [epoch: 8.26 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024203756545295176		[learning rate: 0.00042199]
	Learning Rate: 0.000421988
	LOSS [training: 0.0024203756545295176 | validation: 0.0033324814540793956]
	TIME [epoch: 8.3 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00220732714444058		[learning rate: 0.00041731]
	Learning Rate: 0.000417305
	LOSS [training: 0.00220732714444058 | validation: 0.003739866581771808]
	TIME [epoch: 8.26 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002436556596506016		[learning rate: 0.00041265]
	Learning Rate: 0.000412649
	LOSS [training: 0.002436556596506016 | validation: 0.004172735801839237]
	TIME [epoch: 8.27 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002131597624083819		[learning rate: 0.00040802]
	Learning Rate: 0.000408018
	LOSS [training: 0.002131597624083819 | validation: 0.0033065250986478666]
	TIME [epoch: 8.26 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002477631535109171		[learning rate: 0.00040341]
	Learning Rate: 0.000403414
	LOSS [training: 0.002477631535109171 | validation: 0.003076010792635527]
	TIME [epoch: 8.26 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002296956501863573		[learning rate: 0.00039884]
	Learning Rate: 0.000398836
	LOSS [training: 0.002296956501863573 | validation: 0.002836238190080482]
	TIME [epoch: 8.26 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019640021714376938		[learning rate: 0.00039428]
	Learning Rate: 0.000394284
	LOSS [training: 0.0019640021714376938 | validation: 0.002728050821786611]
	TIME [epoch: 8.3 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022204669284651988		[learning rate: 0.00038976]
	Learning Rate: 0.000389759
	LOSS [training: 0.0022204669284651988 | validation: 0.0026683719685598587]
	TIME [epoch: 8.26 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001983522888748652		[learning rate: 0.00038526]
	Learning Rate: 0.00038526
	LOSS [training: 0.001983522888748652 | validation: 0.0028354615182454666]
	TIME [epoch: 8.26 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002372747415895388		[learning rate: 0.00038079]
	Learning Rate: 0.000380787
	LOSS [training: 0.002372747415895388 | validation: 0.003290819878191211]
	TIME [epoch: 8.26 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021564337960792335		[learning rate: 0.00037634]
	Learning Rate: 0.000376341
	LOSS [training: 0.0021564337960792335 | validation: 0.0035647524717056355]
	TIME [epoch: 8.26 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002217061912009209		[learning rate: 0.00037192]
	Learning Rate: 0.00037192
	LOSS [training: 0.002217061912009209 | validation: 0.002866948012501803]
	TIME [epoch: 8.3 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002284002288580778		[learning rate: 0.00036753]
	Learning Rate: 0.000367527
	LOSS [training: 0.002284002288580778 | validation: 0.003608410566042081]
	TIME [epoch: 8.27 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022426727171889283		[learning rate: 0.00036316]
	Learning Rate: 0.000363159
	LOSS [training: 0.0022426727171889283 | validation: 0.003102417794838056]
	TIME [epoch: 8.26 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002387033777755825		[learning rate: 0.00035882]
	Learning Rate: 0.000358818
	LOSS [training: 0.002387033777755825 | validation: 0.0033421359065466272]
	TIME [epoch: 8.26 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002241473258267803		[learning rate: 0.0003545]
	Learning Rate: 0.000354503
	LOSS [training: 0.002241473258267803 | validation: 0.003963960521370667]
	TIME [epoch: 8.26 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002437683691901812		[learning rate: 0.00035022]
	Learning Rate: 0.000350215
	LOSS [training: 0.002437683691901812 | validation: 0.0034607109309889843]
	TIME [epoch: 8.26 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021761787348938337		[learning rate: 0.00034595]
	Learning Rate: 0.000345953
	LOSS [training: 0.0021761787348938337 | validation: 0.0027890482062893182]
	TIME [epoch: 8.31 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002100617711654436		[learning rate: 0.00034172]
	Learning Rate: 0.000341718
	LOSS [training: 0.002100617711654436 | validation: 0.003358033392059862]
	TIME [epoch: 8.26 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021974959523066257		[learning rate: 0.00033751]
	Learning Rate: 0.000337508
	LOSS [training: 0.0021974959523066257 | validation: 0.0032733355720514948]
	TIME [epoch: 8.26 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002283727557753054		[learning rate: 0.00033333]
	Learning Rate: 0.000333326
	LOSS [training: 0.002283727557753054 | validation: 0.003208404978022494]
	TIME [epoch: 8.26 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00230265452529749		[learning rate: 0.00032917]
	Learning Rate: 0.000329169
	LOSS [training: 0.00230265452529749 | validation: 0.003893855954360261]
	TIME [epoch: 8.26 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002130726774048129		[learning rate: 0.00032504]
	Learning Rate: 0.00032504
	LOSS [training: 0.002130726774048129 | validation: 0.0029394060507521376]
	TIME [epoch: 8.28 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021531615243544663		[learning rate: 0.00032094]
	Learning Rate: 0.000320936
	LOSS [training: 0.0021531615243544663 | validation: 0.0036699453553538236]
	TIME [epoch: 8.29 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023106816339353736		[learning rate: 0.00031686]
	Learning Rate: 0.000316859
	LOSS [training: 0.0023106816339353736 | validation: 0.0033721918998582756]
	TIME [epoch: 8.26 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002304586012513564		[learning rate: 0.00031281]
	Learning Rate: 0.000312809
	LOSS [training: 0.002304586012513564 | validation: 0.0025499493510659126]
	TIME [epoch: 8.26 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002166797985830921		[learning rate: 0.00030879]
	Learning Rate: 0.000308785
	LOSS [training: 0.002166797985830921 | validation: 0.0030654110780247955]
	TIME [epoch: 8.27 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00220912106326161		[learning rate: 0.00030479]
	Learning Rate: 0.000304788
	LOSS [training: 0.00220912106326161 | validation: 0.0032266335265547373]
	TIME [epoch: 8.27 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002081777201673801		[learning rate: 0.00030082]
	Learning Rate: 0.000300817
	LOSS [training: 0.002081777201673801 | validation: 0.0035107987066909695]
	TIME [epoch: 8.32 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019281446773300676		[learning rate: 0.00029687]
	Learning Rate: 0.000296873
	LOSS [training: 0.0019281446773300676 | validation: 0.0032662933956257908]
	TIME [epoch: 8.27 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021502546972246668		[learning rate: 0.00029295]
	Learning Rate: 0.000292955
	LOSS [training: 0.0021502546972246668 | validation: 0.002833322716814501]
	TIME [epoch: 8.29 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019279469359058136		[learning rate: 0.00028906]
	Learning Rate: 0.000289064
	LOSS [training: 0.0019279469359058136 | validation: 0.002395867948789558]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_1807.pth
	Model improved!!!
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002141426571970064		[learning rate: 0.0002852]
	Learning Rate: 0.000285199
	LOSS [training: 0.002141426571970064 | validation: 0.0030453719626727617]
	TIME [epoch: 8.26 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022971030228732727		[learning rate: 0.00028136]
	Learning Rate: 0.000281361
	LOSS [training: 0.0022971030228732727 | validation: 0.0028133235800544797]
	TIME [epoch: 8.3 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022457144431084716		[learning rate: 0.00027755]
	Learning Rate: 0.000277549
	LOSS [training: 0.0022457144431084716 | validation: 0.0027189486042998173]
	TIME [epoch: 8.28 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020687276182276594		[learning rate: 0.00027376]
	Learning Rate: 0.000273764
	LOSS [training: 0.0020687276182276594 | validation: 0.002855233214268779]
	TIME [epoch: 8.26 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019391378175788005		[learning rate: 0.00027001]
	Learning Rate: 0.000270006
	LOSS [training: 0.0019391378175788005 | validation: 0.003172534551483852]
	TIME [epoch: 8.26 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022766469410775234		[learning rate: 0.00026627]
	Learning Rate: 0.000266274
	LOSS [training: 0.0022766469410775234 | validation: 0.003006020298276069]
	TIME [epoch: 8.28 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002184117661034902		[learning rate: 0.00026257]
	Learning Rate: 0.000262569
	LOSS [training: 0.002184117661034902 | validation: 0.0034340991365834385]
	TIME [epoch: 8.26 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019909606007750495		[learning rate: 0.00025889]
	Learning Rate: 0.000258891
	LOSS [training: 0.0019909606007750495 | validation: 0.0031945728153458842]
	TIME [epoch: 8.31 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021557918895178563		[learning rate: 0.00025524]
	Learning Rate: 0.000255239
	LOSS [training: 0.0021557918895178563 | validation: 0.00414034198366668]
	TIME [epoch: 8.26 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020197243677110856		[learning rate: 0.00025161]
	Learning Rate: 0.000251614
	LOSS [training: 0.0020197243677110856 | validation: 0.0030716765277645735]
	TIME [epoch: 8.26 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002185103411035773		[learning rate: 0.00024802]
	Learning Rate: 0.000248016
	LOSS [training: 0.002185103411035773 | validation: 0.0032517173099770053]
	TIME [epoch: 8.26 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001954770108929341		[learning rate: 0.00024444]
	Learning Rate: 0.000244444
	LOSS [training: 0.001954770108929341 | validation: 0.0036558285257050614]
	TIME [epoch: 8.26 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002073853560498297		[learning rate: 0.0002409]
	Learning Rate: 0.000240899
	LOSS [training: 0.002073853560498297 | validation: 0.0031539560943596146]
	TIME [epoch: 8.3 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002069298623870839		[learning rate: 0.00023738]
	Learning Rate: 0.00023738
	LOSS [training: 0.002069298623870839 | validation: 0.00290927060720973]
	TIME [epoch: 8.3 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002009611246556369		[learning rate: 0.00023389]
	Learning Rate: 0.000233889
	LOSS [training: 0.002009611246556369 | validation: 0.00316832374660033]
	TIME [epoch: 8.26 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019910605813219357		[learning rate: 0.00023042]
	Learning Rate: 0.000230424
	LOSS [training: 0.0019910605813219357 | validation: 0.0032953410891167195]
	TIME [epoch: 8.26 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022471423892368564		[learning rate: 0.00022699]
	Learning Rate: 0.000226985
	LOSS [training: 0.0022471423892368564 | validation: 0.0036344151645477407]
	TIME [epoch: 8.26 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002152101794416848		[learning rate: 0.00022357]
	Learning Rate: 0.000223574
	LOSS [training: 0.002152101794416848 | validation: 0.0026282329863021774]
	TIME [epoch: 8.26 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019298695444076237		[learning rate: 0.00022019]
	Learning Rate: 0.000220189
	LOSS [training: 0.0019298695444076237 | validation: 0.002419588279019267]
	TIME [epoch: 8.3 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002187342715671125		[learning rate: 0.00021683]
	Learning Rate: 0.000216831
	LOSS [training: 0.002187342715671125 | validation: 0.0032976170475851516]
	TIME [epoch: 8.26 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00202144978464203		[learning rate: 0.0002135]
	Learning Rate: 0.0002135
	LOSS [training: 0.00202144978464203 | validation: 0.0029161488957312196]
	TIME [epoch: 8.26 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002033676952919093		[learning rate: 0.0002102]
	Learning Rate: 0.000210195
	LOSS [training: 0.002033676952919093 | validation: 0.003581945174214693]
	TIME [epoch: 8.26 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018926850376010868		[learning rate: 0.00020692]
	Learning Rate: 0.000206917
	LOSS [training: 0.0018926850376010868 | validation: 0.0030433473059891403]
	TIME [epoch: 8.26 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023860824200236308		[learning rate: 0.00020367]
	Learning Rate: 0.000203667
	LOSS [training: 0.0023860824200236308 | validation: 0.0032484989156446728]
	TIME [epoch: 8.28 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020501857186070185		[learning rate: 0.00020044]
	Learning Rate: 0.000200442
	LOSS [training: 0.0020501857186070185 | validation: 0.002883574562780606]
	TIME [epoch: 8.29 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020204472367153785		[learning rate: 0.00019725]
	Learning Rate: 0.000197245
	LOSS [training: 0.0020204472367153785 | validation: 0.0027590361830322537]
	TIME [epoch: 8.26 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001933699165329878		[learning rate: 0.00019407]
	Learning Rate: 0.000194075
	LOSS [training: 0.001933699165329878 | validation: 0.002799811136272476]
	TIME [epoch: 8.26 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020406723777358585		[learning rate: 0.00019093]
	Learning Rate: 0.000190931
	LOSS [training: 0.0020406723777358585 | validation: 0.0027280870320787404]
	TIME [epoch: 8.26 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019643934910774457		[learning rate: 0.00018781]
	Learning Rate: 0.000187814
	LOSS [training: 0.0019643934910774457 | validation: 0.002767017477345433]
	TIME [epoch: 8.26 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021712837432073303		[learning rate: 0.00018472]
	Learning Rate: 0.000184724
	LOSS [training: 0.0021712837432073303 | validation: 0.0035078401964913474]
	TIME [epoch: 8.3 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002049525058486793		[learning rate: 0.00018166]
	Learning Rate: 0.000181661
	LOSS [training: 0.002049525058486793 | validation: 0.0028375779235409455]
	TIME [epoch: 8.27 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022128322625719296		[learning rate: 0.00017862]
	Learning Rate: 0.000178624
	LOSS [training: 0.0022128322625719296 | validation: 0.002867395151294357]
	TIME [epoch: 8.26 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019119161368723607		[learning rate: 0.00017561]
	Learning Rate: 0.000175615
	LOSS [training: 0.0019119161368723607 | validation: 0.002970687322588942]
	TIME [epoch: 8.26 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020440277209763788		[learning rate: 0.00017263]
	Learning Rate: 0.000172632
	LOSS [training: 0.0020440277209763788 | validation: 0.0027181741785622525]
	TIME [epoch: 8.26 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019440547998510773		[learning rate: 0.00016968]
	Learning Rate: 0.000169677
	LOSS [training: 0.0019440547998510773 | validation: 0.003422373136455244]
	TIME [epoch: 8.27 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002002362782335871		[learning rate: 0.00016675]
	Learning Rate: 0.000166748
	LOSS [training: 0.002002362782335871 | validation: 0.0025665319300203536]
	TIME [epoch: 8.3 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021966938141229266		[learning rate: 0.00016385]
	Learning Rate: 0.000163846
	LOSS [training: 0.0021966938141229266 | validation: 0.002923677710071893]
	TIME [epoch: 8.27 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002023331165996403		[learning rate: 0.00016097]
	Learning Rate: 0.000160971
	LOSS [training: 0.002023331165996403 | validation: 0.00266200126799143]
	TIME [epoch: 8.27 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019610639880744247		[learning rate: 0.00015812]
	Learning Rate: 0.000158123
	LOSS [training: 0.0019610639880744247 | validation: 0.0032391730132145186]
	TIME [epoch: 8.28 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019871811067401182		[learning rate: 0.0001553]
	Learning Rate: 0.000155302
	LOSS [training: 0.0019871811067401182 | validation: 0.0029490546402476643]
	TIME [epoch: 8.26 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002061057000500929		[learning rate: 0.00015251]
	Learning Rate: 0.000152507
	LOSS [training: 0.002061057000500929 | validation: 0.0031815460810921768]
	TIME [epoch: 8.3 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019664071294329187		[learning rate: 0.00014974]
	Learning Rate: 0.00014974
	LOSS [training: 0.0019664071294329187 | validation: 0.002635437001572317]
	TIME [epoch: 8.27 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021098140437861494		[learning rate: 0.000147]
	Learning Rate: 0.000147
	LOSS [training: 0.0021098140437861494 | validation: 0.003638169719179724]
	TIME [epoch: 8.26 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022501093323257157		[learning rate: 0.00014429]
	Learning Rate: 0.000144286
	LOSS [training: 0.0022501093323257157 | validation: 0.002945717768658964]
	TIME [epoch: 8.26 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020665399953201835		[learning rate: 0.0001416]
	Learning Rate: 0.0001416
	LOSS [training: 0.0020665399953201835 | validation: 0.0033406609733111197]
	TIME [epoch: 8.27 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019078961686281861		[learning rate: 0.00013894]
	Learning Rate: 0.00013894
	LOSS [training: 0.0019078961686281861 | validation: 0.0027581329379045183]
	TIME [epoch: 8.27 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020179391240142098		[learning rate: 0.00013631]
	Learning Rate: 0.000136308
	LOSS [training: 0.0020179391240142098 | validation: 0.0027118778233404858]
	TIME [epoch: 8.3 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002131497375600941		[learning rate: 0.0001337]
	Learning Rate: 0.000133702
	LOSS [training: 0.002131497375600941 | validation: 0.0030844365323642073]
	TIME [epoch: 8.26 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019738317618997253		[learning rate: 0.00013112]
	Learning Rate: 0.000131124
	LOSS [training: 0.0019738317618997253 | validation: 0.0025996034879326732]
	TIME [epoch: 8.26 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018824996183803768		[learning rate: 0.00012857]
	Learning Rate: 0.000128572
	LOSS [training: 0.0018824996183803768 | validation: 0.003128253478229156]
	TIME [epoch: 8.26 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020667157676813566		[learning rate: 0.00012605]
	Learning Rate: 0.000126048
	LOSS [training: 0.0020667157676813566 | validation: 0.0029013322309477283]
	TIME [epoch: 8.26 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002094600943166288		[learning rate: 0.00012355]
	Learning Rate: 0.00012355
	LOSS [training: 0.002094600943166288 | validation: 0.0030564227045443274]
	TIME [epoch: 8.3 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020667890661623433		[learning rate: 0.00012108]
	Learning Rate: 0.000121079
	LOSS [training: 0.0020667890661623433 | validation: 0.0028889347311038434]
	TIME [epoch: 8.28 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019391628326244222		[learning rate: 0.00011864]
	Learning Rate: 0.000118636
	LOSS [training: 0.0019391628326244222 | validation: 0.0030739019349482603]
	TIME [epoch: 8.26 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019224519365527376		[learning rate: 0.00011622]
	Learning Rate: 0.000116219
	LOSS [training: 0.0019224519365527376 | validation: 0.0026744278642894005]
	TIME [epoch: 8.26 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002075149777906275		[learning rate: 0.00011383]
	Learning Rate: 0.00011383
	LOSS [training: 0.002075149777906275 | validation: 0.0028186818186688887]
	TIME [epoch: 8.26 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020362681978994906		[learning rate: 0.00011147]
	Learning Rate: 0.000111468
	LOSS [training: 0.0020362681978994906 | validation: 0.002766167024744975]
	TIME [epoch: 8.26 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002201832486355441		[learning rate: 0.00010913]
	Learning Rate: 0.000109132
	LOSS [training: 0.002201832486355441 | validation: 0.0032178821551936483]
	TIME [epoch: 8.31 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001996161428663111		[learning rate: 0.00010682]
	Learning Rate: 0.000106824
	LOSS [training: 0.001996161428663111 | validation: 0.0025501813921058724]
	TIME [epoch: 8.28 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020625648991075348		[learning rate: 0.00010454]
	Learning Rate: 0.000104543
	LOSS [training: 0.0020625648991075348 | validation: 0.0028754107935543213]
	TIME [epoch: 8.27 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002080092408268889		[learning rate: 0.00010229]
	Learning Rate: 0.000102289
	LOSS [training: 0.002080092408268889 | validation: 0.0029173024916455776]
	TIME [epoch: 8.27 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019444192964982558		[learning rate: 0.00010006]
	Learning Rate: 0.000100061
	LOSS [training: 0.0019444192964982558 | validation: 0.0033307488587474613]
	TIME [epoch: 8.27 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020460748840618265		[learning rate: 9.7861e-05]
	Learning Rate: 9.78614e-05
	LOSS [training: 0.0020460748840618265 | validation: 0.0027906819055881858]
	TIME [epoch: 8.28 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019173097382363916		[learning rate: 9.5688e-05]
	Learning Rate: 9.56885e-05
	LOSS [training: 0.0019173097382363916 | validation: 0.0034853368750693836]
	TIME [epoch: 8.29 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002135491813449337		[learning rate: 9.3543e-05]
	Learning Rate: 9.35426e-05
	LOSS [training: 0.002135491813449337 | validation: 0.003124559037333206]
	TIME [epoch: 8.26 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002114885466292191		[learning rate: 9.1424e-05]
	Learning Rate: 9.14239e-05
	LOSS [training: 0.002114885466292191 | validation: 0.002573448065714165]
	TIME [epoch: 8.26 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019713918255122326		[learning rate: 8.9332e-05]
	Learning Rate: 8.93322e-05
	LOSS [training: 0.0019713918255122326 | validation: 0.003084414989680254]
	TIME [epoch: 8.26 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018384254144116386		[learning rate: 8.7268e-05]
	Learning Rate: 8.72677e-05
	LOSS [training: 0.0018384254144116386 | validation: 0.00386823551518067]
	TIME [epoch: 8.26 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020747262235137533		[learning rate: 8.523e-05]
	Learning Rate: 8.52303e-05
	LOSS [training: 0.0020747262235137533 | validation: 0.0033121513946772893]
	TIME [epoch: 8.31 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018074384400698226		[learning rate: 8.322e-05]
	Learning Rate: 8.322e-05
	LOSS [training: 0.0018074384400698226 | validation: 0.0034259716614619368]
	TIME [epoch: 8.27 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019402545376912676		[learning rate: 8.1237e-05]
	Learning Rate: 8.12368e-05
	LOSS [training: 0.0019402545376912676 | validation: 0.0031282863565048353]
	TIME [epoch: 8.28 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020331126949080015		[learning rate: 7.9281e-05]
	Learning Rate: 7.92808e-05
	LOSS [training: 0.0020331126949080015 | validation: 0.0027898420094114723]
	TIME [epoch: 8.26 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019876361195113853		[learning rate: 7.7352e-05]
	Learning Rate: 7.73519e-05
	LOSS [training: 0.0019876361195113853 | validation: 0.002665417246229504]
	TIME [epoch: 8.26 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021304859700574637		[learning rate: 7.545e-05]
	Learning Rate: 7.54501e-05
	LOSS [training: 0.0021304859700574637 | validation: 0.002657952833175709]
	TIME [epoch: 8.28 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00196975560555607		[learning rate: 7.3575e-05]
	Learning Rate: 7.35755e-05
	LOSS [training: 0.00196975560555607 | validation: 0.0030564456110780958]
	TIME [epoch: 8.3 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019084285094374126		[learning rate: 7.1728e-05]
	Learning Rate: 7.1728e-05
	LOSS [training: 0.0019084285094374126 | validation: 0.0038948152649099527]
	TIME [epoch: 8.26 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018084828833269482		[learning rate: 6.9908e-05]
	Learning Rate: 6.99077e-05
	LOSS [training: 0.0018084828833269482 | validation: 0.0027505065388070214]
	TIME [epoch: 8.26 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018889388597372546		[learning rate: 6.8115e-05]
	Learning Rate: 6.81146e-05
	LOSS [training: 0.0018889388597372546 | validation: 0.003520192774923831]
	TIME [epoch: 8.26 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018513311589536613		[learning rate: 6.6349e-05]
	Learning Rate: 6.63486e-05
	LOSS [training: 0.0018513311589536613 | validation: 0.0035003811566393568]
	TIME [epoch: 8.26 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019300887626210845		[learning rate: 6.461e-05]
	Learning Rate: 6.46098e-05
	LOSS [training: 0.0019300887626210845 | validation: 0.002641556235890714]
	TIME [epoch: 8.32 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019417741976969305		[learning rate: 6.2898e-05]
	Learning Rate: 6.28982e-05
	LOSS [training: 0.0019417741976969305 | validation: 0.003359604983915962]
	TIME [epoch: 8.27 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001918370108160859		[learning rate: 6.1214e-05]
	Learning Rate: 6.12137e-05
	LOSS [training: 0.001918370108160859 | validation: 0.0026294081077978806]
	TIME [epoch: 8.26 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002144564141541987		[learning rate: 5.9556e-05]
	Learning Rate: 5.95565e-05
	LOSS [training: 0.002144564141541987 | validation: 0.003089197790950527]
	TIME [epoch: 8.26 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002054634342938811		[learning rate: 5.7926e-05]
	Learning Rate: 5.79264e-05
	LOSS [training: 0.002054634342938811 | validation: 0.0032963545495769938]
	TIME [epoch: 8.26 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019934919209365996		[learning rate: 5.6324e-05]
	Learning Rate: 5.63235e-05
	LOSS [training: 0.0019934919209365996 | validation: 0.003610922294848158]
	TIME [epoch: 8.27 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017844957706933898		[learning rate: 5.4748e-05]
	Learning Rate: 5.47478e-05
	LOSS [training: 0.0017844957706933898 | validation: 0.0028456522665872078]
	TIME [epoch: 8.3 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021109317541484407		[learning rate: 5.3199e-05]
	Learning Rate: 5.31994e-05
	LOSS [training: 0.0021109317541484407 | validation: 0.0031527874784326635]
	TIME [epoch: 8.26 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019796803400294652		[learning rate: 5.1678e-05]
	Learning Rate: 5.16781e-05
	LOSS [training: 0.0019796803400294652 | validation: 0.0033088351406011496]
	TIME [epoch: 8.26 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002030180220179989		[learning rate: 5.0184e-05]
	Learning Rate: 5.0184e-05
	LOSS [training: 0.002030180220179989 | validation: 0.0028300510345059546]
	TIME [epoch: 8.27 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00198170946043369		[learning rate: 4.8717e-05]
	Learning Rate: 4.87172e-05
	LOSS [training: 0.00198170946043369 | validation: 0.0030705968435393266]
	TIME [epoch: 8.26 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019417862351252427		[learning rate: 4.7278e-05]
	Learning Rate: 4.72776e-05
	LOSS [training: 0.0019417862351252427 | validation: 0.0029901788025134966]
	TIME [epoch: 8.3 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001905206106417559		[learning rate: 4.5865e-05]
	Learning Rate: 4.58652e-05
	LOSS [training: 0.001905206106417559 | validation: 0.003184210187528695]
	TIME [epoch: 8.27 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020983412280610354		[learning rate: 4.448e-05]
	Learning Rate: 4.448e-05
	LOSS [training: 0.0020983412280610354 | validation: 0.0026235913852598316]
	TIME [epoch: 8.26 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018389685291180426		[learning rate: 4.3122e-05]
	Learning Rate: 4.31221e-05
	LOSS [training: 0.0018389685291180426 | validation: 0.002833519162854347]
	TIME [epoch: 8.28 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019625992374571162		[learning rate: 4.1791e-05]
	Learning Rate: 4.17914e-05
	LOSS [training: 0.0019625992374571162 | validation: 0.003540498071825958]
	TIME [epoch: 8.26 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024136400264603572		[learning rate: 4.0488e-05]
	Learning Rate: 4.04879e-05
	LOSS [training: 0.0024136400264603572 | validation: 0.003519251159666111]
	TIME [epoch: 8.27 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017644574269255568		[learning rate: 3.9212e-05]
	Learning Rate: 3.92117e-05
	LOSS [training: 0.0017644574269255568 | validation: 0.0029053590362580536]
	TIME [epoch: 8.3 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002109964394418426		[learning rate: 3.7963e-05]
	Learning Rate: 3.79628e-05
	LOSS [training: 0.002109964394418426 | validation: 0.0024393903813915794]
	TIME [epoch: 8.27 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001842649399840403		[learning rate: 3.6741e-05]
	Learning Rate: 3.6741e-05
	LOSS [training: 0.001842649399840403 | validation: 0.003302753833635176]
	TIME [epoch: 8.25 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022199924715454924		[learning rate: 3.5547e-05]
	Learning Rate: 3.55466e-05
	LOSS [training: 0.0022199924715454924 | validation: 0.003096202345981463]
	TIME [epoch: 8.27 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002269076212891506		[learning rate: 3.4379e-05]
	Learning Rate: 3.43794e-05
	LOSS [training: 0.002269076212891506 | validation: 0.0029220259500779317]
	TIME [epoch: 8.26 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002246935829401146		[learning rate: 3.3239e-05]
	Learning Rate: 3.32394e-05
	LOSS [training: 0.002246935829401146 | validation: 0.003053215432189224]
	TIME [epoch: 8.3 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002080106051073082		[learning rate: 3.2127e-05]
	Learning Rate: 3.21267e-05
	LOSS [training: 0.002080106051073082 | validation: 0.0026018798585410556]
	TIME [epoch: 8.29 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020630338014539827		[learning rate: 3.1041e-05]
	Learning Rate: 3.10413e-05
	LOSS [training: 0.0020630338014539827 | validation: 0.003091884856313209]
	TIME [epoch: 8.26 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019352117544470986		[learning rate: 2.9983e-05]
	Learning Rate: 2.99831e-05
	LOSS [training: 0.0019352117544470986 | validation: 0.0033435238261787063]
	TIME [epoch: 8.26 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020270289813219752		[learning rate: 2.8952e-05]
	Learning Rate: 2.89522e-05
	LOSS [training: 0.0020270289813219752 | validation: 0.0030320690250651276]
	TIME [epoch: 8.26 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019435262327817428		[learning rate: 2.7949e-05]
	Learning Rate: 2.79486e-05
	LOSS [training: 0.0019435262327817428 | validation: 0.002633270389002492]
	TIME [epoch: 8.26 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019103893795479657		[learning rate: 2.6972e-05]
	Learning Rate: 2.69723e-05
	LOSS [training: 0.0019103893795479657 | validation: 0.0025917933067957258]
	TIME [epoch: 8.3 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018958625707755769		[learning rate: 2.6023e-05]
	Learning Rate: 2.60232e-05
	LOSS [training: 0.0018958625707755769 | validation: 0.0029182984258678815]
	TIME [epoch: 8.27 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002193172075498218		[learning rate: 2.5101e-05]
	Learning Rate: 2.51015e-05
	LOSS [training: 0.002193172075498218 | validation: 0.0030344068176131897]
	TIME [epoch: 8.26 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021295146430879313		[learning rate: 2.4207e-05]
	Learning Rate: 2.4207e-05
	LOSS [training: 0.0021295146430879313 | validation: 0.0030289281470126375]
	TIME [epoch: 8.27 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020223602346560628		[learning rate: 2.334e-05]
	Learning Rate: 2.33398e-05
	LOSS [training: 0.0020223602346560628 | validation: 0.0028813110627534293]
	TIME [epoch: 8.26 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019276922227206019		[learning rate: 2.25e-05]
	Learning Rate: 2.24999e-05
	LOSS [training: 0.0019276922227206019 | validation: 0.0031509315847625136]
	TIME [epoch: 8.31 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020158930117761377		[learning rate: 2.1687e-05]
	Learning Rate: 2.16873e-05
	LOSS [training: 0.0020158930117761377 | validation: 0.002704169192862647]
	TIME [epoch: 8.27 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020630996342022984		[learning rate: 2.0902e-05]
	Learning Rate: 2.09019e-05
	LOSS [training: 0.0020630996342022984 | validation: 0.0028847381999506042]
	TIME [epoch: 8.27 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001838617435098407		[learning rate: 2.0144e-05]
	Learning Rate: 2.01439e-05
	LOSS [training: 0.001838617435098407 | validation: 0.0027114586087746712]
	TIME [epoch: 8.26 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001972551069582834		[learning rate: 1.9413e-05]
	Learning Rate: 1.94132e-05
	LOSS [training: 0.001972551069582834 | validation: 0.0028655261265758502]
	TIME [epoch: 8.27 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001731673122471669		[learning rate: 1.871e-05]
	Learning Rate: 1.87097e-05
	LOSS [training: 0.001731673122471669 | validation: 0.003273263719169114]
	TIME [epoch: 8.31 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019101944703416376		[learning rate: 1.8034e-05]
	Learning Rate: 1.80336e-05
	LOSS [training: 0.0019101944703416376 | validation: 0.0027014459039324734]
	TIME [epoch: 8.31 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018345723969168672		[learning rate: 1.7385e-05]
	Learning Rate: 1.73848e-05
	LOSS [training: 0.0018345723969168672 | validation: 0.0026523917201247693]
	TIME [epoch: 8.26 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019005309134087261		[learning rate: 1.6763e-05]
	Learning Rate: 1.67633e-05
	LOSS [training: 0.0019005309134087261 | validation: 0.0032857742350496364]
	TIME [epoch: 8.25 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019154799105029143		[learning rate: 1.6169e-05]
	Learning Rate: 1.61691e-05
	LOSS [training: 0.0019154799105029143 | validation: 0.0029303318422308814]
	TIME [epoch: 8.26 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021299882768756693		[learning rate: 1.5602e-05]
	Learning Rate: 1.56022e-05
	LOSS [training: 0.0021299882768756693 | validation: 0.0031212769905115804]
	TIME [epoch: 8.27 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001827142341682046		[learning rate: 1.5063e-05]
	Learning Rate: 1.50626e-05
	LOSS [training: 0.001827142341682046 | validation: 0.002762780490336202]
	TIME [epoch: 8.27 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017707442635454137		[learning rate: 1.455e-05]
	Learning Rate: 1.45503e-05
	LOSS [training: 0.0017707442635454137 | validation: 0.00302049608215224]
	TIME [epoch: 8.3 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002088581963521267		[learning rate: 1.4065e-05]
	Learning Rate: 1.40653e-05
	LOSS [training: 0.002088581963521267 | validation: 0.0030021671721654417]
	TIME [epoch: 8.26 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00191109136997234		[learning rate: 1.3608e-05]
	Learning Rate: 1.36077e-05
	LOSS [training: 0.00191109136997234 | validation: 0.0028772732545117056]
	TIME [epoch: 8.27 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019021064689724782		[learning rate: 1.3177e-05]
	Learning Rate: 1.31773e-05
	LOSS [training: 0.0019021064689724782 | validation: 0.00290739785123379]
	TIME [epoch: 8.26 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00204975341184468		[learning rate: 1.2774e-05]
	Learning Rate: 1.27743e-05
	LOSS [training: 0.00204975341184468 | validation: 0.0031683967926411294]
	TIME [epoch: 8.27 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020917729505508403		[learning rate: 1.2399e-05]
	Learning Rate: 1.23986e-05
	LOSS [training: 0.0020917729505508403 | validation: 0.0023391727956894944]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd4_20240702_103225/states/model_phi1_1a_v_mmd4_1937.pth
	Model improved!!!
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002021330171689646		[learning rate: 1.205e-05]
	Learning Rate: 1.20502e-05
	LOSS [training: 0.002021330171689646 | validation: 0.0026299523605619736]
	TIME [epoch: 8.27 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021161773617521546		[learning rate: 1.1729e-05]
	Learning Rate: 1.17292e-05
	LOSS [training: 0.0021161773617521546 | validation: 0.0027921430697117316]
	TIME [epoch: 8.26 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019343709032073842		[learning rate: 1.1435e-05]
	Learning Rate: 1.14354e-05
	LOSS [training: 0.0019343709032073842 | validation: 0.0029123393510240535]
	TIME [epoch: 8.25 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002249008519347978		[learning rate: 1.1169e-05]
	Learning Rate: 1.1169e-05
	LOSS [training: 0.002249008519347978 | validation: 0.002845993695162169]
	TIME [epoch: 8.26 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020290583617100823		[learning rate: 1.093e-05]
	Learning Rate: 1.09299e-05
	LOSS [training: 0.0020290583617100823 | validation: 0.0035525506510272003]
	TIME [epoch: 8.28 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002027596479374801		[learning rate: 1.0718e-05]
	Learning Rate: 1.07182e-05
	LOSS [training: 0.002027596479374801 | validation: 0.003049828030578052]
	TIME [epoch: 8.29 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017858443353811026		[learning rate: 1.0534e-05]
	Learning Rate: 1.05337e-05
	LOSS [training: 0.0017858443353811026 | validation: 0.002716739321115072]
	TIME [epoch: 8.26 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002011732480450338		[learning rate: 1.0377e-05]
	Learning Rate: 1.03766e-05
	LOSS [training: 0.002011732480450338 | validation: 0.0027429924050824967]
	TIME [epoch: 8.26 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002006413949211686		[learning rate: 1.0247e-05]
	Learning Rate: 1.02468e-05
	LOSS [training: 0.002006413949211686 | validation: 0.0030199951465664674]
	TIME [epoch: 8.27 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019490534706362223		[learning rate: 1.0144e-05]
	Learning Rate: 1.01443e-05
	LOSS [training: 0.0019490534706362223 | validation: 0.0024134357042691866]
	TIME [epoch: 8.26 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019823857150947552		[learning rate: 1.0069e-05]
	Learning Rate: 1.00692e-05
	LOSS [training: 0.0019823857150947552 | validation: 0.0028922889729487986]
	TIME [epoch: 8.3 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018623624968150403		[learning rate: 1.0021e-05]
	Learning Rate: 1.00213e-05
	LOSS [training: 0.0018623624968150403 | validation: 0.0023696164131465245]
	TIME [epoch: 8.29 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021201701658076773		[learning rate: 1.0001e-05]
	Learning Rate: 1.00009e-05
	LOSS [training: 0.0021201701658076773 | validation: 0.0028333155496752093]
	TIME [epoch: 8.26 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002020149598351552		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.002020149598351552 | validation: 0.0029176152389707717]
	TIME [epoch: 8.26 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001779955756112779		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.001779955756112779 | validation: 0.002980816726468654]
	TIME [epoch: 8.26 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001991623116690307		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.001991623116690307 | validation: 0.00328587488009891]
	TIME [epoch: 8.27 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018734225535588424		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0018734225535588424 | validation: 0.003299681910107222]
	TIME [epoch: 8.3 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017476921829039022		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0017476921829039022 | validation: 0.002682858502068153]
	TIME [epoch: 8.26 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018837049196469345		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0018837049196469345 | validation: 0.0027997076367803552]
	TIME [epoch: 8.25 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002050994454206125		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.002050994454206125 | validation: 0.0030866466266873975]
	TIME [epoch: 8.26 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020778762983487383		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0020778762983487383 | validation: 0.002449390428849921]
	TIME [epoch: 8.25 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018773029482135283		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0018773029482135283 | validation: 0.0027035824584326707]
	TIME [epoch: 8.29 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001846863973647285		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.001846863973647285 | validation: 0.00306715976003846]
	TIME [epoch: 8.28 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022132713943644657		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0022132713943644657 | validation: 0.0032319686904138606]
	TIME [epoch: 8.26 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002150108691017771		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.002150108691017771 | validation: 0.002933573597316892]
	TIME [epoch: 8.26 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001807986071264228		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.001807986071264228 | validation: 0.003215871962453057]
	TIME [epoch: 8.26 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016698686554883603		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0016698686554883603 | validation: 0.0028121333874818466]
	TIME [epoch: 8.27 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019869725696672496		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0019869725696672496 | validation: 0.003355544096131328]
	TIME [epoch: 8.3 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019029237533111718		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0019029237533111718 | validation: 0.0028336766610676163]
	TIME [epoch: 8.27 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00207650314637128		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.00207650314637128 | validation: 0.002841696455883521]
	TIME [epoch: 8.27 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002069204794811116		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.002069204794811116 | validation: 0.0031010173043393863]
	TIME [epoch: 8.26 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020035887943491873		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0020035887943491873 | validation: 0.0031607004888097967]
	TIME [epoch: 8.26 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001850042866426019		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.001850042866426019 | validation: 0.0028499088239060267]
	TIME [epoch: 8.3 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002047623252832298		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.002047623252832298 | validation: 0.0027339321108506435]
	TIME [epoch: 8.28 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018789127864434073		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0018789127864434073 | validation: 0.0029062186099557312]
	TIME [epoch: 8.26 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018214761174201598		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0018214761174201598 | validation: 0.0028073474035923912]
	TIME [epoch: 8.26 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018801783300361394		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0018801783300361394 | validation: 0.0025642207571534526]
	TIME [epoch: 8.26 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019616313992665965		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0019616313992665965 | validation: 0.0033785261031212175]
	TIME [epoch: 8.26 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017848521841319692		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0017848521841319692 | validation: 0.002759548744076804]
	TIME [epoch: 8.3 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020834959213470398		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0020834959213470398 | validation: 0.002671005738959206]
	TIME [epoch: 8.26 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001990752558407841		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.001990752558407841 | validation: 0.00353342327616826]
	TIME [epoch: 8.25 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017851951527766417		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0017851951527766417 | validation: 0.0032806775039721705]
	TIME [epoch: 8.26 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017568394273222753		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0017568394273222753 | validation: 0.0026395014522507436]
	TIME [epoch: 8.26 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019516154257324379		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0019516154257324379 | validation: 0.0028376915031316516]
	TIME [epoch: 8.28 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002042290902473106		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.002042290902473106 | validation: 0.002926125105572808]
	TIME [epoch: 8.28 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020719087158441686		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0020719087158441686 | validation: 0.00316168454169593]
	TIME [epoch: 8.25 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019211944876140836		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0019211944876140836 | validation: 0.0030354326215987822]
	TIME [epoch: 8.25 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001988926757027311		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.001988926757027311 | validation: 0.0031705340825068603]
	TIME [epoch: 8.25 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019288848456638212		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0019288848456638212 | validation: 0.003049479386247695]
	TIME [epoch: 8.25 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021062200548043674		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0021062200548043674 | validation: 0.002424994508356362]
	TIME [epoch: 8.29 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018443664540994317		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0018443664540994317 | validation: 0.0029982525032457774]
	TIME [epoch: 8.25 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001723630096078556		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.001723630096078556 | validation: 0.003043679228838486]
	TIME [epoch: 8.25 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002070218304569154		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.002070218304569154 | validation: 0.002601933271412141]
	TIME [epoch: 8.25 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002059070252585244		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.002059070252585244 | validation: 0.003312867201595446]
	TIME [epoch: 8.25 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020740753746835076		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0020740753746835076 | validation: 0.002785141622649692]
	TIME [epoch: 8.27 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020135231846624443		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0020135231846624443 | validation: 0.002955328530445076]
	TIME [epoch: 8.28 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019769351297805036		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0019769351297805036 | validation: 0.0026404181455570584]
	TIME [epoch: 8.25 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019401974569233276		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0019401974569233276 | validation: 0.003274102094217625]
	TIME [epoch: 8.26 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018447387305735455		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0018447387305735455 | validation: 0.0026507765588114226]
	TIME [epoch: 8.26 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002071418580563132		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.002071418580563132 | validation: 0.002774289737836872]
	TIME [epoch: 8.24 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016973514233809362		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0016973514233809362 | validation: 0.0036731271618900305]
	TIME [epoch: 8.34 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019762220405855676		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0019762220405855676 | validation: 0.003261348401288589]
	TIME [epoch: 8.27 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019811780487775116		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0019811780487775116 | validation: 0.0036682143682618944]
	TIME [epoch: 8.23 sec]
Finished training in 16923.328 seconds.
