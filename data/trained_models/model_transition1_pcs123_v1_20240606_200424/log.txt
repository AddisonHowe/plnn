Args:
Namespace(name='model_transition1_pcs123_v1', outdir='out/model_training/model_transition1_pcs123_v1', training_data='data/training_data/data_transition1_subset_epi_trans_ce_an_pc123/training', validation_data='data/training_data/data_transition1_subset_epi_trans_ce_an_pc123/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=5, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=3, nparams=3, nsigs=2, ncells=500, dt=0.001, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=False, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2474059993

Training model...

Saving initial model state to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.67390930195206		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.67390930195206 | validation: 0.6997217170965994]
	TIME [epoch: 58.9 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5166389033551451		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5166389033551451 | validation: 0.6241259444804514]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4837404905122649		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4837404905122649 | validation: 0.5619462957396857]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.47818443163408514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47818443163408514 | validation: 0.5443012387599375]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4276739312661893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4276739312661893 | validation: 0.5813819242557193]
	TIME [epoch: 33.2 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41242203935198324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41242203935198324 | validation: 0.5069911796048271]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3985383380375525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3985383380375525 | validation: 0.49337157078777566]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3710130529651271		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3710130529651271 | validation: 0.4913622054168008]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3555717241215796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3555717241215796 | validation: 0.4236511125160892]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3374086920784296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3374086920784296 | validation: 0.40375281584545253]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33693412738125794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33693412738125794 | validation: 0.3748769135570835]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.306334865224411		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.306334865224411 | validation: 0.357990075174044]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2934872689912898		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2934872689912898 | validation: 0.35945930256344577]
	TIME [epoch: 33.2 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2494984696727521		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2494984696727521 | validation: 0.32403925479087997]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2584517439271679		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2584517439271679 | validation: 0.3145029521092616]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24891596596690546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24891596596690546 | validation: 0.3187323614362337]
	TIME [epoch: 33.2 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2440726422250475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2440726422250475 | validation: 0.31579349718894884]
	TIME [epoch: 33.2 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26082926720838606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26082926720838606 | validation: 0.291911755759929]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25903902415595753		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25903902415595753 | validation: 0.2997616541070374]
	TIME [epoch: 33.2 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24445900934266548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24445900934266548 | validation: 0.29086335526619284]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2344724779602491		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2344724779602491 | validation: 0.29420953371097147]
	TIME [epoch: 33.2 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24202463897955376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24202463897955376 | validation: 0.27893643635443466]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22952061405087085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22952061405087085 | validation: 0.27747583118825764]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.239054323456345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.239054323456345 | validation: 0.2899146420882449]
	TIME [epoch: 33.2 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2511440020514746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2511440020514746 | validation: 0.2770537868671744]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2309850641564218		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2309850641564218 | validation: 0.26863651361257695]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22310940964012035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22310940964012035 | validation: 0.2613676317649606]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2343067614418875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2343067614418875 | validation: 0.25228631431842985]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22206892208964207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22206892208964207 | validation: 0.3040249685775164]
	TIME [epoch: 33.2 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22662800211947834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22662800211947834 | validation: 0.2589058634183653]
	TIME [epoch: 33.2 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2148070311179945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2148070311179945 | validation: 0.2592333993502093]
	TIME [epoch: 33.2 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.20321616325165592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20321616325165592 | validation: 0.2505566418939563]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.20384824543723956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20384824543723956 | validation: 0.24182147499589446]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22785591477729383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22785591477729383 | validation: 0.2528204962398484]
	TIME [epoch: 33.2 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.20814795567407024		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20814795567407024 | validation: 0.23131867216214325]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.20282895607597254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20282895607597254 | validation: 0.23973731775925736]
	TIME [epoch: 33.2 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22471488780037938		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22471488780037938 | validation: 0.23483795232581536]
	TIME [epoch: 33.2 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18601306519834326		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18601306519834326 | validation: 0.24581818147413434]
	TIME [epoch: 33.2 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18335517451264347		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18335517451264347 | validation: 0.25364794900869236]
	TIME [epoch: 33.2 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1910447703174897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1910447703174897 | validation: 0.2361191975739642]
	TIME [epoch: 33.2 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.20394425581471654		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20394425581471654 | validation: 0.2439924649635848]
	TIME [epoch: 33.2 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18097057074061632		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18097057074061632 | validation: 0.23488220391855236]
	TIME [epoch: 33.2 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1907381037730079		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1907381037730079 | validation: 0.2399980792201497]
	TIME [epoch: 33.2 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18873992424112698		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18873992424112698 | validation: 0.19752834806776787]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18131870737816344		[learning rate: 0.0099823]
	Learning Rate: 0.0099823
	LOSS [training: 0.18131870737816344 | validation: 0.2057901790962596]
	TIME [epoch: 33.2 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18427806423972992		[learning rate: 0.0099426]
	Learning Rate: 0.0099426
	LOSS [training: 0.18427806423972992 | validation: 0.24952373330587502]
	TIME [epoch: 33.2 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19787542929325663		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.19787542929325663 | validation: 0.22053878745035616]
	TIME [epoch: 33.2 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17365018950819852		[learning rate: 0.0098637]
	Learning Rate: 0.00986367
	LOSS [training: 0.17365018950819852 | validation: 0.20518321919382304]
	TIME [epoch: 33.2 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1777765797137771		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 0.1777765797137771 | validation: 0.2096603620161813]
	TIME [epoch: 33.2 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18455282739678802		[learning rate: 0.0097854]
	Learning Rate: 0.00978536
	LOSS [training: 0.18455282739678802 | validation: 0.19931137380691719]
	TIME [epoch: 33.2 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1639936578537786		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.1639936578537786 | validation: 0.23670845035056992]
	TIME [epoch: 33.2 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18054473306569482		[learning rate: 0.0097077]
	Learning Rate: 0.00970768
	LOSS [training: 0.18054473306569482 | validation: 0.2509161759320775]
	TIME [epoch: 33.2 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18389564009156883		[learning rate: 0.0096691]
	Learning Rate: 0.00966907
	LOSS [training: 0.18389564009156883 | validation: 0.20687344897898569]
	TIME [epoch: 33.2 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18194723777010058		[learning rate: 0.0096306]
	Learning Rate: 0.00963061
	LOSS [training: 0.18194723777010058 | validation: 0.2062744566702921]
	TIME [epoch: 33.2 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17471961380822648		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.17471961380822648 | validation: 0.2357701438385206]
	TIME [epoch: 33.2 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1786000093518836		[learning rate: 0.0095542]
	Learning Rate: 0.00955415
	LOSS [training: 0.1786000093518836 | validation: 0.2031473899893966]
	TIME [epoch: 33.2 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16720772676123394		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 0.16720772676123394 | validation: 0.20809727124373517]
	TIME [epoch: 33.2 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17882788061967084		[learning rate: 0.0094783]
	Learning Rate: 0.00947831
	LOSS [training: 0.17882788061967084 | validation: 0.20921269337833817]
	TIME [epoch: 33.2 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1858297971751558		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.1858297971751558 | validation: 0.19196995638913225]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16871527969447003		[learning rate: 0.0094031]
	Learning Rate: 0.00940306
	LOSS [training: 0.16871527969447003 | validation: 0.2210599846166367]
	TIME [epoch: 33.2 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18739554872989667		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.18739554872989667 | validation: 0.20535391351717136]
	TIME [epoch: 33.2 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1621934367941158		[learning rate: 0.0093284]
	Learning Rate: 0.00932841
	LOSS [training: 0.1621934367941158 | validation: 0.19012438370420917]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16741037932636232		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.16741037932636232 | validation: 0.2008688545772122]
	TIME [epoch: 33.2 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1783893473301586		[learning rate: 0.0092544]
	Learning Rate: 0.00925435
	LOSS [training: 0.1783893473301586 | validation: 0.21508262455976915]
	TIME [epoch: 33.2 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17091129256422066		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.17091129256422066 | validation: 0.18653718261006774]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15022932890741206		[learning rate: 0.0091809]
	Learning Rate: 0.00918089
	LOSS [training: 0.15022932890741206 | validation: 0.20530055619108042]
	TIME [epoch: 33.2 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16679943867769173		[learning rate: 0.0091444]
	Learning Rate: 0.00914437
	LOSS [training: 0.16679943867769173 | validation: 0.19341400053985347]
	TIME [epoch: 33.2 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17125058381000477		[learning rate: 0.009108]
	Learning Rate: 0.009108
	LOSS [training: 0.17125058381000477 | validation: 0.22791805113609978]
	TIME [epoch: 33.2 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17875420943286235		[learning rate: 0.0090718]
	Learning Rate: 0.00907178
	LOSS [training: 0.17875420943286235 | validation: 0.18103799847022156]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15774097059466038		[learning rate: 0.0090357]
	Learning Rate: 0.00903569
	LOSS [training: 0.15774097059466038 | validation: 0.2027221236621047]
	TIME [epoch: 33.2 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17710426465230736		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.17710426465230736 | validation: 0.18629454461864986]
	TIME [epoch: 33.2 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16499841437226237		[learning rate: 0.008964]
	Learning Rate: 0.00896396
	LOSS [training: 0.16499841437226237 | validation: 0.1920608683696718]
	TIME [epoch: 33.2 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17628590935179553		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 0.17628590935179553 | validation: 0.20121945385473894]
	TIME [epoch: 33.2 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16295417328857323		[learning rate: 0.0088928]
	Learning Rate: 0.0088928
	LOSS [training: 0.16295417328857323 | validation: 0.19048081324570493]
	TIME [epoch: 33.2 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15673106110310753		[learning rate: 0.0088574]
	Learning Rate: 0.00885743
	LOSS [training: 0.15673106110310753 | validation: 0.2235364758894196]
	TIME [epoch: 33.2 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1667566835602166		[learning rate: 0.0088222]
	Learning Rate: 0.0088222
	LOSS [training: 0.1667566835602166 | validation: 0.18000017989737715]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16955146376579816		[learning rate: 0.0087871]
	Learning Rate: 0.00878711
	LOSS [training: 0.16955146376579816 | validation: 0.22250905048828512]
	TIME [epoch: 33.2 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1757730332829856		[learning rate: 0.0087522]
	Learning Rate: 0.00875216
	LOSS [training: 0.1757730332829856 | validation: 0.18233759773438002]
	TIME [epoch: 33.2 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15164934661536644		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.15164934661536644 | validation: 0.18423156276848657]
	TIME [epoch: 33.2 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15857214648695614		[learning rate: 0.0086827]
	Learning Rate: 0.00868268
	LOSS [training: 0.15857214648695614 | validation: 0.17514162891090718]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15959873932585075		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.15959873932585075 | validation: 0.1855485981397404]
	TIME [epoch: 33.2 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16283733578068738		[learning rate: 0.0086138]
	Learning Rate: 0.00861375
	LOSS [training: 0.16283733578068738 | validation: 0.197204465054624]
	TIME [epoch: 33.2 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16191714858998288		[learning rate: 0.0085795]
	Learning Rate: 0.00857949
	LOSS [training: 0.16191714858998288 | validation: 0.18247479678290018]
	TIME [epoch: 33.2 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1693446709821611		[learning rate: 0.0085454]
	Learning Rate: 0.00854537
	LOSS [training: 0.1693446709821611 | validation: 0.21021721260839027]
	TIME [epoch: 33.2 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1738908298280033		[learning rate: 0.0085114]
	Learning Rate: 0.00851138
	LOSS [training: 0.1738908298280033 | validation: 0.17808610187282176]
	TIME [epoch: 33.2 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15559081236766253		[learning rate: 0.0084775]
	Learning Rate: 0.00847753
	LOSS [training: 0.15559081236766253 | validation: 0.19059916642768376]
	TIME [epoch: 33.2 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1617646759490205		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.1617646759490205 | validation: 0.1889247347918605]
	TIME [epoch: 33.2 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1585567996148814		[learning rate: 0.0084102]
	Learning Rate: 0.00841023
	LOSS [training: 0.1585567996148814 | validation: 0.16618171664705628]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15137310641425702		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 0.15137310641425702 | validation: 0.17603098976290163]
	TIME [epoch: 33.2 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16877999159610488		[learning rate: 0.0083435]
	Learning Rate: 0.00834346
	LOSS [training: 0.16877999159610488 | validation: 0.19970727103602576]
	TIME [epoch: 33.2 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1779013988462605		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.1779013988462605 | validation: 0.1825029730032703]
	TIME [epoch: 33.2 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14987670299921102		[learning rate: 0.0082772]
	Learning Rate: 0.00827722
	LOSS [training: 0.14987670299921102 | validation: 0.17349803877558215]
	TIME [epoch: 33.2 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1494967993388074		[learning rate: 0.0082443]
	Learning Rate: 0.0082443
	LOSS [training: 0.1494967993388074 | validation: 0.17210404436050494]
	TIME [epoch: 33.2 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15468825159910984		[learning rate: 0.0082115]
	Learning Rate: 0.00821151
	LOSS [training: 0.15468825159910984 | validation: 0.19712908095835532]
	TIME [epoch: 33.2 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15740263507447635		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.15740263507447635 | validation: 0.1929920804162016]
	TIME [epoch: 33.2 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16394796932288552		[learning rate: 0.0081463]
	Learning Rate: 0.00814632
	LOSS [training: 0.16394796932288552 | validation: 0.1682998832232689]
	TIME [epoch: 33.2 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15775505966221157		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.15775505966221157 | validation: 0.17601453307842835]
	TIME [epoch: 33.2 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15976398262272895		[learning rate: 0.0080816]
	Learning Rate: 0.00808165
	LOSS [training: 0.15976398262272895 | validation: 0.17812556133034918]
	TIME [epoch: 33.2 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14922240977973758		[learning rate: 0.0080495]
	Learning Rate: 0.00804951
	LOSS [training: 0.14922240977973758 | validation: 0.1772093778914416]
	TIME [epoch: 33.2 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16020031038028193		[learning rate: 0.0080175]
	Learning Rate: 0.00801749
	LOSS [training: 0.16020031038028193 | validation: 0.1736871475738459]
	TIME [epoch: 33.2 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14506280278800374		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.14506280278800374 | validation: 0.24843984039273784]
	TIME [epoch: 33.2 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16517752938115937		[learning rate: 0.0079538]
	Learning Rate: 0.00795384
	LOSS [training: 0.16517752938115937 | validation: 0.1734461728210275]
	TIME [epoch: 33.2 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1546806016132581		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.1546806016132581 | validation: 0.1788449724256278]
	TIME [epoch: 33.2 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14846745403283912		[learning rate: 0.0078907]
	Learning Rate: 0.0078907
	LOSS [training: 0.14846745403283912 | validation: 0.17848077101323315]
	TIME [epoch: 33.2 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16041542493484584		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 0.16041542493484584 | validation: 0.17049471343918818]
	TIME [epoch: 33.2 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16429015319461027		[learning rate: 0.0078281]
	Learning Rate: 0.00782805
	LOSS [training: 0.16429015319461027 | validation: 0.1654914051283382]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1523341277932789		[learning rate: 0.0077969]
	Learning Rate: 0.00779692
	LOSS [training: 0.1523341277932789 | validation: 0.15914246505387497]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14341286239869377		[learning rate: 0.0077659]
	Learning Rate: 0.00776591
	LOSS [training: 0.14341286239869377 | validation: 0.19546184173332676]
	TIME [epoch: 33.2 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16906997935217244		[learning rate: 0.007735]
	Learning Rate: 0.00773502
	LOSS [training: 0.16906997935217244 | validation: 0.17552898013802415]
	TIME [epoch: 33.2 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14120538444225472		[learning rate: 0.0077043]
	Learning Rate: 0.00770426
	LOSS [training: 0.14120538444225472 | validation: 0.16310283363668238]
	TIME [epoch: 33.2 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14788468478324776		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.14788468478324776 | validation: 0.16435350218952222]
	TIME [epoch: 33.2 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14571901905184684		[learning rate: 0.0076431]
	Learning Rate: 0.00764309
	LOSS [training: 0.14571901905184684 | validation: 0.17251309035045456]
	TIME [epoch: 33.2 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1436040209112529		[learning rate: 0.0076127]
	Learning Rate: 0.00761269
	LOSS [training: 0.1436040209112529 | validation: 0.20709468518528062]
	TIME [epoch: 33.2 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15098109877938265		[learning rate: 0.0075824]
	Learning Rate: 0.00758242
	LOSS [training: 0.15098109877938265 | validation: 0.16935894492000472]
	TIME [epoch: 33.2 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15240501512541574		[learning rate: 0.0075523]
	Learning Rate: 0.00755226
	LOSS [training: 0.15240501512541574 | validation: 0.17541386971995793]
	TIME [epoch: 33.2 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16529657141686702		[learning rate: 0.0075222]
	Learning Rate: 0.00752222
	LOSS [training: 0.16529657141686702 | validation: 0.19407774603792113]
	TIME [epoch: 33.2 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.182593728267886		[learning rate: 0.0074923]
	Learning Rate: 0.0074923
	LOSS [training: 0.182593728267886 | validation: 0.16186676878785491]
	TIME [epoch: 33.2 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14815687347551723		[learning rate: 0.0074625]
	Learning Rate: 0.0074625
	LOSS [training: 0.14815687347551723 | validation: 0.15909220218640968]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_118.pth
	Model improved!!!
EPOCH 119/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14823344826526466		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.14823344826526466 | validation: 0.17925856234086496]
	TIME [epoch: 33.2 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1458089659964691		[learning rate: 0.0074033]
	Learning Rate: 0.00740326
	LOSS [training: 0.1458089659964691 | validation: 0.17643762476985647]
	TIME [epoch: 33.2 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15065932837164986		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.15065932837164986 | validation: 0.1517029648825443]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13755835993961366		[learning rate: 0.0073445]
	Learning Rate: 0.00734449
	LOSS [training: 0.13755835993961366 | validation: 0.15897805323465378]
	TIME [epoch: 33.2 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15323552181939082		[learning rate: 0.0073153]
	Learning Rate: 0.00731528
	LOSS [training: 0.15323552181939082 | validation: 0.18437705999171305]
	TIME [epoch: 33.2 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14603689819781573		[learning rate: 0.0072862]
	Learning Rate: 0.00728618
	LOSS [training: 0.14603689819781573 | validation: 0.1674152357434024]
	TIME [epoch: 33.2 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15307156591906354		[learning rate: 0.0072572]
	Learning Rate: 0.0072572
	LOSS [training: 0.15307156591906354 | validation: 0.1717481398068636]
	TIME [epoch: 33.2 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14644395116712491		[learning rate: 0.0072283]
	Learning Rate: 0.00722834
	LOSS [training: 0.14644395116712491 | validation: 0.15673092481948814]
	TIME [epoch: 33.2 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14706916840494624		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.14706916840494624 | validation: 0.17313143043747573]
	TIME [epoch: 33.2 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1461607957748848		[learning rate: 0.007171]
	Learning Rate: 0.00717095
	LOSS [training: 0.1461607957748848 | validation: 0.16174828326318125]
	TIME [epoch: 33.2 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14405766257725114		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.14405766257725114 | validation: 0.15613057831068736]
	TIME [epoch: 33.2 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14245305551744464		[learning rate: 0.007114]
	Learning Rate: 0.00711403
	LOSS [training: 0.14245305551744464 | validation: 0.16122334615546316]
	TIME [epoch: 33.2 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.148828289516174		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.148828289516174 | validation: 0.14802632345559932]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_131.pth
	Model improved!!!
EPOCH 132/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15384209718324027		[learning rate: 0.0070575]
	Learning Rate: 0.00705755
	LOSS [training: 0.15384209718324027 | validation: 0.15893803502860332]
	TIME [epoch: 33.2 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13647386239007409		[learning rate: 0.0070295]
	Learning Rate: 0.00702948
	LOSS [training: 0.13647386239007409 | validation: 0.17056270776497806]
	TIME [epoch: 33.2 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15105970506387537		[learning rate: 0.0070015]
	Learning Rate: 0.00700152
	LOSS [training: 0.15105970506387537 | validation: 0.14484163695619764]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_134.pth
	Model improved!!!
EPOCH 135/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14362351678701393		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.14362351678701393 | validation: 0.18378095188551963]
	TIME [epoch: 33.2 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14334486275269656		[learning rate: 0.0069459]
	Learning Rate: 0.00694594
	LOSS [training: 0.14334486275269656 | validation: 0.1878103515022808]
	TIME [epoch: 33.2 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14224453780204252		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 0.14224453780204252 | validation: 0.1504498590935816]
	TIME [epoch: 33.2 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14393467477478292		[learning rate: 0.0068908]
	Learning Rate: 0.00689079
	LOSS [training: 0.14393467477478292 | validation: 0.1667067382033482]
	TIME [epoch: 33.2 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14890045330153884		[learning rate: 0.0068634]
	Learning Rate: 0.00686339
	LOSS [training: 0.14890045330153884 | validation: 0.15433926041322227]
	TIME [epoch: 33.2 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15265496565305653		[learning rate: 0.0068361]
	Learning Rate: 0.00683609
	LOSS [training: 0.15265496565305653 | validation: 0.1612519179788568]
	TIME [epoch: 33.2 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14541876662824293		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.14541876662824293 | validation: 0.16216978810925686]
	TIME [epoch: 33.2 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1413700447496464		[learning rate: 0.0067818]
	Learning Rate: 0.00678182
	LOSS [training: 0.1413700447496464 | validation: 0.17345829244148714]
	TIME [epoch: 33.2 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1439603580982796		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.1439603580982796 | validation: 0.14925660424658063]
	TIME [epoch: 33.2 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13605537255027778		[learning rate: 0.006728]
	Learning Rate: 0.00672798
	LOSS [training: 0.13605537255027778 | validation: 0.17620235669372022]
	TIME [epoch: 33.2 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13744420044427638		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 0.13744420044427638 | validation: 0.15886024343095645]
	TIME [epoch: 33.2 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13237566067308093		[learning rate: 0.0066746]
	Learning Rate: 0.00667457
	LOSS [training: 0.13237566067308093 | validation: 0.16629784140075868]
	TIME [epoch: 33.2 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13995895446128204		[learning rate: 0.006648]
	Learning Rate: 0.00664802
	LOSS [training: 0.13995895446128204 | validation: 0.15918660626758618]
	TIME [epoch: 33.2 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1316988864325471		[learning rate: 0.0066216]
	Learning Rate: 0.00662158
	LOSS [training: 0.1316988864325471 | validation: 0.15750807745007167]
	TIME [epoch: 33.2 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13324059632329024		[learning rate: 0.0065952]
	Learning Rate: 0.00659524
	LOSS [training: 0.13324059632329024 | validation: 0.20377531971758883]
	TIME [epoch: 33.2 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14846991808248367		[learning rate: 0.006569]
	Learning Rate: 0.00656901
	LOSS [training: 0.14846991808248367 | validation: 0.15269158194225585]
	TIME [epoch: 33.2 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13410346055986755		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.13410346055986755 | validation: 0.14945927714637824]
	TIME [epoch: 33.2 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13295599382508072		[learning rate: 0.0065169]
	Learning Rate: 0.00651686
	LOSS [training: 0.13295599382508072 | validation: 0.1552648794194855]
	TIME [epoch: 33.2 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14501044460402593		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 0.14501044460402593 | validation: 0.17503470469932744]
	TIME [epoch: 33.2 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14897977657257966		[learning rate: 0.0064651]
	Learning Rate: 0.00646512
	LOSS [training: 0.14897977657257966 | validation: 0.14715655917855341]
	TIME [epoch: 33.2 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14064322836354354		[learning rate: 0.0064394]
	Learning Rate: 0.00643941
	LOSS [training: 0.14064322836354354 | validation: 0.15504908706769704]
	TIME [epoch: 33.2 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13130293587952335		[learning rate: 0.0064138]
	Learning Rate: 0.0064138
	LOSS [training: 0.13130293587952335 | validation: 0.16475860235866743]
	TIME [epoch: 33.2 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14047164151070868		[learning rate: 0.0063883]
	Learning Rate: 0.00638829
	LOSS [training: 0.14047164151070868 | validation: 0.1586340499693586]
	TIME [epoch: 33.2 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13810395206990186		[learning rate: 0.0063629]
	Learning Rate: 0.00636288
	LOSS [training: 0.13810395206990186 | validation: 0.18088907636556834]
	TIME [epoch: 33.2 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1501354631861816		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.1501354631861816 | validation: 0.15618700178409917]
	TIME [epoch: 33.2 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1446654152547953		[learning rate: 0.0063124]
	Learning Rate: 0.00631237
	LOSS [training: 0.1446654152547953 | validation: 0.1586888887182759]
	TIME [epoch: 33.2 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14215437768433967		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.14215437768433967 | validation: 0.16682543555655277]
	TIME [epoch: 33.2 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13729401798087165		[learning rate: 0.0062623]
	Learning Rate: 0.00626226
	LOSS [training: 0.13729401798087165 | validation: 0.14528510885976145]
	TIME [epoch: 33.2 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.137133463231708		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.137133463231708 | validation: 0.16312194665392385]
	TIME [epoch: 33.2 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13283565389695384		[learning rate: 0.0062125]
	Learning Rate: 0.00621254
	LOSS [training: 0.13283565389695384 | validation: 0.23408000453366662]
	TIME [epoch: 33.2 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13605312688309248		[learning rate: 0.0061878]
	Learning Rate: 0.00618783
	LOSS [training: 0.13605312688309248 | validation: 0.1556286036008945]
	TIME [epoch: 33.2 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13908894698179025		[learning rate: 0.0061632]
	Learning Rate: 0.00616322
	LOSS [training: 0.13908894698179025 | validation: 0.1652557026951365]
	TIME [epoch: 33.2 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13859422145501193		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.13859422145501193 | validation: 0.15699930758345776]
	TIME [epoch: 33.2 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14952544309719906		[learning rate: 0.0061143]
	Learning Rate: 0.00611429
	LOSS [training: 0.14952544309719906 | validation: 0.15973612490852362]
	TIME [epoch: 33.2 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13398535228364694		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 0.13398535228364694 | validation: 0.15228216084332885]
	TIME [epoch: 33.2 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12815255126617564		[learning rate: 0.0060658]
	Learning Rate: 0.00606575
	LOSS [training: 0.12815255126617564 | validation: 0.14257561941266675]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_170.pth
	Model improved!!!
EPOCH 171/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1468682439084816		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.1468682439084816 | validation: 0.16730144917383738]
	TIME [epoch: 33.2 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15020440687277		[learning rate: 0.0060176]
	Learning Rate: 0.0060176
	LOSS [training: 0.15020440687277 | validation: 0.1546584146311549]
	TIME [epoch: 33.2 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13630537216367813		[learning rate: 0.0059937]
	Learning Rate: 0.00599366
	LOSS [training: 0.13630537216367813 | validation: 0.15653049543718262]
	TIME [epoch: 33.2 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13746308871149152		[learning rate: 0.0059698]
	Learning Rate: 0.00596982
	LOSS [training: 0.13746308871149152 | validation: 0.15118322274847892]
	TIME [epoch: 33.2 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13729753095555775		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.13729753095555775 | validation: 0.1551567688401691]
	TIME [epoch: 33.2 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14075882493029873		[learning rate: 0.0059224]
	Learning Rate: 0.00592243
	LOSS [training: 0.14075882493029873 | validation: 0.16740762291686956]
	TIME [epoch: 33.2 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12967367562828072		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 0.12967367562828072 | validation: 0.18832059502533496]
	TIME [epoch: 33.2 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14058153400847495		[learning rate: 0.0058754]
	Learning Rate: 0.00587541
	LOSS [training: 0.14058153400847495 | validation: 0.16920442316257192]
	TIME [epoch: 33.2 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14021408711456507		[learning rate: 0.005852]
	Learning Rate: 0.00585205
	LOSS [training: 0.14021408711456507 | validation: 0.1547728838092835]
	TIME [epoch: 33.2 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13873694014615637		[learning rate: 0.0058288]
	Learning Rate: 0.00582877
	LOSS [training: 0.13873694014615637 | validation: 0.14569805965449031]
	TIME [epoch: 33.2 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1336367668039602		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.1336367668039602 | validation: 0.14767376112171893]
	TIME [epoch: 33.2 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13832778186530784		[learning rate: 0.0057825]
	Learning Rate: 0.0057825
	LOSS [training: 0.13832778186530784 | validation: 0.1484873405990594]
	TIME [epoch: 33.2 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1264291115638313		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.1264291115638313 | validation: 0.15353947413803315]
	TIME [epoch: 33.2 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14509504505249196		[learning rate: 0.0057366]
	Learning Rate: 0.00573659
	LOSS [training: 0.14509504505249196 | validation: 0.14934515638570184]
	TIME [epoch: 33.2 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13474149587612524		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 0.13474149587612524 | validation: 0.16143592624500086]
	TIME [epoch: 33.2 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13858525110238878		[learning rate: 0.005691]
	Learning Rate: 0.00569105
	LOSS [training: 0.13858525110238878 | validation: 0.15802803511730795]
	TIME [epoch: 33.2 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12747680853150714		[learning rate: 0.0056684]
	Learning Rate: 0.00566841
	LOSS [training: 0.12747680853150714 | validation: 0.1479625135262476]
	TIME [epoch: 33.2 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14231365831619905		[learning rate: 0.0056459]
	Learning Rate: 0.00564587
	LOSS [training: 0.14231365831619905 | validation: 0.2224862409686291]
	TIME [epoch: 33.2 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14545802114049444		[learning rate: 0.0056234]
	Learning Rate: 0.00562341
	LOSS [training: 0.14545802114049444 | validation: 0.1501065409431886]
	TIME [epoch: 33.2 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14227526656860853		[learning rate: 0.005601]
	Learning Rate: 0.00560105
	LOSS [training: 0.14227526656860853 | validation: 0.17054325500673795]
	TIME [epoch: 33.2 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14196137864376135		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.14196137864376135 | validation: 0.18400850028999083]
	TIME [epoch: 33.2 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14819906187990814		[learning rate: 0.0055566]
	Learning Rate: 0.00555658
	LOSS [training: 0.14819906187990814 | validation: 0.14061148990669198]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_192.pth
	Model improved!!!
EPOCH 193/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13166011959252621		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.13166011959252621 | validation: 0.15002620994974794]
	TIME [epoch: 33.2 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13623152666595104		[learning rate: 0.0055125]
	Learning Rate: 0.00551247
	LOSS [training: 0.13623152666595104 | validation: 0.15241070674095186]
	TIME [epoch: 33.2 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1314452903913823		[learning rate: 0.0054905]
	Learning Rate: 0.00549054
	LOSS [training: 0.1314452903913823 | validation: 0.1441135223470922]
	TIME [epoch: 33.2 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13424859970974476		[learning rate: 0.0054687]
	Learning Rate: 0.00546871
	LOSS [training: 0.13424859970974476 | validation: 0.16200455456584753]
	TIME [epoch: 33.2 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1251616715233893		[learning rate: 0.005447]
	Learning Rate: 0.00544696
	LOSS [training: 0.1251616715233893 | validation: 0.19463385459161003]
	TIME [epoch: 33.2 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14754456405740893		[learning rate: 0.0054253]
	Learning Rate: 0.00542529
	LOSS [training: 0.14754456405740893 | validation: 0.212727835623586]
	TIME [epoch: 33.2 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16194012376573147		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.16194012376573147 | validation: 0.1410874974303075]
	TIME [epoch: 33.2 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13370549434398196		[learning rate: 0.0053822]
	Learning Rate: 0.00538222
	LOSS [training: 0.13370549434398196 | validation: 0.18922704910980098]
	TIME [epoch: 33.2 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1358668089015527		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.1358668089015527 | validation: 0.15161379513702794]
	TIME [epoch: 33.2 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13045070966336947		[learning rate: 0.0053395]
	Learning Rate: 0.00533949
	LOSS [training: 0.13045070966336947 | validation: 0.14716173960312323]
	TIME [epoch: 33.2 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13913861923647966		[learning rate: 0.0053183]
	Learning Rate: 0.00531826
	LOSS [training: 0.13913861923647966 | validation: 0.17372896051184494]
	TIME [epoch: 33.2 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13540781238957178		[learning rate: 0.0052971]
	Learning Rate: 0.0052971
	LOSS [training: 0.13540781238957178 | validation: 0.14263704913862096]
	TIME [epoch: 33.2 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1386327020393088		[learning rate: 0.005276]
	Learning Rate: 0.00527604
	LOSS [training: 0.1386327020393088 | validation: 0.15331261084572315]
	TIME [epoch: 33.2 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13053169823939542		[learning rate: 0.0052551]
	Learning Rate: 0.00525505
	LOSS [training: 0.13053169823939542 | validation: 0.14493105196901906]
	TIME [epoch: 33.2 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1479134299156665		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.1479134299156665 | validation: 0.1511512350968897]
	TIME [epoch: 33.2 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13442666385152424		[learning rate: 0.0052133]
	Learning Rate: 0.00521333
	LOSS [training: 0.13442666385152424 | validation: 0.14712115873160753]
	TIME [epoch: 33.2 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14325292498224235		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 0.14325292498224235 | validation: 0.1473334590389463]
	TIME [epoch: 33.2 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13041736475348778		[learning rate: 0.0051719]
	Learning Rate: 0.00517194
	LOSS [training: 0.13041736475348778 | validation: 0.1434010267631623]
	TIME [epoch: 33.2 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13971659989152357		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.13971659989152357 | validation: 0.14690972179037806]
	TIME [epoch: 33.2 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14328890363376434		[learning rate: 0.0051309]
	Learning Rate: 0.00513089
	LOSS [training: 0.14328890363376434 | validation: 0.19008627261953703]
	TIME [epoch: 33.2 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1402863608424848		[learning rate: 0.0051105]
	Learning Rate: 0.00511048
	LOSS [training: 0.1402863608424848 | validation: 0.14827699953908477]
	TIME [epoch: 33.2 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.139287030376217		[learning rate: 0.0050902]
	Learning Rate: 0.00509015
	LOSS [training: 0.139287030376217 | validation: 0.14871307106722573]
	TIME [epoch: 33.2 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14035465093746843		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.14035465093746843 | validation: 0.14541613139579881]
	TIME [epoch: 33.2 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13072347408024912		[learning rate: 0.0050497]
	Learning Rate: 0.00504974
	LOSS [training: 0.13072347408024912 | validation: 0.15703649962009864]
	TIME [epoch: 33.2 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12826104111980602		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 0.12826104111980602 | validation: 0.13858713005030246]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_217.pth
	Model improved!!!
EPOCH 218/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12609957996559223		[learning rate: 0.0050097]
	Learning Rate: 0.00500965
	LOSS [training: 0.12609957996559223 | validation: 0.15373834956534785]
	TIME [epoch: 33.2 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14586955301851562		[learning rate: 0.0049897]
	Learning Rate: 0.00498973
	LOSS [training: 0.14586955301851562 | validation: 0.17307680744505805]
	TIME [epoch: 33.2 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13607206476987058		[learning rate: 0.0049699]
	Learning Rate: 0.00496988
	LOSS [training: 0.13607206476987058 | validation: 0.1436864525799632]
	TIME [epoch: 33.2 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13181043976910434		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.13181043976910434 | validation: 0.14310533183348306]
	TIME [epoch: 33.2 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1303617853097688		[learning rate: 0.0049304]
	Learning Rate: 0.00493043
	LOSS [training: 0.1303617853097688 | validation: 0.1422832755242239]
	TIME [epoch: 33.2 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13155193966955672		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.13155193966955672 | validation: 0.14042481881309118]
	TIME [epoch: 33.2 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13640326623587684		[learning rate: 0.0048913]
	Learning Rate: 0.00489129
	LOSS [training: 0.13640326623587684 | validation: 0.14496983013429998]
	TIME [epoch: 33.2 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1265919212505414		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.1265919212505414 | validation: 0.14874779839059174]
	TIME [epoch: 33.2 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1410447776246414		[learning rate: 0.0048525]
	Learning Rate: 0.00485245
	LOSS [training: 0.1410447776246414 | validation: 0.15504894742045877]
	TIME [epoch: 33.2 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11911311978630058		[learning rate: 0.0048332]
	Learning Rate: 0.00483316
	LOSS [training: 0.11911311978630058 | validation: 0.14878653578119652]
	TIME [epoch: 33.2 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12412710249693257		[learning rate: 0.0048139]
	Learning Rate: 0.00481393
	LOSS [training: 0.12412710249693257 | validation: 0.1418521074525238]
	TIME [epoch: 33.2 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13835812678062953		[learning rate: 0.0047948]
	Learning Rate: 0.00479479
	LOSS [training: 0.13835812678062953 | validation: 0.16969720139101022]
	TIME [epoch: 33.2 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1400388435784833		[learning rate: 0.0047757]
	Learning Rate: 0.00477572
	LOSS [training: 0.1400388435784833 | validation: 0.1457058205619844]
	TIME [epoch: 33.2 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12779814446469617		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.12779814446469617 | validation: 0.1903815542145329]
	TIME [epoch: 33.2 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14203549558687645		[learning rate: 0.0047378]
	Learning Rate: 0.0047378
	LOSS [training: 0.14203549558687645 | validation: 0.15894947163828205]
	TIME [epoch: 33.2 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13814188827515356		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 0.13814188827515356 | validation: 0.14757296384154212]
	TIME [epoch: 33.2 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1353567764834165		[learning rate: 0.0047002]
	Learning Rate: 0.00470019
	LOSS [training: 0.1353567764834165 | validation: 0.1425769149608628]
	TIME [epoch: 33.2 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12255552565618949		[learning rate: 0.0046815]
	Learning Rate: 0.0046815
	LOSS [training: 0.12255552565618949 | validation: 0.16524632468017691]
	TIME [epoch: 33.2 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1464066467059176		[learning rate: 0.0046629]
	Learning Rate: 0.00466288
	LOSS [training: 0.1464066467059176 | validation: 0.14144678092948335]
	TIME [epoch: 33.2 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13646896128409916		[learning rate: 0.0046443]
	Learning Rate: 0.00464433
	LOSS [training: 0.13646896128409916 | validation: 0.17492207884255276]
	TIME [epoch: 33.2 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13939612626740594		[learning rate: 0.0046259]
	Learning Rate: 0.00462586
	LOSS [training: 0.13939612626740594 | validation: 0.13778882795474579]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_238.pth
	Model improved!!!
EPOCH 239/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12778575417617608		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.12778575417617608 | validation: 0.13770202168516016]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_239.pth
	Model improved!!!
EPOCH 240/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13178867672889008		[learning rate: 0.0045891]
	Learning Rate: 0.00458913
	LOSS [training: 0.13178867672889008 | validation: 0.1463815166620702]
	TIME [epoch: 33.2 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1274880633807331		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.1274880633807331 | validation: 0.14910187235836864]
	TIME [epoch: 33.2 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1304035339787437		[learning rate: 0.0045527]
	Learning Rate: 0.0045527
	LOSS [training: 0.1304035339787437 | validation: 0.14166500011088295]
	TIME [epoch: 33.2 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1344930129025965		[learning rate: 0.0045346]
	Learning Rate: 0.00453459
	LOSS [training: 0.1344930129025965 | validation: 0.15034705370637239]
	TIME [epoch: 33.2 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13526569541716615		[learning rate: 0.0045166]
	Learning Rate: 0.00451656
	LOSS [training: 0.13526569541716615 | validation: 0.14705271092271788]
	TIME [epoch: 33.2 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13265557562132171		[learning rate: 0.0044986]
	Learning Rate: 0.0044986
	LOSS [training: 0.13265557562132171 | validation: 0.15115708323416416]
	TIME [epoch: 33.2 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1264133085007931		[learning rate: 0.0044807]
	Learning Rate: 0.0044807
	LOSS [training: 0.1264133085007931 | validation: 0.14793478043159974]
	TIME [epoch: 33.2 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13380771696293914		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.13380771696293914 | validation: 0.1369900638933888]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_247.pth
	Model improved!!!
EPOCH 248/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12764647903926984		[learning rate: 0.0044451]
	Learning Rate: 0.00444513
	LOSS [training: 0.12764647903926984 | validation: 0.14955599239145054]
	TIME [epoch: 33.2 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12081589363413675		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 0.12081589363413675 | validation: 0.14611466789759117]
	TIME [epoch: 33.2 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12738041998609428		[learning rate: 0.0044098]
	Learning Rate: 0.00440984
	LOSS [training: 0.12738041998609428 | validation: 0.1430343974306207]
	TIME [epoch: 33.2 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12098235848826716		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.12098235848826716 | validation: 0.1529161063065056]
	TIME [epoch: 33.2 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1395579005501251		[learning rate: 0.0043748]
	Learning Rate: 0.00437483
	LOSS [training: 0.1395579005501251 | validation: 0.1459757368153831]
	TIME [epoch: 33.2 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12752313307326657		[learning rate: 0.0043574]
	Learning Rate: 0.00435743
	LOSS [training: 0.12752313307326657 | validation: 0.143559170947186]
	TIME [epoch: 33.2 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1335412726388454		[learning rate: 0.0043401]
	Learning Rate: 0.0043401
	LOSS [training: 0.1335412726388454 | validation: 0.14394079516017474]
	TIME [epoch: 33.2 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13445500461988955		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.13445500461988955 | validation: 0.14554899643238503]
	TIME [epoch: 33.2 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1259608842025869		[learning rate: 0.0043056]
	Learning Rate: 0.00430565
	LOSS [training: 0.1259608842025869 | validation: 0.13816856424903673]
	TIME [epoch: 33.2 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12452264200936912		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.12452264200936912 | validation: 0.14081013867331507]
	TIME [epoch: 33.2 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1267392342570076		[learning rate: 0.0042715]
	Learning Rate: 0.00427147
	LOSS [training: 0.1267392342570076 | validation: 0.14139101877459878]
	TIME [epoch: 33.2 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1304526065832213		[learning rate: 0.0042545]
	Learning Rate: 0.00425448
	LOSS [training: 0.1304526065832213 | validation: 0.1364957789098098]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_259.pth
	Model improved!!!
EPOCH 260/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13053568584239392		[learning rate: 0.0042376]
	Learning Rate: 0.00423756
	LOSS [training: 0.13053568584239392 | validation: 0.14774779347429773]
	TIME [epoch: 33.2 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12740177710875705		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.12740177710875705 | validation: 0.14247620377910822]
	TIME [epoch: 33.2 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1303080725381468		[learning rate: 0.0042039]
	Learning Rate: 0.00420391
	LOSS [training: 0.1303080725381468 | validation: 0.1497068108650609]
	TIME [epoch: 33.2 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12219827932049987		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.12219827932049987 | validation: 0.14315723110249398]
	TIME [epoch: 33.2 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12915006414663469		[learning rate: 0.0041705]
	Learning Rate: 0.00417054
	LOSS [training: 0.12915006414663469 | validation: 0.13590565562262363]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_264.pth
	Model improved!!!
EPOCH 265/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13696020655456126		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 0.13696020655456126 | validation: 0.1465288256855331]
	TIME [epoch: 33.2 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12847913361028285		[learning rate: 0.0041374]
	Learning Rate: 0.00413743
	LOSS [training: 0.12847913361028285 | validation: 0.15978135329890983]
	TIME [epoch: 33.2 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12514967252819353		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.12514967252819353 | validation: 0.13632636076214805]
	TIME [epoch: 33.2 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14186737083363835		[learning rate: 0.0041046]
	Learning Rate: 0.00410458
	LOSS [training: 0.14186737083363835 | validation: 0.14143454684092527]
	TIME [epoch: 33.2 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12501801457046086		[learning rate: 0.0040883]
	Learning Rate: 0.00408826
	LOSS [training: 0.12501801457046086 | validation: 0.13140965077725708]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_269.pth
	Model improved!!!
EPOCH 270/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13449612165403957		[learning rate: 0.004072]
	Learning Rate: 0.004072
	LOSS [training: 0.13449612165403957 | validation: 0.14497434376957158]
	TIME [epoch: 33.2 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12574648700230293		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.12574648700230293 | validation: 0.13553863522891724]
	TIME [epoch: 33.2 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1301738622919655		[learning rate: 0.0040397]
	Learning Rate: 0.00403967
	LOSS [training: 0.1301738622919655 | validation: 0.1351522838248694]
	TIME [epoch: 33.2 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13083208312305328		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 0.13083208312305328 | validation: 0.14948313482351042]
	TIME [epoch: 33.2 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1316284501200856		[learning rate: 0.0040076]
	Learning Rate: 0.0040076
	LOSS [training: 0.1316284501200856 | validation: 0.1502040305610763]
	TIME [epoch: 33.2 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12285359181112072		[learning rate: 0.0039917]
	Learning Rate: 0.00399166
	LOSS [training: 0.12285359181112072 | validation: 0.14010421343850096]
	TIME [epoch: 33.2 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12792800406550964		[learning rate: 0.0039758]
	Learning Rate: 0.00397579
	LOSS [training: 0.12792800406550964 | validation: 0.13346650795669165]
	TIME [epoch: 33.2 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14604051001413726		[learning rate: 0.00396]
	Learning Rate: 0.00395997
	LOSS [training: 0.14604051001413726 | validation: 0.14995519320125067]
	TIME [epoch: 33.2 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1272475275423367		[learning rate: 0.0039442]
	Learning Rate: 0.00394422
	LOSS [training: 0.1272475275423367 | validation: 0.1435098733431996]
	TIME [epoch: 33.2 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13550213087119165		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.13550213087119165 | validation: 0.15333997366151605]
	TIME [epoch: 33.2 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14815725417784595		[learning rate: 0.0039129]
	Learning Rate: 0.00391291
	LOSS [training: 0.14815725417784595 | validation: 0.1318213495342851]
	TIME [epoch: 33.2 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12485045035337326		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.12485045035337326 | validation: 0.1467639719014256]
	TIME [epoch: 33.2 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13758463715171224		[learning rate: 0.0038818]
	Learning Rate: 0.00388185
	LOSS [training: 0.13758463715171224 | validation: 0.14398416569079517]
	TIME [epoch: 33.2 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13190304139611758		[learning rate: 0.0038664]
	Learning Rate: 0.00386641
	LOSS [training: 0.13190304139611758 | validation: 0.1427704982578383]
	TIME [epoch: 33.2 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12621127771249		[learning rate: 0.003851]
	Learning Rate: 0.00385103
	LOSS [training: 0.12621127771249 | validation: 0.14482952152253897]
	TIME [epoch: 33.2 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1323447994528349		[learning rate: 0.0038357]
	Learning Rate: 0.00383571
	LOSS [training: 0.1323447994528349 | validation: 0.1370696384826943]
	TIME [epoch: 33.2 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12988766557116221		[learning rate: 0.0038205]
	Learning Rate: 0.00382046
	LOSS [training: 0.12988766557116221 | validation: 0.14319519334868452]
	TIME [epoch: 33.2 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1278179339082179		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.1278179339082179 | validation: 0.13774383789725322]
	TIME [epoch: 33.2 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12258345872039074		[learning rate: 0.0037901]
	Learning Rate: 0.00379013
	LOSS [training: 0.12258345872039074 | validation: 0.1450483163989993]
	TIME [epoch: 33.2 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12622850651430195		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.12622850651430195 | validation: 0.14540161183037287]
	TIME [epoch: 33.2 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13486870899114503		[learning rate: 0.00376]
	Learning Rate: 0.00376004
	LOSS [training: 0.13486870899114503 | validation: 0.14874630231935013]
	TIME [epoch: 33.2 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1247384971581328		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.1247384971581328 | validation: 0.14942345147780817]
	TIME [epoch: 33.2 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12757392965229186		[learning rate: 0.0037302]
	Learning Rate: 0.00373019
	LOSS [training: 0.12757392965229186 | validation: 0.14262003254225225]
	TIME [epoch: 33.2 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11658048463961831		[learning rate: 0.0037154]
	Learning Rate: 0.00371535
	LOSS [training: 0.11658048463961831 | validation: 0.14011192984209525]
	TIME [epoch: 33.2 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13352680411588463		[learning rate: 0.0037006]
	Learning Rate: 0.00370058
	LOSS [training: 0.13352680411588463 | validation: 0.15124222888640002]
	TIME [epoch: 33.2 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12152127382718644		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.12152127382718644 | validation: 0.13997313889039661]
	TIME [epoch: 33.2 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1325674411531141		[learning rate: 0.0036712]
	Learning Rate: 0.0036712
	LOSS [training: 0.1325674411531141 | validation: 0.14320057069212438]
	TIME [epoch: 33.2 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12099853975856112		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 0.12099853975856112 | validation: 0.13288549664713706]
	TIME [epoch: 33.2 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12812319402385922		[learning rate: 0.0036421]
	Learning Rate: 0.00364205
	LOSS [training: 0.12812319402385922 | validation: 0.16148916573742325]
	TIME [epoch: 33.2 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12074361463095072		[learning rate: 0.0036276]
	Learning Rate: 0.00362757
	LOSS [training: 0.12074361463095072 | validation: 0.14064665386589317]
	TIME [epoch: 33.2 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1219646850156062		[learning rate: 0.0036131]
	Learning Rate: 0.00361314
	LOSS [training: 0.1219646850156062 | validation: 0.1440657188207611]
	TIME [epoch: 33.2 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12606733527282887		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.12606733527282887 | validation: 0.1466495845248242]
	TIME [epoch: 33.2 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13378767575986614		[learning rate: 0.0035845]
	Learning Rate: 0.00358445
	LOSS [training: 0.13378767575986614 | validation: 0.14249529591928708]
	TIME [epoch: 33.2 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12282645500929536		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.12282645500929536 | validation: 0.14002497036003353]
	TIME [epoch: 33.2 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12395919155849588		[learning rate: 0.003556]
	Learning Rate: 0.003556
	LOSS [training: 0.12395919155849588 | validation: 0.1396048134482689]
	TIME [epoch: 33.2 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12511114307413562		[learning rate: 0.0035419]
	Learning Rate: 0.00354185
	LOSS [training: 0.12511114307413562 | validation: 0.13973376494622175]
	TIME [epoch: 33.2 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11414172187964783		[learning rate: 0.0035278]
	Learning Rate: 0.00352777
	LOSS [training: 0.11414172187964783 | validation: 0.1462143382949083]
	TIME [epoch: 33.2 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13725024637967823		[learning rate: 0.0035137]
	Learning Rate: 0.00351374
	LOSS [training: 0.13725024637967823 | validation: 0.13820404526029573]
	TIME [epoch: 33.2 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12762084620175285		[learning rate: 0.0034998]
	Learning Rate: 0.00349976
	LOSS [training: 0.12762084620175285 | validation: 0.1458854156692308]
	TIME [epoch: 33.2 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12339377306848176		[learning rate: 0.0034858]
	Learning Rate: 0.00348584
	LOSS [training: 0.12339377306848176 | validation: 0.14792965785849668]
	TIME [epoch: 33.2 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12979486345513688		[learning rate: 0.003472]
	Learning Rate: 0.00347198
	LOSS [training: 0.12979486345513688 | validation: 0.14187280434052724]
	TIME [epoch: 33.2 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12386426666236594		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.12386426666236594 | validation: 0.1402481967215242]
	TIME [epoch: 33.2 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12534693149119777		[learning rate: 0.0034444]
	Learning Rate: 0.00344441
	LOSS [training: 0.12534693149119777 | validation: 0.13110309329260023]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_312.pth
	Model improved!!!
EPOCH 313/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13033399750042507		[learning rate: 0.0034307]
	Learning Rate: 0.00343071
	LOSS [training: 0.13033399750042507 | validation: 0.12953972520557672]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_313.pth
	Model improved!!!
EPOCH 314/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12528317538227782		[learning rate: 0.0034171]
	Learning Rate: 0.00341707
	LOSS [training: 0.12528317538227782 | validation: 0.1899510603023782]
	TIME [epoch: 33.2 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14633952348913265		[learning rate: 0.0034035]
	Learning Rate: 0.00340348
	LOSS [training: 0.14633952348913265 | validation: 0.13513393066616775]
	TIME [epoch: 33.2 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11945673717286454		[learning rate: 0.0033899]
	Learning Rate: 0.00338994
	LOSS [training: 0.11945673717286454 | validation: 0.14145095490944504]
	TIME [epoch: 33.2 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11389661786468364		[learning rate: 0.0033765]
	Learning Rate: 0.00337646
	LOSS [training: 0.11389661786468364 | validation: 0.14445854097732433]
	TIME [epoch: 33.2 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11371261265201306		[learning rate: 0.003363]
	Learning Rate: 0.00336303
	LOSS [training: 0.11371261265201306 | validation: 0.14076401844417846]
	TIME [epoch: 33.2 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14228898115946487		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.14228898115946487 | validation: 0.136732730274103]
	TIME [epoch: 33.2 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1293665002634664		[learning rate: 0.0033363]
	Learning Rate: 0.00333633
	LOSS [training: 0.1293665002634664 | validation: 0.1378496987219077]
	TIME [epoch: 33.2 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13135216543086436		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.13135216543086436 | validation: 0.13297706357595174]
	TIME [epoch: 33.2 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13607984851399307		[learning rate: 0.0033098]
	Learning Rate: 0.00330985
	LOSS [training: 0.13607984851399307 | validation: 0.14666780652685887]
	TIME [epoch: 33.2 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.119890589962423		[learning rate: 0.0032967]
	Learning Rate: 0.00329668
	LOSS [training: 0.119890589962423 | validation: 0.13807092845788138]
	TIME [epoch: 33.2 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1318723564026978		[learning rate: 0.0032836]
	Learning Rate: 0.00328357
	LOSS [training: 0.1318723564026978 | validation: 0.1600727338303148]
	TIME [epoch: 33.2 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13313062067753784		[learning rate: 0.0032705]
	Learning Rate: 0.00327051
	LOSS [training: 0.13313062067753784 | validation: 0.1447334865624773]
	TIME [epoch: 33.2 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12350808476832117		[learning rate: 0.0032575]
	Learning Rate: 0.0032575
	LOSS [training: 0.12350808476832117 | validation: 0.14225163890647238]
	TIME [epoch: 33.2 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13423350661303102		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.13423350661303102 | validation: 0.13591188807285276]
	TIME [epoch: 33.2 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12270747889517697		[learning rate: 0.0032316]
	Learning Rate: 0.00323164
	LOSS [training: 0.12270747889517697 | validation: 0.1394271138697687]
	TIME [epoch: 33.2 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11995048738850508		[learning rate: 0.0032188]
	Learning Rate: 0.00321879
	LOSS [training: 0.11995048738850508 | validation: 0.13795253417279696]
	TIME [epoch: 33.2 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11903104336640474		[learning rate: 0.003206]
	Learning Rate: 0.00320599
	LOSS [training: 0.11903104336640474 | validation: 0.13307135289044134]
	TIME [epoch: 33.2 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12459018649857957		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.12459018649857957 | validation: 0.13697882917592974]
	TIME [epoch: 33.2 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12932309372534623		[learning rate: 0.0031805]
	Learning Rate: 0.00318053
	LOSS [training: 0.12932309372534623 | validation: 0.14249289080518962]
	TIME [epoch: 33.2 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1259052770037318		[learning rate: 0.0031679]
	Learning Rate: 0.00316788
	LOSS [training: 0.1259052770037318 | validation: 0.14190246755733132]
	TIME [epoch: 33.2 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12814525680477412		[learning rate: 0.0031553]
	Learning Rate: 0.00315528
	LOSS [training: 0.12814525680477412 | validation: 0.14357866488579227]
	TIME [epoch: 33.2 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11928506643872705		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.11928506643872705 | validation: 0.1378237165474719]
	TIME [epoch: 33.2 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11840231307533612		[learning rate: 0.0031302]
	Learning Rate: 0.00313023
	LOSS [training: 0.11840231307533612 | validation: 0.14753993109015737]
	TIME [epoch: 33.2 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12925330219552797		[learning rate: 0.0031178]
	Learning Rate: 0.00311779
	LOSS [training: 0.12925330219552797 | validation: 0.14467627580261405]
	TIME [epoch: 33.2 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12489691678403075		[learning rate: 0.0031054]
	Learning Rate: 0.00310538
	LOSS [training: 0.12489691678403075 | validation: 0.142520426949081]
	TIME [epoch: 33.2 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13284547137209068		[learning rate: 0.003093]
	Learning Rate: 0.00309303
	LOSS [training: 0.13284547137209068 | validation: 0.13623237518022624]
	TIME [epoch: 33.2 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11246799824882119		[learning rate: 0.0030807]
	Learning Rate: 0.00308073
	LOSS [training: 0.11246799824882119 | validation: 0.14389743072139796]
	TIME [epoch: 33.2 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12094568749444717		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.12094568749444717 | validation: 0.1412568566044597]
	TIME [epoch: 33.2 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12293069293937532		[learning rate: 0.0030563]
	Learning Rate: 0.00305627
	LOSS [training: 0.12293069293937532 | validation: 0.14300245833136993]
	TIME [epoch: 33.2 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.125874996851414		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.125874996851414 | validation: 0.13759578998808233]
	TIME [epoch: 33.2 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12802189119594243		[learning rate: 0.003032]
	Learning Rate: 0.00303201
	LOSS [training: 0.12802189119594243 | validation: 0.13942992550765923]
	TIME [epoch: 33.2 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11878464980726006		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.11878464980726006 | validation: 0.1345089242559237]
	TIME [epoch: 33.2 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1282887514679848		[learning rate: 0.0030079]
	Learning Rate: 0.00300794
	LOSS [training: 0.1282887514679848 | validation: 0.14498362030794756]
	TIME [epoch: 33.2 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12676545345086354		[learning rate: 0.002996]
	Learning Rate: 0.00299598
	LOSS [training: 0.12676545345086354 | validation: 0.1335846451655475]
	TIME [epoch: 33.2 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12542243570932762		[learning rate: 0.0029841]
	Learning Rate: 0.00298406
	LOSS [training: 0.12542243570932762 | validation: 0.13175817777891163]
	TIME [epoch: 33.2 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11706052824628507		[learning rate: 0.0029722]
	Learning Rate: 0.00297219
	LOSS [training: 0.11706052824628507 | validation: 0.14047775178004382]
	TIME [epoch: 33.2 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12712330420234058		[learning rate: 0.0029604]
	Learning Rate: 0.00296037
	LOSS [training: 0.12712330420234058 | validation: 0.13582678705640677]
	TIME [epoch: 33.2 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1320937852091757		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.1320937852091757 | validation: 0.12971829606175983]
	TIME [epoch: 33.2 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12176470551365609		[learning rate: 0.0029369]
	Learning Rate: 0.00293687
	LOSS [training: 0.12176470551365609 | validation: 0.14028980867339963]
	TIME [epoch: 33.2 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11964575673296249		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.11964575673296249 | validation: 0.1299361018009725]
	TIME [epoch: 33.2 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12127361757396787		[learning rate: 0.0029136]
	Learning Rate: 0.00291355
	LOSS [training: 0.12127361757396787 | validation: 0.13825451430421]
	TIME [epoch: 33.2 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12776982458030037		[learning rate: 0.002902]
	Learning Rate: 0.00290197
	LOSS [training: 0.12776982458030037 | validation: 0.158568374648202]
	TIME [epoch: 33.2 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12863235687578672		[learning rate: 0.0028904]
	Learning Rate: 0.00289042
	LOSS [training: 0.12863235687578672 | validation: 0.14325471157761344]
	TIME [epoch: 33.2 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12011760947985767		[learning rate: 0.0028789]
	Learning Rate: 0.00287893
	LOSS [training: 0.12011760947985767 | validation: 0.14590411715738666]
	TIME [epoch: 33.2 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1254704043981362		[learning rate: 0.0028675]
	Learning Rate: 0.00286748
	LOSS [training: 0.1254704043981362 | validation: 0.131699393932862]
	TIME [epoch: 33.2 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1160841901752457		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.1160841901752457 | validation: 0.142184637492733]
	TIME [epoch: 33.2 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1303289626350445		[learning rate: 0.0028447]
	Learning Rate: 0.00284471
	LOSS [training: 0.1303289626350445 | validation: 0.1283486162150916]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_360.pth
	Model improved!!!
EPOCH 361/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13127026362069305		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.13127026362069305 | validation: 0.134254775416173]
	TIME [epoch: 33.2 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11845184045057261		[learning rate: 0.0028221]
	Learning Rate: 0.00282213
	LOSS [training: 0.11845184045057261 | validation: 0.13035575237852917]
	TIME [epoch: 33.2 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1229586837841097		[learning rate: 0.0028109]
	Learning Rate: 0.00281091
	LOSS [training: 0.1229586837841097 | validation: 0.1394186655153417]
	TIME [epoch: 33.2 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12235158653843284		[learning rate: 0.0027997]
	Learning Rate: 0.00279973
	LOSS [training: 0.12235158653843284 | validation: 0.12788814146452504]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_364.pth
	Model improved!!!
EPOCH 365/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12090517392396263		[learning rate: 0.0027886]
	Learning Rate: 0.00278859
	LOSS [training: 0.12090517392396263 | validation: 0.13469614977459976]
	TIME [epoch: 33.2 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11642663366047855		[learning rate: 0.0027775]
	Learning Rate: 0.0027775
	LOSS [training: 0.11642663366047855 | validation: 0.12649981964931808]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_366.pth
	Model improved!!!
EPOCH 367/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11878228547940196		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.11878228547940196 | validation: 0.1361324663593118]
	TIME [epoch: 33.2 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12358564446139196		[learning rate: 0.0027554]
	Learning Rate: 0.00275545
	LOSS [training: 0.12358564446139196 | validation: 0.13211270359726843]
	TIME [epoch: 33.2 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11901905586734202		[learning rate: 0.0027445]
	Learning Rate: 0.00274449
	LOSS [training: 0.11901905586734202 | validation: 0.13443912606565822]
	TIME [epoch: 33.2 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12147056875871047		[learning rate: 0.0027336]
	Learning Rate: 0.00273357
	LOSS [training: 0.12147056875871047 | validation: 0.14059203461474218]
	TIME [epoch: 33.2 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12015963223270454		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.12015963223270454 | validation: 0.1377170169798456]
	TIME [epoch: 33.2 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12323961911463627		[learning rate: 0.0027119]
	Learning Rate: 0.00271187
	LOSS [training: 0.12323961911463627 | validation: 0.13623308770517178]
	TIME [epoch: 33.2 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12264635310590546		[learning rate: 0.0027011]
	Learning Rate: 0.00270109
	LOSS [training: 0.12264635310590546 | validation: 0.14547931688686846]
	TIME [epoch: 33.2 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12262203942969815		[learning rate: 0.0026903]
	Learning Rate: 0.00269034
	LOSS [training: 0.12262203942969815 | validation: 0.1384317961314862]
	TIME [epoch: 33.2 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12457263334148218		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.12457263334148218 | validation: 0.1437111321572042]
	TIME [epoch: 33.2 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12965324879516985		[learning rate: 0.002669]
	Learning Rate: 0.00266899
	LOSS [training: 0.12965324879516985 | validation: 0.14914468634965464]
	TIME [epoch: 33.2 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12508232765064367		[learning rate: 0.0026584]
	Learning Rate: 0.00265837
	LOSS [training: 0.12508232765064367 | validation: 0.1447513788988442]
	TIME [epoch: 33.2 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12353725536397417		[learning rate: 0.0026478]
	Learning Rate: 0.0026478
	LOSS [training: 0.12353725536397417 | validation: 0.12941839305020336]
	TIME [epoch: 33.2 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12783734270084038		[learning rate: 0.0026373]
	Learning Rate: 0.00263727
	LOSS [training: 0.12783734270084038 | validation: 0.13439532296320755]
	TIME [epoch: 33.2 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12130468215179475		[learning rate: 0.0026268]
	Learning Rate: 0.00262678
	LOSS [training: 0.12130468215179475 | validation: 0.13389297857291738]
	TIME [epoch: 33.2 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11909770092233657		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.11909770092233657 | validation: 0.13654081955600397]
	TIME [epoch: 33.2 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12140088369205865		[learning rate: 0.0026059]
	Learning Rate: 0.00260592
	LOSS [training: 0.12140088369205865 | validation: 0.13347294385738354]
	TIME [epoch: 33.2 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12559439200019698		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.12559439200019698 | validation: 0.1326247306290562]
	TIME [epoch: 33.2 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13456740661648878		[learning rate: 0.0025852]
	Learning Rate: 0.00258523
	LOSS [training: 0.13456740661648878 | validation: 0.13143926584186463]
	TIME [epoch: 33.2 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11783734339588986		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.11783734339588986 | validation: 0.15088128691750974]
	TIME [epoch: 33.2 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1295832841722962		[learning rate: 0.0025647]
	Learning Rate: 0.00256471
	LOSS [training: 0.1295832841722962 | validation: 0.14323058858595294]
	TIME [epoch: 33.2 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11969102179169146		[learning rate: 0.0025545]
	Learning Rate: 0.00255451
	LOSS [training: 0.11969102179169146 | validation: 0.14268064260954455]
	TIME [epoch: 33.2 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12378620966324277		[learning rate: 0.0025444]
	Learning Rate: 0.00254435
	LOSS [training: 0.12378620966324277 | validation: 0.12816972828155138]
	TIME [epoch: 33.2 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1179239001833596		[learning rate: 0.0025342]
	Learning Rate: 0.00253423
	LOSS [training: 0.1179239001833596 | validation: 0.13785407807228905]
	TIME [epoch: 33.2 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11909884042288062		[learning rate: 0.0025242]
	Learning Rate: 0.00252415
	LOSS [training: 0.11909884042288062 | validation: 0.14761612989058212]
	TIME [epoch: 33.2 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12225054776421522		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.12225054776421522 | validation: 0.12918811764343535]
	TIME [epoch: 33.2 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12068631685574914		[learning rate: 0.0025041]
	Learning Rate: 0.00250411
	LOSS [training: 0.12068631685574914 | validation: 0.12755771539283886]
	TIME [epoch: 33.2 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12230262539949804		[learning rate: 0.0024942]
	Learning Rate: 0.00249415
	LOSS [training: 0.12230262539949804 | validation: 0.1365490763795148]
	TIME [epoch: 33.2 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11784968134176434		[learning rate: 0.0024842]
	Learning Rate: 0.00248423
	LOSS [training: 0.11784968134176434 | validation: 0.13065621846079709]
	TIME [epoch: 33.2 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12238284357171564		[learning rate: 0.0024744]
	Learning Rate: 0.00247435
	LOSS [training: 0.12238284357171564 | validation: 0.1353030346653293]
	TIME [epoch: 33.2 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12216803192501244		[learning rate: 0.0024645]
	Learning Rate: 0.00246451
	LOSS [training: 0.12216803192501244 | validation: 0.1372006891690984]
	TIME [epoch: 33.2 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12642613597142427		[learning rate: 0.0024547]
	Learning Rate: 0.00245471
	LOSS [training: 0.12642613597142427 | validation: 0.12984510237631375]
	TIME [epoch: 33.2 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12003976371225497		[learning rate: 0.0024449]
	Learning Rate: 0.00244495
	LOSS [training: 0.12003976371225497 | validation: 0.1407334891195379]
	TIME [epoch: 33.2 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11543760054204458		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.11543760054204458 | validation: 0.13514260208223797]
	TIME [epoch: 33.2 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12588384570103264		[learning rate: 0.0024255]
	Learning Rate: 0.00242554
	LOSS [training: 0.12588384570103264 | validation: 0.13248769792302725]
	TIME [epoch: 33.2 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13235358593229582		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.13235358593229582 | validation: 0.1373921644555029]
	TIME [epoch: 33.2 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12781966859137894		[learning rate: 0.0024063]
	Learning Rate: 0.00240628
	LOSS [training: 0.12781966859137894 | validation: 0.12942396173394594]
	TIME [epoch: 33.2 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12048532510273005		[learning rate: 0.0023967]
	Learning Rate: 0.00239671
	LOSS [training: 0.12048532510273005 | validation: 0.13578412433144565]
	TIME [epoch: 33.2 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1179124257148918		[learning rate: 0.0023872]
	Learning Rate: 0.00238718
	LOSS [training: 0.1179124257148918 | validation: 0.1347601035245831]
	TIME [epoch: 33.2 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11871633227554125		[learning rate: 0.0023777]
	Learning Rate: 0.00237768
	LOSS [training: 0.11871633227554125 | validation: 0.14200646047123439]
	TIME [epoch: 33.2 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12230313803948054		[learning rate: 0.0023682]
	Learning Rate: 0.00236823
	LOSS [training: 0.12230313803948054 | validation: 0.13552453724608582]
	TIME [epoch: 33.2 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12081998622574604		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.12081998622574604 | validation: 0.13367628389299407]
	TIME [epoch: 33.2 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1200950165485589		[learning rate: 0.0023494]
	Learning Rate: 0.00234942
	LOSS [training: 0.1200950165485589 | validation: 0.13433084860764266]
	TIME [epoch: 33.2 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1276441513325759		[learning rate: 0.0023401]
	Learning Rate: 0.00234008
	LOSS [training: 0.1276441513325759 | validation: 0.13449623079399006]
	TIME [epoch: 33.1 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11191203296806007		[learning rate: 0.0023308]
	Learning Rate: 0.00233077
	LOSS [training: 0.11191203296806007 | validation: 0.12992153303873016]
	TIME [epoch: 33 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11461265877481545		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.11461265877481545 | validation: 0.13551781484411304]
	TIME [epoch: 33.1 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11690961553601609		[learning rate: 0.0023123]
	Learning Rate: 0.00231227
	LOSS [training: 0.11690961553601609 | validation: 0.14249471667625607]
	TIME [epoch: 33 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12467486655143352		[learning rate: 0.0023031]
	Learning Rate: 0.00230307
	LOSS [training: 0.12467486655143352 | validation: 0.13148110916690636]
	TIME [epoch: 32.9 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1214088461573984		[learning rate: 0.0022939]
	Learning Rate: 0.00229391
	LOSS [training: 0.1214088461573984 | validation: 0.12871023924178446]
	TIME [epoch: 32.9 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12491031189387429		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.12491031189387429 | validation: 0.14041213615071751]
	TIME [epoch: 32.9 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11550029218917067		[learning rate: 0.0022757]
	Learning Rate: 0.0022757
	LOSS [training: 0.11550029218917067 | validation: 0.15364765054407248]
	TIME [epoch: 32.9 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1116412077268089		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.1116412077268089 | validation: 0.1341171469190149]
	TIME [epoch: 32.9 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12054160519482979		[learning rate: 0.0022576]
	Learning Rate: 0.00225764
	LOSS [training: 0.12054160519482979 | validation: 0.14677551312074155]
	TIME [epoch: 32.7 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1266021660800115		[learning rate: 0.0022487]
	Learning Rate: 0.00224866
	LOSS [training: 0.1266021660800115 | validation: 0.1309648464211605]
	TIME [epoch: 32.8 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11427463300787785		[learning rate: 0.0022397]
	Learning Rate: 0.00223971
	LOSS [training: 0.11427463300787785 | validation: 0.15514901734354725]
	TIME [epoch: 32.8 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13129424318504887		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.13129424318504887 | validation: 0.13699399792742284]
	TIME [epoch: 32.7 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12335924428656561		[learning rate: 0.0022219]
	Learning Rate: 0.00222193
	LOSS [training: 0.12335924428656561 | validation: 0.1454615490870341]
	TIME [epoch: 32.8 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12313711067291133		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.12313711067291133 | validation: 0.13362014344263032]
	TIME [epoch: 32.7 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11816905858655691		[learning rate: 0.0022043]
	Learning Rate: 0.00220429
	LOSS [training: 0.11816905858655691 | validation: 0.13444221955570948]
	TIME [epoch: 32.8 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11945049006840229		[learning rate: 0.0021955]
	Learning Rate: 0.00219553
	LOSS [training: 0.11945049006840229 | validation: 0.14009917221035323]
	TIME [epoch: 32.7 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12010614508233242		[learning rate: 0.0021868]
	Learning Rate: 0.00218679
	LOSS [training: 0.12010614508233242 | validation: 0.1345152399654518]
	TIME [epoch: 32.7 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11283992059626706		[learning rate: 0.0021781]
	Learning Rate: 0.0021781
	LOSS [training: 0.11283992059626706 | validation: 0.1356244878334952]
	TIME [epoch: 32.7 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12583769796750166		[learning rate: 0.0021694]
	Learning Rate: 0.00216943
	LOSS [training: 0.12583769796750166 | validation: 0.13431937464839688]
	TIME [epoch: 32.8 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11897707808488252		[learning rate: 0.0021608]
	Learning Rate: 0.0021608
	LOSS [training: 0.11897707808488252 | validation: 0.13655925298602248]
	TIME [epoch: 32.7 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1312528956317104		[learning rate: 0.0021522]
	Learning Rate: 0.00215221
	LOSS [training: 0.1312528956317104 | validation: 0.1312873698022684]
	TIME [epoch: 32.7 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12634257524560535		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.12634257524560535 | validation: 0.14121526364651465]
	TIME [epoch: 32.7 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13757221542024628		[learning rate: 0.0021351]
	Learning Rate: 0.00213512
	LOSS [training: 0.13757221542024628 | validation: 0.1423800369176136]
	TIME [epoch: 32.7 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12586558094283426		[learning rate: 0.0021266]
	Learning Rate: 0.00212663
	LOSS [training: 0.12586558094283426 | validation: 0.12900262960065498]
	TIME [epoch: 32.8 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12889710342983268		[learning rate: 0.0021182]
	Learning Rate: 0.00211817
	LOSS [training: 0.12889710342983268 | validation: 0.15075033676279959]
	TIME [epoch: 32.7 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1296037954231178		[learning rate: 0.0021097]
	Learning Rate: 0.00210975
	LOSS [training: 0.1296037954231178 | validation: 0.1342622838549984]
	TIME [epoch: 32.8 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11521866486080315		[learning rate: 0.0021014]
	Learning Rate: 0.00210136
	LOSS [training: 0.11521866486080315 | validation: 0.1438866226288022]
	TIME [epoch: 32.7 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11743130513503876		[learning rate: 0.002093]
	Learning Rate: 0.002093
	LOSS [training: 0.11743130513503876 | validation: 0.1426150123470698]
	TIME [epoch: 32.8 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11815654716084951		[learning rate: 0.0020847]
	Learning Rate: 0.00208468
	LOSS [training: 0.11815654716084951 | validation: 0.12876533330241488]
	TIME [epoch: 32.8 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11822679257022085		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.11822679257022085 | validation: 0.13711482952524673]
	TIME [epoch: 32.7 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11797362222717912		[learning rate: 0.0020681]
	Learning Rate: 0.00206813
	LOSS [training: 0.11797362222717912 | validation: 0.13809208160727549]
	TIME [epoch: 32.8 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12434247013821584		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.12434247013821584 | validation: 0.13822848867211462]
	TIME [epoch: 32.7 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1266668210567446		[learning rate: 0.0020517]
	Learning Rate: 0.00205171
	LOSS [training: 0.1266668210567446 | validation: 0.1361129481979246]
	TIME [epoch: 32.7 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1191441271885916		[learning rate: 0.0020435]
	Learning Rate: 0.00204355
	LOSS [training: 0.1191441271885916 | validation: 0.1384509159077411]
	TIME [epoch: 32.8 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12378780380726766		[learning rate: 0.0020354]
	Learning Rate: 0.00203542
	LOSS [training: 0.12378780380726766 | validation: 0.1309559990706095]
	TIME [epoch: 32.8 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1147389824280664		[learning rate: 0.0020273]
	Learning Rate: 0.00202732
	LOSS [training: 0.1147389824280664 | validation: 0.13299627578321677]
	TIME [epoch: 32.7 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11457836101061981		[learning rate: 0.0020193]
	Learning Rate: 0.00201926
	LOSS [training: 0.11457836101061981 | validation: 0.12718516976275632]
	TIME [epoch: 32.7 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1172177711329774		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.1172177711329774 | validation: 0.14010009593468672]
	TIME [epoch: 32.7 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1185518541544775		[learning rate: 0.0020032]
	Learning Rate: 0.00200323
	LOSS [training: 0.1185518541544775 | validation: 0.12871649287352965]
	TIME [epoch: 32.7 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11573194602667708		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.11573194602667708 | validation: 0.13103772225304713]
	TIME [epoch: 32.7 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1160274278098006		[learning rate: 0.0019873]
	Learning Rate: 0.00198733
	LOSS [training: 0.1160274278098006 | validation: 0.14361177327693886]
	TIME [epoch: 32.7 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11918397268700745		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.11918397268700745 | validation: 0.13378520322127477]
	TIME [epoch: 32.8 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12103559356545111		[learning rate: 0.0019715]
	Learning Rate: 0.00197155
	LOSS [training: 0.12103559356545111 | validation: 0.13030770527691166]
	TIME [epoch: 32.7 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11395371280090763		[learning rate: 0.0019637]
	Learning Rate: 0.00196371
	LOSS [training: 0.11395371280090763 | validation: 0.13132148510126873]
	TIME [epoch: 32.7 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11767558325019367		[learning rate: 0.0019559]
	Learning Rate: 0.0019559
	LOSS [training: 0.11767558325019367 | validation: 0.1291745444841408]
	TIME [epoch: 32.7 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12215852810319151		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.12215852810319151 | validation: 0.1350511812640675]
	TIME [epoch: 32.8 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12332014342371814		[learning rate: 0.0019404]
	Learning Rate: 0.00194037
	LOSS [training: 0.12332014342371814 | validation: 0.15439702631873348]
	TIME [epoch: 32.7 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12614609393276643		[learning rate: 0.0019327]
	Learning Rate: 0.00193265
	LOSS [training: 0.12614609393276643 | validation: 0.1312833051750839]
	TIME [epoch: 32.7 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1152030799197401		[learning rate: 0.001925]
	Learning Rate: 0.00192497
	LOSS [training: 0.1152030799197401 | validation: 0.13059787082704705]
	TIME [epoch: 32.7 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12035567182161151		[learning rate: 0.0019173]
	Learning Rate: 0.00191731
	LOSS [training: 0.12035567182161151 | validation: 0.1407300866413969]
	TIME [epoch: 32.7 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11669118961053865		[learning rate: 0.0019097]
	Learning Rate: 0.00190968
	LOSS [training: 0.11669118961053865 | validation: 0.13107887346335131]
	TIME [epoch: 32.7 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11501144169136397		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.11501144169136397 | validation: 0.13310507023163037]
	TIME [epoch: 32.7 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12527074909555877		[learning rate: 0.0018945]
	Learning Rate: 0.00189452
	LOSS [training: 0.12527074909555877 | validation: 0.14932436103456725]
	TIME [epoch: 32.8 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12159730929067449		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.12159730929067449 | validation: 0.13813327810435982]
	TIME [epoch: 32.7 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11326349287735134		[learning rate: 0.0018795]
	Learning Rate: 0.00187948
	LOSS [training: 0.11326349287735134 | validation: 0.13823027161985627]
	TIME [epoch: 32.7 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12054817693147656		[learning rate: 0.001872]
	Learning Rate: 0.00187201
	LOSS [training: 0.12054817693147656 | validation: 0.12942647028787008]
	TIME [epoch: 32.7 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11201545121831841		[learning rate: 0.0018646]
	Learning Rate: 0.00186456
	LOSS [training: 0.11201545121831841 | validation: 0.13085527064493982]
	TIME [epoch: 32.8 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11885974117691805		[learning rate: 0.0018571]
	Learning Rate: 0.00185715
	LOSS [training: 0.11885974117691805 | validation: 0.1339444243504785]
	TIME [epoch: 32.8 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12020215666677897		[learning rate: 0.0018498]
	Learning Rate: 0.00184976
	LOSS [training: 0.12020215666677897 | validation: 0.1470681931817171]
	TIME [epoch: 32.8 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12130632630472135		[learning rate: 0.0018424]
	Learning Rate: 0.0018424
	LOSS [training: 0.12130632630472135 | validation: 0.1334418167034718]
	TIME [epoch: 32.8 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.120079672389022		[learning rate: 0.0018351]
	Learning Rate: 0.00183508
	LOSS [training: 0.120079672389022 | validation: 0.1377314603893051]
	TIME [epoch: 32.7 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12275116430059997		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.12275116430059997 | validation: 0.1411144479081817]
	TIME [epoch: 32.7 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12174705047997447		[learning rate: 0.0018205]
	Learning Rate: 0.00182051
	LOSS [training: 0.12174705047997447 | validation: 0.13296729572181243]
	TIME [epoch: 32.7 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1117953259239573		[learning rate: 0.0018133]
	Learning Rate: 0.00181327
	LOSS [training: 0.1117953259239573 | validation: 0.1384846095784878]
	TIME [epoch: 32.7 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12064799541128599		[learning rate: 0.0018061]
	Learning Rate: 0.00180605
	LOSS [training: 0.12064799541128599 | validation: 0.1391568510600429]
	TIME [epoch: 32.7 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12284480769817605		[learning rate: 0.0017989]
	Learning Rate: 0.00179887
	LOSS [training: 0.12284480769817605 | validation: 0.1249675890420189]
	TIME [epoch: 32.7 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_475.pth
	Model improved!!!
EPOCH 476/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11398663686637447		[learning rate: 0.0017917]
	Learning Rate: 0.00179172
	LOSS [training: 0.11398663686637447 | validation: 0.1287788350151049]
	TIME [epoch: 32.7 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1192876207325819		[learning rate: 0.0017846]
	Learning Rate: 0.00178459
	LOSS [training: 0.1192876207325819 | validation: 0.14123819840153154]
	TIME [epoch: 32.8 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11355597480721236		[learning rate: 0.0017775]
	Learning Rate: 0.00177749
	LOSS [training: 0.11355597480721236 | validation: 0.13033077171982146]
	TIME [epoch: 32.7 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.122990957772824		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.122990957772824 | validation: 0.14115421858406882]
	TIME [epoch: 32.7 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11996034052323536		[learning rate: 0.0017634]
	Learning Rate: 0.00176338
	LOSS [training: 0.11996034052323536 | validation: 0.13628280832931874]
	TIME [epoch: 32.7 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11526228758092971		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.11526228758092971 | validation: 0.13061817333077066]
	TIME [epoch: 32.7 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11722159189961065		[learning rate: 0.0017494]
	Learning Rate: 0.00174938
	LOSS [training: 0.11722159189961065 | validation: 0.14287995023795208]
	TIME [epoch: 32.8 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11643877008356197		[learning rate: 0.0017424]
	Learning Rate: 0.00174242
	LOSS [training: 0.11643877008356197 | validation: 0.1450028184719921]
	TIME [epoch: 32.7 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11955359836338172		[learning rate: 0.0017355]
	Learning Rate: 0.00173549
	LOSS [training: 0.11955359836338172 | validation: 0.13745202929054545]
	TIME [epoch: 32.8 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1309588742704283		[learning rate: 0.0017286]
	Learning Rate: 0.00172859
	LOSS [training: 0.1309588742704283 | validation: 0.13698520773391126]
	TIME [epoch: 32.8 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11880987298790852		[learning rate: 0.0017217]
	Learning Rate: 0.00172172
	LOSS [training: 0.11880987298790852 | validation: 0.13646216389437957]
	TIME [epoch: 32.8 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10939563055969677		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.10939563055969677 | validation: 0.1313244359665287]
	TIME [epoch: 32.8 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11836539164851399		[learning rate: 0.001708]
	Learning Rate: 0.00170805
	LOSS [training: 0.11836539164851399 | validation: 0.13424302975224373]
	TIME [epoch: 32.8 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12778298682064226		[learning rate: 0.0017013]
	Learning Rate: 0.00170125
	LOSS [training: 0.12778298682064226 | validation: 0.1390987833929438]
	TIME [epoch: 32.7 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11667685048069461		[learning rate: 0.0016945]
	Learning Rate: 0.00169449
	LOSS [training: 0.11667685048069461 | validation: 0.12522912796111718]
	TIME [epoch: 32.7 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12287024678428166		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.12287024678428166 | validation: 0.13017277436201885]
	TIME [epoch: 32.7 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11154863258328208		[learning rate: 0.001681]
	Learning Rate: 0.00168104
	LOSS [training: 0.11154863258328208 | validation: 0.13919495522325515]
	TIME [epoch: 32.8 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11454804948140805		[learning rate: 0.0016743]
	Learning Rate: 0.00167435
	LOSS [training: 0.11454804948140805 | validation: 0.1331049752981234]
	TIME [epoch: 32.7 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11441171203741492		[learning rate: 0.0016677]
	Learning Rate: 0.00166769
	LOSS [training: 0.11441171203741492 | validation: 0.13599344945629238]
	TIME [epoch: 32.7 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1284789488524845		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.1284789488524845 | validation: 0.14366126506331456]
	TIME [epoch: 32.8 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1145689137732902		[learning rate: 0.0016545]
	Learning Rate: 0.00165445
	LOSS [training: 0.1145689137732902 | validation: 0.13490026283004458]
	TIME [epoch: 32.8 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10999536640541598		[learning rate: 0.0016479]
	Learning Rate: 0.00164787
	LOSS [training: 0.10999536640541598 | validation: 0.14332644352098683]
	TIME [epoch: 32.7 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12047383452588717		[learning rate: 0.0016413]
	Learning Rate: 0.00164132
	LOSS [training: 0.12047383452588717 | validation: 0.136626426499926]
	TIME [epoch: 32.7 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1184083271278216		[learning rate: 0.0016348]
	Learning Rate: 0.00163479
	LOSS [training: 0.1184083271278216 | validation: 0.1301750619360388]
	TIME [epoch: 32.8 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11429262060484807		[learning rate: 0.0016283]
	Learning Rate: 0.00162829
	LOSS [training: 0.11429262060484807 | validation: 0.13339747485397335]
	TIME [epoch: 32.7 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11278943443588789		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.11278943443588789 | validation: 0.1212572732916137]
	TIME [epoch: 32.7 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_501.pth
	Model improved!!!
EPOCH 502/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11096380938464187		[learning rate: 0.0016154]
	Learning Rate: 0.00161536
	LOSS [training: 0.11096380938464187 | validation: 0.13359414481739346]
	TIME [epoch: 32.8 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11495391420501987		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.11495391420501987 | validation: 0.12440743602172541]
	TIME [epoch: 32.8 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12177448866730092		[learning rate: 0.0016025]
	Learning Rate: 0.00160254
	LOSS [training: 0.12177448866730092 | validation: 0.14249879841975838]
	TIME [epoch: 32.7 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12163065516144354		[learning rate: 0.0015962]
	Learning Rate: 0.00159616
	LOSS [training: 0.12163065516144354 | validation: 0.132241652135092]
	TIME [epoch: 32.7 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11314498882266572		[learning rate: 0.0015898]
	Learning Rate: 0.00158981
	LOSS [training: 0.11314498882266572 | validation: 0.1324192222057347]
	TIME [epoch: 32.8 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1252299275123297		[learning rate: 0.0015835]
	Learning Rate: 0.00158349
	LOSS [training: 0.1252299275123297 | validation: 0.13755314206852906]
	TIME [epoch: 32.7 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11108926440352224		[learning rate: 0.0015772]
	Learning Rate: 0.00157719
	LOSS [training: 0.11108926440352224 | validation: 0.12826018679549137]
	TIME [epoch: 32.7 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11472897538636989		[learning rate: 0.0015709]
	Learning Rate: 0.00157092
	LOSS [training: 0.11472897538636989 | validation: 0.12450694043588521]
	TIME [epoch: 32.7 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12020332219919921		[learning rate: 0.0015647]
	Learning Rate: 0.00156467
	LOSS [training: 0.12020332219919921 | validation: 0.138269122955643]
	TIME [epoch: 32.8 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12520534177455808		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.12520534177455808 | validation: 0.13428904130902963]
	TIME [epoch: 32.7 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11664225440795256		[learning rate: 0.0015522]
	Learning Rate: 0.00155225
	LOSS [training: 0.11664225440795256 | validation: 0.13284676524641537]
	TIME [epoch: 32.8 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12104397078156616		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.12104397078156616 | validation: 0.1303933454191333]
	TIME [epoch: 32.7 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12237186754717783		[learning rate: 0.0015399]
	Learning Rate: 0.00153993
	LOSS [training: 0.12237186754717783 | validation: 0.14101218112571]
	TIME [epoch: 32.7 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1282657221107627		[learning rate: 0.0015338]
	Learning Rate: 0.0015338
	LOSS [training: 0.1282657221107627 | validation: 0.12982956786369054]
	TIME [epoch: 32.7 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11477160162632351		[learning rate: 0.0015277]
	Learning Rate: 0.0015277
	LOSS [training: 0.11477160162632351 | validation: 0.13845454950906833]
	TIME [epoch: 32.7 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11406779065531358		[learning rate: 0.0015216]
	Learning Rate: 0.00152163
	LOSS [training: 0.11406779065531358 | validation: 0.12731893352404097]
	TIME [epoch: 32.7 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11889814442629137		[learning rate: 0.0015156]
	Learning Rate: 0.00151557
	LOSS [training: 0.11889814442629137 | validation: 0.13947911214882308]
	TIME [epoch: 32.8 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11793014746746915		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.11793014746746915 | validation: 0.1256321553647555]
	TIME [epoch: 32.7 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11354001467938181		[learning rate: 0.0015035]
	Learning Rate: 0.00150354
	LOSS [training: 0.11354001467938181 | validation: 0.13090979224112176]
	TIME [epoch: 32.7 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1141296315487977		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.1141296315487977 | validation: 0.14121253270492817]
	TIME [epoch: 32.7 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1128983603951142		[learning rate: 0.0014916]
	Learning Rate: 0.00149161
	LOSS [training: 0.1128983603951142 | validation: 0.14054389981123977]
	TIME [epoch: 32.7 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11099897922515392		[learning rate: 0.0014857]
	Learning Rate: 0.00148567
	LOSS [training: 0.11099897922515392 | validation: 0.13722295635141557]
	TIME [epoch: 32.7 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11618830150868337		[learning rate: 0.0014798]
	Learning Rate: 0.00147976
	LOSS [training: 0.11618830150868337 | validation: 0.12587845162774944]
	TIME [epoch: 32.7 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11627299426083576		[learning rate: 0.0014739]
	Learning Rate: 0.00147388
	LOSS [training: 0.11627299426083576 | validation: 0.13494365576776063]
	TIME [epoch: 32.7 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11478452464882793		[learning rate: 0.001468]
	Learning Rate: 0.00146802
	LOSS [training: 0.11478452464882793 | validation: 0.14572527373439023]
	TIME [epoch: 32.7 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11788344655876415		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.11788344655876415 | validation: 0.12807429427315206]
	TIME [epoch: 32.6 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11502103872454159		[learning rate: 0.0014564]
	Learning Rate: 0.00145636
	LOSS [training: 0.11502103872454159 | validation: 0.13175731416047654]
	TIME [epoch: 32.7 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11777544690753755		[learning rate: 0.0014506]
	Learning Rate: 0.00145057
	LOSS [training: 0.11777544690753755 | validation: 0.1234521440938613]
	TIME [epoch: 32.6 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12661552228959425		[learning rate: 0.0014448]
	Learning Rate: 0.0014448
	LOSS [training: 0.12661552228959425 | validation: 0.131767709037603]
	TIME [epoch: 32.6 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12434356668205401		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.12434356668205401 | validation: 0.13781578927177204]
	TIME [epoch: 32.6 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11575183676876967		[learning rate: 0.0014333]
	Learning Rate: 0.00143333
	LOSS [training: 0.11575183676876967 | validation: 0.13146250686477326]
	TIME [epoch: 32.7 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11738722803147411		[learning rate: 0.0014276]
	Learning Rate: 0.00142763
	LOSS [training: 0.11738722803147411 | validation: 0.13703731691465917]
	TIME [epoch: 32.6 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11452229850190546		[learning rate: 0.001422]
	Learning Rate: 0.00142195
	LOSS [training: 0.11452229850190546 | validation: 0.1312856118777353]
	TIME [epoch: 32.7 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11462926548696355		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.11462926548696355 | validation: 0.13178537703990006]
	TIME [epoch: 32.6 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1142213776233561		[learning rate: 0.0014107]
	Learning Rate: 0.00141066
	LOSS [training: 0.1142213776233561 | validation: 0.13604250069788212]
	TIME [epoch: 32.7 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10937687440533926		[learning rate: 0.0014051]
	Learning Rate: 0.00140505
	LOSS [training: 0.10937687440533926 | validation: 0.13220448915018104]
	TIME [epoch: 32.6 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1196279131738983		[learning rate: 0.0013995]
	Learning Rate: 0.00139946
	LOSS [training: 0.1196279131738983 | validation: 0.13111376220934354]
	TIME [epoch: 32.7 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12510003361225885		[learning rate: 0.0013939]
	Learning Rate: 0.0013939
	LOSS [training: 0.12510003361225885 | validation: 0.1301262879523398]
	TIME [epoch: 32.7 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12184239122029594		[learning rate: 0.0013884]
	Learning Rate: 0.00138835
	LOSS [training: 0.12184239122029594 | validation: 0.12948274508314597]
	TIME [epoch: 32.7 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11730871514257046		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.11730871514257046 | validation: 0.12305853111995475]
	TIME [epoch: 32.7 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12050107471868819		[learning rate: 0.0013773]
	Learning Rate: 0.00137733
	LOSS [training: 0.12050107471868819 | validation: 0.13118486565501902]
	TIME [epoch: 32.7 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11755322311050935		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.11755322311050935 | validation: 0.12977511841062533]
	TIME [epoch: 32.8 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12060466985731708		[learning rate: 0.0013664]
	Learning Rate: 0.0013664
	LOSS [training: 0.12060466985731708 | validation: 0.12994327171228703]
	TIME [epoch: 32.7 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1295574159125469		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.1295574159125469 | validation: 0.13728972012232835]
	TIME [epoch: 32.7 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13063393857758562		[learning rate: 0.0013555]
	Learning Rate: 0.00135555
	LOSS [training: 0.13063393857758562 | validation: 0.1270059116026995]
	TIME [epoch: 32.7 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1106522203784467		[learning rate: 0.0013502]
	Learning Rate: 0.00135016
	LOSS [training: 0.1106522203784467 | validation: 0.13586804293430887]
	TIME [epoch: 32.7 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11208497634747872		[learning rate: 0.0013448]
	Learning Rate: 0.00134479
	LOSS [training: 0.11208497634747872 | validation: 0.13123571949950558]
	TIME [epoch: 32.7 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12082617619665946		[learning rate: 0.0013394]
	Learning Rate: 0.00133944
	LOSS [training: 0.12082617619665946 | validation: 0.13066249915146944]
	TIME [epoch: 32.6 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11295559348255006		[learning rate: 0.0013341]
	Learning Rate: 0.00133411
	LOSS [training: 0.11295559348255006 | validation: 0.129724899576858]
	TIME [epoch: 32.7 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11347149357095485		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.11347149357095485 | validation: 0.12464894005951573]
	TIME [epoch: 32.7 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11645644354812755		[learning rate: 0.0013235]
	Learning Rate: 0.00132352
	LOSS [training: 0.11645644354812755 | validation: 0.132986669087219]
	TIME [epoch: 32.7 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11907250968472119		[learning rate: 0.0013183]
	Learning Rate: 0.00131826
	LOSS [training: 0.11907250968472119 | validation: 0.13087028548229687]
	TIME [epoch: 32.6 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11281778238301923		[learning rate: 0.001313]
	Learning Rate: 0.00131301
	LOSS [training: 0.11281778238301923 | validation: 0.13663036432779313]
	TIME [epoch: 32.7 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11494938298456317		[learning rate: 0.0013078]
	Learning Rate: 0.00130779
	LOSS [training: 0.11494938298456317 | validation: 0.1335183799784075]
	TIME [epoch: 32.6 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11625292264328853		[learning rate: 0.0013026]
	Learning Rate: 0.00130259
	LOSS [training: 0.11625292264328853 | validation: 0.1352421755459252]
	TIME [epoch: 32.7 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11492374039144354		[learning rate: 0.0012974]
	Learning Rate: 0.00129741
	LOSS [training: 0.11492374039144354 | validation: 0.12652349829830117]
	TIME [epoch: 32.6 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11567112040206316		[learning rate: 0.0012922]
	Learning Rate: 0.00129225
	LOSS [training: 0.11567112040206316 | validation: 0.12878502627226046]
	TIME [epoch: 32.6 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12793554822995443		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.12793554822995443 | validation: 0.13939997782237276]
	TIME [epoch: 32.6 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11604763980027578		[learning rate: 0.001282]
	Learning Rate: 0.00128199
	LOSS [training: 0.11604763980027578 | validation: 0.1270034919129346]
	TIME [epoch: 32.7 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11964461636981187		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.11964461636981187 | validation: 0.13039313630544253]
	TIME [epoch: 32.7 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12104999058263505		[learning rate: 0.0012718]
	Learning Rate: 0.00127181
	LOSS [training: 0.12104999058263505 | validation: 0.1303557376671115]
	TIME [epoch: 32.7 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11261487327078266		[learning rate: 0.0012668]
	Learning Rate: 0.00126675
	LOSS [training: 0.11261487327078266 | validation: 0.1256912489938676]
	TIME [epoch: 32.6 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11540251546768777		[learning rate: 0.0012617]
	Learning Rate: 0.00126172
	LOSS [training: 0.11540251546768777 | validation: 0.12907147468414748]
	TIME [epoch: 32.7 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1095548524634687		[learning rate: 0.0012567]
	Learning Rate: 0.0012567
	LOSS [training: 0.1095548524634687 | validation: 0.13719789555080758]
	TIME [epoch: 32.7 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11819585147651426		[learning rate: 0.0012517]
	Learning Rate: 0.0012517
	LOSS [training: 0.11819585147651426 | validation: 0.12743912182754755]
	TIME [epoch: 32.6 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11653480000773812		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.11653480000773812 | validation: 0.1351249288789092]
	TIME [epoch: 32.6 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11678075155469493		[learning rate: 0.0012418]
	Learning Rate: 0.00124176
	LOSS [training: 0.11678075155469493 | validation: 0.1270796580447518]
	TIME [epoch: 32.6 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11855944539090693		[learning rate: 0.0012368]
	Learning Rate: 0.00123682
	LOSS [training: 0.11855944539090693 | validation: 0.13160983287951483]
	TIME [epoch: 32.6 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11889895848530789		[learning rate: 0.0012319]
	Learning Rate: 0.0012319
	LOSS [training: 0.11889895848530789 | validation: 0.12992899665806146]
	TIME [epoch: 32.7 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10918171929430688		[learning rate: 0.001227]
	Learning Rate: 0.001227
	LOSS [training: 0.10918171929430688 | validation: 0.13017124375804223]
	TIME [epoch: 32.6 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1105109785234335		[learning rate: 0.0012221]
	Learning Rate: 0.00122212
	LOSS [training: 0.1105109785234335 | validation: 0.12920290681504196]
	TIME [epoch: 32.7 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11036356600509481		[learning rate: 0.0012173]
	Learning Rate: 0.00121726
	LOSS [training: 0.11036356600509481 | validation: 0.12637991923542824]
	TIME [epoch: 32.6 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12363801628239497		[learning rate: 0.0012124]
	Learning Rate: 0.00121242
	LOSS [training: 0.12363801628239497 | validation: 0.13402199415504046]
	TIME [epoch: 32.6 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11771772588603249		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.11771772588603249 | validation: 0.1421382160506885]
	TIME [epoch: 32.6 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11631546438486683		[learning rate: 0.0012028]
	Learning Rate: 0.0012028
	LOSS [training: 0.11631546438486683 | validation: 0.13197370297263258]
	TIME [epoch: 32.6 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11097054439311213		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.11097054439311213 | validation: 0.12764832253839295]
	TIME [epoch: 32.7 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11610503582612895		[learning rate: 0.0011932]
	Learning Rate: 0.00119325
	LOSS [training: 0.11610503582612895 | validation: 0.13374471226242515]
	TIME [epoch: 32.7 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11579780467060861		[learning rate: 0.0011885]
	Learning Rate: 0.0011885
	LOSS [training: 0.11579780467060861 | validation: 0.13485777754706776]
	TIME [epoch: 32.6 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11255982205367321		[learning rate: 0.0011838]
	Learning Rate: 0.00118378
	LOSS [training: 0.11255982205367321 | validation: 0.1333234790631886]
	TIME [epoch: 32.7 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12130897135053337		[learning rate: 0.0011791]
	Learning Rate: 0.00117907
	LOSS [training: 0.12130897135053337 | validation: 0.13623220207086226]
	TIME [epoch: 32.6 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12112547968270487		[learning rate: 0.0011744]
	Learning Rate: 0.00117438
	LOSS [training: 0.12112547968270487 | validation: 0.12529968875857844]
	TIME [epoch: 32.7 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11258434247735691		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.11258434247735691 | validation: 0.13342114876475986]
	TIME [epoch: 32.6 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11172247712407676		[learning rate: 0.0011651]
	Learning Rate: 0.00116505
	LOSS [training: 0.11172247712407676 | validation: 0.1331556824128522]
	TIME [epoch: 32.6 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11278352603528886		[learning rate: 0.0011604]
	Learning Rate: 0.00116042
	LOSS [training: 0.11278352603528886 | validation: 0.12556539577106388]
	TIME [epoch: 32.6 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11946235986178048		[learning rate: 0.0011558]
	Learning Rate: 0.00115581
	LOSS [training: 0.11946235986178048 | validation: 0.12269319989638187]
	TIME [epoch: 32.6 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11159486938027602		[learning rate: 0.0011512]
	Learning Rate: 0.00115121
	LOSS [training: 0.11159486938027602 | validation: 0.1358156827756073]
	TIME [epoch: 32.6 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10512186195725738		[learning rate: 0.0011466]
	Learning Rate: 0.00114663
	LOSS [training: 0.10512186195725738 | validation: 0.13279087786858]
	TIME [epoch: 32.5 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10684712301618184		[learning rate: 0.0011421]
	Learning Rate: 0.00114207
	LOSS [training: 0.10684712301618184 | validation: 0.1267580831146625]
	TIME [epoch: 32.6 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10776397377435372		[learning rate: 0.0011375]
	Learning Rate: 0.00113753
	LOSS [training: 0.10776397377435372 | validation: 0.13722637797702802]
	TIME [epoch: 32.5 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11745640468101956		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.11745640468101956 | validation: 0.12559560302182277]
	TIME [epoch: 32.6 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10606490223854276		[learning rate: 0.0011285]
	Learning Rate: 0.0011285
	LOSS [training: 0.10606490223854276 | validation: 0.1293914561148493]
	TIME [epoch: 32.6 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11313690807703798		[learning rate: 0.001124]
	Learning Rate: 0.00112401
	LOSS [training: 0.11313690807703798 | validation: 0.1253134164254217]
	TIME [epoch: 32.6 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11207585838472672		[learning rate: 0.0011195]
	Learning Rate: 0.00111954
	LOSS [training: 0.11207585838472672 | validation: 0.12865652582303264]
	TIME [epoch: 32.6 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11708341089591832		[learning rate: 0.0011151]
	Learning Rate: 0.00111508
	LOSS [training: 0.11708341089591832 | validation: 0.14030587312710613]
	TIME [epoch: 32.6 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11436367351182815		[learning rate: 0.0011106]
	Learning Rate: 0.00111065
	LOSS [training: 0.11436367351182815 | validation: 0.13867607410335]
	TIME [epoch: 32.6 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11915306506198621		[learning rate: 0.0011062]
	Learning Rate: 0.00110623
	LOSS [training: 0.11915306506198621 | validation: 0.12345510134522697]
	TIME [epoch: 32.6 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12122982493449978		[learning rate: 0.0011018]
	Learning Rate: 0.00110183
	LOSS [training: 0.12122982493449978 | validation: 0.1339094486012059]
	TIME [epoch: 32.7 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12133884507376985		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.12133884507376985 | validation: 0.1240117354595591]
	TIME [epoch: 32.7 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11938972503223028		[learning rate: 0.0010931]
	Learning Rate: 0.00109309
	LOSS [training: 0.11938972503223028 | validation: 0.1230347681500431]
	TIME [epoch: 32.7 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12059351261519592		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.12059351261519592 | validation: 0.12578555047294557]
	TIME [epoch: 32.7 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11406002840655836		[learning rate: 0.0010844]
	Learning Rate: 0.00108441
	LOSS [training: 0.11406002840655836 | validation: 0.1295135741893293]
	TIME [epoch: 32.7 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11350557465150136		[learning rate: 0.0010801]
	Learning Rate: 0.00108009
	LOSS [training: 0.11350557465150136 | validation: 0.13414978998399957]
	TIME [epoch: 32.6 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12421228062876133		[learning rate: 0.0010758]
	Learning Rate: 0.0010758
	LOSS [training: 0.12421228062876133 | validation: 0.14425326536367172]
	TIME [epoch: 32.6 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11452269208083364		[learning rate: 0.0010715]
	Learning Rate: 0.00107152
	LOSS [training: 0.11452269208083364 | validation: 0.13727781652496077]
	TIME [epoch: 32.7 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11587094472617582		[learning rate: 0.0010673]
	Learning Rate: 0.00106726
	LOSS [training: 0.11587094472617582 | validation: 0.13602940242674505]
	TIME [epoch: 32.6 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10898072575772225		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.10898072575772225 | validation: 0.13274772912556237]
	TIME [epoch: 32.6 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10857640530512548		[learning rate: 0.0010588]
	Learning Rate: 0.00105878
	LOSS [training: 0.10857640530512548 | validation: 0.1281864997158622]
	TIME [epoch: 32.6 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11018068287076675		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.11018068287076675 | validation: 0.13296783798182527]
	TIME [epoch: 32.6 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11375647487688606		[learning rate: 0.0010504]
	Learning Rate: 0.00105038
	LOSS [training: 0.11375647487688606 | validation: 0.13648883760634342]
	TIME [epoch: 32.6 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1170260074200679		[learning rate: 0.0010462]
	Learning Rate: 0.0010462
	LOSS [training: 0.1170260074200679 | validation: 0.127544199927656]
	TIME [epoch: 32.6 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11890709607341964		[learning rate: 0.001042]
	Learning Rate: 0.00104204
	LOSS [training: 0.11890709607341964 | validation: 0.12718325927739987]
	TIME [epoch: 32.6 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1105269747293679		[learning rate: 0.0010379]
	Learning Rate: 0.0010379
	LOSS [training: 0.1105269747293679 | validation: 0.1343720176869547]
	TIME [epoch: 32.6 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12322148734809556		[learning rate: 0.0010338]
	Learning Rate: 0.00103377
	LOSS [training: 0.12322148734809556 | validation: 0.12806156922324557]
	TIME [epoch: 32.6 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11340173345724922		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.11340173345724922 | validation: 0.13428142877867524]
	TIME [epoch: 32.6 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11321913850668398		[learning rate: 0.0010256]
	Learning Rate: 0.00102556
	LOSS [training: 0.11321913850668398 | validation: 0.1271642498591146]
	TIME [epoch: 32.7 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11161880764227478		[learning rate: 0.0010215]
	Learning Rate: 0.00102148
	LOSS [training: 0.11161880764227478 | validation: 0.13768021410393494]
	TIME [epoch: 32.7 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11601142181117169		[learning rate: 0.0010174]
	Learning Rate: 0.00101742
	LOSS [training: 0.11601142181117169 | validation: 0.1226700389863646]
	TIME [epoch: 32.6 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11116461099541117		[learning rate: 0.0010134]
	Learning Rate: 0.00101337
	LOSS [training: 0.11116461099541117 | validation: 0.13397247130362971]
	TIME [epoch: 32.6 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1113713809920929		[learning rate: 0.0010093]
	Learning Rate: 0.00100934
	LOSS [training: 0.1113713809920929 | validation: 0.14198864126174232]
	TIME [epoch: 32.6 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.111853952597921		[learning rate: 0.0010053]
	Learning Rate: 0.00100533
	LOSS [training: 0.111853952597921 | validation: 0.1311647379401202]
	TIME [epoch: 32.6 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11607755479938005		[learning rate: 0.0010013]
	Learning Rate: 0.00100133
	LOSS [training: 0.11607755479938005 | validation: 0.13513481214294648]
	TIME [epoch: 32.6 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1129706557719136		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.1129706557719136 | validation: 0.12406396340433097]
	TIME [epoch: 32.6 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12004098619024736		[learning rate: 0.00099338]
	Learning Rate: 0.00099338
	LOSS [training: 0.12004098619024736 | validation: 0.13419476437558814]
	TIME [epoch: 32.7 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10750950227699371		[learning rate: 0.00098943]
	Learning Rate: 0.000989429
	LOSS [training: 0.10750950227699371 | validation: 0.1268015752903718]
	TIME [epoch: 32.6 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12446977091591088		[learning rate: 0.00098549]
	Learning Rate: 0.000985494
	LOSS [training: 0.12446977091591088 | validation: 0.13580265645113632]
	TIME [epoch: 32.6 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11668290377999223		[learning rate: 0.00098157]
	Learning Rate: 0.000981574
	LOSS [training: 0.11668290377999223 | validation: 0.132722020311062]
	TIME [epoch: 32.7 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11049204271781052		[learning rate: 0.00097767]
	Learning Rate: 0.00097767
	LOSS [training: 0.11049204271781052 | validation: 0.13383245085728587]
	TIME [epoch: 32.7 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11457855637186205		[learning rate: 0.00097378]
	Learning Rate: 0.000973782
	LOSS [training: 0.11457855637186205 | validation: 0.13609739060028245]
	TIME [epoch: 32.7 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12061798844685818		[learning rate: 0.00096991]
	Learning Rate: 0.000969909
	LOSS [training: 0.12061798844685818 | validation: 0.13079683037713438]
	TIME [epoch: 32.7 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11639133443619538		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.11639133443619538 | validation: 0.12325118174766567]
	TIME [epoch: 32.6 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10612634525927381		[learning rate: 0.00096221]
	Learning Rate: 0.000962209
	LOSS [training: 0.10612634525927381 | validation: 0.13161441721153372]
	TIME [epoch: 32.6 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1182396475401196		[learning rate: 0.00095838]
	Learning Rate: 0.000958382
	LOSS [training: 0.1182396475401196 | validation: 0.1300340482603008]
	TIME [epoch: 32.6 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11538040488721446		[learning rate: 0.00095457]
	Learning Rate: 0.00095457
	LOSS [training: 0.11538040488721446 | validation: 0.12351220122818338]
	TIME [epoch: 32.7 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11226597764258155		[learning rate: 0.00095077]
	Learning Rate: 0.000950773
	LOSS [training: 0.11226597764258155 | validation: 0.12611275438162786]
	TIME [epoch: 32.7 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11724170283425225		[learning rate: 0.00094699]
	Learning Rate: 0.000946992
	LOSS [training: 0.11724170283425225 | validation: 0.13585428863745258]
	TIME [epoch: 32.6 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12486206290781807		[learning rate: 0.00094323]
	Learning Rate: 0.000943225
	LOSS [training: 0.12486206290781807 | validation: 0.1322577111225402]
	TIME [epoch: 32.7 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11967162793239335		[learning rate: 0.00093947]
	Learning Rate: 0.000939474
	LOSS [training: 0.11967162793239335 | validation: 0.1300103061078002]
	TIME [epoch: 32.6 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12488474984965069		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.12488474984965069 | validation: 0.1328881066611606]
	TIME [epoch: 32.7 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11642183069847621		[learning rate: 0.00093202]
	Learning Rate: 0.000932015
	LOSS [training: 0.11642183069847621 | validation: 0.1287913694391633]
	TIME [epoch: 32.6 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11248002521231316		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.11248002521231316 | validation: 0.1305055809270798]
	TIME [epoch: 32.6 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12325331066961809		[learning rate: 0.00092462]
	Learning Rate: 0.000924616
	LOSS [training: 0.12325331066961809 | validation: 0.12772352448675992]
	TIME [epoch: 32.7 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11345751422502041		[learning rate: 0.00092094]
	Learning Rate: 0.000920939
	LOSS [training: 0.11345751422502041 | validation: 0.13379006291540038]
	TIME [epoch: 32.7 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11690829432201943		[learning rate: 0.00091728]
	Learning Rate: 0.000917276
	LOSS [training: 0.11690829432201943 | validation: 0.1270936846180483]
	TIME [epoch: 32.6 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11716518882100438		[learning rate: 0.00091363]
	Learning Rate: 0.000913628
	LOSS [training: 0.11716518882100438 | validation: 0.12986851870296542]
	TIME [epoch: 32.6 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11209355998320907		[learning rate: 0.00090999]
	Learning Rate: 0.000909994
	LOSS [training: 0.11209355998320907 | validation: 0.12746667521312544]
	TIME [epoch: 32.6 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12234196940820698		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.12234196940820698 | validation: 0.12588194226041302]
	TIME [epoch: 32.7 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11338209364706309		[learning rate: 0.00090277]
	Learning Rate: 0.00090277
	LOSS [training: 0.11338209364706309 | validation: 0.12819805914386545]
	TIME [epoch: 32.6 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10427485614417148		[learning rate: 0.00089918]
	Learning Rate: 0.000899179
	LOSS [training: 0.10427485614417148 | validation: 0.1339385912809225]
	TIME [epoch: 32.7 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11010175946571765		[learning rate: 0.0008956]
	Learning Rate: 0.000895603
	LOSS [training: 0.11010175946571765 | validation: 0.13281675381632935]
	TIME [epoch: 32.6 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1127360636060985		[learning rate: 0.00089204]
	Learning Rate: 0.000892041
	LOSS [training: 0.1127360636060985 | validation: 0.12615064831817877]
	TIME [epoch: 32.7 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11675678970315209		[learning rate: 0.00088849]
	Learning Rate: 0.000888493
	LOSS [training: 0.11675678970315209 | validation: 0.12583780514330734]
	TIME [epoch: 32.6 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12074110162483026		[learning rate: 0.00088496]
	Learning Rate: 0.000884959
	LOSS [training: 0.12074110162483026 | validation: 0.13533908633894753]
	TIME [epoch: 32.7 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10899992828918606		[learning rate: 0.00088144]
	Learning Rate: 0.000881439
	LOSS [training: 0.10899992828918606 | validation: 0.12444352020096276]
	TIME [epoch: 32.6 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.111242991119682		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.111242991119682 | validation: 0.11950131359469936]
	TIME [epoch: 32.6 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_655.pth
	Model improved!!!
EPOCH 656/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11055796528783084		[learning rate: 0.00087444]
	Learning Rate: 0.000874441
	LOSS [training: 0.11055796528783084 | validation: 0.1316476480722642]
	TIME [epoch: 32.5 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11955650469119014		[learning rate: 0.00087096]
	Learning Rate: 0.000870964
	LOSS [training: 0.11955650469119014 | validation: 0.12892738647389854]
	TIME [epoch: 32.6 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1120843004368744		[learning rate: 0.0008675]
	Learning Rate: 0.0008675
	LOSS [training: 0.1120843004368744 | validation: 0.13162299320281726]
	TIME [epoch: 32.6 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11952512584213516		[learning rate: 0.00086405]
	Learning Rate: 0.000864049
	LOSS [training: 0.11952512584213516 | validation: 0.13398118503318698]
	TIME [epoch: 32.6 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10917731443094914		[learning rate: 0.00086061]
	Learning Rate: 0.000860613
	LOSS [training: 0.10917731443094914 | validation: 0.12515796195825224]
	TIME [epoch: 32.6 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11303502028293101		[learning rate: 0.00085719]
	Learning Rate: 0.00085719
	LOSS [training: 0.11303502028293101 | validation: 0.12741427190668114]
	TIME [epoch: 32.6 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10800186325598972		[learning rate: 0.00085378]
	Learning Rate: 0.00085378
	LOSS [training: 0.10800186325598972 | validation: 0.13344120999635536]
	TIME [epoch: 32.6 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11668569809593533		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.11668569809593533 | validation: 0.12273570838252254]
	TIME [epoch: 32.6 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11541650170706694		[learning rate: 0.000847]
	Learning Rate: 0.000847002
	LOSS [training: 0.11541650170706694 | validation: 0.12450546931606485]
	TIME [epoch: 32.6 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10858091892084748		[learning rate: 0.00084363]
	Learning Rate: 0.000843634
	LOSS [training: 0.10858091892084748 | validation: 0.12393175032484445]
	TIME [epoch: 32.6 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11736420785164293		[learning rate: 0.00084028]
	Learning Rate: 0.000840278
	LOSS [training: 0.11736420785164293 | validation: 0.1308584739150513]
	TIME [epoch: 32.7 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11200280529675563		[learning rate: 0.00083694]
	Learning Rate: 0.000836936
	LOSS [training: 0.11200280529675563 | validation: 0.13151572007232296]
	TIME [epoch: 32.6 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1176330849108787		[learning rate: 0.00083361]
	Learning Rate: 0.000833608
	LOSS [training: 0.1176330849108787 | validation: 0.13175293958766937]
	TIME [epoch: 32.6 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12808773674891646		[learning rate: 0.00083029]
	Learning Rate: 0.000830292
	LOSS [training: 0.12808773674891646 | validation: 0.13031941189956878]
	TIME [epoch: 32.6 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11318018232489507		[learning rate: 0.00082699]
	Learning Rate: 0.00082699
	LOSS [training: 0.11318018232489507 | validation: 0.12060507158299352]
	TIME [epoch: 32.6 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10822277245922526		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.10822277245922526 | validation: 0.1300196591254827]
	TIME [epoch: 32.7 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10902298244762013		[learning rate: 0.00082042]
	Learning Rate: 0.000820424
	LOSS [training: 0.10902298244762013 | validation: 0.12795794412117745]
	TIME [epoch: 32.7 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11664861224571421		[learning rate: 0.00081716]
	Learning Rate: 0.000817161
	LOSS [training: 0.11664861224571421 | validation: 0.12831328743548315]
	TIME [epoch: 32.6 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11007245556678165		[learning rate: 0.00081391]
	Learning Rate: 0.000813911
	LOSS [training: 0.11007245556678165 | validation: 0.1305212566173645]
	TIME [epoch: 32.6 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11644949669473707		[learning rate: 0.00081067]
	Learning Rate: 0.000810674
	LOSS [training: 0.11644949669473707 | validation: 0.12999699114206495]
	TIME [epoch: 32.6 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10975854377916489		[learning rate: 0.00080745]
	Learning Rate: 0.00080745
	LOSS [training: 0.10975854377916489 | validation: 0.12417034854285558]
	TIME [epoch: 32.6 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11528808544830296		[learning rate: 0.00080424]
	Learning Rate: 0.000804238
	LOSS [training: 0.11528808544830296 | validation: 0.12391284415181851]
	TIME [epoch: 32.6 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11322499887763719		[learning rate: 0.00080104]
	Learning Rate: 0.000801039
	LOSS [training: 0.11322499887763719 | validation: 0.13274026811594622]
	TIME [epoch: 32.6 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10647606957955938		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.10647606957955938 | validation: 0.1349380309527355]
	TIME [epoch: 32.6 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11790717169113107		[learning rate: 0.00079468]
	Learning Rate: 0.00079468
	LOSS [training: 0.11790717169113107 | validation: 0.12328466309413169]
	TIME [epoch: 32.6 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11219289706566965		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.11219289706566965 | validation: 0.13340643138657543]
	TIME [epoch: 32.6 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11435458478333614		[learning rate: 0.00078837]
	Learning Rate: 0.000788371
	LOSS [training: 0.11435458478333614 | validation: 0.12666749101934902]
	TIME [epoch: 32.6 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10909205957967659		[learning rate: 0.00078524]
	Learning Rate: 0.000785236
	LOSS [training: 0.10909205957967659 | validation: 0.12917835953947293]
	TIME [epoch: 32.7 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11492734348111494		[learning rate: 0.00078211]
	Learning Rate: 0.000782113
	LOSS [training: 0.11492734348111494 | validation: 0.13259240476514392]
	TIME [epoch: 32.6 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1079115228528002		[learning rate: 0.000779]
	Learning Rate: 0.000779002
	LOSS [training: 0.1079115228528002 | validation: 0.1251107991775567]
	TIME [epoch: 32.6 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11540220378931602		[learning rate: 0.0007759]
	Learning Rate: 0.000775904
	LOSS [training: 0.11540220378931602 | validation: 0.12951679216674492]
	TIME [epoch: 32.7 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11198815133702394		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.11198815133702394 | validation: 0.12360713374758095]
	TIME [epoch: 32.6 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11295377271866212		[learning rate: 0.00076974]
	Learning Rate: 0.000769744
	LOSS [training: 0.11295377271866212 | validation: 0.12698605989007053]
	TIME [epoch: 32.7 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11681245253883327		[learning rate: 0.00076668]
	Learning Rate: 0.000766682
	LOSS [training: 0.11681245253883327 | validation: 0.12773417390396438]
	TIME [epoch: 32.6 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.110506573328432		[learning rate: 0.00076363]
	Learning Rate: 0.000763633
	LOSS [training: 0.110506573328432 | validation: 0.12752102499944523]
	TIME [epoch: 32.7 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11805624701098955		[learning rate: 0.0007606]
	Learning Rate: 0.000760596
	LOSS [training: 0.11805624701098955 | validation: 0.13911415280600492]
	TIME [epoch: 32.6 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11133507524455016		[learning rate: 0.00075757]
	Learning Rate: 0.000757571
	LOSS [training: 0.11133507524455016 | validation: 0.12388661832178231]
	TIME [epoch: 32.7 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11382658766397766		[learning rate: 0.00075456]
	Learning Rate: 0.000754557
	LOSS [training: 0.11382658766397766 | validation: 0.13103023405635378]
	TIME [epoch: 32.6 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11432572921254394		[learning rate: 0.00075156]
	Learning Rate: 0.000751556
	LOSS [training: 0.11432572921254394 | validation: 0.12999325387077212]
	TIME [epoch: 32.6 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10762062202340651		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.10762062202340651 | validation: 0.1252145231011655]
	TIME [epoch: 32.6 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11362031078807187		[learning rate: 0.00074559]
	Learning Rate: 0.00074559
	LOSS [training: 0.11362031078807187 | validation: 0.1260800208840666]
	TIME [epoch: 32.6 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10828870278696762		[learning rate: 0.00074262]
	Learning Rate: 0.000742624
	LOSS [training: 0.10828870278696762 | validation: 0.12063720291409771]
	TIME [epoch: 32.6 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11802892697579484		[learning rate: 0.00073967]
	Learning Rate: 0.000739671
	LOSS [training: 0.11802892697579484 | validation: 0.1291358849662328]
	TIME [epoch: 32.6 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10866193008723725		[learning rate: 0.00073673]
	Learning Rate: 0.000736729
	LOSS [training: 0.10866193008723725 | validation: 0.12590272158424837]
	TIME [epoch: 32.6 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11588175515836999		[learning rate: 0.0007338]
	Learning Rate: 0.000733799
	LOSS [training: 0.11588175515836999 | validation: 0.1292780259343213]
	TIME [epoch: 32.6 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1182551183459822		[learning rate: 0.00073088]
	Learning Rate: 0.00073088
	LOSS [training: 0.1182551183459822 | validation: 0.13032281550563168]
	TIME [epoch: 32.6 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11195758222223051		[learning rate: 0.00072797]
	Learning Rate: 0.000727973
	LOSS [training: 0.11195758222223051 | validation: 0.1268515434342821]
	TIME [epoch: 32.6 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11034596425622939		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.11034596425622939 | validation: 0.1292166344137096]
	TIME [epoch: 32.7 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1098324499165762		[learning rate: 0.00072219]
	Learning Rate: 0.000722194
	LOSS [training: 0.1098324499165762 | validation: 0.1264429782482129]
	TIME [epoch: 32.7 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12408574565172012		[learning rate: 0.00071932]
	Learning Rate: 0.000719322
	LOSS [training: 0.12408574565172012 | validation: 0.13854016064857516]
	TIME [epoch: 32.6 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11013794871309074		[learning rate: 0.00071646]
	Learning Rate: 0.000716461
	LOSS [training: 0.11013794871309074 | validation: 0.12994745333435684]
	TIME [epoch: 32.7 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11344160483545698		[learning rate: 0.00071361]
	Learning Rate: 0.000713611
	LOSS [training: 0.11344160483545698 | validation: 0.12729109831530003]
	TIME [epoch: 32.7 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10742763679361343		[learning rate: 0.00071077]
	Learning Rate: 0.000710773
	LOSS [training: 0.10742763679361343 | validation: 0.126169431735205]
	TIME [epoch: 32.7 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10909225546775596		[learning rate: 0.00070795]
	Learning Rate: 0.000707946
	LOSS [training: 0.10909225546775596 | validation: 0.12200121321905695]
	TIME [epoch: 32.7 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11354783389037072		[learning rate: 0.00070513]
	Learning Rate: 0.00070513
	LOSS [training: 0.11354783389037072 | validation: 0.12831815848107547]
	TIME [epoch: 32.7 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10914430859785042		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.10914430859785042 | validation: 0.1308121831119084]
	TIME [epoch: 32.6 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10747936094470872		[learning rate: 0.00069953]
	Learning Rate: 0.000699532
	LOSS [training: 0.10747936094470872 | validation: 0.12939486828468455]
	TIME [epoch: 32.7 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11579736032924615		[learning rate: 0.00069675]
	Learning Rate: 0.00069675
	LOSS [training: 0.11579736032924615 | validation: 0.12717300949018487]
	TIME [epoch: 32.6 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11313883759010906		[learning rate: 0.00069398]
	Learning Rate: 0.000693979
	LOSS [training: 0.11313883759010906 | validation: 0.13078332083999608]
	TIME [epoch: 32.6 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10854155998478958		[learning rate: 0.00069122]
	Learning Rate: 0.000691219
	LOSS [training: 0.10854155998478958 | validation: 0.12539166127483545]
	TIME [epoch: 32.6 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12165589154607509		[learning rate: 0.00068847]
	Learning Rate: 0.000688469
	LOSS [training: 0.12165589154607509 | validation: 0.13136880446702445]
	TIME [epoch: 32.6 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10923414855611452		[learning rate: 0.00068573]
	Learning Rate: 0.000685731
	LOSS [training: 0.10923414855611452 | validation: 0.12529773408888434]
	TIME [epoch: 32.6 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11102561792256337		[learning rate: 0.000683]
	Learning Rate: 0.000683004
	LOSS [training: 0.11102561792256337 | validation: 0.12247930137777283]
	TIME [epoch: 32.7 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11222643949039253		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.11222643949039253 | validation: 0.12686222656958732]
	TIME [epoch: 32.6 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10958384468632515		[learning rate: 0.00067758]
	Learning Rate: 0.000677582
	LOSS [training: 0.10958384468632515 | validation: 0.13246770336776365]
	TIME [epoch: 32.6 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12249026341394235		[learning rate: 0.00067489]
	Learning Rate: 0.000674887
	LOSS [training: 0.12249026341394235 | validation: 0.1231399974246318]
	TIME [epoch: 32.6 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11630063220526313		[learning rate: 0.0006722]
	Learning Rate: 0.000672202
	LOSS [training: 0.11630063220526313 | validation: 0.12675036177285753]
	TIME [epoch: 32.6 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11216474887532052		[learning rate: 0.00066953]
	Learning Rate: 0.000669529
	LOSS [training: 0.11216474887532052 | validation: 0.13411669022400124]
	TIME [epoch: 32.7 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11021134230679712		[learning rate: 0.00066687]
	Learning Rate: 0.000666866
	LOSS [training: 0.11021134230679712 | validation: 0.13019307544208497]
	TIME [epoch: 32.6 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10879938820184816		[learning rate: 0.00066421]
	Learning Rate: 0.000664213
	LOSS [training: 0.10879938820184816 | validation: 0.1327069032224667]
	TIME [epoch: 32.7 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11114516534654478		[learning rate: 0.00066157]
	Learning Rate: 0.000661572
	LOSS [training: 0.11114516534654478 | validation: 0.12558249433564592]
	TIME [epoch: 32.6 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11098861105269699		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.11098861105269699 | validation: 0.1320880499291158]
	TIME [epoch: 32.7 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11137938269075508		[learning rate: 0.00065632]
	Learning Rate: 0.00065632
	LOSS [training: 0.11137938269075508 | validation: 0.1269978281587752]
	TIME [epoch: 32.6 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12205269552927714		[learning rate: 0.00065371]
	Learning Rate: 0.000653709
	LOSS [training: 0.12205269552927714 | validation: 0.12418438169250268]
	TIME [epoch: 32.6 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10970580236682609		[learning rate: 0.00065111]
	Learning Rate: 0.000651109
	LOSS [training: 0.10970580236682609 | validation: 0.13281355970508285]
	TIME [epoch: 32.6 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10971654343981298		[learning rate: 0.00064852]
	Learning Rate: 0.00064852
	LOSS [training: 0.10971654343981298 | validation: 0.1240730344597317]
	TIME [epoch: 32.6 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11391507264646093		[learning rate: 0.00064594]
	Learning Rate: 0.00064594
	LOSS [training: 0.11391507264646093 | validation: 0.13356420935641236]
	TIME [epoch: 32.6 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1123833741551107		[learning rate: 0.00064337]
	Learning Rate: 0.000643371
	LOSS [training: 0.1123833741551107 | validation: 0.11966116996568625]
	TIME [epoch: 32.6 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11118987729445738		[learning rate: 0.00064081]
	Learning Rate: 0.000640812
	LOSS [training: 0.11118987729445738 | validation: 0.12461032719014926]
	TIME [epoch: 32.7 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11488897888694335		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.11488897888694335 | validation: 0.13197767413877354]
	TIME [epoch: 32.6 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11491107311020736		[learning rate: 0.00063572]
	Learning Rate: 0.000635725
	LOSS [training: 0.11491107311020736 | validation: 0.1245490758524441]
	TIME [epoch: 32.6 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11086492092717343		[learning rate: 0.0006332]
	Learning Rate: 0.000633196
	LOSS [training: 0.11086492092717343 | validation: 0.12522990114218138]
	TIME [epoch: 32.6 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10684054161619105		[learning rate: 0.00063068]
	Learning Rate: 0.000630678
	LOSS [training: 0.10684054161619105 | validation: 0.13387438539348337]
	TIME [epoch: 32.7 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1090506749070156		[learning rate: 0.00062817]
	Learning Rate: 0.00062817
	LOSS [training: 0.1090506749070156 | validation: 0.12744071126686046]
	TIME [epoch: 32.6 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11483307988112289		[learning rate: 0.00062567]
	Learning Rate: 0.000625671
	LOSS [training: 0.11483307988112289 | validation: 0.12322308868878036]
	TIME [epoch: 32.6 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11081169585398565		[learning rate: 0.00062318]
	Learning Rate: 0.000623183
	LOSS [training: 0.11081169585398565 | validation: 0.13161583157262616]
	TIME [epoch: 32.7 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11648844525819434		[learning rate: 0.0006207]
	Learning Rate: 0.000620704
	LOSS [training: 0.11648844525819434 | validation: 0.12748639517229915]
	TIME [epoch: 32.6 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11175961131220927		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.11175961131220927 | validation: 0.13119602038250133]
	TIME [epoch: 32.6 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10708717836575528		[learning rate: 0.00061578]
	Learning Rate: 0.000615777
	LOSS [training: 0.10708717836575528 | validation: 0.1351060237334973]
	TIME [epoch: 32.6 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11644936809494724		[learning rate: 0.00061333]
	Learning Rate: 0.000613327
	LOSS [training: 0.11644936809494724 | validation: 0.13420588345398785]
	TIME [epoch: 32.7 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11125834508075091		[learning rate: 0.00061089]
	Learning Rate: 0.000610888
	LOSS [training: 0.11125834508075091 | validation: 0.13341586988529322]
	TIME [epoch: 32.6 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1069032878196548		[learning rate: 0.00060846]
	Learning Rate: 0.000608458
	LOSS [training: 0.1069032878196548 | validation: 0.13092216347021765]
	TIME [epoch: 32.6 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11271725218955722		[learning rate: 0.00060604]
	Learning Rate: 0.000606038
	LOSS [training: 0.11271725218955722 | validation: 0.136792009557332]
	TIME [epoch: 32.6 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1186211738199817		[learning rate: 0.00060363]
	Learning Rate: 0.000603628
	LOSS [training: 0.1186211738199817 | validation: 0.12645819261339983]
	TIME [epoch: 32.6 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11167765584745891		[learning rate: 0.00060123]
	Learning Rate: 0.000601227
	LOSS [training: 0.11167765584745891 | validation: 0.12258420106092585]
	TIME [epoch: 32.6 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11118407817092628		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.11118407817092628 | validation: 0.12365864268041311]
	TIME [epoch: 32.6 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11768999811482625		[learning rate: 0.00059645]
	Learning Rate: 0.000596454
	LOSS [training: 0.11768999811482625 | validation: 0.12511463419031169]
	TIME [epoch: 32.6 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11155367715997166		[learning rate: 0.00059408]
	Learning Rate: 0.000594082
	LOSS [training: 0.11155367715997166 | validation: 0.14168493695748824]
	TIME [epoch: 32.6 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10461798845248128		[learning rate: 0.00059172]
	Learning Rate: 0.000591719
	LOSS [training: 0.10461798845248128 | validation: 0.13234590086094186]
	TIME [epoch: 32.6 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1184269771321062		[learning rate: 0.00058937]
	Learning Rate: 0.000589365
	LOSS [training: 0.1184269771321062 | validation: 0.1264266019082675]
	TIME [epoch: 32.6 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10714744735748044		[learning rate: 0.00058702]
	Learning Rate: 0.000587021
	LOSS [training: 0.10714744735748044 | validation: 0.12784285373729332]
	TIME [epoch: 32.7 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11324784940976512		[learning rate: 0.00058469]
	Learning Rate: 0.000584687
	LOSS [training: 0.11324784940976512 | validation: 0.1293935037712535]
	TIME [epoch: 32.6 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10440620773182158		[learning rate: 0.00058236]
	Learning Rate: 0.000582361
	LOSS [training: 0.10440620773182158 | validation: 0.12781970082878796]
	TIME [epoch: 32.6 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11695226982121537		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.11695226982121537 | validation: 0.13406788459591645]
	TIME [epoch: 32.6 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11027681841322692		[learning rate: 0.00057774]
	Learning Rate: 0.000577738
	LOSS [training: 0.11027681841322692 | validation: 0.13057700724060337]
	TIME [epoch: 32.7 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10998226409645014		[learning rate: 0.00057544]
	Learning Rate: 0.00057544
	LOSS [training: 0.10998226409645014 | validation: 0.12643310415162595]
	TIME [epoch: 32.7 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11309584352037533		[learning rate: 0.00057315]
	Learning Rate: 0.000573151
	LOSS [training: 0.11309584352037533 | validation: 0.12907099256324725]
	TIME [epoch: 32.6 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11719651007673464		[learning rate: 0.00057087]
	Learning Rate: 0.000570872
	LOSS [training: 0.11719651007673464 | validation: 0.12403876638316409]
	TIME [epoch: 32.6 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1125938374569012		[learning rate: 0.0005686]
	Learning Rate: 0.000568601
	LOSS [training: 0.1125938374569012 | validation: 0.1256853300526657]
	TIME [epoch: 32.7 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11021823567045327		[learning rate: 0.00056634]
	Learning Rate: 0.00056634
	LOSS [training: 0.11021823567045327 | validation: 0.13054012347694144]
	TIME [epoch: 32.7 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1126212664292601		[learning rate: 0.00056409]
	Learning Rate: 0.000564087
	LOSS [training: 0.1126212664292601 | validation: 0.1312606641746881]
	TIME [epoch: 32.6 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10926168303359246		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.10926168303359246 | validation: 0.13150680182219213]
	TIME [epoch: 32.7 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11672782486721449		[learning rate: 0.00055961]
	Learning Rate: 0.000559609
	LOSS [training: 0.11672782486721449 | validation: 0.12612189117566858]
	TIME [epoch: 32.6 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10524361200823325		[learning rate: 0.00055738]
	Learning Rate: 0.000557383
	LOSS [training: 0.10524361200823325 | validation: 0.1287594354952146]
	TIME [epoch: 32.6 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11280245783612723		[learning rate: 0.00055517]
	Learning Rate: 0.000555166
	LOSS [training: 0.11280245783612723 | validation: 0.1259949435604888]
	TIME [epoch: 32.6 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11378445057596097		[learning rate: 0.00055296]
	Learning Rate: 0.000552958
	LOSS [training: 0.11378445057596097 | validation: 0.13008808722133502]
	TIME [epoch: 32.7 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11267101961621745		[learning rate: 0.00055076]
	Learning Rate: 0.000550759
	LOSS [training: 0.11267101961621745 | validation: 0.12485385253295918]
	TIME [epoch: 32.7 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11095980818269364		[learning rate: 0.00054857]
	Learning Rate: 0.000548568
	LOSS [training: 0.11095980818269364 | validation: 0.1270226536944355]
	TIME [epoch: 32.6 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10791229078675413		[learning rate: 0.00054639]
	Learning Rate: 0.000546387
	LOSS [training: 0.10791229078675413 | validation: 0.1270699504294563]
	TIME [epoch: 32.7 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11442339949756336		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.11442339949756336 | validation: 0.12995745624072322]
	TIME [epoch: 32.7 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11243861511180588		[learning rate: 0.00054205]
	Learning Rate: 0.000542049
	LOSS [training: 0.11243861511180588 | validation: 0.12560201959345793]
	TIME [epoch: 32.7 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11343943669058287		[learning rate: 0.00053989]
	Learning Rate: 0.000539893
	LOSS [training: 0.11343943669058287 | validation: 0.12816694970746953]
	TIME [epoch: 32.8 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11585870481175428		[learning rate: 0.00053775]
	Learning Rate: 0.000537746
	LOSS [training: 0.11585870481175428 | validation: 0.12716243108866426]
	TIME [epoch: 32.8 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10992303175914417		[learning rate: 0.00053561]
	Learning Rate: 0.000535607
	LOSS [training: 0.10992303175914417 | validation: 0.12329788814119355]
	TIME [epoch: 32.8 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11214711568031266		[learning rate: 0.00053348]
	Learning Rate: 0.000533477
	LOSS [training: 0.11214711568031266 | validation: 0.12052844837855677]
	TIME [epoch: 32.7 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11372366920633811		[learning rate: 0.00053135]
	Learning Rate: 0.000531355
	LOSS [training: 0.11372366920633811 | validation: 0.1237592990619032]
	TIME [epoch: 32.7 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11247922637213434		[learning rate: 0.00052924]
	Learning Rate: 0.000529241
	LOSS [training: 0.11247922637213434 | validation: 0.12833004535672338]
	TIME [epoch: 32.8 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11677469788521101		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.11677469788521101 | validation: 0.12642773665748047]
	TIME [epoch: 32.7 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1136300470071147		[learning rate: 0.00052504]
	Learning Rate: 0.00052504
	LOSS [training: 0.1136300470071147 | validation: 0.12162672709924638]
	TIME [epoch: 32.7 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11150966123097798		[learning rate: 0.00052295]
	Learning Rate: 0.000522952
	LOSS [training: 0.11150966123097798 | validation: 0.12404266251933187]
	TIME [epoch: 32.7 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11643006478385397		[learning rate: 0.00052087]
	Learning Rate: 0.000520872
	LOSS [training: 0.11643006478385397 | validation: 0.12776102517638782]
	TIME [epoch: 32.7 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1094148830339757		[learning rate: 0.0005188]
	Learning Rate: 0.0005188
	LOSS [training: 0.1094148830339757 | validation: 0.13096342217711174]
	TIME [epoch: 32.7 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1159256794092177		[learning rate: 0.00051674]
	Learning Rate: 0.000516737
	LOSS [training: 0.1159256794092177 | validation: 0.1257066892761273]
	TIME [epoch: 32.7 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10939835314786445		[learning rate: 0.00051468]
	Learning Rate: 0.000514681
	LOSS [training: 0.10939835314786445 | validation: 0.12511113260073556]
	TIME [epoch: 32.7 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11266953220289865		[learning rate: 0.00051263]
	Learning Rate: 0.000512634
	LOSS [training: 0.11266953220289865 | validation: 0.13044873846583546]
	TIME [epoch: 32.6 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11105493153088447		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.11105493153088447 | validation: 0.12424165355138124]
	TIME [epoch: 32.7 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10989361109047233		[learning rate: 0.00050856]
	Learning Rate: 0.000508565
	LOSS [training: 0.10989361109047233 | validation: 0.12571856706526735]
	TIME [epoch: 32.7 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10856273923167598		[learning rate: 0.00050654]
	Learning Rate: 0.000506542
	LOSS [training: 0.10856273923167598 | validation: 0.13203004162325166]
	TIME [epoch: 32.7 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12066781198863286		[learning rate: 0.00050453]
	Learning Rate: 0.000504527
	LOSS [training: 0.12066781198863286 | validation: 0.1293560639168239]
	TIME [epoch: 32.6 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11037909437078028		[learning rate: 0.00050252]
	Learning Rate: 0.000502521
	LOSS [training: 0.11037909437078028 | validation: 0.1274745375628478]
	TIME [epoch: 32.7 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11520645614149805		[learning rate: 0.00050052]
	Learning Rate: 0.000500522
	LOSS [training: 0.11520645614149805 | validation: 0.1340570530383779]
	TIME [epoch: 32.7 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12452346033490475		[learning rate: 0.00049853]
	Learning Rate: 0.000498531
	LOSS [training: 0.12452346033490475 | validation: 0.13162474994056644]
	TIME [epoch: 32.7 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11758066199612552		[learning rate: 0.00049655]
	Learning Rate: 0.000496548
	LOSS [training: 0.11758066199612552 | validation: 0.1314557212425398]
	TIME [epoch: 32.6 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10625769429734114		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.10625769429734114 | validation: 0.1248301424501637]
	TIME [epoch: 32.6 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11091405231199013		[learning rate: 0.00049261]
	Learning Rate: 0.000492606
	LOSS [training: 0.11091405231199013 | validation: 0.12207120462902873]
	TIME [epoch: 32.7 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10862441888102364		[learning rate: 0.00049065]
	Learning Rate: 0.000490647
	LOSS [training: 0.10862441888102364 | validation: 0.12853031292455902]
	TIME [epoch: 32.6 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11312861615741499		[learning rate: 0.0004887]
	Learning Rate: 0.000488696
	LOSS [training: 0.11312861615741499 | validation: 0.119227369434548]
	TIME [epoch: 32.7 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_802.pth
	Model improved!!!
EPOCH 803/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11479844336769984		[learning rate: 0.00048675]
	Learning Rate: 0.000486752
	LOSS [training: 0.11479844336769984 | validation: 0.13052644546129652]
	TIME [epoch: 32.6 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12154382690695921		[learning rate: 0.00048482]
	Learning Rate: 0.000484816
	LOSS [training: 0.12154382690695921 | validation: 0.12732135040422907]
	TIME [epoch: 32.7 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1112512837947077		[learning rate: 0.00048289]
	Learning Rate: 0.000482888
	LOSS [training: 0.1112512837947077 | validation: 0.12518593922251645]
	TIME [epoch: 32.7 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10687297614879353		[learning rate: 0.00048097]
	Learning Rate: 0.000480967
	LOSS [training: 0.10687297614879353 | validation: 0.12731149952121829]
	TIME [epoch: 32.7 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11521978145529126		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.11521978145529126 | validation: 0.13371019308511337]
	TIME [epoch: 32.7 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10741209808248968		[learning rate: 0.00047715]
	Learning Rate: 0.000477149
	LOSS [training: 0.10741209808248968 | validation: 0.12821197479589333]
	TIME [epoch: 32.7 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11214063596195446		[learning rate: 0.00047525]
	Learning Rate: 0.000475251
	LOSS [training: 0.11214063596195446 | validation: 0.1257232553224134]
	TIME [epoch: 32.7 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11596745131565392		[learning rate: 0.00047336]
	Learning Rate: 0.000473361
	LOSS [training: 0.11596745131565392 | validation: 0.12191366039436898]
	TIME [epoch: 32.7 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11005430359993099		[learning rate: 0.00047148]
	Learning Rate: 0.000471478
	LOSS [training: 0.11005430359993099 | validation: 0.12989522973923942]
	TIME [epoch: 32.7 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11243456893662897		[learning rate: 0.0004696]
	Learning Rate: 0.000469603
	LOSS [training: 0.11243456893662897 | validation: 0.13186685070583704]
	TIME [epoch: 32.7 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10931920206205407		[learning rate: 0.00046774]
	Learning Rate: 0.000467735
	LOSS [training: 0.10931920206205407 | validation: 0.12556540106502237]
	TIME [epoch: 32.7 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10802021588343008		[learning rate: 0.00046587]
	Learning Rate: 0.000465875
	LOSS [training: 0.10802021588343008 | validation: 0.12426900235583456]
	TIME [epoch: 32.6 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11050709625623785		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.11050709625623785 | validation: 0.13009253204511584]
	TIME [epoch: 32.7 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1142417411843616		[learning rate: 0.00046218]
	Learning Rate: 0.000462176
	LOSS [training: 0.1142417411843616 | validation: 0.12454587703279466]
	TIME [epoch: 32.6 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10938806644777592		[learning rate: 0.00046034]
	Learning Rate: 0.000460338
	LOSS [training: 0.10938806644777592 | validation: 0.12622764800048217]
	TIME [epoch: 32.6 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10456524895349058		[learning rate: 0.00045851]
	Learning Rate: 0.000458507
	LOSS [training: 0.10456524895349058 | validation: 0.1315558739070491]
	TIME [epoch: 32.7 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11273891638820116		[learning rate: 0.00045668]
	Learning Rate: 0.000456684
	LOSS [training: 0.11273891638820116 | validation: 0.12520423359667915]
	TIME [epoch: 32.8 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10904022097946872		[learning rate: 0.00045487]
	Learning Rate: 0.000454867
	LOSS [training: 0.10904022097946872 | validation: 0.12341778767807683]
	TIME [epoch: 32.7 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11066299085125143		[learning rate: 0.00045306]
	Learning Rate: 0.000453058
	LOSS [training: 0.11066299085125143 | validation: 0.1300468235151356]
	TIME [epoch: 32.6 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10756854311052796		[learning rate: 0.00045126]
	Learning Rate: 0.000451256
	LOSS [training: 0.10756854311052796 | validation: 0.1270381498959805]
	TIME [epoch: 32.7 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11114181265729045		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.11114181265729045 | validation: 0.12769793528110282]
	TIME [epoch: 32.7 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11442971672488943		[learning rate: 0.00044767]
	Learning Rate: 0.000447674
	LOSS [training: 0.11442971672488943 | validation: 0.12694465083862844]
	TIME [epoch: 32.7 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10509014097601897		[learning rate: 0.00044589]
	Learning Rate: 0.000445893
	LOSS [training: 0.10509014097601897 | validation: 0.12828854316887223]
	TIME [epoch: 32.7 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11124537234353721		[learning rate: 0.00044412]
	Learning Rate: 0.00044412
	LOSS [training: 0.11124537234353721 | validation: 0.13498699041362155]
	TIME [epoch: 32.7 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11715479863569232		[learning rate: 0.00044235]
	Learning Rate: 0.000442353
	LOSS [training: 0.11715479863569232 | validation: 0.13485553405902856]
	TIME [epoch: 32.7 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11067952903965854		[learning rate: 0.00044059]
	Learning Rate: 0.000440594
	LOSS [training: 0.11067952903965854 | validation: 0.12762117787985616]
	TIME [epoch: 32.7 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12043498748243928		[learning rate: 0.00043884]
	Learning Rate: 0.000438842
	LOSS [training: 0.12043498748243928 | validation: 0.12586956644709327]
	TIME [epoch: 32.7 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11407895424699671		[learning rate: 0.0004371]
	Learning Rate: 0.000437096
	LOSS [training: 0.11407895424699671 | validation: 0.1250774420366493]
	TIME [epoch: 32.7 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11932763119912645		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.11932763119912645 | validation: 0.12979791970858845]
	TIME [epoch: 32.7 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10499951272585381		[learning rate: 0.00043363]
	Learning Rate: 0.000433626
	LOSS [training: 0.10499951272585381 | validation: 0.12740138840065102]
	TIME [epoch: 32.7 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10917549951332964		[learning rate: 0.0004319]
	Learning Rate: 0.000431901
	LOSS [training: 0.10917549951332964 | validation: 0.12772201024485202]
	TIME [epoch: 32.8 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10970732407892655		[learning rate: 0.00043018]
	Learning Rate: 0.000430184
	LOSS [training: 0.10970732407892655 | validation: 0.12808316454517213]
	TIME [epoch: 32.8 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10711180790873659		[learning rate: 0.00042847]
	Learning Rate: 0.000428473
	LOSS [training: 0.10711180790873659 | validation: 0.12586327442886666]
	TIME [epoch: 32.7 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10799092855406567		[learning rate: 0.00042677]
	Learning Rate: 0.000426768
	LOSS [training: 0.10799092855406567 | validation: 0.1279690041882536]
	TIME [epoch: 32.7 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10924537512377594		[learning rate: 0.00042507]
	Learning Rate: 0.000425071
	LOSS [training: 0.10924537512377594 | validation: 0.13143751995832656]
	TIME [epoch: 32.6 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11273184157907003		[learning rate: 0.00042338]
	Learning Rate: 0.00042338
	LOSS [training: 0.11273184157907003 | validation: 0.13029253128464288]
	TIME [epoch: 32.6 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11023157666886292		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.11023157666886292 | validation: 0.12225774496816058]
	TIME [epoch: 32.7 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10671608354821156		[learning rate: 0.00042002]
	Learning Rate: 0.000420019
	LOSS [training: 0.10671608354821156 | validation: 0.12434537772851666]
	TIME [epoch: 32.6 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11393570530702846		[learning rate: 0.00041835]
	Learning Rate: 0.000418349
	LOSS [training: 0.11393570530702846 | validation: 0.12310043980340934]
	TIME [epoch: 32.7 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10972559025812686		[learning rate: 0.00041668]
	Learning Rate: 0.000416685
	LOSS [training: 0.10972559025812686 | validation: 0.12222102921895835]
	TIME [epoch: 32.6 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11356128071694939		[learning rate: 0.00041503]
	Learning Rate: 0.000415028
	LOSS [training: 0.11356128071694939 | validation: 0.1341142188576574]
	TIME [epoch: 32.7 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11509184155644799		[learning rate: 0.00041338]
	Learning Rate: 0.000413377
	LOSS [training: 0.11509184155644799 | validation: 0.13068901015711626]
	TIME [epoch: 32.7 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10957502973161354		[learning rate: 0.00041173]
	Learning Rate: 0.000411733
	LOSS [training: 0.10957502973161354 | validation: 0.12708623067452743]
	TIME [epoch: 32.6 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10894197824456153		[learning rate: 0.0004101]
	Learning Rate: 0.000410095
	LOSS [training: 0.10894197824456153 | validation: 0.12457096097898565]
	TIME [epoch: 32.6 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11487814164958128		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.11487814164958128 | validation: 0.12748819436693043]
	TIME [epoch: 32.7 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10770524386409303		[learning rate: 0.00040684]
	Learning Rate: 0.00040684
	LOSS [training: 0.10770524386409303 | validation: 0.1312419520312284]
	TIME [epoch: 32.7 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10740128252789541		[learning rate: 0.00040522]
	Learning Rate: 0.000405221
	LOSS [training: 0.10740128252789541 | validation: 0.12017643443749323]
	TIME [epoch: 32.7 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12036904055205265		[learning rate: 0.00040361]
	Learning Rate: 0.00040361
	LOSS [training: 0.12036904055205265 | validation: 0.12302978689750046]
	TIME [epoch: 32.7 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11082901809888267		[learning rate: 0.000402]
	Learning Rate: 0.000402004
	LOSS [training: 0.11082901809888267 | validation: 0.12405815428318694]
	TIME [epoch: 32.7 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11971741480658017		[learning rate: 0.00040041]
	Learning Rate: 0.000400406
	LOSS [training: 0.11971741480658017 | validation: 0.13302089988129176]
	TIME [epoch: 32.7 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10876831076516282		[learning rate: 0.00039881]
	Learning Rate: 0.000398813
	LOSS [training: 0.10876831076516282 | validation: 0.1363260888444915]
	TIME [epoch: 32.6 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10595673094485075		[learning rate: 0.00039723]
	Learning Rate: 0.000397227
	LOSS [training: 0.10595673094485075 | validation: 0.12853867571853242]
	TIME [epoch: 32.7 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1117770137336863		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.1117770137336863 | validation: 0.12159133314039386]
	TIME [epoch: 32.7 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11081947856218496		[learning rate: 0.00039407]
	Learning Rate: 0.000394073
	LOSS [training: 0.11081947856218496 | validation: 0.13374375778282527]
	TIME [epoch: 32.7 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10637973287939952		[learning rate: 0.00039251]
	Learning Rate: 0.000392506
	LOSS [training: 0.10637973287939952 | validation: 0.12892315820465367]
	TIME [epoch: 32.6 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10871280475689585		[learning rate: 0.00039094]
	Learning Rate: 0.000390945
	LOSS [training: 0.10871280475689585 | validation: 0.12684887250393367]
	TIME [epoch: 32.6 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10463016864179604		[learning rate: 0.00038939]
	Learning Rate: 0.00038939
	LOSS [training: 0.10463016864179604 | validation: 0.1334367165305395]
	TIME [epoch: 32.6 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11408920591892145		[learning rate: 0.00038784]
	Learning Rate: 0.000387841
	LOSS [training: 0.11408920591892145 | validation: 0.1230702278193964]
	TIME [epoch: 32.7 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11058783593399685		[learning rate: 0.0003863]
	Learning Rate: 0.000386299
	LOSS [training: 0.11058783593399685 | validation: 0.12968817205340832]
	TIME [epoch: 32.6 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11418861427028831		[learning rate: 0.00038476]
	Learning Rate: 0.000384762
	LOSS [training: 0.11418861427028831 | validation: 0.1322485778383187]
	TIME [epoch: 32.6 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10542062950647418		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.10542062950647418 | validation: 0.12069464866199989]
	TIME [epoch: 32.7 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1110909184494867		[learning rate: 0.00038171]
	Learning Rate: 0.000381708
	LOSS [training: 0.1110909184494867 | validation: 0.1285579196281925]
	TIME [epoch: 32.6 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10039301123476846		[learning rate: 0.00038019]
	Learning Rate: 0.000380189
	LOSS [training: 0.10039301123476846 | validation: 0.1269154866628996]
	TIME [epoch: 32.6 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10669624293200505		[learning rate: 0.00037868]
	Learning Rate: 0.000378677
	LOSS [training: 0.10669624293200505 | validation: 0.13191940929301166]
	TIME [epoch: 32.7 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11146738740660547		[learning rate: 0.00037717]
	Learning Rate: 0.000377171
	LOSS [training: 0.11146738740660547 | validation: 0.12823314086879128]
	TIME [epoch: 32.7 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11195868336179375		[learning rate: 0.00037567]
	Learning Rate: 0.000375671
	LOSS [training: 0.11195868336179375 | validation: 0.1261105329246975]
	TIME [epoch: 32.7 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1096421357176275		[learning rate: 0.00037418]
	Learning Rate: 0.000374177
	LOSS [training: 0.1096421357176275 | validation: 0.12055799173436563]
	TIME [epoch: 32.7 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11275782394356851		[learning rate: 0.00037269]
	Learning Rate: 0.000372689
	LOSS [training: 0.11275782394356851 | validation: 0.12128101221026535]
	TIME [epoch: 32.7 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1076774631404484		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.1076774631404484 | validation: 0.12751879765015892]
	TIME [epoch: 32.6 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10574837684581088		[learning rate: 0.00036973]
	Learning Rate: 0.00036973
	LOSS [training: 0.10574837684581088 | validation: 0.12684794478841793]
	TIME [epoch: 32.7 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10977495754814942		[learning rate: 0.00036826]
	Learning Rate: 0.000368259
	LOSS [training: 0.10977495754814942 | validation: 0.13192597175737014]
	TIME [epoch: 32.7 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1095279288478223		[learning rate: 0.00036679]
	Learning Rate: 0.000366795
	LOSS [training: 0.1095279288478223 | validation: 0.12446373728438856]
	TIME [epoch: 32.7 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1102666208666458		[learning rate: 0.00036534]
	Learning Rate: 0.000365336
	LOSS [training: 0.1102666208666458 | validation: 0.12776468654183945]
	TIME [epoch: 32.6 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10595911334062903		[learning rate: 0.00036388]
	Learning Rate: 0.000363883
	LOSS [training: 0.10595911334062903 | validation: 0.1264559869287984]
	TIME [epoch: 32.6 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10898829229534522		[learning rate: 0.00036244]
	Learning Rate: 0.000362436
	LOSS [training: 0.10898829229534522 | validation: 0.1270575424905196]
	TIME [epoch: 32.7 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10463786068750475		[learning rate: 0.00036099]
	Learning Rate: 0.000360994
	LOSS [training: 0.10463786068750475 | validation: 0.13149770987958403]
	TIME [epoch: 32.7 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11647246781945844		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.11647246781945844 | validation: 0.12178899315332141]
	TIME [epoch: 32.7 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10813046284123798		[learning rate: 0.00035813]
	Learning Rate: 0.000358128
	LOSS [training: 0.10813046284123798 | validation: 0.12459864929706843]
	TIME [epoch: 32.6 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11080304987940409		[learning rate: 0.0003567]
	Learning Rate: 0.000356704
	LOSS [training: 0.11080304987940409 | validation: 0.12934160997490682]
	TIME [epoch: 32.7 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11029904666066577		[learning rate: 0.00035529]
	Learning Rate: 0.000355285
	LOSS [training: 0.11029904666066577 | validation: 0.12821074353458936]
	TIME [epoch: 32.7 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10886969107203416		[learning rate: 0.00035387]
	Learning Rate: 0.000353872
	LOSS [training: 0.10886969107203416 | validation: 0.12687983575677092]
	TIME [epoch: 32.6 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10851486228102895		[learning rate: 0.00035246]
	Learning Rate: 0.000352465
	LOSS [training: 0.10851486228102895 | validation: 0.12717558303579887]
	TIME [epoch: 32.6 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10816121555224562		[learning rate: 0.00035106]
	Learning Rate: 0.000351063
	LOSS [training: 0.10816121555224562 | validation: 0.13095593667625965]
	TIME [epoch: 32.6 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11461712537438672		[learning rate: 0.00034967]
	Learning Rate: 0.000349666
	LOSS [training: 0.11461712537438672 | validation: 0.12712829834241518]
	TIME [epoch: 32.6 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11631185746815478		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.11631185746815478 | validation: 0.12401244226709007]
	TIME [epoch: 32.6 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11179222374854009		[learning rate: 0.00034689]
	Learning Rate: 0.000346891
	LOSS [training: 0.11179222374854009 | validation: 0.12444837906612989]
	TIME [epoch: 32.6 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1199005634379246		[learning rate: 0.00034551]
	Learning Rate: 0.000345511
	LOSS [training: 0.1199005634379246 | validation: 0.13017461319347795]
	TIME [epoch: 32.6 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1141005000774491		[learning rate: 0.00034414]
	Learning Rate: 0.000344137
	LOSS [training: 0.1141005000774491 | validation: 0.1294607565079467]
	TIME [epoch: 32.6 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10589507219243541		[learning rate: 0.00034277]
	Learning Rate: 0.000342768
	LOSS [training: 0.10589507219243541 | validation: 0.1253692096301799]
	TIME [epoch: 32.6 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10844728014068182		[learning rate: 0.0003414]
	Learning Rate: 0.000341405
	LOSS [training: 0.10844728014068182 | validation: 0.1299532993672716]
	TIME [epoch: 32.7 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11626075151228273		[learning rate: 0.00034005]
	Learning Rate: 0.000340047
	LOSS [training: 0.11626075151228273 | validation: 0.12671693577582893]
	TIME [epoch: 32.6 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10539138892923096		[learning rate: 0.00033869]
	Learning Rate: 0.000338694
	LOSS [training: 0.10539138892923096 | validation: 0.12786807506307105]
	TIME [epoch: 32.6 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11309915593535133		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.11309915593535133 | validation: 0.1286224018625492]
	TIME [epoch: 32.6 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10817058634126732		[learning rate: 0.00033601]
	Learning Rate: 0.000336005
	LOSS [training: 0.10817058634126732 | validation: 0.13161622703872772]
	TIME [epoch: 32.7 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11003318806337894		[learning rate: 0.00033467]
	Learning Rate: 0.000334669
	LOSS [training: 0.11003318806337894 | validation: 0.11955297522945504]
	TIME [epoch: 32.7 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11080159629628238		[learning rate: 0.00033334]
	Learning Rate: 0.000333338
	LOSS [training: 0.11080159629628238 | validation: 0.1252135759507193]
	TIME [epoch: 32.7 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11736455903066724		[learning rate: 0.00033201]
	Learning Rate: 0.000332012
	LOSS [training: 0.11736455903066724 | validation: 0.12577042563357893]
	TIME [epoch: 32.6 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11735767608854074		[learning rate: 0.00033069]
	Learning Rate: 0.000330692
	LOSS [training: 0.11735767608854074 | validation: 0.12896332980273786]
	TIME [epoch: 32.7 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10921638763618104		[learning rate: 0.00032938]
	Learning Rate: 0.000329376
	LOSS [training: 0.10921638763618104 | validation: 0.12498012197660605]
	TIME [epoch: 32.7 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11243929516052947		[learning rate: 0.00032807]
	Learning Rate: 0.000328066
	LOSS [training: 0.11243929516052947 | validation: 0.12149144271130177]
	TIME [epoch: 32.6 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10803070048607949		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.10803070048607949 | validation: 0.12158634648096045]
	TIME [epoch: 32.6 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10440081439888872		[learning rate: 0.00032546]
	Learning Rate: 0.000325462
	LOSS [training: 0.10440081439888872 | validation: 0.12713123942005883]
	TIME [epoch: 32.7 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12606118237172484		[learning rate: 0.00032417]
	Learning Rate: 0.000324167
	LOSS [training: 0.12606118237172484 | validation: 0.12653622816351204]
	TIME [epoch: 32.7 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1133070111997228		[learning rate: 0.00032288]
	Learning Rate: 0.000322878
	LOSS [training: 0.1133070111997228 | validation: 0.13254344121060163]
	TIME [epoch: 32.7 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11285867478644102		[learning rate: 0.00032159]
	Learning Rate: 0.000321594
	LOSS [training: 0.11285867478644102 | validation: 0.12299707034138754]
	TIME [epoch: 32.6 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11121996697421313		[learning rate: 0.00032031]
	Learning Rate: 0.000320315
	LOSS [training: 0.11121996697421313 | validation: 0.12783008240383695]
	TIME [epoch: 32.6 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10452716644583565		[learning rate: 0.00031904]
	Learning Rate: 0.000319041
	LOSS [training: 0.10452716644583565 | validation: 0.12576773005936343]
	TIME [epoch: 32.7 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11002393403272304		[learning rate: 0.00031777]
	Learning Rate: 0.000317772
	LOSS [training: 0.11002393403272304 | validation: 0.12605537414295936]
	TIME [epoch: 32.7 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11081225703873573		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.11081225703873573 | validation: 0.1337473899240121]
	TIME [epoch: 32.7 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11186475073042443		[learning rate: 0.00031525]
	Learning Rate: 0.000315249
	LOSS [training: 0.11186475073042443 | validation: 0.1276636270198392]
	TIME [epoch: 32.6 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.112135240244881		[learning rate: 0.000314]
	Learning Rate: 0.000313995
	LOSS [training: 0.112135240244881 | validation: 0.1291659533709033]
	TIME [epoch: 32.7 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10755951384377105		[learning rate: 0.00031275]
	Learning Rate: 0.000312746
	LOSS [training: 0.10755951384377105 | validation: 0.1289737842767043]
	TIME [epoch: 32.7 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11462087309777898		[learning rate: 0.0003115]
	Learning Rate: 0.000311503
	LOSS [training: 0.11462087309777898 | validation: 0.13199387709017052]
	TIME [epoch: 32.7 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11138616925741299		[learning rate: 0.00031026]
	Learning Rate: 0.000310264
	LOSS [training: 0.11138616925741299 | validation: 0.12743067658561205]
	TIME [epoch: 32.7 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11585967881324749		[learning rate: 0.00030903]
	Learning Rate: 0.00030903
	LOSS [training: 0.11585967881324749 | validation: 0.12461368610282826]
	TIME [epoch: 32.7 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10857243779399636		[learning rate: 0.0003078]
	Learning Rate: 0.0003078
	LOSS [training: 0.10857243779399636 | validation: 0.11805679875464987]
	TIME [epoch: 32.7 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_918.pth
	Model improved!!!
EPOCH 919/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11243643361680518		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.11243643361680518 | validation: 0.1335779137748917]
	TIME [epoch: 32.6 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10808129701805418		[learning rate: 0.00030536]
	Learning Rate: 0.000305357
	LOSS [training: 0.10808129701805418 | validation: 0.12293144851904503]
	TIME [epoch: 32.7 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10325937605190456		[learning rate: 0.00030414]
	Learning Rate: 0.000304142
	LOSS [training: 0.10325937605190456 | validation: 0.12808481183552384]
	TIME [epoch: 32.7 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11904319123279622		[learning rate: 0.00030293]
	Learning Rate: 0.000302933
	LOSS [training: 0.11904319123279622 | validation: 0.12027482522939223]
	TIME [epoch: 32.6 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11043289208145365		[learning rate: 0.00030173]
	Learning Rate: 0.000301728
	LOSS [training: 0.11043289208145365 | validation: 0.1296731544781347]
	TIME [epoch: 32.6 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10789573327122406		[learning rate: 0.00030053]
	Learning Rate: 0.000300528
	LOSS [training: 0.10789573327122406 | validation: 0.12323511568635466]
	TIME [epoch: 32.6 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11246421441576045		[learning rate: 0.00029933]
	Learning Rate: 0.000299333
	LOSS [training: 0.11246421441576045 | validation: 0.13180331698913395]
	TIME [epoch: 32.7 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11380534194169195		[learning rate: 0.00029814]
	Learning Rate: 0.000298142
	LOSS [training: 0.11380534194169195 | validation: 0.11934643425734152]
	TIME [epoch: 32.7 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10543324426127704		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.10543324426127704 | validation: 0.1265249440401745]
	TIME [epoch: 32.6 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11164138689913145		[learning rate: 0.00029578]
	Learning Rate: 0.000295775
	LOSS [training: 0.11164138689913145 | validation: 0.13102424982119798]
	TIME [epoch: 32.6 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1069272070338695		[learning rate: 0.0002946]
	Learning Rate: 0.000294599
	LOSS [training: 0.1069272070338695 | validation: 0.12828670683516358]
	TIME [epoch: 32.7 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11110593203423089		[learning rate: 0.00029343]
	Learning Rate: 0.000293427
	LOSS [training: 0.11110593203423089 | validation: 0.12365937720144642]
	TIME [epoch: 32.6 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11798997813224966		[learning rate: 0.00029226]
	Learning Rate: 0.00029226
	LOSS [training: 0.11798997813224966 | validation: 0.13139913925598745]
	TIME [epoch: 32.7 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11173647537080576		[learning rate: 0.0002911]
	Learning Rate: 0.000291098
	LOSS [training: 0.11173647537080576 | validation: 0.1265200417275437]
	TIME [epoch: 32.7 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1078240374550839		[learning rate: 0.00028994]
	Learning Rate: 0.00028994
	LOSS [training: 0.1078240374550839 | validation: 0.12496979004152353]
	TIME [epoch: 32.7 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10377828178878615		[learning rate: 0.00028879]
	Learning Rate: 0.000288786
	LOSS [training: 0.10377828178878615 | validation: 0.12615067993080092]
	TIME [epoch: 32.7 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10626678796006585		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.10626678796006585 | validation: 0.13319933735404682]
	TIME [epoch: 32.7 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10597650203808194		[learning rate: 0.00028649]
	Learning Rate: 0.000286494
	LOSS [training: 0.10597650203808194 | validation: 0.12182044530361222]
	TIME [epoch: 32.8 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11567983377385392		[learning rate: 0.00028535]
	Learning Rate: 0.000285354
	LOSS [training: 0.11567983377385392 | validation: 0.12326674775574295]
	TIME [epoch: 32.7 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11643133102003672		[learning rate: 0.00028422]
	Learning Rate: 0.00028422
	LOSS [training: 0.11643133102003672 | validation: 0.13074828922850246]
	TIME [epoch: 32.7 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10684249312524896		[learning rate: 0.00028309]
	Learning Rate: 0.000283089
	LOSS [training: 0.10684249312524896 | validation: 0.12768483862383495]
	TIME [epoch: 32.7 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11386608174247331		[learning rate: 0.00028196]
	Learning Rate: 0.000281963
	LOSS [training: 0.11386608174247331 | validation: 0.12446885905614749]
	TIME [epoch: 32.7 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1088611284176824		[learning rate: 0.00028084]
	Learning Rate: 0.000280842
	LOSS [training: 0.1088611284176824 | validation: 0.1270922536446047]
	TIME [epoch: 32.7 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10306310842012029		[learning rate: 0.00027972]
	Learning Rate: 0.000279725
	LOSS [training: 0.10306310842012029 | validation: 0.12781756044087683]
	TIME [epoch: 32.7 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10838364184617637		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.10838364184617637 | validation: 0.1256453495879073]
	TIME [epoch: 32.7 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11242902674964451		[learning rate: 0.0002775]
	Learning Rate: 0.000277504
	LOSS [training: 0.11242902674964451 | validation: 0.12537670089470235]
	TIME [epoch: 32.8 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.09896178760749273		[learning rate: 0.0002764]
	Learning Rate: 0.0002764
	LOSS [training: 0.09896178760749273 | validation: 0.12628181945127753]
	TIME [epoch: 32.7 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11262641938385351		[learning rate: 0.0002753]
	Learning Rate: 0.000275301
	LOSS [training: 0.11262641938385351 | validation: 0.13396143562396773]
	TIME [epoch: 32.6 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10668004426036133		[learning rate: 0.00027421]
	Learning Rate: 0.000274206
	LOSS [training: 0.10668004426036133 | validation: 0.12688002843144353]
	TIME [epoch: 32.8 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11155457258920182		[learning rate: 0.00027312]
	Learning Rate: 0.000273115
	LOSS [training: 0.11155457258920182 | validation: 0.12701811624654433]
	TIME [epoch: 32.7 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10755832488094835		[learning rate: 0.00027203]
	Learning Rate: 0.000272029
	LOSS [training: 0.10755832488094835 | validation: 0.1280441934407803]
	TIME [epoch: 32.7 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10269275817746576		[learning rate: 0.00027095]
	Learning Rate: 0.000270947
	LOSS [training: 0.10269275817746576 | validation: 0.1271927246816397]
	TIME [epoch: 32.7 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11695737150889401		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.11695737150889401 | validation: 0.1309082318458384]
	TIME [epoch: 32.7 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11073795005519353		[learning rate: 0.0002688]
	Learning Rate: 0.000268796
	LOSS [training: 0.11073795005519353 | validation: 0.1257142015141241]
	TIME [epoch: 32.7 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1108654513986874		[learning rate: 0.00026773]
	Learning Rate: 0.000267727
	LOSS [training: 0.1108654513986874 | validation: 0.11998264254091104]
	TIME [epoch: 32.7 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11163636761432588		[learning rate: 0.00026666]
	Learning Rate: 0.000266662
	LOSS [training: 0.11163636761432588 | validation: 0.1232473993087578]
	TIME [epoch: 32.7 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11525060509532281		[learning rate: 0.0002656]
	Learning Rate: 0.000265602
	LOSS [training: 0.11525060509532281 | validation: 0.12404231388248785]
	TIME [epoch: 32.7 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11741613283038091		[learning rate: 0.00026455]
	Learning Rate: 0.000264545
	LOSS [training: 0.11741613283038091 | validation: 0.12614520576541718]
	TIME [epoch: 32.6 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10898009862349466		[learning rate: 0.00026349]
	Learning Rate: 0.000263493
	LOSS [training: 0.10898009862349466 | validation: 0.12854297635031636]
	TIME [epoch: 32.6 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1042164268947346		[learning rate: 0.00026245]
	Learning Rate: 0.000262445
	LOSS [training: 0.1042164268947346 | validation: 0.12260256384211429]
	TIME [epoch: 32.7 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11258490598988224		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.11258490598988224 | validation: 0.1328490720595175]
	TIME [epoch: 32.7 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10613984050607184		[learning rate: 0.00026036]
	Learning Rate: 0.000260362
	LOSS [training: 0.10613984050607184 | validation: 0.12569432501452904]
	TIME [epoch: 32.7 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10744007990822904		[learning rate: 0.00025933]
	Learning Rate: 0.000259326
	LOSS [training: 0.10744007990822904 | validation: 0.12473921837446755]
	TIME [epoch: 32.6 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11859808698227667		[learning rate: 0.00025829]
	Learning Rate: 0.000258295
	LOSS [training: 0.11859808698227667 | validation: 0.12300298656210626]
	TIME [epoch: 32.6 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11193126732169786		[learning rate: 0.00025727]
	Learning Rate: 0.000257267
	LOSS [training: 0.11193126732169786 | validation: 0.13073905353618076]
	TIME [epoch: 32.6 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11672001255249476		[learning rate: 0.00025624]
	Learning Rate: 0.000256244
	LOSS [training: 0.11672001255249476 | validation: 0.1283727305471434]
	TIME [epoch: 32.6 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11142343652454285		[learning rate: 0.00025522]
	Learning Rate: 0.000255225
	LOSS [training: 0.11142343652454285 | validation: 0.13438769774759754]
	TIME [epoch: 32.7 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10857494358268889		[learning rate: 0.00025421]
	Learning Rate: 0.00025421
	LOSS [training: 0.10857494358268889 | validation: 0.119763906035867]
	TIME [epoch: 32.6 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11453261459655627		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.11453261459655627 | validation: 0.13396261753125252]
	TIME [epoch: 32.7 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11803354344753611		[learning rate: 0.00025219]
	Learning Rate: 0.000252192
	LOSS [training: 0.11803354344753611 | validation: 0.12872268975290158]
	TIME [epoch: 32.6 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10733035854750683		[learning rate: 0.00025119]
	Learning Rate: 0.000251189
	LOSS [training: 0.10733035854750683 | validation: 0.1264652403245295]
	TIME [epoch: 32.7 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1102874746432184		[learning rate: 0.00025019]
	Learning Rate: 0.00025019
	LOSS [training: 0.1102874746432184 | validation: 0.13050722321745106]
	TIME [epoch: 32.6 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11069924886197767		[learning rate: 0.00024919]
	Learning Rate: 0.000249195
	LOSS [training: 0.11069924886197767 | validation: 0.12370412590360658]
	TIME [epoch: 32.7 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11654010779138442		[learning rate: 0.0002482]
	Learning Rate: 0.000248203
	LOSS [training: 0.11654010779138442 | validation: 0.12194057086804685]
	TIME [epoch: 32.7 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10772593761829419		[learning rate: 0.00024722]
	Learning Rate: 0.000247216
	LOSS [training: 0.10772593761829419 | validation: 0.1270793669249631]
	TIME [epoch: 32.7 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1067030329928054		[learning rate: 0.00024623]
	Learning Rate: 0.000246233
	LOSS [training: 0.1067030329928054 | validation: 0.12374327244590107]
	TIME [epoch: 32.7 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11404882122040744		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.11404882122040744 | validation: 0.12801398454127005]
	TIME [epoch: 32.7 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11242896974998394		[learning rate: 0.00024428]
	Learning Rate: 0.000244278
	LOSS [training: 0.11242896974998394 | validation: 0.12723147563658282]
	TIME [epoch: 32.7 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10688975031784057		[learning rate: 0.00024331]
	Learning Rate: 0.000243307
	LOSS [training: 0.10688975031784057 | validation: 0.12239012871015476]
	TIME [epoch: 32.7 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10724491298258153		[learning rate: 0.00024234]
	Learning Rate: 0.000242339
	LOSS [training: 0.10724491298258153 | validation: 0.13087175510866636]
	TIME [epoch: 32.7 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11364970636934367		[learning rate: 0.00024138]
	Learning Rate: 0.000241375
	LOSS [training: 0.11364970636934367 | validation: 0.1318048008542842]
	TIME [epoch: 32.7 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10582984503472022		[learning rate: 0.00024042]
	Learning Rate: 0.000240415
	LOSS [training: 0.10582984503472022 | validation: 0.1292436374244788]
	TIME [epoch: 32.7 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1073637431613292		[learning rate: 0.00023946]
	Learning Rate: 0.000239459
	LOSS [training: 0.1073637431613292 | validation: 0.12593704648790327]
	TIME [epoch: 32.7 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11003824976209288		[learning rate: 0.00023851]
	Learning Rate: 0.000238506
	LOSS [training: 0.11003824976209288 | validation: 0.12226047409687987]
	TIME [epoch: 32.7 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10785725399342692		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.10785725399342692 | validation: 0.12628652208679134]
	TIME [epoch: 32.7 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10854764585397218		[learning rate: 0.00023661]
	Learning Rate: 0.000236613
	LOSS [training: 0.10854764585397218 | validation: 0.1313439281471999]
	TIME [epoch: 32.7 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1100732025144585		[learning rate: 0.00023567]
	Learning Rate: 0.000235672
	LOSS [training: 0.1100732025144585 | validation: 0.12492716238778871]
	TIME [epoch: 32.7 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10786237713297825		[learning rate: 0.00023473]
	Learning Rate: 0.000234735
	LOSS [training: 0.10786237713297825 | validation: 0.1260869341060889]
	TIME [epoch: 32.7 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11271536016249037		[learning rate: 0.0002338]
	Learning Rate: 0.000233801
	LOSS [training: 0.11271536016249037 | validation: 0.12783860241939973]
	TIME [epoch: 32.7 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11458433056147317		[learning rate: 0.00023287]
	Learning Rate: 0.000232871
	LOSS [training: 0.11458433056147317 | validation: 0.13034750303117243]
	TIME [epoch: 32.8 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10484787649222788		[learning rate: 0.00023194]
	Learning Rate: 0.000231945
	LOSS [training: 0.10484787649222788 | validation: 0.12687606069245957]
	TIME [epoch: 32.7 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11089192482298287		[learning rate: 0.00023102]
	Learning Rate: 0.000231022
	LOSS [training: 0.11089192482298287 | validation: 0.13058432329839306]
	TIME [epoch: 32.7 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10086352718052656		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.10086352718052656 | validation: 0.12809871810028978]
	TIME [epoch: 32.7 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10342791085622077		[learning rate: 0.00022919]
	Learning Rate: 0.000229188
	LOSS [training: 0.10342791085622077 | validation: 0.12789659063276368]
	TIME [epoch: 32.7 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10752077343515348		[learning rate: 0.00022828]
	Learning Rate: 0.000228277
	LOSS [training: 0.10752077343515348 | validation: 0.13438383145342467]
	TIME [epoch: 32.7 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11307698961732898		[learning rate: 0.00022737]
	Learning Rate: 0.000227369
	LOSS [training: 0.11307698961732898 | validation: 0.12968748250150125]
	TIME [epoch: 32.7 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11485986082869117		[learning rate: 0.00022646]
	Learning Rate: 0.000226464
	LOSS [training: 0.11485986082869117 | validation: 0.1211025048821863]
	TIME [epoch: 32.7 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10633262007591537		[learning rate: 0.00022556]
	Learning Rate: 0.000225564
	LOSS [training: 0.10633262007591537 | validation: 0.13459085230287166]
	TIME [epoch: 32.7 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11283785431406056		[learning rate: 0.00022467]
	Learning Rate: 0.000224667
	LOSS [training: 0.11283785431406056 | validation: 0.12040898966195228]
	TIME [epoch: 32.7 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10191241459041646		[learning rate: 0.00022377]
	Learning Rate: 0.000223773
	LOSS [training: 0.10191241459041646 | validation: 0.12928811427052653]
	TIME [epoch: 32.8 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11184868635527397		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.11184868635527397 | validation: 0.13181333400797654]
	TIME [epoch: 32.7 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10180442745304161		[learning rate: 0.000222]
	Learning Rate: 0.000221997
	LOSS [training: 0.10180442745304161 | validation: 0.12877726572757925]
	TIME [epoch: 32.6 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10807904856760156		[learning rate: 0.00022111]
	Learning Rate: 0.000221114
	LOSS [training: 0.10807904856760156 | validation: 0.12391107669800636]
	TIME [epoch: 32.6 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11033938548897078		[learning rate: 0.00022023]
	Learning Rate: 0.000220234
	LOSS [training: 0.11033938548897078 | validation: 0.12582845917321425]
	TIME [epoch: 32.7 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11041361500175437		[learning rate: 0.00021936]
	Learning Rate: 0.000219358
	LOSS [training: 0.11041361500175437 | validation: 0.1253676448936511]
	TIME [epoch: 32.6 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10429700551497453		[learning rate: 0.00021849]
	Learning Rate: 0.000218486
	LOSS [training: 0.10429700551497453 | validation: 0.13516566392397825]
	TIME [epoch: 32.7 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1076770078905699		[learning rate: 0.00021762]
	Learning Rate: 0.000217617
	LOSS [training: 0.1076770078905699 | validation: 0.13122952301274973]
	TIME [epoch: 32.7 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11004645566283824		[learning rate: 0.00021675]
	Learning Rate: 0.000216751
	LOSS [training: 0.11004645566283824 | validation: 0.12923772687630394]
	TIME [epoch: 32.6 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1055581328148348		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.1055581328148348 | validation: 0.12225841369728643]
	TIME [epoch: 32.6 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11266001835801326		[learning rate: 0.00021503]
	Learning Rate: 0.00021503
	LOSS [training: 0.11266001835801326 | validation: 0.1199464549710401]
	TIME [epoch: 32.7 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11656335751667142		[learning rate: 0.00021418]
	Learning Rate: 0.000214175
	LOSS [training: 0.11656335751667142 | validation: 0.12741937575149528]
	TIME [epoch: 32.7 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11061756119889717		[learning rate: 0.00021332]
	Learning Rate: 0.000213323
	LOSS [training: 0.11061756119889717 | validation: 0.1321969255614194]
	TIME [epoch: 32.6 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10706105738815185		[learning rate: 0.00021247]
	Learning Rate: 0.000212475
	LOSS [training: 0.10706105738815185 | validation: 0.12565407081810515]
	TIME [epoch: 32.7 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11078297589683858		[learning rate: 0.00021163]
	Learning Rate: 0.00021163
	LOSS [training: 0.11078297589683858 | validation: 0.12459888565556747]
	TIME [epoch: 32.6 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10867582892317862		[learning rate: 0.00021079]
	Learning Rate: 0.000210788
	LOSS [training: 0.10867582892317862 | validation: 0.13179432322144188]
	TIME [epoch: 32.7 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10904782342754982		[learning rate: 0.00020995]
	Learning Rate: 0.00020995
	LOSS [training: 0.10904782342754982 | validation: 0.1217643971946368]
	TIME [epoch: 32.6 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10875533233993094		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.10875533233993094 | validation: 0.12321184790597735]
	TIME [epoch: 32.7 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10714867152193164		[learning rate: 0.00020828]
	Learning Rate: 0.000208283
	LOSS [training: 0.10714867152193164 | validation: 0.13419247451776906]
	TIME [epoch: 32.7 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10282649417452358		[learning rate: 0.00020745]
	Learning Rate: 0.000207455
	LOSS [training: 0.10282649417452358 | validation: 0.12936985261813713]
	TIME [epoch: 32.7 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10810799119793785		[learning rate: 0.00020663]
	Learning Rate: 0.00020663
	LOSS [training: 0.10810799119793785 | validation: 0.12315659890939874]
	TIME [epoch: 32.6 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10592941021566868		[learning rate: 0.00020581]
	Learning Rate: 0.000205808
	LOSS [training: 0.10592941021566868 | validation: 0.13020731461380625]
	TIME [epoch: 32.6 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10396786415066714		[learning rate: 0.00020499]
	Learning Rate: 0.000204989
	LOSS [training: 0.10396786415066714 | validation: 0.12912622660236467]
	TIME [epoch: 32.7 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12325322350957418		[learning rate: 0.00020417]
	Learning Rate: 0.000204174
	LOSS [training: 0.12325322350957418 | validation: 0.12698061946851363]
	TIME [epoch: 32.7 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11443364241359887		[learning rate: 0.00020336]
	Learning Rate: 0.000203362
	LOSS [training: 0.11443364241359887 | validation: 0.12000966527073911]
	TIME [epoch: 32.6 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1072665106650111		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.1072665106650111 | validation: 0.12300682565131182]
	TIME [epoch: 32.6 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1183762301488871		[learning rate: 0.00020175]
	Learning Rate: 0.000201747
	LOSS [training: 0.1183762301488871 | validation: 0.12976237851065084]
	TIME [epoch: 32.7 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11007017309252344		[learning rate: 0.00020094]
	Learning Rate: 0.000200945
	LOSS [training: 0.11007017309252344 | validation: 0.1300334086439384]
	TIME [epoch: 32.6 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1100047607890568		[learning rate: 0.00020015]
	Learning Rate: 0.000200146
	LOSS [training: 0.1100047607890568 | validation: 0.13029764593704055]
	TIME [epoch: 32.6 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1147969547227348		[learning rate: 0.00019935]
	Learning Rate: 0.00019935
	LOSS [training: 0.1147969547227348 | validation: 0.1309546492587602]
	TIME [epoch: 32.7 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.09810892579969871		[learning rate: 0.00019856]
	Learning Rate: 0.000198557
	LOSS [training: 0.09810892579969871 | validation: 0.13193025242403683]
	TIME [epoch: 32.7 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11126490797228485		[learning rate: 0.00019777]
	Learning Rate: 0.000197767
	LOSS [training: 0.11126490797228485 | validation: 0.13477520183017197]
	TIME [epoch: 32.7 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11764497792195086		[learning rate: 0.00019698]
	Learning Rate: 0.00019698
	LOSS [training: 0.11764497792195086 | validation: 0.12340311722015251]
	TIME [epoch: 32.6 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10306959097387355		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.10306959097387355 | validation: 0.12590439399071163]
	TIME [epoch: 32.7 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10945884533109829		[learning rate: 0.00019542]
	Learning Rate: 0.000195417
	LOSS [training: 0.10945884533109829 | validation: 0.1249390611555328]
	TIME [epoch: 32.7 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1141857575339788		[learning rate: 0.00019464]
	Learning Rate: 0.000194639
	LOSS [training: 0.1141857575339788 | validation: 0.13115090557181247]
	TIME [epoch: 32.7 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12133538547869994		[learning rate: 0.00019387]
	Learning Rate: 0.000193865
	LOSS [training: 0.12133538547869994 | validation: 0.13041420859114455]
	TIME [epoch: 32.7 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10368857166031191		[learning rate: 0.00019309]
	Learning Rate: 0.000193094
	LOSS [training: 0.10368857166031191 | validation: 0.13037138525596065]
	TIME [epoch: 32.8 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10551455995797732		[learning rate: 0.00019233]
	Learning Rate: 0.000192326
	LOSS [training: 0.10551455995797732 | validation: 0.13539351874727884]
	TIME [epoch: 32.7 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11187246409670874		[learning rate: 0.00019156]
	Learning Rate: 0.000191561
	LOSS [training: 0.11187246409670874 | validation: 0.12937848739532115]
	TIME [epoch: 32.7 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10852651737024585		[learning rate: 0.0001908]
	Learning Rate: 0.000190799
	LOSS [training: 0.10852651737024585 | validation: 0.12624645516509128]
	TIME [epoch: 32.7 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11360108817057386		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.11360108817057386 | validation: 0.1292966265292545]
	TIME [epoch: 32.7 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10910227092753905		[learning rate: 0.00018928]
	Learning Rate: 0.000189285
	LOSS [training: 0.10910227092753905 | validation: 0.1183868861092026]
	TIME [epoch: 32.7 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11989127353009904		[learning rate: 0.00018853]
	Learning Rate: 0.000188532
	LOSS [training: 0.11989127353009904 | validation: 0.12100133669529642]
	TIME [epoch: 32.6 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10852860246160907		[learning rate: 0.00018778]
	Learning Rate: 0.000187782
	LOSS [training: 0.10852860246160907 | validation: 0.1345456881679999]
	TIME [epoch: 32.7 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11870038963038614		[learning rate: 0.00018704]
	Learning Rate: 0.000187035
	LOSS [training: 0.11870038963038614 | validation: 0.12692701697702607]
	TIME [epoch: 32.7 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10981412531161391		[learning rate: 0.00018629]
	Learning Rate: 0.000186291
	LOSS [training: 0.10981412531161391 | validation: 0.12478774931257267]
	TIME [epoch: 32.7 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11393561415683195		[learning rate: 0.00018555]
	Learning Rate: 0.00018555
	LOSS [training: 0.11393561415683195 | validation: 0.12802361496702663]
	TIME [epoch: 32.7 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11768924584633132		[learning rate: 0.00018481]
	Learning Rate: 0.000184812
	LOSS [training: 0.11768924584633132 | validation: 0.1229901770340871]
	TIME [epoch: 32.7 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.111608630085522		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.111608630085522 | validation: 0.1279540290642172]
	TIME [epoch: 32.6 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10456190562327612		[learning rate: 0.00018335]
	Learning Rate: 0.000183345
	LOSS [training: 0.10456190562327612 | validation: 0.1263781427535243]
	TIME [epoch: 32.7 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10338493914996051		[learning rate: 0.00018262]
	Learning Rate: 0.000182616
	LOSS [training: 0.10338493914996051 | validation: 0.1286379777560613]
	TIME [epoch: 32.7 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1068670307930637		[learning rate: 0.00018189]
	Learning Rate: 0.00018189
	LOSS [training: 0.1068670307930637 | validation: 0.12732402923731376]
	TIME [epoch: 32.7 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11273641893155559		[learning rate: 0.00018117]
	Learning Rate: 0.000181166
	LOSS [training: 0.11273641893155559 | validation: 0.12291714133559559]
	TIME [epoch: 32.7 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11650904783476311		[learning rate: 0.00018045]
	Learning Rate: 0.000180446
	LOSS [training: 0.11650904783476311 | validation: 0.12730486681990089]
	TIME [epoch: 32.7 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10513005426206361		[learning rate: 0.00017973]
	Learning Rate: 0.000179728
	LOSS [training: 0.10513005426206361 | validation: 0.12587752170552877]
	TIME [epoch: 32.7 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1092572187999977		[learning rate: 0.00017901]
	Learning Rate: 0.000179013
	LOSS [training: 0.1092572187999977 | validation: 0.1230395850479928]
	TIME [epoch: 32.6 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11534508268713463		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.11534508268713463 | validation: 0.12578360356510138]
	TIME [epoch: 32.7 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1013796867352851		[learning rate: 0.00017759]
	Learning Rate: 0.000177592
	LOSS [training: 0.1013796867352851 | validation: 0.12908258124680136]
	TIME [epoch: 32.7 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10421723418007542		[learning rate: 0.00017689]
	Learning Rate: 0.000176886
	LOSS [training: 0.10421723418007542 | validation: 0.13410410817147903]
	TIME [epoch: 32.8 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1058978733311142		[learning rate: 0.00017618]
	Learning Rate: 0.000176182
	LOSS [training: 0.1058978733311142 | validation: 0.12737319548114986]
	TIME [epoch: 32.7 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11258832497303405		[learning rate: 0.00017548]
	Learning Rate: 0.000175481
	LOSS [training: 0.11258832497303405 | validation: 0.12339999521777903]
	TIME [epoch: 32.7 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11450366354709678		[learning rate: 0.00017478]
	Learning Rate: 0.000174783
	LOSS [training: 0.11450366354709678 | validation: 0.12830242830539734]
	TIME [epoch: 32.7 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10193147673507647		[learning rate: 0.00017409]
	Learning Rate: 0.000174088
	LOSS [training: 0.10193147673507647 | validation: 0.11783794026421415]
	TIME [epoch: 32.7 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_1061.pth
	Model improved!!!
EPOCH 1062/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10822406439936404		[learning rate: 0.0001734]
	Learning Rate: 0.000173396
	LOSS [training: 0.10822406439936404 | validation: 0.12557426509293876]
	TIME [epoch: 32.7 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11503761824149608		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.11503761824149608 | validation: 0.13735838667338246]
	TIME [epoch: 32.6 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10967017335429553		[learning rate: 0.00017202]
	Learning Rate: 0.000172019
	LOSS [training: 0.10967017335429553 | validation: 0.12610302994882958]
	TIME [epoch: 32.7 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10761381381216699		[learning rate: 0.00017134]
	Learning Rate: 0.000171335
	LOSS [training: 0.10761381381216699 | validation: 0.12742957213672237]
	TIME [epoch: 32.7 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1047725370445936		[learning rate: 0.00017065]
	Learning Rate: 0.000170654
	LOSS [training: 0.1047725370445936 | validation: 0.12330646656915459]
	TIME [epoch: 32.7 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10463425924764046		[learning rate: 0.00016997]
	Learning Rate: 0.000169975
	LOSS [training: 0.10463425924764046 | validation: 0.13082656346328336]
	TIME [epoch: 32.7 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1168391772430124		[learning rate: 0.0001693]
	Learning Rate: 0.000169299
	LOSS [training: 0.1168391772430124 | validation: 0.12546879525169455]
	TIME [epoch: 32.7 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1083428948435225		[learning rate: 0.00016863]
	Learning Rate: 0.000168625
	LOSS [training: 0.1083428948435225 | validation: 0.12826118649134888]
	TIME [epoch: 32.7 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10943362334619798		[learning rate: 0.00016795]
	Learning Rate: 0.000167955
	LOSS [training: 0.10943362334619798 | validation: 0.1242556133595231]
	TIME [epoch: 32.7 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10821135658007702		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.10821135658007702 | validation: 0.1343603489730153]
	TIME [epoch: 32.7 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1212911005310997		[learning rate: 0.00016662]
	Learning Rate: 0.000166621
	LOSS [training: 0.1212911005310997 | validation: 0.1240063398579413]
	TIME [epoch: 32.7 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10599986032232307		[learning rate: 0.00016596]
	Learning Rate: 0.000165959
	LOSS [training: 0.10599986032232307 | validation: 0.12920733571252258]
	TIME [epoch: 32.7 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10714423658285835		[learning rate: 0.0001653]
	Learning Rate: 0.000165299
	LOSS [training: 0.10714423658285835 | validation: 0.12863401023469972]
	TIME [epoch: 32.7 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11421618422858902		[learning rate: 0.00016464]
	Learning Rate: 0.000164641
	LOSS [training: 0.11421618422858902 | validation: 0.12408828904954945]
	TIME [epoch: 32.8 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11167635506831042		[learning rate: 0.00016399]
	Learning Rate: 0.000163986
	LOSS [training: 0.11167635506831042 | validation: 0.12668344666235654]
	TIME [epoch: 32.7 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11185371959582022		[learning rate: 0.00016333]
	Learning Rate: 0.000163334
	LOSS [training: 0.11185371959582022 | validation: 0.1257842024013452]
	TIME [epoch: 32.8 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11328201177203373		[learning rate: 0.00016268]
	Learning Rate: 0.000162685
	LOSS [training: 0.11328201177203373 | validation: 0.1322866468189246]
	TIME [epoch: 32.8 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11297289833496754		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.11297289833496754 | validation: 0.12711457056661696]
	TIME [epoch: 32.8 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1057374294096884		[learning rate: 0.00016139]
	Learning Rate: 0.000161393
	LOSS [training: 0.1057374294096884 | validation: 0.1285422686165307]
	TIME [epoch: 32.7 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10611601650676043		[learning rate: 0.00016075]
	Learning Rate: 0.000160751
	LOSS [training: 0.10611601650676043 | validation: 0.1240666828826272]
	TIME [epoch: 32.7 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10730652354932091		[learning rate: 0.00016011]
	Learning Rate: 0.000160112
	LOSS [training: 0.10730652354932091 | validation: 0.1263581516604371]
	TIME [epoch: 32.7 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1086079907353659		[learning rate: 0.00015947]
	Learning Rate: 0.000159475
	LOSS [training: 0.1086079907353659 | validation: 0.12750584401463017]
	TIME [epoch: 32.7 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1050477804597569		[learning rate: 0.00015884]
	Learning Rate: 0.000158841
	LOSS [training: 0.1050477804597569 | validation: 0.12590363415812322]
	TIME [epoch: 32.7 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10419375495111081		[learning rate: 0.00015821]
	Learning Rate: 0.000158209
	LOSS [training: 0.10419375495111081 | validation: 0.12472485793162755]
	TIME [epoch: 32.7 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1046783658277344		[learning rate: 0.00015758]
	Learning Rate: 0.00015758
	LOSS [training: 0.1046783658277344 | validation: 0.12747745564773355]
	TIME [epoch: 32.7 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10753763745810178		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.10753763745810178 | validation: 0.1337416772469318]
	TIME [epoch: 32.7 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11192003495665774		[learning rate: 0.00015633]
	Learning Rate: 0.000156329
	LOSS [training: 0.11192003495665774 | validation: 0.12682789739803077]
	TIME [epoch: 32.7 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11176998606908065		[learning rate: 0.00015571]
	Learning Rate: 0.000155707
	LOSS [training: 0.11176998606908065 | validation: 0.12994136278228033]
	TIME [epoch: 32.8 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10315219403756146		[learning rate: 0.00015509]
	Learning Rate: 0.000155088
	LOSS [training: 0.10315219403756146 | validation: 0.1212155998352781]
	TIME [epoch: 32.7 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10373522966423503		[learning rate: 0.00015447]
	Learning Rate: 0.000154471
	LOSS [training: 0.10373522966423503 | validation: 0.1330454051725355]
	TIME [epoch: 32.7 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1082822023060353		[learning rate: 0.00015386]
	Learning Rate: 0.000153856
	LOSS [training: 0.1082822023060353 | validation: 0.12396711870925248]
	TIME [epoch: 32.7 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10894883384978021		[learning rate: 0.00015324]
	Learning Rate: 0.000153244
	LOSS [training: 0.10894883384978021 | validation: 0.12359628875190662]
	TIME [epoch: 32.7 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10962338724263233		[learning rate: 0.00015263]
	Learning Rate: 0.000152635
	LOSS [training: 0.10962338724263233 | validation: 0.12693463965925506]
	TIME [epoch: 32.7 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11711031672162149		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.11711031672162149 | validation: 0.13101159063837148]
	TIME [epoch: 32.7 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11915276680957992		[learning rate: 0.00015142]
	Learning Rate: 0.000151423
	LOSS [training: 0.11915276680957992 | validation: 0.12073488186217349]
	TIME [epoch: 32.7 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10736438930705147		[learning rate: 0.00015082]
	Learning Rate: 0.000150821
	LOSS [training: 0.10736438930705147 | validation: 0.1265755790164988]
	TIME [epoch: 32.7 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11490271487589768		[learning rate: 0.00015022]
	Learning Rate: 0.000150221
	LOSS [training: 0.11490271487589768 | validation: 0.12764474803975115]
	TIME [epoch: 32.7 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10951647382298785		[learning rate: 0.00014962]
	Learning Rate: 0.000149624
	LOSS [training: 0.10951647382298785 | validation: 0.1256105673340131]
	TIME [epoch: 32.7 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11023345189575999		[learning rate: 0.00014903]
	Learning Rate: 0.000149028
	LOSS [training: 0.11023345189575999 | validation: 0.12808213605730218]
	TIME [epoch: 32.7 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10635414707620289		[learning rate: 0.00014844]
	Learning Rate: 0.000148436
	LOSS [training: 0.10635414707620289 | validation: 0.12927626370112272]
	TIME [epoch: 32.8 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10405481037285996		[learning rate: 0.00014785]
	Learning Rate: 0.000147845
	LOSS [training: 0.10405481037285996 | validation: 0.13332295693119905]
	TIME [epoch: 32.7 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10992761180848115		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.10992761180848115 | validation: 0.12219487259505465]
	TIME [epoch: 32.7 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10464724010508464		[learning rate: 0.00014667]
	Learning Rate: 0.000146672
	LOSS [training: 0.10464724010508464 | validation: 0.1291307405759552]
	TIME [epoch: 32.7 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10601170796151614		[learning rate: 0.00014609]
	Learning Rate: 0.000146088
	LOSS [training: 0.10601170796151614 | validation: 0.12253779566525005]
	TIME [epoch: 32.8 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10589467420361376		[learning rate: 0.00014551]
	Learning Rate: 0.000145507
	LOSS [training: 0.10589467420361376 | validation: 0.12975660157273972]
	TIME [epoch: 32.7 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11228276507014447		[learning rate: 0.00014493]
	Learning Rate: 0.000144929
	LOSS [training: 0.11228276507014447 | validation: 0.1247737095880705]
	TIME [epoch: 32.6 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10813650968166234		[learning rate: 0.00014435]
	Learning Rate: 0.000144352
	LOSS [training: 0.10813650968166234 | validation: 0.13001743653310488]
	TIME [epoch: 32.7 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11344671748496972		[learning rate: 0.00014378]
	Learning Rate: 0.000143778
	LOSS [training: 0.11344671748496972 | validation: 0.1240842398084629]
	TIME [epoch: 32.7 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10486104109722502		[learning rate: 0.00014321]
	Learning Rate: 0.000143206
	LOSS [training: 0.10486104109722502 | validation: 0.13001577261192698]
	TIME [epoch: 32.7 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10666764790561943		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.10666764790561943 | validation: 0.12413650549421165]
	TIME [epoch: 32.7 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10447296011341428		[learning rate: 0.00014207]
	Learning Rate: 0.000142069
	LOSS [training: 0.10447296011341428 | validation: 0.13478783591062404]
	TIME [epoch: 32.7 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11868041643278088		[learning rate: 0.0001415]
	Learning Rate: 0.000141504
	LOSS [training: 0.11868041643278088 | validation: 0.12941106532191324]
	TIME [epoch: 32.7 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1129527362174419		[learning rate: 0.00014094]
	Learning Rate: 0.000140941
	LOSS [training: 0.1129527362174419 | validation: 0.12538655877325705]
	TIME [epoch: 32.7 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11306155902707313		[learning rate: 0.00014038]
	Learning Rate: 0.000140381
	LOSS [training: 0.11306155902707313 | validation: 0.12580525652401206]
	TIME [epoch: 32.8 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11247062863894704		[learning rate: 0.00013982]
	Learning Rate: 0.000139822
	LOSS [training: 0.11247062863894704 | validation: 0.12742131527778838]
	TIME [epoch: 32.7 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10494071656857823		[learning rate: 0.00013927]
	Learning Rate: 0.000139266
	LOSS [training: 0.10494071656857823 | validation: 0.13312533185353798]
	TIME [epoch: 32.7 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10187122735900822		[learning rate: 0.00013871]
	Learning Rate: 0.000138712
	LOSS [training: 0.10187122735900822 | validation: 0.13070543315183863]
	TIME [epoch: 32.7 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1067281245733111		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.1067281245733111 | validation: 0.12483490954135017]
	TIME [epoch: 32.8 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11061291187991698		[learning rate: 0.00013761]
	Learning Rate: 0.000137611
	LOSS [training: 0.11061291187991698 | validation: 0.13114212898696617]
	TIME [epoch: 32.7 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1149546157923541		[learning rate: 0.00013706]
	Learning Rate: 0.000137064
	LOSS [training: 0.1149546157923541 | validation: 0.13167298094678767]
	TIME [epoch: 32.7 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1077982802026033		[learning rate: 0.00013652]
	Learning Rate: 0.000136519
	LOSS [training: 0.1077982802026033 | validation: 0.1287365678114867]
	TIME [epoch: 32.6 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11030112276957389		[learning rate: 0.00013598]
	Learning Rate: 0.000135976
	LOSS [training: 0.11030112276957389 | validation: 0.12366679592745325]
	TIME [epoch: 32.7 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10291222126922485		[learning rate: 0.00013543]
	Learning Rate: 0.000135435
	LOSS [training: 0.10291222126922485 | validation: 0.12787033491461003]
	TIME [epoch: 32.6 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1128037717876122		[learning rate: 0.0001349]
	Learning Rate: 0.000134896
	LOSS [training: 0.1128037717876122 | validation: 0.13163991821233928]
	TIME [epoch: 32.7 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10999118870462427		[learning rate: 0.00013436]
	Learning Rate: 0.00013436
	LOSS [training: 0.10999118870462427 | validation: 0.12707418959435135]
	TIME [epoch: 32.7 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11591573959725492		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.11591573959725492 | validation: 0.12730983093057677]
	TIME [epoch: 32.6 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11001422398116768		[learning rate: 0.00013329]
	Learning Rate: 0.000133293
	LOSS [training: 0.11001422398116768 | validation: 0.11933120011661495]
	TIME [epoch: 32.6 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10994738414142845		[learning rate: 0.00013276]
	Learning Rate: 0.000132763
	LOSS [training: 0.10994738414142845 | validation: 0.12450650183166881]
	TIME [epoch: 32.7 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10929167265006336		[learning rate: 0.00013223]
	Learning Rate: 0.000132235
	LOSS [training: 0.10929167265006336 | validation: 0.12415982490161204]
	TIME [epoch: 32.7 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10677654112194279		[learning rate: 0.00013171]
	Learning Rate: 0.000131709
	LOSS [training: 0.10677654112194279 | validation: 0.11802039493378884]
	TIME [epoch: 32.6 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1108809636417075		[learning rate: 0.00013119]
	Learning Rate: 0.000131185
	LOSS [training: 0.1108809636417075 | validation: 0.12910520244990903]
	TIME [epoch: 32.7 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10924632390019316		[learning rate: 0.00013066]
	Learning Rate: 0.000130663
	LOSS [training: 0.10924632390019316 | validation: 0.12256283173077172]
	TIME [epoch: 32.7 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10987672413656055		[learning rate: 0.00013014]
	Learning Rate: 0.000130144
	LOSS [training: 0.10987672413656055 | validation: 0.1282476729140461]
	TIME [epoch: 32.7 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10473673752928828		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.10473673752928828 | validation: 0.1275642473224204]
	TIME [epoch: 32.7 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10573911372720006		[learning rate: 0.00012911]
	Learning Rate: 0.000129111
	LOSS [training: 0.10573911372720006 | validation: 0.1212938920434298]
	TIME [epoch: 32.7 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11019085834941074		[learning rate: 0.0001286]
	Learning Rate: 0.000128597
	LOSS [training: 0.11019085834941074 | validation: 0.12769659291215726]
	TIME [epoch: 32.7 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10567590322255593		[learning rate: 0.00012809]
	Learning Rate: 0.000128086
	LOSS [training: 0.10567590322255593 | validation: 0.1287284330560666]
	TIME [epoch: 32.7 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10715468170129072		[learning rate: 0.00012758]
	Learning Rate: 0.000127576
	LOSS [training: 0.10715468170129072 | validation: 0.12670309234268967]
	TIME [epoch: 32.7 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11201422483852015		[learning rate: 0.00012707]
	Learning Rate: 0.000127069
	LOSS [training: 0.11201422483852015 | validation: 0.1269440019262455]
	TIME [epoch: 32.7 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11500176385928221		[learning rate: 0.00012656]
	Learning Rate: 0.000126563
	LOSS [training: 0.11500176385928221 | validation: 0.12740224181144896]
	TIME [epoch: 32.7 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10860491188848753		[learning rate: 0.00012606]
	Learning Rate: 0.00012606
	LOSS [training: 0.10860491188848753 | validation: 0.12629485404769203]
	TIME [epoch: 32.7 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10783447394244991		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.10783447394244991 | validation: 0.1250695279972405]
	TIME [epoch: 32.7 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10573467880360485		[learning rate: 0.00012506]
	Learning Rate: 0.000125059
	LOSS [training: 0.10573467880360485 | validation: 0.1363104752033976]
	TIME [epoch: 32.6 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10674956949291449		[learning rate: 0.00012456]
	Learning Rate: 0.000124562
	LOSS [training: 0.10674956949291449 | validation: 0.1335673439236904]
	TIME [epoch: 32.7 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1093829299083422		[learning rate: 0.00012407]
	Learning Rate: 0.000124066
	LOSS [training: 0.1093829299083422 | validation: 0.12377640195122304]
	TIME [epoch: 32.6 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10569219357750559		[learning rate: 0.00012357]
	Learning Rate: 0.000123573
	LOSS [training: 0.10569219357750559 | validation: 0.1280095365543336]
	TIME [epoch: 32.7 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10524850875416551		[learning rate: 0.00012308]
	Learning Rate: 0.000123081
	LOSS [training: 0.10524850875416551 | validation: 0.12905221563152547]
	TIME [epoch: 32.7 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1173558701676048		[learning rate: 0.00012259]
	Learning Rate: 0.000122592
	LOSS [training: 0.1173558701676048 | validation: 0.12704353317962744]
	TIME [epoch: 32.7 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11993735251286311		[learning rate: 0.0001221]
	Learning Rate: 0.000122104
	LOSS [training: 0.11993735251286311 | validation: 0.1231089063522901]
	TIME [epoch: 32.6 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11632687254843449		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.11632687254843449 | validation: 0.12626963195809227]
	TIME [epoch: 32.6 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10503140313836877		[learning rate: 0.00012113]
	Learning Rate: 0.000121135
	LOSS [training: 0.10503140313836877 | validation: 0.12471582467812832]
	TIME [epoch: 32.7 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11026976730478906		[learning rate: 0.00012065]
	Learning Rate: 0.000120653
	LOSS [training: 0.11026976730478906 | validation: 0.12268004017410021]
	TIME [epoch: 32.7 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10960856568804865		[learning rate: 0.00012017]
	Learning Rate: 0.000120173
	LOSS [training: 0.10960856568804865 | validation: 0.13049536459145697]
	TIME [epoch: 32.6 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10608985292951942		[learning rate: 0.0001197]
	Learning Rate: 0.000119695
	LOSS [training: 0.10608985292951942 | validation: 0.1273062709482607]
	TIME [epoch: 32.7 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11979747961458011		[learning rate: 0.00011922]
	Learning Rate: 0.000119219
	LOSS [training: 0.11979747961458011 | validation: 0.11906684511589305]
	TIME [epoch: 32.7 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10767061624403361		[learning rate: 0.00011875]
	Learning Rate: 0.000118745
	LOSS [training: 0.10767061624403361 | validation: 0.132711898642272]
	TIME [epoch: 32.7 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10869359430144038		[learning rate: 0.00011827]
	Learning Rate: 0.000118273
	LOSS [training: 0.10869359430144038 | validation: 0.12880377308323265]
	TIME [epoch: 32.7 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10470329253056795		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.10470329253056795 | validation: 0.1255386543898988]
	TIME [epoch: 32.7 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11047639934099432		[learning rate: 0.00011733]
	Learning Rate: 0.000117334
	LOSS [training: 0.11047639934099432 | validation: 0.11585858233520374]
	TIME [epoch: 32.8 sec]
	Saving model to: out/model_training/model_transition1_pcs123_v1_20240606_200424/states/model_transition1_pcs123_v1_1160.pth
	Model improved!!!
EPOCH 1161/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10935040125319812		[learning rate: 0.00011687]
	Learning Rate: 0.000116867
	LOSS [training: 0.10935040125319812 | validation: 0.12533726351835445]
	TIME [epoch: 32.7 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10763918526193252		[learning rate: 0.0001164]
	Learning Rate: 0.000116402
	LOSS [training: 0.10763918526193252 | validation: 0.12348264220895029]
	TIME [epoch: 32.6 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10718694578876588		[learning rate: 0.00011594]
	Learning Rate: 0.000115939
	LOSS [training: 0.10718694578876588 | validation: 0.12849180997466697]
	TIME [epoch: 32.8 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11013358310605234		[learning rate: 0.00011548]
	Learning Rate: 0.000115478
	LOSS [training: 0.11013358310605234 | validation: 0.12767845032238495]
	TIME [epoch: 32.7 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11453581312898363		[learning rate: 0.00011502]
	Learning Rate: 0.000115019
	LOSS [training: 0.11453581312898363 | validation: 0.12184098286253961]
	TIME [epoch: 32.7 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11433147826232457		[learning rate: 0.00011456]
	Learning Rate: 0.000114561
	LOSS [training: 0.11433147826232457 | validation: 0.12665984241078335]
	TIME [epoch: 32.7 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10809943117653305		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.10809943117653305 | validation: 0.12181260176126303]
	TIME [epoch: 32.8 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11056779079729367		[learning rate: 0.00011365]
	Learning Rate: 0.000113652
	LOSS [training: 0.11056779079729367 | validation: 0.12733032908837294]
	TIME [epoch: 32.7 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11424147834563193		[learning rate: 0.0001132]
	Learning Rate: 0.0001132
	LOSS [training: 0.11424147834563193 | validation: 0.12680116761044807]
	TIME [epoch: 32.7 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10887018379706594		[learning rate: 0.00011275]
	Learning Rate: 0.00011275
	LOSS [training: 0.10887018379706594 | validation: 0.12631859786080227]
	TIME [epoch: 32.7 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11347826010525813		[learning rate: 0.0001123]
	Learning Rate: 0.000112301
	LOSS [training: 0.11347826010525813 | validation: 0.1274574847503468]
	TIME [epoch: 32.8 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11473195683894698		[learning rate: 0.00011185]
	Learning Rate: 0.000111855
	LOSS [training: 0.11473195683894698 | validation: 0.12854428551213437]
	TIME [epoch: 32.7 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10920305730090632		[learning rate: 0.00011141]
	Learning Rate: 0.00011141
	LOSS [training: 0.10920305730090632 | validation: 0.12042399789261418]
	TIME [epoch: 32.7 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10423925293202506		[learning rate: 0.00011097]
	Learning Rate: 0.000110967
	LOSS [training: 0.10423925293202506 | validation: 0.12831188065809024]
	TIME [epoch: 32.8 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10516922371249024		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.10516922371249024 | validation: 0.12435733836172673]
	TIME [epoch: 32.7 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1064315447053012		[learning rate: 0.00011009]
	Learning Rate: 0.000110086
	LOSS [training: 0.1064315447053012 | validation: 0.12721642933218963]
	TIME [epoch: 32.7 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10895471037843035		[learning rate: 0.00010965]
	Learning Rate: 0.000109648
	LOSS [training: 0.10895471037843035 | validation: 0.12764352218988395]
	TIME [epoch: 32.7 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11113384731580091		[learning rate: 0.00010921]
	Learning Rate: 0.000109212
	LOSS [training: 0.11113384731580091 | validation: 0.1277840926249823]
	TIME [epoch: 32.7 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10688901789022694		[learning rate: 0.00010878]
	Learning Rate: 0.000108777
	LOSS [training: 0.10688901789022694 | validation: 0.12303482333286872]
	TIME [epoch: 32.7 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10486417279644691		[learning rate: 0.00010834]
	Learning Rate: 0.000108345
	LOSS [training: 0.10486417279644691 | validation: 0.12681761603171057]
	TIME [epoch: 32.7 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11651438899679856		[learning rate: 0.00010791]
	Learning Rate: 0.000107914
	LOSS [training: 0.11651438899679856 | validation: 0.12956432746656288]
	TIME [epoch: 32.7 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11134166884274024		[learning rate: 0.00010748]
	Learning Rate: 0.000107485
	LOSS [training: 0.11134166884274024 | validation: 0.12030252985310733]
	TIME [epoch: 32.6 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11072817213107307		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.11072817213107307 | validation: 0.126290761766662]
	TIME [epoch: 32.7 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10589606339352546		[learning rate: 0.00010663]
	Learning Rate: 0.000106631
	LOSS [training: 0.10589606339352546 | validation: 0.1288160912236753]
	TIME [epoch: 32.6 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11648944441139258		[learning rate: 0.00010621]
	Learning Rate: 0.000106207
	LOSS [training: 0.11648944441139258 | validation: 0.12753407640923822]
	TIME [epoch: 32.7 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11618839578359957		[learning rate: 0.00010578]
	Learning Rate: 0.000105785
	LOSS [training: 0.11618839578359957 | validation: 0.12770643869971962]
	TIME [epoch: 32.6 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11742530537842752		[learning rate: 0.00010536]
	Learning Rate: 0.000105364
	LOSS [training: 0.11742530537842752 | validation: 0.1279455509581915]
	TIME [epoch: 32.7 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11427397125520487		[learning rate: 0.00010494]
	Learning Rate: 0.000104945
	LOSS [training: 0.11427397125520487 | validation: 0.12285007192676545]
	TIME [epoch: 32.6 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10906868428479065		[learning rate: 0.00010453]
	Learning Rate: 0.000104528
	LOSS [training: 0.10906868428479065 | validation: 0.12420506668962643]
	TIME [epoch: 32.7 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1121602127922699		[learning rate: 0.00010411]
	Learning Rate: 0.000104112
	LOSS [training: 0.1121602127922699 | validation: 0.1290341136261227]
	TIME [epoch: 32.6 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11108120700046092		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.11108120700046092 | validation: 0.12478677301463847]
	TIME [epoch: 32.7 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1101437128574862		[learning rate: 0.00010329]
	Learning Rate: 0.000103285
	LOSS [training: 0.1101437128574862 | validation: 0.12316478383204821]
	TIME [epoch: 32.6 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10870829768685691		[learning rate: 0.00010287]
	Learning Rate: 0.000102874
	LOSS [training: 0.10870829768685691 | validation: 0.12651885687608694]
	TIME [epoch: 32.7 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10774676397085756		[learning rate: 0.00010247]
	Learning Rate: 0.000102465
	LOSS [training: 0.10774676397085756 | validation: 0.135165582451322]
	TIME [epoch: 32.7 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11297038663363941		[learning rate: 0.00010206]
	Learning Rate: 0.000102058
	LOSS [training: 0.11297038663363941 | validation: 0.1204108073166533]
	TIME [epoch: 32.7 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1053760257717658		[learning rate: 0.00010165]
	Learning Rate: 0.000101652
	LOSS [training: 0.1053760257717658 | validation: 0.12320277775347832]
	TIME [epoch: 32.7 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11029409737804646		[learning rate: 0.00010125]
	Learning Rate: 0.000101248
	LOSS [training: 0.11029409737804646 | validation: 0.12239371742952447]
	TIME [epoch: 32.6 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10682221487691627		[learning rate: 0.00010084]
	Learning Rate: 0.000100845
	LOSS [training: 0.10682221487691627 | validation: 0.1226360418132604]
	TIME [epoch: 32.6 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10944081663809323		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.10944081663809323 | validation: 0.13439550253921037]
	TIME [epoch: 32.7 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10672498924514048		[learning rate: 0.00010004]
	Learning Rate: 0.000100044
	LOSS [training: 0.10672498924514048 | validation: 0.1288557029864335]
	TIME [epoch: 32.7 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12041220551695526		[learning rate: 9.9646e-05]
	Learning Rate: 9.96464e-05
	LOSS [training: 0.12041220551695526 | validation: 0.12938040639276774]
	TIME [epoch: 32.7 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10566458134627653		[learning rate: 9.925e-05]
	Learning Rate: 9.92501e-05
	LOSS [training: 0.10566458134627653 | validation: 0.11985045487860509]
	TIME [epoch: 32.7 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10846512305843026		[learning rate: 9.8855e-05]
	Learning Rate: 9.88553e-05
	LOSS [training: 0.10846512305843026 | validation: 0.1263584161408267]
	TIME [epoch: 32.8 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11464552197071473		[learning rate: 9.8462e-05]
	Learning Rate: 9.84622e-05
	LOSS [training: 0.11464552197071473 | validation: 0.12782174391514972]
	TIME [epoch: 32.7 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11039503033597516		[learning rate: 9.8071e-05]
	Learning Rate: 9.80705e-05
	LOSS [training: 0.11039503033597516 | validation: 0.1231502965850074]
	TIME [epoch: 32.7 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10429165682040958		[learning rate: 9.768e-05]
	Learning Rate: 9.76805e-05
	LOSS [training: 0.10429165682040958 | validation: 0.12719489958750135]
	TIME [epoch: 32.7 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11921955246412565		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.11921955246412565 | validation: 0.1209330947571073]
	TIME [epoch: 32.7 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11692051964662682		[learning rate: 9.6905e-05]
	Learning Rate: 9.6905e-05
	LOSS [training: 0.11692051964662682 | validation: 0.12936999597266513]
	TIME [epoch: 32.7 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1075678378277048		[learning rate: 9.652e-05]
	Learning Rate: 9.65196e-05
	LOSS [training: 0.1075678378277048 | validation: 0.13463177999843376]
	TIME [epoch: 32.7 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11489458893693895		[learning rate: 9.6136e-05]
	Learning Rate: 9.61357e-05
	LOSS [training: 0.11489458893693895 | validation: 0.12785436555108964]
	TIME [epoch: 32.7 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10763666783838786		[learning rate: 9.5753e-05]
	Learning Rate: 9.57533e-05
	LOSS [training: 0.10763666783838786 | validation: 0.1328029505234879]
	TIME [epoch: 32.7 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10912735922800103		[learning rate: 9.5372e-05]
	Learning Rate: 9.53725e-05
	LOSS [training: 0.10912735922800103 | validation: 0.12471325917808977]
	TIME [epoch: 32.7 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10879160997581791		[learning rate: 9.4993e-05]
	Learning Rate: 9.49932e-05
	LOSS [training: 0.10879160997581791 | validation: 0.12251281809516332]
	TIME [epoch: 32.7 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10954420409544945		[learning rate: 9.4615e-05]
	Learning Rate: 9.46154e-05
	LOSS [training: 0.10954420409544945 | validation: 0.1255197923544683]
	TIME [epoch: 32.7 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10599847641682818		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.10599847641682818 | validation: 0.12378689368735427]
	TIME [epoch: 32.7 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11407971585857668		[learning rate: 9.3864e-05]
	Learning Rate: 9.38642e-05
	LOSS [training: 0.11407971585857668 | validation: 0.1238947639132874]
	TIME [epoch: 32.7 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10913087614744955		[learning rate: 9.3491e-05]
	Learning Rate: 9.34909e-05
	LOSS [training: 0.10913087614744955 | validation: 0.1370005691709264]
	TIME [epoch: 32.7 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10807140041414497		[learning rate: 9.3119e-05]
	Learning Rate: 9.3119e-05
	LOSS [training: 0.10807140041414497 | validation: 0.1265665910140435]
	TIME [epoch: 32.7 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11025643487271575		[learning rate: 9.2749e-05]
	Learning Rate: 9.27487e-05
	LOSS [training: 0.11025643487271575 | validation: 0.1275325538459156]
	TIME [epoch: 32.7 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1113530836436896		[learning rate: 9.238e-05]
	Learning Rate: 9.23798e-05
	LOSS [training: 0.1113530836436896 | validation: 0.12743868810414266]
	TIME [epoch: 32.7 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10832706662407715		[learning rate: 9.2012e-05]
	Learning Rate: 9.20124e-05
	LOSS [training: 0.10832706662407715 | validation: 0.12683428289005746]
	TIME [epoch: 32.7 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11167242567554811		[learning rate: 9.1646e-05]
	Learning Rate: 9.16464e-05
	LOSS [training: 0.11167242567554811 | validation: 0.130231637090297]
	TIME [epoch: 32.7 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10670163222492841		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.10670163222492841 | validation: 0.12717903398334468]
	TIME [epoch: 32.7 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1120548489879195		[learning rate: 9.0919e-05]
	Learning Rate: 9.09188e-05
	LOSS [training: 0.1120548489879195 | validation: 0.13487142095958168]
	TIME [epoch: 32.7 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10991193743868674		[learning rate: 9.0557e-05]
	Learning Rate: 9.05572e-05
	LOSS [training: 0.10991193743868674 | validation: 0.11913104928228901]
	TIME [epoch: 32.7 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11080350469493896		[learning rate: 9.0197e-05]
	Learning Rate: 9.01971e-05
	LOSS [training: 0.11080350469493896 | validation: 0.13130285598644595]
	TIME [epoch: 32.7 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11846836128147774		[learning rate: 8.9838e-05]
	Learning Rate: 8.98383e-05
	LOSS [training: 0.11846836128147774 | validation: 0.12890621678770872]
	TIME [epoch: 32.7 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10468438696214061		[learning rate: 8.9481e-05]
	Learning Rate: 8.9481e-05
	LOSS [training: 0.10468438696214061 | validation: 0.11977726380288685]
	TIME [epoch: 32.7 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1100104249966		[learning rate: 8.9125e-05]
	Learning Rate: 8.91251e-05
	LOSS [training: 0.1100104249966 | validation: 0.13133686447451987]
	TIME [epoch: 32.8 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10623615781271963		[learning rate: 8.8771e-05]
	Learning Rate: 8.87706e-05
	LOSS [training: 0.10623615781271963 | validation: 0.12736772491994222]
	TIME [epoch: 32.7 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10520459510462303		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.10520459510462303 | validation: 0.1305682059345429]
	TIME [epoch: 32.7 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11245658922609827		[learning rate: 8.8066e-05]
	Learning Rate: 8.80659e-05
	LOSS [training: 0.11245658922609827 | validation: 0.12388977580697147]
	TIME [epoch: 32.7 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11288112358716004		[learning rate: 8.7716e-05]
	Learning Rate: 8.77156e-05
	LOSS [training: 0.11288112358716004 | validation: 0.12686713865046523]
	TIME [epoch: 32.7 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11045066395039685		[learning rate: 8.7367e-05]
	Learning Rate: 8.73668e-05
	LOSS [training: 0.11045066395039685 | validation: 0.1226477987588473]
	TIME [epoch: 32.6 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10633485380468805		[learning rate: 8.7019e-05]
	Learning Rate: 8.70193e-05
	LOSS [training: 0.10633485380468805 | validation: 0.12047901441277367]
	TIME [epoch: 32.7 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1069852436794169		[learning rate: 8.6673e-05]
	Learning Rate: 8.66731e-05
	LOSS [training: 0.1069852436794169 | validation: 0.12420880439972289]
	TIME [epoch: 32.7 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11001713203679554		[learning rate: 8.6328e-05]
	Learning Rate: 8.63284e-05
	LOSS [training: 0.11001713203679554 | validation: 0.13023435756787372]
	TIME [epoch: 32.7 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11258785971228649		[learning rate: 8.5985e-05]
	Learning Rate: 8.59851e-05
	LOSS [training: 0.11258785971228649 | validation: 0.12991909568475618]
	TIME [epoch: 32.6 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1161275311888005		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.1161275311888005 | validation: 0.13220833064859794]
	TIME [epoch: 32.7 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10829896665539192		[learning rate: 8.5302e-05]
	Learning Rate: 8.53025e-05
	LOSS [training: 0.10829896665539192 | validation: 0.12588150514346078]
	TIME [epoch: 32.8 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10459210834965904		[learning rate: 8.4963e-05]
	Learning Rate: 8.49632e-05
	LOSS [training: 0.10459210834965904 | validation: 0.12412036242946978]
	TIME [epoch: 32.7 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10557676535005321		[learning rate: 8.4625e-05]
	Learning Rate: 8.46253e-05
	LOSS [training: 0.10557676535005321 | validation: 0.13092573704864324]
	TIME [epoch: 32.7 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10566812227693659		[learning rate: 8.4289e-05]
	Learning Rate: 8.42887e-05
	LOSS [training: 0.10566812227693659 | validation: 0.11892671512748294]
	TIME [epoch: 32.7 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10730391577276292		[learning rate: 8.3953e-05]
	Learning Rate: 8.39534e-05
	LOSS [training: 0.10730391577276292 | validation: 0.12178023469228165]
	TIME [epoch: 32.8 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11015056880100138		[learning rate: 8.362e-05]
	Learning Rate: 8.36195e-05
	LOSS [training: 0.11015056880100138 | validation: 0.12230806695492387]
	TIME [epoch: 32.7 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11228829067834327		[learning rate: 8.3287e-05]
	Learning Rate: 8.3287e-05
	LOSS [training: 0.11228829067834327 | validation: 0.13127060253304257]
	TIME [epoch: 32.7 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10898095155159288		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.10898095155159288 | validation: 0.13035334003767246]
	TIME [epoch: 32.6 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10877909218175844		[learning rate: 8.2626e-05]
	Learning Rate: 8.26257e-05
	LOSS [training: 0.10877909218175844 | validation: 0.12675413998209492]
	TIME [epoch: 32.7 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10465820619272087		[learning rate: 8.2297e-05]
	Learning Rate: 8.22971e-05
	LOSS [training: 0.10465820619272087 | validation: 0.12929659246942607]
	TIME [epoch: 32.7 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10661099227548955		[learning rate: 8.197e-05]
	Learning Rate: 8.19698e-05
	LOSS [training: 0.10661099227548955 | validation: 0.11809136815416317]
	TIME [epoch: 32.7 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1071525045265292		[learning rate: 8.1644e-05]
	Learning Rate: 8.16438e-05
	LOSS [training: 0.1071525045265292 | validation: 0.12164935395687324]
	TIME [epoch: 32.7 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11239299322543245		[learning rate: 8.1319e-05]
	Learning Rate: 8.13191e-05
	LOSS [training: 0.11239299322543245 | validation: 0.1201311120964633]
	TIME [epoch: 32.7 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10797135638054615		[learning rate: 8.0996e-05]
	Learning Rate: 8.09957e-05
	LOSS [training: 0.10797135638054615 | validation: 0.11992021393910715]
	TIME [epoch: 32.7 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10625063059893708		[learning rate: 8.0673e-05]
	Learning Rate: 8.06735e-05
	LOSS [training: 0.10625063059893708 | validation: 0.12503658747677454]
	TIME [epoch: 32.7 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11741984469091982		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.11741984469091982 | validation: 0.12483329056654942]
	TIME [epoch: 32.7 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10668572282709417		[learning rate: 8.0033e-05]
	Learning Rate: 8.0033e-05
	LOSS [training: 0.10668572282709417 | validation: 0.12411501334044697]
	TIME [epoch: 32.6 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11583048121922264		[learning rate: 7.9715e-05]
	Learning Rate: 7.97147e-05
	LOSS [training: 0.11583048121922264 | validation: 0.12699836177395538]
	TIME [epoch: 32.7 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10484336249606609		[learning rate: 7.9398e-05]
	Learning Rate: 7.93977e-05
	LOSS [training: 0.10484336249606609 | validation: 0.130384328406643]
	TIME [epoch: 32.7 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11324108654057098		[learning rate: 7.9082e-05]
	Learning Rate: 7.90819e-05
	LOSS [training: 0.11324108654057098 | validation: 0.13083579264286632]
	TIME [epoch: 32.7 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10578724212114664		[learning rate: 7.8767e-05]
	Learning Rate: 7.87673e-05
	LOSS [training: 0.10578724212114664 | validation: 0.12568410620808063]
	TIME [epoch: 32.6 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10684006045751886		[learning rate: 7.8454e-05]
	Learning Rate: 7.84541e-05
	LOSS [training: 0.10684006045751886 | validation: 0.12988056635460493]
	TIME [epoch: 32.6 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11316990181470257		[learning rate: 7.8142e-05]
	Learning Rate: 7.8142e-05
	LOSS [training: 0.11316990181470257 | validation: 0.12394229337138041]
	TIME [epoch: 32.7 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10626714528314693		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.10626714528314693 | validation: 0.13390045861859295]
	TIME [epoch: 32.7 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1054457433664246		[learning rate: 7.7522e-05]
	Learning Rate: 7.75217e-05
	LOSS [training: 0.1054457433664246 | validation: 0.13284568633701627]
	TIME [epoch: 32.6 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10117188051574434		[learning rate: 7.7213e-05]
	Learning Rate: 7.72134e-05
	LOSS [training: 0.10117188051574434 | validation: 0.12318513314176996]
	TIME [epoch: 32.7 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10670497947867054		[learning rate: 7.6906e-05]
	Learning Rate: 7.69062e-05
	LOSS [training: 0.10670497947867054 | validation: 0.12771925807656057]
	TIME [epoch: 32.8 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.09892096828095356		[learning rate: 7.66e-05]
	Learning Rate: 7.66004e-05
	LOSS [training: 0.09892096828095356 | validation: 0.12749488494786348]
	TIME [epoch: 32.7 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11652667210576		[learning rate: 7.6296e-05]
	Learning Rate: 7.62957e-05
	LOSS [training: 0.11652667210576 | validation: 0.12484994348815952]
	TIME [epoch: 32.6 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10178875910191877		[learning rate: 7.5992e-05]
	Learning Rate: 7.59922e-05
	LOSS [training: 0.10178875910191877 | validation: 0.12568081305499915]
	TIME [epoch: 32.7 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10746711014864448		[learning rate: 7.569e-05]
	Learning Rate: 7.569e-05
	LOSS [training: 0.10746711014864448 | validation: 0.12404428905337457]
	TIME [epoch: 32.7 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11588846901257105		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.11588846901257105 | validation: 0.12814878391934123]
	TIME [epoch: 32.7 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1062007910864353		[learning rate: 7.5089e-05]
	Learning Rate: 7.50891e-05
	LOSS [training: 0.1062007910864353 | validation: 0.12207844110461878]
	TIME [epoch: 32.7 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11291095126057447		[learning rate: 7.479e-05]
	Learning Rate: 7.47905e-05
	LOSS [training: 0.11291095126057447 | validation: 0.13185246319262736]
	TIME [epoch: 32.7 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11104724442438857		[learning rate: 7.4493e-05]
	Learning Rate: 7.4493e-05
	LOSS [training: 0.11104724442438857 | validation: 0.12339089393054989]
	TIME [epoch: 32.6 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1134805084810431		[learning rate: 7.4197e-05]
	Learning Rate: 7.41967e-05
	LOSS [training: 0.1134805084810431 | validation: 0.1269590365477112]
	TIME [epoch: 32.6 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.102247899800403		[learning rate: 7.3902e-05]
	Learning Rate: 7.39016e-05
	LOSS [training: 0.102247899800403 | validation: 0.12575144830578938]
	TIME [epoch: 32.7 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10517604042227804		[learning rate: 7.3608e-05]
	Learning Rate: 7.36077e-05
	LOSS [training: 0.10517604042227804 | validation: 0.13226100942760305]
	TIME [epoch: 32.7 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10876901550937672		[learning rate: 7.3315e-05]
	Learning Rate: 7.33149e-05
	LOSS [training: 0.10876901550937672 | validation: 0.13268063374258077]
	TIME [epoch: 32.7 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10332842524973769		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.10332842524973769 | validation: 0.12509987081226376]
	TIME [epoch: 32.7 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11176077464833573		[learning rate: 7.2733e-05]
	Learning Rate: 7.27329e-05
	LOSS [training: 0.11176077464833573 | validation: 0.12313563192413313]
	TIME [epoch: 32.7 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10806483983339071		[learning rate: 7.2444e-05]
	Learning Rate: 7.24436e-05
	LOSS [training: 0.10806483983339071 | validation: 0.121557051832672]
	TIME [epoch: 32.7 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10619604229624878		[learning rate: 7.2155e-05]
	Learning Rate: 7.21555e-05
	LOSS [training: 0.10619604229624878 | validation: 0.12319975114870467]
	TIME [epoch: 32.7 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.112057307486994		[learning rate: 7.1868e-05]
	Learning Rate: 7.18685e-05
	LOSS [training: 0.112057307486994 | validation: 0.12985985772516612]
	TIME [epoch: 32.7 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10553911382965114		[learning rate: 7.1583e-05]
	Learning Rate: 7.15827e-05
	LOSS [training: 0.10553911382965114 | validation: 0.13103770561658337]
	TIME [epoch: 32.7 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10603842120408483		[learning rate: 7.1298e-05]
	Learning Rate: 7.12979e-05
	LOSS [training: 0.10603842120408483 | validation: 0.12744302589592157]
	TIME [epoch: 32.7 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10623787612306061		[learning rate: 7.1014e-05]
	Learning Rate: 7.10144e-05
	LOSS [training: 0.10623787612306061 | validation: 0.1268833274772297]
	TIME [epoch: 32.6 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10962535309126405		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.10962535309126405 | validation: 0.12453806897798425]
	TIME [epoch: 32.6 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10977070088080912		[learning rate: 7.0451e-05]
	Learning Rate: 7.04506e-05
	LOSS [training: 0.10977070088080912 | validation: 0.12082571748235178]
	TIME [epoch: 32.7 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10736468269877954		[learning rate: 7.017e-05]
	Learning Rate: 7.01704e-05
	LOSS [training: 0.10736468269877954 | validation: 0.12648592707242923]
	TIME [epoch: 32.7 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10589216099869161		[learning rate: 6.9891e-05]
	Learning Rate: 6.98913e-05
	LOSS [training: 0.10589216099869161 | validation: 0.13126621074229045]
	TIME [epoch: 32.6 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10874905326859911		[learning rate: 6.9613e-05]
	Learning Rate: 6.96133e-05
	LOSS [training: 0.10874905326859911 | validation: 0.12072623004836477]
	TIME [epoch: 32.8 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10988471723472822		[learning rate: 6.9336e-05]
	Learning Rate: 6.93364e-05
	LOSS [training: 0.10988471723472822 | validation: 0.1318621586152959]
	TIME [epoch: 32.7 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11062223584980704		[learning rate: 6.9061e-05]
	Learning Rate: 6.90607e-05
	LOSS [training: 0.11062223584980704 | validation: 0.12408076711464497]
	TIME [epoch: 32.7 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10648539504962812		[learning rate: 6.8786e-05]
	Learning Rate: 6.8786e-05
	LOSS [training: 0.10648539504962812 | validation: 0.12870824959710134]
	TIME [epoch: 32.6 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11425125611840363		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.11425125611840363 | validation: 0.12122858937947005]
	TIME [epoch: 32.8 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10852281171275184		[learning rate: 6.824e-05]
	Learning Rate: 6.82399e-05
	LOSS [training: 0.10852281171275184 | validation: 0.12409853517339972]
	TIME [epoch: 32.7 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11139690876623885		[learning rate: 6.7968e-05]
	Learning Rate: 6.79685e-05
	LOSS [training: 0.11139690876623885 | validation: 0.12259381539891154]
	TIME [epoch: 32.7 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11320756401727171		[learning rate: 6.7698e-05]
	Learning Rate: 6.76982e-05
	LOSS [training: 0.11320756401727171 | validation: 0.1297125543664474]
	TIME [epoch: 32.7 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11286890848292486		[learning rate: 6.7429e-05]
	Learning Rate: 6.74289e-05
	LOSS [training: 0.11286890848292486 | validation: 0.12390002947426229]
	TIME [epoch: 32.7 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10510931673690299		[learning rate: 6.7161e-05]
	Learning Rate: 6.71607e-05
	LOSS [training: 0.10510931673690299 | validation: 0.12655540789845948]
	TIME [epoch: 32.7 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11064972299619708		[learning rate: 6.6894e-05]
	Learning Rate: 6.68936e-05
	LOSS [training: 0.11064972299619708 | validation: 0.12770925162516045]
	TIME [epoch: 32.7 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1032483564794245		[learning rate: 6.6628e-05]
	Learning Rate: 6.66276e-05
	LOSS [training: 0.1032483564794245 | validation: 0.12244389539255314]
	TIME [epoch: 32.7 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10759412365684073		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.10759412365684073 | validation: 0.1344228946186731]
	TIME [epoch: 32.7 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11062973683004512		[learning rate: 6.6099e-05]
	Learning Rate: 6.60986e-05
	LOSS [training: 0.11062973683004512 | validation: 0.11980051113260566]
	TIME [epoch: 32.7 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11388346171967635		[learning rate: 6.5836e-05]
	Learning Rate: 6.58357e-05
	LOSS [training: 0.11388346171967635 | validation: 0.12128014423934959]
	TIME [epoch: 32.7 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10782625390080612		[learning rate: 6.5574e-05]
	Learning Rate: 6.55739e-05
	LOSS [training: 0.10782625390080612 | validation: 0.13024773604073667]
	TIME [epoch: 32.8 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10993212565218197		[learning rate: 6.5313e-05]
	Learning Rate: 6.53131e-05
	LOSS [training: 0.10993212565218197 | validation: 0.12786242078796722]
	TIME [epoch: 32.7 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10318049622276487		[learning rate: 6.5053e-05]
	Learning Rate: 6.50533e-05
	LOSS [training: 0.10318049622276487 | validation: 0.1208488868508307]
	TIME [epoch: 32.7 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10790737733085168		[learning rate: 6.4795e-05]
	Learning Rate: 6.47945e-05
	LOSS [training: 0.10790737733085168 | validation: 0.13748026449891407]
	TIME [epoch: 32.7 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11222258955501643		[learning rate: 6.4537e-05]
	Learning Rate: 6.45368e-05
	LOSS [training: 0.11222258955501643 | validation: 0.13352386087979526]
	TIME [epoch: 32.7 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10814378190182028		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.10814378190182028 | validation: 0.12350245242659438]
	TIME [epoch: 32.7 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10800406716502811		[learning rate: 6.4025e-05]
	Learning Rate: 6.40245e-05
	LOSS [training: 0.10800406716502811 | validation: 0.11947279259977014]
	TIME [epoch: 32.7 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11216025377305115		[learning rate: 6.377e-05]
	Learning Rate: 6.37699e-05
	LOSS [training: 0.11216025377305115 | validation: 0.13194034691054257]
	TIME [epoch: 32.8 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10641341859817005		[learning rate: 6.3516e-05]
	Learning Rate: 6.35162e-05
	LOSS [training: 0.10641341859817005 | validation: 0.1274444771215431]
	TIME [epoch: 32.7 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11825965302464403		[learning rate: 6.3264e-05]
	Learning Rate: 6.32636e-05
	LOSS [training: 0.11825965302464403 | validation: 0.12955412928748775]
	TIME [epoch: 32.7 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1110445042945035		[learning rate: 6.3012e-05]
	Learning Rate: 6.3012e-05
	LOSS [training: 0.1110445042945035 | validation: 0.12326272528474332]
	TIME [epoch: 32.7 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10896866954728819		[learning rate: 6.2761e-05]
	Learning Rate: 6.27614e-05
	LOSS [training: 0.10896866954728819 | validation: 0.12907747616692242]
	TIME [epoch: 32.7 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10393891189480595		[learning rate: 6.2512e-05]
	Learning Rate: 6.25117e-05
	LOSS [training: 0.10393891189480595 | validation: 0.12878552258556408]
	TIME [epoch: 32.7 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11554220588887312		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.11554220588887312 | validation: 0.13052326151801402]
	TIME [epoch: 32.7 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10791128830859459		[learning rate: 6.2015e-05]
	Learning Rate: 6.20155e-05
	LOSS [training: 0.10791128830859459 | validation: 0.12401475961769706]
	TIME [epoch: 32.7 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11048540536622137		[learning rate: 6.1769e-05]
	Learning Rate: 6.17688e-05
	LOSS [training: 0.11048540536622137 | validation: 0.12225754471653187]
	TIME [epoch: 32.8 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1047259527133182		[learning rate: 6.1523e-05]
	Learning Rate: 6.15231e-05
	LOSS [training: 0.1047259527133182 | validation: 0.12675255218102588]
	TIME [epoch: 32.7 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10744926779529194		[learning rate: 6.1278e-05]
	Learning Rate: 6.12784e-05
	LOSS [training: 0.10744926779529194 | validation: 0.12174411707261013]
	TIME [epoch: 32.7 sec]
EPOCH 1324/2000:
	Training over batches...
