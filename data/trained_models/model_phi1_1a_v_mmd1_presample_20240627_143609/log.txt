Args:
Namespace(name='model_phi1_1a_v_mmd1_presample', outdir='out/model_training/model_phi1_1a_v_mmd1_presample', training_data='data/training_data/data_phi1_1a/training', validation_data='data/training_data/data_phi1_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, patience=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=200, model_do_sample=False, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1121647162

Training model...

Saving initial model state to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.66706695026515		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.66706695026515 | validation: 4.08792376671153]
	TIME [epoch: 25.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.092257669782134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.092257669782134 | validation: 3.7768306870248263]
	TIME [epoch: 9.22 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6200836906559384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6200836906559384 | validation: 3.205867661248684]
	TIME [epoch: 9.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.134731843129086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.134731843129086 | validation: 3.021656926804508]
	TIME [epoch: 9.21 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8371393941023775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8371393941023775 | validation: 2.612339956649559]
	TIME [epoch: 9.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.551424267157773		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.551424267157773 | validation: 2.5956223496288438]
	TIME [epoch: 9.21 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4319237792016715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4319237792016715 | validation: 2.4778649421829018]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3992275865081525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3992275865081525 | validation: 2.457139378882389]
	TIME [epoch: 9.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3897426943576496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3897426943576496 | validation: 2.48501140600548]
	TIME [epoch: 9.2 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3993709519789483		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3993709519789483 | validation: 2.4628902179855903]
	TIME [epoch: 9.21 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3886329645965563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3886329645965563 | validation: 2.4039809603092013]
	TIME [epoch: 9.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.360488150834472		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.360488150834472 | validation: 2.401855486677552]
	TIME [epoch: 9.2 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3615170897127955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3615170897127955 | validation: 2.4324673039382296]
	TIME [epoch: 9.23 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3497921881194808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3497921881194808 | validation: 2.3758905185931507]
	TIME [epoch: 9.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.317908688325942		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.317908688325942 | validation: 2.456744779504694]
	TIME [epoch: 9.24 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.344462659447215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.344462659447215 | validation: 2.346496360602747]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2802385049554257		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2802385049554257 | validation: 2.3709478271986466]
	TIME [epoch: 9.24 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.245489649114204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.245489649114204 | validation: 2.3910183313376367]
	TIME [epoch: 9.24 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.323329295470877		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.323329295470877 | validation: 2.4601300018231194]
	TIME [epoch: 9.24 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2897153356410076		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2897153356410076 | validation: 2.301263112800628]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.237718984489688		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.237718984489688 | validation: 2.3455338375603896]
	TIME [epoch: 9.23 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1236644974371135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1236644974371135 | validation: 2.280846446673058]
	TIME [epoch: 9.22 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.109443343825757		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.109443343825757 | validation: 2.2862235525203243]
	TIME [epoch: 9.23 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0446241946141854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0446241946141854 | validation: 2.0899827766404337]
	TIME [epoch: 9.21 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9072673769648267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9072673769648267 | validation: 2.1414026091620477]
	TIME [epoch: 9.24 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.814312553099471		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.814312553099471 | validation: 1.8605227522090808]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6848619411718855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6848619411718855 | validation: 1.6195114843900211]
	TIME [epoch: 9.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4708340056981632		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4708340056981632 | validation: 1.291802069149261]
	TIME [epoch: 9.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4920109713884275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4920109713884275 | validation: 1.607656011367248]
	TIME [epoch: 9.23 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.30018701196505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.30018701196505 | validation: 1.1765069031307873]
	TIME [epoch: 9.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1790238423171213		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1790238423171213 | validation: 1.2107139121220905]
	TIME [epoch: 9.23 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.260126207818719		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.260126207818719 | validation: 1.1084313667497443]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1500396794279293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1500396794279293 | validation: 1.082088475095111]
	TIME [epoch: 9.22 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0293312233285168		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0293312233285168 | validation: 1.1317206726294768]
	TIME [epoch: 9.24 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1381647608868597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1381647608868597 | validation: 0.9902871574379326]
	TIME [epoch: 9.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9035594835495419		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9035594835495419 | validation: 1.1400035794331098]
	TIME [epoch: 9.24 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.111908471564617		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.111908471564617 | validation: 1.0668116802162915]
	TIME [epoch: 9.22 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9303000126532065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9303000126532065 | validation: 0.8338984111581005]
	TIME [epoch: 9.22 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7884811585784954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7884811585784954 | validation: 0.7384501530753137]
	TIME [epoch: 9.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8479224722036699		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8479224722036699 | validation: 1.7319885271161486]
	TIME [epoch: 9.24 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0997620420322978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0997620420322978 | validation: 0.6813108837940027]
	TIME [epoch: 9.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7207707155713194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7207707155713194 | validation: 0.6275513786505338]
	TIME [epoch: 9.22 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6963376307276633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6963376307276633 | validation: 0.9291194713807817]
	TIME [epoch: 9.23 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7791518606317872		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7791518606317872 | validation: 0.7429234118071399]
	TIME [epoch: 9.24 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8459054365310705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8459054365310705 | validation: 0.6325220134999952]
	TIME [epoch: 9.23 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5941212278404178		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5941212278404178 | validation: 0.5415014328497025]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6338714652351705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6338714652351705 | validation: 0.809503800684432]
	TIME [epoch: 9.24 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6519259780079175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6519259780079175 | validation: 0.5251127444124651]
	TIME [epoch: 9.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5802432862974927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5802432862974927 | validation: 1.0827802435041407]
	TIME [epoch: 9.25 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8201901127591735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8201901127591735 | validation: 0.5290872680336137]
	TIME [epoch: 9.24 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6156064165066044		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 0.6156064165066044 | validation: 0.6323518795093124]
	TIME [epoch: 9.23 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6587626268582061		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 0.6587626268582061 | validation: 0.5679231581423774]
	TIME [epoch: 9.24 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5729068107814579		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.5729068107814579 | validation: 0.7060912250354671]
	TIME [epoch: 9.24 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6372179368138827		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 0.6372179368138827 | validation: 0.5790822556161888]
	TIME [epoch: 9.25 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6014785717434943		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.6014785717434943 | validation: 0.9802649816015614]
	TIME [epoch: 9.24 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7290287454713453		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 0.7290287454713453 | validation: 0.5576540008502899]
	TIME [epoch: 9.24 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5231592426283318		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 0.5231592426283318 | validation: 0.48122539570263095]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5449782386235942		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 0.5449782386235942 | validation: 0.5310879531239068]
	TIME [epoch: 9.22 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5142807116711315		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 0.5142807116711315 | validation: 0.7149130514587081]
	TIME [epoch: 9.23 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7716751149488428		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.7716751149488428 | validation: 1.1913156165299736]
	TIME [epoch: 9.23 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8435476710223045		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 0.8435476710223045 | validation: 0.6334450540479224]
	TIME [epoch: 9.22 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5401504414529612		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.5401504414529612 | validation: 0.5126946326094678]
	TIME [epoch: 9.23 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4300152688711927		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 0.4300152688711927 | validation: 0.3785530158962845]
	TIME [epoch: 9.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6479478479219782		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 0.6479478479219782 | validation: 0.7173499930746206]
	TIME [epoch: 9.25 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5868921074461081		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.5868921074461081 | validation: 0.4324231995093333]
	TIME [epoch: 9.24 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40739108050757145		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 0.40739108050757145 | validation: 0.49184660505239286]
	TIME [epoch: 9.23 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4820862625575744		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 0.4820862625575744 | validation: 0.8149954045597642]
	TIME [epoch: 9.23 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6244936258924916		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 0.6244936258924916 | validation: 0.6366324635948696]
	TIME [epoch: 9.24 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5744307712577735		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 0.5744307712577735 | validation: 0.5158956334972915]
	TIME [epoch: 9.24 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46871132058281145		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.46871132058281145 | validation: 0.37576520901692895]
	TIME [epoch: 9.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4445023596973675		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.4445023596973675 | validation: 0.45605948018295267]
	TIME [epoch: 9.23 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47566255260180157		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 0.47566255260180157 | validation: 0.42417738497051904]
	TIME [epoch: 9.24 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4854955073263386		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 0.4854955073263386 | validation: 0.49050991575627767]
	TIME [epoch: 9.24 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4535924617312109		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 0.4535924617312109 | validation: 0.42129138858574666]
	TIME [epoch: 9.24 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5835198523180686		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.5835198523180686 | validation: 0.4981926931760832]
	TIME [epoch: 9.24 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4700528307055988		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 0.4700528307055988 | validation: 0.41522835018946125]
	TIME [epoch: 9.23 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39817010720115104		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 0.39817010720115104 | validation: 0.38944881647136165]
	TIME [epoch: 9.24 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44181261637319824		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 0.44181261637319824 | validation: 0.353125699319304]
	TIME [epoch: 9.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3619525665543978		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 0.3619525665543978 | validation: 0.359641609242864]
	TIME [epoch: 9.24 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5234838720992326		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.5234838720992326 | validation: 0.4075817477802932]
	TIME [epoch: 9.24 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4378758312911958		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.4378758312911958 | validation: 0.3692618496546888]
	TIME [epoch: 9.23 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34044679385241655		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 0.34044679385241655 | validation: 0.35247169392057887]
	TIME [epoch: 9.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6110566709467107		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 0.6110566709467107 | validation: 0.46758651586160827]
	TIME [epoch: 9.23 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41186293065776974		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.41186293065776974 | validation: 0.5202835386405785]
	TIME [epoch: 9.23 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5011699314117861		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.5011699314117861 | validation: 0.5216364224402872]
	TIME [epoch: 9.22 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41003578663395146		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.41003578663395146 | validation: 0.4363425746015596]
	TIME [epoch: 9.22 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4132555905686681		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.4132555905686681 | validation: 0.48977502025242736]
	TIME [epoch: 9.22 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4177817296634332		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 0.4177817296634332 | validation: 0.45540536436266105]
	TIME [epoch: 9.25 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3709349606466307		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.3709349606466307 | validation: 0.604774511730117]
	TIME [epoch: 9.24 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6026216259097932		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.6026216259097932 | validation: 0.5018802227878694]
	TIME [epoch: 9.22 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45685132937496287		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.45685132937496287 | validation: 0.4033377455859122]
	TIME [epoch: 9.23 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3390109463970603		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.3390109463970603 | validation: 0.362206957519121]
	TIME [epoch: 9.25 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37324008808193915		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 0.37324008808193915 | validation: 0.5894281487881725]
	TIME [epoch: 9.25 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.504091890361698		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.504091890361698 | validation: 0.27516396807687793]
	TIME [epoch: 9.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4066341118018647		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.4066341118018647 | validation: 0.4323329048012041]
	TIME [epoch: 9.23 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4326916108087641		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.4326916108087641 | validation: 0.3030921265238721]
	TIME [epoch: 9.23 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2687193776397588		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.2687193776397588 | validation: 0.289637334273202]
	TIME [epoch: 9.23 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49350201453495224		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.49350201453495224 | validation: 0.4771593770561794]
	TIME [epoch: 9.24 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4218063073552216		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.4218063073552216 | validation: 0.3746850303442565]
	TIME [epoch: 9.23 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3590967323969993		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.3590967323969993 | validation: 0.413721575542112]
	TIME [epoch: 9.23 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32008066225039733		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.32008066225039733 | validation: 0.2969437057779505]
	TIME [epoch: 9.23 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34633941987179395		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.34633941987179395 | validation: 0.3790905588920086]
	TIME [epoch: 9.23 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33527902600868725		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.33527902600868725 | validation: 0.3006037675117112]
	TIME [epoch: 9.23 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29164193607988403		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.29164193607988403 | validation: 0.23492933708204933]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3696893354714166		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.3696893354714166 | validation: 0.23750356409151158]
	TIME [epoch: 9.22 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29941735795128904		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.29941735795128904 | validation: 0.2785567976729832]
	TIME [epoch: 9.22 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3049246072594739		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.3049246072594739 | validation: 0.3125283905832149]
	TIME [epoch: 9.22 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25015859357148107		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.25015859357148107 | validation: 0.26651511142631923]
	TIME [epoch: 9.23 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32110467952461064		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.32110467952461064 | validation: 0.3301229510272705]
	TIME [epoch: 9.23 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3142100152456806		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.3142100152456806 | validation: 0.33338747253433987]
	TIME [epoch: 9.21 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3067109018352291		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.3067109018352291 | validation: 0.25441233325417745]
	TIME [epoch: 9.22 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3095266880895795		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.3095266880895795 | validation: 0.3882339736332465]
	TIME [epoch: 9.22 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2802990522258947		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.2802990522258947 | validation: 0.25324492714332797]
	TIME [epoch: 9.24 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25532113258560846		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.25532113258560846 | validation: 0.3557457405117207]
	TIME [epoch: 9.23 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30670349382403417		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.30670349382403417 | validation: 0.29749118565768645]
	TIME [epoch: 9.22 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25175683850339425		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.25175683850339425 | validation: 0.23780668907737285]
	TIME [epoch: 9.23 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29176926358271016		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.29176926358271016 | validation: 0.2490212241117559]
	TIME [epoch: 9.22 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2701932531098792		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.2701932531098792 | validation: 0.18255837039727396]
	TIME [epoch: 9.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_118.pth
	Model improved!!!
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19256438605777307		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.19256438605777307 | validation: 0.31337634292187916]
	TIME [epoch: 9.23 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37909096661336705		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.37909096661336705 | validation: 0.46716403419846675]
	TIME [epoch: 9.23 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35207324068454604		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.35207324068454604 | validation: 0.27324631600486454]
	TIME [epoch: 9.23 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26438289485046196		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.26438289485046196 | validation: 0.5066548697573507]
	TIME [epoch: 9.23 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3021277064364821		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.3021277064364821 | validation: 0.23876956383958003]
	TIME [epoch: 9.25 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3115442472921592		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.3115442472921592 | validation: 0.5788130119168098]
	TIME [epoch: 9.23 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3918246375897419		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.3918246375897419 | validation: 0.3672150078473827]
	TIME [epoch: 9.23 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30039932743080566		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.30039932743080566 | validation: 0.37223268805528276]
	TIME [epoch: 9.24 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3168944615460642		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.3168944615460642 | validation: 0.37123312693244304]
	TIME [epoch: 9.23 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31693874863472815		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.31693874863472815 | validation: 0.3065010360501365]
	TIME [epoch: 9.25 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28908716581823535		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.28908716581823535 | validation: 0.2652111996825106]
	TIME [epoch: 9.23 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2589653788221445		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.2589653788221445 | validation: 0.51106374609673]
	TIME [epoch: 9.23 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3565833646744605		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.3565833646744605 | validation: 0.24505809843630838]
	TIME [epoch: 9.23 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2568663362567277		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.2568663362567277 | validation: 0.2605261991007164]
	TIME [epoch: 9.23 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24295079395061847		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.24295079395061847 | validation: 0.3330783417746457]
	TIME [epoch: 9.25 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23417821907636366		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.23417821907636366 | validation: 0.23415541170857612]
	TIME [epoch: 9.22 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1994809480628727		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.1994809480628727 | validation: 0.20532918095409636]
	TIME [epoch: 9.24 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2317337806987634		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.2317337806987634 | validation: 0.3176707314571869]
	TIME [epoch: 9.23 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29530371112660025		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.29530371112660025 | validation: 0.2956349327179917]
	TIME [epoch: 9.23 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2760815612910388		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.2760815612910388 | validation: 0.2704347840328899]
	TIME [epoch: 9.24 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39844428171691115		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.39844428171691115 | validation: 0.21767175292202787]
	TIME [epoch: 9.23 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2898364077726375		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.2898364077726375 | validation: 0.25180027415518724]
	TIME [epoch: 9.23 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20488788666166086		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.20488788666166086 | validation: 0.19010077794487576]
	TIME [epoch: 9.23 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22972042081037822		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.22972042081037822 | validation: 0.47319114666109174]
	TIME [epoch: 9.23 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3607916423165036		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.3607916423165036 | validation: 0.2870272567881542]
	TIME [epoch: 9.25 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21282737993334302		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.21282737993334302 | validation: 0.17577522108582766]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_144.pth
	Model improved!!!
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17841852465883823		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.17841852465883823 | validation: 0.18810750307605723]
	TIME [epoch: 9.23 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24379195285152983		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.24379195285152983 | validation: 0.19218150707600234]
	TIME [epoch: 9.23 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2434234130691203		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.2434234130691203 | validation: 0.2680139475206373]
	TIME [epoch: 9.23 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20289781379131566		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.20289781379131566 | validation: 0.2323977879080139]
	TIME [epoch: 9.24 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21244240638390569		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.21244240638390569 | validation: 0.1949462281301544]
	TIME [epoch: 9.23 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20809239683581607		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.20809239683581607 | validation: 0.22735523670841506]
	TIME [epoch: 9.23 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22531906747486066		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.22531906747486066 | validation: 0.2637923859182126]
	TIME [epoch: 9.23 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19693487770029547		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.19693487770029547 | validation: 0.16840261919181043]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_152.pth
	Model improved!!!
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3119206623824019		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.3119206623824019 | validation: 0.3836805774212857]
	TIME [epoch: 9.25 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2984712172482325		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.2984712172482325 | validation: 0.2799085643959941]
	TIME [epoch: 9.22 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2410184276639244		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.2410184276639244 | validation: 0.5381392669321572]
	TIME [epoch: 9.22 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.295352061644511		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.295352061644511 | validation: 0.18988467768556283]
	TIME [epoch: 9.23 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1746909582269373		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.1746909582269373 | validation: 0.3043148373464382]
	TIME [epoch: 9.23 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27677994883217266		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.27677994883217266 | validation: 0.8728395903955886]
	TIME [epoch: 9.24 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35225703140579395		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.35225703140579395 | validation: 0.2215673378911514]
	TIME [epoch: 9.22 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20363815994437584		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.20363815994437584 | validation: 0.22236528823432533]
	TIME [epoch: 9.23 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20392551413742027		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.20392551413742027 | validation: 0.202499658576968]
	TIME [epoch: 9.23 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3803549586961266		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.3803549586961266 | validation: 0.2808805900247521]
	TIME [epoch: 9.23 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36611663452021687		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.36611663452021687 | validation: 0.29202729681602235]
	TIME [epoch: 9.24 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34240070960491015		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.34240070960491015 | validation: 0.21302653827120477]
	TIME [epoch: 9.22 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2360288585654618		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.2360288585654618 | validation: 0.1669802864476777]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_165.pth
	Model improved!!!
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19359894574679154		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.19359894574679154 | validation: 0.20554266652563086]
	TIME [epoch: 9.23 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28270574368019225		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.28270574368019225 | validation: 0.28331502863268077]
	TIME [epoch: 9.22 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21941987224885007		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.21941987224885007 | validation: 0.17459102592602405]
	TIME [epoch: 9.23 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15376000004024734		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.15376000004024734 | validation: 0.22362491017185043]
	TIME [epoch: 9.21 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18150588200337908		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.18150588200337908 | validation: 0.15808035440969948]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_170.pth
	Model improved!!!
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1917349897956505		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.1917349897956505 | validation: 0.23225429851795265]
	TIME [epoch: 9.22 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20841280901369783		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.20841280901369783 | validation: 0.1576985698733536]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_172.pth
	Model improved!!!
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22227536260069303		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.22227536260069303 | validation: 0.24655940110194985]
	TIME [epoch: 9.22 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24597069351501044		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.24597069351501044 | validation: 0.21214476272961724]
	TIME [epoch: 9.21 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20526823618884754		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.20526823618884754 | validation: 0.17330029666272345]
	TIME [epoch: 9.21 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1654064622546361		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.1654064622546361 | validation: 0.21168174403793474]
	TIME [epoch: 9.21 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2117013158757432		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.2117013158757432 | validation: 0.20932364803865985]
	TIME [epoch: 9.21 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1819861551788458		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.1819861551788458 | validation: 0.14371592873330064]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_178.pth
	Model improved!!!
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17302243762679637		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.17302243762679637 | validation: 0.2902700896441446]
	TIME [epoch: 9.23 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22634290678602087		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.22634290678602087 | validation: 0.19384477720795393]
	TIME [epoch: 9.23 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27024095878560905		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.27024095878560905 | validation: 0.1681634887618233]
	TIME [epoch: 9.24 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1601305278295962		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.1601305278295962 | validation: 0.20996165161673846]
	TIME [epoch: 9.24 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22043798009448407		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.22043798009448407 | validation: 0.3941538843490413]
	TIME [epoch: 9.24 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26680285249090785		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.26680285249090785 | validation: 0.13989418705203288]
	TIME [epoch: 9.22 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_184.pth
	Model improved!!!
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15195891237273917		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.15195891237273917 | validation: 0.6648741920584202]
	TIME [epoch: 9.23 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2941553585801104		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.2941553585801104 | validation: 0.1311559884989324]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_186.pth
	Model improved!!!
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11904502132365705		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.11904502132365705 | validation: 0.14600218747525923]
	TIME [epoch: 9.24 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14070347287793522		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.14070347287793522 | validation: 0.24468165547701806]
	TIME [epoch: 9.23 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17467059872866164		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.17467059872866164 | validation: 0.13027918442733466]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_189.pth
	Model improved!!!
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20704881963334476		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.20704881963334476 | validation: 0.16650970127675768]
	TIME [epoch: 9.23 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11922645895497805		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.11922645895497805 | validation: 0.23036196347160343]
	TIME [epoch: 9.21 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17178139372346224		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.17178139372346224 | validation: 0.2545513967749827]
	TIME [epoch: 9.24 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2305560022143159		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.2305560022143159 | validation: 0.15762199629754586]
	TIME [epoch: 9.23 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14189179764896828		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.14189179764896828 | validation: 0.2666518176042968]
	TIME [epoch: 9.23 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17043709694160905		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.17043709694160905 | validation: 0.1189257544031996]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_195.pth
	Model improved!!!
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14841675250955932		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.14841675250955932 | validation: 0.12454359842323696]
	TIME [epoch: 9.24 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13822986307300988		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.13822986307300988 | validation: 0.187599794941887]
	TIME [epoch: 9.24 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19961964910517843		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.19961964910517843 | validation: 0.1676294271684871]
	TIME [epoch: 9.23 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14707348372050247		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.14707348372050247 | validation: 0.1571298417041791]
	TIME [epoch: 9.23 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15204416652144223		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.15204416652144223 | validation: 0.20868549820819254]
	TIME [epoch: 9.22 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1633600183115375		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.1633600183115375 | validation: 0.1000905966357418]
	TIME [epoch: 9.19 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_201.pth
	Model improved!!!
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10495422725069536		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.10495422725069536 | validation: 0.38208904415417744]
	TIME [epoch: 9.24 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3541043103819116		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.3541043103819116 | validation: 0.4021314416945653]
	TIME [epoch: 9.22 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31559179523566167		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.31559179523566167 | validation: 0.2978689066686229]
	TIME [epoch: 9.22 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23504216095939906		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.23504216095939906 | validation: 0.257573738435208]
	TIME [epoch: 9.23 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23556900114886786		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.23556900114886786 | validation: 0.24433912858300816]
	TIME [epoch: 9.23 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20023249551308892		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.20023249551308892 | validation: 0.14089521677784647]
	TIME [epoch: 9.24 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2755200852695897		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.2755200852695897 | validation: 0.25622963573976376]
	TIME [epoch: 9.22 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2926627309431882		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.2926627309431882 | validation: 0.22276848590883214]
	TIME [epoch: 9.24 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18843588051438043		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.18843588051438043 | validation: 0.11150159185047159]
	TIME [epoch: 9.24 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.130790392095975		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.130790392095975 | validation: 0.1754264879776215]
	TIME [epoch: 9.22 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12475291033726098		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.12475291033726098 | validation: 0.09678069323039226]
	TIME [epoch: 9.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_212.pth
	Model improved!!!
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10785366358925413		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.10785366358925413 | validation: 0.08138071092088031]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_213.pth
	Model improved!!!
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08803180039133006		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.08803180039133006 | validation: 0.2041170322850884]
	TIME [epoch: 9.23 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11510414931255719		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.11510414931255719 | validation: 0.09540029648873787]
	TIME [epoch: 9.24 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08485100881251059		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.08485100881251059 | validation: 0.07740165112296062]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_216.pth
	Model improved!!!
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1104525908203513		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.1104525908203513 | validation: 0.18169347856671725]
	TIME [epoch: 9.23 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13613185859359622		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.13613185859359622 | validation: 0.12476694871046379]
	TIME [epoch: 9.24 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11605047342935101		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.11605047342935101 | validation: 0.1029771219669679]
	TIME [epoch: 9.23 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12453547856672761		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.12453547856672761 | validation: 0.13272927830811834]
	TIME [epoch: 9.23 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1009198524073809		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.1009198524073809 | validation: 0.1457079797004963]
	TIME [epoch: 9.23 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11655423561885771		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.11655423561885771 | validation: 0.08270483167296794]
	TIME [epoch: 9.25 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11015368511106001		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.11015368511106001 | validation: 0.19496557906736137]
	TIME [epoch: 9.24 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17525538221994189		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.17525538221994189 | validation: 0.2103983632287984]
	TIME [epoch: 9.24 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12395696239090168		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.12395696239090168 | validation: 0.07432706792909871]
	TIME [epoch: 9.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_225.pth
	Model improved!!!
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09093504090030727		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.09093504090030727 | validation: 0.21229427818804397]
	TIME [epoch: 9.23 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1653543131039055		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.1653543131039055 | validation: 0.14239515331160543]
	TIME [epoch: 9.24 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07936248489259154		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.07936248489259154 | validation: 0.0722978372694376]
	TIME [epoch: 9.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_228.pth
	Model improved!!!
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10646766424786248		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.10646766424786248 | validation: 0.10776832912109965]
	TIME [epoch: 9.21 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07978655380723898		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.07978655380723898 | validation: 0.11166163364304182]
	TIME [epoch: 9.21 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11379624135354408		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.11379624135354408 | validation: 0.07314336898847458]
	TIME [epoch: 9.22 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0650882735608769		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.0650882735608769 | validation: 0.05805214261723333]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_232.pth
	Model improved!!!
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05801324626422103		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.05801324626422103 | validation: 0.08629790440886143]
	TIME [epoch: 9.22 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08488632050252114		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.08488632050252114 | validation: 0.1768793911800146]
	TIME [epoch: 9.23 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1899168853578832		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.1899168853578832 | validation: 0.1725888869652891]
	TIME [epoch: 9.23 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1321064806151325		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.1321064806151325 | validation: 0.0798504682693247]
	TIME [epoch: 9.23 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07638260045805238		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.07638260045805238 | validation: 0.060480858197046385]
	TIME [epoch: 9.24 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061364449468486064		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.061364449468486064 | validation: 0.10317463270301253]
	TIME [epoch: 9.23 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09892748418323427		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.09892748418323427 | validation: 0.062139468336643494]
	TIME [epoch: 9.23 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13043105933298121		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.13043105933298121 | validation: 0.14739755230266166]
	TIME [epoch: 9.24 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0959282565663791		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.0959282565663791 | validation: 0.0870640676087143]
	TIME [epoch: 9.24 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07702392003764764		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.07702392003764764 | validation: 0.08186198970336162]
	TIME [epoch: 9.24 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10981092465349299		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.10981092465349299 | validation: 0.07731176007543508]
	TIME [epoch: 9.23 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07324869094973646		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.07324869094973646 | validation: 0.0651438985972499]
	TIME [epoch: 9.22 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08395843908165514		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.08395843908165514 | validation: 0.1928344627928342]
	TIME [epoch: 9.22 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11364862033481572		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.11364862033481572 | validation: 0.0508464540295261]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_246.pth
	Model improved!!!
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07456845895086539		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.07456845895086539 | validation: 0.12085283085153896]
	TIME [epoch: 9.24 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08720619471579419		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.08720619471579419 | validation: 0.043031114414864666]
	TIME [epoch: 9.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_248.pth
	Model improved!!!
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06692860464332027		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.06692860464332027 | validation: 0.09356061672252727]
	TIME [epoch: 9.24 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07732009855065888		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.07732009855065888 | validation: 0.09251966399712516]
	TIME [epoch: 9.23 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08026722588221832		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.08026722588221832 | validation: 0.05386451060981805]
	TIME [epoch: 9.25 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0658725556571209		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.0658725556571209 | validation: 0.06931289512399164]
	TIME [epoch: 9.23 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09782268822542539		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.09782268822542539 | validation: 0.09978807346603019]
	TIME [epoch: 9.24 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07491386192437162		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.07491386192437162 | validation: 0.0911979680774211]
	TIME [epoch: 9.23 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06350981166260503		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.06350981166260503 | validation: 0.0648263899627543]
	TIME [epoch: 9.23 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08294434775784923		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.08294434775784923 | validation: 0.06376180329509212]
	TIME [epoch: 9.24 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07145903164884826		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.07145903164884826 | validation: 0.043429213628492586]
	TIME [epoch: 9.23 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03833529023018108		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.03833529023018108 | validation: 0.04727458965004504]
	TIME [epoch: 9.23 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09465267962614017		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.09465267962614017 | validation: 0.050675355936474376]
	TIME [epoch: 9.23 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04911763218450861		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.04911763218450861 | validation: 0.0793995955410632]
	TIME [epoch: 9.23 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06851151091258616		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.06851151091258616 | validation: 0.0601758153319989]
	TIME [epoch: 9.24 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052224565560556505		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.052224565560556505 | validation: 0.04728576793649167]
	TIME [epoch: 9.23 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08318200574260656		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.08318200574260656 | validation: 0.08625460841069629]
	TIME [epoch: 9.24 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0529801636560821		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.0529801636560821 | validation: 0.10027702809269151]
	TIME [epoch: 9.23 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07269069960476347		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.07269069960476347 | validation: 0.03875091142888132]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_265.pth
	Model improved!!!
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05688603047487342		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.05688603047487342 | validation: 0.114637201086456]
	TIME [epoch: 9.24 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05120769724229006		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.05120769724229006 | validation: 0.08351826988975378]
	TIME [epoch: 9.23 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0922088510004156		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.0922088510004156 | validation: 0.03395053215718221]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_268.pth
	Model improved!!!
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03523492197645404		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.03523492197645404 | validation: 0.037213355140600694]
	TIME [epoch: 9.23 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06613278389718755		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.06613278389718755 | validation: 0.037638329083081276]
	TIME [epoch: 9.33 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03820397902015656		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.03820397902015656 | validation: 0.04304567199180921]
	TIME [epoch: 9.24 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06420455447372123		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.06420455447372123 | validation: 0.05643862739396732]
	TIME [epoch: 9.23 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044868859220179434		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.044868859220179434 | validation: 0.038126110522987956]
	TIME [epoch: 9.22 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054697592325032		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.054697592325032 | validation: 0.033883814088300476]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_274.pth
	Model improved!!!
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045657193080105136		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.045657193080105136 | validation: 0.0686042365263941]
	TIME [epoch: 9.23 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05182670508613114		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.05182670508613114 | validation: 0.04971427815128121]
	TIME [epoch: 9.53 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04936575738617884		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.04936575738617884 | validation: 0.03467514853455425]
	TIME [epoch: 9.21 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03863407694790784		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.03863407694790784 | validation: 0.05528940477460399]
	TIME [epoch: 9.21 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05087419652221648		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.05087419652221648 | validation: 0.050424090670190796]
	TIME [epoch: 9.21 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036055240108786364		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.036055240108786364 | validation: 0.02921078953517901]
	TIME [epoch: 9.22 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_280.pth
	Model improved!!!
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04981856628798803		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.04981856628798803 | validation: 0.059320957335471936]
	TIME [epoch: 9.25 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044444230952450384		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.044444230952450384 | validation: 0.06398417558709696]
	TIME [epoch: 9.23 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06708597257065353		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.06708597257065353 | validation: 0.07472583638921126]
	TIME [epoch: 9.23 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054322184283682504		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.054322184283682504 | validation: 0.024437920769108393]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_284.pth
	Model improved!!!
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03030838861075239		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.03030838861075239 | validation: 0.04788343907514807]
	TIME [epoch: 9.24 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042826507484165416		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.042826507484165416 | validation: 0.028691324336848116]
	TIME [epoch: 9.25 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02965181797625114		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.02965181797625114 | validation: 0.0379208477855401]
	TIME [epoch: 9.24 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03786394836711036		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.03786394836711036 | validation: 0.05691202679921087]
	TIME [epoch: 9.24 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050014372693454406		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.050014372693454406 | validation: 0.024068933326592924]
	TIME [epoch: 9.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_289.pth
	Model improved!!!
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03230584886171596		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.03230584886171596 | validation: 0.03201797396256513]
	TIME [epoch: 9.24 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04367377238949678		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.04367377238949678 | validation: 0.045004538306581535]
	TIME [epoch: 9.25 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027540044595165555		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.027540044595165555 | validation: 0.023989609581424896]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_292.pth
	Model improved!!!
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04080576434574111		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.04080576434574111 | validation: 0.06151632100969359]
	TIME [epoch: 9.23 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03679774375909749		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.03679774375909749 | validation: 0.020971066749632457]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_294.pth
	Model improved!!!
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03947489929583935		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.03947489929583935 | validation: 0.04306262195315276]
	TIME [epoch: 9.23 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05116895427470852		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.05116895427470852 | validation: 0.04816512204003211]
	TIME [epoch: 9.24 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02559117684235601		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.02559117684235601 | validation: 0.03574304762479258]
	TIME [epoch: 9.22 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021938592999332242		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.021938592999332242 | validation: 0.02442046536512857]
	TIME [epoch: 9.23 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05779386577847879		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.05779386577847879 | validation: 0.0448124494217733]
	TIME [epoch: 9.22 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03656759728144479		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.03656759728144479 | validation: 0.039204942651287975]
	TIME [epoch: 9.23 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049341102972817664		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.049341102972817664 | validation: 0.06969120316051391]
	TIME [epoch: 9.22 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049939690291751666		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.049939690291751666 | validation: 0.04195367686695871]
	TIME [epoch: 9.21 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04202064915692928		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.04202064915692928 | validation: 0.038264268386826734]
	TIME [epoch: 9.21 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050968544223212384		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.050968544223212384 | validation: 0.026071278117932445]
	TIME [epoch: 9.2 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019647823156940723		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.019647823156940723 | validation: 0.02560583356519819]
	TIME [epoch: 9.22 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03009084993043172		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.03009084993043172 | validation: 0.04964079289344182]
	TIME [epoch: 9.22 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04138601456248425		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.04138601456248425 | validation: 0.023754671182067456]
	TIME [epoch: 9.21 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03367739226213628		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.03367739226213628 | validation: 0.09424516383473308]
	TIME [epoch: 9.2 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047109175868584804		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.047109175868584804 | validation: 0.023084571540027462]
	TIME [epoch: 9.22 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023015181266132397		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.023015181266132397 | validation: 0.06183612907349605]
	TIME [epoch: 9.23 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047930076134762176		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.047930076134762176 | validation: 0.024875948024318993]
	TIME [epoch: 9.24 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02193015922386147		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.02193015922386147 | validation: 0.03838515700733583]
	TIME [epoch: 9.22 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0380691116875443		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.0380691116875443 | validation: 0.02817797038018033]
	TIME [epoch: 9.22 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025012704313685248		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.025012704313685248 | validation: 0.04475933544383094]
	TIME [epoch: 9.22 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035822511899779856		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.035822511899779856 | validation: 0.06651565773657878]
	TIME [epoch: 9.24 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035679941697223605		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.035679941697223605 | validation: 0.01865836704453169]
	TIME [epoch: 9.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_316.pth
	Model improved!!!
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01728044098360218		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.01728044098360218 | validation: 0.020522808049400973]
	TIME [epoch: 9.23 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0239481074163248		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.0239481074163248 | validation: 0.08847266495921777]
	TIME [epoch: 9.23 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046334241501199386		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.046334241501199386 | validation: 0.02007312526519487]
	TIME [epoch: 9.24 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02409467655923144		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.02409467655923144 | validation: 0.035077874757877534]
	TIME [epoch: 9.24 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03181437670726278		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.03181437670726278 | validation: 0.030273601521765742]
	TIME [epoch: 9.25 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04046409801647681		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.04046409801647681 | validation: 0.026018579853401908]
	TIME [epoch: 9.22 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024469442855083304		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.024469442855083304 | validation: 0.03504683232387576]
	TIME [epoch: 9.23 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025447532793292482		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.025447532793292482 | validation: 0.020623888502327846]
	TIME [epoch: 9.24 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026742516272694365		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.026742516272694365 | validation: 0.05720561638121631]
	TIME [epoch: 9.24 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03867522958914353		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.03867522958914353 | validation: 0.023086152151540154]
	TIME [epoch: 9.24 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018414107374411015		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.018414107374411015 | validation: 0.01615614642410493]
	TIME [epoch: 9.21 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_327.pth
	Model improved!!!
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034208613979701485		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.034208613979701485 | validation: 0.08903987154895746]
	TIME [epoch: 9.24 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03737968922982976		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.03737968922982976 | validation: 0.021315844679229153]
	TIME [epoch: 9.24 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024772019927457298		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.024772019927457298 | validation: 0.031849598978225056]
	TIME [epoch: 9.24 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030669476364273536		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.030669476364273536 | validation: 0.019156311980405426]
	TIME [epoch: 9.24 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0202010136661422		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.0202010136661422 | validation: 0.03163230753159673]
	TIME [epoch: 9.23 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0391878987736045		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.0391878987736045 | validation: 0.01965202599625592]
	TIME [epoch: 9.23 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03546686793269617		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.03546686793269617 | validation: 0.03926028588789739]
	TIME [epoch: 9.23 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01862395790578738		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.01862395790578738 | validation: 0.018045897515617953]
	TIME [epoch: 9.24 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026011282004624284		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.026011282004624284 | validation: 0.023680525557700678]
	TIME [epoch: 9.24 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03920876091813544		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.03920876091813544 | validation: 0.04486020278808227]
	TIME [epoch: 9.24 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024117288986163395		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.024117288986163395 | validation: 0.016860329017375122]
	TIME [epoch: 9.23 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013619322153475241		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.013619322153475241 | validation: 0.017536732777942425]
	TIME [epoch: 9.23 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042957790461427905		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.042957790461427905 | validation: 0.01965004023047208]
	TIME [epoch: 9.24 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016543130764529287		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.016543130764529287 | validation: 0.05705409648527031]
	TIME [epoch: 9.24 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028996858436812052		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.028996858436812052 | validation: 0.02166432438657643]
	TIME [epoch: 9.24 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027927440696742543		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.027927440696742543 | validation: 0.028666292160024056]
	TIME [epoch: 9.23 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017989558275767165		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.017989558275767165 | validation: 0.028524657025189568]
	TIME [epoch: 9.24 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024010026141216407		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.024010026141216407 | validation: 0.0298018209442015]
	TIME [epoch: 9.24 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03361906713071583		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.03361906713071583 | validation: 0.019545206372465845]
	TIME [epoch: 9.24 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014836957144779304		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.014836957144779304 | validation: 0.025033259369819913]
	TIME [epoch: 9.23 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0233878846803251		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.0233878846803251 | validation: 0.026033778945376323]
	TIME [epoch: 9.23 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022877591272152567		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.022877591272152567 | validation: 0.028041142219153655]
	TIME [epoch: 9.23 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02860282927777453		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.02860282927777453 | validation: 0.024127501137058638]
	TIME [epoch: 9.24 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02942946553809952		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.02942946553809952 | validation: 0.02735571243321231]
	TIME [epoch: 9.24 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020628691064158086		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.020628691064158086 | validation: 0.016219683973891376]
	TIME [epoch: 9.23 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012342438044550392		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.012342438044550392 | validation: 0.01590617669580369]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_353.pth
	Model improved!!!
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04013976662301569		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.04013976662301569 | validation: 0.03167553027297597]
	TIME [epoch: 9.23 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02009521335041048		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.02009521335041048 | validation: 0.01880897952424735]
	TIME [epoch: 9.24 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018791824145273053		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.018791824145273053 | validation: 0.025496143749401172]
	TIME [epoch: 9.24 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023802548644012687		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.023802548644012687 | validation: 0.015966958779492994]
	TIME [epoch: 9.23 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01707931785072572		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.01707931785072572 | validation: 0.025347674625650442]
	TIME [epoch: 9.23 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033562283856340386		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.033562283856340386 | validation: 0.01766570205174517]
	TIME [epoch: 9.23 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01310711740231968		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.01310711740231968 | validation: 0.018814052730395797]
	TIME [epoch: 9.24 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023084227420968363		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.023084227420968363 | validation: 0.028590216310238125]
	TIME [epoch: 9.24 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025107244683346033		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.025107244683346033 | validation: 0.017097912553719726]
	TIME [epoch: 9.23 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014815318216818314		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.014815318216818314 | validation: 0.01701392181880304]
	TIME [epoch: 9.22 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0325022591738066		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.0325022591738066 | validation: 0.017960781705040323]
	TIME [epoch: 9.23 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024123418649813815		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.024123418649813815 | validation: 0.024276194213383097]
	TIME [epoch: 9.24 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015366903540083373		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.015366903540083373 | validation: 0.01691698227102951]
	TIME [epoch: 9.24 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027164755636983652		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.027164755636983652 | validation: 0.032228227310627626]
	TIME [epoch: 9.23 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020123008872009587		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.020123008872009587 | validation: 0.019206308621333944]
	TIME [epoch: 9.22 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022043814419279772		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.022043814419279772 | validation: 0.018132572987679986]
	TIME [epoch: 9.23 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016158272279251533		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.016158272279251533 | validation: 0.018398168588259073]
	TIME [epoch: 9.25 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021260754564155267		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.021260754564155267 | validation: 0.02715388210809535]
	TIME [epoch: 9.24 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02851701642094886		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.02851701642094886 | validation: 0.016861780281048844]
	TIME [epoch: 9.24 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011020279478046693		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.011020279478046693 | validation: 0.016708435011677406]
	TIME [epoch: 9.24 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01603272710884003		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.01603272710884003 | validation: 0.038851046034536346]
	TIME [epoch: 9.22 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02953890127044727		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.02953890127044727 | validation: 0.01618720695025872]
	TIME [epoch: 9.25 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01787134956094248		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.01787134956094248 | validation: 0.02152666805894533]
	TIME [epoch: 9.24 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02002892231725852		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.02002892231725852 | validation: 0.016673984405012773]
	TIME [epoch: 9.23 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03740611407018829		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.03740611407018829 | validation: 0.05349956689810398]
	TIME [epoch: 9.23 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027811437657352056		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.027811437657352056 | validation: 0.018021563284096355]
	TIME [epoch: 9.22 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013097345279065004		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.013097345279065004 | validation: 0.013426783341092353]
	TIME [epoch: 9.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_380.pth
	Model improved!!!
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02312894880116298		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.02312894880116298 | validation: 0.029942601795922827]
	TIME [epoch: 9.23 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016983620722466942		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.016983620722466942 | validation: 0.020443575032618948]
	TIME [epoch: 9.23 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015058154760723187		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.015058154760723187 | validation: 0.03399416205869995]
	TIME [epoch: 9.23 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028831864037087526		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.028831864037087526 | validation: 0.014756293686864742]
	TIME [epoch: 9.23 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015398025313680352		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.015398025313680352 | validation: 0.01403076326434732]
	TIME [epoch: 9.25 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014882257005609734		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.014882257005609734 | validation: 0.030626065430224125]
	TIME [epoch: 9.23 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024086969511394267		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.024086969511394267 | validation: 0.018719702906140515]
	TIME [epoch: 9.22 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013065049902869552		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.013065049902869552 | validation: 0.009651690542817821]
	TIME [epoch: 9.22 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_388.pth
	Model improved!!!
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015564901894536715		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.015564901894536715 | validation: 0.03424124244728672]
	TIME [epoch: 9.22 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021318765270176072		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.021318765270176072 | validation: 0.011105731944434795]
	TIME [epoch: 9.24 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017391590350273673		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.017391590350273673 | validation: 0.025219787704384263]
	TIME [epoch: 9.23 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020621156958286337		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.020621156958286337 | validation: 0.025303085153461333]
	TIME [epoch: 9.22 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0194521160296937		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.0194521160296937 | validation: 0.03042912445651395]
	TIME [epoch: 9.22 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02314149971315439		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.02314149971315439 | validation: 0.019021971746877725]
	TIME [epoch: 9.21 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01287332063193972		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.01287332063193972 | validation: 0.019527621078273518]
	TIME [epoch: 9.23 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01829727617643423		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.01829727617643423 | validation: 0.013795747407676551]
	TIME [epoch: 9.22 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010696301177583424		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.010696301177583424 | validation: 0.015809400048381293]
	TIME [epoch: 9.22 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02698386535376481		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.02698386535376481 | validation: 0.04497692999525221]
	TIME [epoch: 9.22 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019053143739841835		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.019053143739841835 | validation: 0.01017629101086939]
	TIME [epoch: 9.22 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011579650694981992		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.011579650694981992 | validation: 0.011447784610203238]
	TIME [epoch: 9.25 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02050640827470253		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.02050640827470253 | validation: 0.02148546685992296]
	TIME [epoch: 9.22 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015931164147774242		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.015931164147774242 | validation: 0.014917071072519262]
	TIME [epoch: 9.22 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011980824355600134		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.011980824355600134 | validation: 0.009120559135303848]
	TIME [epoch: 9.21 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_403.pth
	Model improved!!!
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0172587367171325		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.0172587367171325 | validation: 0.05178784921274446]
	TIME [epoch: 9.22 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026700869151123508		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.026700869151123508 | validation: 0.014750072264638814]
	TIME [epoch: 9.25 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012415448291934632		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.012415448291934632 | validation: 0.01947643295057857]
	TIME [epoch: 9.24 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023970098188120036		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.023970098188120036 | validation: 0.02582204665452001]
	TIME [epoch: 9.23 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014526459504936912		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.014526459504936912 | validation: 0.013704490280172166]
	TIME [epoch: 9.23 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016730115575632525		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.016730115575632525 | validation: 0.012567974107305145]
	TIME [epoch: 9.22 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011955626318367664		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.011955626318367664 | validation: 0.023215956943109607]
	TIME [epoch: 9.24 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01712564562326566		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.01712564562326566 | validation: 0.012422247390565664]
	TIME [epoch: 9.23 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017737758819744556		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.017737758819744556 | validation: 0.015617744957841916]
	TIME [epoch: 9.23 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014997177535840563		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.014997177535840563 | validation: 0.01551557030944835]
	TIME [epoch: 9.23 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023274548240181776		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.023274548240181776 | validation: 0.013293393569505565]
	TIME [epoch: 9.23 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01109335581631616		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.01109335581631616 | validation: 0.014202402524606625]
	TIME [epoch: 9.23 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016891047532912297		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.016891047532912297 | validation: 0.02045884104783052]
	TIME [epoch: 9.23 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016864450645400424		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.016864450645400424 | validation: 0.040377927493559174]
	TIME [epoch: 9.23 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022756656921138724		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.022756656921138724 | validation: 0.014954105679571828]
	TIME [epoch: 9.23 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011750781162299738		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.011750781162299738 | validation: 0.024118898815663658]
	TIME [epoch: 9.23 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01926656014948077		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.01926656014948077 | validation: 0.01574325015488466]
	TIME [epoch: 9.23 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02735232975236346		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.02735232975236346 | validation: 0.01336701696434502]
	TIME [epoch: 9.23 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011591279060029352		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.011591279060029352 | validation: 0.008219807362629686]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_422.pth
	Model improved!!!
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007996117806066693		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.007996117806066693 | validation: 0.011048680603848261]
	TIME [epoch: 9.23 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024201195854873656		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.024201195854873656 | validation: 0.01467652263449997]
	TIME [epoch: 9.23 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012992057693984559		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.012992057693984559 | validation: 0.011467462916961496]
	TIME [epoch: 9.24 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010151404785588587		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.010151404785588587 | validation: 0.011243268889160357]
	TIME [epoch: 9.23 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012036448541857264		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.012036448541857264 | validation: 0.028947405773145925]
	TIME [epoch: 9.23 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025376097047110503		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.025376097047110503 | validation: 0.017043657518461104]
	TIME [epoch: 9.23 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01168389218051015		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.01168389218051015 | validation: 0.008767957411401022]
	TIME [epoch: 9.23 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009691756195202978		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.009691756195202978 | validation: 0.019583678210048527]
	TIME [epoch: 9.23 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021429573706675625		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.021429573706675625 | validation: 0.02534833216369506]
	TIME [epoch: 9.23 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016821318882813803		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.016821318882813803 | validation: 0.022303109174936893]
	TIME [epoch: 9.24 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022546718164559935		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.022546718164559935 | validation: 0.033415717587087404]
	TIME [epoch: 9.23 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018285287629525426		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.018285287629525426 | validation: 0.01232706846709845]
	TIME [epoch: 9.23 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010560801775531656		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.010560801775531656 | validation: 0.012366187125961029]
	TIME [epoch: 9.24 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01463557226520293		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.01463557226520293 | validation: 0.01808794582213279]
	TIME [epoch: 9.23 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016347486276860012		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.016347486276860012 | validation: 0.012296110162071225]
	TIME [epoch: 9.24 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012785660675423203		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.012785660675423203 | validation: 0.021612390401509154]
	TIME [epoch: 9.23 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051350568529031804		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.051350568529031804 | validation: 0.0731702220952818]
	TIME [epoch: 9.23 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06771225075911395		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.06771225075911395 | validation: 0.04916007993890886]
	TIME [epoch: 9.24 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027357698893573763		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.027357698893573763 | validation: 0.014517842078817088]
	TIME [epoch: 9.22 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013443137130246655		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.013443137130246655 | validation: 0.01009877171515251]
	TIME [epoch: 9.23 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020100321005344684		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.020100321005344684 | validation: 0.016444409100060335]
	TIME [epoch: 9.23 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01007079962913095		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.01007079962913095 | validation: 0.008030747082299072]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_444.pth
	Model improved!!!
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007943305600751826		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.007943305600751826 | validation: 0.017873817801119025]
	TIME [epoch: 9.24 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023917451855823172		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.023917451855823172 | validation: 0.008734406993491532]
	TIME [epoch: 9.22 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014387620620073198		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.014387620620073198 | validation: 0.008599827280993193]
	TIME [epoch: 9.22 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008311778425854802		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.008311778425854802 | validation: 0.008248550090836434]
	TIME [epoch: 9.23 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00758840434743404		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.00758840434743404 | validation: 0.011861451078753641]
	TIME [epoch: 9.23 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02297142620566092		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.02297142620566092 | validation: 0.008927771234974763]
	TIME [epoch: 9.24 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009887598498336581		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.009887598498336581 | validation: 0.009913450870405642]
	TIME [epoch: 9.23 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009378496313425976		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.009378496313425976 | validation: 0.009176584548772234]
	TIME [epoch: 9.23 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019206490211036494		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.019206490211036494 | validation: 0.01713433481286933]
	TIME [epoch: 9.23 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015725047297192363		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.015725047297192363 | validation: 0.01620750909872953]
	TIME [epoch: 9.23 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015109188828676443		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.015109188828676443 | validation: 0.011193205828329542]
	TIME [epoch: 9.25 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010466026586202529		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.010466026586202529 | validation: 0.009756870229496586]
	TIME [epoch: 9.22 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009278553795212304		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.009278553795212304 | validation: 0.00986751029031432]
	TIME [epoch: 9.23 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016132936851477542		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.016132936851477542 | validation: 0.01464685659341803]
	TIME [epoch: 9.24 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010089091683983628		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.010089091683983628 | validation: 0.011591239527409637]
	TIME [epoch: 9.24 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016660482923153187		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.016660482923153187 | validation: 0.014556027020090947]
	TIME [epoch: 9.28 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012287743913956012		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.012287743913956012 | validation: 0.010086982021055874]
	TIME [epoch: 9.32 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01256526556907337		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.01256526556907337 | validation: 0.015866145141695473]
	TIME [epoch: 9.23 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011928824284561415		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.011928824284561415 | validation: 0.009154823376422155]
	TIME [epoch: 9.24 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008487487672565845		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.008487487672565845 | validation: 0.011268243328317887]
	TIME [epoch: 9.26 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020915867115942045		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.020915867115942045 | validation: 0.012159760389249378]
	TIME [epoch: 9.25 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012854953276007709		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.012854953276007709 | validation: 0.009540247856564795]
	TIME [epoch: 9.27 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010329672143547136		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.010329672143547136 | validation: 0.013542994362255076]
	TIME [epoch: 9.23 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010928524166254453		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.010928524166254453 | validation: 0.015893700461406833]
	TIME [epoch: 9.23 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013582814675535524		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.013582814675535524 | validation: 0.015038729338149483]
	TIME [epoch: 9.23 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010915644568199025		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.010915644568199025 | validation: 0.010991168885436138]
	TIME [epoch: 9.24 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008303415062006918		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.008303415062006918 | validation: 0.011838421934494752]
	TIME [epoch: 9.23 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019305891012373122		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.019305891012373122 | validation: 0.01023660873616644]
	TIME [epoch: 9.22 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008155532070793182		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.008155532070793182 | validation: 0.011075733467738096]
	TIME [epoch: 9.23 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01245345515273956		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.01245345515273956 | validation: 0.016548232955236553]
	TIME [epoch: 9.23 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010169311749910113		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.010169311749910113 | validation: 0.012026740719089983]
	TIME [epoch: 9.24 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01152808340743293		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.01152808340743293 | validation: 0.017281836111778852]
	TIME [epoch: 9.23 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012015214984599648		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.012015214984599648 | validation: 0.009479332169482862]
	TIME [epoch: 9.23 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009911808957977357		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.009911808957977357 | validation: 0.009332459120117657]
	TIME [epoch: 9.22 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01394955448160478		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.01394955448160478 | validation: 0.02544593990924625]
	TIME [epoch: 9.23 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014736395306406622		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.014736395306406622 | validation: 0.010017811897147656]
	TIME [epoch: 9.24 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009572471207255778		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.009572471207255778 | validation: 0.014289276862903863]
	TIME [epoch: 9.24 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012598277585321619		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.012598277585321619 | validation: 0.008845320911957555]
	TIME [epoch: 9.23 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0077462302581891435		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.0077462302581891435 | validation: 0.006871910235056009]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_483.pth
	Model improved!!!
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019499630098689942		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.019499630098689942 | validation: 0.014224249256586552]
	TIME [epoch: 9.23 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0110062513157318		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.0110062513157318 | validation: 0.012602345685009154]
	TIME [epoch: 9.25 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008775407813375689		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.008775407813375689 | validation: 0.00835311743775965]
	TIME [epoch: 9.23 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008870323989856231		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.008870323989856231 | validation: 0.009959926975131464]
	TIME [epoch: 9.23 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009507634931715726		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.009507634931715726 | validation: 0.008102349221732572]
	TIME [epoch: 9.22 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014147433407179772		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.014147433407179772 | validation: 0.024898503652109473]
	TIME [epoch: 9.23 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01458327034458811		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.01458327034458811 | validation: 0.012878292078596977]
	TIME [epoch: 9.24 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009204176055303607		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.009204176055303607 | validation: 0.007081665241627072]
	TIME [epoch: 9.23 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00785198313677414		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.00785198313677414 | validation: 0.01623570700849861]
	TIME [epoch: 9.22 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01926381366411834		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.01926381366411834 | validation: 0.01153832625398303]
	TIME [epoch: 9.22 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010263895509740727		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.010263895509740727 | validation: 0.009344452738222181]
	TIME [epoch: 9.24 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00880921627020328		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.00880921627020328 | validation: 0.013791940199372915]
	TIME [epoch: 9.25 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009725436836342681		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.009725436836342681 | validation: 0.009397651860567315]
	TIME [epoch: 9.23 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01283422077928597		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.01283422077928597 | validation: 0.009528510738792528]
	TIME [epoch: 9.23 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00864318491685617		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.00864318491685617 | validation: 0.011475467783643374]
	TIME [epoch: 9.23 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012652853872857684		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.012652853872857684 | validation: 0.007703010064370106]
	TIME [epoch: 9.22 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009607256035161282		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.009607256035161282 | validation: 0.009991694881621004]
	TIME [epoch: 9.24 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009080156882790028		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.009080156882790028 | validation: 0.010047670859685526]
	TIME [epoch: 9.22 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016340640995053664		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.016340640995053664 | validation: 0.008215418326363983]
	TIME [epoch: 9.22 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010211201255869561		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.010211201255869561 | validation: 0.009424245942659374]
	TIME [epoch: 9.22 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007062001043849402		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.007062001043849402 | validation: 0.013033799692588992]
	TIME [epoch: 9.22 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01005048711584558		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.01005048711584558 | validation: 0.011547948899439098]
	TIME [epoch: 9.24 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010612141614305315		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.010612141614305315 | validation: 0.011886752730555493]
	TIME [epoch: 9.22 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011236114990584349		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.011236114990584349 | validation: 0.01373060226745223]
	TIME [epoch: 9.22 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01066944927535635		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.01066944927535635 | validation: 0.012951843613342364]
	TIME [epoch: 9.22 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010897658889632495		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.010897658889632495 | validation: 0.008670274986355348]
	TIME [epoch: 9.22 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007528540656419053		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.007528540656419053 | validation: 0.009508889734252355]
	TIME [epoch: 9.24 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007713243674112715		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.007713243674112715 | validation: 0.007287094503857081]
	TIME [epoch: 9.22 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013024376928454338		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.013024376928454338 | validation: 0.030180446224238835]
	TIME [epoch: 9.22 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014081294846152172		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.014081294846152172 | validation: 0.008671883666693681]
	TIME [epoch: 9.23 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008442739091745245		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.008442739091745245 | validation: 0.00661386095365769]
	TIME [epoch: 9.21 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_514.pth
	Model improved!!!
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008622310415579728		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.008622310415579728 | validation: 0.013236538536224637]
	TIME [epoch: 9.23 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010679811622936432		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.010679811622936432 | validation: 0.011042942528432246]
	TIME [epoch: 9.22 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011322513138198846		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.011322513138198846 | validation: 0.010187571029360503]
	TIME [epoch: 9.21 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007988770750280262		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.007988770750280262 | validation: 0.007166706054513019]
	TIME [epoch: 9.21 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010374133311571148		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.010374133311571148 | validation: 0.02424780466475846]
	TIME [epoch: 9.22 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01219071187047258		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.01219071187047258 | validation: 0.007935210684391406]
	TIME [epoch: 9.23 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006517816974297933		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.006517816974297933 | validation: 0.00992245708785795]
	TIME [epoch: 9.22 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0132451179978928		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.0132451179978928 | validation: 0.01299849984648906]
	TIME [epoch: 9.22 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009073294990535477		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.009073294990535477 | validation: 0.012136895903998938]
	TIME [epoch: 9.22 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010034240573453097		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.010034240573453097 | validation: 0.03365718857321473]
	TIME [epoch: 9.23 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026370009810607248		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.026370009810607248 | validation: 0.015155024680417297]
	TIME [epoch: 9.22 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0102006036389272		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.0102006036389272 | validation: 0.009942870234195305]
	TIME [epoch: 9.22 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00825036155412838		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.00825036155412838 | validation: 0.01325236820379027]
	TIME [epoch: 9.23 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00869091692522496		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.00869091692522496 | validation: 0.009363345460752496]
	TIME [epoch: 9.22 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007553960945692899		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.007553960945692899 | validation: 0.008612573601611996]
	TIME [epoch: 9.23 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012354052706855563		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.012354052706855563 | validation: 0.015276716984738602]
	TIME [epoch: 9.22 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011356982695467812		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.011356982695467812 | validation: 0.02257252706600417]
	TIME [epoch: 9.22 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010796259266540245		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.010796259266540245 | validation: 0.009733527624090986]
	TIME [epoch: 9.21 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010289123677842127		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.010289123677842127 | validation: 0.0135542011376223]
	TIME [epoch: 9.21 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00906867953947495		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.00906867953947495 | validation: 0.00751364723688455]
	TIME [epoch: 9.22 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006430558659976962		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.006430558659976962 | validation: 0.006267636850631771]
	TIME [epoch: 9.22 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_535.pth
	Model improved!!!
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00784420659249789		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.00784420659249789 | validation: 0.012035887498161955]
	TIME [epoch: 9.23 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01653576210813604		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.01653576210813604 | validation: 0.009054166591905773]
	TIME [epoch: 9.23 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006732956657863819		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.006732956657863819 | validation: 0.007731602988003147]
	TIME [epoch: 9.23 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00866374871507829		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.00866374871507829 | validation: 0.012849934050568486]
	TIME [epoch: 9.23 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010612352054022228		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.010612352054022228 | validation: 0.013114913726874544]
	TIME [epoch: 9.24 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010809765624489449		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.010809765624489449 | validation: 0.00794880616518236]
	TIME [epoch: 9.22 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009027283903791948		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.009027283903791948 | validation: 0.011039906915945415]
	TIME [epoch: 9.23 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011082419519611647		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.011082419519611647 | validation: 0.01187854861292605]
	TIME [epoch: 9.23 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007730996312534233		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.007730996312534233 | validation: 0.007796389622102919]
	TIME [epoch: 9.24 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009008584392957417		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.009008584392957417 | validation: 0.01712270622958204]
	TIME [epoch: 9.25 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01385135376206742		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.01385135376206742 | validation: 0.00843921714645135]
	TIME [epoch: 9.22 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009661835814207117		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.009661835814207117 | validation: 0.012245996060588784]
	TIME [epoch: 9.23 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009090938321163014		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.009090938321163014 | validation: 0.0060868648467378265]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_548.pth
	Model improved!!!
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006639761804025651		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.006639761804025651 | validation: 0.00796254959622705]
	TIME [epoch: 9.24 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011539390409676449		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.011539390409676449 | validation: 0.009058427604836487]
	TIME [epoch: 9.23 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006606340164901357		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.006606340164901357 | validation: 0.00911426916087416]
	TIME [epoch: 9.22 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00645893719093202		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.00645893719093202 | validation: 0.007726257777159315]
	TIME [epoch: 9.23 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013968246864400905		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.013968246864400905 | validation: 0.014024258398728597]
	TIME [epoch: 9.23 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007258809095817885		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.007258809095817885 | validation: 0.006029570574054413]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_554.pth
	Model improved!!!
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005838945195375017		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.005838945195375017 | validation: 0.007795608409989869]
	TIME [epoch: 9.23 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009398816607001797		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.009398816607001797 | validation: 0.01701370028924956]
	TIME [epoch: 9.23 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008550208223496766		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.008550208223496766 | validation: 0.009405833996640009]
	TIME [epoch: 9.22 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007000920832106139		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.007000920832106139 | validation: 0.00794960660232554]
	TIME [epoch: 9.22 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008586732296610606		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.008586732296610606 | validation: 0.017352456441974886]
	TIME [epoch: 9.24 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011238793894160338		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.011238793894160338 | validation: 0.009566836619250733]
	TIME [epoch: 9.23 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007671442507666918		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.007671442507666918 | validation: 0.007484868369621365]
	TIME [epoch: 9.23 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007578279954875701		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.007578279954875701 | validation: 0.00912622997857743]
	TIME [epoch: 9.22 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008468818774020656		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.008468818774020656 | validation: 0.009798436792582802]
	TIME [epoch: 9.22 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009366488234665883		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.009366488234665883 | validation: 0.00991448046103224]
	TIME [epoch: 9.24 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00928660506242532		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.00928660506242532 | validation: 0.012888014271111449]
	TIME [epoch: 9.23 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010223214434936078		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.010223214434936078 | validation: 0.009528630959724789]
	TIME [epoch: 9.23 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008689050522943923		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.008689050522943923 | validation: 0.007849829836437599]
	TIME [epoch: 9.22 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006921395097930213		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.006921395097930213 | validation: 0.00883092619384104]
	TIME [epoch: 9.23 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006640998188946749		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.006640998188946749 | validation: 0.008590479704798966]
	TIME [epoch: 9.23 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009407089130319811		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.009407089130319811 | validation: 0.013990368352876252]
	TIME [epoch: 9.24 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007975619975492771		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.007975619975492771 | validation: 0.007282901908370347]
	TIME [epoch: 9.23 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0072620890846859625		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.0072620890846859625 | validation: 0.008622471522930024]
	TIME [epoch: 9.22 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006560266970289193		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.006560266970289193 | validation: 0.009801830579919757]
	TIME [epoch: 9.22 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010931076389446893		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.010931076389446893 | validation: 0.009039612852626187]
	TIME [epoch: 9.24 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008692975268138616		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.008692975268138616 | validation: 0.007410138511589092]
	TIME [epoch: 9.23 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005996379123261719		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.005996379123261719 | validation: 0.00982516348113609]
	TIME [epoch: 9.22 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00872603380805852		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.00872603380805852 | validation: 0.007324130083861734]
	TIME [epoch: 9.23 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00869896972445375		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.00869896972445375 | validation: 0.009966885013155685]
	TIME [epoch: 9.22 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008353405736453861		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.008353405736453861 | validation: 0.007362664238992118]
	TIME [epoch: 9.24 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006912211635890971		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.006912211635890971 | validation: 0.007526631177134925]
	TIME [epoch: 9.23 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007829535419222988		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.007829535419222988 | validation: 0.013670569443076219]
	TIME [epoch: 9.22 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007531833331089114		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.007531833331089114 | validation: 0.008353551914601182]
	TIME [epoch: 9.22 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006842305213225707		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.006842305213225707 | validation: 0.0051162295912464155]
	TIME [epoch: 9.22 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_583.pth
	Model improved!!!
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007556742247739014		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.007556742247739014 | validation: 0.01015314757742446]
	TIME [epoch: 9.23 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008502653123979916		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.008502653123979916 | validation: 0.008546567579208159]
	TIME [epoch: 9.23 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007525977235308432		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.007525977235308432 | validation: 0.007505560566267963]
	TIME [epoch: 9.22 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00668683445207104		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.00668683445207104 | validation: 0.008528129305776046]
	TIME [epoch: 9.23 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008076374491488503		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.008076374491488503 | validation: 0.007443334699825418]
	TIME [epoch: 9.22 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006814195229000765		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.006814195229000765 | validation: 0.010165840412311774]
	TIME [epoch: 9.23 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006765359754735583		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.006765359754735583 | validation: 0.0062320437253097025]
	TIME [epoch: 9.23 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00780783827762388		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.00780783827762388 | validation: 0.010267491054778127]
	TIME [epoch: 9.22 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011839550075958208		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.011839550075958208 | validation: 0.012059179991630833]
	TIME [epoch: 9.22 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008278287280267232		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.008278287280267232 | validation: 0.008034241796380827]
	TIME [epoch: 9.23 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008080993985320195		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.008080993985320195 | validation: 0.006753850875855864]
	TIME [epoch: 9.23 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006648516270292081		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.006648516270292081 | validation: 0.007340922059879]
	TIME [epoch: 9.23 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00786962657236071		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.00786962657236071 | validation: 0.008044879899684698]
	TIME [epoch: 9.22 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006897689157285252		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.006897689157285252 | validation: 0.006635904247573687]
	TIME [epoch: 9.22 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007931386991336567		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.007931386991336567 | validation: 0.008243207631569573]
	TIME [epoch: 9.23 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006577555971526981		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.006577555971526981 | validation: 0.0073554618029589795]
	TIME [epoch: 9.23 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008252786935371553		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.008252786935371553 | validation: 0.007002449941051413]
	TIME [epoch: 9.23 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006094533516543855		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.006094533516543855 | validation: 0.0058836984746462335]
	TIME [epoch: 9.52 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009617845172146077		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.009617845172146077 | validation: 0.01574000767289351]
	TIME [epoch: 9.22 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008660113804780777		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.008660113804780777 | validation: 0.010624486216868134]
	TIME [epoch: 9.22 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007446991019817125		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.007446991019817125 | validation: 0.007977419738910732]
	TIME [epoch: 9.22 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006598557477135721		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.006598557477135721 | validation: 0.00853574511107187]
	TIME [epoch: 9.21 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006491225045142304		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.006491225045142304 | validation: 0.010133868993228472]
	TIME [epoch: 9.21 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008598849199352911		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.008598849199352911 | validation: 0.008967578776328951]
	TIME [epoch: 9.21 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007456819154488082		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.007456819154488082 | validation: 0.010314569481787344]
	TIME [epoch: 9.21 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007183983402292369		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.007183983402292369 | validation: 0.007353357229988428]
	TIME [epoch: 9.23 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0069758401260875185		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.0069758401260875185 | validation: 0.0072782504900095815]
	TIME [epoch: 9.22 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007133716459162916		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.007133716459162916 | validation: 0.008091683004854416]
	TIME [epoch: 9.21 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007781162539915544		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.007781162539915544 | validation: 0.00695567140529184]
	TIME [epoch: 9.22 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0077184846402942545		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.0077184846402942545 | validation: 0.007708527902626113]
	TIME [epoch: 9.23 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004989777732681406		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.004989777732681406 | validation: 0.007437789656751627]
	TIME [epoch: 9.23 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006162939961564957		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.006162939961564957 | validation: 0.00840448679894041]
	TIME [epoch: 9.23 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006942300111160785		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.006942300111160785 | validation: 0.01570638409102549]
	TIME [epoch: 9.22 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009491537130700564		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.009491537130700564 | validation: 0.00912577003982994]
	TIME [epoch: 9.22 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0069934261094866754		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.0069934261094866754 | validation: 0.006949127367230689]
	TIME [epoch: 9.23 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005632686607898638		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.005632686607898638 | validation: 0.006182015393771246]
	TIME [epoch: 9.23 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006331223141333734		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.006331223141333734 | validation: 0.015167134999852509]
	TIME [epoch: 9.23 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008280935655855583		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.008280935655855583 | validation: 0.005135941360755949]
	TIME [epoch: 9.21 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006478597715674572		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.006478597715674572 | validation: 0.007826854939067825]
	TIME [epoch: 9.23 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005370866829606723		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.005370866829606723 | validation: 0.008422890211350498]
	TIME [epoch: 9.23 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008219472968176626		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.008219472968176626 | validation: 0.0064255889078183885]
	TIME [epoch: 9.25 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006292621704287285		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.006292621704287285 | validation: 0.007967876995005802]
	TIME [epoch: 9.23 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008545253303864448		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.008545253303864448 | validation: 0.005527438709300425]
	TIME [epoch: 9.23 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005428969429270208		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.005428969429270208 | validation: 0.00894181191534893]
	TIME [epoch: 9.22 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005916769547184126		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.005916769547184126 | validation: 0.006692403017310282]
	TIME [epoch: 9.23 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007290617643892316		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.007290617643892316 | validation: 0.007451076230470333]
	TIME [epoch: 9.24 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0049138699933038476		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.0049138699933038476 | validation: 0.006926273595283042]
	TIME [epoch: 9.23 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005517592971696694		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.005517592971696694 | validation: 0.006941516604163794]
	TIME [epoch: 9.23 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008010058294062409		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.008010058294062409 | validation: 0.010224556766194194]
	TIME [epoch: 9.23 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007651804155102555		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.007651804155102555 | validation: 0.007960531552960726]
	TIME [epoch: 9.22 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005651326879294214		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.005651326879294214 | validation: 0.006317107379359746]
	TIME [epoch: 9.24 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006183086638171071		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.006183086638171071 | validation: 0.006991814481651888]
	TIME [epoch: 9.23 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007010499869366752		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.007010499869366752 | validation: 0.0051045004417016445]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_636.pth
	Model improved!!!
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005124237761671978		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.005124237761671978 | validation: 0.010599507773921709]
	TIME [epoch: 9.22 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007977165915939579		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.007977165915939579 | validation: 0.006272080935632076]
	TIME [epoch: 9.21 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005531434272967815		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.005531434272967815 | validation: 0.009264831361594852]
	TIME [epoch: 9.23 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005081491790585864		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.005081491790585864 | validation: 0.006399036673619057]
	TIME [epoch: 9.23 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007388634363871141		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.007388634363871141 | validation: 0.007755824052036677]
	TIME [epoch: 9.22 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00637280583095615		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.00637280583095615 | validation: 0.007539815068300596]
	TIME [epoch: 9.23 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005191528283529313		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.005191528283529313 | validation: 0.00543322855822756]
	TIME [epoch: 9.22 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005860703884615841		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.005860703884615841 | validation: 0.010206166356346597]
	TIME [epoch: 9.23 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008034839260602191		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.008034839260602191 | validation: 0.005120413101804828]
	TIME [epoch: 9.23 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0056858330738755415		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.0056858330738755415 | validation: 0.006327096418280436]
	TIME [epoch: 9.22 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00560156823857761		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.00560156823857761 | validation: 0.010215732533600495]
	TIME [epoch: 9.23 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009154699520544447		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.009154699520544447 | validation: 0.008453920107777284]
	TIME [epoch: 9.22 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0057747208131679415		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.0057747208131679415 | validation: 0.005352137669981379]
	TIME [epoch: 9.23 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0053500649054291985		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.0053500649054291985 | validation: 0.006424287453338263]
	TIME [epoch: 9.23 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0066387142872037855		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.0066387142872037855 | validation: 0.006607188637908682]
	TIME [epoch: 9.23 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00640297590341108		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.00640297590341108 | validation: 0.00636960000265462]
	TIME [epoch: 9.23 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005816473592981828		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.005816473592981828 | validation: 0.005341074520247862]
	TIME [epoch: 9.22 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005899802349244405		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.005899802349244405 | validation: 0.007295271606088559]
	TIME [epoch: 9.22 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007012465949900331		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.007012465949900331 | validation: 0.006001940561620374]
	TIME [epoch: 9.22 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005840975917330779		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.005840975917330779 | validation: 0.00502926365337526]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_656.pth
	Model improved!!!
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008180552706713478		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.008180552706713478 | validation: 0.006536211108231655]
	TIME [epoch: 9.23 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006184205069520278		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.006184205069520278 | validation: 0.0055267635495559065]
	TIME [epoch: 9.23 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0049654040312884975		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.0049654040312884975 | validation: 0.006084138960033576]
	TIME [epoch: 9.24 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006103608657569716		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.006103608657569716 | validation: 0.007010698110295897]
	TIME [epoch: 9.22 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009527816661745566		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.009527816661745566 | validation: 0.005527697260566329]
	TIME [epoch: 9.23 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005262503434421093		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.005262503434421093 | validation: 0.006269498431984663]
	TIME [epoch: 9.23 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00546689169875318		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.00546689169875318 | validation: 0.008363967529236786]
	TIME [epoch: 9.23 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00568870472558774		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.00568870472558774 | validation: 0.0053948516007882264]
	TIME [epoch: 9.24 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005411557498835046		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.005411557498835046 | validation: 0.006013075189943798]
	TIME [epoch: 9.23 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005053807004489917		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.005053807004489917 | validation: 0.004592091369381192]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_666.pth
	Model improved!!!
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005558817845868114		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.005558817845868114 | validation: 0.008469071493018556]
	TIME [epoch: 9.23 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006995381352020307		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.006995381352020307 | validation: 0.00543654364489205]
	TIME [epoch: 9.22 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006372044197733631		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.006372044197733631 | validation: 0.007313154106695843]
	TIME [epoch: 9.24 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005299118887696699		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.005299118887696699 | validation: 0.004966086143525213]
	TIME [epoch: 9.24 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004332143968606657		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.004332143968606657 | validation: 0.006324942273588778]
	TIME [epoch: 9.22 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006857660820734885		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.006857660820734885 | validation: 0.004949820383354989]
	TIME [epoch: 9.23 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005187577788260869		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.005187577788260869 | validation: 0.005098761098510809]
	TIME [epoch: 9.23 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006494771079141785		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.006494771079141785 | validation: 0.0068093846679136765]
	TIME [epoch: 9.25 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004428103961848931		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.004428103961848931 | validation: 0.005794530692385974]
	TIME [epoch: 9.23 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006775529670839541		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.006775529670839541 | validation: 0.009177741646123679]
	TIME [epoch: 9.22 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00542604424739628		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.00542604424739628 | validation: 0.007019945433313144]
	TIME [epoch: 9.23 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004955608911348625		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.004955608911348625 | validation: 0.004663570900150257]
	TIME [epoch: 9.22 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005079582577941597		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.005079582577941597 | validation: 0.005977312599467044]
	TIME [epoch: 9.24 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005262598803803277		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.005262598803803277 | validation: 0.008097596928137541]
	TIME [epoch: 9.24 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006674159666210214		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.006674159666210214 | validation: 0.005989072435553029]
	TIME [epoch: 9.22 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005221017501876844		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.005221017501876844 | validation: 0.0046006641701628395]
	TIME [epoch: 9.23 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004461230314491902		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.004461230314491902 | validation: 0.005465261566909171]
	TIME [epoch: 9.23 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005364970372415831		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.005364970372415831 | validation: 0.007642344601744883]
	TIME [epoch: 9.25 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008283703464930322		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.008283703464930322 | validation: 0.00803869892241863]
	TIME [epoch: 9.23 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0054783248302807536		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.0054783248302807536 | validation: 0.005153057595525011]
	TIME [epoch: 9.23 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004389067212866704		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.004389067212866704 | validation: 0.005173016677166459]
	TIME [epoch: 9.22 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0061795975226691165		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.0061795975226691165 | validation: 0.00577202277943422]
	TIME [epoch: 9.23 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004448210986170341		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.004448210986170341 | validation: 0.00543995143136534]
	TIME [epoch: 9.24 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005082796485260325		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.005082796485260325 | validation: 0.010266798951014794]
	TIME [epoch: 9.23 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006042354147008168		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.006042354147008168 | validation: 0.00852038169924377]
	TIME [epoch: 9.23 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005197650663033654		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.005197650663033654 | validation: 0.0058651125250285905]
	TIME [epoch: 9.22 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006118660770122607		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.006118660770122607 | validation: 0.008481226244092505]
	TIME [epoch: 9.22 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005852152705003262		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.005852152705003262 | validation: 0.005861247756909721]
	TIME [epoch: 9.24 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00478673752976373		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.00478673752976373 | validation: 0.005706714690092483]
	TIME [epoch: 9.23 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004703355974604015		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.004703355974604015 | validation: 0.0043524449660289795]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_696.pth
	Model improved!!!
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004753377857204372		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.004753377857204372 | validation: 0.009649678497528884]
	TIME [epoch: 9.23 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006673860212772457		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.006673860212772457 | validation: 0.0059643615243706]
	TIME [epoch: 9.22 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005186009268713517		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.005186009268713517 | validation: 0.005446130462204261]
	TIME [epoch: 9.24 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00456085362050669		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.00456085362050669 | validation: 0.004995822152206522]
	TIME [epoch: 9.23 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004867492878311232		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.004867492878311232 | validation: 0.007259039739787526]
	TIME [epoch: 9.23 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005817480915328216		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.005817480915328216 | validation: 0.009464503895087396]
	TIME [epoch: 9.23 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005518621296196449		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.005518621296196449 | validation: 0.007221878843659362]
	TIME [epoch: 9.22 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0053476119556780674		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.0053476119556780674 | validation: 0.004718813776777275]
	TIME [epoch: 9.24 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004474029834407053		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.004474029834407053 | validation: 0.004860879943856443]
	TIME [epoch: 9.23 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0053027745328401345		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.0053027745328401345 | validation: 0.007484260432172245]
	TIME [epoch: 9.22 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006082296817124223		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.006082296817124223 | validation: 0.005137205315228816]
	TIME [epoch: 9.22 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004752526058389652		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.004752526058389652 | validation: 0.005154027022197194]
	TIME [epoch: 9.22 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005020960898824521		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.005020960898824521 | validation: 0.005792427951793302]
	TIME [epoch: 9.23 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005133321030288756		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.005133321030288756 | validation: 0.006528111773383148]
	TIME [epoch: 9.22 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005050577571506084		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.005050577571506084 | validation: 0.00439283373083561]
	TIME [epoch: 9.22 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004257308265917131		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.004257308265917131 | validation: 0.006073646775054804]
	TIME [epoch: 9.22 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005238893461594963		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.005238893461594963 | validation: 0.00756074347411901]
	TIME [epoch: 9.23 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005731387670869623		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.005731387670869623 | validation: 0.011423147730209422]
	TIME [epoch: 9.23 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006093914869656627		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.006093914869656627 | validation: 0.00557355310030376]
	TIME [epoch: 9.22 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0054961383712636355		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.0054961383712636355 | validation: 0.006620188193978447]
	TIME [epoch: 9.22 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004972838570370182		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.004972838570370182 | validation: 0.004329886489125641]
	TIME [epoch: 9.22 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_717.pth
	Model improved!!!
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005046360463594042		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.005046360463594042 | validation: 0.005759692613153469]
	TIME [epoch: 9.23 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004740069587841846		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.004740069587841846 | validation: 0.0070838900289806]
	TIME [epoch: 9.23 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005558824499398176		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.005558824499398176 | validation: 0.005281193763620317]
	TIME [epoch: 9.22 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004322326592614255		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.004322326592614255 | validation: 0.006471672466164208]
	TIME [epoch: 9.23 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004897788860394608		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.004897788860394608 | validation: 0.005683147163008981]
	TIME [epoch: 9.23 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004574168239918875		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.004574168239918875 | validation: 0.006013300036707631]
	TIME [epoch: 9.24 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005730609245079921		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.005730609245079921 | validation: 0.005126987302743545]
	TIME [epoch: 9.24 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004556948531219381		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.004556948531219381 | validation: 0.004624746795152306]
	TIME [epoch: 9.22 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0045227827874248115		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.0045227827874248115 | validation: 0.004458894301067258]
	TIME [epoch: 9.23 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004583134790720316		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.004583134790720316 | validation: 0.0052244428297268195]
	TIME [epoch: 9.24 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005989085134797183		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.005989085134797183 | validation: 0.005465953243569726]
	TIME [epoch: 9.24 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004718355917017492		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.004718355917017492 | validation: 0.004459930012076529]
	TIME [epoch: 9.24 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004790630075391848		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.004790630075391848 | validation: 0.006106529461468819]
	TIME [epoch: 9.23 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0047391564725434545		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.0047391564725434545 | validation: 0.004262323403355386]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_731.pth
	Model improved!!!
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004186261119742645		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.004186261119742645 | validation: 0.006860532206713832]
	TIME [epoch: 9.22 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005891620158801094		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.005891620158801094 | validation: 0.005019123533220482]
	TIME [epoch: 9.24 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005156205037360553		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.005156205037360553 | validation: 0.0047347366573317375]
	TIME [epoch: 9.25 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004618604466009394		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.004618604466009394 | validation: 0.004122085233808856]
	TIME [epoch: 9.23 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_735.pth
	Model improved!!!
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003877848801417368		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.003877848801417368 | validation: 0.0053704182933119755]
	TIME [epoch: 9.23 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006201529691743663		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.006201529691743663 | validation: 0.004827191485498252]
	TIME [epoch: 9.23 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004483867242092535		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.004483867242092535 | validation: 0.00467112992289693]
	TIME [epoch: 9.24 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004715017324184894		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.004715017324184894 | validation: 0.005115498290039738]
	TIME [epoch: 9.24 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004004063065232607		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.004004063065232607 | validation: 0.0054316440650626005]
	TIME [epoch: 9.24 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004730979817537877		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.004730979817537877 | validation: 0.006275122660616858]
	TIME [epoch: 9.22 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004172239285402508		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.004172239285402508 | validation: 0.007477133308239652]
	TIME [epoch: 9.23 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0051084643680971605		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.0051084643680971605 | validation: 0.007136203249391548]
	TIME [epoch: 9.24 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005823763658335689		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.005823763658335689 | validation: 0.005687158784816591]
	TIME [epoch: 9.23 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005204078952369073		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.005204078952369073 | validation: 0.003765398177964111]
	TIME [epoch: 9.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_745.pth
	Model improved!!!
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005866935516474605		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.005866935516474605 | validation: 0.005124744876631971]
	TIME [epoch: 9.23 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004923996986818729		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.004923996986818729 | validation: 0.00652732106368259]
	TIME [epoch: 9.22 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004473312769539359		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.004473312769539359 | validation: 0.0058786944750646285]
	TIME [epoch: 9.24 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004673022871123004		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.004673022871123004 | validation: 0.004769136636127868]
	TIME [epoch: 9.23 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005022453497399998		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.005022453497399998 | validation: 0.005312511927799885]
	TIME [epoch: 9.23 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004289665781827794		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.004289665781827794 | validation: 0.005724485974781606]
	TIME [epoch: 9.24 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004454766768630047		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.004454766768630047 | validation: 0.00647981349202306]
	TIME [epoch: 9.23 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004322982421996128		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.004322982421996128 | validation: 0.004364130130668151]
	TIME [epoch: 9.24 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003594031650127485		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.003594031650127485 | validation: 0.006094413552437519]
	TIME [epoch: 9.23 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004628699794750755		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.004628699794750755 | validation: 0.005175804253339705]
	TIME [epoch: 9.23 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004769051247553014		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.004769051247553014 | validation: 0.004236972584764239]
	TIME [epoch: 9.23 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003992810109035233		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.003992810109035233 | validation: 0.004403814417033493]
	TIME [epoch: 9.23 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004608899721182355		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.004608899721182355 | validation: 0.004571150603934976]
	TIME [epoch: 9.23 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003730246973803372		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.003730246973803372 | validation: 0.0056592837369775755]
	TIME [epoch: 9.23 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004764607921634994		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.004764607921634994 | validation: 0.004817835988754387]
	TIME [epoch: 9.23 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00543490950128582		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.00543490950128582 | validation: 0.005263539123214135]
	TIME [epoch: 9.23 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004800486040663313		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.004800486040663313 | validation: 0.004911366802338954]
	TIME [epoch: 9.23 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003954681255509405		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.003954681255509405 | validation: 0.004106511178254989]
	TIME [epoch: 9.23 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035878413267778453		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.0035878413267778453 | validation: 0.004456776924714002]
	TIME [epoch: 9.23 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038530753013090255		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.0038530753013090255 | validation: 0.005490581519129419]
	TIME [epoch: 9.23 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005519604078834163		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.005519604078834163 | validation: 0.00718116155530969]
	TIME [epoch: 9.23 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004440190363924871		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.004440190363924871 | validation: 0.006837828323904494]
	TIME [epoch: 9.23 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00428969662064918		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.00428969662064918 | validation: 0.00414322396218734]
	TIME [epoch: 9.24 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004175121312646422		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.004175121312646422 | validation: 0.004528712077729472]
	TIME [epoch: 9.23 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004041265758963757		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.004041265758963757 | validation: 0.004012763343841406]
	TIME [epoch: 9.23 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004378163801432746		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.004378163801432746 | validation: 0.0063401214890098]
	TIME [epoch: 9.23 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0046545857932553305		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.0046545857932553305 | validation: 0.005605089781458261]
	TIME [epoch: 9.22 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004685691221117789		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.004685691221117789 | validation: 0.004171769642441869]
	TIME [epoch: 9.24 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0050085210367017685		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.0050085210367017685 | validation: 0.0048495198540992905]
	TIME [epoch: 9.22 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004675693655117996		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.004675693655117996 | validation: 0.004568499490735606]
	TIME [epoch: 9.23 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004055342063283146		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.004055342063283146 | validation: 0.004812359794641117]
	TIME [epoch: 9.23 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00409770268500778		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.00409770268500778 | validation: 0.007530425232509245]
	TIME [epoch: 9.23 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009831871442897289		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.009831871442897289 | validation: 0.012313233498478019]
	TIME [epoch: 9.24 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0069845518441496186		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.0069845518441496186 | validation: 0.0056391465695982065]
	TIME [epoch: 9.23 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003913317520521772		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.003913317520521772 | validation: 0.005803998755321188]
	TIME [epoch: 9.22 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004283170004214768		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.004283170004214768 | validation: 0.00464287058330597]
	TIME [epoch: 9.23 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004351120811563174		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.004351120811563174 | validation: 0.0065852258570730845]
	TIME [epoch: 9.23 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004055050823145858		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.004055050823145858 | validation: 0.004517561845416086]
	TIME [epoch: 9.24 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003958843834575754		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.003958843834575754 | validation: 0.005224708912382032]
	TIME [epoch: 9.23 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00341444285737126		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.00341444285737126 | validation: 0.004104909499901815]
	TIME [epoch: 9.22 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004710119486468923		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.004710119486468923 | validation: 0.006422081343872014]
	TIME [epoch: 9.23 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004009062140197073		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.004009062140197073 | validation: 0.004857000782918589]
	TIME [epoch: 9.23 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004191095948823295		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.004191095948823295 | validation: 0.004705919017323545]
	TIME [epoch: 9.24 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004173396078951748		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.004173396078951748 | validation: 0.004329429219301896]
	TIME [epoch: 9.23 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004221920143864066		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.004221920143864066 | validation: 0.004764752712278818]
	TIME [epoch: 9.23 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004617967498832046		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.004617967498832046 | validation: 0.005297854726662433]
	TIME [epoch: 9.22 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004266089066246169		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.004266089066246169 | validation: 0.004410626533649412]
	TIME [epoch: 9.23 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004496678672656775		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.004496678672656775 | validation: 0.00658749538534796]
	TIME [epoch: 9.24 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0046021759765192795		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.0046021759765192795 | validation: 0.00470075213667013]
	TIME [epoch: 9.23 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00441196934824443		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.00441196934824443 | validation: 0.005016897840495295]
	TIME [epoch: 9.23 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036782790202348164		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.0036782790202348164 | validation: 0.0041169767670929825]
	TIME [epoch: 9.23 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037795309400247977		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.0037795309400247977 | validation: 0.005752242329306933]
	TIME [epoch: 9.22 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0043642875282094646		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.0043642875282094646 | validation: 0.0035271038466105934]
	TIME [epoch: 9.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_798.pth
	Model improved!!!
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003966897610331179		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.003966897610331179 | validation: 0.005391941457022313]
	TIME [epoch: 9.23 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004068057608822988		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.004068057608822988 | validation: 0.005520673187850787]
	TIME [epoch: 9.23 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004036322947761958		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.004036322947761958 | validation: 0.004720370324909121]
	TIME [epoch: 9.21 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036532701821628735		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.0036532701821628735 | validation: 0.005367102414041629]
	TIME [epoch: 9.22 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00457120737298933		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.00457120737298933 | validation: 0.003978305765211745]
	TIME [epoch: 9.24 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004132141050957064		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.004132141050957064 | validation: 0.004632572309549252]
	TIME [epoch: 9.22 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038156474260199174		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.0038156474260199174 | validation: 0.004172346685636769]
	TIME [epoch: 9.23 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0039859137441641025		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.0039859137441641025 | validation: 0.005958809281344087]
	TIME [epoch: 9.23 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0044326116983655645		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.0044326116983655645 | validation: 0.0051417400232138906]
	TIME [epoch: 9.23 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035287103143003505		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.0035287103143003505 | validation: 0.003993251337076412]
	TIME [epoch: 9.23 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003527996411277907		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.003527996411277907 | validation: 0.004743470313734276]
	TIME [epoch: 9.23 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0045602230042024305		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.0045602230042024305 | validation: 0.004239099318214632]
	TIME [epoch: 9.22 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003804027935126668		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.003804027935126668 | validation: 0.004249807882675568]
	TIME [epoch: 9.22 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004292995599362568		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.004292995599362568 | validation: 0.004589050075729288]
	TIME [epoch: 9.21 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003928169736757692		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.003928169736757692 | validation: 0.00474869181089268]
	TIME [epoch: 9.22 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004618346457152688		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.004618346457152688 | validation: 0.004101916065744046]
	TIME [epoch: 9.23 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004307271442881378		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.004307271442881378 | validation: 0.00502020339892651]
	TIME [epoch: 9.22 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004679389769971792		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.004679389769971792 | validation: 0.004483696034133869]
	TIME [epoch: 9.23 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035541316587900896		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.0035541316587900896 | validation: 0.004301356408131505]
	TIME [epoch: 9.22 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00391300977842332		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.00391300977842332 | validation: 0.004534690664788314]
	TIME [epoch: 9.24 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036220934744393		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.0036220934744393 | validation: 0.003690223709225336]
	TIME [epoch: 9.22 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003709453249684456		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.003709453249684456 | validation: 0.0045138619786048405]
	TIME [epoch: 9.23 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004238633327106108		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.004238633327106108 | validation: 0.0043415743243600735]
	TIME [epoch: 9.23 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004124691967967555		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.004124691967967555 | validation: 0.005140010086557667]
	TIME [epoch: 9.23 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036042232716097067		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.0036042232716097067 | validation: 0.005086062162917099]
	TIME [epoch: 9.24 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004139666269148187		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.004139666269148187 | validation: 0.005072418829823647]
	TIME [epoch: 9.21 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00370206513789806		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.00370206513789806 | validation: 0.0046448830182222005]
	TIME [epoch: 9.22 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004010954740684424		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.004010954740684424 | validation: 0.004905043633695468]
	TIME [epoch: 9.22 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038274074442542745		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.0038274074442542745 | validation: 0.005546902098849506]
	TIME [epoch: 9.22 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038300971872493065		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.0038300971872493065 | validation: 0.0035324999548855427]
	TIME [epoch: 9.23 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004113476940181824		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.004113476940181824 | validation: 0.006485302932281242]
	TIME [epoch: 9.22 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0044692580996945185		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.0044692580996945185 | validation: 0.005238243968245523]
	TIME [epoch: 9.21 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035884523635918188		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.0035884523635918188 | validation: 0.0042739884340682755]
	TIME [epoch: 9.22 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004050539808322069		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.004050539808322069 | validation: 0.004068784734759708]
	TIME [epoch: 9.22 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003893315119761554		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.003893315119761554 | validation: 0.004049381558759337]
	TIME [epoch: 9.23 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004143383400398438		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.004143383400398438 | validation: 0.0034505686647970414]
	TIME [epoch: 9.52 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_834.pth
	Model improved!!!
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003777569160464749		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.003777569160464749 | validation: 0.0031729522121200365]
	TIME [epoch: 9.21 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_835.pth
	Model improved!!!
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037864325302824405		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.0037864325302824405 | validation: 0.005195974641087943]
	TIME [epoch: 9.23 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038213296556355776		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.0038213296556355776 | validation: 0.005646728898460778]
	TIME [epoch: 9.21 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004438164588117089		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.004438164588117089 | validation: 0.004434078580658042]
	TIME [epoch: 9.19 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038488133484512466		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.0038488133484512466 | validation: 0.004298968356851793]
	TIME [epoch: 9.17 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004186019941445597		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.004186019941445597 | validation: 0.0034496952678043976]
	TIME [epoch: 9.17 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037324733370390018		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.0037324733370390018 | validation: 0.00434480209263478]
	TIME [epoch: 9.17 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033244066911609594		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.0033244066911609594 | validation: 0.004113453045895443]
	TIME [epoch: 9.17 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034628208716479406		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.0034628208716479406 | validation: 0.004560455839898699]
	TIME [epoch: 9.18 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003822469935993891		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.003822469935993891 | validation: 0.0043584025566061006]
	TIME [epoch: 9.17 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036998213735545665		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.0036998213735545665 | validation: 0.004886640208321444]
	TIME [epoch: 9.17 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003928073997812221		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.003928073997812221 | validation: 0.005095762590248649]
	TIME [epoch: 9.17 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036848037621231003		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.0036848037621231003 | validation: 0.0038197132660201527]
	TIME [epoch: 9.17 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037781252888219475		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.0037781252888219475 | validation: 0.004791813705933121]
	TIME [epoch: 9.18 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003504596947351252		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.003504596947351252 | validation: 0.0038644885668386265]
	TIME [epoch: 9.17 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004534426982590841		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.004534426982590841 | validation: 0.003889778772212809]
	TIME [epoch: 9.16 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038153225727169636		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.0038153225727169636 | validation: 0.00494583045546305]
	TIME [epoch: 9.17 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004255073226975528		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.004255073226975528 | validation: 0.00443494661944442]
	TIME [epoch: 9.17 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0039729084509058585		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.0039729084509058585 | validation: 0.00357989773626804]
	TIME [epoch: 9.18 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037441808046048985		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.0037441808046048985 | validation: 0.004127486963171991]
	TIME [epoch: 9.17 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035507606071765625		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.0035507606071765625 | validation: 0.0037957525953934567]
	TIME [epoch: 9.16 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004598154280772923		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.004598154280772923 | validation: 0.015639505151284733]
	TIME [epoch: 9.17 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006872258740155533		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.006872258740155533 | validation: 0.005092251424812476]
	TIME [epoch: 9.18 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037424455570077716		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.0037424455570077716 | validation: 0.004023988903585173]
	TIME [epoch: 9.22 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036450619230016046		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.0036450619230016046 | validation: 0.0041146130384486414]
	TIME [epoch: 9.2 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032050744206918915		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.0032050744206918915 | validation: 0.00455062581674145]
	TIME [epoch: 9.18 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032351084880850676		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.0032351084880850676 | validation: 0.005549881772535486]
	TIME [epoch: 9.18 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003778430234038962		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.003778430234038962 | validation: 0.004514700257400711]
	TIME [epoch: 9.18 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003475558387794139		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.003475558387794139 | validation: 0.003241803162705072]
	TIME [epoch: 9.19 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003600077256387085		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.003600077256387085 | validation: 0.00357490879084836]
	TIME [epoch: 9.17 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036568879597531174		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.0036568879597531174 | validation: 0.003617975592087242]
	TIME [epoch: 9.18 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003427337888335469		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.003427337888335469 | validation: 0.0032622663688150733]
	TIME [epoch: 9.18 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036988563114764518		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.0036988563114764518 | validation: 0.00341163381574166]
	TIME [epoch: 9.18 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032045700942972717		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.0032045700942972717 | validation: 0.00498559241925948]
	TIME [epoch: 9.19 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036135102651964654		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.0036135102651964654 | validation: 0.004501552105488235]
	TIME [epoch: 9.13 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036245303047527985		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.0036245303047527985 | validation: 0.003730520057962682]
	TIME [epoch: 9.18 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033340915074155666		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.0033340915074155666 | validation: 0.003890326890780453]
	TIME [epoch: 9.18 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031892999879261446		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.0031892999879261446 | validation: 0.003922508186707285]
	TIME [epoch: 9.17 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003769781454149969		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.003769781454149969 | validation: 0.00391291105958806]
	TIME [epoch: 9.19 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032089670810921777		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.0032089670810921777 | validation: 0.0034982668873719904]
	TIME [epoch: 9.17 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003596073514675613		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.003596073514675613 | validation: 0.0037812447314686227]
	TIME [epoch: 9.18 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033899933256191705		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.0033899933256191705 | validation: 0.0034515850767922905]
	TIME [epoch: 9.17 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003925089386598269		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.003925089386598269 | validation: 0.004049667043605976]
	TIME [epoch: 9.17 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003913477243141049		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.003913477243141049 | validation: 0.004168442855993618]
	TIME [epoch: 9.18 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003908030561958978		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.003908030561958978 | validation: 0.00398982305292692]
	TIME [epoch: 9.17 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003063906103650245		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.003063906103650245 | validation: 0.003460782924165481]
	TIME [epoch: 9.17 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003133450315338205		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.003133450315338205 | validation: 0.003360627891413527]
	TIME [epoch: 9.17 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003020209270964399		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.003020209270964399 | validation: 0.0047093577626057224]
	TIME [epoch: 9.17 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003910626514460282		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.003910626514460282 | validation: 0.0041924812531116545]
	TIME [epoch: 9.19 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038944083785295543		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.0038944083785295543 | validation: 0.00406239106081931]
	TIME [epoch: 9.19 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030625505288786347		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.0030625505288786347 | validation: 0.005179376589382886]
	TIME [epoch: 9.17 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035828921145980306		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.0035828921145980306 | validation: 0.004654581292628258]
	TIME [epoch: 9.17 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00380889764451547		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.00380889764451547 | validation: 0.004065306837449283]
	TIME [epoch: 9.17 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032349598465460806		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.0032349598465460806 | validation: 0.002965719413335948]
	TIME [epoch: 9.19 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_888.pth
	Model improved!!!
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036928602984417033		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.0036928602984417033 | validation: 0.0038888694241536164]
	TIME [epoch: 9.19 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030859412318153595		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.0030859412318153595 | validation: 0.003059648149932628]
	TIME [epoch: 9.19 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028909752379638783		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.0028909752379638783 | validation: 0.003493370350725818]
	TIME [epoch: 9.2 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034581691876066608		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.0034581691876066608 | validation: 0.003996465733701026]
	TIME [epoch: 9.18 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031657324044852097		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.0031657324044852097 | validation: 0.0035041298600679343]
	TIME [epoch: 9.19 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003894645853664518		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.003894645853664518 | validation: 0.0034081848716087794]
	TIME [epoch: 9.2 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003769507808912188		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.003769507808912188 | validation: 0.004291360811772863]
	TIME [epoch: 9.2 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003196815897150544		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.003196815897150544 | validation: 0.003908058987284611]
	TIME [epoch: 9.19 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032276496126006837		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.0032276496126006837 | validation: 0.005928369412497438]
	TIME [epoch: 9.17 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035597355354159755		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.0035597355354159755 | validation: 0.00520929524632167]
	TIME [epoch: 9.16 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029019303119110452		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.0029019303119110452 | validation: 0.004056130250661241]
	TIME [epoch: 9.16 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036432067433571354		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.0036432067433571354 | validation: 0.00481540748985889]
	TIME [epoch: 9.17 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035827821185070367		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.0035827821185070367 | validation: 0.004585585271416148]
	TIME [epoch: 9.15 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003701763133954583		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.003701763133954583 | validation: 0.004119772325557849]
	TIME [epoch: 9.16 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003377286485463229		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.003377286485463229 | validation: 0.004471756518968349]
	TIME [epoch: 9.16 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033994542067870832		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.0033994542067870832 | validation: 0.0036210788637359246]
	TIME [epoch: 9.15 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037611391302811614		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.0037611391302811614 | validation: 0.0043482171250409825]
	TIME [epoch: 9.14 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034622218496815575		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.0034622218496815575 | validation: 0.0036675813981572342]
	TIME [epoch: 9.16 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00342330063573332		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.00342330063573332 | validation: 0.0037670410183247957]
	TIME [epoch: 9.14 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030145666952347996		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.0030145666952347996 | validation: 0.005457547397774787]
	TIME [epoch: 9.16 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035345647620761526		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.0035345647620761526 | validation: 0.004087987404595714]
	TIME [epoch: 9.15 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034316900647649528		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.0034316900647649528 | validation: 0.006166375866691756]
	TIME [epoch: 9.16 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003233006973458589		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.003233006973458589 | validation: 0.004702668379636522]
	TIME [epoch: 9.15 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037485470520348795		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.0037485470520348795 | validation: 0.003480369975528073]
	TIME [epoch: 9.15 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032619175535849756		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.0032619175535849756 | validation: 0.0044009241013894035]
	TIME [epoch: 9.15 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003493226418480419		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.003493226418480419 | validation: 0.0036276732648151495]
	TIME [epoch: 9.15 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003358782981146176		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.003358782981146176 | validation: 0.004047542302280521]
	TIME [epoch: 9.14 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032571885463291016		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.0032571885463291016 | validation: 0.004059028070940291]
	TIME [epoch: 9.15 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030376334269121862		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.0030376334269121862 | validation: 0.0038141729977115347]
	TIME [epoch: 9.16 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033258919267218274		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.0033258919267218274 | validation: 0.0032827861697065845]
	TIME [epoch: 9.16 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032602851610924145		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.0032602851610924145 | validation: 0.0035332639761669372]
	TIME [epoch: 9.16 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003143780653774188		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.003143780653774188 | validation: 0.0028499906777594113]
	TIME [epoch: 9.15 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_920.pth
	Model improved!!!
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033585890796594717		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.0033585890796594717 | validation: 0.0035474189284669918]
	TIME [epoch: 9.25 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031358726193598035		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.0031358726193598035 | validation: 0.00403067917895042]
	TIME [epoch: 9.15 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032876004400963065		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.0032876004400963065 | validation: 0.0048228091141382995]
	TIME [epoch: 9.17 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028518054438823525		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.0028518054438823525 | validation: 0.0030400614587829606]
	TIME [epoch: 9.16 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033361504247083743		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.0033361504247083743 | validation: 0.004486624890333038]
	TIME [epoch: 9.15 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032461133533443955		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.0032461133533443955 | validation: 0.003516018108207817]
	TIME [epoch: 9.16 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003025291424119064		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.003025291424119064 | validation: 0.003388756435573098]
	TIME [epoch: 9.15 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038996071260719353		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.0038996071260719353 | validation: 0.007935167838610221]
	TIME [epoch: 9.17 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005400671769874362		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.005400671769874362 | validation: 0.004379362074776011]
	TIME [epoch: 9.17 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003714060616557453		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.003714060616557453 | validation: 0.00456801059104636]
	TIME [epoch: 9.15 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035534157472046917		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.0035534157472046917 | validation: 0.0033323242116739217]
	TIME [epoch: 9.16 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003112434975649322		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.003112434975649322 | validation: 0.00554790837501707]
	TIME [epoch: 9.14 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004572272176856971		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.004572272176856971 | validation: 0.005109061812174821]
	TIME [epoch: 9.17 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033148043449278226		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.0033148043449278226 | validation: 0.003282161587204478]
	TIME [epoch: 9.16 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027850622790262674		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.0027850622790262674 | validation: 0.0036941679026844775]
	TIME [epoch: 9.15 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031105060185935176		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.0031105060185935176 | validation: 0.003865272278691818]
	TIME [epoch: 9.16 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030489419407995107		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.0030489419407995107 | validation: 0.003460365031791729]
	TIME [epoch: 9.15 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029116509071772326		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.0029116509071772326 | validation: 0.004009214692533082]
	TIME [epoch: 9.15 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003836902781990914		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.003836902781990914 | validation: 0.0029611001855559343]
	TIME [epoch: 9.15 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028363914391587174		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.0028363914391587174 | validation: 0.003885002072239219]
	TIME [epoch: 9.15 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032988011920263367		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.0032988011920263367 | validation: 0.0031850874678346196]
	TIME [epoch: 9.16 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004033323164006567		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.004033323164006567 | validation: 0.003757378582021735]
	TIME [epoch: 9.15 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002993993449756815		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.002993993449756815 | validation: 0.0033952234872423304]
	TIME [epoch: 9.17 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002970806068195339		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.002970806068195339 | validation: 0.005713974763538292]
	TIME [epoch: 9.15 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002783239701298945		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.002783239701298945 | validation: 0.0039048635761190884]
	TIME [epoch: 9.16 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030207884294931563		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.0030207884294931563 | validation: 0.004202158303917703]
	TIME [epoch: 9.15 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032614987178138837		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.0032614987178138837 | validation: 0.0038749169375583733]
	TIME [epoch: 9.16 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031023403093028857		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.0031023403093028857 | validation: 0.0028577457801141877]
	TIME [epoch: 9.16 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029879502217711965		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.0029879502217711965 | validation: 0.0042038384140181346]
	TIME [epoch: 9.16 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003083167324745406		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.003083167324745406 | validation: 0.003284305579952858]
	TIME [epoch: 9.16 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029814312643108246		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.0029814312643108246 | validation: 0.004522685338603341]
	TIME [epoch: 9.16 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003105354250268341		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.003105354250268341 | validation: 0.003685926299226975]
	TIME [epoch: 9.16 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003175503822150369		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.003175503822150369 | validation: 0.0035510312156532596]
	TIME [epoch: 9.17 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002929546388145603		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.002929546388145603 | validation: 0.00347910616573798]
	TIME [epoch: 9.16 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002719361531703958		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.002719361531703958 | validation: 0.0036002494253417217]
	TIME [epoch: 9.16 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003150853178638262		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.003150853178638262 | validation: 0.003984677528875764]
	TIME [epoch: 9.16 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034627192758408458		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.0034627192758408458 | validation: 0.0033729032026480273]
	TIME [epoch: 9.15 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028637104010532034		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.0028637104010532034 | validation: 0.0030210972894812206]
	TIME [epoch: 9.17 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029787247275352385		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.0029787247275352385 | validation: 0.002998051580158397]
	TIME [epoch: 9.17 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031133866554125668		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.0031133866554125668 | validation: 0.003654020653606402]
	TIME [epoch: 9.18 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028598446573669858		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.0028598446573669858 | validation: 0.003982256419973879]
	TIME [epoch: 9.17 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029243287364235353		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.0029243287364235353 | validation: 0.002841205781322042]
	TIME [epoch: 9.16 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_962.pth
	Model improved!!!
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002916435841248354		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.002916435841248354 | validation: 0.0033244850140124777]
	TIME [epoch: 9.3 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003428377234913141		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.003428377234913141 | validation: 0.0037279205405375626]
	TIME [epoch: 9.18 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003115637315437427		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.003115637315437427 | validation: 0.0029465632473464377]
	TIME [epoch: 9.17 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003288002851416732		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.003288002851416732 | validation: 0.0029270872342128103]
	TIME [epoch: 9.17 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002898029912296291		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.002898029912296291 | validation: 0.00391377587657369]
	TIME [epoch: 9.18 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030964222659305056		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.0030964222659305056 | validation: 0.0032986804446308326]
	TIME [epoch: 9.19 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003133217209511194		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.003133217209511194 | validation: 0.0027419164517488008]
	TIME [epoch: 9.17 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_969.pth
	Model improved!!!
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002501875784292386		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.002501875784292386 | validation: 0.003641878000581998]
	TIME [epoch: 9.18 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028678137076873964		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.0028678137076873964 | validation: 0.0032011072874969185]
	TIME [epoch: 9.17 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029586869222476752		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.0029586869222476752 | validation: 0.004058443846168538]
	TIME [epoch: 9.17 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029981957135212264		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.0029981957135212264 | validation: 0.00511120311459637]
	TIME [epoch: 9.19 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029826251001713517		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.0029826251001713517 | validation: 0.004012335551109868]
	TIME [epoch: 9.17 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00317434697011825		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.00317434697011825 | validation: 0.003442642065957675]
	TIME [epoch: 9.16 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002873708827162126		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.002873708827162126 | validation: 0.003769758359952809]
	TIME [epoch: 9.16 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029459623636608145		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.0029459623636608145 | validation: 0.002952058293703172]
	TIME [epoch: 9.17 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003336532401428942		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.003336532401428942 | validation: 0.003363137268661171]
	TIME [epoch: 9.18 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033739812442485284		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.0033739812442485284 | validation: 0.004096161462324229]
	TIME [epoch: 9.17 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031086301838754733		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.0031086301838754733 | validation: 0.00416971771701462]
	TIME [epoch: 9.17 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004252882231974779		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.004252882231974779 | validation: 0.006771383041500013]
	TIME [epoch: 9.17 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003866865518869665		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.003866865518869665 | validation: 0.0033811981121270387]
	TIME [epoch: 9.17 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029720636545806423		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.0029720636545806423 | validation: 0.004840479166357403]
	TIME [epoch: 9.18 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030606639896589563		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.0030606639896589563 | validation: 0.0039307522413750675]
	TIME [epoch: 9.18 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029058002618968736		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.0029058002618968736 | validation: 0.0033390771631631256]
	TIME [epoch: 9.16 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027101865637841234		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.0027101865637841234 | validation: 0.003988833990142761]
	TIME [epoch: 9.17 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003141359523490172		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.003141359523490172 | validation: 0.0031853585937909818]
	TIME [epoch: 9.17 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029101191873978855		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.0029101191873978855 | validation: 0.003169474567375809]
	TIME [epoch: 9.18 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028484421615640187		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.0028484421615640187 | validation: 0.0038518946262331086]
	TIME [epoch: 9.17 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002662710293088467		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.002662710293088467 | validation: 0.0047613850726676895]
	TIME [epoch: 9.17 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002994574462140062		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.002994574462140062 | validation: 0.0035024808241690426]
	TIME [epoch: 9.16 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031978222596102624		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.0031978222596102624 | validation: 0.00383928873244107]
	TIME [epoch: 9.17 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002675475702528577		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.002675475702528577 | validation: 0.004612610330038899]
	TIME [epoch: 9.18 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027480838708379084		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.0027480838708379084 | validation: 0.0029808331898636808]
	TIME [epoch: 9.18 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029345805732875533		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.0029345805732875533 | validation: 0.0033814122673605203]
	TIME [epoch: 9.17 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002931648447021396		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.002931648447021396 | validation: 0.003523603465090063]
	TIME [epoch: 9.17 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00265827804094254		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.00265827804094254 | validation: 0.003101989663074857]
	TIME [epoch: 9.18 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029189293793768158		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.0029189293793768158 | validation: 0.0032363658086719945]
	TIME [epoch: 9.18 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032435088909598207		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.0032435088909598207 | validation: 0.004172747136721279]
	TIME [epoch: 9.28 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027757915922499814		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.0027757915922499814 | validation: 0.002807667262607467]
	TIME [epoch: 9.18 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030082339652730203		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.0030082339652730203 | validation: 0.0033588649638414676]
	TIME [epoch: 9.18 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028618939847112604		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.0028618939847112604 | validation: 0.003742314247946045]
	TIME [epoch: 9.17 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028810468921052768		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.0028810468921052768 | validation: 0.003112542677474816]
	TIME [epoch: 9.17 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029700343745634188		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.0029700343745634188 | validation: 0.002894853200398698]
	TIME [epoch: 9.17 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002831738574497921		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.002831738574497921 | validation: 0.003937242140331804]
	TIME [epoch: 9.15 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028999189260275325		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.0028999189260275325 | validation: 0.00414755025593415]
	TIME [epoch: 9.16 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031346397583620197		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.0031346397583620197 | validation: 0.0027916294353837845]
	TIME [epoch: 9.16 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034619051357029757		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.0034619051357029757 | validation: 0.0035666629189324483]
	TIME [epoch: 9.18 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027414806305479486		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.0027414806305479486 | validation: 0.003994637032242826]
	TIME [epoch: 9.16 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002557739850265755		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.002557739850265755 | validation: 0.003571096713122101]
	TIME [epoch: 9.16 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029305210323758405		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.0029305210323758405 | validation: 0.003148637955548715]
	TIME [epoch: 9.16 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027793692805540265		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.0027793692805540265 | validation: 0.002647837906622671]
	TIME [epoch: 9.16 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_1012.pth
	Model improved!!!
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00263382020849083		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.00263382020849083 | validation: 0.0030407645412775346]
	TIME [epoch: 9.17 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031618760936978673		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.0031618760936978673 | validation: 0.003469932409970759]
	TIME [epoch: 9.17 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027555313351902188		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.0027555313351902188 | validation: 0.004745286648866152]
	TIME [epoch: 9.16 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030005605862638545		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.0030005605862638545 | validation: 0.002743016051119537]
	TIME [epoch: 9.18 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026337516791322766		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.0026337516791322766 | validation: 0.0034204981147197867]
	TIME [epoch: 9.16 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002657916587047753		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.002657916587047753 | validation: 0.004228603745948408]
	TIME [epoch: 9.17 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029024135003501038		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.0029024135003501038 | validation: 0.0033894636172015907]
	TIME [epoch: 9.16 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002620377584054999		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.002620377584054999 | validation: 0.003229822503355732]
	TIME [epoch: 9.16 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029407052188143283		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.0029407052188143283 | validation: 0.0037658625912203366]
	TIME [epoch: 9.16 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029914050447699615		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.0029914050447699615 | validation: 0.0034015600267682097]
	TIME [epoch: 9.16 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026387711741591513		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.0026387711741591513 | validation: 0.0034126244757011178]
	TIME [epoch: 9.18 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030613856661110676		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.0030613856661110676 | validation: 0.003479349283140782]
	TIME [epoch: 9.16 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002865493794457161		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.002865493794457161 | validation: 0.0033912458955863505]
	TIME [epoch: 9.18 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002583744862329357		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.002583744862329357 | validation: 0.003043552585971149]
	TIME [epoch: 9.16 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002559737349040832		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.002559737349040832 | validation: 0.0029002327009140134]
	TIME [epoch: 9.16 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002454506710863633		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.002454506710863633 | validation: 0.002941828850434219]
	TIME [epoch: 9.17 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029026886436018893		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.0029026886436018893 | validation: 0.002945117436920186]
	TIME [epoch: 9.16 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025552706153422963		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.0025552706153422963 | validation: 0.002508483927408226]
	TIME [epoch: 9.16 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_1030.pth
	Model improved!!!
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027293432661706614		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.0027293432661706614 | validation: 0.0038883756940731526]
	TIME [epoch: 9.16 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028148776073379407		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.0028148776073379407 | validation: 0.0038681468974707364]
	TIME [epoch: 9.16 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002576407871926428		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.002576407871926428 | validation: 0.0036347857616117144]
	TIME [epoch: 9.16 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027285191400867725		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.0027285191400867725 | validation: 0.0037915798225373297]
	TIME [epoch: 9.16 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00290845830968785		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.00290845830968785 | validation: 0.002633507396942994]
	TIME [epoch: 9.14 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00267969733162841		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.00267969733162841 | validation: 0.0028067362507223264]
	TIME [epoch: 9.15 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027392546560648817		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.0027392546560648817 | validation: 0.003317553930353142]
	TIME [epoch: 9.14 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002623149438472292		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.002623149438472292 | validation: 0.0028510048991841333]
	TIME [epoch: 9.17 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022575361614372595		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.0022575361614372595 | validation: 0.0027268739475034163]
	TIME [epoch: 9.16 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027480654596957173		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.0027480654596957173 | validation: 0.004021654394107509]
	TIME [epoch: 9.15 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002639406929979485		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.002639406929979485 | validation: 0.0031994331832548226]
	TIME [epoch: 9.15 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030228374938241305		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.0030228374938241305 | validation: 0.0031764503181416492]
	TIME [epoch: 9.11 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002746027013603165		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.002746027013603165 | validation: 0.003246282219811883]
	TIME [epoch: 9.08 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030275621258475105		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.0030275621258475105 | validation: 0.0031779459490419073]
	TIME [epoch: 9.08 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024782309130444917		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.0024782309130444917 | validation: 0.0032886026847135314]
	TIME [epoch: 9.06 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002911684706408735		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.002911684706408735 | validation: 0.0028040405645139675]
	TIME [epoch: 9.09 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003023473358302204		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.003023473358302204 | validation: 0.0030223295739745977]
	TIME [epoch: 9.07 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027042233825936056		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.0027042233825936056 | validation: 0.0025538258799999384]
	TIME [epoch: 9.08 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025981554350176456		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.0025981554350176456 | validation: 0.003296101867834068]
	TIME [epoch: 9.08 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025467150692943343		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.0025467150692943343 | validation: 0.0026107816581237737]
	TIME [epoch: 9.07 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024452267060936757		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.0024452267060936757 | validation: 0.0026251974364370845]
	TIME [epoch: 9.06 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002901465841784993		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.002901465841784993 | validation: 0.003372814167474773]
	TIME [epoch: 9.08 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002710582599477028		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.002710582599477028 | validation: 0.002712307526822213]
	TIME [epoch: 9.07 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023448445385631216		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.0023448445385631216 | validation: 0.0036855070499594404]
	TIME [epoch: 9.08 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002559775585732781		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.002559775585732781 | validation: 0.002673430838615653]
	TIME [epoch: 9.08 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002904316185072009		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.002904316185072009 | validation: 0.0034642861941275053]
	TIME [epoch: 9.07 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029606955270669545		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.0029606955270669545 | validation: 0.00356047803961217]
	TIME [epoch: 9.06 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027072083551999953		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.0027072083551999953 | validation: 0.003841712380013142]
	TIME [epoch: 9.08 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025730631493367418		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.0025730631493367418 | validation: 0.0030088264579354613]
	TIME [epoch: 9.08 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002740631901469742		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.002740631901469742 | validation: 0.0025094633423858293]
	TIME [epoch: 9.07 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029268728238631275		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.0029268728238631275 | validation: 0.0033518146826635913]
	TIME [epoch: 9.06 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027121449994918587		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.0027121449994918587 | validation: 0.003438296881424532]
	TIME [epoch: 9.06 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00281476100337078		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.00281476100337078 | validation: 0.0026526200127436547]
	TIME [epoch: 9.07 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023636228441337487		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.0023636228441337487 | validation: 0.003301975002946091]
	TIME [epoch: 9.08 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002631321348867647		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.002631321348867647 | validation: 0.0032364350298758862]
	TIME [epoch: 9.06 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002457018090079568		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.002457018090079568 | validation: 0.002620453010466629]
	TIME [epoch: 9.07 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024224962064422996		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.0024224962064422996 | validation: 0.0036431889493721953]
	TIME [epoch: 9.07 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002752881553597851		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.002752881553597851 | validation: 0.0032763186361499715]
	TIME [epoch: 9.06 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002191063123311114		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.002191063123311114 | validation: 0.0031262462474668223]
	TIME [epoch: 9.07 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028522179005134405		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.0028522179005134405 | validation: 0.0026865829885725293]
	TIME [epoch: 9.08 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00240088901079902		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.00240088901079902 | validation: 0.003080881067194472]
	TIME [epoch: 9.06 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002489879365867396		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.002489879365867396 | validation: 0.003736941577779685]
	TIME [epoch: 9.08 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00269858789460364		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.00269858789460364 | validation: 0.0033765424941701767]
	TIME [epoch: 9.07 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025564273146149565		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.0025564273146149565 | validation: 0.002219888663372092]
	TIME [epoch: 9.07 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_1074.pth
	Model improved!!!
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027853819206379504		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.0027853819206379504 | validation: 0.0029362075186297066]
	TIME [epoch: 9.07 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025813520948834074		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.0025813520948834074 | validation: 0.00242509679345024]
	TIME [epoch: 9.07 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027282175131126286		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.0027282175131126286 | validation: 0.002448479068919258]
	TIME [epoch: 9.07 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002808516285187472		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.002808516285187472 | validation: 0.0034443279085596586]
	TIME [epoch: 9.09 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025451961888456488		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.0025451961888456488 | validation: 0.003933226516201862]
	TIME [epoch: 9.11 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024070248058343097		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.0024070248058343097 | validation: 0.0032661440658751]
	TIME [epoch: 9.06 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002433828699258585		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.002433828699258585 | validation: 0.003078338251771582]
	TIME [epoch: 9.06 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002919366427000611		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.002919366427000611 | validation: 0.0024803359442489093]
	TIME [epoch: 9.07 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028231271561258483		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.0028231271561258483 | validation: 0.0032849567978418892]
	TIME [epoch: 9.06 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028689865112687886		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.0028689865112687886 | validation: 0.0028198797548324855]
	TIME [epoch: 9.08 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024801816090455116		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.0024801816090455116 | validation: 0.002396486982517404]
	TIME [epoch: 9.07 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002860410565454908		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.002860410565454908 | validation: 0.002813189270186577]
	TIME [epoch: 9.09 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002493134473703296		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.002493134473703296 | validation: 0.003698694299824038]
	TIME [epoch: 9.09 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025522772924249457		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.0025522772924249457 | validation: 0.002957953580432286]
	TIME [epoch: 9.06 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002465846965992054		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.002465846965992054 | validation: 0.003001662152863428]
	TIME [epoch: 9.08 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026957033487173742		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.0026957033487173742 | validation: 0.002626018600084244]
	TIME [epoch: 9.08 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023254669132563334		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.0023254669132563334 | validation: 0.002746353345208475]
	TIME [epoch: 9.07 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023361708186409877		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.0023361708186409877 | validation: 0.00275992767229177]
	TIME [epoch: 9.08 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029794078298289645		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.0029794078298289645 | validation: 0.002831981296415046]
	TIME [epoch: 9.06 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002621680207430432		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.002621680207430432 | validation: 0.0034162050644383525]
	TIME [epoch: 9.08 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025535046084829978		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.0025535046084829978 | validation: 0.00588385512900718]
	TIME [epoch: 9.09 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003252819266704602		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.003252819266704602 | validation: 0.0034307056672216443]
	TIME [epoch: 9.07 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002452624860717895		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.002452624860717895 | validation: 0.0026189480220547585]
	TIME [epoch: 9.06 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002528216486779033		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.002528216486779033 | validation: 0.002781277120387375]
	TIME [epoch: 9.07 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021153655911040335		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.0021153655911040335 | validation: 0.002369592221506683]
	TIME [epoch: 9.09 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002789304442426833		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.002789304442426833 | validation: 0.003935349801498525]
	TIME [epoch: 9.07 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027953534356353585		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.0027953534356353585 | validation: 0.0029139830067542675]
	TIME [epoch: 9.09 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003804225473746205		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.003804225473746205 | validation: 0.007050999016225636]
	TIME [epoch: 9.1 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030802782463376453		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.0030802782463376453 | validation: 0.0031745375883384837]
	TIME [epoch: 9.11 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026997459231563386		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.0026997459231563386 | validation: 0.0029022023873704573]
	TIME [epoch: 9.11 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024756090618828115		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.0024756090618828115 | validation: 0.002873116389038486]
	TIME [epoch: 9.1 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022493526192594528		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.0022493526192594528 | validation: 0.0033330299016063477]
	TIME [epoch: 9.09 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029017919416231665		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.0029017919416231665 | validation: 0.0031603185591149484]
	TIME [epoch: 9.08 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002569222736743574		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.002569222736743574 | validation: 0.0031108946060389078]
	TIME [epoch: 9.09 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00223198982754191		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.00223198982754191 | validation: 0.0027438717175723593]
	TIME [epoch: 9.11 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027438128971823505		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.0027438128971823505 | validation: 0.004148654381132332]
	TIME [epoch: 9.12 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027281417798002026		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.0027281417798002026 | validation: 0.0035305520197487414]
	TIME [epoch: 9.12 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026739662000468067		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.0026739662000468067 | validation: 0.0029731532599831046]
	TIME [epoch: 9.11 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025663357251855196		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.0025663357251855196 | validation: 0.002724138978483214]
	TIME [epoch: 9.09 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002733744640980921		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.002733744640980921 | validation: 0.0026267671841442635]
	TIME [epoch: 9.11 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023606335954925377		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.0023606335954925377 | validation: 0.0037317393343322997]
	TIME [epoch: 9.1 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024890814949102124		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.0024890814949102124 | validation: 0.0024680674660729667]
	TIME [epoch: 9.09 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026752350123129057		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.0026752350123129057 | validation: 0.0030941611701802226]
	TIME [epoch: 9.1 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026669668878664386		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.0026669668878664386 | validation: 0.002732766670950207]
	TIME [epoch: 9.09 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024699644399608107		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.0024699644399608107 | validation: 0.002962109158228989]
	TIME [epoch: 9.11 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002546336205880108		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.002546336205880108 | validation: 0.0034686708329469927]
	TIME [epoch: 9.1 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002693034743817528		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.002693034743817528 | validation: 0.0032524239585161397]
	TIME [epoch: 9.09 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025703018451947593		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.0025703018451947593 | validation: 0.00270077182205112]
	TIME [epoch: 9.09 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002343961212730098		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.002343961212730098 | validation: 0.0026485908752335962]
	TIME [epoch: 9.09 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026044925194583478		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.0026044925194583478 | validation: 0.0025940631792766974]
	TIME [epoch: 9.1 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023528541173720137		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.0023528541173720137 | validation: 0.002542330049258947]
	TIME [epoch: 9.1 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027055358001014523		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.0027055358001014523 | validation: 0.0031219155821981997]
	TIME [epoch: 9.09 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002498824099431791		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.002498824099431791 | validation: 0.0026597534523366837]
	TIME [epoch: 9.09 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025291879949832113		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.0025291879949832113 | validation: 0.002540846359258463]
	TIME [epoch: 9.09 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022041035386176893		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.0022041035386176893 | validation: 0.002608794095581933]
	TIME [epoch: 9.11 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024622207652003083		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.0024622207652003083 | validation: 0.0029918186507254937]
	TIME [epoch: 9.1 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002231557334385704		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.002231557334385704 | validation: 0.00305928683625135]
	TIME [epoch: 9.11 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023171494351129857		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.0023171494351129857 | validation: 0.0029095592712935197]
	TIME [epoch: 9.13 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021659296928627767		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.0021659296928627767 | validation: 0.002859809336990794]
	TIME [epoch: 9.09 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023525615891667705		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.0023525615891667705 | validation: 0.002889832918112204]
	TIME [epoch: 9.1 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024495839659125418		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.0024495839659125418 | validation: 0.0025887843914657455]
	TIME [epoch: 9.12 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023334313091116603		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.0023334313091116603 | validation: 0.002285645178416516]
	TIME [epoch: 9.09 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002735570596175592		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.002735570596175592 | validation: 0.0026622343234377257]
	TIME [epoch: 9.09 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021896157604940456		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.0021896157604940456 | validation: 0.003063717396221954]
	TIME [epoch: 9.1 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028357656521605405		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.0028357656521605405 | validation: 0.0035437868872450714]
	TIME [epoch: 9.11 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002527485975208658		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.002527485975208658 | validation: 0.0023686138578969595]
	TIME [epoch: 9.09 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002442323855218502		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.002442323855218502 | validation: 0.002971876399083049]
	TIME [epoch: 9.13 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002491456114692926		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.002491456114692926 | validation: 0.0031770353114156835]
	TIME [epoch: 9.1 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002459875546288272		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.002459875546288272 | validation: 0.0029096253583587826]
	TIME [epoch: 9.09 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00236236539708639		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.00236236539708639 | validation: 0.0035073465687312927]
	TIME [epoch: 9.09 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002451503111299427		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.002451503111299427 | validation: 0.0025728784990462464]
	TIME [epoch: 9.13 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002620333315057256		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.002620333315057256 | validation: 0.004917813256602219]
	TIME [epoch: 9.09 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027974054594147118		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.0027974054594147118 | validation: 0.0030302468034922214]
	TIME [epoch: 9.11 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022058967441472297		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.0022058967441472297 | validation: 0.002322751253950173]
	TIME [epoch: 9.07 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025075412800966202		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.0025075412800966202 | validation: 0.0036357362418830332]
	TIME [epoch: 9.11 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002372541781582527		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.002372541781582527 | validation: 0.0026661375166497766]
	TIME [epoch: 9.08 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023733712936974912		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.0023733712936974912 | validation: 0.002456567702368409]
	TIME [epoch: 9.11 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023672802225281784		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.0023672802225281784 | validation: 0.00350316362189487]
	TIME [epoch: 9.07 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002306756720663489		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.002306756720663489 | validation: 0.0029161837326155318]
	TIME [epoch: 9.08 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002236603350782516		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.002236603350782516 | validation: 0.0023385433046200464]
	TIME [epoch: 9.1 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023955951355348515		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.0023955951355348515 | validation: 0.0023719959968948982]
	TIME [epoch: 9.09 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002417522123090442		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.002417522123090442 | validation: 0.003200462402178759]
	TIME [epoch: 9.08 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002268458767722013		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.002268458767722013 | validation: 0.0026605437690233446]
	TIME [epoch: 9.09 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002490152291516766		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.002490152291516766 | validation: 0.003616921174218682]
	TIME [epoch: 9.07 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002282621075422771		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.002282621075422771 | validation: 0.0029008252397806533]
	TIME [epoch: 9.08 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002198635100303968		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.002198635100303968 | validation: 0.0026249614938185476]
	TIME [epoch: 9.09 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023536589228214605		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.0023536589228214605 | validation: 0.0026794653535663045]
	TIME [epoch: 9.08 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021844798278237397		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.0021844798278237397 | validation: 0.0031526159770775795]
	TIME [epoch: 9.08 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002640813555613518		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.002640813555613518 | validation: 0.002836106446240055]
	TIME [epoch: 9.08 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025122921103893853		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.0025122921103893853 | validation: 0.0023638771681090613]
	TIME [epoch: 9.09 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002444948204088164		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.002444948204088164 | validation: 0.002563792459395129]
	TIME [epoch: 9.09 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021208289713843084		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.0021208289713843084 | validation: 0.0027772050534975944]
	TIME [epoch: 9.08 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022443112059131478		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.0022443112059131478 | validation: 0.0030962543151546455]
	TIME [epoch: 9.08 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002217257678239702		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.002217257678239702 | validation: 0.0025498813140985748]
	TIME [epoch: 9.09 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00235260668965675		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.00235260668965675 | validation: 0.002552259201779361]
	TIME [epoch: 9.08 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002388103479566939		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.002388103479566939 | validation: 0.0026859292354369266]
	TIME [epoch: 9.1 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024881479885941428		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.0024881479885941428 | validation: 0.003410415405932432]
	TIME [epoch: 9.07 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002415936604044706		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.002415936604044706 | validation: 0.0023678218105635473]
	TIME [epoch: 9.08 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002214101925273779		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.002214101925273779 | validation: 0.003241115003633086]
	TIME [epoch: 9.08 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002615119149647269		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.002615119149647269 | validation: 0.0023168379868551527]
	TIME [epoch: 9.08 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026280881273499906		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.0026280881273499906 | validation: 0.002400410262864017]
	TIME [epoch: 9.1 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd1_presample_20240627_143609/states/model_phi1_1a_v_mmd1_presample_1175.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 10956.260 seconds.
