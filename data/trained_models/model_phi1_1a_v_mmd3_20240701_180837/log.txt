Args:
Namespace(name='model_phi1_1a_v_mmd3', outdir='out/model_training/model_phi1_1a_v_mmd3', training_data='data/training_data/data_phi1_1a/training', validation_data='data/training_data/data_phi1_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='warmup_cosine_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2203541524

Training model...

Saving initial model state to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.196029504853026		[learning rate: 0.01015]
	Learning Rate: 0.01015
	LOSS [training: 5.196029504853026 | validation: 5.512100161782392]
	TIME [epoch: 101 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459676421573041		[learning rate: 0.01035]
	Learning Rate: 0.01035
	LOSS [training: 4.459676421573041 | validation: 5.298233737118789]
	TIME [epoch: 8.53 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.325980414038045		[learning rate: 0.01055]
	Learning Rate: 0.01055
	LOSS [training: 4.325980414038045 | validation: 4.771851433563235]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.088479957787026		[learning rate: 0.01075]
	Learning Rate: 0.01075
	LOSS [training: 4.088479957787026 | validation: 3.868657895941383]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2615694775439916		[learning rate: 0.01095]
	Learning Rate: 0.01095
	LOSS [training: 3.2615694775439916 | validation: 3.5779796547087193]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0868402708596117		[learning rate: 0.01115]
	Learning Rate: 0.01115
	LOSS [training: 3.0868402708596117 | validation: 3.3631047492163395]
	TIME [epoch: 8.36 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8701474237939566		[learning rate: 0.01135]
	Learning Rate: 0.01135
	LOSS [training: 2.8701474237939566 | validation: 3.0761656285852146]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.594440108834015		[learning rate: 0.01155]
	Learning Rate: 0.01155
	LOSS [training: 2.594440108834015 | validation: 2.919937716690342]
	TIME [epoch: 8.37 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4584559580021894		[learning rate: 0.01175]
	Learning Rate: 0.01175
	LOSS [training: 2.4584559580021894 | validation: 2.881446602176048]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4785844733888736		[learning rate: 0.01195]
	Learning Rate: 0.01195
	LOSS [training: 2.4785844733888736 | validation: 2.67738975339155]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1319973958116423		[learning rate: 0.01215]
	Learning Rate: 0.01215
	LOSS [training: 2.1319973958116423 | validation: 2.728676317897166]
	TIME [epoch: 8.34 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0155590865637074		[learning rate: 0.01235]
	Learning Rate: 0.01235
	LOSS [training: 2.0155590865637074 | validation: 2.4960443011273403]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9799674784008066		[learning rate: 0.01255]
	Learning Rate: 0.01255
	LOSS [training: 1.9799674784008066 | validation: 2.3679957432103125]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8964107828431631		[learning rate: 0.01275]
	Learning Rate: 0.01275
	LOSS [training: 1.8964107828431631 | validation: 2.2927049815686757]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6084796477036725		[learning rate: 0.01295]
	Learning Rate: 0.01295
	LOSS [training: 1.6084796477036725 | validation: 1.8678847987359235]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6983027628821112		[learning rate: 0.01315]
	Learning Rate: 0.01315
	LOSS [training: 1.6983027628821112 | validation: 1.76084835305563]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4513898840926844		[learning rate: 0.01335]
	Learning Rate: 0.01335
	LOSS [training: 1.4513898840926844 | validation: 1.9392728007206985]
	TIME [epoch: 8.35 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1509502627006964		[learning rate: 0.01355]
	Learning Rate: 0.01355
	LOSS [training: 1.1509502627006964 | validation: 1.4100337329779333]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.392078637549384		[learning rate: 0.01375]
	Learning Rate: 0.01375
	LOSS [training: 1.392078637549384 | validation: 1.7238246557135808]
	TIME [epoch: 8.29 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3013847106985157		[learning rate: 0.01395]
	Learning Rate: 0.01395
	LOSS [training: 1.3013847106985157 | validation: 1.600441634573807]
	TIME [epoch: 8.3 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2113137629680613		[learning rate: 0.01415]
	Learning Rate: 0.01415
	LOSS [training: 1.2113137629680613 | validation: 1.7434349889226717]
	TIME [epoch: 8.3 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2272606522639165		[learning rate: 0.01435]
	Learning Rate: 0.01435
	LOSS [training: 1.2272606522639165 | validation: 1.5093955183164978]
	TIME [epoch: 8.32 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2028025990931746		[learning rate: 0.01455]
	Learning Rate: 0.01455
	LOSS [training: 1.2028025990931746 | validation: 1.9193031215229053]
	TIME [epoch: 8.33 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3255875739867777		[learning rate: 0.01475]
	Learning Rate: 0.01475
	LOSS [training: 1.3255875739867777 | validation: 0.9824056608047462]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9579774372741187		[learning rate: 0.01495]
	Learning Rate: 0.01495
	LOSS [training: 0.9579774372741187 | validation: 1.345060503798803]
	TIME [epoch: 8.29 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9072244006941608		[learning rate: 0.01515]
	Learning Rate: 0.01515
	LOSS [training: 0.9072244006941608 | validation: 1.0386746639250792]
	TIME [epoch: 8.3 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0869154123982154		[learning rate: 0.01535]
	Learning Rate: 0.01535
	LOSS [training: 1.0869154123982154 | validation: 1.7646450957184912]
	TIME [epoch: 8.31 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1169459709691956		[learning rate: 0.01555]
	Learning Rate: 0.01555
	LOSS [training: 1.1169459709691956 | validation: 1.155803865425786]
	TIME [epoch: 8.35 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8384461793132785		[learning rate: 0.01575]
	Learning Rate: 0.01575
	LOSS [training: 0.8384461793132785 | validation: 0.9436177036627456]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7496331511323735		[learning rate: 0.01595]
	Learning Rate: 0.01595
	LOSS [training: 0.7496331511323735 | validation: 1.2768754808814275]
	TIME [epoch: 8.29 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.127991089287878		[learning rate: 0.01615]
	Learning Rate: 0.01615
	LOSS [training: 1.127991089287878 | validation: 0.860770345553971]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7707660664036011		[learning rate: 0.01635]
	Learning Rate: 0.01635
	LOSS [training: 0.7707660664036011 | validation: 0.7024322117146791]
	TIME [epoch: 8.35 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7212889749540307		[learning rate: 0.01655]
	Learning Rate: 0.01655
	LOSS [training: 0.7212889749540307 | validation: 0.8416519698811505]
	TIME [epoch: 8.35 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7458196397803996		[learning rate: 0.01675]
	Learning Rate: 0.01675
	LOSS [training: 0.7458196397803996 | validation: 0.7112129003045267]
	TIME [epoch: 8.31 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6888228710760583		[learning rate: 0.01695]
	Learning Rate: 0.01695
	LOSS [training: 0.6888228710760583 | validation: 0.5928592491923547]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7249118292788417		[learning rate: 0.01715]
	Learning Rate: 0.01715
	LOSS [training: 0.7249118292788417 | validation: 1.7724716379342538]
	TIME [epoch: 8.31 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0809452146024237		[learning rate: 0.01735]
	Learning Rate: 0.01735
	LOSS [training: 1.0809452146024237 | validation: 0.7832548883597894]
	TIME [epoch: 8.3 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9415201843319759		[learning rate: 0.01755]
	Learning Rate: 0.01755
	LOSS [training: 0.9415201843319759 | validation: 1.4780856670202622]
	TIME [epoch: 8.31 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1499751195704369		[learning rate: 0.01775]
	Learning Rate: 0.01775
	LOSS [training: 1.1499751195704369 | validation: 0.8551760987649013]
	TIME [epoch: 8.34 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6401587670096		[learning rate: 0.01795]
	Learning Rate: 0.01795
	LOSS [training: 0.6401587670096 | validation: 0.9551395958780065]
	TIME [epoch: 8.3 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7411701423343033		[learning rate: 0.01815]
	Learning Rate: 0.01815
	LOSS [training: 0.7411701423343033 | validation: 0.5568935919470615]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5330295092589772		[learning rate: 0.01835]
	Learning Rate: 0.01835
	LOSS [training: 0.5330295092589772 | validation: 1.1403174571269123]
	TIME [epoch: 8.3 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6519537966097957		[learning rate: 0.01855]
	Learning Rate: 0.01855
	LOSS [training: 0.6519537966097957 | validation: 0.7936680912729626]
	TIME [epoch: 8.31 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6684706738891475		[learning rate: 0.01875]
	Learning Rate: 0.01875
	LOSS [training: 0.6684706738891475 | validation: 0.6108933868475541]
	TIME [epoch: 8.34 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6781418945233257		[learning rate: 0.01895]
	Learning Rate: 0.01895
	LOSS [training: 0.6781418945233257 | validation: 0.6855644478928737]
	TIME [epoch: 8.31 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9104913043440909		[learning rate: 0.01915]
	Learning Rate: 0.01915
	LOSS [training: 0.9104913043440909 | validation: 0.5745902305515586]
	TIME [epoch: 8.29 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.810477832125643		[learning rate: 0.01935]
	Learning Rate: 0.01935
	LOSS [training: 0.810477832125643 | validation: 1.027603824651769]
	TIME [epoch: 8.31 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2642462193814072		[learning rate: 0.01955]
	Learning Rate: 0.01955
	LOSS [training: 1.2642462193814072 | validation: 0.8576955466500671]
	TIME [epoch: 8.3 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5677122343744035		[learning rate: 0.01975]
	Learning Rate: 0.01975
	LOSS [training: 0.5677122343744035 | validation: 0.6597430255524982]
	TIME [epoch: 8.31 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.168244971580047		[learning rate: 0.01995]
	Learning Rate: 0.01995
	LOSS [training: 1.168244971580047 | validation: 1.172677103848835]
	TIME [epoch: 8.34 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.670924911652801		[learning rate: 0.02]
	Learning Rate: 0.02
	LOSS [training: 0.670924911652801 | validation: 0.5592109793732787]
	TIME [epoch: 8.29 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6018025922324106		[learning rate: 0.02]
	Learning Rate: 0.02
	LOSS [training: 0.6018025922324106 | validation: 0.542077506297402]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5021123043495866		[learning rate: 0.02]
	Learning Rate: 0.0199999
	LOSS [training: 0.5021123043495866 | validation: 0.6084404012921396]
	TIME [epoch: 8.29 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5758932412640863		[learning rate: 0.02]
	Learning Rate: 0.0199998
	LOSS [training: 0.5758932412640863 | validation: 0.5962588530377366]
	TIME [epoch: 8.29 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5925084443879842		[learning rate: 0.02]
	Learning Rate: 0.0199997
	LOSS [training: 0.5925084443879842 | validation: 0.7810684219877896]
	TIME [epoch: 8.33 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5496014883177585		[learning rate: 0.02]
	Learning Rate: 0.0199995
	LOSS [training: 0.5496014883177585 | validation: 0.8992637659533833]
	TIME [epoch: 8.3 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6419277748818959		[learning rate: 0.019999]
	Learning Rate: 0.0199994
	LOSS [training: 0.6419277748818959 | validation: 0.8823218545762368]
	TIME [epoch: 8.29 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5916858154327751		[learning rate: 0.019999]
	Learning Rate: 0.0199992
	LOSS [training: 0.5916858154327751 | validation: 0.9222392431747665]
	TIME [epoch: 8.3 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5663296258639521		[learning rate: 0.019999]
	Learning Rate: 0.019999
	LOSS [training: 0.5663296258639521 | validation: 0.582671465816319]
	TIME [epoch: 8.3 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5220055093165757		[learning rate: 0.019999]
	Learning Rate: 0.0199987
	LOSS [training: 0.5220055093165757 | validation: 0.5224213123389795]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4483797467397491		[learning rate: 0.019998]
	Learning Rate: 0.0199984
	LOSS [training: 0.4483797467397491 | validation: 0.7845573807964801]
	TIME [epoch: 8.35 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.642355203032771		[learning rate: 0.019998]
	Learning Rate: 0.0199981
	LOSS [training: 0.642355203032771 | validation: 0.39013505963843675]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.604046196341759		[learning rate: 0.019998]
	Learning Rate: 0.0199978
	LOSS [training: 0.604046196341759 | validation: 0.3937143610388667]
	TIME [epoch: 8.3 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40937490990210806		[learning rate: 0.019997]
	Learning Rate: 0.0199974
	LOSS [training: 0.40937490990210806 | validation: 0.7406537079048601]
	TIME [epoch: 8.3 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5215091559795133		[learning rate: 0.019997]
	Learning Rate: 0.019997
	LOSS [training: 0.5215091559795133 | validation: 0.4352447116274617]
	TIME [epoch: 8.3 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6018563874459357		[learning rate: 0.019997]
	Learning Rate: 0.0199966
	LOSS [training: 0.6018563874459357 | validation: 0.5171608063183708]
	TIME [epoch: 8.34 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43553372608948826		[learning rate: 0.019996]
	Learning Rate: 0.0199962
	LOSS [training: 0.43553372608948826 | validation: 0.6829683942340127]
	TIME [epoch: 8.32 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5756878131139075		[learning rate: 0.019996]
	Learning Rate: 0.0199957
	LOSS [training: 0.5756878131139075 | validation: 0.5557471850106891]
	TIME [epoch: 8.3 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4606707097458715		[learning rate: 0.019995]
	Learning Rate: 0.0199952
	LOSS [training: 0.4606707097458715 | validation: 0.5458805487535525]
	TIME [epoch: 8.3 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6901275553912924		[learning rate: 0.019995]
	Learning Rate: 0.0199947
	LOSS [training: 0.6901275553912924 | validation: 0.5551936794364664]
	TIME [epoch: 8.3 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5338129997442698		[learning rate: 0.019994]
	Learning Rate: 0.0199941
	LOSS [training: 0.5338129997442698 | validation: 0.6096476239117576]
	TIME [epoch: 8.3 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45679981916317913		[learning rate: 0.019994]
	Learning Rate: 0.0199935
	LOSS [training: 0.45679981916317913 | validation: 0.4240928275913136]
	TIME [epoch: 8.34 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32207496157871646		[learning rate: 0.019993]
	Learning Rate: 0.0199929
	LOSS [training: 0.32207496157871646 | validation: 0.3418765649078378]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4468927891672404		[learning rate: 0.019992]
	Learning Rate: 0.0199923
	LOSS [training: 0.4468927891672404 | validation: 0.4742544977232749]
	TIME [epoch: 8.3 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46980855212526274		[learning rate: 0.019992]
	Learning Rate: 0.0199916
	LOSS [training: 0.46980855212526274 | validation: 0.323285411476958]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5770598676555204		[learning rate: 0.019991]
	Learning Rate: 0.0199909
	LOSS [training: 0.5770598676555204 | validation: 1.0999635330578528]
	TIME [epoch: 8.34 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7254186310587865		[learning rate: 0.01999]
	Learning Rate: 0.0199902
	LOSS [training: 0.7254186310587865 | validation: 0.5569808185004155]
	TIME [epoch: 8.39 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4939823263029046		[learning rate: 0.019989]
	Learning Rate: 0.0199895
	LOSS [training: 0.4939823263029046 | validation: 0.4207219299501667]
	TIME [epoch: 8.32 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3298829261827427		[learning rate: 0.019989]
	Learning Rate: 0.0199887
	LOSS [training: 0.3298829261827427 | validation: 0.32689876387052696]
	TIME [epoch: 8.33 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3507006465666599		[learning rate: 0.019988]
	Learning Rate: 0.0199879
	LOSS [training: 0.3507006465666599 | validation: 0.6346519805057635]
	TIME [epoch: 8.33 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5980932852992504		[learning rate: 0.019987]
	Learning Rate: 0.0199871
	LOSS [training: 0.5980932852992504 | validation: 0.8000941563147875]
	TIME [epoch: 8.32 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3955240113717756		[learning rate: 0.019986]
	Learning Rate: 0.0199862
	LOSS [training: 0.3955240113717756 | validation: 0.386972307315983]
	TIME [epoch: 8.34 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28188257850072973		[learning rate: 0.019985]
	Learning Rate: 0.0199853
	LOSS [training: 0.28188257850072973 | validation: 0.21080547244106013]
	TIME [epoch: 8.36 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48719997445130453		[learning rate: 0.019984]
	Learning Rate: 0.0199844
	LOSS [training: 0.48719997445130453 | validation: 0.9157912851405065]
	TIME [epoch: 8.43 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5223842838584427		[learning rate: 0.019984]
	Learning Rate: 0.0199835
	LOSS [training: 0.5223842838584427 | validation: 0.4548023815506025]
	TIME [epoch: 8.31 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35332691293703383		[learning rate: 0.019983]
	Learning Rate: 0.0199825
	LOSS [training: 0.35332691293703383 | validation: 0.18742073130334408]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3119615274225876		[learning rate: 0.019982]
	Learning Rate: 0.0199816
	LOSS [training: 0.3119615274225876 | validation: 0.3864560583505574]
	TIME [epoch: 8.31 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4818123365092628		[learning rate: 0.019981]
	Learning Rate: 0.0199805
	LOSS [training: 0.4818123365092628 | validation: 1.0747886186898186]
	TIME [epoch: 8.35 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.581305863133998		[learning rate: 0.019979]
	Learning Rate: 0.0199795
	LOSS [training: 0.581305863133998 | validation: 0.5219419179833433]
	TIME [epoch: 8.31 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39735185447215327		[learning rate: 0.019978]
	Learning Rate: 0.0199784
	LOSS [training: 0.39735185447215327 | validation: 0.46070755331212854]
	TIME [epoch: 8.31 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32570311937121854		[learning rate: 0.019977]
	Learning Rate: 0.0199773
	LOSS [training: 0.32570311937121854 | validation: 0.1757997904085521]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23881720768869966		[learning rate: 0.019976]
	Learning Rate: 0.0199762
	LOSS [training: 0.23881720768869966 | validation: 0.6046296321287437]
	TIME [epoch: 8.31 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3589356504565576		[learning rate: 0.019975]
	Learning Rate: 0.019975
	LOSS [training: 0.3589356504565576 | validation: 0.2843602161376546]
	TIME [epoch: 8.32 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38492010915731184		[learning rate: 0.019974]
	Learning Rate: 0.0199739
	LOSS [training: 0.38492010915731184 | validation: 0.23273725118724098]
	TIME [epoch: 8.33 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.197648902303534		[learning rate: 0.019973]
	Learning Rate: 0.0199727
	LOSS [training: 0.197648902303534 | validation: 0.4569044581382935]
	TIME [epoch: 8.3 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25525820101083235		[learning rate: 0.019971]
	Learning Rate: 0.0199714
	LOSS [training: 0.25525820101083235 | validation: 0.44952438789856863]
	TIME [epoch: 8.31 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5227427513069163		[learning rate: 0.01997]
	Learning Rate: 0.0199702
	LOSS [training: 0.5227427513069163 | validation: 0.43771636814149595]
	TIME [epoch: 8.29 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3980149169956949		[learning rate: 0.019969]
	Learning Rate: 0.0199689
	LOSS [training: 0.3980149169956949 | validation: 0.4121378811793131]
	TIME [epoch: 8.29 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3156437182834127		[learning rate: 0.019968]
	Learning Rate: 0.0199675
	LOSS [training: 0.3156437182834127 | validation: 0.31978610596005663]
	TIME [epoch: 8.33 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.315489831150921		[learning rate: 0.019966]
	Learning Rate: 0.0199662
	LOSS [training: 0.315489831150921 | validation: 0.28975223479336915]
	TIME [epoch: 8.3 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31980972881291425		[learning rate: 0.019965]
	Learning Rate: 0.0199648
	LOSS [training: 0.31980972881291425 | validation: 0.20753634995992626]
	TIME [epoch: 8.29 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2849093692675957		[learning rate: 0.019963]
	Learning Rate: 0.0199634
	LOSS [training: 0.2849093692675957 | validation: 0.28554987899886763]
	TIME [epoch: 8.29 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3372021087368845		[learning rate: 0.019962]
	Learning Rate: 0.019962
	LOSS [training: 0.3372021087368845 | validation: 0.35939050223431845]
	TIME [epoch: 8.29 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2502884007936901		[learning rate: 0.019961]
	Learning Rate: 0.0199606
	LOSS [training: 0.2502884007936901 | validation: 0.16983630758722484]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2813597978502764		[learning rate: 0.019959]
	Learning Rate: 0.0199591
	LOSS [training: 0.2813597978502764 | validation: 0.22565171183348098]
	TIME [epoch: 8.33 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34290074602769155		[learning rate: 0.019958]
	Learning Rate: 0.0199576
	LOSS [training: 0.34290074602769155 | validation: 0.2862530526063273]
	TIME [epoch: 8.3 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16592570875119889		[learning rate: 0.019956]
	Learning Rate: 0.019956
	LOSS [training: 0.16592570875119889 | validation: 0.22364703948719927]
	TIME [epoch: 8.3 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31432515360665736		[learning rate: 0.019954]
	Learning Rate: 0.0199545
	LOSS [training: 0.31432515360665736 | validation: 0.18341905380250983]
	TIME [epoch: 8.29 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2161863184111931		[learning rate: 0.019953]
	Learning Rate: 0.0199529
	LOSS [training: 0.2161863184111931 | validation: 0.2398272342256711]
	TIME [epoch: 8.31 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23742967993343772		[learning rate: 0.019951]
	Learning Rate: 0.0199513
	LOSS [training: 0.23742967993343772 | validation: 0.21491782918360658]
	TIME [epoch: 8.33 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18393779248366063		[learning rate: 0.01995]
	Learning Rate: 0.0199496
	LOSS [training: 0.18393779248366063 | validation: 0.09212849142314908]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_111.pth
	Model improved!!!
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3104267266585541		[learning rate: 0.019948]
	Learning Rate: 0.0199479
	LOSS [training: 0.3104267266585541 | validation: 0.17116158125174963]
	TIME [epoch: 8.29 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22547229309892042		[learning rate: 0.019946]
	Learning Rate: 0.0199462
	LOSS [training: 0.22547229309892042 | validation: 0.15306439545493553]
	TIME [epoch: 8.3 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15334191595421437		[learning rate: 0.019945]
	Learning Rate: 0.0199445
	LOSS [training: 0.15334191595421437 | validation: 0.1614100942643869]
	TIME [epoch: 8.29 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19666919020256707		[learning rate: 0.019943]
	Learning Rate: 0.0199428
	LOSS [training: 0.19666919020256707 | validation: 0.411542477765958]
	TIME [epoch: 8.31 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2747144054489069		[learning rate: 0.019941]
	Learning Rate: 0.019941
	LOSS [training: 0.2747144054489069 | validation: 0.09870785422816367]
	TIME [epoch: 8.33 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2082445264640582		[learning rate: 0.019939]
	Learning Rate: 0.0199392
	LOSS [training: 0.2082445264640582 | validation: 0.24513496329840684]
	TIME [epoch: 8.29 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26132372643601004		[learning rate: 0.019937]
	Learning Rate: 0.0199374
	LOSS [training: 0.26132372643601004 | validation: 0.16093830202371226]
	TIME [epoch: 8.29 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1165908515009275		[learning rate: 0.019935]
	Learning Rate: 0.0199355
	LOSS [training: 0.1165908515009275 | validation: 0.13600987196511188]
	TIME [epoch: 8.28 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20590790835089806		[learning rate: 0.019934]
	Learning Rate: 0.0199336
	LOSS [training: 0.20590790835089806 | validation: 0.21693527410783264]
	TIME [epoch: 8.28 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18199976364163947		[learning rate: 0.019932]
	Learning Rate: 0.0199317
	LOSS [training: 0.18199976364163947 | validation: 0.23080553125413977]
	TIME [epoch: 8.32 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27605205862496957		[learning rate: 0.01993]
	Learning Rate: 0.0199297
	LOSS [training: 0.27605205862496957 | validation: 0.23545448943488234]
	TIME [epoch: 8.3 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24046513025275656		[learning rate: 0.019928]
	Learning Rate: 0.0199278
	LOSS [training: 0.24046513025275656 | validation: 0.32758660198243283]
	TIME [epoch: 8.29 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1730515100325375		[learning rate: 0.019926]
	Learning Rate: 0.0199258
	LOSS [training: 0.1730515100325375 | validation: 0.10855562638901253]
	TIME [epoch: 8.29 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2218307291541758		[learning rate: 0.019924]
	Learning Rate: 0.0199238
	LOSS [training: 0.2218307291541758 | validation: 0.14853433884030112]
	TIME [epoch: 8.29 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15853219012822944		[learning rate: 0.019922]
	Learning Rate: 0.0199217
	LOSS [training: 0.15853219012822944 | validation: 0.1532047535212163]
	TIME [epoch: 8.3 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18733933288208016		[learning rate: 0.01992]
	Learning Rate: 0.0199196
	LOSS [training: 0.18733933288208016 | validation: 0.20798640326756518]
	TIME [epoch: 8.33 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16694284568839754		[learning rate: 0.019918]
	Learning Rate: 0.0199175
	LOSS [training: 0.16694284568839754 | validation: 0.15778538489441915]
	TIME [epoch: 8.29 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18919733306399128		[learning rate: 0.019915]
	Learning Rate: 0.0199154
	LOSS [training: 0.18919733306399128 | validation: 0.07362213925156696]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_129.pth
	Model improved!!!
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12555864456836885		[learning rate: 0.019913]
	Learning Rate: 0.0199132
	LOSS [training: 0.12555864456836885 | validation: 0.22084432194084846]
	TIME [epoch: 8.29 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19757704375244112		[learning rate: 0.019911]
	Learning Rate: 0.019911
	LOSS [training: 0.19757704375244112 | validation: 0.19722397471590547]
	TIME [epoch: 8.28 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12073328377519478		[learning rate: 0.019909]
	Learning Rate: 0.0199088
	LOSS [training: 0.12073328377519478 | validation: 0.1876652402785003]
	TIME [epoch: 8.32 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1826204561537248		[learning rate: 0.019907]
	Learning Rate: 0.0199066
	LOSS [training: 0.1826204561537248 | validation: 0.3199070623520991]
	TIME [epoch: 8.3 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13109105248001665		[learning rate: 0.019904]
	Learning Rate: 0.0199043
	LOSS [training: 0.13109105248001665 | validation: 0.1343900056238999]
	TIME [epoch: 8.29 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2456415643939988		[learning rate: 0.019902]
	Learning Rate: 0.019902
	LOSS [training: 0.2456415643939988 | validation: 0.17293359587981008]
	TIME [epoch: 8.29 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13486217331795186		[learning rate: 0.0199]
	Learning Rate: 0.0198997
	LOSS [training: 0.13486217331795186 | validation: 0.09379342681066796]
	TIME [epoch: 8.29 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16455635207491026		[learning rate: 0.019897]
	Learning Rate: 0.0198974
	LOSS [training: 0.16455635207491026 | validation: 0.09340950841936149]
	TIME [epoch: 8.29 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11105169628463261		[learning rate: 0.019895]
	Learning Rate: 0.019895
	LOSS [training: 0.11105169628463261 | validation: 0.26848935331668333]
	TIME [epoch: 8.34 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1880782899137225		[learning rate: 0.019893]
	Learning Rate: 0.0198926
	LOSS [training: 0.1880782899137225 | validation: 0.1117709699810662]
	TIME [epoch: 8.29 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11427561248227461		[learning rate: 0.01989]
	Learning Rate: 0.0198901
	LOSS [training: 0.11427561248227461 | validation: 0.08316974955302306]
	TIME [epoch: 8.29 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11056876032315237		[learning rate: 0.019888]
	Learning Rate: 0.0198877
	LOSS [training: 0.11056876032315237 | validation: 0.23037120201675926]
	TIME [epoch: 8.29 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24524299053360013		[learning rate: 0.019885]
	Learning Rate: 0.0198852
	LOSS [training: 0.24524299053360013 | validation: 0.1697308179958455]
	TIME [epoch: 8.29 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2524971275037625		[learning rate: 0.019883]
	Learning Rate: 0.0198827
	LOSS [training: 0.2524971275037625 | validation: 0.3309897143947085]
	TIME [epoch: 8.33 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17807608474709202		[learning rate: 0.01988]
	Learning Rate: 0.0198802
	LOSS [training: 0.17807608474709202 | validation: 0.30994688856440444]
	TIME [epoch: 8.3 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19091648533066138		[learning rate: 0.019878]
	Learning Rate: 0.0198776
	LOSS [training: 0.19091648533066138 | validation: 0.2302838633761119]
	TIME [epoch: 8.29 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22749009882390386		[learning rate: 0.019875]
	Learning Rate: 0.019875
	LOSS [training: 0.22749009882390386 | validation: 0.4838451490722778]
	TIME [epoch: 8.29 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21349272279255382		[learning rate: 0.019872]
	Learning Rate: 0.0198724
	LOSS [training: 0.21349272279255382 | validation: 0.08248598564087144]
	TIME [epoch: 8.29 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11731248116723975		[learning rate: 0.01987]
	Learning Rate: 0.0198697
	LOSS [training: 0.11731248116723975 | validation: 0.25159317381050283]
	TIME [epoch: 8.29 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15853971843734777		[learning rate: 0.019867]
	Learning Rate: 0.0198671
	LOSS [training: 0.15853971843734777 | validation: 0.08591535549507925]
	TIME [epoch: 8.33 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10251421230388318		[learning rate: 0.019864]
	Learning Rate: 0.0198644
	LOSS [training: 0.10251421230388318 | validation: 0.26682508949209416]
	TIME [epoch: 8.29 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22671377341486135		[learning rate: 0.019862]
	Learning Rate: 0.0198616
	LOSS [training: 0.22671377341486135 | validation: 0.20505211600194106]
	TIME [epoch: 8.3 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12455540610819116		[learning rate: 0.019859]
	Learning Rate: 0.0198589
	LOSS [training: 0.12455540610819116 | validation: 0.06909869122390111]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_152.pth
	Model improved!!!
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11072581146672103		[learning rate: 0.019856]
	Learning Rate: 0.0198561
	LOSS [training: 0.11072581146672103 | validation: 0.32321258413024107]
	TIME [epoch: 8.3 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19983977499509353		[learning rate: 0.019853]
	Learning Rate: 0.0198533
	LOSS [training: 0.19983977499509353 | validation: 0.15802936310590404]
	TIME [epoch: 8.37 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18469462385210547		[learning rate: 0.01985]
	Learning Rate: 0.0198505
	LOSS [training: 0.18469462385210547 | validation: 0.25602262958003763]
	TIME [epoch: 8.33 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17312214803224382		[learning rate: 0.019848]
	Learning Rate: 0.0198476
	LOSS [training: 0.17312214803224382 | validation: 0.11138824803508265]
	TIME [epoch: 8.31 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13702671274830336		[learning rate: 0.019845]
	Learning Rate: 0.0198447
	LOSS [training: 0.13702671274830336 | validation: 0.27794635752970576]
	TIME [epoch: 8.31 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16047654969024977		[learning rate: 0.019842]
	Learning Rate: 0.0198418
	LOSS [training: 0.16047654969024977 | validation: 0.04985899896064028]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_158.pth
	Model improved!!!
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06427811192076965		[learning rate: 0.019839]
	Learning Rate: 0.0198388
	LOSS [training: 0.06427811192076965 | validation: 0.05969396560697883]
	TIME [epoch: 8.31 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17159429418767153		[learning rate: 0.019836]
	Learning Rate: 0.0198359
	LOSS [training: 0.17159429418767153 | validation: 0.24339739388170323]
	TIME [epoch: 8.34 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17746448453227237		[learning rate: 0.019833]
	Learning Rate: 0.0198329
	LOSS [training: 0.17746448453227237 | validation: 0.08972225301809984]
	TIME [epoch: 8.31 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11859766957131918		[learning rate: 0.01983]
	Learning Rate: 0.0198299
	LOSS [training: 0.11859766957131918 | validation: 0.28107692410163865]
	TIME [epoch: 8.3 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1939252464530695		[learning rate: 0.019827]
	Learning Rate: 0.0198268
	LOSS [training: 0.1939252464530695 | validation: 0.1322927288278854]
	TIME [epoch: 8.29 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09012155367146665		[learning rate: 0.019824]
	Learning Rate: 0.0198237
	LOSS [training: 0.09012155367146665 | validation: 0.06275075251132259]
	TIME [epoch: 8.29 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1092187880143993		[learning rate: 0.019821]
	Learning Rate: 0.0198206
	LOSS [training: 0.1092187880143993 | validation: 0.22619118240447664]
	TIME [epoch: 8.33 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1699688139376558		[learning rate: 0.019818]
	Learning Rate: 0.0198175
	LOSS [training: 0.1699688139376558 | validation: 0.06042573254720299]
	TIME [epoch: 8.31 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052649105075182404		[learning rate: 0.019814]
	Learning Rate: 0.0198143
	LOSS [training: 0.052649105075182404 | validation: 0.20742032179519126]
	TIME [epoch: 8.3 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17100988088765587		[learning rate: 0.019811]
	Learning Rate: 0.0198112
	LOSS [training: 0.17100988088765587 | validation: 0.17269364182741564]
	TIME [epoch: 8.29 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13615165034980706		[learning rate: 0.019808]
	Learning Rate: 0.0198079
	LOSS [training: 0.13615165034980706 | validation: 0.16448056918966256]
	TIME [epoch: 8.29 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08851740212336051		[learning rate: 0.019805]
	Learning Rate: 0.0198047
	LOSS [training: 0.08851740212336051 | validation: 0.35321788742900373]
	TIME [epoch: 8.3 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19141361259996145		[learning rate: 0.019801]
	Learning Rate: 0.0198014
	LOSS [training: 0.19141361259996145 | validation: 0.09339199900807746]
	TIME [epoch: 8.35 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053196381184520365		[learning rate: 0.019798]
	Learning Rate: 0.0197982
	LOSS [training: 0.053196381184520365 | validation: 0.08565154665972444]
	TIME [epoch: 8.3 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.148336101493175		[learning rate: 0.019795]
	Learning Rate: 0.0197948
	LOSS [training: 0.148336101493175 | validation: 0.11535897190671915]
	TIME [epoch: 8.3 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15428341156589181		[learning rate: 0.019791]
	Learning Rate: 0.0197915
	LOSS [training: 0.15428341156589181 | validation: 0.14574644447034404]
	TIME [epoch: 8.3 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1471893264131876		[learning rate: 0.019788]
	Learning Rate: 0.0197881
	LOSS [training: 0.1471893264131876 | validation: 0.14968361352326875]
	TIME [epoch: 8.29 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1350151243250412		[learning rate: 0.019785]
	Learning Rate: 0.0197847
	LOSS [training: 0.1350151243250412 | validation: 0.05057553894387341]
	TIME [epoch: 8.31 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12026800739714044		[learning rate: 0.019781]
	Learning Rate: 0.0197813
	LOSS [training: 0.12026800739714044 | validation: 0.08353636747284962]
	TIME [epoch: 8.32 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1254438411277549		[learning rate: 0.019778]
	Learning Rate: 0.0197778
	LOSS [training: 0.1254438411277549 | validation: 0.1412429167916564]
	TIME [epoch: 8.31 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13731718474249788		[learning rate: 0.019774]
	Learning Rate: 0.0197744
	LOSS [training: 0.13731718474249788 | validation: 0.13601423932704923]
	TIME [epoch: 8.29 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10911000546836874		[learning rate: 0.019771]
	Learning Rate: 0.0197709
	LOSS [training: 0.10911000546836874 | validation: 0.10471691891729172]
	TIME [epoch: 8.29 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09762640996248582		[learning rate: 0.019767]
	Learning Rate: 0.0197673
	LOSS [training: 0.09762640996248582 | validation: 0.2352685317966608]
	TIME [epoch: 8.29 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14579360849460393		[learning rate: 0.019764]
	Learning Rate: 0.0197638
	LOSS [training: 0.14579360849460393 | validation: 0.12832824004575655]
	TIME [epoch: 8.33 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12468618756259461		[learning rate: 0.01976]
	Learning Rate: 0.0197602
	LOSS [training: 0.12468618756259461 | validation: 0.23468358467047223]
	TIME [epoch: 8.31 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15679096835190162		[learning rate: 0.019757]
	Learning Rate: 0.0197566
	LOSS [training: 0.15679096835190162 | validation: 0.08479781971760007]
	TIME [epoch: 8.29 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1295672018568096		[learning rate: 0.019753]
	Learning Rate: 0.0197529
	LOSS [training: 0.1295672018568096 | validation: 0.06587179807228978]
	TIME [epoch: 8.29 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06664770936878542		[learning rate: 0.019749]
	Learning Rate: 0.0197493
	LOSS [training: 0.06664770936878542 | validation: 0.09774527850387206]
	TIME [epoch: 8.3 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09912496667755655		[learning rate: 0.019746]
	Learning Rate: 0.0197456
	LOSS [training: 0.09912496667755655 | validation: 0.49005689590172263]
	TIME [epoch: 8.31 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1394118995730214		[learning rate: 0.019742]
	Learning Rate: 0.0197419
	LOSS [training: 0.1394118995730214 | validation: 0.3775391356582597]
	TIME [epoch: 8.33 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31731920738463926		[learning rate: 0.019738]
	Learning Rate: 0.0197381
	LOSS [training: 0.31731920738463926 | validation: 0.2194828530347579]
	TIME [epoch: 8.3 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1986343217485707		[learning rate: 0.019734]
	Learning Rate: 0.0197343
	LOSS [training: 0.1986343217485707 | validation: 0.16739046777761224]
	TIME [epoch: 8.3 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.084257006528273		[learning rate: 0.019731]
	Learning Rate: 0.0197305
	LOSS [training: 0.084257006528273 | validation: 0.06808005018694338]
	TIME [epoch: 8.3 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12377058691345899		[learning rate: 0.019727]
	Learning Rate: 0.0197267
	LOSS [training: 0.12377058691345899 | validation: 0.13428383461644716]
	TIME [epoch: 8.29 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05826486418663266		[learning rate: 0.019723]
	Learning Rate: 0.0197229
	LOSS [training: 0.05826486418663266 | validation: 0.042061527376419314]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_193.pth
	Model improved!!!
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13855996687663288		[learning rate: 0.019719]
	Learning Rate: 0.019719
	LOSS [training: 0.13855996687663288 | validation: 0.16048180302787746]
	TIME [epoch: 8.31 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08750351988543809		[learning rate: 0.019715]
	Learning Rate: 0.0197151
	LOSS [training: 0.08750351988543809 | validation: 0.08647701586440058]
	TIME [epoch: 8.28 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12929634199506512		[learning rate: 0.019711]
	Learning Rate: 0.0197112
	LOSS [training: 0.12929634199506512 | validation: 0.09530144059793215]
	TIME [epoch: 8.29 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15950419804104127		[learning rate: 0.019707]
	Learning Rate: 0.0197072
	LOSS [training: 0.15950419804104127 | validation: 0.21189544920183964]
	TIME [epoch: 8.29 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10069014285023814		[learning rate: 0.019703]
	Learning Rate: 0.0197032
	LOSS [training: 0.10069014285023814 | validation: 0.05899604421159689]
	TIME [epoch: 8.29 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05899253147397501		[learning rate: 0.019699]
	Learning Rate: 0.0196992
	LOSS [training: 0.05899253147397501 | validation: 0.13722828149948704]
	TIME [epoch: 8.33 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18267568958936997		[learning rate: 0.019695]
	Learning Rate: 0.0196952
	LOSS [training: 0.18267568958936997 | validation: 0.22895822596694626]
	TIME [epoch: 8.29 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10199876270760289		[learning rate: 0.019691]
	Learning Rate: 0.0196911
	LOSS [training: 0.10199876270760289 | validation: 0.10449157636922066]
	TIME [epoch: 8.28 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12960853443669226		[learning rate: 0.019687]
	Learning Rate: 0.019687
	LOSS [training: 0.12960853443669226 | validation: 0.08711602180741859]
	TIME [epoch: 8.29 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06411294931788764		[learning rate: 0.019683]
	Learning Rate: 0.0196829
	LOSS [training: 0.06411294931788764 | validation: 0.05326083705074977]
	TIME [epoch: 8.29 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06969782894049316		[learning rate: 0.019679]
	Learning Rate: 0.0196788
	LOSS [training: 0.06969782894049316 | validation: 0.25897553465285406]
	TIME [epoch: 8.32 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14591529597684608		[learning rate: 0.019675]
	Learning Rate: 0.0196746
	LOSS [training: 0.14591529597684608 | validation: 0.09417268410090673]
	TIME [epoch: 8.3 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11849915573448687		[learning rate: 0.01967]
	Learning Rate: 0.0196704
	LOSS [training: 0.11849915573448687 | validation: 0.11912822247738966]
	TIME [epoch: 8.28 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06402458452601088		[learning rate: 0.019666]
	Learning Rate: 0.0196662
	LOSS [training: 0.06402458452601088 | validation: 0.051151019105541574]
	TIME [epoch: 8.29 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14326515026316294		[learning rate: 0.019662]
	Learning Rate: 0.0196619
	LOSS [training: 0.14326515026316294 | validation: 0.09536592988869785]
	TIME [epoch: 8.28 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07245166634190846		[learning rate: 0.019658]
	Learning Rate: 0.0196576
	LOSS [training: 0.07245166634190846 | validation: 0.08470685435505293]
	TIME [epoch: 8.28 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14634911580079002		[learning rate: 0.019653]
	Learning Rate: 0.0196533
	LOSS [training: 0.14634911580079002 | validation: 0.09454466853564181]
	TIME [epoch: 8.32 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10232226146098586		[learning rate: 0.019649]
	Learning Rate: 0.019649
	LOSS [training: 0.10232226146098586 | validation: 0.14619979164710944]
	TIME [epoch: 8.29 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06788843176159567		[learning rate: 0.019645]
	Learning Rate: 0.0196447
	LOSS [training: 0.06788843176159567 | validation: 0.06412863869969429]
	TIME [epoch: 8.28 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08857094802591345		[learning rate: 0.01964]
	Learning Rate: 0.0196403
	LOSS [training: 0.08857094802591345 | validation: 0.17455201874729775]
	TIME [epoch: 8.28 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10841976016159553		[learning rate: 0.019636]
	Learning Rate: 0.0196359
	LOSS [training: 0.10841976016159553 | validation: 0.04172576721613296]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_214.pth
	Model improved!!!
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04688068384295199		[learning rate: 0.019631]
	Learning Rate: 0.0196314
	LOSS [training: 0.04688068384295199 | validation: 0.16079499773731426]
	TIME [epoch: 8.33 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16504852425520508		[learning rate: 0.019627]
	Learning Rate: 0.019627
	LOSS [training: 0.16504852425520508 | validation: 0.04984283167048656]
	TIME [epoch: 8.3 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04834404083290038		[learning rate: 0.019622]
	Learning Rate: 0.0196225
	LOSS [training: 0.04834404083290038 | validation: 0.05201582184257652]
	TIME [epoch: 8.29 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12445612709474788		[learning rate: 0.019618]
	Learning Rate: 0.019618
	LOSS [training: 0.12445612709474788 | validation: 0.1120939534396592]
	TIME [epoch: 8.29 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07680521049936084		[learning rate: 0.019613]
	Learning Rate: 0.0196134
	LOSS [training: 0.07680521049936084 | validation: 0.20521759736207584]
	TIME [epoch: 8.29 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11164847855079761		[learning rate: 0.019609]
	Learning Rate: 0.0196089
	LOSS [training: 0.11164847855079761 | validation: 0.14984453028444328]
	TIME [epoch: 8.29 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13574792495060448		[learning rate: 0.019604]
	Learning Rate: 0.0196043
	LOSS [training: 0.13574792495060448 | validation: 0.08720054681509913]
	TIME [epoch: 8.33 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05963116359237119		[learning rate: 0.0196]
	Learning Rate: 0.0195997
	LOSS [training: 0.05963116359237119 | validation: 0.162284758378702]
	TIME [epoch: 8.29 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12081812991293053		[learning rate: 0.019595]
	Learning Rate: 0.019595
	LOSS [training: 0.12081812991293053 | validation: 0.10527998620780726]
	TIME [epoch: 8.3 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05464799598095261		[learning rate: 0.01959]
	Learning Rate: 0.0195904
	LOSS [training: 0.05464799598095261 | validation: 0.05990338382211788]
	TIME [epoch: 8.29 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09627431535515438		[learning rate: 0.019586]
	Learning Rate: 0.0195857
	LOSS [training: 0.09627431535515438 | validation: 0.26343708242772335]
	TIME [epoch: 8.29 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1279981114743243		[learning rate: 0.019581]
	Learning Rate: 0.0195809
	LOSS [training: 0.1279981114743243 | validation: 0.09784996490736694]
	TIME [epoch: 8.33 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09049131794350236		[learning rate: 0.019576]
	Learning Rate: 0.0195762
	LOSS [training: 0.09049131794350236 | validation: 0.21292738936487532]
	TIME [epoch: 8.3 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2659246177541069		[learning rate: 0.019571]
	Learning Rate: 0.0195714
	LOSS [training: 0.2659246177541069 | validation: 0.1492708497520493]
	TIME [epoch: 8.28 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13851824214544461		[learning rate: 0.019567]
	Learning Rate: 0.0195666
	LOSS [training: 0.13851824214544461 | validation: 0.0921741524086525]
	TIME [epoch: 8.28 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07919139435832667		[learning rate: 0.019562]
	Learning Rate: 0.0195618
	LOSS [training: 0.07919139435832667 | validation: 0.06046953508833347]
	TIME [epoch: 8.28 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11676757761067988		[learning rate: 0.019557]
	Learning Rate: 0.0195569
	LOSS [training: 0.11676757761067988 | validation: 0.15218769757599487]
	TIME [epoch: 8.29 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1014660904069597		[learning rate: 0.019552]
	Learning Rate: 0.0195521
	LOSS [training: 0.1014660904069597 | validation: 0.13529788253024916]
	TIME [epoch: 8.33 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15146580812532096		[learning rate: 0.019547]
	Learning Rate: 0.0195472
	LOSS [training: 0.15146580812532096 | validation: 0.07927787934305888]
	TIME [epoch: 8.29 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05718358569010134		[learning rate: 0.019542]
	Learning Rate: 0.0195422
	LOSS [training: 0.05718358569010134 | validation: 0.05817275227130632]
	TIME [epoch: 8.28 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11941612504800375		[learning rate: 0.019537]
	Learning Rate: 0.0195373
	LOSS [training: 0.11941612504800375 | validation: 0.17484569325583163]
	TIME [epoch: 8.29 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09194888034715774		[learning rate: 0.019532]
	Learning Rate: 0.0195323
	LOSS [training: 0.09194888034715774 | validation: 0.10371811522587643]
	TIME [epoch: 8.29 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0745260829496963		[learning rate: 0.019527]
	Learning Rate: 0.0195273
	LOSS [training: 0.0745260829496963 | validation: 0.11295926296984769]
	TIME [epoch: 8.31 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11121668979138113		[learning rate: 0.019522]
	Learning Rate: 0.0195222
	LOSS [training: 0.11121668979138113 | validation: 0.10419206934417385]
	TIME [epoch: 8.31 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05771157299103279		[learning rate: 0.019517]
	Learning Rate: 0.0195172
	LOSS [training: 0.05771157299103279 | validation: 0.10478247432500713]
	TIME [epoch: 8.29 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16232843342197573		[learning rate: 0.019512]
	Learning Rate: 0.0195121
	LOSS [training: 0.16232843342197573 | validation: 0.08506664242726848]
	TIME [epoch: 8.29 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08988068812294803		[learning rate: 0.019507]
	Learning Rate: 0.019507
	LOSS [training: 0.08988068812294803 | validation: 0.09855518502316116]
	TIME [epoch: 8.31 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10026466062188716		[learning rate: 0.019502]
	Learning Rate: 0.0195018
	LOSS [training: 0.10026466062188716 | validation: 0.09424018954516784]
	TIME [epoch: 8.29 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10245151583656313		[learning rate: 0.019497]
	Learning Rate: 0.0194967
	LOSS [training: 0.10245151583656313 | validation: 0.048502503032828444]
	TIME [epoch: 8.33 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07148463583353017		[learning rate: 0.019491]
	Learning Rate: 0.0194915
	LOSS [training: 0.07148463583353017 | validation: 0.16192306683050556]
	TIME [epoch: 8.29 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12170507860795565		[learning rate: 0.019486]
	Learning Rate: 0.0194863
	LOSS [training: 0.12170507860795565 | validation: 0.09368171298233705]
	TIME [epoch: 8.28 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0781759335188279		[learning rate: 0.019481]
	Learning Rate: 0.019481
	LOSS [training: 0.0781759335188279 | validation: 0.05452804236917283]
	TIME [epoch: 8.28 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11511605190999825		[learning rate: 0.019476]
	Learning Rate: 0.0194757
	LOSS [training: 0.11511605190999825 | validation: 0.07718170585133041]
	TIME [epoch: 8.29 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05326878121087757		[learning rate: 0.01947]
	Learning Rate: 0.0194705
	LOSS [training: 0.05326878121087757 | validation: 0.12869537602789308]
	TIME [epoch: 8.31 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12065419627881008		[learning rate: 0.019465]
	Learning Rate: 0.0194651
	LOSS [training: 0.12065419627881008 | validation: 0.09082288823181489]
	TIME [epoch: 8.31 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054687481870568634		[learning rate: 0.01946]
	Learning Rate: 0.0194598
	LOSS [training: 0.054687481870568634 | validation: 0.08733644787303088]
	TIME [epoch: 8.28 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10610526346190219		[learning rate: 0.019454]
	Learning Rate: 0.0194544
	LOSS [training: 0.10610526346190219 | validation: 0.13649776901895222]
	TIME [epoch: 8.28 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0779358430776036		[learning rate: 0.019449]
	Learning Rate: 0.019449
	LOSS [training: 0.0779358430776036 | validation: 0.052325312935681274]
	TIME [epoch: 8.29 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07332716211264223		[learning rate: 0.019444]
	Learning Rate: 0.0194436
	LOSS [training: 0.07332716211264223 | validation: 0.07758318179118329]
	TIME [epoch: 8.29 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08841607403058037		[learning rate: 0.019438]
	Learning Rate: 0.0194381
	LOSS [training: 0.08841607403058037 | validation: 0.15704065944290463]
	TIME [epoch: 8.33 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10566814937636387		[learning rate: 0.019433]
	Learning Rate: 0.0194327
	LOSS [training: 0.10566814937636387 | validation: 0.06150958588912343]
	TIME [epoch: 8.3 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053677770568045596		[learning rate: 0.019427]
	Learning Rate: 0.0194272
	LOSS [training: 0.053677770568045596 | validation: 0.08459596999857873]
	TIME [epoch: 8.29 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10852455017952839		[learning rate: 0.019422]
	Learning Rate: 0.0194216
	LOSS [training: 0.10852455017952839 | validation: 0.05798525934798825]
	TIME [epoch: 8.29 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07013439028650481		[learning rate: 0.019416]
	Learning Rate: 0.0194161
	LOSS [training: 0.07013439028650481 | validation: 0.2239756807308442]
	TIME [epoch: 8.3 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12228496663302649		[learning rate: 0.019411]
	Learning Rate: 0.0194105
	LOSS [training: 0.12228496663302649 | validation: 0.08332834674682782]
	TIME [epoch: 8.3 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06562308216138985		[learning rate: 0.019405]
	Learning Rate: 0.0194049
	LOSS [training: 0.06562308216138985 | validation: 0.17650761529423686]
	TIME [epoch: 8.33 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10269363798700118		[learning rate: 0.019399]
	Learning Rate: 0.0193993
	LOSS [training: 0.10269363798700118 | validation: 0.04978439934242862]
	TIME [epoch: 8.29 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06014915564854174		[learning rate: 0.019394]
	Learning Rate: 0.0193936
	LOSS [training: 0.06014915564854174 | validation: 0.09817751087352919]
	TIME [epoch: 8.28 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08829010995615472		[learning rate: 0.019388]
	Learning Rate: 0.0193879
	LOSS [training: 0.08829010995615472 | validation: 0.10261416335224594]
	TIME [epoch: 8.29 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0574177212497862		[learning rate: 0.019382]
	Learning Rate: 0.0193822
	LOSS [training: 0.0574177212497862 | validation: 0.08324349268626811]
	TIME [epoch: 8.29 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10661942171823419		[learning rate: 0.019376]
	Learning Rate: 0.0193765
	LOSS [training: 0.10661942171823419 | validation: 0.06172447877501808]
	TIME [epoch: 8.32 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05866156729833133		[learning rate: 0.019371]
	Learning Rate: 0.0193707
	LOSS [training: 0.05866156729833133 | validation: 0.07319216497844343]
	TIME [epoch: 8.29 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1011650580621001		[learning rate: 0.019365]
	Learning Rate: 0.0193649
	LOSS [training: 0.1011650580621001 | validation: 0.11774061902691474]
	TIME [epoch: 8.29 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05117560296461669		[learning rate: 0.019359]
	Learning Rate: 0.0193591
	LOSS [training: 0.05117560296461669 | validation: 0.1498874513093773]
	TIME [epoch: 8.29 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11154171003254236		[learning rate: 0.019353]
	Learning Rate: 0.0193533
	LOSS [training: 0.11154171003254236 | validation: 0.039474793733652966]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_269.pth
	Model improved!!!
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06768266858265844		[learning rate: 0.019347]
	Learning Rate: 0.0193474
	LOSS [training: 0.06768266858265844 | validation: 0.07627658554375652]
	TIME [epoch: 8.32 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1067065091762606		[learning rate: 0.019342]
	Learning Rate: 0.0193416
	LOSS [training: 0.1067065091762606 | validation: 0.11803355672117123]
	TIME [epoch: 8.32 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07965137973626582		[learning rate: 0.019336]
	Learning Rate: 0.0193356
	LOSS [training: 0.07965137973626582 | validation: 0.06382225944086974]
	TIME [epoch: 8.3 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0720626616162594		[learning rate: 0.01933]
	Learning Rate: 0.0193297
	LOSS [training: 0.0720626616162594 | validation: 0.08174438586013169]
	TIME [epoch: 8.29 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09519091005537111		[learning rate: 0.019324]
	Learning Rate: 0.0193237
	LOSS [training: 0.09519091005537111 | validation: 0.06475694824346354]
	TIME [epoch: 8.29 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054745243320034706		[learning rate: 0.019318]
	Learning Rate: 0.0193178
	LOSS [training: 0.054745243320034706 | validation: 0.06577298715908275]
	TIME [epoch: 8.29 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08077112553387593		[learning rate: 0.019312]
	Learning Rate: 0.0193117
	LOSS [training: 0.08077112553387593 | validation: 0.07925887581030473]
	TIME [epoch: 8.32 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05412425031228822		[learning rate: 0.019306]
	Learning Rate: 0.0193057
	LOSS [training: 0.05412425031228822 | validation: 0.06291669054575524]
	TIME [epoch: 8.3 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10177701333192835		[learning rate: 0.0193]
	Learning Rate: 0.0192996
	LOSS [training: 0.10177701333192835 | validation: 0.05061633696592457]
	TIME [epoch: 8.29 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05091907246205467		[learning rate: 0.019294]
	Learning Rate: 0.0192935
	LOSS [training: 0.05091907246205467 | validation: 0.17723164936356306]
	TIME [epoch: 8.29 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12277217141924618		[learning rate: 0.019287]
	Learning Rate: 0.0192874
	LOSS [training: 0.12277217141924618 | validation: 0.06592706648076124]
	TIME [epoch: 8.29 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06502746813022907		[learning rate: 0.019281]
	Learning Rate: 0.0192813
	LOSS [training: 0.06502746813022907 | validation: 0.08340273716550076]
	TIME [epoch: 8.29 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034574474314737036		[learning rate: 0.019275]
	Learning Rate: 0.0192751
	LOSS [training: 0.034574474314737036 | validation: 0.036966177658757]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_282.pth
	Model improved!!!
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10578576840874665		[learning rate: 0.019269]
	Learning Rate: 0.0192689
	LOSS [training: 0.10578576840874665 | validation: 0.15186419188707395]
	TIME [epoch: 8.3 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08732833124628862		[learning rate: 0.019263]
	Learning Rate: 0.0192627
	LOSS [training: 0.08732833124628862 | validation: 0.05621642832636316]
	TIME [epoch: 8.32 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07163396331166061		[learning rate: 0.019256]
	Learning Rate: 0.0192565
	LOSS [training: 0.07163396331166061 | validation: 0.05785910524006304]
	TIME [epoch: 8.31 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06757840938763378		[learning rate: 0.01925]
	Learning Rate: 0.0192502
	LOSS [training: 0.06757840938763378 | validation: 0.19105852532677914]
	TIME [epoch: 8.3 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1427365046703463		[learning rate: 0.019244]
	Learning Rate: 0.0192439
	LOSS [training: 0.1427365046703463 | validation: 0.0531821572403145]
	TIME [epoch: 8.34 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030640214333449274		[learning rate: 0.019238]
	Learning Rate: 0.0192376
	LOSS [training: 0.030640214333449274 | validation: 0.03051701761085331]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_288.pth
	Model improved!!!
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10922313886526264		[learning rate: 0.019231]
	Learning Rate: 0.0192313
	LOSS [training: 0.10922313886526264 | validation: 0.11689985625447606]
	TIME [epoch: 8.31 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0667341006557326		[learning rate: 0.019225]
	Learning Rate: 0.0192249
	LOSS [training: 0.0667341006557326 | validation: 0.07002765270904691]
	TIME [epoch: 8.31 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06807793198400895		[learning rate: 0.019218]
	Learning Rate: 0.0192185
	LOSS [training: 0.06807793198400895 | validation: 0.10233525667946722]
	TIME [epoch: 8.3 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09779209009424435		[learning rate: 0.019212]
	Learning Rate: 0.0192121
	LOSS [training: 0.09779209009424435 | validation: 0.05349449327615621]
	TIME [epoch: 8.3 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050867138494622		[learning rate: 0.019206]
	Learning Rate: 0.0192056
	LOSS [training: 0.050867138494622 | validation: 0.1005632353308508]
	TIME [epoch: 8.33 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07907626855357963		[learning rate: 0.019199]
	Learning Rate: 0.0191992
	LOSS [training: 0.07907626855357963 | validation: 0.1491495553141518]
	TIME [epoch: 8.3 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15222620813264992		[learning rate: 0.019193]
	Learning Rate: 0.0191927
	LOSS [training: 0.15222620813264992 | validation: 0.05022071511485711]
	TIME [epoch: 8.29 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05240740656568323		[learning rate: 0.019186]
	Learning Rate: 0.0191861
	LOSS [training: 0.05240740656568323 | validation: 0.08562458205463243]
	TIME [epoch: 8.31 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06098406140336344		[learning rate: 0.01918]
	Learning Rate: 0.0191796
	LOSS [training: 0.06098406140336344 | validation: 0.10126152001823663]
	TIME [epoch: 8.29 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059601020943264		[learning rate: 0.019173]
	Learning Rate: 0.019173
	LOSS [training: 0.059601020943264 | validation: 0.0365359295121236]
	TIME [epoch: 8.34 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09099675350198047		[learning rate: 0.019166]
	Learning Rate: 0.0191664
	LOSS [training: 0.09099675350198047 | validation: 0.11199631693879947]
	TIME [epoch: 8.3 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08483833855813805		[learning rate: 0.01916]
	Learning Rate: 0.0191598
	LOSS [training: 0.08483833855813805 | validation: 0.18250786187028578]
	TIME [epoch: 8.31 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08190000896916985		[learning rate: 0.019153]
	Learning Rate: 0.0191532
	LOSS [training: 0.08190000896916985 | validation: 0.046155475076245775]
	TIME [epoch: 8.3 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04837467858712434		[learning rate: 0.019146]
	Learning Rate: 0.0191465
	LOSS [training: 0.04837467858712434 | validation: 0.051106749841118376]
	TIME [epoch: 8.29 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07207216703156415		[learning rate: 0.01914]
	Learning Rate: 0.0191398
	LOSS [training: 0.07207216703156415 | validation: 0.0767019102997348]
	TIME [epoch: 8.3 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057972508369158		[learning rate: 0.019133]
	Learning Rate: 0.0191331
	LOSS [training: 0.057972508369158 | validation: 0.12205085168404725]
	TIME [epoch: 8.33 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07293540046165894		[learning rate: 0.019126]
	Learning Rate: 0.0191263
	LOSS [training: 0.07293540046165894 | validation: 0.06264290309885022]
	TIME [epoch: 8.3 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07815798489169962		[learning rate: 0.01912]
	Learning Rate: 0.0191196
	LOSS [training: 0.07815798489169962 | validation: 0.06391847712543972]
	TIME [epoch: 8.31 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03679320093073303		[learning rate: 0.019113]
	Learning Rate: 0.0191128
	LOSS [training: 0.03679320093073303 | validation: 0.03378468600096856]
	TIME [epoch: 8.29 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10525076049725446		[learning rate: 0.019106]
	Learning Rate: 0.019106
	LOSS [training: 0.10525076049725446 | validation: 0.1417771806314499]
	TIME [epoch: 8.29 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08058025344333193		[learning rate: 0.019099]
	Learning Rate: 0.0190991
	LOSS [training: 0.08058025344333193 | validation: 0.07966043546706071]
	TIME [epoch: 8.31 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06150484968054353		[learning rate: 0.019092]
	Learning Rate: 0.0190922
	LOSS [training: 0.06150484968054353 | validation: 0.09872144049893919]
	TIME [epoch: 8.31 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0711039360115932		[learning rate: 0.019085]
	Learning Rate: 0.0190853
	LOSS [training: 0.0711039360115932 | validation: 0.11759038071375272]
	TIME [epoch: 8.29 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06487476537016047		[learning rate: 0.019078]
	Learning Rate: 0.0190784
	LOSS [training: 0.06487476537016047 | validation: 0.07390923578331843]
	TIME [epoch: 8.3 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06824056520780113		[learning rate: 0.019071]
	Learning Rate: 0.0190715
	LOSS [training: 0.06824056520780113 | validation: 0.06363023427133442]
	TIME [epoch: 8.29 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06017932567189273		[learning rate: 0.019065]
	Learning Rate: 0.0190645
	LOSS [training: 0.06017932567189273 | validation: 0.0977774582365389]
	TIME [epoch: 8.29 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07752911060650848		[learning rate: 0.019058]
	Learning Rate: 0.0190575
	LOSS [training: 0.07752911060650848 | validation: 0.06003772565980188]
	TIME [epoch: 8.33 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044694317593987995		[learning rate: 0.019051]
	Learning Rate: 0.0190505
	LOSS [training: 0.044694317593987995 | validation: 0.1350181049491423]
	TIME [epoch: 8.31 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10448731567380751		[learning rate: 0.019043]
	Learning Rate: 0.0190435
	LOSS [training: 0.10448731567380751 | validation: 0.10079398170177106]
	TIME [epoch: 8.31 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04833189765728498		[learning rate: 0.019036]
	Learning Rate: 0.0190364
	LOSS [training: 0.04833189765728498 | validation: 0.05678623952287546]
	TIME [epoch: 8.3 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05141722411248015		[learning rate: 0.019029]
	Learning Rate: 0.0190293
	LOSS [training: 0.05141722411248015 | validation: 0.14192287578945406]
	TIME [epoch: 8.29 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1011331789317398		[learning rate: 0.019022]
	Learning Rate: 0.0190222
	LOSS [training: 0.1011331789317398 | validation: 0.17432147147029195]
	TIME [epoch: 8.32 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06645039192133222		[learning rate: 0.019015]
	Learning Rate: 0.019015
	LOSS [training: 0.06645039192133222 | validation: 0.03580748633031718]
	TIME [epoch: 8.32 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05847817349207034		[learning rate: 0.019008]
	Learning Rate: 0.0190079
	LOSS [training: 0.05847817349207034 | validation: 0.12659500398763546]
	TIME [epoch: 8.31 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06193214746105446		[learning rate: 0.019001]
	Learning Rate: 0.0190007
	LOSS [training: 0.06193214746105446 | validation: 0.03204272600065521]
	TIME [epoch: 8.29 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05930027685904741		[learning rate: 0.018993]
	Learning Rate: 0.0189935
	LOSS [training: 0.05930027685904741 | validation: 0.17396733204633427]
	TIME [epoch: 8.29 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0865136455033264		[learning rate: 0.018986]
	Learning Rate: 0.0189862
	LOSS [training: 0.0865136455033264 | validation: 0.025741174620803515]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_325.pth
	Model improved!!!
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02544594475530019		[learning rate: 0.018979]
	Learning Rate: 0.018979
	LOSS [training: 0.02544594475530019 | validation: 0.10511373114629616]
	TIME [epoch: 8.32 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10318032805336753		[learning rate: 0.018972]
	Learning Rate: 0.0189717
	LOSS [training: 0.10318032805336753 | validation: 0.1218222692625491]
	TIME [epoch: 8.29 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06725493212149695		[learning rate: 0.018964]
	Learning Rate: 0.0189644
	LOSS [training: 0.06725493212149695 | validation: 0.037920571812291914]
	TIME [epoch: 8.28 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025803736483358954		[learning rate: 0.018957]
	Learning Rate: 0.018957
	LOSS [training: 0.025803736483358954 | validation: 0.1548814212313344]
	TIME [epoch: 8.29 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12084770840997525		[learning rate: 0.01895]
	Learning Rate: 0.0189497
	LOSS [training: 0.12084770840997525 | validation: 0.07590036417109497]
	TIME [epoch: 8.28 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044382287983267606		[learning rate: 0.018942]
	Learning Rate: 0.0189423
	LOSS [training: 0.044382287983267606 | validation: 0.045433170611863236]
	TIME [epoch: 8.3 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056949082878119034		[learning rate: 0.018935]
	Learning Rate: 0.0189349
	LOSS [training: 0.056949082878119034 | validation: 0.15712448337359036]
	TIME [epoch: 8.32 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05992541206903565		[learning rate: 0.018927]
	Learning Rate: 0.0189274
	LOSS [training: 0.05992541206903565 | validation: 0.09177466642149523]
	TIME [epoch: 8.29 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0736234751284109		[learning rate: 0.01892]
	Learning Rate: 0.01892
	LOSS [training: 0.0736234751284109 | validation: 0.08058202705531832]
	TIME [epoch: 8.29 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07792320562417855		[learning rate: 0.018912]
	Learning Rate: 0.0189125
	LOSS [training: 0.07792320562417855 | validation: 0.053507182960472216]
	TIME [epoch: 8.28 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0221874737285855		[learning rate: 0.018905]
	Learning Rate: 0.018905
	LOSS [training: 0.0221874737285855 | validation: 0.051916868155220425]
	TIME [epoch: 8.28 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20921750409183304		[learning rate: 0.018897]
	Learning Rate: 0.0188974
	LOSS [training: 0.20921750409183304 | validation: 0.19153436012212763]
	TIME [epoch: 8.33 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07737695547943309		[learning rate: 0.01889]
	Learning Rate: 0.0188899
	LOSS [training: 0.07737695547943309 | validation: 0.048225423145745336]
	TIME [epoch: 8.31 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033368667570810265		[learning rate: 0.018882]
	Learning Rate: 0.0188823
	LOSS [training: 0.033368667570810265 | validation: 0.053340656932075556]
	TIME [epoch: 8.29 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12859245694230645		[learning rate: 0.018875]
	Learning Rate: 0.0188747
	LOSS [training: 0.12859245694230645 | validation: 0.04569542445830584]
	TIME [epoch: 8.31 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0493760196820708		[learning rate: 0.018867]
	Learning Rate: 0.0188671
	LOSS [training: 0.0493760196820708 | validation: 0.03729066012548724]
	TIME [epoch: 8.29 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04861878885454929		[learning rate: 0.018859]
	Learning Rate: 0.0188594
	LOSS [training: 0.04861878885454929 | validation: 0.08827558297291466]
	TIME [epoch: 8.29 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10735438839048146		[learning rate: 0.018852]
	Learning Rate: 0.0188517
	LOSS [training: 0.10735438839048146 | validation: 0.09703934717382373]
	TIME [epoch: 8.32 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04871197153123193		[learning rate: 0.018844]
	Learning Rate: 0.018844
	LOSS [training: 0.04871197153123193 | validation: 0.06906760508583551]
	TIME [epoch: 8.29 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038205315978704704		[learning rate: 0.018836]
	Learning Rate: 0.0188363
	LOSS [training: 0.038205315978704704 | validation: 0.09837467281365733]
	TIME [epoch: 8.29 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09080815319368896		[learning rate: 0.018829]
	Learning Rate: 0.0188286
	LOSS [training: 0.09080815319368896 | validation: 0.04243836589421342]
	TIME [epoch: 8.29 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03923661906059147		[learning rate: 0.018821]
	Learning Rate: 0.0188208
	LOSS [training: 0.03923661906059147 | validation: 0.04591833828710398]
	TIME [epoch: 8.29 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07343893233291919		[learning rate: 0.018813]
	Learning Rate: 0.018813
	LOSS [training: 0.07343893233291919 | validation: 0.08461805691390027]
	TIME [epoch: 8.33 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04830647145171254		[learning rate: 0.018805]
	Learning Rate: 0.0188052
	LOSS [training: 0.04830647145171254 | validation: 0.03297373642617464]
	TIME [epoch: 8.3 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07478905262505056		[learning rate: 0.018797]
	Learning Rate: 0.0187973
	LOSS [training: 0.07478905262505056 | validation: 0.09930318054361524]
	TIME [epoch: 8.29 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05574810867939855		[learning rate: 0.018789]
	Learning Rate: 0.0187894
	LOSS [training: 0.05574810867939855 | validation: 0.02879724387881832]
	TIME [epoch: 8.28 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029450419377624264		[learning rate: 0.018782]
	Learning Rate: 0.0187815
	LOSS [training: 0.029450419377624264 | validation: 0.1728708242147144]
	TIME [epoch: 8.29 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09199698089364566		[learning rate: 0.018774]
	Learning Rate: 0.0187736
	LOSS [training: 0.09199698089364566 | validation: 0.02261419503143789]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_353.pth
	Model improved!!!
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05737852972438406		[learning rate: 0.018766]
	Learning Rate: 0.0187657
	LOSS [training: 0.05737852972438406 | validation: 0.0594041332797376]
	TIME [epoch: 8.34 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048066479133857434		[learning rate: 0.018758]
	Learning Rate: 0.0187577
	LOSS [training: 0.048066479133857434 | validation: 0.022849130623393818]
	TIME [epoch: 8.3 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04319213980245518		[learning rate: 0.01875]
	Learning Rate: 0.0187497
	LOSS [training: 0.04319213980245518 | validation: 0.15311082336812146]
	TIME [epoch: 8.28 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07878598919585737		[learning rate: 0.018742]
	Learning Rate: 0.0187417
	LOSS [training: 0.07878598919585737 | validation: 0.02489961050246382]
	TIME [epoch: 8.28 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04072254909887843		[learning rate: 0.018734]
	Learning Rate: 0.0187337
	LOSS [training: 0.04072254909887843 | validation: 0.08709312785191109]
	TIME [epoch: 8.29 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06911996947946515		[learning rate: 0.018726]
	Learning Rate: 0.0187256
	LOSS [training: 0.06911996947946515 | validation: 0.05231865511335683]
	TIME [epoch: 8.32 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025527277610877485		[learning rate: 0.018718]
	Learning Rate: 0.0187175
	LOSS [training: 0.025527277610877485 | validation: 0.043321289035852376]
	TIME [epoch: 8.31 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06184244920702567		[learning rate: 0.018709]
	Learning Rate: 0.0187094
	LOSS [training: 0.06184244920702567 | validation: 0.08015643031917602]
	TIME [epoch: 8.29 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13992915365088981		[learning rate: 0.018701]
	Learning Rate: 0.0187013
	LOSS [training: 0.13992915365088981 | validation: 0.06064650118642941]
	TIME [epoch: 8.29 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045574999330140864		[learning rate: 0.018693]
	Learning Rate: 0.0186931
	LOSS [training: 0.045574999330140864 | validation: 0.029159118011479437]
	TIME [epoch: 8.29 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040528290720611926		[learning rate: 0.018685]
	Learning Rate: 0.0186849
	LOSS [training: 0.040528290720611926 | validation: 0.14092521208662315]
	TIME [epoch: 8.3 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10696276171059077		[learning rate: 0.018677]
	Learning Rate: 0.0186767
	LOSS [training: 0.10696276171059077 | validation: 0.07652542335457285]
	TIME [epoch: 8.34 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039535167645513555		[learning rate: 0.018668]
	Learning Rate: 0.0186685
	LOSS [training: 0.039535167645513555 | validation: 0.024800305885561022]
	TIME [epoch: 8.3 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04104454931225236		[learning rate: 0.01866]
	Learning Rate: 0.0186602
	LOSS [training: 0.04104454931225236 | validation: 0.13721023542561955]
	TIME [epoch: 8.29 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07505847492041307		[learning rate: 0.018652]
	Learning Rate: 0.018652
	LOSS [training: 0.07505847492041307 | validation: 0.10047610146963308]
	TIME [epoch: 8.28 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10056484927184883		[learning rate: 0.018644]
	Learning Rate: 0.0186437
	LOSS [training: 0.10056484927184883 | validation: 0.06736975416558318]
	TIME [epoch: 8.29 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047423086364391104		[learning rate: 0.018635]
	Learning Rate: 0.0186353
	LOSS [training: 0.047423086364391104 | validation: 0.04609569174186709]
	TIME [epoch: 8.32 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025353267107755185		[learning rate: 0.018627]
	Learning Rate: 0.018627
	LOSS [training: 0.025353267107755185 | validation: 0.020035257597413144]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_371.pth
	Model improved!!!
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044051964856308266		[learning rate: 0.018619]
	Learning Rate: 0.0186186
	LOSS [training: 0.044051964856308266 | validation: 0.34436018202619045]
	TIME [epoch: 8.36 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12920486757518415		[learning rate: 0.01861]
	Learning Rate: 0.0186102
	LOSS [training: 0.12920486757518415 | validation: 0.06737745874648618]
	TIME [epoch: 8.28 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07406872390496708		[learning rate: 0.018602]
	Learning Rate: 0.0186018
	LOSS [training: 0.07406872390496708 | validation: 0.1155706777354124]
	TIME [epoch: 8.28 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10975299164682155		[learning rate: 0.018593]
	Learning Rate: 0.0185934
	LOSS [training: 0.10975299164682155 | validation: 0.043751602746895574]
	TIME [epoch: 8.29 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03906494578407793		[learning rate: 0.018585]
	Learning Rate: 0.0185849
	LOSS [training: 0.03906494578407793 | validation: 0.03306014864019523]
	TIME [epoch: 8.33 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0774223449285899		[learning rate: 0.018576]
	Learning Rate: 0.0185764
	LOSS [training: 0.0774223449285899 | validation: 0.11961302704967217]
	TIME [epoch: 8.29 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06079663038094567		[learning rate: 0.018568]
	Learning Rate: 0.0185679
	LOSS [training: 0.06079663038094567 | validation: 0.03445702495375479]
	TIME [epoch: 8.28 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03949379506905857		[learning rate: 0.018559]
	Learning Rate: 0.0185594
	LOSS [training: 0.03949379506905857 | validation: 0.07448777490774375]
	TIME [epoch: 8.29 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07769456836110061		[learning rate: 0.018551]
	Learning Rate: 0.0185508
	LOSS [training: 0.07769456836110061 | validation: 0.1276763890170965]
	TIME [epoch: 8.3 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04909354860075539		[learning rate: 0.018542]
	Learning Rate: 0.0185422
	LOSS [training: 0.04909354860075539 | validation: 0.023642914059803313]
	TIME [epoch: 8.31 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02893901930797147		[learning rate: 0.018534]
	Learning Rate: 0.0185336
	LOSS [training: 0.02893901930797147 | validation: 0.1560745994760312]
	TIME [epoch: 8.32 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0927201696544548		[learning rate: 0.018525]
	Learning Rate: 0.018525
	LOSS [training: 0.0927201696544548 | validation: 0.08074899015782494]
	TIME [epoch: 8.29 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049140259871504534		[learning rate: 0.018516]
	Learning Rate: 0.0185163
	LOSS [training: 0.049140259871504534 | validation: 0.07096261816652077]
	TIME [epoch: 8.29 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03474394940644056		[learning rate: 0.018508]
	Learning Rate: 0.0185077
	LOSS [training: 0.03474394940644056 | validation: 0.05030895177300697]
	TIME [epoch: 8.28 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07993826516831673		[learning rate: 0.018499]
	Learning Rate: 0.018499
	LOSS [training: 0.07993826516831673 | validation: 0.12698812632288856]
	TIME [epoch: 8.3 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05106825071878624		[learning rate: 0.01849]
	Learning Rate: 0.0184902
	LOSS [training: 0.05106825071878624 | validation: 0.05082155993135361]
	TIME [epoch: 8.33 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05081443343895089		[learning rate: 0.018481]
	Learning Rate: 0.0184815
	LOSS [training: 0.05081443343895089 | validation: 0.1041585928925041]
	TIME [epoch: 8.29 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052144311855158165		[learning rate: 0.018473]
	Learning Rate: 0.0184727
	LOSS [training: 0.052144311855158165 | validation: 0.04620635319625088]
	TIME [epoch: 8.29 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03652890538020913		[learning rate: 0.018464]
	Learning Rate: 0.0184639
	LOSS [training: 0.03652890538020913 | validation: 0.04882855874124934]
	TIME [epoch: 8.29 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0851703237679678		[learning rate: 0.018455]
	Learning Rate: 0.0184551
	LOSS [training: 0.0851703237679678 | validation: 0.027786303010224382]
	TIME [epoch: 8.28 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03762022614415407		[learning rate: 0.018446]
	Learning Rate: 0.0184463
	LOSS [training: 0.03762022614415407 | validation: 0.10581068631435772]
	TIME [epoch: 8.31 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059835308535393046		[learning rate: 0.018437]
	Learning Rate: 0.0184374
	LOSS [training: 0.059835308535393046 | validation: 0.04104318253586778]
	TIME [epoch: 8.32 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06493158172316156		[learning rate: 0.018429]
	Learning Rate: 0.0184285
	LOSS [training: 0.06493158172316156 | validation: 0.11222471036083959]
	TIME [epoch: 8.28 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05621503839065116		[learning rate: 0.01842]
	Learning Rate: 0.0184196
	LOSS [training: 0.05621503839065116 | validation: 0.03805125335745674]
	TIME [epoch: 8.28 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026589602315586224		[learning rate: 0.018411]
	Learning Rate: 0.0184107
	LOSS [training: 0.026589602315586224 | validation: 0.028154521494389316]
	TIME [epoch: 8.29 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09880206289642779		[learning rate: 0.018402]
	Learning Rate: 0.0184017
	LOSS [training: 0.09880206289642779 | validation: 0.11220919160670653]
	TIME [epoch: 8.28 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04341572051845512		[learning rate: 0.018393]
	Learning Rate: 0.0183928
	LOSS [training: 0.04341572051845512 | validation: 0.02767075034404426]
	TIME [epoch: 8.33 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020207354771340662		[learning rate: 0.018384]
	Learning Rate: 0.0183838
	LOSS [training: 0.020207354771340662 | validation: 0.09666363323860527]
	TIME [epoch: 8.3 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09556238163199174		[learning rate: 0.018375]
	Learning Rate: 0.0183747
	LOSS [training: 0.09556238163199174 | validation: 0.03257204124682199]
	TIME [epoch: 8.29 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02788365714989668		[learning rate: 0.018366]
	Learning Rate: 0.0183657
	LOSS [training: 0.02788365714989668 | validation: 0.03192545196124065]
	TIME [epoch: 8.28 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037533787883590394		[learning rate: 0.018357]
	Learning Rate: 0.0183566
	LOSS [training: 0.037533787883590394 | validation: 0.06709855712793264]
	TIME [epoch: 8.3 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05728075581608695		[learning rate: 0.018348]
	Learning Rate: 0.0183475
	LOSS [training: 0.05728075581608695 | validation: 0.025157835576740513]
	TIME [epoch: 8.3 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04268171031275751		[learning rate: 0.018338]
	Learning Rate: 0.0183384
	LOSS [training: 0.04268171031275751 | validation: 0.09589763623871372]
	TIME [epoch: 8.33 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05918763357748658		[learning rate: 0.018329]
	Learning Rate: 0.0183293
	LOSS [training: 0.05918763357748658 | validation: 0.07472742681731762]
	TIME [epoch: 8.29 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035442349020935335		[learning rate: 0.01832]
	Learning Rate: 0.0183201
	LOSS [training: 0.035442349020935335 | validation: 0.07940343561413404]
	TIME [epoch: 8.29 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08121133981780529		[learning rate: 0.018311]
	Learning Rate: 0.0183109
	LOSS [training: 0.08121133981780529 | validation: 0.056554861077661334]
	TIME [epoch: 8.29 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03882604467334372		[learning rate: 0.018302]
	Learning Rate: 0.0183017
	LOSS [training: 0.03882604467334372 | validation: 0.11323121887313572]
	TIME [epoch: 8.29 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05132011790411611		[learning rate: 0.018293]
	Learning Rate: 0.0182925
	LOSS [training: 0.05132011790411611 | validation: 0.04250547987250052]
	TIME [epoch: 8.32 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08986358188653823		[learning rate: 0.018283]
	Learning Rate: 0.0182833
	LOSS [training: 0.08986358188653823 | validation: 0.17711353321333434]
	TIME [epoch: 8.3 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08526717617995018		[learning rate: 0.018274]
	Learning Rate: 0.018274
	LOSS [training: 0.08526717617995018 | validation: 0.020141914960880337]
	TIME [epoch: 8.29 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02703909935320384		[learning rate: 0.018265]
	Learning Rate: 0.0182647
	LOSS [training: 0.02703909935320384 | validation: 0.034306911195162784]
	TIME [epoch: 8.28 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06831729262586508		[learning rate: 0.018255]
	Learning Rate: 0.0182554
	LOSS [training: 0.06831729262586508 | validation: 0.08095867057305509]
	TIME [epoch: 8.28 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05011370842924863		[learning rate: 0.018246]
	Learning Rate: 0.018246
	LOSS [training: 0.05011370842924863 | validation: 0.06942101503924723]
	TIME [epoch: 8.29 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050504196555601295		[learning rate: 0.018237]
	Learning Rate: 0.0182367
	LOSS [training: 0.050504196555601295 | validation: 0.07495286041141642]
	TIME [epoch: 8.32 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05187492814533176		[learning rate: 0.018227]
	Learning Rate: 0.0182273
	LOSS [training: 0.05187492814533176 | validation: 0.04704243941002208]
	TIME [epoch: 8.29 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07256014628398395		[learning rate: 0.018218]
	Learning Rate: 0.0182179
	LOSS [training: 0.07256014628398395 | validation: 0.056568522634822524]
	TIME [epoch: 8.28 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04697080985420066		[learning rate: 0.018208]
	Learning Rate: 0.0182085
	LOSS [training: 0.04697080985420066 | validation: 0.03252830963503519]
	TIME [epoch: 8.3 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037307185574502896		[learning rate: 0.018199]
	Learning Rate: 0.018199
	LOSS [training: 0.037307185574502896 | validation: 0.056187027904334635]
	TIME [epoch: 8.29 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07645798124767425		[learning rate: 0.01819]
	Learning Rate: 0.0181895
	LOSS [training: 0.07645798124767425 | validation: 0.03366738582723089]
	TIME [epoch: 8.33 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045148603181436736		[learning rate: 0.01818]
	Learning Rate: 0.01818
	LOSS [training: 0.045148603181436736 | validation: 0.0711444432575799]
	TIME [epoch: 8.3 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05336511723004403		[learning rate: 0.018171]
	Learning Rate: 0.0181705
	LOSS [training: 0.05336511723004403 | validation: 0.023479577419915278]
	TIME [epoch: 8.28 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10201669087350272		[learning rate: 0.018161]
	Learning Rate: 0.018161
	LOSS [training: 0.10201669087350272 | validation: 0.2249134613410504]
	TIME [epoch: 8.29 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10105143204939623		[learning rate: 0.018151]
	Learning Rate: 0.0181514
	LOSS [training: 0.10105143204939623 | validation: 0.04174497872784129]
	TIME [epoch: 8.29 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07271319276657287		[learning rate: 0.018142]
	Learning Rate: 0.0181418
	LOSS [training: 0.07271319276657287 | validation: 0.039536793916984045]
	TIME [epoch: 8.29 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03384795221191911		[learning rate: 0.018132]
	Learning Rate: 0.0181322
	LOSS [training: 0.03384795221191911 | validation: 0.026874943535079986]
	TIME [epoch: 8.33 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061988245799150396		[learning rate: 0.018123]
	Learning Rate: 0.0181226
	LOSS [training: 0.061988245799150396 | validation: 0.08644671150405098]
	TIME [epoch: 8.29 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04314709294428938		[learning rate: 0.018113]
	Learning Rate: 0.0181129
	LOSS [training: 0.04314709294428938 | validation: 0.031181089441533263]
	TIME [epoch: 8.29 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025156884544306014		[learning rate: 0.018103]
	Learning Rate: 0.0181032
	LOSS [training: 0.025156884544306014 | validation: 0.10787914625630438]
	TIME [epoch: 8.29 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07704294662943523		[learning rate: 0.018094]
	Learning Rate: 0.0180936
	LOSS [training: 0.07704294662943523 | validation: 0.03653033368540631]
	TIME [epoch: 8.29 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023234289573749182		[learning rate: 0.018084]
	Learning Rate: 0.0180838
	LOSS [training: 0.023234289573749182 | validation: 0.062264157053318475]
	TIME [epoch: 8.32 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07784499987164067		[learning rate: 0.018074]
	Learning Rate: 0.0180741
	LOSS [training: 0.07784499987164067 | validation: 0.017266742956609512]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_432.pth
	Model improved!!!
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018959225812112786		[learning rate: 0.018064]
	Learning Rate: 0.0180643
	LOSS [training: 0.018959225812112786 | validation: 0.016789276893557865]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_433.pth
	Model improved!!!
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049365796521235454		[learning rate: 0.018055]
	Learning Rate: 0.0180545
	LOSS [training: 0.049365796521235454 | validation: 0.09440084830522147]
	TIME [epoch: 8.33 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03980184905626219		[learning rate: 0.018045]
	Learning Rate: 0.0180447
	LOSS [training: 0.03980184905626219 | validation: 0.053950757449910916]
	TIME [epoch: 8.3 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05602902799093747		[learning rate: 0.018035]
	Learning Rate: 0.0180349
	LOSS [training: 0.05602902799093747 | validation: 0.0519594239104727]
	TIME [epoch: 8.32 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05516159157690553		[learning rate: 0.018025]
	Learning Rate: 0.0180251
	LOSS [training: 0.05516159157690553 | validation: 0.05820108250689222]
	TIME [epoch: 8.34 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0591565547536373		[learning rate: 0.018015]
	Learning Rate: 0.0180152
	LOSS [training: 0.0591565547536373 | validation: 0.05661915791157666]
	TIME [epoch: 8.3 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026357723516960557		[learning rate: 0.018005]
	Learning Rate: 0.0180053
	LOSS [training: 0.026357723516960557 | validation: 0.022494578147061753]
	TIME [epoch: 8.29 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1083271352032833		[learning rate: 0.017995]
	Learning Rate: 0.0179954
	LOSS [training: 0.1083271352032833 | validation: 0.0877843284322544]
	TIME [epoch: 8.31 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039877716479767934		[learning rate: 0.017985]
	Learning Rate: 0.0179854
	LOSS [training: 0.039877716479767934 | validation: 0.023720138454465637]
	TIME [epoch: 8.29 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024929103817391992		[learning rate: 0.017975]
	Learning Rate: 0.0179755
	LOSS [training: 0.024929103817391992 | validation: 0.05927040299271412]
	TIME [epoch: 8.33 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06670809135950977		[learning rate: 0.017965]
	Learning Rate: 0.0179655
	LOSS [training: 0.06670809135950977 | validation: 0.05598661277812386]
	TIME [epoch: 8.31 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04812816866357232		[learning rate: 0.017955]
	Learning Rate: 0.0179555
	LOSS [training: 0.04812816866357232 | validation: 0.046562308675413874]
	TIME [epoch: 8.29 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0372847033256182		[learning rate: 0.017945]
	Learning Rate: 0.0179455
	LOSS [training: 0.0372847033256182 | validation: 0.13695095017824033]
	TIME [epoch: 8.29 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09652971225521018		[learning rate: 0.017935]
	Learning Rate: 0.0179354
	LOSS [training: 0.09652971225521018 | validation: 0.10349404074273788]
	TIME [epoch: 8.31 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04493603479336216		[learning rate: 0.017925]
	Learning Rate: 0.0179253
	LOSS [training: 0.04493603479336216 | validation: 0.038922815784687925]
	TIME [epoch: 8.32 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05252129709515371		[learning rate: 0.017915]
	Learning Rate: 0.0179152
	LOSS [training: 0.05252129709515371 | validation: 0.11667751336874436]
	TIME [epoch: 8.36 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056098910337697865		[learning rate: 0.017905]
	Learning Rate: 0.0179051
	LOSS [training: 0.056098910337697865 | validation: 0.02210675306218795]
	TIME [epoch: 8.3 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02801616168385607		[learning rate: 0.017895]
	Learning Rate: 0.017895
	LOSS [training: 0.02801616168385607 | validation: 0.058144016077159244]
	TIME [epoch: 8.33 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04565360900002675		[learning rate: 0.017885]
	Learning Rate: 0.0178848
	LOSS [training: 0.04565360900002675 | validation: 0.057254131820308876]
	TIME [epoch: 8.31 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0705791770906584		[learning rate: 0.017875]
	Learning Rate: 0.0178747
	LOSS [training: 0.0705791770906584 | validation: 0.031507504480742556]
	TIME [epoch: 8.3 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016360619635974294		[learning rate: 0.017864]
	Learning Rate: 0.0178645
	LOSS [training: 0.016360619635974294 | validation: 0.029758261138628898]
	TIME [epoch: 8.33 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06641188282187305		[learning rate: 0.017854]
	Learning Rate: 0.0178542
	LOSS [training: 0.06641188282187305 | validation: 0.06580206684252175]
	TIME [epoch: 8.32 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05715051216234221		[learning rate: 0.017844]
	Learning Rate: 0.017844
	LOSS [training: 0.05715051216234221 | validation: 0.06115203005892147]
	TIME [epoch: 8.3 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03400356051368923		[learning rate: 0.017834]
	Learning Rate: 0.0178337
	LOSS [training: 0.03400356051368923 | validation: 0.044507813155041626]
	TIME [epoch: 8.31 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031679016468614665		[learning rate: 0.017823]
	Learning Rate: 0.0178235
	LOSS [training: 0.031679016468614665 | validation: 0.211949170193255]
	TIME [epoch: 8.29 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1309763860558139		[learning rate: 0.017813]
	Learning Rate: 0.0178131
	LOSS [training: 0.1309763860558139 | validation: 0.04424524008343092]
	TIME [epoch: 8.29 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03958966472727647		[learning rate: 0.017803]
	Learning Rate: 0.0178028
	LOSS [training: 0.03958966472727647 | validation: 0.07643043287375165]
	TIME [epoch: 8.33 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05090359579810796		[learning rate: 0.017792]
	Learning Rate: 0.0177925
	LOSS [training: 0.05090359579810796 | validation: 0.019971608487067465]
	TIME [epoch: 8.28 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01233198618695889		[learning rate: 0.017782]
	Learning Rate: 0.0177821
	LOSS [training: 0.01233198618695889 | validation: 0.02781613112887693]
	TIME [epoch: 8.28 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06676406614115174		[learning rate: 0.017772]
	Learning Rate: 0.0177717
	LOSS [training: 0.06676406614115174 | validation: 0.11806137682194885]
	TIME [epoch: 8.28 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05086355255044745		[learning rate: 0.017761]
	Learning Rate: 0.0177613
	LOSS [training: 0.05086355255044745 | validation: 0.027135100997617897]
	TIME [epoch: 8.27 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04256710940905992		[learning rate: 0.017751]
	Learning Rate: 0.0177509
	LOSS [training: 0.04256710940905992 | validation: 0.0721747499778212]
	TIME [epoch: 8.3 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04342114569938315		[learning rate: 0.01774]
	Learning Rate: 0.0177404
	LOSS [training: 0.04342114569938315 | validation: 0.06121676269472509]
	TIME [epoch: 8.31 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04813852395412836		[learning rate: 0.01773]
	Learning Rate: 0.0177299
	LOSS [training: 0.04813852395412836 | validation: 0.07564565968683984]
	TIME [epoch: 8.28 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037029396161381206		[learning rate: 0.017719]
	Learning Rate: 0.0177194
	LOSS [training: 0.037029396161381206 | validation: 0.03601943366400534]
	TIME [epoch: 8.28 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058629232684221044		[learning rate: 0.017709]
	Learning Rate: 0.0177089
	LOSS [training: 0.058629232684221044 | validation: 0.2747374371173275]
	TIME [epoch: 8.28 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10478402872659094		[learning rate: 0.017698]
	Learning Rate: 0.0176984
	LOSS [training: 0.10478402872659094 | validation: 0.0870605756199544]
	TIME [epoch: 8.28 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060880432124225684		[learning rate: 0.017688]
	Learning Rate: 0.0176878
	LOSS [training: 0.060880432124225684 | validation: 0.04191468816768796]
	TIME [epoch: 8.32 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02445811800365763		[learning rate: 0.017677]
	Learning Rate: 0.0176772
	LOSS [training: 0.02445811800365763 | validation: 0.06065143886631069]
	TIME [epoch: 8.28 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07415510574125811		[learning rate: 0.017667]
	Learning Rate: 0.0176666
	LOSS [training: 0.07415510574125811 | validation: 0.06380633843125888]
	TIME [epoch: 8.27 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05104034821028515		[learning rate: 0.017656]
	Learning Rate: 0.017656
	LOSS [training: 0.05104034821028515 | validation: 0.018410344508686526]
	TIME [epoch: 8.28 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015896555382292628		[learning rate: 0.017645]
	Learning Rate: 0.0176454
	LOSS [training: 0.015896555382292628 | validation: 0.02340210323985212]
	TIME [epoch: 8.28 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03154935961504638		[learning rate: 0.017635]
	Learning Rate: 0.0176347
	LOSS [training: 0.03154935961504638 | validation: 0.019262022715601165]
	TIME [epoch: 8.29 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03381695038893286		[learning rate: 0.017624]
	Learning Rate: 0.017624
	LOSS [training: 0.03381695038893286 | validation: 0.12940355495638747]
	TIME [epoch: 8.32 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10119140586293526		[learning rate: 0.017613]
	Learning Rate: 0.0176133
	LOSS [training: 0.10119140586293526 | validation: 0.10079536121528276]
	TIME [epoch: 8.28 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04356300172868701		[learning rate: 0.017603]
	Learning Rate: 0.0176026
	LOSS [training: 0.04356300172868701 | validation: 0.02930908673682598]
	TIME [epoch: 8.27 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023601993618378808		[learning rate: 0.017592]
	Learning Rate: 0.0175918
	LOSS [training: 0.023601993618378808 | validation: 0.03238396621951435]
	TIME [epoch: 8.28 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06881417155873024		[learning rate: 0.017581]
	Learning Rate: 0.0175811
	LOSS [training: 0.06881417155873024 | validation: 0.09019939662387719]
	TIME [epoch: 8.27 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04588439660780397		[learning rate: 0.01757]
	Learning Rate: 0.0175703
	LOSS [training: 0.04588439660780397 | validation: 0.022772630487009622]
	TIME [epoch: 8.31 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027243618184497127		[learning rate: 0.017559]
	Learning Rate: 0.0175595
	LOSS [training: 0.027243618184497127 | validation: 0.03781724861716555]
	TIME [epoch: 8.29 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050539796488761515		[learning rate: 0.017549]
	Learning Rate: 0.0175486
	LOSS [training: 0.050539796488761515 | validation: 0.030731996785734714]
	TIME [epoch: 8.28 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03608544740726794		[learning rate: 0.017538]
	Learning Rate: 0.0175378
	LOSS [training: 0.03608544740726794 | validation: 0.030032821193331415]
	TIME [epoch: 8.28 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049244544468904715		[learning rate: 0.017527]
	Learning Rate: 0.0175269
	LOSS [training: 0.049244544468904715 | validation: 0.1788900160548299]
	TIME [epoch: 8.28 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07387728316970008		[learning rate: 0.017516]
	Learning Rate: 0.017516
	LOSS [training: 0.07387728316970008 | validation: 0.053095479750014024]
	TIME [epoch: 8.28 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17028045491405058		[learning rate: 0.017505]
	Learning Rate: 0.0175051
	LOSS [training: 0.17028045491405058 | validation: 0.13363347810618054]
	TIME [epoch: 8.32 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1097523745838553		[learning rate: 0.017494]
	Learning Rate: 0.0174942
	LOSS [training: 0.1097523745838553 | validation: 0.09103800309598024]
	TIME [epoch: 8.28 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09642889416791758		[learning rate: 0.017483]
	Learning Rate: 0.0174832
	LOSS [training: 0.09642889416791758 | validation: 0.06653210896144446]
	TIME [epoch: 8.28 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04785843044280593		[learning rate: 0.017472]
	Learning Rate: 0.0174722
	LOSS [training: 0.04785843044280593 | validation: 0.050003143479067744]
	TIME [epoch: 8.27 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055936542623256466		[learning rate: 0.017461]
	Learning Rate: 0.0174612
	LOSS [training: 0.055936542623256466 | validation: 0.15314392192661055]
	TIME [epoch: 8.28 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05322926748969675		[learning rate: 0.01745]
	Learning Rate: 0.0174502
	LOSS [training: 0.05322926748969675 | validation: 0.14864295883568468]
	TIME [epoch: 8.3 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14581491758396525		[learning rate: 0.017439]
	Learning Rate: 0.0174392
	LOSS [training: 0.14581491758396525 | validation: 0.09346247615869219]
	TIME [epoch: 8.3 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03477779270097749		[learning rate: 0.017428]
	Learning Rate: 0.0174281
	LOSS [training: 0.03477779270097749 | validation: 0.05246622592373597]
	TIME [epoch: 8.28 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04183585801662159		[learning rate: 0.017417]
	Learning Rate: 0.017417
	LOSS [training: 0.04183585801662159 | validation: 0.07018511723239837]
	TIME [epoch: 8.28 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054920541313829646		[learning rate: 0.017406]
	Learning Rate: 0.0174059
	LOSS [training: 0.054920541313829646 | validation: 0.03352089716343871]
	TIME [epoch: 8.28 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01459950292556804		[learning rate: 0.017395]
	Learning Rate: 0.0173948
	LOSS [training: 0.01459950292556804 | validation: 0.02138284218725691]
	TIME [epoch: 8.28 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021156119520871694		[learning rate: 0.017384]
	Learning Rate: 0.0173837
	LOSS [training: 0.021156119520871694 | validation: 0.06089744580004905]
	TIME [epoch: 8.32 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0773427636483508		[learning rate: 0.017373]
	Learning Rate: 0.0173725
	LOSS [training: 0.0773427636483508 | validation: 0.10420992451451913]
	TIME [epoch: 8.28 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04787227546421244		[learning rate: 0.017361]
	Learning Rate: 0.0173614
	LOSS [training: 0.04787227546421244 | validation: 0.04247658685812501]
	TIME [epoch: 8.28 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04269307720048162		[learning rate: 0.01735]
	Learning Rate: 0.0173502
	LOSS [training: 0.04269307720048162 | validation: 0.029536072420179277]
	TIME [epoch: 8.27 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026036717719713595		[learning rate: 0.017339]
	Learning Rate: 0.0173389
	LOSS [training: 0.026036717719713595 | validation: 0.08717171605334671]
	TIME [epoch: 8.28 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06902981411761222		[learning rate: 0.017328]
	Learning Rate: 0.0173277
	LOSS [training: 0.06902981411761222 | validation: 0.06428817877636372]
	TIME [epoch: 8.3 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030277953761556224		[learning rate: 0.017316]
	Learning Rate: 0.0173164
	LOSS [training: 0.030277953761556224 | validation: 0.035751057862577706]
	TIME [epoch: 8.3 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043429647011459245		[learning rate: 0.017305]
	Learning Rate: 0.0173052
	LOSS [training: 0.043429647011459245 | validation: 0.07335738560768969]
	TIME [epoch: 8.28 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0657113184652161		[learning rate: 0.017294]
	Learning Rate: 0.0172939
	LOSS [training: 0.0657113184652161 | validation: 0.03643036421416716]
	TIME [epoch: 8.27 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017357683828357964		[learning rate: 0.017283]
	Learning Rate: 0.0172826
	LOSS [training: 0.017357683828357964 | validation: 0.050718086604950884]
	TIME [epoch: 8.27 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09298786900141773		[learning rate: 0.017271]
	Learning Rate: 0.0172712
	LOSS [training: 0.09298786900141773 | validation: 0.0905661235633863]
	TIME [epoch: 8.27 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04745038542282667		[learning rate: 0.01726]
	Learning Rate: 0.0172599
	LOSS [training: 0.04745038542282667 | validation: 0.021048561841121066]
	TIME [epoch: 8.31 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021784486625892205		[learning rate: 0.017248]
	Learning Rate: 0.0172485
	LOSS [training: 0.021784486625892205 | validation: 0.041498950010000535]
	TIME [epoch: 8.28 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06092200720699667		[learning rate: 0.017237]
	Learning Rate: 0.0172371
	LOSS [training: 0.06092200720699667 | validation: 0.06634651033471486]
	TIME [epoch: 8.3 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0373805786777823		[learning rate: 0.017226]
	Learning Rate: 0.0172257
	LOSS [training: 0.0373805786777823 | validation: 0.0313986158500326]
	TIME [epoch: 8.27 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047111608687416054		[learning rate: 0.017214]
	Learning Rate: 0.0172142
	LOSS [training: 0.047111608687416054 | validation: 0.044834581138687796]
	TIME [epoch: 8.28 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03760189803158148		[learning rate: 0.017203]
	Learning Rate: 0.0172028
	LOSS [training: 0.03760189803158148 | validation: 0.023879291597152248]
	TIME [epoch: 8.28 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02849271259003265		[learning rate: 0.017191]
	Learning Rate: 0.0171913
	LOSS [training: 0.02849271259003265 | validation: 0.033830358252633856]
	TIME [epoch: 8.31 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05919817375864842		[learning rate: 0.01718]
	Learning Rate: 0.0171798
	LOSS [training: 0.05919817375864842 | validation: 0.09247814193868092]
	TIME [epoch: 8.28 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036937050558414314		[learning rate: 0.017168]
	Learning Rate: 0.0171683
	LOSS [training: 0.036937050558414314 | validation: 0.013417959172430636]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_517.pth
	Model improved!!!
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011428957365252426		[learning rate: 0.017157]
	Learning Rate: 0.0171567
	LOSS [training: 0.011428957365252426 | validation: 0.03054548767200467]
	TIME [epoch: 8.27 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03988309966772152		[learning rate: 0.017145]
	Learning Rate: 0.0171452
	LOSS [training: 0.03988309966772152 | validation: 0.18532736236850134]
	TIME [epoch: 8.27 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1127739159193262		[learning rate: 0.017134]
	Learning Rate: 0.0171336
	LOSS [training: 0.1127739159193262 | validation: 0.04159531726267093]
	TIME [epoch: 8.31 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027426840770622005		[learning rate: 0.017122]
	Learning Rate: 0.017122
	LOSS [training: 0.027426840770622005 | validation: 0.05268746337817598]
	TIME [epoch: 8.28 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05526893264383012		[learning rate: 0.01711]
	Learning Rate: 0.0171104
	LOSS [training: 0.05526893264383012 | validation: 0.07592607840892415]
	TIME [epoch: 8.27 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04345703827044575		[learning rate: 0.017099]
	Learning Rate: 0.0170988
	LOSS [training: 0.04345703827044575 | validation: 0.027154627474905383]
	TIME [epoch: 8.27 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025148208006064692		[learning rate: 0.017087]
	Learning Rate: 0.0170871
	LOSS [training: 0.025148208006064692 | validation: 0.030569448130919226]
	TIME [epoch: 8.27 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06399644524695794		[learning rate: 0.017075]
	Learning Rate: 0.0170755
	LOSS [training: 0.06399644524695794 | validation: 0.05214530894896137]
	TIME [epoch: 8.35 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026125258114690464		[learning rate: 0.017064]
	Learning Rate: 0.0170638
	LOSS [training: 0.026125258114690464 | validation: 0.017551633033948313]
	TIME [epoch: 8.31 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02423593326041031		[learning rate: 0.017052]
	Learning Rate: 0.0170521
	LOSS [training: 0.02423593326041031 | validation: 0.04682588095782349]
	TIME [epoch: 8.28 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04549284898334606		[learning rate: 0.01704]
	Learning Rate: 0.0170403
	LOSS [training: 0.04549284898334606 | validation: 0.05003916563389503]
	TIME [epoch: 8.28 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06629368427971442		[learning rate: 0.017029]
	Learning Rate: 0.0170286
	LOSS [training: 0.06629368427971442 | validation: 0.07925801294395482]
	TIME [epoch: 8.27 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027611938226855787		[learning rate: 0.017017]
	Learning Rate: 0.0170168
	LOSS [training: 0.027611938226855787 | validation: 0.0359493242797265]
	TIME [epoch: 8.27 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04098424717079549		[learning rate: 0.017005]
	Learning Rate: 0.017005
	LOSS [training: 0.04098424717079549 | validation: 0.03200581838902897]
	TIME [epoch: 8.3 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03333427291680628		[learning rate: 0.016993]
	Learning Rate: 0.0169932
	LOSS [training: 0.03333427291680628 | validation: 0.050041916381893065]
	TIME [epoch: 8.28 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04069755481384328		[learning rate: 0.016981]
	Learning Rate: 0.0169814
	LOSS [training: 0.04069755481384328 | validation: 0.08506797730365509]
	TIME [epoch: 8.28 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07075820973994655		[learning rate: 0.01697]
	Learning Rate: 0.0169695
	LOSS [training: 0.07075820973994655 | validation: 0.02288627656373879]
	TIME [epoch: 8.27 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017067953133190678		[learning rate: 0.016958]
	Learning Rate: 0.0169577
	LOSS [training: 0.017067953133190678 | validation: 0.0363216195494734]
	TIME [epoch: 8.27 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05461853349571748		[learning rate: 0.016946]
	Learning Rate: 0.0169458
	LOSS [training: 0.05461853349571748 | validation: 0.050350873249338915]
	TIME [epoch: 8.28 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05884705872649747		[learning rate: 0.016934]
	Learning Rate: 0.0169339
	LOSS [training: 0.05884705872649747 | validation: 0.0662217559589604]
	TIME [epoch: 8.31 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23920276149199604		[learning rate: 0.016922]
	Learning Rate: 0.016922
	LOSS [training: 0.23920276149199604 | validation: 0.16303219798576069]
	TIME [epoch: 8.27 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1792651485533004		[learning rate: 0.01691]
	Learning Rate: 0.01691
	LOSS [training: 0.1792651485533004 | validation: 0.10457049795762684]
	TIME [epoch: 8.27 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11424728110967151		[learning rate: 0.016898]
	Learning Rate: 0.0168981
	LOSS [training: 0.11424728110967151 | validation: 0.0998295456632573]
	TIME [epoch: 8.27 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09156730351587723		[learning rate: 0.016886]
	Learning Rate: 0.0168861
	LOSS [training: 0.09156730351587723 | validation: 0.057251869227852435]
	TIME [epoch: 8.27 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08169943552608266		[learning rate: 0.016874]
	Learning Rate: 0.0168741
	LOSS [training: 0.08169943552608266 | validation: 0.05323010250497218]
	TIME [epoch: 8.31 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04887796387999853		[learning rate: 0.016862]
	Learning Rate: 0.0168621
	LOSS [training: 0.04887796387999853 | validation: 0.07919673483093642]
	TIME [epoch: 8.28 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05816970880739202		[learning rate: 0.01685]
	Learning Rate: 0.0168501
	LOSS [training: 0.05816970880739202 | validation: 0.028445686112766502]
	TIME [epoch: 8.27 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04742107022302044		[learning rate: 0.016838]
	Learning Rate: 0.016838
	LOSS [training: 0.04742107022302044 | validation: 0.0655105622887052]
	TIME [epoch: 8.27 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04033288597828373		[learning rate: 0.016826]
	Learning Rate: 0.0168259
	LOSS [training: 0.04033288597828373 | validation: 0.02532140975234063]
	TIME [epoch: 8.27 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022642829435274337		[learning rate: 0.016814]
	Learning Rate: 0.0168138
	LOSS [training: 0.022642829435274337 | validation: 0.07677608162545779]
	TIME [epoch: 8.28 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08021862627325249		[learning rate: 0.016802]
	Learning Rate: 0.0168017
	LOSS [training: 0.08021862627325249 | validation: 0.18940158474250807]
	TIME [epoch: 8.31 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08189395421477708		[learning rate: 0.01679]
	Learning Rate: 0.0167896
	LOSS [training: 0.08189395421477708 | validation: 0.06925889091484028]
	TIME [epoch: 8.27 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03813417231111856		[learning rate: 0.016777]
	Learning Rate: 0.0167775
	LOSS [training: 0.03813417231111856 | validation: 0.03632314905936847]
	TIME [epoch: 8.27 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026859662702385975		[learning rate: 0.016765]
	Learning Rate: 0.0167653
	LOSS [training: 0.026859662702385975 | validation: 0.08794716723014126]
	TIME [epoch: 8.28 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06577414796236175		[learning rate: 0.016753]
	Learning Rate: 0.0167531
	LOSS [training: 0.06577414796236175 | validation: 0.020906803379549352]
	TIME [epoch: 8.27 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017131531432551007		[learning rate: 0.016741]
	Learning Rate: 0.0167409
	LOSS [training: 0.017131531432551007 | validation: 0.049742086458603674]
	TIME [epoch: 8.29 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06068632012600745		[learning rate: 0.016729]
	Learning Rate: 0.0167287
	LOSS [training: 0.06068632012600745 | validation: 0.02848642974878935]
	TIME [epoch: 8.3 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024670856319448296		[learning rate: 0.016716]
	Learning Rate: 0.0167165
	LOSS [training: 0.024670856319448296 | validation: 0.014393470211345242]
	TIME [epoch: 8.27 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017453178868016055		[learning rate: 0.016704]
	Learning Rate: 0.0167042
	LOSS [training: 0.017453178868016055 | validation: 0.049090098077915895]
	TIME [epoch: 8.27 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08540973387848856		[learning rate: 0.016692]
	Learning Rate: 0.0166919
	LOSS [training: 0.08540973387848856 | validation: 0.0717719483230462]
	TIME [epoch: 8.27 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029537778347583674		[learning rate: 0.01668]
	Learning Rate: 0.0166796
	LOSS [training: 0.029537778347583674 | validation: 0.013405491588342831]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_558.pth
	Model improved!!!
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014141740857614476		[learning rate: 0.016667]
	Learning Rate: 0.0166673
	LOSS [training: 0.014141740857614476 | validation: 0.1152299184669821]
	TIME [epoch: 8.31 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07480304549967297		[learning rate: 0.016655]
	Learning Rate: 0.016655
	LOSS [training: 0.07480304549967297 | validation: 0.05371723305260867]
	TIME [epoch: 8.27 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02426280147419541		[learning rate: 0.016643]
	Learning Rate: 0.0166427
	LOSS [training: 0.02426280147419541 | validation: 0.04073834987706751]
	TIME [epoch: 8.27 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045987016597940945		[learning rate: 0.01663]
	Learning Rate: 0.0166303
	LOSS [training: 0.045987016597940945 | validation: 0.08730751195180017]
	TIME [epoch: 8.27 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04148281860606779		[learning rate: 0.016618]
	Learning Rate: 0.0166179
	LOSS [training: 0.04148281860606779 | validation: 0.025110911861970515]
	TIME [epoch: 8.27 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043210630737005394		[learning rate: 0.016606]
	Learning Rate: 0.0166055
	LOSS [training: 0.043210630737005394 | validation: 0.02294857990659827]
	TIME [epoch: 8.28 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02955110988636285		[learning rate: 0.016593]
	Learning Rate: 0.0165931
	LOSS [training: 0.02955110988636285 | validation: 0.02574482816620781]
	TIME [epoch: 8.3 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05073270284608508		[learning rate: 0.016581]
	Learning Rate: 0.0165807
	LOSS [training: 0.05073270284608508 | validation: 0.12043728018934129]
	TIME [epoch: 8.27 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04067396669240402		[learning rate: 0.016568]
	Learning Rate: 0.0165682
	LOSS [training: 0.04067396669240402 | validation: 0.029774791088937623]
	TIME [epoch: 8.26 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019594494198404908		[learning rate: 0.016556]
	Learning Rate: 0.0165557
	LOSS [training: 0.019594494198404908 | validation: 0.04306123842499415]
	TIME [epoch: 8.27 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049635648113015664		[learning rate: 0.016543]
	Learning Rate: 0.0165432
	LOSS [training: 0.049635648113015664 | validation: 0.02048970722064747]
	TIME [epoch: 8.27 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04083168195675321		[learning rate: 0.016531]
	Learning Rate: 0.0165307
	LOSS [training: 0.04083168195675321 | validation: 0.15836765959343424]
	TIME [epoch: 8.3 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1162615891478024		[learning rate: 0.016518]
	Learning Rate: 0.0165182
	LOSS [training: 0.1162615891478024 | validation: 0.05102223464649652]
	TIME [epoch: 8.28 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03525744972281406		[learning rate: 0.016506]
	Learning Rate: 0.0165057
	LOSS [training: 0.03525744972281406 | validation: 0.036468812959216015]
	TIME [epoch: 8.27 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054907110912390034		[learning rate: 0.016493]
	Learning Rate: 0.0164931
	LOSS [training: 0.054907110912390034 | validation: 0.04121579012934507]
	TIME [epoch: 8.35 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02291796871416997		[learning rate: 0.016481]
	Learning Rate: 0.0164805
	LOSS [training: 0.02291796871416997 | validation: 0.013151250372793067]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_574.pth
	Model improved!!!
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018212648862881542		[learning rate: 0.016468]
	Learning Rate: 0.0164679
	LOSS [training: 0.018212648862881542 | validation: 0.022565884122305757]
	TIME [epoch: 8.28 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0533232632998908		[learning rate: 0.016455]
	Learning Rate: 0.0164553
	LOSS [training: 0.0533232632998908 | validation: 0.07041846333880722]
	TIME [epoch: 8.31 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032940391799682237		[learning rate: 0.016443]
	Learning Rate: 0.0164427
	LOSS [training: 0.032940391799682237 | validation: 0.01770373660500108]
	TIME [epoch: 8.27 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015435142113335295		[learning rate: 0.01643]
	Learning Rate: 0.01643
	LOSS [training: 0.015435142113335295 | validation: 0.03205332573879795]
	TIME [epoch: 8.27 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06671077264982073		[learning rate: 0.016417]
	Learning Rate: 0.0164173
	LOSS [training: 0.06671077264982073 | validation: 0.03764892748716478]
	TIME [epoch: 8.27 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03193226004371873		[learning rate: 0.016405]
	Learning Rate: 0.0164047
	LOSS [training: 0.03193226004371873 | validation: 0.053670739651704186]
	TIME [epoch: 8.27 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04607943847875277		[learning rate: 0.016392]
	Learning Rate: 0.016392
	LOSS [training: 0.04607943847875277 | validation: 0.02162481164103404]
	TIME [epoch: 8.31 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015621478308398197		[learning rate: 0.016379]
	Learning Rate: 0.0163792
	LOSS [training: 0.015621478308398197 | validation: 0.027423515100114412]
	TIME [epoch: 8.28 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037428028872159846		[learning rate: 0.016366]
	Learning Rate: 0.0163665
	LOSS [training: 0.037428028872159846 | validation: 0.10287404816765791]
	TIME [epoch: 8.27 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050624501779189666		[learning rate: 0.016354]
	Learning Rate: 0.0163537
	LOSS [training: 0.050624501779189666 | validation: 0.03304110681841927]
	TIME [epoch: 8.27 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034870714059481486		[learning rate: 0.016341]
	Learning Rate: 0.016341
	LOSS [training: 0.034870714059481486 | validation: 0.07459642999771218]
	TIME [epoch: 8.27 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04881789629598895		[learning rate: 0.016328]
	Learning Rate: 0.0163282
	LOSS [training: 0.04881789629598895 | validation: 0.10240766963398196]
	TIME [epoch: 8.28 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07482328900119554		[learning rate: 0.016315]
	Learning Rate: 0.0163154
	LOSS [training: 0.07482328900119554 | validation: 0.030267679271316954]
	TIME [epoch: 8.31 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024138216240283852		[learning rate: 0.016303]
	Learning Rate: 0.0163025
	LOSS [training: 0.024138216240283852 | validation: 0.016123601201416156]
	TIME [epoch: 8.27 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03439272326360504		[learning rate: 0.01629]
	Learning Rate: 0.0162897
	LOSS [training: 0.03439272326360504 | validation: 0.1685362441150965]
	TIME [epoch: 8.26 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09053273502206852		[learning rate: 0.016277]
	Learning Rate: 0.0162768
	LOSS [training: 0.09053273502206852 | validation: 0.04783104167740013]
	TIME [epoch: 8.27 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032341449269097114		[learning rate: 0.016264]
	Learning Rate: 0.016264
	LOSS [training: 0.032341449269097114 | validation: 0.05449722309994612]
	TIME [epoch: 8.27 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024617841747763918		[learning rate: 0.016251]
	Learning Rate: 0.0162511
	LOSS [training: 0.024617841747763918 | validation: 0.01286348549977743]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_592.pth
	Model improved!!!
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0224486124759228		[learning rate: 0.016238]
	Learning Rate: 0.0162382
	LOSS [training: 0.0224486124759228 | validation: 0.050031056226270215]
	TIME [epoch: 8.28 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06322979821875158		[learning rate: 0.016225]
	Learning Rate: 0.0162252
	LOSS [training: 0.06322979821875158 | validation: 0.026149816999310162]
	TIME [epoch: 8.27 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022769626838865804		[learning rate: 0.016212]
	Learning Rate: 0.0162123
	LOSS [training: 0.022769626838865804 | validation: 0.028196390584760506]
	TIME [epoch: 8.27 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03388067966687598		[learning rate: 0.016199]
	Learning Rate: 0.0161993
	LOSS [training: 0.03388067966687598 | validation: 0.05034507209960018]
	TIME [epoch: 8.27 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08725755981036688		[learning rate: 0.016186]
	Learning Rate: 0.0161864
	LOSS [training: 0.08725755981036688 | validation: 0.12629324827466165]
	TIME [epoch: 8.28 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09488185019285005		[learning rate: 0.016173]
	Learning Rate: 0.0161734
	LOSS [training: 0.09488185019285005 | validation: 0.06389498376255158]
	TIME [epoch: 8.31 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028483652994028934		[learning rate: 0.01616]
	Learning Rate: 0.0161603
	LOSS [training: 0.028483652994028934 | validation: 0.037065133147735546]
	TIME [epoch: 8.27 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020870219510581017		[learning rate: 0.016147]
	Learning Rate: 0.0161473
	LOSS [training: 0.020870219510581017 | validation: 0.024682482420120392]
	TIME [epoch: 8.27 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03625202254489464		[learning rate: 0.016134]
	Learning Rate: 0.0161343
	LOSS [training: 0.03625202254489464 | validation: 0.100289080146329]
	TIME [epoch: 8.28 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049693452498893106		[learning rate: 0.016121]
	Learning Rate: 0.0161212
	LOSS [training: 0.049693452498893106 | validation: 0.01998636181960308]
	TIME [epoch: 8.28 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02125751714805827		[learning rate: 0.016108]
	Learning Rate: 0.0161081
	LOSS [training: 0.02125751714805827 | validation: 0.05882211152435542]
	TIME [epoch: 8.32 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05183393082973276		[learning rate: 0.016095]
	Learning Rate: 0.016095
	LOSS [training: 0.05183393082973276 | validation: 0.0413081457399392]
	TIME [epoch: 8.3 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04036517629111061		[learning rate: 0.016082]
	Learning Rate: 0.0160819
	LOSS [training: 0.04036517629111061 | validation: 0.03284008002697763]
	TIME [epoch: 8.28 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023549710773231237		[learning rate: 0.016069]
	Learning Rate: 0.0160688
	LOSS [training: 0.023549710773231237 | validation: 0.01466393430296619]
	TIME [epoch: 8.28 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037434986493582095		[learning rate: 0.016056]
	Learning Rate: 0.0160556
	LOSS [training: 0.037434986493582095 | validation: 0.11004206328088856]
	TIME [epoch: 8.28 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05338283150533385		[learning rate: 0.016042]
	Learning Rate: 0.0160425
	LOSS [training: 0.05338283150533385 | validation: 0.033045774797961114]
	TIME [epoch: 8.3 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012665046116988252		[learning rate: 0.016029]
	Learning Rate: 0.0160293
	LOSS [training: 0.012665046116988252 | validation: 0.016580501858736597]
	TIME [epoch: 8.32 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04699924293970971		[learning rate: 0.016016]
	Learning Rate: 0.0160161
	LOSS [training: 0.04699924293970971 | validation: 0.039471899868847325]
	TIME [epoch: 8.28 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018723272516286592		[learning rate: 0.016003]
	Learning Rate: 0.0160029
	LOSS [training: 0.018723272516286592 | validation: 0.020208049548534855]
	TIME [epoch: 8.29 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0358017111266935		[learning rate: 0.01599]
	Learning Rate: 0.0159897
	LOSS [training: 0.0358017111266935 | validation: 0.1631304562979511]
	TIME [epoch: 8.29 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06403493232025677		[learning rate: 0.015976]
	Learning Rate: 0.0159764
	LOSS [training: 0.06403493232025677 | validation: 0.10555359024804174]
	TIME [epoch: 8.28 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04146167841916466		[learning rate: 0.015963]
	Learning Rate: 0.0159632
	LOSS [training: 0.04146167841916466 | validation: 0.02025442252466465]
	TIME [epoch: 8.33 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017263239490205865		[learning rate: 0.01595]
	Learning Rate: 0.0159499
	LOSS [training: 0.017263239490205865 | validation: 0.053992901558670967]
	TIME [epoch: 8.3 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03774399220552827		[learning rate: 0.015937]
	Learning Rate: 0.0159366
	LOSS [training: 0.03774399220552827 | validation: 0.11604959944559616]
	TIME [epoch: 8.28 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056246280396500405		[learning rate: 0.015923]
	Learning Rate: 0.0159233
	LOSS [training: 0.056246280396500405 | validation: 0.017396742629510614]
	TIME [epoch: 8.28 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027839094289168156		[learning rate: 0.01591]
	Learning Rate: 0.01591
	LOSS [training: 0.027839094289168156 | validation: 0.04964713809238511]
	TIME [epoch: 8.28 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044618604642879846		[learning rate: 0.015897]
	Learning Rate: 0.0158966
	LOSS [training: 0.044618604642879846 | validation: 0.017736198220327598]
	TIME [epoch: 8.28 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012753024762558947		[learning rate: 0.015883]
	Learning Rate: 0.0158833
	LOSS [training: 0.012753024762558947 | validation: 0.010469244082332182]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_620.pth
	Model improved!!!
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03289065191525533		[learning rate: 0.01587]
	Learning Rate: 0.0158699
	LOSS [training: 0.03289065191525533 | validation: 0.12443081579688021]
	TIME [epoch: 8.28 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039645468599997916		[learning rate: 0.015856]
	Learning Rate: 0.0158565
	LOSS [training: 0.039645468599997916 | validation: 0.053120511707131945]
	TIME [epoch: 8.28 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05248216491032215		[learning rate: 0.015843]
	Learning Rate: 0.0158431
	LOSS [training: 0.05248216491032215 | validation: 0.10166898129048435]
	TIME [epoch: 8.28 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06356575165428362		[learning rate: 0.01583]
	Learning Rate: 0.0158297
	LOSS [training: 0.06356575165428362 | validation: 0.1590976288133709]
	TIME [epoch: 8.28 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07002227734697143		[learning rate: 0.015816]
	Learning Rate: 0.0158162
	LOSS [training: 0.07002227734697143 | validation: 0.04692967701195086]
	TIME [epoch: 8.31 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034500416631129696		[learning rate: 0.015803]
	Learning Rate: 0.0158028
	LOSS [training: 0.034500416631129696 | validation: 0.0407411226872578]
	TIME [epoch: 8.3 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02157911265488152		[learning rate: 0.015789]
	Learning Rate: 0.0157893
	LOSS [training: 0.02157911265488152 | validation: 0.0524796214252571]
	TIME [epoch: 8.28 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045762605875688436		[learning rate: 0.015776]
	Learning Rate: 0.0157758
	LOSS [training: 0.045762605875688436 | validation: 0.05511899794970854]
	TIME [epoch: 8.28 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01653497313862483		[learning rate: 0.015762]
	Learning Rate: 0.0157623
	LOSS [training: 0.01653497313862483 | validation: 0.013050767845903768]
	TIME [epoch: 8.27 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04233112153531797		[learning rate: 0.015749]
	Learning Rate: 0.0157488
	LOSS [training: 0.04233112153531797 | validation: 0.08053530778356682]
	TIME [epoch: 8.28 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036254928864675635		[learning rate: 0.015735]
	Learning Rate: 0.0157353
	LOSS [training: 0.036254928864675635 | validation: 0.028869823495233676]
	TIME [epoch: 8.33 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03224275578280063		[learning rate: 0.015722]
	Learning Rate: 0.0157217
	LOSS [training: 0.03224275578280063 | validation: 0.046970782179367176]
	TIME [epoch: 8.28 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033694479862358045		[learning rate: 0.015708]
	Learning Rate: 0.0157082
	LOSS [training: 0.033694479862358045 | validation: 0.031266487440571714]
	TIME [epoch: 8.28 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02448274893290503		[learning rate: 0.015695]
	Learning Rate: 0.0156946
	LOSS [training: 0.02448274893290503 | validation: 0.030829312910168917]
	TIME [epoch: 8.28 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04494485186915437		[learning rate: 0.015681]
	Learning Rate: 0.015681
	LOSS [training: 0.04494485186915437 | validation: 0.030306207174897907]
	TIME [epoch: 8.27 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02003397072289338		[learning rate: 0.015667]
	Learning Rate: 0.0156674
	LOSS [training: 0.02003397072289338 | validation: 0.016809703581522926]
	TIME [epoch: 8.3 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019947186959532535		[learning rate: 0.015654]
	Learning Rate: 0.0156537
	LOSS [training: 0.019947186959532535 | validation: 0.06432552978433709]
	TIME [epoch: 8.3 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050887177362300064		[learning rate: 0.01564]
	Learning Rate: 0.0156401
	LOSS [training: 0.050887177362300064 | validation: 0.021157977549940914]
	TIME [epoch: 8.28 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022714469221012633		[learning rate: 0.015626]
	Learning Rate: 0.0156264
	LOSS [training: 0.022714469221012633 | validation: 0.009685052792273724]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_639.pth
	Model improved!!!
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016785143405325116		[learning rate: 0.015613]
	Learning Rate: 0.0156128
	LOSS [training: 0.016785143405325116 | validation: 0.11410220388906053]
	TIME [epoch: 8.27 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04164802456131271		[learning rate: 0.015599]
	Learning Rate: 0.0155991
	LOSS [training: 0.04164802456131271 | validation: 0.02305640940026684]
	TIME [epoch: 8.27 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016917941281451188		[learning rate: 0.015585]
	Learning Rate: 0.0155854
	LOSS [training: 0.016917941281451188 | validation: 0.027338961056110563]
	TIME [epoch: 8.32 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03758001772684829		[learning rate: 0.015572]
	Learning Rate: 0.0155717
	LOSS [training: 0.03758001772684829 | validation: 0.04773197304502512]
	TIME [epoch: 8.27 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031718344837951835		[learning rate: 0.015558]
	Learning Rate: 0.0155579
	LOSS [training: 0.031718344837951835 | validation: 0.041018912605483716]
	TIME [epoch: 8.27 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029928071284981893		[learning rate: 0.015544]
	Learning Rate: 0.0155442
	LOSS [training: 0.029928071284981893 | validation: 0.034245339430762134]
	TIME [epoch: 8.27 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02530327175910881		[learning rate: 0.01553]
	Learning Rate: 0.0155304
	LOSS [training: 0.02530327175910881 | validation: 0.011078518087702978]
	TIME [epoch: 8.27 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024051380257128135		[learning rate: 0.015517]
	Learning Rate: 0.0155166
	LOSS [training: 0.024051380257128135 | validation: 0.0638070930752854]
	TIME [epoch: 8.29 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05948618333708369		[learning rate: 0.015503]
	Learning Rate: 0.0155028
	LOSS [training: 0.05948618333708369 | validation: 0.05254560900937216]
	TIME [epoch: 8.3 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03760104076669967		[learning rate: 0.015489]
	Learning Rate: 0.015489
	LOSS [training: 0.03760104076669967 | validation: 0.03619034652109779]
	TIME [epoch: 8.27 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020973957877859342		[learning rate: 0.015475]
	Learning Rate: 0.0154752
	LOSS [training: 0.020973957877859342 | validation: 0.029486703817133704]
	TIME [epoch: 8.28 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04119055285224402		[learning rate: 0.015461]
	Learning Rate: 0.0154614
	LOSS [training: 0.04119055285224402 | validation: 0.16467847738966931]
	TIME [epoch: 8.28 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10538796605490536		[learning rate: 0.015448]
	Learning Rate: 0.0154475
	LOSS [training: 0.10538796605490536 | validation: 0.02601228974742581]
	TIME [epoch: 8.28 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02865509050734581		[learning rate: 0.015434]
	Learning Rate: 0.0154336
	LOSS [training: 0.02865509050734581 | validation: 0.01131550644546032]
	TIME [epoch: 8.31 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01408338833190612		[learning rate: 0.01542]
	Learning Rate: 0.0154198
	LOSS [training: 0.01408338833190612 | validation: 0.0203405940947751]
	TIME [epoch: 8.28 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047555546328794066		[learning rate: 0.015406]
	Learning Rate: 0.0154059
	LOSS [training: 0.047555546328794066 | validation: 0.048223673339524556]
	TIME [epoch: 8.28 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03748780750888765		[learning rate: 0.015392]
	Learning Rate: 0.0153919
	LOSS [training: 0.03748780750888765 | validation: 0.02582591468640592]
	TIME [epoch: 8.28 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032590510855591205		[learning rate: 0.015378]
	Learning Rate: 0.015378
	LOSS [training: 0.032590510855591205 | validation: 0.03374979340324327]
	TIME [epoch: 8.27 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03834174070703898		[learning rate: 0.015364]
	Learning Rate: 0.0153641
	LOSS [training: 0.03834174070703898 | validation: 0.05569303606781911]
	TIME [epoch: 8.28 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09021201122622777		[learning rate: 0.01535]
	Learning Rate: 0.0153501
	LOSS [training: 0.09021201122622777 | validation: 0.05567895884718704]
	TIME [epoch: 8.31 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02794186796994437		[learning rate: 0.015336]
	Learning Rate: 0.0153361
	LOSS [training: 0.02794186796994437 | validation: 0.017162860382739144]
	TIME [epoch: 8.27 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013434788411223635		[learning rate: 0.015322]
	Learning Rate: 0.0153222
	LOSS [training: 0.013434788411223635 | validation: 0.015822493668998718]
	TIME [epoch: 8.27 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05476808141364401		[learning rate: 0.015308]
	Learning Rate: 0.0153082
	LOSS [training: 0.05476808141364401 | validation: 0.04368475304513564]
	TIME [epoch: 8.27 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02275805142915066		[learning rate: 0.015294]
	Learning Rate: 0.0152941
	LOSS [training: 0.02275805142915066 | validation: 0.027110424928197607]
	TIME [epoch: 8.28 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020770224742448475		[learning rate: 0.01528]
	Learning Rate: 0.0152801
	LOSS [training: 0.020770224742448475 | validation: 0.01694535674413403]
	TIME [epoch: 8.31 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0479081207596649		[learning rate: 0.015266]
	Learning Rate: 0.0152661
	LOSS [training: 0.0479081207596649 | validation: 0.15775952168838364]
	TIME [epoch: 8.28 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2844388441204499		[learning rate: 0.015252]
	Learning Rate: 0.015252
	LOSS [training: 0.2844388441204499 | validation: 0.3858207586500199]
	TIME [epoch: 8.27 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11671444975939534		[learning rate: 0.015238]
	Learning Rate: 0.0152379
	LOSS [training: 0.11671444975939534 | validation: 0.03995939951175281]
	TIME [epoch: 8.27 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01612528378159934		[learning rate: 0.015224]
	Learning Rate: 0.0152238
	LOSS [training: 0.01612528378159934 | validation: 0.013130976050823482]
	TIME [epoch: 8.27 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008184767160117578		[learning rate: 0.01521]
	Learning Rate: 0.0152097
	LOSS [training: 0.008184767160117578 | validation: 0.01756768993475623]
	TIME [epoch: 8.28 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038141088719503904		[learning rate: 0.015196]
	Learning Rate: 0.0151956
	LOSS [training: 0.038141088719503904 | validation: 0.02231942879889348]
	TIME [epoch: 8.31 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013486354589194702		[learning rate: 0.015182]
	Learning Rate: 0.0151815
	LOSS [training: 0.013486354589194702 | validation: 0.02578697960907846]
	TIME [epoch: 8.27 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03313716843132254		[learning rate: 0.015167]
	Learning Rate: 0.0151674
	LOSS [training: 0.03313716843132254 | validation: 0.05764299077873692]
	TIME [epoch: 8.28 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06645431771201588		[learning rate: 0.015153]
	Learning Rate: 0.0151532
	LOSS [training: 0.06645431771201588 | validation: 0.07003263895031685]
	TIME [epoch: 8.28 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027325705768777596		[learning rate: 0.015139]
	Learning Rate: 0.015139
	LOSS [training: 0.027325705768777596 | validation: 0.03140252097770622]
	TIME [epoch: 8.27 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018872880725964655		[learning rate: 0.015125]
	Learning Rate: 0.0151248
	LOSS [training: 0.018872880725964655 | validation: 0.04159008828873846]
	TIME [epoch: 8.29 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03544834842737551		[learning rate: 0.015111]
	Learning Rate: 0.0151106
	LOSS [training: 0.03544834842737551 | validation: 0.05387392499107171]
	TIME [epoch: 8.29 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027595943381953213		[learning rate: 0.015096]
	Learning Rate: 0.0150964
	LOSS [training: 0.027595943381953213 | validation: 0.019463621489061618]
	TIME [epoch: 8.27 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01920343943416339		[learning rate: 0.015082]
	Learning Rate: 0.0150822
	LOSS [training: 0.01920343943416339 | validation: 0.08251872396184577]
	TIME [epoch: 8.27 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04935709675340825		[learning rate: 0.015068]
	Learning Rate: 0.015068
	LOSS [training: 0.04935709675340825 | validation: 0.036445618433223415]
	TIME [epoch: 8.28 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02346723115185603		[learning rate: 0.015054]
	Learning Rate: 0.0150537
	LOSS [training: 0.02346723115185603 | validation: 0.024967039960728462]
	TIME [epoch: 8.28 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040823706252063635		[learning rate: 0.015039]
	Learning Rate: 0.0150394
	LOSS [training: 0.040823706252063635 | validation: 0.0587523299224185]
	TIME [epoch: 8.32 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021386871143836046		[learning rate: 0.015025]
	Learning Rate: 0.0150251
	LOSS [training: 0.021386871143836046 | validation: 0.012200649319644409]
	TIME [epoch: 8.27 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01314394188200368		[learning rate: 0.015011]
	Learning Rate: 0.0150108
	LOSS [training: 0.01314394188200368 | validation: 0.08429292807597877]
	TIME [epoch: 8.27 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07873334632591639		[learning rate: 0.014997]
	Learning Rate: 0.0149965
	LOSS [training: 0.07873334632591639 | validation: 0.03992655062543206]
	TIME [epoch: 8.28 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020221629587153685		[learning rate: 0.014982]
	Learning Rate: 0.0149822
	LOSS [training: 0.020221629587153685 | validation: 0.00970122570315092]
	TIME [epoch: 8.28 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006979508508815266		[learning rate: 0.014968]
	Learning Rate: 0.0149679
	LOSS [training: 0.006979508508815266 | validation: 0.026154855186868456]
	TIME [epoch: 8.29 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05082597985625038		[learning rate: 0.014954]
	Learning Rate: 0.0149535
	LOSS [training: 0.05082597985625038 | validation: 0.039571191890675005]
	TIME [epoch: 8.3 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029887930067887338		[learning rate: 0.014939]
	Learning Rate: 0.0149392
	LOSS [training: 0.029887930067887338 | validation: 0.08745492395439405]
	TIME [epoch: 8.27 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04052459178609773		[learning rate: 0.014925]
	Learning Rate: 0.0149248
	LOSS [training: 0.04052459178609773 | validation: 0.03302191597064077]
	TIME [epoch: 8.27 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017895759924072923		[learning rate: 0.01491]
	Learning Rate: 0.0149104
	LOSS [training: 0.017895759924072923 | validation: 0.02781744220022925]
	TIME [epoch: 8.28 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022398281244077844		[learning rate: 0.014896]
	Learning Rate: 0.014896
	LOSS [training: 0.022398281244077844 | validation: 0.048360397354148536]
	TIME [epoch: 8.28 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05897401595542696		[learning rate: 0.014882]
	Learning Rate: 0.0148816
	LOSS [training: 0.05897401595542696 | validation: 0.05244864809395565]
	TIME [epoch: 8.31 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031229416424027597		[learning rate: 0.014867]
	Learning Rate: 0.0148671
	LOSS [training: 0.031229416424027597 | validation: 0.028971105229857085]
	TIME [epoch: 8.28 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018079083063491104		[learning rate: 0.014853]
	Learning Rate: 0.0148527
	LOSS [training: 0.018079083063491104 | validation: 0.011284651157536508]
	TIME [epoch: 8.27 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006931434923597398		[learning rate: 0.014838]
	Learning Rate: 0.0148382
	LOSS [training: 0.006931434923597398 | validation: 0.010473291622042271]
	TIME [epoch: 8.27 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052399556232772454		[learning rate: 0.014824]
	Learning Rate: 0.0148237
	LOSS [training: 0.052399556232772454 | validation: 0.04905983570108009]
	TIME [epoch: 8.28 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0617949163800649		[learning rate: 0.014809]
	Learning Rate: 0.0148093
	LOSS [training: 0.0617949163800649 | validation: 0.0350298846877527]
	TIME [epoch: 8.28 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03542345175673569		[learning rate: 0.014795]
	Learning Rate: 0.0147948
	LOSS [training: 0.03542345175673569 | validation: 0.03317124051443837]
	TIME [epoch: 8.3 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020546725563369457		[learning rate: 0.01478]
	Learning Rate: 0.0147803
	LOSS [training: 0.020546725563369457 | validation: 0.010821076221842248]
	TIME [epoch: 8.27 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01696578350928856		[learning rate: 0.014766]
	Learning Rate: 0.0147657
	LOSS [training: 0.01696578350928856 | validation: 0.13931202485007016]
	TIME [epoch: 8.27 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07761963113525729		[learning rate: 0.014751]
	Learning Rate: 0.0147512
	LOSS [training: 0.07761963113525729 | validation: 0.04905279092976926]
	TIME [epoch: 8.27 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02720258277914707		[learning rate: 0.014737]
	Learning Rate: 0.0147366
	LOSS [training: 0.02720258277914707 | validation: 0.023776063626595415]
	TIME [epoch: 8.28 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01878554714878001		[learning rate: 0.014722]
	Learning Rate: 0.0147221
	LOSS [training: 0.01878554714878001 | validation: 0.035429717903726836]
	TIME [epoch: 8.31 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03708113586573811		[learning rate: 0.014707]
	Learning Rate: 0.0147075
	LOSS [training: 0.03708113586573811 | validation: 0.019630080920733692]
	TIME [epoch: 8.28 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012077342829649736		[learning rate: 0.014693]
	Learning Rate: 0.0146929
	LOSS [training: 0.012077342829649736 | validation: 0.026293280373263478]
	TIME [epoch: 8.27 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05459521822947934		[learning rate: 0.014678]
	Learning Rate: 0.0146783
	LOSS [training: 0.05459521822947934 | validation: 0.018524494000742957]
	TIME [epoch: 8.27 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017691468834255628		[learning rate: 0.014664]
	Learning Rate: 0.0146637
	LOSS [training: 0.017691468834255628 | validation: 0.02042770640510224]
	TIME [epoch: 8.27 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028108645866973116		[learning rate: 0.014649]
	Learning Rate: 0.0146491
	LOSS [training: 0.028108645866973116 | validation: 0.03327045770585365]
	TIME [epoch: 8.27 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03721182355711304		[learning rate: 0.014634]
	Learning Rate: 0.0146344
	LOSS [training: 0.03721182355711304 | validation: 0.03949699945140986]
	TIME [epoch: 8.31 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017968084207543863		[learning rate: 0.01462]
	Learning Rate: 0.0146198
	LOSS [training: 0.017968084207543863 | validation: 0.01637809605353157]
	TIME [epoch: 8.27 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025853557640814213		[learning rate: 0.014605]
	Learning Rate: 0.0146051
	LOSS [training: 0.025853557640814213 | validation: 0.07550759655261106]
	TIME [epoch: 8.27 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04502341730229069		[learning rate: 0.01459]
	Learning Rate: 0.0145904
	LOSS [training: 0.04502341730229069 | validation: 0.04563081520283328]
	TIME [epoch: 8.27 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01825558341515177		[learning rate: 0.014576]
	Learning Rate: 0.0145757
	LOSS [training: 0.01825558341515177 | validation: 0.00932331655488956]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_713.pth
	Model improved!!!
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012612634323911435		[learning rate: 0.014561]
	Learning Rate: 0.014561
	LOSS [training: 0.012612634323911435 | validation: 0.05106719482968047]
	TIME [epoch: 8.3 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04657023443240265		[learning rate: 0.014546]
	Learning Rate: 0.0145463
	LOSS [training: 0.04657023443240265 | validation: 0.040935677172035764]
	TIME [epoch: 8.28 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02521683116323935		[learning rate: 0.014532]
	Learning Rate: 0.0145316
	LOSS [training: 0.02521683116323935 | validation: 0.014959710752970356]
	TIME [epoch: 8.27 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03003133320406938		[learning rate: 0.014517]
	Learning Rate: 0.0145168
	LOSS [training: 0.03003133320406938 | validation: 0.03529495075686398]
	TIME [epoch: 8.27 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023650236766138255		[learning rate: 0.014502]
	Learning Rate: 0.0145021
	LOSS [training: 0.023650236766138255 | validation: 0.020335946980764436]
	TIME [epoch: 8.27 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014371082715128148		[learning rate: 0.014487]
	Learning Rate: 0.0144873
	LOSS [training: 0.014371082715128148 | validation: 0.07229958222853962]
	TIME [epoch: 8.27 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06204281175465029		[learning rate: 0.014473]
	Learning Rate: 0.0144726
	LOSS [training: 0.06204281175465029 | validation: 0.049590986785975774]
	TIME [epoch: 8.31 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024473184086739184		[learning rate: 0.014458]
	Learning Rate: 0.0144578
	LOSS [training: 0.024473184086739184 | validation: 0.03639018866790914]
	TIME [epoch: 8.27 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024003362999593394		[learning rate: 0.014443]
	Learning Rate: 0.014443
	LOSS [training: 0.024003362999593394 | validation: 0.027514181352828716]
	TIME [epoch: 8.27 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01554844526401044		[learning rate: 0.014428]
	Learning Rate: 0.0144281
	LOSS [training: 0.01554844526401044 | validation: 0.028506018559338285]
	TIME [epoch: 8.27 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050063005329583896		[learning rate: 0.014413]
	Learning Rate: 0.0144133
	LOSS [training: 0.050063005329583896 | validation: 0.045809875585867535]
	TIME [epoch: 8.27 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025132955947969524		[learning rate: 0.014398]
	Learning Rate: 0.0143985
	LOSS [training: 0.025132955947969524 | validation: 0.030869275912911328]
	TIME [epoch: 8.3 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02328817271569314		[learning rate: 0.014384]
	Learning Rate: 0.0143836
	LOSS [training: 0.02328817271569314 | validation: 0.017365846155632157]
	TIME [epoch: 8.27 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016922198833703602		[learning rate: 0.014369]
	Learning Rate: 0.0143688
	LOSS [training: 0.016922198833703602 | validation: 0.056840407598821974]
	TIME [epoch: 8.26 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03859435117436885		[learning rate: 0.014354]
	Learning Rate: 0.0143539
	LOSS [training: 0.03859435117436885 | validation: 0.012529295270848438]
	TIME [epoch: 8.27 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016060145026008176		[learning rate: 0.014339]
	Learning Rate: 0.014339
	LOSS [training: 0.016060145026008176 | validation: 0.0347446835357427]
	TIME [epoch: 8.26 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02432984737099099		[learning rate: 0.014324]
	Learning Rate: 0.0143241
	LOSS [training: 0.02432984737099099 | validation: 0.02792400327276988]
	TIME [epoch: 8.26 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03524384675420458		[learning rate: 0.014309]
	Learning Rate: 0.0143092
	LOSS [training: 0.03524384675420458 | validation: 0.03205386591827149]
	TIME [epoch: 8.3 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01695769083237726		[learning rate: 0.014294]
	Learning Rate: 0.0142943
	LOSS [training: 0.01695769083237726 | validation: 0.019562433481885858]
	TIME [epoch: 8.26 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03471111542891426		[learning rate: 0.014279]
	Learning Rate: 0.0142793
	LOSS [training: 0.03471111542891426 | validation: 0.02282705694322075]
	TIME [epoch: 8.26 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019101412071661418		[learning rate: 0.014264]
	Learning Rate: 0.0142644
	LOSS [training: 0.019101412071661418 | validation: 0.019023418834284985]
	TIME [epoch: 8.26 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033762336481247435		[learning rate: 0.014249]
	Learning Rate: 0.0142494
	LOSS [training: 0.033762336481247435 | validation: 0.04337816215461565]
	TIME [epoch: 8.26 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022678199659835703		[learning rate: 0.014234]
	Learning Rate: 0.0142345
	LOSS [training: 0.022678199659835703 | validation: 0.022741770938487765]
	TIME [epoch: 8.28 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028749954835139375		[learning rate: 0.014219]
	Learning Rate: 0.0142195
	LOSS [training: 0.028749954835139375 | validation: 0.03694984698910205]
	TIME [epoch: 8.28 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019905122929609168		[learning rate: 0.014205]
	Learning Rate: 0.0142045
	LOSS [training: 0.019905122929609168 | validation: 0.026121670650401847]
	TIME [epoch: 8.26 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019188063531262255		[learning rate: 0.01419]
	Learning Rate: 0.0141895
	LOSS [training: 0.019188063531262255 | validation: 0.022652568810204173]
	TIME [epoch: 8.27 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02710233448742644		[learning rate: 0.014174]
	Learning Rate: 0.0141745
	LOSS [training: 0.02710233448742644 | validation: 0.09578233290473193]
	TIME [epoch: 8.25 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04755985033234618		[learning rate: 0.014159]
	Learning Rate: 0.0141595
	LOSS [training: 0.04755985033234618 | validation: 0.04251439287241439]
	TIME [epoch: 8.26 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021878437885638053		[learning rate: 0.014144]
	Learning Rate: 0.0141444
	LOSS [training: 0.021878437885638053 | validation: 0.022938904620492247]
	TIME [epoch: 8.29 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013253353458968768		[learning rate: 0.014129]
	Learning Rate: 0.0141294
	LOSS [training: 0.013253353458968768 | validation: 0.018735821505718758]
	TIME [epoch: 8.26 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024266848016494372		[learning rate: 0.014114]
	Learning Rate: 0.0141143
	LOSS [training: 0.024266848016494372 | validation: 0.029670005503110913]
	TIME [epoch: 8.25 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013510235795067783		[learning rate: 0.014099]
	Learning Rate: 0.0140992
	LOSS [training: 0.013510235795067783 | validation: 0.017615288820805892]
	TIME [epoch: 8.25 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024354559955233168		[learning rate: 0.014084]
	Learning Rate: 0.0140842
	LOSS [training: 0.024354559955233168 | validation: 0.0469512157497505]
	TIME [epoch: 8.26 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05138997897158835		[learning rate: 0.014069]
	Learning Rate: 0.0140691
	LOSS [training: 0.05138997897158835 | validation: 0.0408883843155813]
	TIME [epoch: 8.27 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02904221504113169		[learning rate: 0.014054]
	Learning Rate: 0.014054
	LOSS [training: 0.02904221504113169 | validation: 0.056852160142595254]
	TIME [epoch: 8.29 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033417070807378345		[learning rate: 0.014039]
	Learning Rate: 0.0140389
	LOSS [training: 0.033417070807378345 | validation: 0.03848722122042214]
	TIME [epoch: 8.26 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017782032705087512		[learning rate: 0.014024]
	Learning Rate: 0.0140237
	LOSS [training: 0.017782032705087512 | validation: 0.03696620970244136]
	TIME [epoch: 8.25 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03762609894180242		[learning rate: 0.014009]
	Learning Rate: 0.0140086
	LOSS [training: 0.03762609894180242 | validation: 0.0331292928654028]
	TIME [epoch: 8.26 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02317374821967866		[learning rate: 0.013993]
	Learning Rate: 0.0139934
	LOSS [training: 0.02317374821967866 | validation: 0.02093108167309135]
	TIME [epoch: 8.26 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015619100987945602		[learning rate: 0.013978]
	Learning Rate: 0.0139783
	LOSS [training: 0.015619100987945602 | validation: 0.018302160094718665]
	TIME [epoch: 8.29 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024962118050327248		[learning rate: 0.013963]
	Learning Rate: 0.0139631
	LOSS [training: 0.024962118050327248 | validation: 0.04250879420274571]
	TIME [epoch: 8.27 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044551729237537745		[learning rate: 0.013948]
	Learning Rate: 0.0139479
	LOSS [training: 0.044551729237537745 | validation: 0.037645960292118516]
	TIME [epoch: 8.26 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020418404666046167		[learning rate: 0.013933]
	Learning Rate: 0.0139327
	LOSS [training: 0.020418404666046167 | validation: 0.014022510888317387]
	TIME [epoch: 8.26 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021560615552564506		[learning rate: 0.013918]
	Learning Rate: 0.0139175
	LOSS [training: 0.021560615552564506 | validation: 0.035054629712985536]
	TIME [epoch: 8.26 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024240893610850113		[learning rate: 0.013902]
	Learning Rate: 0.0139023
	LOSS [training: 0.024240893610850113 | validation: 0.05212745999337014]
	TIME [epoch: 8.26 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028042892304717338		[learning rate: 0.013887]
	Learning Rate: 0.0138871
	LOSS [training: 0.028042892304717338 | validation: 0.0335452874091632]
	TIME [epoch: 8.29 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02239673428376454		[learning rate: 0.013872]
	Learning Rate: 0.0138719
	LOSS [training: 0.02239673428376454 | validation: 0.0576389886610309]
	TIME [epoch: 8.26 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02886311727377781		[learning rate: 0.013857]
	Learning Rate: 0.0138566
	LOSS [training: 0.02886311727377781 | validation: 0.029126751366271977]
	TIME [epoch: 8.26 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022808045022308432		[learning rate: 0.013841]
	Learning Rate: 0.0138414
	LOSS [training: 0.022808045022308432 | validation: 0.020473852677529197]
	TIME [epoch: 8.26 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019809758264539915		[learning rate: 0.013826]
	Learning Rate: 0.0138261
	LOSS [training: 0.019809758264539915 | validation: 0.0141838319201266]
	TIME [epoch: 8.26 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015532080211413625		[learning rate: 0.013811]
	Learning Rate: 0.0138108
	LOSS [training: 0.015532080211413625 | validation: 0.012325155736191818]
	TIME [epoch: 8.29 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00822635286510336		[learning rate: 0.013796]
	Learning Rate: 0.0137955
	LOSS [training: 0.00822635286510336 | validation: 0.024215557182994098]
	TIME [epoch: 8.26 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05068807319813524		[learning rate: 0.01378]
	Learning Rate: 0.0137802
	LOSS [training: 0.05068807319813524 | validation: 0.06824903030380312]
	TIME [epoch: 8.26 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021191054558829917		[learning rate: 0.013765]
	Learning Rate: 0.0137649
	LOSS [training: 0.021191054558829917 | validation: 0.011024284577059021]
	TIME [epoch: 8.26 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01844749870178454		[learning rate: 0.01375]
	Learning Rate: 0.0137496
	LOSS [training: 0.01844749870178454 | validation: 0.04992819600430194]
	TIME [epoch: 8.26 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02198346650336172		[learning rate: 0.013734]
	Learning Rate: 0.0137343
	LOSS [training: 0.02198346650336172 | validation: 0.019858318456006996]
	TIME [epoch: 8.26 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03381847345307359		[learning rate: 0.013719]
	Learning Rate: 0.013719
	LOSS [training: 0.03381847345307359 | validation: 0.08932199303325453]
	TIME [epoch: 8.3 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04022213961517453		[learning rate: 0.013704]
	Learning Rate: 0.0137036
	LOSS [training: 0.04022213961517453 | validation: 0.024702593191904012]
	TIME [epoch: 8.26 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02226236017733423		[learning rate: 0.013688]
	Learning Rate: 0.0136882
	LOSS [training: 0.02226236017733423 | validation: 0.06870107557595297]
	TIME [epoch: 8.26 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03437133479118394		[learning rate: 0.013673]
	Learning Rate: 0.0136729
	LOSS [training: 0.03437133479118394 | validation: 0.02243771263562505]
	TIME [epoch: 8.26 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015875459102126118		[learning rate: 0.013657]
	Learning Rate: 0.0136575
	LOSS [training: 0.015875459102126118 | validation: 0.022234447960171856]
	TIME [epoch: 8.26 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018461943486844528		[learning rate: 0.013642]
	Learning Rate: 0.0136421
	LOSS [training: 0.018461943486844528 | validation: 0.03279380798340867]
	TIME [epoch: 8.28 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027756841672512987		[learning rate: 0.013627]
	Learning Rate: 0.0136267
	LOSS [training: 0.027756841672512987 | validation: 0.06704206523730936]
	TIME [epoch: 8.29 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019332758935427963		[learning rate: 0.013611]
	Learning Rate: 0.0136113
	LOSS [training: 0.019332758935427963 | validation: 0.02318361527268429]
	TIME [epoch: 8.26 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01852758917970796		[learning rate: 0.013596]
	Learning Rate: 0.0135959
	LOSS [training: 0.01852758917970796 | validation: 0.03362701109944931]
	TIME [epoch: 8.27 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03741766989842861		[learning rate: 0.01358]
	Learning Rate: 0.0135805
	LOSS [training: 0.03741766989842861 | validation: 0.013218123899341672]
	TIME [epoch: 8.26 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012604814818284777		[learning rate: 0.013565]
	Learning Rate: 0.013565
	LOSS [training: 0.012604814818284777 | validation: 0.01622453755099668]
	TIME [epoch: 8.26 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02118704707061536		[learning rate: 0.01355]
	Learning Rate: 0.0135496
	LOSS [training: 0.02118704707061536 | validation: 0.035571980711850214]
	TIME [epoch: 8.3 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017889939897052363		[learning rate: 0.013534]
	Learning Rate: 0.0135341
	LOSS [training: 0.017889939897052363 | validation: 0.020606384446527532]
	TIME [epoch: 8.27 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015262458033161685		[learning rate: 0.013519]
	Learning Rate: 0.0135186
	LOSS [training: 0.015262458033161685 | validation: 0.059147383331143055]
	TIME [epoch: 8.26 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028887081729906134		[learning rate: 0.013503]
	Learning Rate: 0.0135032
	LOSS [training: 0.028887081729906134 | validation: 0.016771060469636175]
	TIME [epoch: 8.35 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024316523360785096		[learning rate: 0.013488]
	Learning Rate: 0.0134877
	LOSS [training: 0.024316523360785096 | validation: 0.008886824692441057]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_785.pth
	Model improved!!!
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011510002368487482		[learning rate: 0.013472]
	Learning Rate: 0.0134722
	LOSS [training: 0.011510002368487482 | validation: 0.031188162614328097]
	TIME [epoch: 8.34 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032445820344892885		[learning rate: 0.013457]
	Learning Rate: 0.0134567
	LOSS [training: 0.032445820344892885 | validation: 0.017177417361873237]
	TIME [epoch: 8.29 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008797536607880133		[learning rate: 0.013441]
	Learning Rate: 0.0134412
	LOSS [training: 0.008797536607880133 | validation: 0.018265840012527408]
	TIME [epoch: 8.25 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04063870902237965		[learning rate: 0.013426]
	Learning Rate: 0.0134256
	LOSS [training: 0.04063870902237965 | validation: 0.0339463619731912]
	TIME [epoch: 8.26 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02047242197629111		[learning rate: 0.01341]
	Learning Rate: 0.0134101
	LOSS [training: 0.02047242197629111 | validation: 0.025799835101712836]
	TIME [epoch: 8.26 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06595533301296343		[learning rate: 0.013395]
	Learning Rate: 0.0133946
	LOSS [training: 0.06595533301296343 | validation: 0.060981628910772495]
	TIME [epoch: 8.25 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035481187915935804		[learning rate: 0.013379]
	Learning Rate: 0.013379
	LOSS [training: 0.035481187915935804 | validation: 0.04459234770758397]
	TIME [epoch: 8.3 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02207066492548169		[learning rate: 0.013363]
	Learning Rate: 0.0133635
	LOSS [training: 0.02207066492548169 | validation: 0.031015025171727044]
	TIME [epoch: 8.27 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01459091536438266		[learning rate: 0.013348]
	Learning Rate: 0.0133479
	LOSS [training: 0.01459091536438266 | validation: 0.03603297673855288]
	TIME [epoch: 8.26 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03094090397634599		[learning rate: 0.013332]
	Learning Rate: 0.0133323
	LOSS [training: 0.03094090397634599 | validation: 0.02675249003394794]
	TIME [epoch: 8.26 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0124456645059932		[learning rate: 0.013317]
	Learning Rate: 0.0133167
	LOSS [training: 0.0124456645059932 | validation: 0.018980393437754373]
	TIME [epoch: 8.26 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01925783806619142		[learning rate: 0.013301]
	Learning Rate: 0.0133011
	LOSS [training: 0.01925783806619142 | validation: 0.04209002629423589]
	TIME [epoch: 8.26 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025431664967208216		[learning rate: 0.013286]
	Learning Rate: 0.0132855
	LOSS [training: 0.025431664967208216 | validation: 0.027751536544447113]
	TIME [epoch: 8.29 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015487836058991941		[learning rate: 0.01327]
	Learning Rate: 0.0132699
	LOSS [training: 0.015487836058991941 | validation: 0.058082005001483965]
	TIME [epoch: 8.26 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03496253682131666		[learning rate: 0.013254]
	Learning Rate: 0.0132543
	LOSS [training: 0.03496253682131666 | validation: 0.026926289144274407]
	TIME [epoch: 8.26 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01612498311160038		[learning rate: 0.013239]
	Learning Rate: 0.0132386
	LOSS [training: 0.01612498311160038 | validation: 0.016198747845636546]
	TIME [epoch: 8.26 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03067083602467483		[learning rate: 0.013223]
	Learning Rate: 0.013223
	LOSS [training: 0.03067083602467483 | validation: 0.03375066304438116]
	TIME [epoch: 8.26 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018578459138752237		[learning rate: 0.013207]
	Learning Rate: 0.0132074
	LOSS [training: 0.018578459138752237 | validation: 0.010601932312867279]
	TIME [epoch: 8.29 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015292978101349275		[learning rate: 0.013192]
	Learning Rate: 0.0131917
	LOSS [training: 0.015292978101349275 | validation: 0.02407503790274848]
	TIME [epoch: 8.26 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01869348118355118		[learning rate: 0.013176]
	Learning Rate: 0.013176
	LOSS [training: 0.01869348118355118 | validation: 0.056899542323028025]
	TIME [epoch: 8.26 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040263713335346604		[learning rate: 0.01316]
	Learning Rate: 0.0131603
	LOSS [training: 0.040263713335346604 | validation: 0.021746961483726436]
	TIME [epoch: 8.26 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011604472167012877		[learning rate: 0.013145]
	Learning Rate: 0.0131447
	LOSS [training: 0.011604472167012877 | validation: 0.019525461540983013]
	TIME [epoch: 8.26 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018940895191184248		[learning rate: 0.013129]
	Learning Rate: 0.013129
	LOSS [training: 0.018940895191184248 | validation: 0.030184273644982114]
	TIME [epoch: 8.26 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026364611731358904		[learning rate: 0.013113]
	Learning Rate: 0.0131133
	LOSS [training: 0.026364611731358904 | validation: 0.023957062621757463]
	TIME [epoch: 8.29 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012820303540211637		[learning rate: 0.013098]
	Learning Rate: 0.0130976
	LOSS [training: 0.012820303540211637 | validation: 0.019673770138600746]
	TIME [epoch: 8.26 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018279630324238016		[learning rate: 0.013082]
	Learning Rate: 0.0130818
	LOSS [training: 0.018279630324238016 | validation: 0.05021190585070812]
	TIME [epoch: 8.26 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03704098863656843		[learning rate: 0.013066]
	Learning Rate: 0.0130661
	LOSS [training: 0.03704098863656843 | validation: 0.03853262173950597]
	TIME [epoch: 8.26 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01650040148139154		[learning rate: 0.01305]
	Learning Rate: 0.0130504
	LOSS [training: 0.01650040148139154 | validation: 0.134789496389211]
	TIME [epoch: 8.26 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029690080387813747		[learning rate: 0.013035]
	Learning Rate: 0.0130346
	LOSS [training: 0.029690080387813747 | validation: 0.019222054057491354]
	TIME [epoch: 8.29 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032883695002835084		[learning rate: 0.013019]
	Learning Rate: 0.0130189
	LOSS [training: 0.032883695002835084 | validation: 0.023486234233258213]
	TIME [epoch: 8.27 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018849686115020574		[learning rate: 0.013003]
	Learning Rate: 0.0130031
	LOSS [training: 0.018849686115020574 | validation: 0.02827038065472519]
	TIME [epoch: 8.26 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01551894815347446		[learning rate: 0.012987]
	Learning Rate: 0.0129873
	LOSS [training: 0.01551894815347446 | validation: 0.014457686631379753]
	TIME [epoch: 8.26 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016041788830421212		[learning rate: 0.012972]
	Learning Rate: 0.0129716
	LOSS [training: 0.016041788830421212 | validation: 0.01857792720298449]
	TIME [epoch: 8.26 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03527950478540868		[learning rate: 0.012956]
	Learning Rate: 0.0129558
	LOSS [training: 0.03527950478540868 | validation: 0.030460910673403035]
	TIME [epoch: 8.26 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020535471157143773		[learning rate: 0.01294]
	Learning Rate: 0.01294
	LOSS [training: 0.020535471157143773 | validation: 0.023347439338768365]
	TIME [epoch: 8.3 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009993027450007845		[learning rate: 0.012924]
	Learning Rate: 0.0129242
	LOSS [training: 0.009993027450007845 | validation: 0.00926591809148319]
	TIME [epoch: 8.26 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0072161559672798015		[learning rate: 0.012908]
	Learning Rate: 0.0129084
	LOSS [training: 0.0072161559672798015 | validation: 0.008988267113777128]
	TIME [epoch: 8.26 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03974628050570661		[learning rate: 0.012893]
	Learning Rate: 0.0128926
	LOSS [training: 0.03974628050570661 | validation: 0.05365950135111211]
	TIME [epoch: 8.26 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028325467109360847		[learning rate: 0.012877]
	Learning Rate: 0.0128767
	LOSS [training: 0.028325467109360847 | validation: 0.021288560158644092]
	TIME [epoch: 8.26 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01078697754000158		[learning rate: 0.012861]
	Learning Rate: 0.0128609
	LOSS [training: 0.01078697754000158 | validation: 0.023027206314081717]
	TIME [epoch: 8.28 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021562571130788653		[learning rate: 0.012845]
	Learning Rate: 0.0128451
	LOSS [training: 0.021562571130788653 | validation: 0.021905064458942247]
	TIME [epoch: 8.28 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03562927214470807		[learning rate: 0.012829]
	Learning Rate: 0.0128292
	LOSS [training: 0.03562927214470807 | validation: 0.015211818859879354]
	TIME [epoch: 8.26 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011891071167377852		[learning rate: 0.012813]
	Learning Rate: 0.0128133
	LOSS [training: 0.011891071167377852 | validation: 0.011151110304506343]
	TIME [epoch: 8.26 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009957502809325303		[learning rate: 0.012797]
	Learning Rate: 0.0127975
	LOSS [training: 0.009957502809325303 | validation: 0.022259033659336867]
	TIME [epoch: 8.26 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025993200629957885		[learning rate: 0.012782]
	Learning Rate: 0.0127816
	LOSS [training: 0.025993200629957885 | validation: 0.048581918249060524]
	TIME [epoch: 8.26 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02150074751917233		[learning rate: 0.012766]
	Learning Rate: 0.0127657
	LOSS [training: 0.02150074751917233 | validation: 0.014658291117644173]
	TIME [epoch: 8.3 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01654263862197378		[learning rate: 0.01275]
	Learning Rate: 0.0127498
	LOSS [training: 0.01654263862197378 | validation: 0.014683149044410135]
	TIME [epoch: 8.26 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014331491207560554		[learning rate: 0.012734]
	Learning Rate: 0.0127339
	LOSS [training: 0.014331491207560554 | validation: 0.026904880801196046]
	TIME [epoch: 8.26 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028965868992918788		[learning rate: 0.012718]
	Learning Rate: 0.012718
	LOSS [training: 0.028965868992918788 | validation: 0.02422792058215418]
	TIME [epoch: 8.26 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02408105791643765		[learning rate: 0.012702]
	Learning Rate: 0.0127021
	LOSS [training: 0.02408105791643765 | validation: 0.021200510562693106]
	TIME [epoch: 8.26 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011547553194505195		[learning rate: 0.012686]
	Learning Rate: 0.0126862
	LOSS [training: 0.011547553194505195 | validation: 0.014960764442697274]
	TIME [epoch: 8.27 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02260634899531394		[learning rate: 0.01267]
	Learning Rate: 0.0126703
	LOSS [training: 0.02260634899531394 | validation: 0.03208773316442938]
	TIME [epoch: 8.29 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01923296437382659		[learning rate: 0.012654]
	Learning Rate: 0.0126544
	LOSS [training: 0.01923296437382659 | validation: 0.032455414490982853]
	TIME [epoch: 8.26 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01571949719167523		[learning rate: 0.012638]
	Learning Rate: 0.0126384
	LOSS [training: 0.01571949719167523 | validation: 0.011066949375624035]
	TIME [epoch: 8.26 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015284018628993055		[learning rate: 0.012622]
	Learning Rate: 0.0126225
	LOSS [training: 0.015284018628993055 | validation: 0.018244629357984113]
	TIME [epoch: 8.26 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021390371251538066		[learning rate: 0.012607]
	Learning Rate: 0.0126065
	LOSS [training: 0.021390371251538066 | validation: 0.019934567225649312]
	TIME [epoch: 8.26 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014103189533181048		[learning rate: 0.012591]
	Learning Rate: 0.0125906
	LOSS [training: 0.014103189533181048 | validation: 0.03302154434201233]
	TIME [epoch: 8.29 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03188677852885609		[learning rate: 0.012575]
	Learning Rate: 0.0125746
	LOSS [training: 0.03188677852885609 | validation: 0.019835301473059]
	TIME [epoch: 8.27 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01723528387498803		[learning rate: 0.012559]
	Learning Rate: 0.0125586
	LOSS [training: 0.01723528387498803 | validation: 0.014833557374999631]
	TIME [epoch: 8.25 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022701969348639793		[learning rate: 0.012543]
	Learning Rate: 0.0125426
	LOSS [training: 0.022701969348639793 | validation: 0.022286637365302203]
	TIME [epoch: 8.26 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012278754414905304		[learning rate: 0.012527]
	Learning Rate: 0.0125267
	LOSS [training: 0.012278754414905304 | validation: 0.012450542990024531]
	TIME [epoch: 8.25 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02222441567458302		[learning rate: 0.012511]
	Learning Rate: 0.0125107
	LOSS [training: 0.02222441567458302 | validation: 0.03015172582977147]
	TIME [epoch: 8.27 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017154357162776242		[learning rate: 0.012495]
	Learning Rate: 0.0124947
	LOSS [training: 0.017154357162776242 | validation: 0.007383149466115584]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_848.pth
	Model improved!!!
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012625936768439577		[learning rate: 0.012479]
	Learning Rate: 0.0124786
	LOSS [training: 0.012625936768439577 | validation: 0.02231045890952308]
	TIME [epoch: 8.27 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02542642544525118		[learning rate: 0.012463]
	Learning Rate: 0.0124626
	LOSS [training: 0.02542642544525118 | validation: 0.027696774745796564]
	TIME [epoch: 8.27 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04582824239308222		[learning rate: 0.012447]
	Learning Rate: 0.0124466
	LOSS [training: 0.04582824239308222 | validation: 0.058129141917448654]
	TIME [epoch: 8.27 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02317868627700677		[learning rate: 0.012431]
	Learning Rate: 0.0124306
	LOSS [training: 0.02317868627700677 | validation: 0.03886974104036693]
	TIME [epoch: 8.27 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013518930011959047		[learning rate: 0.012415]
	Learning Rate: 0.0124145
	LOSS [training: 0.013518930011959047 | validation: 0.02521157365868043]
	TIME [epoch: 8.31 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014203404008498158		[learning rate: 0.012399]
	Learning Rate: 0.0123985
	LOSS [training: 0.014203404008498158 | validation: 0.052374847234787844]
	TIME [epoch: 8.28 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03614218409938249		[learning rate: 0.012382]
	Learning Rate: 0.0123825
	LOSS [training: 0.03614218409938249 | validation: 0.022624070314998027]
	TIME [epoch: 8.27 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014156376969183052		[learning rate: 0.012366]
	Learning Rate: 0.0123664
	LOSS [training: 0.014156376969183052 | validation: 0.01569706848165378]
	TIME [epoch: 8.27 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02040580538503105		[learning rate: 0.01235]
	Learning Rate: 0.0123503
	LOSS [training: 0.02040580538503105 | validation: 0.02915892149904295]
	TIME [epoch: 8.27 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018020867948443		[learning rate: 0.012334]
	Learning Rate: 0.0123343
	LOSS [training: 0.018020867948443 | validation: 0.018528940977977807]
	TIME [epoch: 8.28 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01246204259910709		[learning rate: 0.012318]
	Learning Rate: 0.0123182
	LOSS [training: 0.01246204259910709 | validation: 0.06723901217887748]
	TIME [epoch: 8.31 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029252143889603604		[learning rate: 0.012302]
	Learning Rate: 0.0123021
	LOSS [training: 0.029252143889603604 | validation: 0.01615443671235002]
	TIME [epoch: 8.27 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010983884181622005		[learning rate: 0.012286]
	Learning Rate: 0.012286
	LOSS [training: 0.010983884181622005 | validation: 0.012536742839516283]
	TIME [epoch: 8.27 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018461607688915537		[learning rate: 0.01227]
	Learning Rate: 0.0122699
	LOSS [training: 0.018461607688915537 | validation: 0.019418670371295157]
	TIME [epoch: 8.27 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027405620769143556		[learning rate: 0.012254]
	Learning Rate: 0.0122538
	LOSS [training: 0.027405620769143556 | validation: 0.060049942220320285]
	TIME [epoch: 8.27 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019219872574587668		[learning rate: 0.012238]
	Learning Rate: 0.0122377
	LOSS [training: 0.019219872574587668 | validation: 0.00781257298886268]
	TIME [epoch: 8.32 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004765738180468826		[learning rate: 0.012222]
	Learning Rate: 0.0122216
	LOSS [training: 0.004765738180468826 | validation: 0.010500446944390077]
	TIME [epoch: 8.28 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04237857074717384		[learning rate: 0.012205]
	Learning Rate: 0.0122055
	LOSS [training: 0.04237857074717384 | validation: 0.06321701859453344]
	TIME [epoch: 8.27 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026809917617419896		[learning rate: 0.012189]
	Learning Rate: 0.0121894
	LOSS [training: 0.026809917617419896 | validation: 0.01326707155215567]
	TIME [epoch: 8.27 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013375251310754122		[learning rate: 0.012173]
	Learning Rate: 0.0121732
	LOSS [training: 0.013375251310754122 | validation: 0.013023473541604557]
	TIME [epoch: 8.27 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012516249028752063		[learning rate: 0.012157]
	Learning Rate: 0.0121571
	LOSS [training: 0.012516249028752063 | validation: 0.02468694772313329]
	TIME [epoch: 8.27 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015690404753051036		[learning rate: 0.012141]
	Learning Rate: 0.012141
	LOSS [training: 0.015690404753051036 | validation: 0.05074284887211595]
	TIME [epoch: 8.32 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02978212467300006		[learning rate: 0.012125]
	Learning Rate: 0.0121248
	LOSS [training: 0.02978212467300006 | validation: 0.00739186061030944]
	TIME [epoch: 8.27 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0062156755506637545		[learning rate: 0.012109]
	Learning Rate: 0.0121087
	LOSS [training: 0.0062156755506637545 | validation: 0.012362207016753097]
	TIME [epoch: 8.28 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021299184530983756		[learning rate: 0.012093]
	Learning Rate: 0.0120925
	LOSS [training: 0.021299184530983756 | validation: 0.08076938600980953]
	TIME [epoch: 8.27 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027628865018163168		[learning rate: 0.012076]
	Learning Rate: 0.0120763
	LOSS [training: 0.027628865018163168 | validation: 0.02157431272113497]
	TIME [epoch: 8.27 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018210582644331418		[learning rate: 0.01206]
	Learning Rate: 0.0120602
	LOSS [training: 0.018210582644331418 | validation: 0.019717674105057533]
	TIME [epoch: 8.29 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018633189420983513		[learning rate: 0.012044]
	Learning Rate: 0.012044
	LOSS [training: 0.018633189420983513 | validation: 0.017245161618813093]
	TIME [epoch: 8.3 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017994015903600478		[learning rate: 0.012028]
	Learning Rate: 0.0120278
	LOSS [training: 0.017994015903600478 | validation: 0.012272656661334262]
	TIME [epoch: 8.27 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008781156415634837		[learning rate: 0.012012]
	Learning Rate: 0.0120116
	LOSS [training: 0.008781156415634837 | validation: 0.016564571044628034]
	TIME [epoch: 8.27 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02782427583433785		[learning rate: 0.011995]
	Learning Rate: 0.0119954
	LOSS [training: 0.02782427583433785 | validation: 0.0468405498263407]
	TIME [epoch: 8.27 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023185690842515413		[learning rate: 0.011979]
	Learning Rate: 0.0119792
	LOSS [training: 0.023185690842515413 | validation: 0.013985939048954864]
	TIME [epoch: 8.27 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009639911279408948		[learning rate: 0.011963]
	Learning Rate: 0.011963
	LOSS [training: 0.009639911279408948 | validation: 0.021747348137780287]
	TIME [epoch: 8.31 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020241008128136416		[learning rate: 0.011947]
	Learning Rate: 0.0119468
	LOSS [training: 0.020241008128136416 | validation: 0.02515377142883539]
	TIME [epoch: 8.28 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0184473968698591		[learning rate: 0.011931]
	Learning Rate: 0.0119306
	LOSS [training: 0.0184473968698591 | validation: 0.015155985677549586]
	TIME [epoch: 8.27 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0077762197270875195		[learning rate: 0.011914]
	Learning Rate: 0.0119144
	LOSS [training: 0.0077762197270875195 | validation: 0.011316498187421623]
	TIME [epoch: 8.27 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014329571602544607		[learning rate: 0.011898]
	Learning Rate: 0.0118982
	LOSS [training: 0.014329571602544607 | validation: 0.023269352054098524]
	TIME [epoch: 8.27 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019183031322959808		[learning rate: 0.011882]
	Learning Rate: 0.0118819
	LOSS [training: 0.019183031322959808 | validation: 0.05873121437929128]
	TIME [epoch: 8.28 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022789817163224826		[learning rate: 0.011866]
	Learning Rate: 0.0118657
	LOSS [training: 0.022789817163224826 | validation: 0.022099323666121093]
	TIME [epoch: 8.31 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018655388152215825		[learning rate: 0.011849]
	Learning Rate: 0.0118495
	LOSS [training: 0.018655388152215825 | validation: 0.025665335414871482]
	TIME [epoch: 8.27 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017187112742571054		[learning rate: 0.011833]
	Learning Rate: 0.0118332
	LOSS [training: 0.017187112742571054 | validation: 0.02037144801884029]
	TIME [epoch: 8.27 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011523472337025043		[learning rate: 0.011817]
	Learning Rate: 0.011817
	LOSS [training: 0.011523472337025043 | validation: 0.017828612139242007]
	TIME [epoch: 8.27 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013154645275823613		[learning rate: 0.011801]
	Learning Rate: 0.0118007
	LOSS [training: 0.013154645275823613 | validation: 0.14137676577744096]
	TIME [epoch: 8.27 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0635871949350709		[learning rate: 0.011784]
	Learning Rate: 0.0117844
	LOSS [training: 0.0635871949350709 | validation: 0.052922954507293035]
	TIME [epoch: 8.31 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019847942937754673		[learning rate: 0.011768]
	Learning Rate: 0.0117682
	LOSS [training: 0.019847942937754673 | validation: 0.036939198129210954]
	TIME [epoch: 8.28 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012531290522050275		[learning rate: 0.011752]
	Learning Rate: 0.0117519
	LOSS [training: 0.012531290522050275 | validation: 0.032495376377673114]
	TIME [epoch: 8.27 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018396552454856604		[learning rate: 0.011736]
	Learning Rate: 0.0117356
	LOSS [training: 0.018396552454856604 | validation: 0.03888092123978697]
	TIME [epoch: 8.27 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015346508943927525		[learning rate: 0.011719]
	Learning Rate: 0.0117194
	LOSS [training: 0.015346508943927525 | validation: 0.02178673545761127]
	TIME [epoch: 8.27 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011361529704460764		[learning rate: 0.011703]
	Learning Rate: 0.0117031
	LOSS [training: 0.011361529704460764 | validation: 0.024884173855686774]
	TIME [epoch: 8.27 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022860357519153263		[learning rate: 0.011687]
	Learning Rate: 0.0116868
	LOSS [training: 0.022860357519153263 | validation: 0.01932615080427044]
	TIME [epoch: 8.31 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010665910244709725		[learning rate: 0.01167]
	Learning Rate: 0.0116705
	LOSS [training: 0.010665910244709725 | validation: 0.018153394931061377]
	TIME [epoch: 8.27 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019188659285031138		[learning rate: 0.011654]
	Learning Rate: 0.0116542
	LOSS [training: 0.019188659285031138 | validation: 0.032196893221154474]
	TIME [epoch: 8.27 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016157024286790535		[learning rate: 0.011638]
	Learning Rate: 0.0116379
	LOSS [training: 0.016157024286790535 | validation: 0.021073122406998004]
	TIME [epoch: 8.27 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011857041630399379		[learning rate: 0.011622]
	Learning Rate: 0.0116216
	LOSS [training: 0.011857041630399379 | validation: 0.013549114982787245]
	TIME [epoch: 8.26 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010565276999048964		[learning rate: 0.011605]
	Learning Rate: 0.0116053
	LOSS [training: 0.010565276999048964 | validation: 0.043036275890263376]
	TIME [epoch: 8.38 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020243736276071143		[learning rate: 0.011589]
	Learning Rate: 0.011589
	LOSS [training: 0.020243736276071143 | validation: 0.02440689716150265]
	TIME [epoch: 8.27 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010302227901950062		[learning rate: 0.011573]
	Learning Rate: 0.0115726
	LOSS [training: 0.010302227901950062 | validation: 0.015495060517720594]
	TIME [epoch: 8.26 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01793374193671758		[learning rate: 0.011556]
	Learning Rate: 0.0115563
	LOSS [training: 0.01793374193671758 | validation: 0.05140385220162368]
	TIME [epoch: 8.26 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04504384235387797		[learning rate: 0.01154]
	Learning Rate: 0.01154
	LOSS [training: 0.04504384235387797 | validation: 0.016732110680408502]
	TIME [epoch: 8.26 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010346605082730683		[learning rate: 0.011524]
	Learning Rate: 0.0115237
	LOSS [training: 0.010346605082730683 | validation: 0.007455316119625476]
	TIME [epoch: 8.27 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0073191252085317805		[learning rate: 0.011507]
	Learning Rate: 0.0115073
	LOSS [training: 0.0073191252085317805 | validation: 0.009188772784176241]
	TIME [epoch: 8.3 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010619244523910675		[learning rate: 0.011491]
	Learning Rate: 0.011491
	LOSS [training: 0.010619244523910675 | validation: 0.04061890449004954]
	TIME [epoch: 8.27 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023484048554465852		[learning rate: 0.011475]
	Learning Rate: 0.0114746
	LOSS [training: 0.023484048554465852 | validation: 0.027526276807344117]
	TIME [epoch: 8.26 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014872559348613302		[learning rate: 0.011458]
	Learning Rate: 0.0114583
	LOSS [training: 0.014872559348613302 | validation: 0.05224216675412292]
	TIME [epoch: 8.26 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021359596994304703		[learning rate: 0.011442]
	Learning Rate: 0.0114419
	LOSS [training: 0.021359596994304703 | validation: 0.012119564891950076]
	TIME [epoch: 8.26 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009775956686995105		[learning rate: 0.011426]
	Learning Rate: 0.0114256
	LOSS [training: 0.009775956686995105 | validation: 0.008377990102042222]
	TIME [epoch: 8.31 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011867691574193161		[learning rate: 0.011409]
	Learning Rate: 0.0114092
	LOSS [training: 0.011867691574193161 | validation: 0.02894382563685215]
	TIME [epoch: 8.27 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033443874619374904		[learning rate: 0.011393]
	Learning Rate: 0.0113929
	LOSS [training: 0.033443874619374904 | validation: 0.007381318376119909]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_916.pth
	Model improved!!!
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007789750386294256		[learning rate: 0.011376]
	Learning Rate: 0.0113765
	LOSS [training: 0.007789750386294256 | validation: 0.011963139004440293]
	TIME [epoch: 8.26 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010744040108951566		[learning rate: 0.01136]
	Learning Rate: 0.0113601
	LOSS [training: 0.010744040108951566 | validation: 0.031830014690645926]
	TIME [epoch: 8.26 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0226266468321921		[learning rate: 0.011344]
	Learning Rate: 0.0113437
	LOSS [training: 0.0226266468321921 | validation: 0.010095424672341615]
	TIME [epoch: 8.26 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007861956941715105		[learning rate: 0.011327]
	Learning Rate: 0.0113274
	LOSS [training: 0.007861956941715105 | validation: 0.03184916894409398]
	TIME [epoch: 8.29 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030463868123719054		[learning rate: 0.011311]
	Learning Rate: 0.011311
	LOSS [training: 0.030463868123719054 | validation: 0.02203850795233865]
	TIME [epoch: 8.26 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010598796343348404		[learning rate: 0.011295]
	Learning Rate: 0.0112946
	LOSS [training: 0.010598796343348404 | validation: 0.01170672896381401]
	TIME [epoch: 8.26 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017761899449439414		[learning rate: 0.011278]
	Learning Rate: 0.0112782
	LOSS [training: 0.017761899449439414 | validation: 0.020145920360063803]
	TIME [epoch: 8.26 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01500805955398409		[learning rate: 0.011262]
	Learning Rate: 0.0112618
	LOSS [training: 0.01500805955398409 | validation: 0.009751726628713885]
	TIME [epoch: 8.26 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006431868716637942		[learning rate: 0.011245]
	Learning Rate: 0.0112454
	LOSS [training: 0.006431868716637942 | validation: 0.011051640069787856]
	TIME [epoch: 8.28 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02608981309646291		[learning rate: 0.011229]
	Learning Rate: 0.011229
	LOSS [training: 0.02608981309646291 | validation: 0.02963652232754651]
	TIME [epoch: 8.28 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06108287797296637		[learning rate: 0.011213]
	Learning Rate: 0.0112126
	LOSS [training: 0.06108287797296637 | validation: 0.06033646482069589]
	TIME [epoch: 8.26 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021270551359703623		[learning rate: 0.011196]
	Learning Rate: 0.0111962
	LOSS [training: 0.021270551359703623 | validation: 0.006534369176839649]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_928.pth
	Model improved!!!
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004664459690580814		[learning rate: 0.01118]
	Learning Rate: 0.0111798
	LOSS [training: 0.004664459690580814 | validation: 0.009963323964009332]
	TIME [epoch: 8.26 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007157836214099926		[learning rate: 0.011163]
	Learning Rate: 0.0111634
	LOSS [training: 0.007157836214099926 | validation: 0.008623948388667167]
	TIME [epoch: 8.26 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015955858846627136		[learning rate: 0.011147]
	Learning Rate: 0.011147
	LOSS [training: 0.015955858846627136 | validation: 0.04210600243878263]
	TIME [epoch: 8.3 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0185028775473891		[learning rate: 0.011131]
	Learning Rate: 0.0111305
	LOSS [training: 0.0185028775473891 | validation: 0.017078819428335758]
	TIME [epoch: 8.26 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011245954980129895		[learning rate: 0.011114]
	Learning Rate: 0.0111141
	LOSS [training: 0.011245954980129895 | validation: 0.010288020623080122]
	TIME [epoch: 8.26 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00935679591600687		[learning rate: 0.011098]
	Learning Rate: 0.0110977
	LOSS [training: 0.00935679591600687 | validation: 0.020668642084162928]
	TIME [epoch: 8.26 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01922933694915722		[learning rate: 0.011081]
	Learning Rate: 0.0110813
	LOSS [training: 0.01922933694915722 | validation: 0.014581624088291431]
	TIME [epoch: 8.26 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01758363190251237		[learning rate: 0.011065]
	Learning Rate: 0.0110648
	LOSS [training: 0.01758363190251237 | validation: 0.014304919653695635]
	TIME [epoch: 8.28 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008828799098814125		[learning rate: 0.011048]
	Learning Rate: 0.0110484
	LOSS [training: 0.008828799098814125 | validation: 0.010729808676650254]
	TIME [epoch: 8.29 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011917131833175944		[learning rate: 0.011032]
	Learning Rate: 0.011032
	LOSS [training: 0.011917131833175944 | validation: 0.014294305187378278]
	TIME [epoch: 8.26 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011974055286721054		[learning rate: 0.011016]
	Learning Rate: 0.0110155
	LOSS [training: 0.011974055286721054 | validation: 0.02304926293866713]
	TIME [epoch: 8.26 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0278754626536643		[learning rate: 0.010999]
	Learning Rate: 0.0109991
	LOSS [training: 0.0278754626536643 | validation: 0.017065238013117403]
	TIME [epoch: 8.26 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012815778799689793		[learning rate: 0.010983]
	Learning Rate: 0.0109826
	LOSS [training: 0.012815778799689793 | validation: 0.012589293829154979]
	TIME [epoch: 8.26 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006524294595697621		[learning rate: 0.010966]
	Learning Rate: 0.0109662
	LOSS [training: 0.006524294595697621 | validation: 0.014580036267838617]
	TIME [epoch: 8.3 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020861093367108133		[learning rate: 0.01095]
	Learning Rate: 0.0109497
	LOSS [training: 0.020861093367108133 | validation: 0.02546765615293936]
	TIME [epoch: 8.27 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020342541048930886		[learning rate: 0.010933]
	Learning Rate: 0.0109333
	LOSS [training: 0.020342541048930886 | validation: 0.027078354570315308]
	TIME [epoch: 8.26 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015396194535809874		[learning rate: 0.010917]
	Learning Rate: 0.0109168
	LOSS [training: 0.015396194535809874 | validation: 0.012540821990535432]
	TIME [epoch: 8.26 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01554149079525546		[learning rate: 0.0109]
	Learning Rate: 0.0109004
	LOSS [training: 0.01554149079525546 | validation: 0.04901312231405876]
	TIME [epoch: 8.26 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029921933825945157		[learning rate: 0.010884]
	Learning Rate: 0.0108839
	LOSS [training: 0.029921933825945157 | validation: 0.021812254604045525]
	TIME [epoch: 8.26 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016785975748442893		[learning rate: 0.010867]
	Learning Rate: 0.0108674
	LOSS [training: 0.016785975748442893 | validation: 0.00991336033382577]
	TIME [epoch: 8.3 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01521630484822183		[learning rate: 0.010851]
	Learning Rate: 0.010851
	LOSS [training: 0.01521630484822183 | validation: 0.016863617994978833]
	TIME [epoch: 8.26 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012152620000598219		[learning rate: 0.010834]
	Learning Rate: 0.0108345
	LOSS [training: 0.012152620000598219 | validation: 0.017751546552265206]
	TIME [epoch: 8.26 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013887106742539882		[learning rate: 0.010818]
	Learning Rate: 0.010818
	LOSS [training: 0.013887106742539882 | validation: 0.018315625591391476]
	TIME [epoch: 8.26 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020490060560153154		[learning rate: 0.010802]
	Learning Rate: 0.0108016
	LOSS [training: 0.020490060560153154 | validation: 0.02358718731371027]
	TIME [epoch: 8.26 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011893769503337025		[learning rate: 0.010785]
	Learning Rate: 0.0107851
	LOSS [training: 0.011893769503337025 | validation: 0.007762420332741089]
	TIME [epoch: 8.29 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008744579668614272		[learning rate: 0.010769]
	Learning Rate: 0.0107686
	LOSS [training: 0.008744579668614272 | validation: 0.013546107906615357]
	TIME [epoch: 8.26 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010297437130756513		[learning rate: 0.010752]
	Learning Rate: 0.0107521
	LOSS [training: 0.010297437130756513 | validation: 0.010493295996729364]
	TIME [epoch: 8.26 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010251201000501807		[learning rate: 0.010736]
	Learning Rate: 0.0107356
	LOSS [training: 0.010251201000501807 | validation: 0.023012065081351358]
	TIME [epoch: 8.26 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0490229865614422		[learning rate: 0.010719]
	Learning Rate: 0.0107192
	LOSS [training: 0.0490229865614422 | validation: 0.045422949821658745]
	TIME [epoch: 8.26 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02984156446303484		[learning rate: 0.010703]
	Learning Rate: 0.0107027
	LOSS [training: 0.02984156446303484 | validation: 0.038968134222422526]
	TIME [epoch: 8.27 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013336935110739377		[learning rate: 0.010686]
	Learning Rate: 0.0106862
	LOSS [training: 0.013336935110739377 | validation: 0.01690873081291248]
	TIME [epoch: 8.29 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008087429454852715		[learning rate: 0.01067]
	Learning Rate: 0.0106697
	LOSS [training: 0.008087429454852715 | validation: 0.02043524855258232]
	TIME [epoch: 8.26 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01782015384640629		[learning rate: 0.010653]
	Learning Rate: 0.0106532
	LOSS [training: 0.01782015384640629 | validation: 0.01964883383988867]
	TIME [epoch: 8.26 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01636825328281897		[learning rate: 0.010637]
	Learning Rate: 0.0106367
	LOSS [training: 0.01636825328281897 | validation: 0.015801598720391913]
	TIME [epoch: 8.26 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014006082294334352		[learning rate: 0.01062]
	Learning Rate: 0.0106202
	LOSS [training: 0.014006082294334352 | validation: 0.029508466538915742]
	TIME [epoch: 8.26 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012742766863509992		[learning rate: 0.010604]
	Learning Rate: 0.0106037
	LOSS [training: 0.012742766863509992 | validation: 0.019559634706354176]
	TIME [epoch: 8.29 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013855680672152548		[learning rate: 0.010587]
	Learning Rate: 0.0105872
	LOSS [training: 0.013855680672152548 | validation: 0.013948383789329031]
	TIME [epoch: 8.27 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007605091720429278		[learning rate: 0.010571]
	Learning Rate: 0.0105707
	LOSS [training: 0.007605091720429278 | validation: 0.013473645350014546]
	TIME [epoch: 8.26 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021038462132581547		[learning rate: 0.010554]
	Learning Rate: 0.0105542
	LOSS [training: 0.021038462132581547 | validation: 0.02209095450016454]
	TIME [epoch: 8.26 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011991335047838971		[learning rate: 0.010538]
	Learning Rate: 0.0105377
	LOSS [training: 0.011991335047838971 | validation: 0.012755636192783987]
	TIME [epoch: 8.26 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0074548337433566455		[learning rate: 0.010521]
	Learning Rate: 0.0105212
	LOSS [training: 0.0074548337433566455 | validation: 0.027812003772769534]
	TIME [epoch: 8.26 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017244939640526143		[learning rate: 0.010505]
	Learning Rate: 0.0105047
	LOSS [training: 0.017244939640526143 | validation: 0.030842901837187676]
	TIME [epoch: 8.3 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01977768482296371		[learning rate: 0.010488]
	Learning Rate: 0.0104882
	LOSS [training: 0.01977768482296371 | validation: 0.015668906093007216]
	TIME [epoch: 8.26 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010556539343494702		[learning rate: 0.010472]
	Learning Rate: 0.0104717
	LOSS [training: 0.010556539343494702 | validation: 0.00941683803426571]
	TIME [epoch: 8.26 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008833399095199772		[learning rate: 0.010455]
	Learning Rate: 0.0104552
	LOSS [training: 0.008833399095199772 | validation: 0.012695771273592494]
	TIME [epoch: 8.26 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020570788279477743		[learning rate: 0.010439]
	Learning Rate: 0.0104387
	LOSS [training: 0.020570788279477743 | validation: 0.02535631959174383]
	TIME [epoch: 8.26 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010535764699819993		[learning rate: 0.010422]
	Learning Rate: 0.0104222
	LOSS [training: 0.010535764699819993 | validation: 0.009780746746708861]
	TIME [epoch: 8.27 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011784037429670347		[learning rate: 0.010406]
	Learning Rate: 0.0104057
	LOSS [training: 0.011784037429670347 | validation: 0.0343456773295254]
	TIME [epoch: 8.28 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01860129607030493		[learning rate: 0.010389]
	Learning Rate: 0.0103891
	LOSS [training: 0.01860129607030493 | validation: 0.005896910490084121]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_977.pth
	Model improved!!!
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005112217385216769		[learning rate: 0.010373]
	Learning Rate: 0.0103726
	LOSS [training: 0.005112217385216769 | validation: 0.010972100008863516]
	TIME [epoch: 8.33 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009777530250415247		[learning rate: 0.010356]
	Learning Rate: 0.0103561
	LOSS [training: 0.009777530250415247 | validation: 0.015026645449193377]
	TIME [epoch: 8.26 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014436947219603934		[learning rate: 0.01034]
	Learning Rate: 0.0103396
	LOSS [training: 0.014436947219603934 | validation: 0.04303447526646412]
	TIME [epoch: 8.26 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019448801343864452		[learning rate: 0.010323]
	Learning Rate: 0.0103231
	LOSS [training: 0.019448801343864452 | validation: 0.008257144641750204]
	TIME [epoch: 8.29 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011872965629443441		[learning rate: 0.010307]
	Learning Rate: 0.0103066
	LOSS [training: 0.011872965629443441 | validation: 0.04469755218431766]
	TIME [epoch: 8.26 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027364195219906583		[learning rate: 0.01029]
	Learning Rate: 0.01029
	LOSS [training: 0.027364195219906583 | validation: 0.015544980591814911]
	TIME [epoch: 8.25 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012769287301668647		[learning rate: 0.010274]
	Learning Rate: 0.0102735
	LOSS [training: 0.012769287301668647 | validation: 0.012347599350448739]
	TIME [epoch: 8.26 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016568015345176088		[learning rate: 0.010257]
	Learning Rate: 0.010257
	LOSS [training: 0.016568015345176088 | validation: 0.008688551957511764]
	TIME [epoch: 8.26 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00932775186212501		[learning rate: 0.01024]
	Learning Rate: 0.0102405
	LOSS [training: 0.00932775186212501 | validation: 0.0103087066330095]
	TIME [epoch: 8.27 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012840466407516522		[learning rate: 0.010224]
	Learning Rate: 0.010224
	LOSS [training: 0.012840466407516522 | validation: 0.0173767691485935]
	TIME [epoch: 8.28 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013695279933942902		[learning rate: 0.010207]
	Learning Rate: 0.0102074
	LOSS [training: 0.013695279933942902 | validation: 0.007086480695426858]
	TIME [epoch: 8.26 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006365188426670577		[learning rate: 0.010191]
	Learning Rate: 0.0101909
	LOSS [training: 0.006365188426670577 | validation: 0.011117891513463533]
	TIME [epoch: 8.26 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02060749371170714		[learning rate: 0.010174]
	Learning Rate: 0.0101744
	LOSS [training: 0.02060749371170714 | validation: 0.017849262574750745]
	TIME [epoch: 8.26 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0821815142839844		[learning rate: 0.010158]
	Learning Rate: 0.0101579
	LOSS [training: 0.0821815142839844 | validation: 0.032800482323022497]
	TIME [epoch: 8.26 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019905616159052425		[learning rate: 0.010141]
	Learning Rate: 0.0101413
	LOSS [training: 0.019905616159052425 | validation: 0.023491598029954937]
	TIME [epoch: 8.29 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01196926423979828		[learning rate: 0.010125]
	Learning Rate: 0.0101248
	LOSS [training: 0.01196926423979828 | validation: 0.019532951555328363]
	TIME [epoch: 8.26 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01860151390886247		[learning rate: 0.010108]
	Learning Rate: 0.0101083
	LOSS [training: 0.01860151390886247 | validation: 0.027204017133018593]
	TIME [epoch: 8.26 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010103811740718784		[learning rate: 0.010092]
	Learning Rate: 0.0100918
	LOSS [training: 0.010103811740718784 | validation: 0.017724141646537836]
	TIME [epoch: 8.26 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009808216317738776		[learning rate: 0.010075]
	Learning Rate: 0.0100752
	LOSS [training: 0.009808216317738776 | validation: 0.021471780363901724]
	TIME [epoch: 8.26 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017162201534131404		[learning rate: 0.010059]
	Learning Rate: 0.0100587
	LOSS [training: 0.017162201534131404 | validation: 0.013887931320365018]
	TIME [epoch: 8.26 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0076054771954825046		[learning rate: 0.010042]
	Learning Rate: 0.0100422
	LOSS [training: 0.0076054771954825046 | validation: 0.015679149814627168]
	TIME [epoch: 8.29 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016172371013184847		[learning rate: 0.010026]
	Learning Rate: 0.0100257
	LOSS [training: 0.016172371013184847 | validation: 0.01636072104331388]
	TIME [epoch: 8.26 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00891645071033993		[learning rate: 0.010009]
	Learning Rate: 0.0100091
	LOSS [training: 0.00891645071033993 | validation: 0.01732282018391895]
	TIME [epoch: 8.26 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010927667704197966		[learning rate: 0.0099926]
	Learning Rate: 0.00999261
	LOSS [training: 0.010927667704197966 | validation: 0.01809436868611498]
	TIME [epoch: 8.27 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019652839989360314		[learning rate: 0.0099761]
	Learning Rate: 0.00997608
	LOSS [training: 0.019652839989360314 | validation: 0.01225588481689769]
	TIME [epoch: 8.26 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007324556863443999		[learning rate: 0.0099596]
	Learning Rate: 0.00995955
	LOSS [training: 0.007324556863443999 | validation: 0.02216754350534199]
	TIME [epoch: 8.29 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00875228107049136		[learning rate: 0.009943]
	Learning Rate: 0.00994303
	LOSS [training: 0.00875228107049136 | validation: 0.01757445300351184]
	TIME [epoch: 8.27 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013826294019464126		[learning rate: 0.0099265]
	Learning Rate: 0.0099265
	LOSS [training: 0.013826294019464126 | validation: 0.011499468508711728]
	TIME [epoch: 8.25 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012050718105094612		[learning rate: 0.00991]
	Learning Rate: 0.00990997
	LOSS [training: 0.012050718105094612 | validation: 0.018899715352646035]
	TIME [epoch: 8.25 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010913697818630573		[learning rate: 0.0098934]
	Learning Rate: 0.00989345
	LOSS [training: 0.010913697818630573 | validation: 0.02321751289441366]
	TIME [epoch: 8.26 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025360781703085252		[learning rate: 0.0098769]
	Learning Rate: 0.00987692
	LOSS [training: 0.025360781703085252 | validation: 0.025353263380726857]
	TIME [epoch: 8.26 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016378429324564802		[learning rate: 0.0098604]
	Learning Rate: 0.0098604
	LOSS [training: 0.016378429324564802 | validation: 0.038958186596107225]
	TIME [epoch: 8.29 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01499355613126026		[learning rate: 0.0098439]
	Learning Rate: 0.00984387
	LOSS [training: 0.01499355613126026 | validation: 0.01688830784366161]
	TIME [epoch: 8.4 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006906487834886324		[learning rate: 0.0098274]
	Learning Rate: 0.00982735
	LOSS [training: 0.006906487834886324 | validation: 0.01673652189270793]
	TIME [epoch: 8.27 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014015804708605112		[learning rate: 0.0098108]
	Learning Rate: 0.00981083
	LOSS [training: 0.014015804708605112 | validation: 0.023476297936320466]
	TIME [epoch: 8.25 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011925482715527291		[learning rate: 0.0097943]
	Learning Rate: 0.0097943
	LOSS [training: 0.011925482715527291 | validation: 0.01767647133783031]
	TIME [epoch: 8.25 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013311833427391768		[learning rate: 0.0097778]
	Learning Rate: 0.00977778
	LOSS [training: 0.013311833427391768 | validation: 0.01867382628801976]
	TIME [epoch: 8.29 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010737791076341058		[learning rate: 0.0097613]
	Learning Rate: 0.00976126
	LOSS [training: 0.010737791076341058 | validation: 0.024895006630353954]
	TIME [epoch: 8.27 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016613813936948555		[learning rate: 0.0097447]
	Learning Rate: 0.00974474
	LOSS [training: 0.016613813936948555 | validation: 0.021531460947691358]
	TIME [epoch: 8.26 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008360215733288882		[learning rate: 0.0097282]
	Learning Rate: 0.00972822
	LOSS [training: 0.008360215733288882 | validation: 0.010430574849868344]
	TIME [epoch: 8.25 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011589675241343633		[learning rate: 0.0097117]
	Learning Rate: 0.0097117
	LOSS [training: 0.011589675241343633 | validation: 0.04500200446454965]
	TIME [epoch: 8.26 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018335963018970173		[learning rate: 0.0096952]
	Learning Rate: 0.00969518
	LOSS [training: 0.018335963018970173 | validation: 0.013127165694324327]
	TIME [epoch: 8.26 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01092931518449591		[learning rate: 0.0096787]
	Learning Rate: 0.00967866
	LOSS [training: 0.01092931518449591 | validation: 0.011476370448794328]
	TIME [epoch: 8.29 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008824568285632932		[learning rate: 0.0096621]
	Learning Rate: 0.00966214
	LOSS [training: 0.008824568285632932 | validation: 0.020561277091224996]
	TIME [epoch: 8.26 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02073650346799972		[learning rate: 0.0096456]
	Learning Rate: 0.00964563
	LOSS [training: 0.02073650346799972 | validation: 0.024226116978643256]
	TIME [epoch: 8.26 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033868744810296246		[learning rate: 0.0096291]
	Learning Rate: 0.00962911
	LOSS [training: 0.033868744810296246 | validation: 0.020240324956770448]
	TIME [epoch: 8.26 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018855584263426935		[learning rate: 0.0096126]
	Learning Rate: 0.0096126
	LOSS [training: 0.018855584263426935 | validation: 0.013132361187567795]
	TIME [epoch: 8.26 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011101499649589518		[learning rate: 0.0095961]
	Learning Rate: 0.00959609
	LOSS [training: 0.011101499649589518 | validation: 0.006104717039948337]
	TIME [epoch: 8.28 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008639713015585422		[learning rate: 0.0095796]
	Learning Rate: 0.00957957
	LOSS [training: 0.008639713015585422 | validation: 0.008574859291970396]
	TIME [epoch: 8.28 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009202587134965037		[learning rate: 0.0095631]
	Learning Rate: 0.00956306
	LOSS [training: 0.009202587134965037 | validation: 0.02375298806953892]
	TIME [epoch: 8.26 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02578729404092809		[learning rate: 0.0095466]
	Learning Rate: 0.00954655
	LOSS [training: 0.02578729404092809 | validation: 0.008089460573965984]
	TIME [epoch: 8.26 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010603885298045542		[learning rate: 0.00953]
	Learning Rate: 0.00953004
	LOSS [training: 0.010603885298045542 | validation: 0.015789825190482255]
	TIME [epoch: 8.25 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011114338995776516		[learning rate: 0.0095135]
	Learning Rate: 0.00951354
	LOSS [training: 0.011114338995776516 | validation: 0.013994565060598426]
	TIME [epoch: 8.26 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012375990240540305		[learning rate: 0.009497]
	Learning Rate: 0.00949703
	LOSS [training: 0.012375990240540305 | validation: 0.018989365108197105]
	TIME [epoch: 8.3 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00821527678034656		[learning rate: 0.0094805]
	Learning Rate: 0.00948053
	LOSS [training: 0.00821527678034656 | validation: 0.005638388041243595]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_1032.pth
	Model improved!!!
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004208397392454956		[learning rate: 0.009464]
	Learning Rate: 0.00946402
	LOSS [training: 0.004208397392454956 | validation: 0.010834130417769754]
	TIME [epoch: 8.26 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017866973460473095		[learning rate: 0.0094475]
	Learning Rate: 0.00944752
	LOSS [training: 0.017866973460473095 | validation: 0.01563004188945758]
	TIME [epoch: 8.26 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00918664824469267		[learning rate: 0.009431]
	Learning Rate: 0.00943102
	LOSS [training: 0.00918664824469267 | validation: 0.010634862507232747]
	TIME [epoch: 8.26 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013204402233703439		[learning rate: 0.0094145]
	Learning Rate: 0.00941452
	LOSS [training: 0.013204402233703439 | validation: 0.02628854272884007]
	TIME [epoch: 8.27 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015162862888316808		[learning rate: 0.009398]
	Learning Rate: 0.00939803
	LOSS [training: 0.015162862888316808 | validation: 0.015170886956305807]
	TIME [epoch: 8.28 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007735470844608355		[learning rate: 0.0093815]
	Learning Rate: 0.00938153
	LOSS [training: 0.007735470844608355 | validation: 0.006376130735919867]
	TIME [epoch: 8.26 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017413810610614495		[learning rate: 0.009365]
	Learning Rate: 0.00936504
	LOSS [training: 0.017413810610614495 | validation: 0.027183869864608697]
	TIME [epoch: 8.26 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012147877475733091		[learning rate: 0.0093485]
	Learning Rate: 0.00934855
	LOSS [training: 0.012147877475733091 | validation: 0.011676902975660076]
	TIME [epoch: 8.25 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008496790350701564		[learning rate: 0.0093321]
	Learning Rate: 0.00933206
	LOSS [training: 0.008496790350701564 | validation: 0.03977932733749556]
	TIME [epoch: 8.26 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018454334694227734		[learning rate: 0.0093156]
	Learning Rate: 0.00931557
	LOSS [training: 0.018454334694227734 | validation: 0.025351931439167592]
	TIME [epoch: 8.29 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0142006045927149		[learning rate: 0.0092991]
	Learning Rate: 0.00929908
	LOSS [training: 0.0142006045927149 | validation: 0.007193820210736075]
	TIME [epoch: 8.26 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005736774056094491		[learning rate: 0.0092826]
	Learning Rate: 0.0092826
	LOSS [training: 0.005736774056094491 | validation: 0.01320721011173915]
	TIME [epoch: 8.26 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008692156386008905		[learning rate: 0.0092661]
	Learning Rate: 0.00926612
	LOSS [training: 0.008692156386008905 | validation: 0.022615427331045705]
	TIME [epoch: 8.26 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018352085653613168		[learning rate: 0.0092496]
	Learning Rate: 0.00924964
	LOSS [training: 0.018352085653613168 | validation: 0.04459001394590398]
	TIME [epoch: 8.26 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02916778195365312		[learning rate: 0.0092332]
	Learning Rate: 0.00923316
	LOSS [training: 0.02916778195365312 | validation: 0.0197529689165536]
	TIME [epoch: 8.26 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013209202879831532		[learning rate: 0.0092167]
	Learning Rate: 0.00921668
	LOSS [training: 0.013209202879831532 | validation: 0.007924428718990644]
	TIME [epoch: 8.29 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00975541389669464		[learning rate: 0.0092002]
	Learning Rate: 0.00920021
	LOSS [training: 0.00975541389669464 | validation: 0.009293030167154515]
	TIME [epoch: 8.26 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008468997037784419		[learning rate: 0.0091837]
	Learning Rate: 0.00918374
	LOSS [training: 0.008468997037784419 | validation: 0.006179590373485074]
	TIME [epoch: 8.26 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005920430684652396		[learning rate: 0.0091673]
	Learning Rate: 0.00916727
	LOSS [training: 0.005920430684652396 | validation: 0.058381459926102164]
	TIME [epoch: 8.26 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02288570840343933		[learning rate: 0.0091508]
	Learning Rate: 0.0091508
	LOSS [training: 0.02288570840343933 | validation: 0.03035781614156228]
	TIME [epoch: 8.26 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013349897922662201		[learning rate: 0.0091343]
	Learning Rate: 0.00913434
	LOSS [training: 0.013349897922662201 | validation: 0.015544647738954528]
	TIME [epoch: 8.29 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012448748526753305		[learning rate: 0.0091179]
	Learning Rate: 0.00911787
	LOSS [training: 0.012448748526753305 | validation: 0.015179180136989254]
	TIME [epoch: 8.27 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00871211727988274		[learning rate: 0.0091014]
	Learning Rate: 0.00910141
	LOSS [training: 0.00871211727988274 | validation: 0.011591999394622961]
	TIME [epoch: 8.25 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018072869089422634		[learning rate: 0.009085]
	Learning Rate: 0.00908496
	LOSS [training: 0.018072869089422634 | validation: 0.023990571724819873]
	TIME [epoch: 8.25 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01298683269478649		[learning rate: 0.0090685]
	Learning Rate: 0.0090685
	LOSS [training: 0.01298683269478649 | validation: 0.011400887474198814]
	TIME [epoch: 8.26 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0060456935515668464		[learning rate: 0.009052]
	Learning Rate: 0.00905205
	LOSS [training: 0.0060456935515668464 | validation: 0.008872512282609473]
	TIME [epoch: 8.26 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015451537535643713		[learning rate: 0.0090356]
	Learning Rate: 0.0090356
	LOSS [training: 0.015451537535643713 | validation: 0.013388512698612302]
	TIME [epoch: 8.29 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010993169564422006		[learning rate: 0.0090192]
	Learning Rate: 0.00901915
	LOSS [training: 0.010993169564422006 | validation: 0.012386759471600162]
	TIME [epoch: 8.26 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005432154154390704		[learning rate: 0.0090027]
	Learning Rate: 0.00900271
	LOSS [training: 0.005432154154390704 | validation: 0.0109485608458828]
	TIME [epoch: 8.26 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007609693896921579		[learning rate: 0.0089863]
	Learning Rate: 0.00898627
	LOSS [training: 0.007609693896921579 | validation: 0.01994578456844176]
	TIME [epoch: 8.26 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019873398355841662		[learning rate: 0.0089698]
	Learning Rate: 0.00896983
	LOSS [training: 0.019873398355841662 | validation: 0.014558756325567142]
	TIME [epoch: 8.26 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00747407021182057		[learning rate: 0.0089534]
	Learning Rate: 0.00895339
	LOSS [training: 0.00747407021182057 | validation: 0.007949654502132728]
	TIME [epoch: 8.29 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0077716556931516955		[learning rate: 0.008937]
	Learning Rate: 0.00893696
	LOSS [training: 0.0077716556931516955 | validation: 0.011899789693390804]
	TIME [epoch: 8.26 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010602466924084257		[learning rate: 0.0089205]
	Learning Rate: 0.00892053
	LOSS [training: 0.010602466924084257 | validation: 0.017757624662932965]
	TIME [epoch: 8.26 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01280842851097478		[learning rate: 0.0089041]
	Learning Rate: 0.0089041
	LOSS [training: 0.01280842851097478 | validation: 0.032696701875406006]
	TIME [epoch: 8.26 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015465894354701524		[learning rate: 0.0088877]
	Learning Rate: 0.00888767
	LOSS [training: 0.015465894354701524 | validation: 0.01433592663536123]
	TIME [epoch: 8.26 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006896904688500499		[learning rate: 0.0088713]
	Learning Rate: 0.00887125
	LOSS [training: 0.006896904688500499 | validation: 0.0068801078044489865]
	TIME [epoch: 8.26 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007789619770041275		[learning rate: 0.0088548]
	Learning Rate: 0.00885484
	LOSS [training: 0.007789619770041275 | validation: 0.013183540034634088]
	TIME [epoch: 8.3 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013673109409939524		[learning rate: 0.0088384]
	Learning Rate: 0.00883842
	LOSS [training: 0.013673109409939524 | validation: 0.023722298553688903]
	TIME [epoch: 8.26 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008530404324362062		[learning rate: 0.008822]
	Learning Rate: 0.00882201
	LOSS [training: 0.008530404324362062 | validation: 0.008079139609320104]
	TIME [epoch: 8.26 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012844245498659812		[learning rate: 0.0088056]
	Learning Rate: 0.0088056
	LOSS [training: 0.012844245498659812 | validation: 0.02076350939715485]
	TIME [epoch: 8.27 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015180134862001572		[learning rate: 0.0087892]
	Learning Rate: 0.00878919
	LOSS [training: 0.015180134862001572 | validation: 0.011464205523997536]
	TIME [epoch: 8.26 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007303626881597794		[learning rate: 0.0087728]
	Learning Rate: 0.00877279
	LOSS [training: 0.007303626881597794 | validation: 0.012373806444470913]
	TIME [epoch: 8.27 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005932329613410671		[learning rate: 0.0087564]
	Learning Rate: 0.00875639
	LOSS [training: 0.005932329613410671 | validation: 0.013956577216273563]
	TIME [epoch: 8.28 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008933188450956314		[learning rate: 0.00874]
	Learning Rate: 0.00874
	LOSS [training: 0.008933188450956314 | validation: 0.02495680772590917]
	TIME [epoch: 8.25 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017873095485512466		[learning rate: 0.0087236]
	Learning Rate: 0.00872361
	LOSS [training: 0.017873095485512466 | validation: 0.010106338750440124]
	TIME [epoch: 8.26 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008610355517744129		[learning rate: 0.0087072]
	Learning Rate: 0.00870722
	LOSS [training: 0.008610355517744129 | validation: 0.009000592818251114]
	TIME [epoch: 8.26 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007803238707550968		[learning rate: 0.0086908]
	Learning Rate: 0.00869083
	LOSS [training: 0.007803238707550968 | validation: 0.015582892276475784]
	TIME [epoch: 8.26 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009861902825630426		[learning rate: 0.0086745]
	Learning Rate: 0.00867445
	LOSS [training: 0.009861902825630426 | validation: 0.005815961963434209]
	TIME [epoch: 8.29 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009908425518269941		[learning rate: 0.0086581]
	Learning Rate: 0.00865807
	LOSS [training: 0.009908425518269941 | validation: 0.012287867055443304]
	TIME [epoch: 8.26 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006877977684372635		[learning rate: 0.0086417]
	Learning Rate: 0.0086417
	LOSS [training: 0.006877977684372635 | validation: 0.012274448304797916]
	TIME [epoch: 8.26 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015429369331228267		[learning rate: 0.0086253]
	Learning Rate: 0.00862533
	LOSS [training: 0.015429369331228267 | validation: 0.007964473501057268]
	TIME [epoch: 8.26 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008943481747056102		[learning rate: 0.008609]
	Learning Rate: 0.00860896
	LOSS [training: 0.008943481747056102 | validation: 0.0057253883699642134]
	TIME [epoch: 8.25 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017110221077110774		[learning rate: 0.0085926]
	Learning Rate: 0.0085926
	LOSS [training: 0.017110221077110774 | validation: 0.0063201791750826675]
	TIME [epoch: 8.26 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006674117474806166		[learning rate: 0.0085762]
	Learning Rate: 0.00857624
	LOSS [training: 0.006674117474806166 | validation: 0.01379107543964665]
	TIME [epoch: 8.29 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013044286723848598		[learning rate: 0.0085599]
	Learning Rate: 0.00855989
	LOSS [training: 0.013044286723848598 | validation: 0.01604194655004007]
	TIME [epoch: 8.26 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02385161638725407		[learning rate: 0.0085435]
	Learning Rate: 0.00854354
	LOSS [training: 0.02385161638725407 | validation: 0.015195082767493526]
	TIME [epoch: 8.26 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011684178736209755		[learning rate: 0.0085272]
	Learning Rate: 0.00852719
	LOSS [training: 0.011684178736209755 | validation: 0.013807630741225645]
	TIME [epoch: 8.26 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007178315984714205		[learning rate: 0.0085108]
	Learning Rate: 0.00851085
	LOSS [training: 0.007178315984714205 | validation: 0.014832796566315434]
	TIME [epoch: 8.25 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008396093329155585		[learning rate: 0.0084945]
	Learning Rate: 0.00849451
	LOSS [training: 0.008396093329155585 | validation: 0.009387487302427312]
	TIME [epoch: 8.29 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013510642970434463		[learning rate: 0.0084782]
	Learning Rate: 0.00847817
	LOSS [training: 0.013510642970434463 | validation: 0.010711785642120424]
	TIME [epoch: 8.26 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006643848765402577		[learning rate: 0.0084618]
	Learning Rate: 0.00846184
	LOSS [training: 0.006643848765402577 | validation: 0.01888869706064293]
	TIME [epoch: 8.26 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014352088593151843		[learning rate: 0.0084455]
	Learning Rate: 0.00844552
	LOSS [training: 0.014352088593151843 | validation: 0.015436719384645461]
	TIME [epoch: 8.26 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006944520544735379		[learning rate: 0.0084292]
	Learning Rate: 0.0084292
	LOSS [training: 0.006944520544735379 | validation: 0.008023224486168786]
	TIME [epoch: 8.26 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010175695744163167		[learning rate: 0.0084129]
	Learning Rate: 0.00841288
	LOSS [training: 0.010175695744163167 | validation: 0.018472205646436052]
	TIME [epoch: 8.26 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008129845397148857		[learning rate: 0.0083966]
	Learning Rate: 0.00839657
	LOSS [training: 0.008129845397148857 | validation: 0.020696021462699443]
	TIME [epoch: 8.29 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014269862135755228		[learning rate: 0.0083803]
	Learning Rate: 0.00838026
	LOSS [training: 0.014269862135755228 | validation: 0.008588745475379658]
	TIME [epoch: 8.26 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0039283442367820855		[learning rate: 0.008364]
	Learning Rate: 0.00836395
	LOSS [training: 0.0039283442367820855 | validation: 0.009680334761130092]
	TIME [epoch: 8.26 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008924186503060219		[learning rate: 0.0083477]
	Learning Rate: 0.00834765
	LOSS [training: 0.008924186503060219 | validation: 0.013200436328236495]
	TIME [epoch: 8.27 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018594678863045576		[learning rate: 0.0083314]
	Learning Rate: 0.00833136
	LOSS [training: 0.018594678863045576 | validation: 0.014671910425864472]
	TIME [epoch: 8.27 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006922770081603542		[learning rate: 0.0083151]
	Learning Rate: 0.00831507
	LOSS [training: 0.006922770081603542 | validation: 0.007393452281108551]
	TIME [epoch: 8.31 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009151645760920962		[learning rate: 0.0082988]
	Learning Rate: 0.00829878
	LOSS [training: 0.009151645760920962 | validation: 0.08368557132677004]
	TIME [epoch: 8.28 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029026905397206572		[learning rate: 0.0082825]
	Learning Rate: 0.0082825
	LOSS [training: 0.029026905397206572 | validation: 0.017217222440834706]
	TIME [epoch: 8.27 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00873629144145399		[learning rate: 0.0082662]
	Learning Rate: 0.00826622
	LOSS [training: 0.00873629144145399 | validation: 0.014213750990343676]
	TIME [epoch: 8.27 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00862951574550299		[learning rate: 0.0082499]
	Learning Rate: 0.00824995
	LOSS [training: 0.00862951574550299 | validation: 0.016783503775878103]
	TIME [epoch: 8.27 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008385159700318858		[learning rate: 0.0082337]
	Learning Rate: 0.00823368
	LOSS [training: 0.008385159700318858 | validation: 0.030343303634551795]
	TIME [epoch: 8.27 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010296555081336778		[learning rate: 0.0082174]
	Learning Rate: 0.00821742
	LOSS [training: 0.010296555081336778 | validation: 0.0134855148152776]
	TIME [epoch: 8.31 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010674057426093845		[learning rate: 0.0082012]
	Learning Rate: 0.00820116
	LOSS [training: 0.010674057426093845 | validation: 0.010339005574182016]
	TIME [epoch: 8.27 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006072302570830831		[learning rate: 0.0081849]
	Learning Rate: 0.00818491
	LOSS [training: 0.006072302570830831 | validation: 0.007141731333144945]
	TIME [epoch: 8.27 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006539630312590208		[learning rate: 0.0081687]
	Learning Rate: 0.00816866
	LOSS [training: 0.006539630312590208 | validation: 0.011308319622490834]
	TIME [epoch: 8.27 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019958597986611308		[learning rate: 0.0081524]
	Learning Rate: 0.00815242
	LOSS [training: 0.019958597986611308 | validation: 0.02759186630727039]
	TIME [epoch: 8.27 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00880724373619719		[learning rate: 0.0081362]
	Learning Rate: 0.00813618
	LOSS [training: 0.00880724373619719 | validation: 0.018908986760334593]
	TIME [epoch: 8.31 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013486810568869655		[learning rate: 0.00812]
	Learning Rate: 0.00811995
	LOSS [training: 0.013486810568869655 | validation: 0.020069489684677352]
	TIME [epoch: 8.28 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005856490088377319		[learning rate: 0.0081037]
	Learning Rate: 0.00810372
	LOSS [training: 0.005856490088377319 | validation: 0.005513003847210345]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_1116.pth
	Model improved!!!
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004045604219663772		[learning rate: 0.0080875]
	Learning Rate: 0.0080875
	LOSS [training: 0.004045604219663772 | validation: 0.006550214761501862]
	TIME [epoch: 8.27 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00892447319941804		[learning rate: 0.0080713]
	Learning Rate: 0.00807128
	LOSS [training: 0.00892447319941804 | validation: 0.014292617814212732]
	TIME [epoch: 8.26 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015363706629613188		[learning rate: 0.0080551]
	Learning Rate: 0.00805507
	LOSS [training: 0.015363706629613188 | validation: 0.006545859628591953]
	TIME [epoch: 8.27 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007402390428935479		[learning rate: 0.0080389]
	Learning Rate: 0.00803887
	LOSS [training: 0.007402390428935479 | validation: 0.008707324719647762]
	TIME [epoch: 8.3 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011282717671039312		[learning rate: 0.0080227]
	Learning Rate: 0.00802267
	LOSS [training: 0.011282717671039312 | validation: 0.016545745235547363]
	TIME [epoch: 8.26 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010477484975494914		[learning rate: 0.0080065]
	Learning Rate: 0.00800647
	LOSS [training: 0.010477484975494914 | validation: 0.014077468103553124]
	TIME [epoch: 8.26 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01120557311141064		[learning rate: 0.0079903]
	Learning Rate: 0.00799028
	LOSS [training: 0.01120557311141064 | validation: 0.007890833237809104]
	TIME [epoch: 8.26 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004774508391804433		[learning rate: 0.0079741]
	Learning Rate: 0.0079741
	LOSS [training: 0.004774508391804433 | validation: 0.008933804796315434]
	TIME [epoch: 8.26 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015434573123883487		[learning rate: 0.0079579]
	Learning Rate: 0.00795792
	LOSS [training: 0.015434573123883487 | validation: 0.012136775220867528]
	TIME [epoch: 8.3 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006493567067975033		[learning rate: 0.0079417]
	Learning Rate: 0.00794174
	LOSS [training: 0.006493567067975033 | validation: 0.010074124643655324]
	TIME [epoch: 8.27 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007997408069606964		[learning rate: 0.0079256]
	Learning Rate: 0.00792558
	LOSS [training: 0.007997408069606964 | validation: 0.0057292738030736805]
	TIME [epoch: 8.26 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007835531041213113		[learning rate: 0.0079094]
	Learning Rate: 0.00790941
	LOSS [training: 0.007835531041213113 | validation: 0.01611516261815465]
	TIME [epoch: 8.26 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009936667233814745		[learning rate: 0.0078933]
	Learning Rate: 0.00789326
	LOSS [training: 0.009936667233814745 | validation: 0.007416316989490477]
	TIME [epoch: 8.26 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0072106315228834235		[learning rate: 0.0078771]
	Learning Rate: 0.00787711
	LOSS [training: 0.0072106315228834235 | validation: 0.014285724033028298]
	TIME [epoch: 8.26 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010211478500791224		[learning rate: 0.007861]
	Learning Rate: 0.00786096
	LOSS [training: 0.010211478500791224 | validation: 0.007012197206262763]
	TIME [epoch: 8.31 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005869186849906102		[learning rate: 0.0078448]
	Learning Rate: 0.00784482
	LOSS [training: 0.005869186849906102 | validation: 0.011609874760438618]
	TIME [epoch: 8.27 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009395328819370597		[learning rate: 0.0078287]
	Learning Rate: 0.00782869
	LOSS [training: 0.009395328819370597 | validation: 0.0062297683752992475]
	TIME [epoch: 8.26 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008164104164287218		[learning rate: 0.0078126]
	Learning Rate: 0.00781256
	LOSS [training: 0.008164104164287218 | validation: 0.014430812765299528]
	TIME [epoch: 8.26 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010158683997613714		[learning rate: 0.0077964]
	Learning Rate: 0.00779644
	LOSS [training: 0.010158683997613714 | validation: 0.011537060677028838]
	TIME [epoch: 8.26 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010420226003663921		[learning rate: 0.0077803]
	Learning Rate: 0.00778033
	LOSS [training: 0.010420226003663921 | validation: 0.013108789494924042]
	TIME [epoch: 8.28 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006719360670134719		[learning rate: 0.0077642]
	Learning Rate: 0.00776422
	LOSS [training: 0.006719360670134719 | validation: 0.00792825592382342]
	TIME [epoch: 8.29 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010033330388181964		[learning rate: 0.0077481]
	Learning Rate: 0.00774812
	LOSS [training: 0.010033330388181964 | validation: 0.013018259495519728]
	TIME [epoch: 8.26 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007023820447849109		[learning rate: 0.007732]
	Learning Rate: 0.00773202
	LOSS [training: 0.007023820447849109 | validation: 0.016182365773405073]
	TIME [epoch: 8.26 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009715455828885876		[learning rate: 0.0077159]
	Learning Rate: 0.00771593
	LOSS [training: 0.009715455828885876 | validation: 0.03191448478782523]
	TIME [epoch: 8.26 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015241185681357678		[learning rate: 0.0076998]
	Learning Rate: 0.00769985
	LOSS [training: 0.015241185681357678 | validation: 0.01333245341361081]
	TIME [epoch: 8.26 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006485374030052891		[learning rate: 0.0076838]
	Learning Rate: 0.00768377
	LOSS [training: 0.006485374030052891 | validation: 0.018930359372198557]
	TIME [epoch: 8.3 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00700483949349451		[learning rate: 0.0076677]
	Learning Rate: 0.0076677
	LOSS [training: 0.00700483949349451 | validation: 0.016821783127669628]
	TIME [epoch: 8.27 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014045178246170954		[learning rate: 0.0076516]
	Learning Rate: 0.00765163
	LOSS [training: 0.014045178246170954 | validation: 0.014467005865511997]
	TIME [epoch: 8.26 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00527483624985479		[learning rate: 0.0076356]
	Learning Rate: 0.00763557
	LOSS [training: 0.00527483624985479 | validation: 0.010250670197491492]
	TIME [epoch: 8.26 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0068860605463259734		[learning rate: 0.0076195]
	Learning Rate: 0.00761952
	LOSS [training: 0.0068860605463259734 | validation: 0.014254394276468003]
	TIME [epoch: 8.26 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007910230351537798		[learning rate: 0.0076035]
	Learning Rate: 0.00760347
	LOSS [training: 0.007910230351537798 | validation: 0.017795076953521196]
	TIME [epoch: 8.27 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01665469359922138		[learning rate: 0.0075874]
	Learning Rate: 0.00758744
	LOSS [training: 0.01665469359922138 | validation: 0.009364675855923514]
	TIME [epoch: 8.3 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009114527867704343		[learning rate: 0.0075714]
	Learning Rate: 0.0075714
	LOSS [training: 0.009114527867704343 | validation: 0.0189774479651419]
	TIME [epoch: 8.26 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011873973940357541		[learning rate: 0.0075554]
	Learning Rate: 0.00755538
	LOSS [training: 0.011873973940357541 | validation: 0.007138708057779754]
	TIME [epoch: 8.26 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007607340556369492		[learning rate: 0.0075394]
	Learning Rate: 0.00753936
	LOSS [training: 0.007607340556369492 | validation: 0.007423210970241238]
	TIME [epoch: 8.26 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010673617833292248		[learning rate: 0.0075233]
	Learning Rate: 0.00752335
	LOSS [training: 0.010673617833292248 | validation: 0.012069220216522607]
	TIME [epoch: 8.26 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012731000114347166		[learning rate: 0.0075073]
	Learning Rate: 0.00750734
	LOSS [training: 0.012731000114347166 | validation: 0.006417527390789155]
	TIME [epoch: 8.3 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008716031611323881		[learning rate: 0.0074913]
	Learning Rate: 0.00749134
	LOSS [training: 0.008716031611323881 | validation: 0.007900012152529085]
	TIME [epoch: 8.27 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006437600483814214		[learning rate: 0.0074754]
	Learning Rate: 0.00747535
	LOSS [training: 0.006437600483814214 | validation: 0.008241957920372368]
	TIME [epoch: 8.26 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005434283738991517		[learning rate: 0.0074594]
	Learning Rate: 0.00745937
	LOSS [training: 0.005434283738991517 | validation: 0.007944095673208538]
	TIME [epoch: 8.26 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00924663633945739		[learning rate: 0.0074434]
	Learning Rate: 0.00744339
	LOSS [training: 0.00924663633945739 | validation: 0.013209063721185538]
	TIME [epoch: 8.26 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005391873052836604		[learning rate: 0.0074274]
	Learning Rate: 0.00742742
	LOSS [training: 0.005391873052836604 | validation: 0.004486859267304674]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_1158.pth
	Model improved!!!
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003635588710329185		[learning rate: 0.0074115]
	Learning Rate: 0.00741145
	LOSS [training: 0.003635588710329185 | validation: 0.004739803333163428]
	TIME [epoch: 8.3 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018219303372261336		[learning rate: 0.0073955]
	Learning Rate: 0.0073955
	LOSS [training: 0.018219303372261336 | validation: 0.018661727750119293]
	TIME [epoch: 8.26 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013467580727527325		[learning rate: 0.0073795]
	Learning Rate: 0.00737955
	LOSS [training: 0.013467580727527325 | validation: 0.011950709010650196]
	TIME [epoch: 8.26 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004220866835017356		[learning rate: 0.0073636]
	Learning Rate: 0.0073636
	LOSS [training: 0.004220866835017356 | validation: 0.007480532068898089]
	TIME [epoch: 8.26 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006226350398342229		[learning rate: 0.0073477]
	Learning Rate: 0.00734767
	LOSS [training: 0.006226350398342229 | validation: 0.014691910356690287]
	TIME [epoch: 8.26 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007255042167408057		[learning rate: 0.0073317]
	Learning Rate: 0.00733174
	LOSS [training: 0.007255042167408057 | validation: 0.007263033866236066]
	TIME [epoch: 8.29 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010399475760480118		[learning rate: 0.0073158]
	Learning Rate: 0.00731582
	LOSS [training: 0.010399475760480118 | validation: 0.00796184513684495]
	TIME [epoch: 8.27 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006605170543989717		[learning rate: 0.0072999]
	Learning Rate: 0.00729991
	LOSS [training: 0.006605170543989717 | validation: 0.012416677715973195]
	TIME [epoch: 8.26 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006182198299195716		[learning rate: 0.007284]
	Learning Rate: 0.007284
	LOSS [training: 0.006182198299195716 | validation: 0.00674663435352009]
	TIME [epoch: 8.25 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005246856237859284		[learning rate: 0.0072681]
	Learning Rate: 0.0072681
	LOSS [training: 0.005246856237859284 | validation: 0.018102773370902825]
	TIME [epoch: 8.26 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012213485268419238		[learning rate: 0.0072522]
	Learning Rate: 0.00725221
	LOSS [training: 0.012213485268419238 | validation: 0.008176274275725188]
	TIME [epoch: 8.26 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006697955670443014		[learning rate: 0.0072363]
	Learning Rate: 0.00723633
	LOSS [training: 0.006697955670443014 | validation: 0.009568600074518843]
	TIME [epoch: 8.29 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00589797626923892		[learning rate: 0.0072205]
	Learning Rate: 0.00722045
	LOSS [training: 0.00589797626923892 | validation: 0.014499146881380123]
	TIME [epoch: 8.26 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007605887416510434		[learning rate: 0.0072046]
	Learning Rate: 0.00720458
	LOSS [training: 0.007605887416510434 | validation: 0.011476373259317642]
	TIME [epoch: 8.26 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009693437607278284		[learning rate: 0.0071887]
	Learning Rate: 0.00718872
	LOSS [training: 0.009693437607278284 | validation: 0.009576046721208094]
	TIME [epoch: 8.25 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007043686857128957		[learning rate: 0.0071729]
	Learning Rate: 0.00717287
	LOSS [training: 0.007043686857128957 | validation: 0.014586165360877822]
	TIME [epoch: 8.26 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015278397757946626		[learning rate: 0.007157]
	Learning Rate: 0.00715702
	LOSS [training: 0.015278397757946626 | validation: 0.017281536967755022]
	TIME [epoch: 8.3 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007984837605983175		[learning rate: 0.0071412]
	Learning Rate: 0.00714119
	LOSS [training: 0.007984837605983175 | validation: 0.01337838995486713]
	TIME [epoch: 8.26 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006569922226592292		[learning rate: 0.0071254]
	Learning Rate: 0.00712536
	LOSS [training: 0.006569922226592292 | validation: 0.011009150567525054]
	TIME [epoch: 8.26 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005489468470082266		[learning rate: 0.0071095]
	Learning Rate: 0.00710954
	LOSS [training: 0.005489468470082266 | validation: 0.00972228635213496]
	TIME [epoch: 8.26 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008539349239087574		[learning rate: 0.0070937]
	Learning Rate: 0.00709372
	LOSS [training: 0.008539349239087574 | validation: 0.011557911863887098]
	TIME [epoch: 8.26 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005339521713066502		[learning rate: 0.0070779]
	Learning Rate: 0.00707792
	LOSS [training: 0.005339521713066502 | validation: 0.00999171524332176]
	TIME [epoch: 8.26 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004752283821734307		[learning rate: 0.0070621]
	Learning Rate: 0.00706212
	LOSS [training: 0.004752283821734307 | validation: 0.008818026431351973]
	TIME [epoch: 8.3 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010612981029951382		[learning rate: 0.0070463]
	Learning Rate: 0.00704633
	LOSS [training: 0.010612981029951382 | validation: 0.020662837097005643]
	TIME [epoch: 8.26 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01158032509641005		[learning rate: 0.0070305]
	Learning Rate: 0.00703055
	LOSS [training: 0.01158032509641005 | validation: 0.0075736497746594095]
	TIME [epoch: 8.26 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003629247350980934		[learning rate: 0.0070148]
	Learning Rate: 0.00701477
	LOSS [training: 0.003629247350980934 | validation: 0.006912073872843661]
	TIME [epoch: 8.26 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00651003594791473		[learning rate: 0.006999]
	Learning Rate: 0.00699901
	LOSS [training: 0.00651003594791473 | validation: 0.008852761482739087]
	TIME [epoch: 8.26 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004838712397625589		[learning rate: 0.0069833]
	Learning Rate: 0.00698325
	LOSS [training: 0.004838712397625589 | validation: 0.029174680407908517]
	TIME [epoch: 8.28 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012597633612648545		[learning rate: 0.0069675]
	Learning Rate: 0.0069675
	LOSS [training: 0.012597633612648545 | validation: 0.00528485213888402]
	TIME [epoch: 8.29 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008943205521336723		[learning rate: 0.0069518]
	Learning Rate: 0.00695176
	LOSS [training: 0.008943205521336723 | validation: 0.03442261434669014]
	TIME [epoch: 8.26 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014792867227800897		[learning rate: 0.006936]
	Learning Rate: 0.00693603
	LOSS [training: 0.014792867227800897 | validation: 0.006449737254624558]
	TIME [epoch: 8.34 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003769647071196743		[learning rate: 0.0069203]
	Learning Rate: 0.0069203
	LOSS [training: 0.003769647071196743 | validation: 0.006661211093745517]
	TIME [epoch: 8.26 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0043616442983008		[learning rate: 0.0069046]
	Learning Rate: 0.00690459
	LOSS [training: 0.0043616442983008 | validation: 0.007313989462550165]
	TIME [epoch: 8.26 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009953902016784444		[learning rate: 0.0068889]
	Learning Rate: 0.00688888
	LOSS [training: 0.009953902016784444 | validation: 0.009660609133382628]
	TIME [epoch: 8.3 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007481006050973179		[learning rate: 0.0068732]
	Learning Rate: 0.00687318
	LOSS [training: 0.007481006050973179 | validation: 0.00999399233951245]
	TIME [epoch: 8.26 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009640970988954207		[learning rate: 0.0068575]
	Learning Rate: 0.00685749
	LOSS [training: 0.009640970988954207 | validation: 0.004370453627802019]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_1194.pth
	Model improved!!!
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004548803748107395		[learning rate: 0.0068418]
	Learning Rate: 0.00684181
	LOSS [training: 0.004548803748107395 | validation: 0.006245753074357686]
	TIME [epoch: 8.26 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004912310253714946		[learning rate: 0.0068261]
	Learning Rate: 0.00682614
	LOSS [training: 0.004912310253714946 | validation: 0.013038533847713389]
	TIME [epoch: 8.25 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009631920564876589		[learning rate: 0.0068105]
	Learning Rate: 0.00681048
	LOSS [training: 0.009631920564876589 | validation: 0.00491134279155754]
	TIME [epoch: 8.27 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033143370802341697		[learning rate: 0.0067948]
	Learning Rate: 0.00679482
	LOSS [training: 0.0033143370802341697 | validation: 0.00598175727949428]
	TIME [epoch: 8.28 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006399336358598944		[learning rate: 0.0067792]
	Learning Rate: 0.00677917
	LOSS [training: 0.006399336358598944 | validation: 0.006362058404202923]
	TIME [epoch: 8.25 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008368484872029062		[learning rate: 0.0067635]
	Learning Rate: 0.00676354
	LOSS [training: 0.008368484872029062 | validation: 0.022616489695931587]
	TIME [epoch: 8.26 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008155490083356988		[learning rate: 0.0067479]
	Learning Rate: 0.00674791
	LOSS [training: 0.008155490083356988 | validation: 0.006070614002182348]
	TIME [epoch: 8.26 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009000470406268325		[learning rate: 0.0067323]
	Learning Rate: 0.00673229
	LOSS [training: 0.009000470406268325 | validation: 0.012429547660953392]
	TIME [epoch: 8.26 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007231758425129813		[learning rate: 0.0067167]
	Learning Rate: 0.00671668
	LOSS [training: 0.007231758425129813 | validation: 0.013990226211410594]
	TIME [epoch: 8.29 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008321691175461582		[learning rate: 0.0067011]
	Learning Rate: 0.00670108
	LOSS [training: 0.008321691175461582 | validation: 0.010932818340470973]
	TIME [epoch: 8.26 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008773915334898784		[learning rate: 0.0066855]
	Learning Rate: 0.00668548
	LOSS [training: 0.008773915334898784 | validation: 0.0065896035853467635]
	TIME [epoch: 8.25 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0050900257706304325		[learning rate: 0.0066699]
	Learning Rate: 0.0066699
	LOSS [training: 0.0050900257706304325 | validation: 0.0073576475233977905]
	TIME [epoch: 8.25 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004709236714372544		[learning rate: 0.0066543]
	Learning Rate: 0.00665432
	LOSS [training: 0.004709236714372544 | validation: 0.01332059723773564]
	TIME [epoch: 8.25 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008308311924527783		[learning rate: 0.0066388]
	Learning Rate: 0.00663876
	LOSS [training: 0.008308311924527783 | validation: 0.009193267604223314]
	TIME [epoch: 8.26 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0050268270610038255		[learning rate: 0.0066232]
	Learning Rate: 0.0066232
	LOSS [training: 0.0050268270610038255 | validation: 0.00433283078100912]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_1209.pth
	Model improved!!!
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005259902230055189		[learning rate: 0.0066077]
	Learning Rate: 0.00660765
	LOSS [training: 0.005259902230055189 | validation: 0.008964623073031636]
	TIME [epoch: 8.25 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01359942374873745		[learning rate: 0.0065921]
	Learning Rate: 0.00659212
	LOSS [training: 0.01359942374873745 | validation: 0.015877027401752345]
	TIME [epoch: 8.25 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011577964026011444		[learning rate: 0.0065766]
	Learning Rate: 0.00657659
	LOSS [training: 0.011577964026011444 | validation: 0.013939761100831888]
	TIME [epoch: 8.26 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00579280110288047		[learning rate: 0.0065611]
	Learning Rate: 0.00656107
	LOSS [training: 0.00579280110288047 | validation: 0.010277944111560064]
	TIME [epoch: 8.25 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004895827935986011		[learning rate: 0.0065456]
	Learning Rate: 0.00654556
	LOSS [training: 0.004895827935986011 | validation: 0.010455183974138919]
	TIME [epoch: 8.29 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006829461315710324		[learning rate: 0.0065301]
	Learning Rate: 0.00653006
	LOSS [training: 0.006829461315710324 | validation: 0.008375925443702643]
	TIME [epoch: 8.26 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004742267564137697		[learning rate: 0.0065146]
	Learning Rate: 0.00651457
	LOSS [training: 0.004742267564137697 | validation: 0.016263053578574018]
	TIME [epoch: 8.26 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008520570445490351		[learning rate: 0.0064991]
	Learning Rate: 0.00649909
	LOSS [training: 0.008520570445490351 | validation: 0.010989501355637327]
	TIME [epoch: 8.26 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006235207582496585		[learning rate: 0.0064836]
	Learning Rate: 0.00648362
	LOSS [training: 0.006235207582496585 | validation: 0.010764442664313496]
	TIME [epoch: 8.26 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010597334556133636		[learning rate: 0.0064682]
	Learning Rate: 0.00646815
	LOSS [training: 0.010597334556133636 | validation: 0.00812284237129492]
	TIME [epoch: 8.26 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007691085293666915		[learning rate: 0.0064527]
	Learning Rate: 0.0064527
	LOSS [training: 0.007691085293666915 | validation: 0.011177333935003007]
	TIME [epoch: 8.3 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006416753237257924		[learning rate: 0.0064373]
	Learning Rate: 0.00643726
	LOSS [training: 0.006416753237257924 | validation: 0.006455384415165135]
	TIME [epoch: 8.26 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006669102699136524		[learning rate: 0.0064218]
	Learning Rate: 0.00642183
	LOSS [training: 0.006669102699136524 | validation: 0.0163052499984018]
	TIME [epoch: 8.26 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008490347081488785		[learning rate: 0.0064064]
	Learning Rate: 0.0064064
	LOSS [training: 0.008490347081488785 | validation: 0.006145270948625918]
	TIME [epoch: 8.26 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038254454074228873		[learning rate: 0.006391]
	Learning Rate: 0.00639099
	LOSS [training: 0.0038254454074228873 | validation: 0.006080675256124177]
	TIME [epoch: 8.26 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005852312975176193		[learning rate: 0.0063756]
	Learning Rate: 0.00637559
	LOSS [training: 0.005852312975176193 | validation: 0.009922837021069207]
	TIME [epoch: 8.29 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006693019745651687		[learning rate: 0.0063602]
	Learning Rate: 0.00636019
	LOSS [training: 0.006693019745651687 | validation: 0.007503333869992525]
	TIME [epoch: 8.27 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00761015404291139		[learning rate: 0.0063448]
	Learning Rate: 0.00634481
	LOSS [training: 0.00761015404291139 | validation: 0.0043094579135517916]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_1227.pth
	Model improved!!!
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0045619979339730984		[learning rate: 0.0063294]
	Learning Rate: 0.00632944
	LOSS [training: 0.0045619979339730984 | validation: 0.011725384279068815]
	TIME [epoch: 8.26 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007525294806611165		[learning rate: 0.0063141]
	Learning Rate: 0.00631407
	LOSS [training: 0.007525294806611165 | validation: 0.005345740486169671]
	TIME [epoch: 8.26 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034291509817103785		[learning rate: 0.0062987]
	Learning Rate: 0.00629872
	LOSS [training: 0.0034291509817103785 | validation: 0.04978539749993231]
	TIME [epoch: 8.27 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009519855947294006		[learning rate: 0.0062834]
	Learning Rate: 0.00628338
	LOSS [training: 0.009519855947294006 | validation: 0.013650110931160616]
	TIME [epoch: 8.29 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006808190892582108		[learning rate: 0.006268]
	Learning Rate: 0.00626804
	LOSS [training: 0.006808190892582108 | validation: 0.011466880696035672]
	TIME [epoch: 8.25 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00597829036073534		[learning rate: 0.0062527]
	Learning Rate: 0.00625272
	LOSS [training: 0.00597829036073534 | validation: 0.019748187676935484]
	TIME [epoch: 8.25 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010489336031930752		[learning rate: 0.0062374]
	Learning Rate: 0.00623741
	LOSS [training: 0.010489336031930752 | validation: 0.014704989629800432]
	TIME [epoch: 8.25 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0063632446709503306		[learning rate: 0.0062221]
	Learning Rate: 0.00622211
	LOSS [training: 0.0063632446709503306 | validation: 0.007406587887537343]
	TIME [epoch: 8.26 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036510640557488594		[learning rate: 0.0062068]
	Learning Rate: 0.00620681
	LOSS [training: 0.0036510640557488594 | validation: 0.008080994050720925]
	TIME [epoch: 8.29 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007981027975796117		[learning rate: 0.0061915]
	Learning Rate: 0.00619153
	LOSS [training: 0.007981027975796117 | validation: 0.012618079856069126]
	TIME [epoch: 8.26 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006472260855625456		[learning rate: 0.0061763]
	Learning Rate: 0.00617626
	LOSS [training: 0.006472260855625456 | validation: 0.009901705558564]
	TIME [epoch: 8.26 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009035182589081679		[learning rate: 0.006161]
	Learning Rate: 0.006161
	LOSS [training: 0.009035182589081679 | validation: 0.019237322449881994]
	TIME [epoch: 8.25 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010143103336567837		[learning rate: 0.0061458]
	Learning Rate: 0.00614575
	LOSS [training: 0.010143103336567837 | validation: 0.004515233466230163]
	TIME [epoch: 8.25 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006764071987089965		[learning rate: 0.0061305]
	Learning Rate: 0.00613051
	LOSS [training: 0.006764071987089965 | validation: 0.007743935737613941]
	TIME [epoch: 8.26 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0072176784711217145		[learning rate: 0.0061153]
	Learning Rate: 0.00611528
	LOSS [training: 0.0072176784711217145 | validation: 0.011580579101432028]
	TIME [epoch: 8.29 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005585289741801589		[learning rate: 0.0061001]
	Learning Rate: 0.00610007
	LOSS [training: 0.005585289741801589 | validation: 0.005436333204003666]
	TIME [epoch: 8.27 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005292646162805158		[learning rate: 0.0060849]
	Learning Rate: 0.00608486
	LOSS [training: 0.005292646162805158 | validation: 0.005036501718088966]
	TIME [epoch: 8.26 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003846475145216756		[learning rate: 0.0060697]
	Learning Rate: 0.00606966
	LOSS [training: 0.003846475145216756 | validation: 0.011396914810854513]
	TIME [epoch: 8.25 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009491329791023932		[learning rate: 0.0060545]
	Learning Rate: 0.00605447
	LOSS [training: 0.009491329791023932 | validation: 0.005403998744820024]
	TIME [epoch: 8.25 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003817804095714923		[learning rate: 0.0060393]
	Learning Rate: 0.0060393
	LOSS [training: 0.003817804095714923 | validation: 0.0060956163847369895]
	TIME [epoch: 8.28 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0047051673162391335		[learning rate: 0.0060241]
	Learning Rate: 0.00602413
	LOSS [training: 0.0047051673162391335 | validation: 0.009212907716866461]
	TIME [epoch: 8.28 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006485813411527545		[learning rate: 0.006009]
	Learning Rate: 0.00600898
	LOSS [training: 0.006485813411527545 | validation: 0.008051045016204033]
	TIME [epoch: 8.25 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00808389092495648		[learning rate: 0.0059938]
	Learning Rate: 0.00599384
	LOSS [training: 0.00808389092495648 | validation: 0.0042242932641217605]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_1250.pth
	Model improved!!!
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003059753439187032		[learning rate: 0.0059787]
	Learning Rate: 0.00597871
	LOSS [training: 0.003059753439187032 | validation: 0.006413808953127332]
	TIME [epoch: 8.27 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005311552308654899		[learning rate: 0.0059636]
	Learning Rate: 0.00596359
	LOSS [training: 0.005311552308654899 | validation: 0.017027448370093533]
	TIME [epoch: 8.27 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00721743452210819		[learning rate: 0.0059485]
	Learning Rate: 0.00594848
	LOSS [training: 0.00721743452210819 | validation: 0.00562349624184317]
	TIME [epoch: 8.31 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032954580056052995		[learning rate: 0.0059334]
	Learning Rate: 0.00593338
	LOSS [training: 0.0032954580056052995 | validation: 0.004453876938694322]
	TIME [epoch: 8.27 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008484419251543165		[learning rate: 0.0059183]
	Learning Rate: 0.00591829
	LOSS [training: 0.008484419251543165 | validation: 0.010289602468891636]
	TIME [epoch: 8.27 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006821007011717726		[learning rate: 0.0059032]
	Learning Rate: 0.00590321
	LOSS [training: 0.006821007011717726 | validation: 0.01090803808781006]
	TIME [epoch: 8.27 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006619330939028322		[learning rate: 0.0058881]
	Learning Rate: 0.00588815
	LOSS [training: 0.006619330939028322 | validation: 0.006931659645262293]
	TIME [epoch: 8.27 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004704430896971123		[learning rate: 0.0058731]
	Learning Rate: 0.00587309
	LOSS [training: 0.004704430896971123 | validation: 0.00654190807731106]
	TIME [epoch: 8.37 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004870833200401476		[learning rate: 0.0058581]
	Learning Rate: 0.00585805
	LOSS [training: 0.004870833200401476 | validation: 0.004592807830467882]
	TIME [epoch: 8.3 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003879690531708449		[learning rate: 0.005843]
	Learning Rate: 0.00584302
	LOSS [training: 0.003879690531708449 | validation: 0.00916464475836034]
	TIME [epoch: 8.34 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02484759722710792		[learning rate: 0.005828]
	Learning Rate: 0.005828
	LOSS [training: 0.02484759722710792 | validation: 0.017093824645101053]
	TIME [epoch: 8.27 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009144010972666471		[learning rate: 0.005813]
	Learning Rate: 0.00581299
	LOSS [training: 0.009144010972666471 | validation: 0.011102267248802936]
	TIME [epoch: 8.27 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0049200438250594026		[learning rate: 0.005798]
	Learning Rate: 0.005798
	LOSS [training: 0.0049200438250594026 | validation: 0.009912348188137509]
	TIME [epoch: 8.27 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004903053567704414		[learning rate: 0.005783]
	Learning Rate: 0.00578301
	LOSS [training: 0.004903053567704414 | validation: 0.009731725139651617]
	TIME [epoch: 8.32 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0048712951613567685		[learning rate: 0.005768]
	Learning Rate: 0.00576804
	LOSS [training: 0.0048712951613567685 | validation: 0.00881467089887581]
	TIME [epoch: 8.27 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006664404616338411		[learning rate: 0.0057531]
	Learning Rate: 0.00575307
	LOSS [training: 0.006664404616338411 | validation: 0.01295780623036201]
	TIME [epoch: 8.27 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005516128333524499		[learning rate: 0.0057381]
	Learning Rate: 0.00573812
	LOSS [training: 0.005516128333524499 | validation: 0.00872738780339479]
	TIME [epoch: 8.27 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005000611142116751		[learning rate: 0.0057232]
	Learning Rate: 0.00572318
	LOSS [training: 0.005000611142116751 | validation: 0.007311633322980149]
	TIME [epoch: 8.27 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004412533695433003		[learning rate: 0.0057083]
	Learning Rate: 0.00570826
	LOSS [training: 0.004412533695433003 | validation: 0.009326779136582947]
	TIME [epoch: 8.28 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006144584058497549		[learning rate: 0.0056933]
	Learning Rate: 0.00569334
	LOSS [training: 0.006144584058497549 | validation: 0.010221786057589163]
	TIME [epoch: 8.3 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006068445337584358		[learning rate: 0.0056784]
	Learning Rate: 0.00567844
	LOSS [training: 0.006068445337584358 | validation: 0.007225048201234884]
	TIME [epoch: 8.26 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004714120614953178		[learning rate: 0.0056635]
	Learning Rate: 0.00566355
	LOSS [training: 0.004714120614953178 | validation: 0.005564335193536605]
	TIME [epoch: 8.26 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004068740032554438		[learning rate: 0.0056487]
	Learning Rate: 0.00564867
	LOSS [training: 0.004068740032554438 | validation: 0.005449204977174446]
	TIME [epoch: 8.27 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009455608434851855		[learning rate: 0.0056338]
	Learning Rate: 0.0056338
	LOSS [training: 0.009455608434851855 | validation: 0.008236540980558564]
	TIME [epoch: 8.27 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0044862700040485285		[learning rate: 0.0056189]
	Learning Rate: 0.00561894
	LOSS [training: 0.0044862700040485285 | validation: 0.004974902984084056]
	TIME [epoch: 8.3 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005803770226741457		[learning rate: 0.0056041]
	Learning Rate: 0.0056041
	LOSS [training: 0.005803770226741457 | validation: 0.01011844875081369]
	TIME [epoch: 8.28 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004805321335582955		[learning rate: 0.0055893]
	Learning Rate: 0.00558927
	LOSS [training: 0.004805321335582955 | validation: 0.008019935020118047]
	TIME [epoch: 8.27 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004956830534286491		[learning rate: 0.0055744]
	Learning Rate: 0.00557445
	LOSS [training: 0.004956830534286491 | validation: 0.007572543375677415]
	TIME [epoch: 8.27 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005953697101236974		[learning rate: 0.0055596]
	Learning Rate: 0.00555964
	LOSS [training: 0.005953697101236974 | validation: 0.004803848909695237]
	TIME [epoch: 8.26 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008314657848497671		[learning rate: 0.0055448]
	Learning Rate: 0.00554484
	LOSS [training: 0.008314657848497671 | validation: 0.00588990004906553]
	TIME [epoch: 8.28 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006169235082105127		[learning rate: 0.0055301]
	Learning Rate: 0.00553006
	LOSS [training: 0.006169235082105127 | validation: 0.0032973910310256215]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_1281.pth
	Model improved!!!
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038476020015642595		[learning rate: 0.0055153]
	Learning Rate: 0.00551529
	LOSS [training: 0.0038476020015642595 | validation: 0.007269179056224615]
	TIME [epoch: 8.26 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005321388590676142		[learning rate: 0.0055005]
	Learning Rate: 0.00550053
	LOSS [training: 0.005321388590676142 | validation: 0.007953500728702259]
	TIME [epoch: 8.26 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009155830538914993		[learning rate: 0.0054858]
	Learning Rate: 0.00548578
	LOSS [training: 0.009155830538914993 | validation: 0.0055622374243375645]
	TIME [epoch: 8.26 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005095951718036798		[learning rate: 0.005471]
	Learning Rate: 0.00547105
	LOSS [training: 0.005095951718036798 | validation: 0.02621236575007469]
	TIME [epoch: 8.26 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010929743755084233		[learning rate: 0.0054563]
	Learning Rate: 0.00545632
	LOSS [training: 0.010929743755084233 | validation: 0.009248915786842534]
	TIME [epoch: 8.3 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005062242823159585		[learning rate: 0.0054416]
	Learning Rate: 0.00544161
	LOSS [training: 0.005062242823159585 | validation: 0.008212749358580188]
	TIME [epoch: 8.27 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00655430927256715		[learning rate: 0.0054269]
	Learning Rate: 0.00542692
	LOSS [training: 0.00655430927256715 | validation: 0.008990819069468584]
	TIME [epoch: 8.26 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008131497228484386		[learning rate: 0.0054122]
	Learning Rate: 0.00541223
	LOSS [training: 0.008131497228484386 | validation: 0.011939357457328086]
	TIME [epoch: 8.26 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004416441922225861		[learning rate: 0.0053976]
	Learning Rate: 0.00539756
	LOSS [training: 0.004416441922225861 | validation: 0.007951159758504519]
	TIME [epoch: 8.26 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004613162105752666		[learning rate: 0.0053829]
	Learning Rate: 0.0053829
	LOSS [training: 0.004613162105752666 | validation: 0.010751393985719305]
	TIME [epoch: 8.26 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005499266314106856		[learning rate: 0.0053683]
	Learning Rate: 0.00536825
	LOSS [training: 0.005499266314106856 | validation: 0.008272522792755348]
	TIME [epoch: 8.29 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004560497960857891		[learning rate: 0.0053536]
	Learning Rate: 0.00535362
	LOSS [training: 0.004560497960857891 | validation: 0.009098149838217363]
	TIME [epoch: 8.26 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0052049155380207756		[learning rate: 0.005339]
	Learning Rate: 0.005339
	LOSS [training: 0.0052049155380207756 | validation: 0.006818637973012744]
	TIME [epoch: 8.26 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005052227950174746		[learning rate: 0.0053244]
	Learning Rate: 0.00532439
	LOSS [training: 0.005052227950174746 | validation: 0.006287322083064055]
	TIME [epoch: 8.26 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005667596977239913		[learning rate: 0.0053098]
	Learning Rate: 0.00530979
	LOSS [training: 0.005667596977239913 | validation: 0.007045086869238792]
	TIME [epoch: 8.26 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00477273681467273		[learning rate: 0.0052952]
	Learning Rate: 0.00529521
	LOSS [training: 0.00477273681467273 | validation: 0.0056394803907644205]
	TIME [epoch: 8.29 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003496755765111481		[learning rate: 0.0052806]
	Learning Rate: 0.00528064
	LOSS [training: 0.003496755765111481 | validation: 0.00854503230064203]
	TIME [epoch: 8.26 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007459688143843707		[learning rate: 0.0052661]
	Learning Rate: 0.00526608
	LOSS [training: 0.007459688143843707 | validation: 0.0068775696241130824]
	TIME [epoch: 8.26 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00372749097905246		[learning rate: 0.0052515]
	Learning Rate: 0.00525154
	LOSS [training: 0.00372749097905246 | validation: 0.003996902374696989]
	TIME [epoch: 8.26 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004316491595127446		[learning rate: 0.005237]
	Learning Rate: 0.00523701
	LOSS [training: 0.004316491595127446 | validation: 0.009571515680661637]
	TIME [epoch: 8.26 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006578731133646561		[learning rate: 0.0052225]
	Learning Rate: 0.00522249
	LOSS [training: 0.006578731133646561 | validation: 0.004320824574854058]
	TIME [epoch: 8.26 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003998358947842253		[learning rate: 0.005208]
	Learning Rate: 0.00520799
	LOSS [training: 0.003998358947842253 | validation: 0.020775784739067653]
	TIME [epoch: 8.29 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008120279825242665		[learning rate: 0.0051935]
	Learning Rate: 0.00519349
	LOSS [training: 0.008120279825242665 | validation: 0.008420054198348782]
	TIME [epoch: 8.26 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006921207056845879		[learning rate: 0.005179]
	Learning Rate: 0.00517901
	LOSS [training: 0.006921207056845879 | validation: 0.009049100114700802]
	TIME [epoch: 8.25 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005025268192202014		[learning rate: 0.0051645]
	Learning Rate: 0.00516455
	LOSS [training: 0.005025268192202014 | validation: 0.007514898109776996]
	TIME [epoch: 8.25 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004795352872608332		[learning rate: 0.0051501]
	Learning Rate: 0.0051501
	LOSS [training: 0.004795352872608332 | validation: 0.006154878689604581]
	TIME [epoch: 8.26 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00577300002545966		[learning rate: 0.0051357]
	Learning Rate: 0.00513566
	LOSS [training: 0.00577300002545966 | validation: 0.005617406375600502]
	TIME [epoch: 8.29 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035682712801285003		[learning rate: 0.0051212]
	Learning Rate: 0.00512123
	LOSS [training: 0.0035682712801285003 | validation: 0.0057428866011045784]
	TIME [epoch: 8.27 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035113540594917583		[learning rate: 0.0051068]
	Learning Rate: 0.00510682
	LOSS [training: 0.0035113540594917583 | validation: 0.005141966693385367]
	TIME [epoch: 8.26 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004142168924690088		[learning rate: 0.0050924]
	Learning Rate: 0.00509242
	LOSS [training: 0.004142168924690088 | validation: 0.017339924336695157]
	TIME [epoch: 8.26 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008102745036008024		[learning rate: 0.005078]
	Learning Rate: 0.00507803
	LOSS [training: 0.008102745036008024 | validation: 0.006862845654786561]
	TIME [epoch: 8.26 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029281136472677043		[learning rate: 0.0050637]
	Learning Rate: 0.00506366
	LOSS [training: 0.0029281136472677043 | validation: 0.006561156649931869]
	TIME [epoch: 8.26 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005829049805978603		[learning rate: 0.0050493]
	Learning Rate: 0.0050493
	LOSS [training: 0.005829049805978603 | validation: 0.008138556749190144]
	TIME [epoch: 8.29 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004069244471729206		[learning rate: 0.005035]
	Learning Rate: 0.00503496
	LOSS [training: 0.004069244471729206 | validation: 0.0040525558931885355]
	TIME [epoch: 8.26 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004408180361863743		[learning rate: 0.0050206]
	Learning Rate: 0.00502063
	LOSS [training: 0.004408180361863743 | validation: 0.012360300415616508]
	TIME [epoch: 8.26 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006045886515464106		[learning rate: 0.0050063]
	Learning Rate: 0.00500631
	LOSS [training: 0.006045886515464106 | validation: 0.007659582913622422]
	TIME [epoch: 8.26 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003933146775932575		[learning rate: 0.004992]
	Learning Rate: 0.004992
	LOSS [training: 0.003933146775932575 | validation: 0.009562321277823976]
	TIME [epoch: 8.26 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0055333289780038365		[learning rate: 0.0049777]
	Learning Rate: 0.00497771
	LOSS [training: 0.0055333289780038365 | validation: 0.0072173421264804605]
	TIME [epoch: 8.28 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004631248172575748		[learning rate: 0.0049634]
	Learning Rate: 0.00496344
	LOSS [training: 0.004631248172575748 | validation: 0.005808485383118204]
	TIME [epoch: 8.28 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003148363041258748		[learning rate: 0.0049492]
	Learning Rate: 0.00494917
	LOSS [training: 0.003148363041258748 | validation: 0.006602788615656662]
	TIME [epoch: 8.26 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005252150355153006		[learning rate: 0.0049349]
	Learning Rate: 0.00493492
	LOSS [training: 0.005252150355153006 | validation: 0.008644347375932804]
	TIME [epoch: 8.26 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006385410110213347		[learning rate: 0.0049207]
	Learning Rate: 0.00492069
	LOSS [training: 0.006385410110213347 | validation: 0.005288909464292047]
	TIME [epoch: 8.25 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006421479908687706		[learning rate: 0.0049065]
	Learning Rate: 0.00490647
	LOSS [training: 0.006421479908687706 | validation: 0.008348116101854028]
	TIME [epoch: 8.26 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034091768277767676		[learning rate: 0.0048923]
	Learning Rate: 0.00489226
	LOSS [training: 0.0034091768277767676 | validation: 0.005731717236352355]
	TIME [epoch: 8.3 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003563376676116203		[learning rate: 0.0048781]
	Learning Rate: 0.00487807
	LOSS [training: 0.003563376676116203 | validation: 0.007924030386651753]
	TIME [epoch: 8.26 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005068916365719956		[learning rate: 0.0048639]
	Learning Rate: 0.00486389
	LOSS [training: 0.005068916365719956 | validation: 0.0061664688863713535]
	TIME [epoch: 8.25 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00326123411814432		[learning rate: 0.0048497]
	Learning Rate: 0.00484972
	LOSS [training: 0.00326123411814432 | validation: 0.005746265908895605]
	TIME [epoch: 8.26 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004684795452738433		[learning rate: 0.0048356]
	Learning Rate: 0.00483557
	LOSS [training: 0.004684795452738433 | validation: 0.007750056595238652]
	TIME [epoch: 8.26 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005407921208473204		[learning rate: 0.0048214]
	Learning Rate: 0.00482143
	LOSS [training: 0.005407921208473204 | validation: 0.005460008210194678]
	TIME [epoch: 8.28 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003306633428545314		[learning rate: 0.0048073]
	Learning Rate: 0.00480731
	LOSS [training: 0.003306633428545314 | validation: 0.005689772413907931]
	TIME [epoch: 8.28 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004787322840317475		[learning rate: 0.0047932]
	Learning Rate: 0.0047932
	LOSS [training: 0.004787322840317475 | validation: 0.0069332524093326225]
	TIME [epoch: 8.26 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004769792131249836		[learning rate: 0.0047791]
	Learning Rate: 0.0047791
	LOSS [training: 0.004769792131249836 | validation: 0.00350213360979669]
	TIME [epoch: 8.26 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002575234413346508		[learning rate: 0.004765]
	Learning Rate: 0.00476502
	LOSS [training: 0.002575234413346508 | validation: 0.003882048076984187]
	TIME [epoch: 8.26 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037204600565313127		[learning rate: 0.004751]
	Learning Rate: 0.00475096
	LOSS [training: 0.0037204600565313127 | validation: 0.007414435688553505]
	TIME [epoch: 8.25 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005568860808061656		[learning rate: 0.0047369]
	Learning Rate: 0.00473691
	LOSS [training: 0.005568860808061656 | validation: 0.004096226730803282]
	TIME [epoch: 8.3 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004417282774477547		[learning rate: 0.0047229]
	Learning Rate: 0.00472287
	LOSS [training: 0.004417282774477547 | validation: 0.004991655169009049]
	TIME [epoch: 8.26 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007151352178797773		[learning rate: 0.0047088]
	Learning Rate: 0.00470885
	LOSS [training: 0.007151352178797773 | validation: 0.013888004073471686]
	TIME [epoch: 8.26 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030652585810402836		[learning rate: 0.0046948]
	Learning Rate: 0.00469484
	LOSS [training: 0.0030652585810402836 | validation: 0.002715518769194379]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_1339.pth
	Model improved!!!
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0049795643878637365		[learning rate: 0.0046808]
	Learning Rate: 0.00468084
	LOSS [training: 0.0049795643878637365 | validation: 0.005163584841095825]
	TIME [epoch: 8.26 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005690862676575129		[learning rate: 0.0046669]
	Learning Rate: 0.00466686
	LOSS [training: 0.005690862676575129 | validation: 0.01251798752301323]
	TIME [epoch: 8.28 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006320672350005852		[learning rate: 0.0046529]
	Learning Rate: 0.0046529
	LOSS [training: 0.006320672350005852 | validation: 0.005730442781978507]
	TIME [epoch: 8.28 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003630076609529068		[learning rate: 0.0046389]
	Learning Rate: 0.00463895
	LOSS [training: 0.003630076609529068 | validation: 0.0031533813456760644]
	TIME [epoch: 8.26 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002390754943450868		[learning rate: 0.004625]
	Learning Rate: 0.00462501
	LOSS [training: 0.002390754943450868 | validation: 0.0035180321681253933]
	TIME [epoch: 8.26 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004252073073566774		[learning rate: 0.0046111]
	Learning Rate: 0.00461109
	LOSS [training: 0.004252073073566774 | validation: 0.009533149758311397]
	TIME [epoch: 8.25 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004664763866556638		[learning rate: 0.0045972]
	Learning Rate: 0.00459719
	LOSS [training: 0.004664763866556638 | validation: 0.007502097151453813]
	TIME [epoch: 8.26 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005915720720425639		[learning rate: 0.0045833]
	Learning Rate: 0.0045833
	LOSS [training: 0.005915720720425639 | validation: 0.009682884258482813]
	TIME [epoch: 8.29 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005212571218261994		[learning rate: 0.0045694]
	Learning Rate: 0.00456942
	LOSS [training: 0.005212571218261994 | validation: 0.00498079535872394]
	TIME [epoch: 8.26 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028033817395795384		[learning rate: 0.0045556]
	Learning Rate: 0.00455556
	LOSS [training: 0.0028033817395795384 | validation: 0.003237837427377369]
	TIME [epoch: 8.26 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037775198419361944		[learning rate: 0.0045417]
	Learning Rate: 0.00454171
	LOSS [training: 0.0037775198419361944 | validation: 0.05177906268510036]
	TIME [epoch: 8.26 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005352117954764185		[learning rate: 0.0045279]
	Learning Rate: 0.00452788
	LOSS [training: 0.005352117954764185 | validation: 0.006528300174094396]
	TIME [epoch: 8.26 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004527343571473123		[learning rate: 0.0045141]
	Learning Rate: 0.00451406
	LOSS [training: 0.004527343571473123 | validation: 0.0056095932770217115]
	TIME [epoch: 8.26 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033308565908124945		[learning rate: 0.0045003]
	Learning Rate: 0.00450026
	LOSS [training: 0.0033308565908124945 | validation: 0.0057987786926857144]
	TIME [epoch: 8.29 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0052731718651642286		[learning rate: 0.0044865]
	Learning Rate: 0.00448648
	LOSS [training: 0.0052731718651642286 | validation: 0.00956179096360803]
	TIME [epoch: 8.26 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00428496605160994		[learning rate: 0.0044727]
	Learning Rate: 0.0044727
	LOSS [training: 0.00428496605160994 | validation: 0.003469285115661196]
	TIME [epoch: 8.25 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0044142241116066445		[learning rate: 0.0044589]
	Learning Rate: 0.00445895
	LOSS [training: 0.0044142241116066445 | validation: 0.005515360207996571]
	TIME [epoch: 8.25 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008264507118511961		[learning rate: 0.0044452]
	Learning Rate: 0.00444521
	LOSS [training: 0.008264507118511961 | validation: 0.0029941836199188785]
	TIME [epoch: 8.25 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002848470764556402		[learning rate: 0.0044315]
	Learning Rate: 0.00443148
	LOSS [training: 0.002848470764556402 | validation: 0.005565765434080241]
	TIME [epoch: 8.29 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029245725244479055		[learning rate: 0.0044178]
	Learning Rate: 0.00441777
	LOSS [training: 0.0029245725244479055 | validation: 0.010305706120727865]
	TIME [epoch: 8.27 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029031268108693		[learning rate: 0.0044041]
	Learning Rate: 0.00440407
	LOSS [training: 0.0029031268108693 | validation: 0.004077383362731977]
	TIME [epoch: 8.25 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024459963069929217		[learning rate: 0.0043904]
	Learning Rate: 0.00439039
	LOSS [training: 0.0024459963069929217 | validation: 0.007722935092928456]
	TIME [epoch: 8.26 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005986387566687945		[learning rate: 0.0043767]
	Learning Rate: 0.00437673
	LOSS [training: 0.005986387566687945 | validation: 0.004283986152589055]
	TIME [epoch: 8.26 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027616668384454926		[learning rate: 0.0043631]
	Learning Rate: 0.00436308
	LOSS [training: 0.0027616668384454926 | validation: 0.006664799095537483]
	TIME [epoch: 8.26 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003656717752384529		[learning rate: 0.0043494]
	Learning Rate: 0.00434945
	LOSS [training: 0.003656717752384529 | validation: 0.003623838175953674]
	TIME [epoch: 8.3 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004621692817404155		[learning rate: 0.0043358]
	Learning Rate: 0.00433583
	LOSS [training: 0.004621692817404155 | validation: 0.015215067157943216]
	TIME [epoch: 8.26 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007458614370346825		[learning rate: 0.0043222]
	Learning Rate: 0.00432222
	LOSS [training: 0.007458614370346825 | validation: 0.022796129307612042]
	TIME [epoch: 8.26 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010207857625283236		[learning rate: 0.0043086]
	Learning Rate: 0.00430864
	LOSS [training: 0.010207857625283236 | validation: 0.008643128515508193]
	TIME [epoch: 8.25 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004316996240068607		[learning rate: 0.0042951]
	Learning Rate: 0.00429506
	LOSS [training: 0.004316996240068607 | validation: 0.0066215910584197495]
	TIME [epoch: 8.26 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036061234107413135		[learning rate: 0.0042815]
	Learning Rate: 0.00428151
	LOSS [training: 0.0036061234107413135 | validation: 0.00578852904046724]
	TIME [epoch: 8.28 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033324157220201976		[learning rate: 0.004268]
	Learning Rate: 0.00426797
	LOSS [training: 0.0033324157220201976 | validation: 0.007969637657946678]
	TIME [epoch: 8.28 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004562678143747971		[learning rate: 0.0042544]
	Learning Rate: 0.00425444
	LOSS [training: 0.004562678143747971 | validation: 0.008042415462349673]
	TIME [epoch: 8.25 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036977500872964596		[learning rate: 0.0042409]
	Learning Rate: 0.00424093
	LOSS [training: 0.0036977500872964596 | validation: 0.010213904018274142]
	TIME [epoch: 8.26 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00708541750059027		[learning rate: 0.0042274]
	Learning Rate: 0.00422744
	LOSS [training: 0.00708541750059027 | validation: 0.0067564441499390025]
	TIME [epoch: 8.26 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00425917516898212		[learning rate: 0.004214]
	Learning Rate: 0.00421396
	LOSS [training: 0.00425917516898212 | validation: 0.004990432808746943]
	TIME [epoch: 8.26 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003267614244906794		[learning rate: 0.0042005]
	Learning Rate: 0.0042005
	LOSS [training: 0.003267614244906794 | validation: 0.006669643386766659]
	TIME [epoch: 8.3 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003494261656195736		[learning rate: 0.0041871]
	Learning Rate: 0.00418705
	LOSS [training: 0.003494261656195736 | validation: 0.004513566821977146]
	TIME [epoch: 8.26 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025034707326039383		[learning rate: 0.0041736]
	Learning Rate: 0.00417362
	LOSS [training: 0.0025034707326039383 | validation: 0.006390249341547761]
	TIME [epoch: 8.25 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004725499686572902		[learning rate: 0.0041602]
	Learning Rate: 0.00416021
	LOSS [training: 0.004725499686572902 | validation: 0.005134042192487043]
	TIME [epoch: 8.26 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003235717218643385		[learning rate: 0.0041468]
	Learning Rate: 0.00414681
	LOSS [training: 0.003235717218643385 | validation: 0.012855023085526949]
	TIME [epoch: 8.26 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003127691673691954		[learning rate: 0.0041334]
	Learning Rate: 0.00413343
	LOSS [training: 0.003127691673691954 | validation: 0.00643716501204504]
	TIME [epoch: 8.27 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007683077922451228		[learning rate: 0.0041201]
	Learning Rate: 0.00412006
	LOSS [training: 0.007683077922451228 | validation: 0.0053512475540762605]
	TIME [epoch: 8.28 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002607471303996669		[learning rate: 0.0041067]
	Learning Rate: 0.00410671
	LOSS [training: 0.002607471303996669 | validation: 0.00440091533096527]
	TIME [epoch: 8.26 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027256360167957593		[learning rate: 0.0040934]
	Learning Rate: 0.00409338
	LOSS [training: 0.0027256360167957593 | validation: 0.007316475415433028]
	TIME [epoch: 8.26 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0039279993096479875		[learning rate: 0.0040801]
	Learning Rate: 0.00408006
	LOSS [training: 0.0039279993096479875 | validation: 0.003770251110287141]
	TIME [epoch: 8.26 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0042126014667537865		[learning rate: 0.0040668]
	Learning Rate: 0.00406676
	LOSS [training: 0.0042126014667537865 | validation: 0.004186189259349255]
	TIME [epoch: 8.26 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030768354329522365		[learning rate: 0.0040535]
	Learning Rate: 0.00405347
	LOSS [training: 0.0030768354329522365 | validation: 0.010948062064735626]
	TIME [epoch: 8.3 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0057715794073551945		[learning rate: 0.0040402]
	Learning Rate: 0.00404021
	LOSS [training: 0.0057715794073551945 | validation: 0.0027663727122049534]
	TIME [epoch: 8.26 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036186539078513053		[learning rate: 0.004027]
	Learning Rate: 0.00402695
	LOSS [training: 0.0036186539078513053 | validation: 0.006276857547622263]
	TIME [epoch: 8.26 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005226962526592105		[learning rate: 0.0040137]
	Learning Rate: 0.00401372
	LOSS [training: 0.005226962526592105 | validation: 0.009633228448025822]
	TIME [epoch: 8.25 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004758550443001281		[learning rate: 0.0040005]
	Learning Rate: 0.0040005
	LOSS [training: 0.004758550443001281 | validation: 0.004326129750119301]
	TIME [epoch: 8.26 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033727337188553825		[learning rate: 0.0039873]
	Learning Rate: 0.00398729
	LOSS [training: 0.0033727337188553825 | validation: 0.0042233895913207095]
	TIME [epoch: 8.26 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038689873823008238		[learning rate: 0.0039741]
	Learning Rate: 0.00397411
	LOSS [training: 0.0038689873823008238 | validation: 0.005479776213666441]
	TIME [epoch: 8.29 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034210066695793085		[learning rate: 0.0039609]
	Learning Rate: 0.00396093
	LOSS [training: 0.0034210066695793085 | validation: 0.003286788922198556]
	TIME [epoch: 8.26 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031416541393374034		[learning rate: 0.0039478]
	Learning Rate: 0.00394778
	LOSS [training: 0.0031416541393374034 | validation: 0.007314298008324843]
	TIME [epoch: 8.26 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004309683441821395		[learning rate: 0.0039346]
	Learning Rate: 0.00393464
	LOSS [training: 0.004309683441821395 | validation: 0.006952472509228265]
	TIME [epoch: 8.26 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034576686385005776		[learning rate: 0.0039215]
	Learning Rate: 0.00392152
	LOSS [training: 0.0034576686385005776 | validation: 0.007419848685617145]
	TIME [epoch: 8.26 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004200544603451683		[learning rate: 0.0039084]
	Learning Rate: 0.00390842
	LOSS [training: 0.004200544603451683 | validation: 0.003722828194471503]
	TIME [epoch: 8.29 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004647666371026963		[learning rate: 0.0038953]
	Learning Rate: 0.00389533
	LOSS [training: 0.004647666371026963 | validation: 0.008735397697335986]
	TIME [epoch: 8.27 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004618313450626019		[learning rate: 0.0038823]
	Learning Rate: 0.00388226
	LOSS [training: 0.004618313450626019 | validation: 0.007497612194766264]
	TIME [epoch: 8.26 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003265778449951676		[learning rate: 0.0038692]
	Learning Rate: 0.0038692
	LOSS [training: 0.003265778449951676 | validation: 0.005662511165097514]
	TIME [epoch: 8.25 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035340935973054623		[learning rate: 0.0038562]
	Learning Rate: 0.00385617
	LOSS [training: 0.0035340935973054623 | validation: 0.006942777332377531]
	TIME [epoch: 8.26 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035508719525140266		[learning rate: 0.0038431]
	Learning Rate: 0.00384315
	LOSS [training: 0.0035508719525140266 | validation: 0.006120787335475404]
	TIME [epoch: 8.26 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003908890321066587		[learning rate: 0.0038301]
	Learning Rate: 0.00383014
	LOSS [training: 0.003908890321066587 | validation: 0.008511572236526217]
	TIME [epoch: 8.29 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032121852893601584		[learning rate: 0.0038172]
	Learning Rate: 0.00381716
	LOSS [training: 0.0032121852893601584 | validation: 0.0038817170754931116]
	TIME [epoch: 8.26 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029151825910195494		[learning rate: 0.0038042]
	Learning Rate: 0.00380419
	LOSS [training: 0.0029151825910195494 | validation: 0.007933948190284194]
	TIME [epoch: 8.26 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005962608034595315		[learning rate: 0.0037912]
	Learning Rate: 0.00379123
	LOSS [training: 0.005962608034595315 | validation: 0.005298731259057552]
	TIME [epoch: 8.25 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004897762429232644		[learning rate: 0.0037783]
	Learning Rate: 0.0037783
	LOSS [training: 0.004897762429232644 | validation: 0.004227753298049062]
	TIME [epoch: 8.26 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003057034320824428		[learning rate: 0.0037654]
	Learning Rate: 0.00376538
	LOSS [training: 0.003057034320824428 | validation: 0.0033284372450599316]
	TIME [epoch: 8.29 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031185148313623836		[learning rate: 0.0037525]
	Learning Rate: 0.00375248
	LOSS [training: 0.0031185148313623836 | validation: 0.0040124716061050916]
	TIME [epoch: 8.27 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005485482917873542		[learning rate: 0.0037396]
	Learning Rate: 0.00373959
	LOSS [training: 0.005485482917873542 | validation: 0.005446503188093829]
	TIME [epoch: 8.26 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003431762995552242		[learning rate: 0.0037267]
	Learning Rate: 0.00372672
	LOSS [training: 0.003431762995552242 | validation: 0.004256913598479653]
	TIME [epoch: 8.26 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002921672402910534		[learning rate: 0.0037139]
	Learning Rate: 0.00371387
	LOSS [training: 0.002921672402910534 | validation: 0.006625721245967872]
	TIME [epoch: 8.26 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033670799421239785		[learning rate: 0.003701]
	Learning Rate: 0.00370104
	LOSS [training: 0.0033670799421239785 | validation: 0.0050120049198606655]
	TIME [epoch: 8.26 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032130583847837907		[learning rate: 0.0036882]
	Learning Rate: 0.00368822
	LOSS [training: 0.0032130583847837907 | validation: 0.0035097658541767282]
	TIME [epoch: 8.3 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003005503322801771		[learning rate: 0.0036754]
	Learning Rate: 0.00367542
	LOSS [training: 0.003005503322801771 | validation: 0.004573779388623393]
	TIME [epoch: 8.25 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003188119586813378		[learning rate: 0.0036626]
	Learning Rate: 0.00366264
	LOSS [training: 0.003188119586813378 | validation: 0.0045248549262233905]
	TIME [epoch: 8.26 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005549933647087762		[learning rate: 0.0036499]
	Learning Rate: 0.00364988
	LOSS [training: 0.005549933647087762 | validation: 0.008566835165210389]
	TIME [epoch: 8.25 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005807877817722959		[learning rate: 0.0036371]
	Learning Rate: 0.00363713
	LOSS [training: 0.005807877817722959 | validation: 0.00795292584798303]
	TIME [epoch: 8.26 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003983652253394691		[learning rate: 0.0036244]
	Learning Rate: 0.0036244
	LOSS [training: 0.003983652253394691 | validation: 0.0065928005928048644]
	TIME [epoch: 8.28 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031643528522991545		[learning rate: 0.0036117]
	Learning Rate: 0.00361169
	LOSS [training: 0.0031643528522991545 | validation: 0.00666613991261396]
	TIME [epoch: 8.27 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029202452587222217		[learning rate: 0.003599]
	Learning Rate: 0.003599
	LOSS [training: 0.0029202452587222217 | validation: 0.008000160213311387]
	TIME [epoch: 8.26 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033187448400728435		[learning rate: 0.0035863]
	Learning Rate: 0.00358632
	LOSS [training: 0.0033187448400728435 | validation: 0.006795138209130777]
	TIME [epoch: 8.26 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006271526456793126		[learning rate: 0.0035737]
	Learning Rate: 0.00357366
	LOSS [training: 0.006271526456793126 | validation: 0.00470411058112387]
	TIME [epoch: 8.26 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004288090697980794		[learning rate: 0.003561]
	Learning Rate: 0.00356102
	LOSS [training: 0.004288090697980794 | validation: 0.010845900729863233]
	TIME [epoch: 8.26 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0047918954165290534		[learning rate: 0.0035484]
	Learning Rate: 0.00354839
	LOSS [training: 0.0047918954165290534 | validation: 0.005891659783065424]
	TIME [epoch: 8.29 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00322668679597883		[learning rate: 0.0035358]
	Learning Rate: 0.00353579
	LOSS [training: 0.00322668679597883 | validation: 0.003913960993747753]
	TIME [epoch: 8.26 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029944140743490832		[learning rate: 0.0035232]
	Learning Rate: 0.0035232
	LOSS [training: 0.0029944140743490832 | validation: 0.00503734229818955]
	TIME [epoch: 8.25 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003649982574264623		[learning rate: 0.0035106]
	Learning Rate: 0.00351063
	LOSS [training: 0.003649982574264623 | validation: 0.004184906066994363]
	TIME [epoch: 8.26 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038301414336438335		[learning rate: 0.0034981]
	Learning Rate: 0.00349807
	LOSS [training: 0.0038301414336438335 | validation: 0.007011239456970126]
	TIME [epoch: 8.26 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00372782959400273		[learning rate: 0.0034855]
	Learning Rate: 0.00348554
	LOSS [training: 0.00372782959400273 | validation: 0.003890023810111951]
	TIME [epoch: 8.27 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003213423773929344		[learning rate: 0.003473]
	Learning Rate: 0.00347302
	LOSS [training: 0.003213423773929344 | validation: 0.005595920147827926]
	TIME [epoch: 8.28 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002868937132818347		[learning rate: 0.0034605]
	Learning Rate: 0.00346052
	LOSS [training: 0.002868937132818347 | validation: 0.0032654341014269946]
	TIME [epoch: 8.25 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002960253456924911		[learning rate: 0.003448]
	Learning Rate: 0.00344804
	LOSS [training: 0.002960253456924911 | validation: 0.007511276753181814]
	TIME [epoch: 8.25 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0040750081682727314		[learning rate: 0.0034356]
	Learning Rate: 0.00343557
	LOSS [training: 0.0040750081682727314 | validation: 0.004888798539205322]
	TIME [epoch: 8.26 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020043378560161054		[learning rate: 0.0034231]
	Learning Rate: 0.00342313
	LOSS [training: 0.0020043378560161054 | validation: 0.005918607312610052]
	TIME [epoch: 8.26 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003981618412653433		[learning rate: 0.0034107]
	Learning Rate: 0.0034107
	LOSS [training: 0.003981618412653433 | validation: 0.008843769200077754]
	TIME [epoch: 8.29 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004322004397051068		[learning rate: 0.0033983]
	Learning Rate: 0.00339829
	LOSS [training: 0.004322004397051068 | validation: 0.005079337251999823]
	TIME [epoch: 8.27 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023427921469069807		[learning rate: 0.0033859]
	Learning Rate: 0.0033859
	LOSS [training: 0.0023427921469069807 | validation: 0.005592441248698046]
	TIME [epoch: 8.25 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002516805383036112		[learning rate: 0.0033735]
	Learning Rate: 0.00337352
	LOSS [training: 0.002516805383036112 | validation: 0.004041980113696868]
	TIME [epoch: 8.25 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003497076420156501		[learning rate: 0.0033612]
	Learning Rate: 0.00336117
	LOSS [training: 0.003497076420156501 | validation: 0.005784073468856595]
	TIME [epoch: 8.26 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002999494633987066		[learning rate: 0.0033488]
	Learning Rate: 0.00334883
	LOSS [training: 0.002999494633987066 | validation: 0.0056326368071033745]
	TIME [epoch: 8.27 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030012031235711585		[learning rate: 0.0033365]
	Learning Rate: 0.00333651
	LOSS [training: 0.0030012031235711585 | validation: 0.0052746722699494744]
	TIME [epoch: 8.29 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025476128714242044		[learning rate: 0.0033242]
	Learning Rate: 0.00332421
	LOSS [training: 0.0025476128714242044 | validation: 0.006419922176664516]
	TIME [epoch: 8.26 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004090086449534644		[learning rate: 0.0033119]
	Learning Rate: 0.00331192
	LOSS [training: 0.004090086449534644 | validation: 0.0046558183559259735]
	TIME [epoch: 8.25 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027972793559160286		[learning rate: 0.0032997]
	Learning Rate: 0.00329966
	LOSS [training: 0.0027972793559160286 | validation: 0.0030180411008992446]
	TIME [epoch: 8.25 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023496159017627398		[learning rate: 0.0032874]
	Learning Rate: 0.00328741
	LOSS [training: 0.0023496159017627398 | validation: 0.003225466643921813]
	TIME [epoch: 8.25 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002325306627800394		[learning rate: 0.0032752]
	Learning Rate: 0.00327518
	LOSS [training: 0.002325306627800394 | validation: 0.00414874159502982]
	TIME [epoch: 8.29 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005005176373761088		[learning rate: 0.003263]
	Learning Rate: 0.00326298
	LOSS [training: 0.005005176373761088 | validation: 0.005091589919576232]
	TIME [epoch: 8.26 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002192131340149397		[learning rate: 0.0032508]
	Learning Rate: 0.00325078
	LOSS [training: 0.002192131340149397 | validation: 0.0031491786968933285]
	TIME [epoch: 8.26 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028301737038849877		[learning rate: 0.0032386]
	Learning Rate: 0.00323861
	LOSS [training: 0.0028301737038849877 | validation: 0.005335774653081899]
	TIME [epoch: 8.25 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003204419429727245		[learning rate: 0.0032265]
	Learning Rate: 0.00322646
	LOSS [training: 0.003204419429727245 | validation: 0.003419043212312261]
	TIME [epoch: 8.26 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00226752568467319		[learning rate: 0.0032143]
	Learning Rate: 0.00321432
	LOSS [training: 0.00226752568467319 | validation: 0.0046471425594514166]
	TIME [epoch: 8.27 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022391112126724923		[learning rate: 0.0032022]
	Learning Rate: 0.0032022
	LOSS [training: 0.0022391112126724923 | validation: 0.005172770517734177]
	TIME [epoch: 8.29 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006581888446004378		[learning rate: 0.0031901]
	Learning Rate: 0.00319011
	LOSS [training: 0.006581888446004378 | validation: 0.010663142140203535]
	TIME [epoch: 8.26 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004266459023175021		[learning rate: 0.003178]
	Learning Rate: 0.00317803
	LOSS [training: 0.004266459023175021 | validation: 0.009154254464312237]
	TIME [epoch: 8.26 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033222045490103416		[learning rate: 0.003166]
	Learning Rate: 0.00316596
	LOSS [training: 0.0033222045490103416 | validation: 0.005233784112015407]
	TIME [epoch: 8.25 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030425300762897145		[learning rate: 0.0031539]
	Learning Rate: 0.00315392
	LOSS [training: 0.0030425300762897145 | validation: 0.007859443870545832]
	TIME [epoch: 8.25 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003340201022100898		[learning rate: 0.0031419]
	Learning Rate: 0.0031419
	LOSS [training: 0.003340201022100898 | validation: 0.005097301897298582]
	TIME [epoch: 8.29 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030582746867803545		[learning rate: 0.0031299]
	Learning Rate: 0.00312989
	LOSS [training: 0.0030582746867803545 | validation: 0.004392462416337109]
	TIME [epoch: 8.27 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022685640893017325		[learning rate: 0.0031179]
	Learning Rate: 0.00311791
	LOSS [training: 0.0022685640893017325 | validation: 0.005533074249616828]
	TIME [epoch: 8.26 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029074896566662575		[learning rate: 0.0031059]
	Learning Rate: 0.00310594
	LOSS [training: 0.0029074896566662575 | validation: 0.005732817906728101]
	TIME [epoch: 8.26 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031489378491507698		[learning rate: 0.003094]
	Learning Rate: 0.00309399
	LOSS [training: 0.0031489378491507698 | validation: 0.004664613017138692]
	TIME [epoch: 8.26 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025071784155885446		[learning rate: 0.0030821]
	Learning Rate: 0.00308206
	LOSS [training: 0.0025071784155885446 | validation: 0.0035971610544463396]
	TIME [epoch: 8.25 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002534931647058448		[learning rate: 0.0030701]
	Learning Rate: 0.00307015
	LOSS [training: 0.002534931647058448 | validation: 0.006148900939486443]
	TIME [epoch: 8.3 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026498319969713397		[learning rate: 0.0030583]
	Learning Rate: 0.00305826
	LOSS [training: 0.0026498319969713397 | validation: 0.004434686394083464]
	TIME [epoch: 8.26 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023662347756228976		[learning rate: 0.0030464]
	Learning Rate: 0.00304639
	LOSS [training: 0.0023662347756228976 | validation: 0.0034689079147750624]
	TIME [epoch: 8.26 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002805582684667696		[learning rate: 0.0030345]
	Learning Rate: 0.00303453
	LOSS [training: 0.002805582684667696 | validation: 0.00396777923642066]
	TIME [epoch: 8.26 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019004334254551832		[learning rate: 0.0030227]
	Learning Rate: 0.0030227
	LOSS [training: 0.0019004334254551832 | validation: 0.003958635967679765]
	TIME [epoch: 8.25 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003282426059273332		[learning rate: 0.0030109]
	Learning Rate: 0.00301088
	LOSS [training: 0.003282426059273332 | validation: 0.00348060517560407]
	TIME [epoch: 8.27 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028397765039684052		[learning rate: 0.0029991]
	Learning Rate: 0.00299908
	LOSS [training: 0.0028397765039684052 | validation: 0.0068173410997400315]
	TIME [epoch: 8.28 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00400519928860682		[learning rate: 0.0029873]
	Learning Rate: 0.00298731
	LOSS [training: 0.00400519928860682 | validation: 0.009102014526449032]
	TIME [epoch: 8.25 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00279702302778211		[learning rate: 0.0029755]
	Learning Rate: 0.00297555
	LOSS [training: 0.00279702302778211 | validation: 0.0023681116664017736]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_1472.pth
	Model improved!!!
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021471987425994796		[learning rate: 0.0029638]
	Learning Rate: 0.00296381
	LOSS [training: 0.0021471987425994796 | validation: 0.007000475961310936]
	TIME [epoch: 8.25 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031312043100769		[learning rate: 0.0029521]
	Learning Rate: 0.00295209
	LOSS [training: 0.0031312043100769 | validation: 0.004136900680373947]
	TIME [epoch: 8.25 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026120416033712643		[learning rate: 0.0029404]
	Learning Rate: 0.00294039
	LOSS [training: 0.0026120416033712643 | validation: 0.004119155344021228]
	TIME [epoch: 8.3 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004031886136795895		[learning rate: 0.0029287]
	Learning Rate: 0.00292871
	LOSS [training: 0.004031886136795895 | validation: 0.003699834549870826]
	TIME [epoch: 8.26 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025702334695665414		[learning rate: 0.002917]
	Learning Rate: 0.00291705
	LOSS [training: 0.0025702334695665414 | validation: 0.0041792540934993015]
	TIME [epoch: 8.25 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002635434813893148		[learning rate: 0.0029054]
	Learning Rate: 0.0029054
	LOSS [training: 0.002635434813893148 | validation: 0.004424106268150537]
	TIME [epoch: 8.26 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037315476842849898		[learning rate: 0.0028938]
	Learning Rate: 0.00289378
	LOSS [training: 0.0037315476842849898 | validation: 0.0033617121747467936]
	TIME [epoch: 8.26 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002559074641830122		[learning rate: 0.0028822]
	Learning Rate: 0.00288218
	LOSS [training: 0.002559074641830122 | validation: 0.0036247072505545706]
	TIME [epoch: 8.27 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024985722026336287		[learning rate: 0.0028706]
	Learning Rate: 0.00287059
	LOSS [training: 0.0024985722026336287 | validation: 0.00445029508629567]
	TIME [epoch: 8.29 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024086175687392936		[learning rate: 0.002859]
	Learning Rate: 0.00285903
	LOSS [training: 0.0024086175687392936 | validation: 0.004102998991398089]
	TIME [epoch: 8.25 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033850504036773248		[learning rate: 0.0028475]
	Learning Rate: 0.00284748
	LOSS [training: 0.0033850504036773248 | validation: 0.004951503005268694]
	TIME [epoch: 8.25 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002646926513060173		[learning rate: 0.002836]
	Learning Rate: 0.00283596
	LOSS [training: 0.002646926513060173 | validation: 0.005390283823481898]
	TIME [epoch: 8.26 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019560365280015795		[learning rate: 0.0028245]
	Learning Rate: 0.00282445
	LOSS [training: 0.0019560365280015795 | validation: 0.0029202894379048434]
	TIME [epoch: 8.26 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002195274814364619		[learning rate: 0.002813]
	Learning Rate: 0.00281297
	LOSS [training: 0.002195274814364619 | validation: 0.005788626762627638]
	TIME [epoch: 8.3 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002105445700484337		[learning rate: 0.0028015]
	Learning Rate: 0.0028015
	LOSS [training: 0.002105445700484337 | validation: 0.006042717713804779]
	TIME [epoch: 8.26 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005200713166875991		[learning rate: 0.0027901]
	Learning Rate: 0.00279005
	LOSS [training: 0.005200713166875991 | validation: 0.0022379394947498695]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_1488.pth
	Model improved!!!
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027929762815371755		[learning rate: 0.0027786]
	Learning Rate: 0.00277863
	LOSS [training: 0.0027929762815371755 | validation: 0.0021051206192492585]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_1489.pth
	Model improved!!!
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002960668183081781		[learning rate: 0.0027672]
	Learning Rate: 0.00276722
	LOSS [training: 0.002960668183081781 | validation: 0.005561168335142579]
	TIME [epoch: 8.27 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033663982584126416		[learning rate: 0.0027558]
	Learning Rate: 0.00275583
	LOSS [training: 0.0033663982584126416 | validation: 0.003761403584707391]
	TIME [epoch: 8.29 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026992230195644774		[learning rate: 0.0027445]
	Learning Rate: 0.00274446
	LOSS [training: 0.0026992230195644774 | validation: 0.0029599013104037435]
	TIME [epoch: 8.3 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031433305910190785		[learning rate: 0.0027331]
	Learning Rate: 0.00273312
	LOSS [training: 0.0031433305910190785 | validation: 0.0036523178129373906]
	TIME [epoch: 8.27 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026689972720282695		[learning rate: 0.0027218]
	Learning Rate: 0.00272179
	LOSS [training: 0.0026689972720282695 | validation: 0.00385314868856491]
	TIME [epoch: 8.28 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002446536953685612		[learning rate: 0.0027105]
	Learning Rate: 0.00271048
	LOSS [training: 0.002446536953685612 | validation: 0.002315074537645218]
	TIME [epoch: 8.27 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026820784814490664		[learning rate: 0.0026992]
	Learning Rate: 0.00269919
	LOSS [training: 0.0026820784814490664 | validation: 0.00359573287047089]
	TIME [epoch: 8.27 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002371890911991458		[learning rate: 0.0026879]
	Learning Rate: 0.00268792
	LOSS [training: 0.002371890911991458 | validation: 0.0025047500568154838]
	TIME [epoch: 8.32 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019336512154541755		[learning rate: 0.0026767]
	Learning Rate: 0.00267667
	LOSS [training: 0.0019336512154541755 | validation: 0.0034400493674650525]
	TIME [epoch: 8.27 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026220485006054305		[learning rate: 0.0026654]
	Learning Rate: 0.00266545
	LOSS [training: 0.0026220485006054305 | validation: 0.003143440760278077]
	TIME [epoch: 8.27 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002284445225998528		[learning rate: 0.0026542]
	Learning Rate: 0.00265424
	LOSS [training: 0.002284445225998528 | validation: 0.003386027683328243]
	TIME [epoch: 8.27 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002558351224483273		[learning rate: 0.0026431]
	Learning Rate: 0.00264305
	LOSS [training: 0.002558351224483273 | validation: 0.00667061065366637]
	TIME [epoch: 8.27 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025380611387121263		[learning rate: 0.0026319]
	Learning Rate: 0.00263188
	LOSS [training: 0.0025380611387121263 | validation: 0.004083360869667649]
	TIME [epoch: 8.28 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017729178064307106		[learning rate: 0.0026207]
	Learning Rate: 0.00262073
	LOSS [training: 0.0017729178064307106 | validation: 0.0030445155805850447]
	TIME [epoch: 8.29 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024616274126704136		[learning rate: 0.0026096]
	Learning Rate: 0.00260961
	LOSS [training: 0.0024616274126704136 | validation: 0.002913703441769616]
	TIME [epoch: 8.26 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001821495934258381		[learning rate: 0.0025985]
	Learning Rate: 0.0025985
	LOSS [training: 0.001821495934258381 | validation: 0.004071365183282179]
	TIME [epoch: 8.26 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002557478370027686		[learning rate: 0.0025874]
	Learning Rate: 0.00258741
	LOSS [training: 0.002557478370027686 | validation: 0.005080115449516186]
	TIME [epoch: 8.26 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028010063048242795		[learning rate: 0.0025763]
	Learning Rate: 0.00257635
	LOSS [training: 0.0028010063048242795 | validation: 0.0046917821589350685]
	TIME [epoch: 8.26 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002181627673591006		[learning rate: 0.0025653]
	Learning Rate: 0.0025653
	LOSS [training: 0.002181627673591006 | validation: 0.003189466623572409]
	TIME [epoch: 8.3 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00228075562679881		[learning rate: 0.0025543]
	Learning Rate: 0.00255427
	LOSS [training: 0.00228075562679881 | validation: 0.002991225249251328]
	TIME [epoch: 8.27 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002721287319905023		[learning rate: 0.0025433]
	Learning Rate: 0.00254327
	LOSS [training: 0.002721287319905023 | validation: 0.0028643789240964503]
	TIME [epoch: 8.26 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024538946179143667		[learning rate: 0.0025323]
	Learning Rate: 0.00253228
	LOSS [training: 0.0024538946179143667 | validation: 0.006453034846777382]
	TIME [epoch: 8.26 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025258103082702633		[learning rate: 0.0025213]
	Learning Rate: 0.00252132
	LOSS [training: 0.0025258103082702633 | validation: 0.002797283561782037]
	TIME [epoch: 8.26 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002248020311740064		[learning rate: 0.0025104]
	Learning Rate: 0.00251037
	LOSS [training: 0.002248020311740064 | validation: 0.005797866298101118]
	TIME [epoch: 8.27 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004367287655531498		[learning rate: 0.0024994]
	Learning Rate: 0.00249945
	LOSS [training: 0.004367287655531498 | validation: 0.0018780931942848325]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_1514.pth
	Model improved!!!
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002221135427659516		[learning rate: 0.0024885]
	Learning Rate: 0.00248855
	LOSS [training: 0.002221135427659516 | validation: 0.004936958077577032]
	TIME [epoch: 8.26 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002994728053218876		[learning rate: 0.0024777]
	Learning Rate: 0.00247766
	LOSS [training: 0.002994728053218876 | validation: 0.003079198019248445]
	TIME [epoch: 8.26 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002708124811604703		[learning rate: 0.0024668]
	Learning Rate: 0.0024668
	LOSS [training: 0.002708124811604703 | validation: 0.002914731731945645]
	TIME [epoch: 8.26 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028763717719787604		[learning rate: 0.002456]
	Learning Rate: 0.00245596
	LOSS [training: 0.0028763717719787604 | validation: 0.005075526745014762]
	TIME [epoch: 8.26 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027419788813577944		[learning rate: 0.0024451]
	Learning Rate: 0.00244514
	LOSS [training: 0.0027419788813577944 | validation: 0.004038565963484622]
	TIME [epoch: 8.3 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024030605354885587		[learning rate: 0.0024343]
	Learning Rate: 0.00243434
	LOSS [training: 0.0024030605354885587 | validation: 0.0028140682875327093]
	TIME [epoch: 8.27 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001924643605508271		[learning rate: 0.0024236]
	Learning Rate: 0.00242356
	LOSS [training: 0.001924643605508271 | validation: 0.004470440021293941]
	TIME [epoch: 8.26 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022096363877753267		[learning rate: 0.0024128]
	Learning Rate: 0.0024128
	LOSS [training: 0.0022096363877753267 | validation: 0.003001007472516399]
	TIME [epoch: 8.26 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019594272691580055		[learning rate: 0.0024021]
	Learning Rate: 0.00240206
	LOSS [training: 0.0019594272691580055 | validation: 0.00726938968024087]
	TIME [epoch: 8.26 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002627311299738388		[learning rate: 0.0023913]
	Learning Rate: 0.00239134
	LOSS [training: 0.002627311299738388 | validation: 0.003163164817925136]
	TIME [epoch: 8.27 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020861249080605174		[learning rate: 0.0023806]
	Learning Rate: 0.00238065
	LOSS [training: 0.0020861249080605174 | validation: 0.016935635216164438]
	TIME [epoch: 8.3 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004122901046369443		[learning rate: 0.00237]
	Learning Rate: 0.00236997
	LOSS [training: 0.004122901046369443 | validation: 0.005638821379392052]
	TIME [epoch: 8.26 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002377907591619298		[learning rate: 0.0023593]
	Learning Rate: 0.00235931
	LOSS [training: 0.002377907591619298 | validation: 0.00477170966483428]
	TIME [epoch: 8.26 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024435789783386853		[learning rate: 0.0023487]
	Learning Rate: 0.00234868
	LOSS [training: 0.0024435789783386853 | validation: 0.00472047273820698]
	TIME [epoch: 8.26 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025886333363251395		[learning rate: 0.0023381]
	Learning Rate: 0.00233807
	LOSS [training: 0.0025886333363251395 | validation: 0.004582823024207074]
	TIME [epoch: 8.26 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029518592251371613		[learning rate: 0.0023275]
	Learning Rate: 0.00232748
	LOSS [training: 0.0029518592251371613 | validation: 0.005169473367874744]
	TIME [epoch: 8.29 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027650837125959356		[learning rate: 0.0023169]
	Learning Rate: 0.0023169
	LOSS [training: 0.0027650837125959356 | validation: 0.005440718611351695]
	TIME [epoch: 8.27 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002407654162340513		[learning rate: 0.0023064]
	Learning Rate: 0.00230635
	LOSS [training: 0.002407654162340513 | validation: 0.0036891409422061556]
	TIME [epoch: 8.26 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002472793156845513		[learning rate: 0.0022958]
	Learning Rate: 0.00229583
	LOSS [training: 0.002472793156845513 | validation: 0.004001633686463299]
	TIME [epoch: 8.26 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002079608296211252		[learning rate: 0.0022853]
	Learning Rate: 0.00228532
	LOSS [training: 0.002079608296211252 | validation: 0.0041012094206545145]
	TIME [epoch: 8.26 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003704639407422343		[learning rate: 0.0022748]
	Learning Rate: 0.00227483
	LOSS [training: 0.003704639407422343 | validation: 0.0037350054012929798]
	TIME [epoch: 8.27 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025506592316522224		[learning rate: 0.0022644]
	Learning Rate: 0.00226436
	LOSS [training: 0.0025506592316522224 | validation: 0.003199544145913743]
	TIME [epoch: 8.3 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002529538208399194		[learning rate: 0.0022539]
	Learning Rate: 0.00225392
	LOSS [training: 0.002529538208399194 | validation: 0.004504612218321366]
	TIME [epoch: 8.26 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002149286278526561		[learning rate: 0.0022435]
	Learning Rate: 0.0022435
	LOSS [training: 0.002149286278526561 | validation: 0.003476388080909109]
	TIME [epoch: 8.26 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002686282925943135		[learning rate: 0.0022331]
	Learning Rate: 0.00223309
	LOSS [training: 0.002686282925943135 | validation: 0.003344728693570959]
	TIME [epoch: 8.26 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002034428250717876		[learning rate: 0.0022227]
	Learning Rate: 0.00222271
	LOSS [training: 0.002034428250717876 | validation: 0.0032896886698495394]
	TIME [epoch: 8.26 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00170277122911329		[learning rate: 0.0022124]
	Learning Rate: 0.00221235
	LOSS [training: 0.00170277122911329 | validation: 0.003874694183581594]
	TIME [epoch: 8.3 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001741439467242626		[learning rate: 0.002202]
	Learning Rate: 0.00220202
	LOSS [training: 0.001741439467242626 | validation: 0.004891312200868199]
	TIME [epoch: 8.27 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025716881014608735		[learning rate: 0.0021917]
	Learning Rate: 0.0021917
	LOSS [training: 0.0025716881014608735 | validation: 0.0031959579112132855]
	TIME [epoch: 8.26 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002600533120277075		[learning rate: 0.0021814]
	Learning Rate: 0.0021814
	LOSS [training: 0.002600533120277075 | validation: 0.0022078258582891655]
	TIME [epoch: 8.26 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002280062849347585		[learning rate: 0.0021711]
	Learning Rate: 0.00217113
	LOSS [training: 0.002280062849347585 | validation: 0.005926516680854211]
	TIME [epoch: 8.26 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002286761126961533		[learning rate: 0.0021609]
	Learning Rate: 0.00216088
	LOSS [training: 0.002286761126961533 | validation: 0.0031414285524435977]
	TIME [epoch: 8.26 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002710574114960363		[learning rate: 0.0021506]
	Learning Rate: 0.00215064
	LOSS [training: 0.002710574114960363 | validation: 0.003768831536558645]
	TIME [epoch: 8.3 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002075985345064768		[learning rate: 0.0021404]
	Learning Rate: 0.00214043
	LOSS [training: 0.002075985345064768 | validation: 0.002801268185977478]
	TIME [epoch: 8.26 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001638209166180619		[learning rate: 0.0021302]
	Learning Rate: 0.00213025
	LOSS [training: 0.001638209166180619 | validation: 0.0027120267135876714]
	TIME [epoch: 8.26 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002417500412475562		[learning rate: 0.0021201]
	Learning Rate: 0.00212008
	LOSS [training: 0.002417500412475562 | validation: 0.006123817462607115]
	TIME [epoch: 8.26 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002955783943633368		[learning rate: 0.0021099]
	Learning Rate: 0.00210993
	LOSS [training: 0.002955783943633368 | validation: 0.004097141944763601]
	TIME [epoch: 8.25 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022029821579288506		[learning rate: 0.0020998]
	Learning Rate: 0.00209981
	LOSS [training: 0.0022029821579288506 | validation: 0.004797009286315166]
	TIME [epoch: 8.28 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019829933384542		[learning rate: 0.0020897]
	Learning Rate: 0.00208971
	LOSS [training: 0.0019829933384542 | validation: 0.003201564122302644]
	TIME [epoch: 8.28 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025947328932981475		[learning rate: 0.0020796]
	Learning Rate: 0.00207963
	LOSS [training: 0.0025947328932981475 | validation: 0.0044821184458094035]
	TIME [epoch: 8.31 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025034197302420185		[learning rate: 0.0020696]
	Learning Rate: 0.00206957
	LOSS [training: 0.0025034197302420185 | validation: 0.004415143990664078]
	TIME [epoch: 8.26 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020061500742574504		[learning rate: 0.0020595]
	Learning Rate: 0.00205953
	LOSS [training: 0.0020061500742574504 | validation: 0.0032940759067989584]
	TIME [epoch: 8.26 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016579539560691785		[learning rate: 0.0020495]
	Learning Rate: 0.00204952
	LOSS [training: 0.0016579539560691785 | validation: 0.007819796465189398]
	TIME [epoch: 8.26 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008145481553864012		[learning rate: 0.0020395]
	Learning Rate: 0.00203952
	LOSS [training: 0.008145481553864012 | validation: 0.004095121748393013]
	TIME [epoch: 8.3 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0043140928755804765		[learning rate: 0.0020296]
	Learning Rate: 0.00202955
	LOSS [training: 0.0043140928755804765 | validation: 0.003258252385651499]
	TIME [epoch: 8.26 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026672648802941717		[learning rate: 0.0020196]
	Learning Rate: 0.0020196
	LOSS [training: 0.0026672648802941717 | validation: 0.002789689059015117]
	TIME [epoch: 8.26 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002616159488389658		[learning rate: 0.0020097]
	Learning Rate: 0.00200967
	LOSS [training: 0.002616159488389658 | validation: 0.0034692718294857166]
	TIME [epoch: 8.26 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019994180633916233		[learning rate: 0.0019998]
	Learning Rate: 0.00199977
	LOSS [training: 0.0019994180633916233 | validation: 0.0026076027779004408]
	TIME [epoch: 8.26 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001791798933789224		[learning rate: 0.0019899]
	Learning Rate: 0.00198988
	LOSS [training: 0.001791798933789224 | validation: 0.002808368053078298]
	TIME [epoch: 8.28 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014339866034103295		[learning rate: 0.00198]
	Learning Rate: 0.00198002
	LOSS [training: 0.0014339866034103295 | validation: 0.002209003125039148]
	TIME [epoch: 8.28 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017483171134083783		[learning rate: 0.0019702]
	Learning Rate: 0.00197018
	LOSS [training: 0.0017483171134083783 | validation: 0.0031204583883371172]
	TIME [epoch: 8.26 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017097691704677275		[learning rate: 0.0019604]
	Learning Rate: 0.00196036
	LOSS [training: 0.0017097691704677275 | validation: 0.0020510618289024756]
	TIME [epoch: 8.25 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019128230173464382		[learning rate: 0.0019506]
	Learning Rate: 0.00195056
	LOSS [training: 0.0019128230173464382 | validation: 0.003493371224690257]
	TIME [epoch: 8.26 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033568140117171503		[learning rate: 0.0019408]
	Learning Rate: 0.00194079
	LOSS [training: 0.0033568140117171503 | validation: 0.00310547605173158]
	TIME [epoch: 8.26 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018597036188480107		[learning rate: 0.001931]
	Learning Rate: 0.00193103
	LOSS [training: 0.0018597036188480107 | validation: 0.0024246635265400443]
	TIME [epoch: 8.3 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016760513146340792		[learning rate: 0.0019213]
	Learning Rate: 0.0019213
	LOSS [training: 0.0016760513146340792 | validation: 0.0034692410933499095]
	TIME [epoch: 8.26 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015181885011251407		[learning rate: 0.0019116]
	Learning Rate: 0.0019116
	LOSS [training: 0.0015181885011251407 | validation: 0.0024083255547517482]
	TIME [epoch: 8.26 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031107376282616017		[learning rate: 0.0019019]
	Learning Rate: 0.00190191
	LOSS [training: 0.0031107376282616017 | validation: 0.0021828792750872967]
	TIME [epoch: 8.26 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023104038092787824		[learning rate: 0.0018922]
	Learning Rate: 0.00189225
	LOSS [training: 0.0023104038092787824 | validation: 0.001938258209816266]
	TIME [epoch: 8.26 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023540579156611685		[learning rate: 0.0018826]
	Learning Rate: 0.0018826
	LOSS [training: 0.0023540579156611685 | validation: 0.0028784389415909325]
	TIME [epoch: 8.26 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022926884848364338		[learning rate: 0.001873]
	Learning Rate: 0.00187298
	LOSS [training: 0.0022926884848364338 | validation: 0.002713424499865149]
	TIME [epoch: 8.3 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019389994401789255		[learning rate: 0.0018634]
	Learning Rate: 0.00186339
	LOSS [training: 0.0019389994401789255 | validation: 0.0022522996520811]
	TIME [epoch: 8.26 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00155508152937532		[learning rate: 0.0018538]
	Learning Rate: 0.00185381
	LOSS [training: 0.00155508152937532 | validation: 0.002553277852438434]
	TIME [epoch: 8.26 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018525950356660715		[learning rate: 0.0018443]
	Learning Rate: 0.00184426
	LOSS [training: 0.0018525950356660715 | validation: 0.002582542326803905]
	TIME [epoch: 8.26 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016942239749986716		[learning rate: 0.0018347]
	Learning Rate: 0.00183473
	LOSS [training: 0.0016942239749986716 | validation: 0.0017996130169451153]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_1579.pth
	Model improved!!!
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002151778795086901		[learning rate: 0.0018252]
	Learning Rate: 0.00182522
	LOSS [training: 0.002151778795086901 | validation: 0.0034025525251984083]
	TIME [epoch: 8.29 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020804885541614044		[learning rate: 0.0018157]
	Learning Rate: 0.00181573
	LOSS [training: 0.0020804885541614044 | validation: 0.0025637248292622924]
	TIME [epoch: 8.27 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016541218178580204		[learning rate: 0.0018063]
	Learning Rate: 0.00180627
	LOSS [training: 0.0016541218178580204 | validation: 0.003686695560697022]
	TIME [epoch: 8.25 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015752389206748268		[learning rate: 0.0017968]
	Learning Rate: 0.00179683
	LOSS [training: 0.0015752389206748268 | validation: 0.00263744637915451]
	TIME [epoch: 8.26 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016633727432883597		[learning rate: 0.0017874]
	Learning Rate: 0.00178741
	LOSS [training: 0.0016633727432883597 | validation: 0.0022920412517568193]
	TIME [epoch: 8.26 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017969477119676445		[learning rate: 0.001778]
	Learning Rate: 0.00177801
	LOSS [training: 0.0017969477119676445 | validation: 0.0038467889699727977]
	TIME [epoch: 8.26 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018680821715701635		[learning rate: 0.0017686]
	Learning Rate: 0.00176864
	LOSS [training: 0.0018680821715701635 | validation: 0.003158310006603605]
	TIME [epoch: 8.29 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014389130739374289		[learning rate: 0.0017593]
	Learning Rate: 0.00175929
	LOSS [training: 0.0014389130739374289 | validation: 0.004081094331306493]
	TIME [epoch: 8.26 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026564969867358948		[learning rate: 0.00175]
	Learning Rate: 0.00174996
	LOSS [training: 0.0026564969867358948 | validation: 0.003156127183305613]
	TIME [epoch: 8.26 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00200911903274515		[learning rate: 0.0017407]
	Learning Rate: 0.00174065
	LOSS [training: 0.00200911903274515 | validation: 0.0017766381131706624]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_1589.pth
	Model improved!!!
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016886655965040864		[learning rate: 0.0017314]
	Learning Rate: 0.00173137
	LOSS [training: 0.0016886655965040864 | validation: 0.002250880052861649]
	TIME [epoch: 8.26 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016009825950210443		[learning rate: 0.0017221]
	Learning Rate: 0.00172211
	LOSS [training: 0.0016009825950210443 | validation: 0.00307643278562605]
	TIME [epoch: 8.29 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001978115429453434		[learning rate: 0.0017129]
	Learning Rate: 0.00171287
	LOSS [training: 0.001978115429453434 | validation: 0.0024030170155359956]
	TIME [epoch: 8.26 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017386229579480828		[learning rate: 0.0017037]
	Learning Rate: 0.00170365
	LOSS [training: 0.0017386229579480828 | validation: 0.0023304327997227324]
	TIME [epoch: 8.25 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001597098178856968		[learning rate: 0.0016945]
	Learning Rate: 0.00169446
	LOSS [training: 0.001597098178856968 | validation: 0.003816407984279734]
	TIME [epoch: 8.26 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016056620492152318		[learning rate: 0.0016853]
	Learning Rate: 0.00168529
	LOSS [training: 0.0016056620492152318 | validation: 0.003475442510070927]
	TIME [epoch: 8.26 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016092157795194895		[learning rate: 0.0016761]
	Learning Rate: 0.00167614
	LOSS [training: 0.0016092157795194895 | validation: 0.002690338952130584]
	TIME [epoch: 8.26 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016252048647454886		[learning rate: 0.001667]
	Learning Rate: 0.00166702
	LOSS [training: 0.0016252048647454886 | validation: 0.0026119662595681954]
	TIME [epoch: 8.29 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004752156844412037		[learning rate: 0.0016579]
	Learning Rate: 0.00165792
	LOSS [training: 0.004752156844412037 | validation: 0.00623394606193433]
	TIME [epoch: 8.26 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002172460595597396		[learning rate: 0.0016488]
	Learning Rate: 0.00164884
	LOSS [training: 0.002172460595597396 | validation: 0.004235396839704002]
	TIME [epoch: 8.26 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016626368599879748		[learning rate: 0.0016398]
	Learning Rate: 0.00163978
	LOSS [training: 0.0016626368599879748 | validation: 0.004317535942159326]
	TIME [epoch: 8.26 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001904514216756665		[learning rate: 0.0016307]
	Learning Rate: 0.00163075
	LOSS [training: 0.001904514216756665 | validation: 0.003800080510183726]
	TIME [epoch: 8.26 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002237639003738018		[learning rate: 0.0016217]
	Learning Rate: 0.00162174
	LOSS [training: 0.002237639003738018 | validation: 0.0034897695442246664]
	TIME [epoch: 8.29 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018206829378824725		[learning rate: 0.0016128]
	Learning Rate: 0.00161275
	LOSS [training: 0.0018206829378824725 | validation: 0.003691117321749156]
	TIME [epoch: 8.26 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017633470711622867		[learning rate: 0.0016038]
	Learning Rate: 0.00160379
	LOSS [training: 0.0017633470711622867 | validation: 0.0031902032896603157]
	TIME [epoch: 8.25 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016531391994979267		[learning rate: 0.0015948]
	Learning Rate: 0.00159484
	LOSS [training: 0.0016531391994979267 | validation: 0.004062420456183354]
	TIME [epoch: 8.25 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018698416755536839		[learning rate: 0.0015859]
	Learning Rate: 0.00158593
	LOSS [training: 0.0018698416755536839 | validation: 0.002917145735432527]
	TIME [epoch: 8.26 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018635459796842624		[learning rate: 0.001577]
	Learning Rate: 0.00157703
	LOSS [training: 0.0018635459796842624 | validation: 0.0025434548745767315]
	TIME [epoch: 8.26 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017521953312902058		[learning rate: 0.0015682]
	Learning Rate: 0.00156816
	LOSS [training: 0.0017521953312902058 | validation: 0.0026044597368051247]
	TIME [epoch: 8.29 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015943529609290827		[learning rate: 0.0015593]
	Learning Rate: 0.00155931
	LOSS [training: 0.0015943529609290827 | validation: 0.002983198448492707]
	TIME [epoch: 8.26 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017081189162841126		[learning rate: 0.0015505]
	Learning Rate: 0.00155048
	LOSS [training: 0.0017081189162841126 | validation: 0.003506337118636429]
	TIME [epoch: 8.26 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020731339608040804		[learning rate: 0.0015417]
	Learning Rate: 0.00154168
	LOSS [training: 0.0020731339608040804 | validation: 0.0020745731863808957]
	TIME [epoch: 8.26 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020373826476532413		[learning rate: 0.0015329]
	Learning Rate: 0.0015329
	LOSS [training: 0.0020373826476532413 | validation: 0.0028195079241237816]
	TIME [epoch: 8.26 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002892122996906283		[learning rate: 0.0015241]
	Learning Rate: 0.00152414
	LOSS [training: 0.002892122996906283 | validation: 0.0025677753706185424]
	TIME [epoch: 8.29 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001522428547153905		[learning rate: 0.0015154]
	Learning Rate: 0.00151541
	LOSS [training: 0.001522428547153905 | validation: 0.0027232736379870478]
	TIME [epoch: 8.26 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00205645710760336		[learning rate: 0.0015067]
	Learning Rate: 0.0015067
	LOSS [training: 0.00205645710760336 | validation: 0.0021378215120322146]
	TIME [epoch: 8.26 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013198397071778306		[learning rate: 0.001498]
	Learning Rate: 0.00149801
	LOSS [training: 0.0013198397071778306 | validation: 0.002377252645838641]
	TIME [epoch: 8.26 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013747825336211767		[learning rate: 0.0014893]
	Learning Rate: 0.00148934
	LOSS [training: 0.0013747825336211767 | validation: 0.002616502483145786]
	TIME [epoch: 8.26 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017021002862513312		[learning rate: 0.0014807]
	Learning Rate: 0.0014807
	LOSS [training: 0.0017021002862513312 | validation: 0.0019209858294893412]
	TIME [epoch: 8.26 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012365258484573647		[learning rate: 0.0014721]
	Learning Rate: 0.00147209
	LOSS [training: 0.0012365258484573647 | validation: 0.0017837000369351516]
	TIME [epoch: 8.3 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012091031762823767		[learning rate: 0.0014635]
	Learning Rate: 0.00146349
	LOSS [training: 0.0012091031762823767 | validation: 0.0030560657477310374]
	TIME [epoch: 8.26 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016955916073662424		[learning rate: 0.0014549]
	Learning Rate: 0.00145492
	LOSS [training: 0.0016955916073662424 | validation: 0.00205078347744397]
	TIME [epoch: 8.25 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013550847598044395		[learning rate: 0.0014464]
	Learning Rate: 0.00144637
	LOSS [training: 0.0013550847598044395 | validation: 0.0032083475397878506]
	TIME [epoch: 8.26 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022029898858730726		[learning rate: 0.0014378]
	Learning Rate: 0.00143785
	LOSS [training: 0.0022029898858730726 | validation: 0.0038664421581265807]
	TIME [epoch: 8.26 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002010558344739004		[learning rate: 0.0014293]
	Learning Rate: 0.00142935
	LOSS [training: 0.002010558344739004 | validation: 0.002680137842327456]
	TIME [epoch: 8.27 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014933875856962245		[learning rate: 0.0014209]
	Learning Rate: 0.00142087
	LOSS [training: 0.0014933875856962245 | validation: 0.0030263263661314994]
	TIME [epoch: 8.28 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001753419473397037		[learning rate: 0.0014124]
	Learning Rate: 0.00141242
	LOSS [training: 0.001753419473397037 | validation: 0.0023874164426692774]
	TIME [epoch: 8.25 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018786088258563357		[learning rate: 0.001404]
	Learning Rate: 0.00140399
	LOSS [training: 0.0018786088258563357 | validation: 0.0021585708290666984]
	TIME [epoch: 8.25 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001431451511004211		[learning rate: 0.0013956]
	Learning Rate: 0.00139558
	LOSS [training: 0.001431451511004211 | validation: 0.003641805203931635]
	TIME [epoch: 8.26 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014936558587508692		[learning rate: 0.0013872]
	Learning Rate: 0.0013872
	LOSS [training: 0.0014936558587508692 | validation: 0.002822789732070972]
	TIME [epoch: 8.25 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015278308626788888		[learning rate: 0.0013788]
	Learning Rate: 0.00137884
	LOSS [training: 0.0015278308626788888 | validation: 0.0026742373496795742]
	TIME [epoch: 8.29 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001307508240095267		[learning rate: 0.0013705]
	Learning Rate: 0.0013705
	LOSS [training: 0.001307508240095267 | validation: 0.0026235522925144488]
	TIME [epoch: 8.27 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016861567830699213		[learning rate: 0.0013622]
	Learning Rate: 0.00136219
	LOSS [training: 0.0016861567830699213 | validation: 0.002197029635435853]
	TIME [epoch: 8.25 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013028448687474044		[learning rate: 0.0013539]
	Learning Rate: 0.0013539
	LOSS [training: 0.0013028448687474044 | validation: 0.002071080485818301]
	TIME [epoch: 8.26 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012416783733791492		[learning rate: 0.0013456]
	Learning Rate: 0.00134564
	LOSS [training: 0.0012416783733791492 | validation: 0.002115728636115542]
	TIME [epoch: 8.26 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018493178574868355		[learning rate: 0.0013374]
	Learning Rate: 0.00133739
	LOSS [training: 0.0018493178574868355 | validation: 0.006547273430478919]
	TIME [epoch: 8.26 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015306370644727258		[learning rate: 0.0013292]
	Learning Rate: 0.00132918
	LOSS [training: 0.0015306370644727258 | validation: 0.002089474428428775]
	TIME [epoch: 8.29 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015342822587454058		[learning rate: 0.001321]
	Learning Rate: 0.00132098
	LOSS [training: 0.0015342822587454058 | validation: 0.002290396731041617]
	TIME [epoch: 8.26 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012892219639479157		[learning rate: 0.0013128]
	Learning Rate: 0.00131281
	LOSS [training: 0.0012892219639479157 | validation: 0.0021835556617925923]
	TIME [epoch: 8.25 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001403662570829944		[learning rate: 0.0013047]
	Learning Rate: 0.00130466
	LOSS [training: 0.001403662570829944 | validation: 0.0019232898680259548]
	TIME [epoch: 8.25 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014867070162013197		[learning rate: 0.0012965]
	Learning Rate: 0.00129654
	LOSS [training: 0.0014867070162013197 | validation: 0.0019025029897946882]
	TIME [epoch: 8.26 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001245412641639692		[learning rate: 0.0012884]
	Learning Rate: 0.00128844
	LOSS [training: 0.001245412641639692 | validation: 0.0030453137206978413]
	TIME [epoch: 8.3 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012724585623456709		[learning rate: 0.0012804]
	Learning Rate: 0.00128037
	LOSS [training: 0.0012724585623456709 | validation: 0.0027479320889110996]
	TIME [epoch: 8.26 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013093682555182055		[learning rate: 0.0012723]
	Learning Rate: 0.00127232
	LOSS [training: 0.0013093682555182055 | validation: 0.0027401029021197915]
	TIME [epoch: 8.25 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017406790272989927		[learning rate: 0.0012643]
	Learning Rate: 0.00126429
	LOSS [training: 0.0017406790272989927 | validation: 0.0029703867354747013]
	TIME [epoch: 8.25 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014929791030289376		[learning rate: 0.0012563]
	Learning Rate: 0.00125629
	LOSS [training: 0.0014929791030289376 | validation: 0.002007321646347723]
	TIME [epoch: 8.26 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014255793168620316		[learning rate: 0.0012483]
	Learning Rate: 0.00124831
	LOSS [training: 0.0014255793168620316 | validation: 0.0022746395181187716]
	TIME [epoch: 8.26 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015168500900465567		[learning rate: 0.0012404]
	Learning Rate: 0.00124035
	LOSS [training: 0.0015168500900465567 | validation: 0.003008091876966664]
	TIME [epoch: 8.29 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014690992517339386		[learning rate: 0.0012324]
	Learning Rate: 0.00123242
	LOSS [training: 0.0014690992517339386 | validation: 0.0025033629902976324]
	TIME [epoch: 8.26 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013031035232904742		[learning rate: 0.0012245]
	Learning Rate: 0.00122451
	LOSS [training: 0.0013031035232904742 | validation: 0.0023135925709685907]
	TIME [epoch: 8.25 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013953159287985548		[learning rate: 0.0012166]
	Learning Rate: 0.00121663
	LOSS [training: 0.0013953159287985548 | validation: 0.002753455071834602]
	TIME [epoch: 8.25 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015216632565254334		[learning rate: 0.0012088]
	Learning Rate: 0.00120877
	LOSS [training: 0.0015216632565254334 | validation: 0.0018320295045572107]
	TIME [epoch: 8.25 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001406175523087698		[learning rate: 0.0012009]
	Learning Rate: 0.00120093
	LOSS [training: 0.001406175523087698 | validation: 0.0025534722025161074]
	TIME [epoch: 8.29 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001710590052810286		[learning rate: 0.0011931]
	Learning Rate: 0.00119312
	LOSS [training: 0.001710590052810286 | validation: 0.002463793313985059]
	TIME [epoch: 8.26 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015128085444147403		[learning rate: 0.0011853]
	Learning Rate: 0.00118533
	LOSS [training: 0.0015128085444147403 | validation: 0.0025017114084780125]
	TIME [epoch: 8.26 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013700524820819033		[learning rate: 0.0011776]
	Learning Rate: 0.00117757
	LOSS [training: 0.0013700524820819033 | validation: 0.001961497303377329]
	TIME [epoch: 8.25 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014001705464689025		[learning rate: 0.0011698]
	Learning Rate: 0.00116983
	LOSS [training: 0.0014001705464689025 | validation: 0.001601978534108487]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_1656.pth
	Model improved!!!
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013387121118733007		[learning rate: 0.0011621]
	Learning Rate: 0.00116211
	LOSS [training: 0.0013387121118733007 | validation: 0.002027867523010567]
	TIME [epoch: 8.28 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001233563150788705		[learning rate: 0.0011544]
	Learning Rate: 0.00115442
	LOSS [training: 0.001233563150788705 | validation: 0.0021007458060100606]
	TIME [epoch: 8.3 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016186543269099017		[learning rate: 0.0011468]
	Learning Rate: 0.00114676
	LOSS [training: 0.0016186543269099017 | validation: 0.002443685866384534]
	TIME [epoch: 8.27 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014524397874026		[learning rate: 0.0011391]
	Learning Rate: 0.00113911
	LOSS [training: 0.0014524397874026 | validation: 0.002081744172331264]
	TIME [epoch: 8.27 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001245832985530171		[learning rate: 0.0011315]
	Learning Rate: 0.0011315
	LOSS [training: 0.001245832985530171 | validation: 0.0024307008530803707]
	TIME [epoch: 8.27 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013269093257102706		[learning rate: 0.0011239]
	Learning Rate: 0.0011239
	LOSS [training: 0.0013269093257102706 | validation: 0.0028827598522983893]
	TIME [epoch: 8.27 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00138172261285108		[learning rate: 0.0011163]
	Learning Rate: 0.00111633
	LOSS [training: 0.00138172261285108 | validation: 0.00263341268072711]
	TIME [epoch: 8.31 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012489237835513		[learning rate: 0.0011088]
	Learning Rate: 0.00110879
	LOSS [training: 0.0012489237835513 | validation: 0.0018328754461329312]
	TIME [epoch: 8.28 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011083995313495392		[learning rate: 0.0011013]
	Learning Rate: 0.00110127
	LOSS [training: 0.0011083995313495392 | validation: 0.0022531526212700363]
	TIME [epoch: 8.27 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011374815715406417		[learning rate: 0.0010938]
	Learning Rate: 0.00109377
	LOSS [training: 0.0011374815715406417 | validation: 0.0019211876280477548]
	TIME [epoch: 8.27 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010168482849449		[learning rate: 0.0010863]
	Learning Rate: 0.0010863
	LOSS [training: 0.0010168482849449 | validation: 0.0018742589620273425]
	TIME [epoch: 8.27 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014250024014748814		[learning rate: 0.0010788]
	Learning Rate: 0.00107885
	LOSS [training: 0.0014250024014748814 | validation: 0.002258676725791105]
	TIME [epoch: 8.27 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012530150678143888		[learning rate: 0.0010714]
	Learning Rate: 0.00107143
	LOSS [training: 0.0012530150678143888 | validation: 0.0024730070370228502]
	TIME [epoch: 8.32 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013555082781631983		[learning rate: 0.001064]
	Learning Rate: 0.00106403
	LOSS [training: 0.0013555082781631983 | validation: 0.002364798478396157]
	TIME [epoch: 8.27 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017616661218750503		[learning rate: 0.0010567]
	Learning Rate: 0.00105665
	LOSS [training: 0.0017616661218750503 | validation: 0.002087316956533501]
	TIME [epoch: 8.27 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016460572315067402		[learning rate: 0.0010493]
	Learning Rate: 0.0010493
	LOSS [training: 0.0016460572315067402 | validation: 0.002389663579724948]
	TIME [epoch: 8.26 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014898883315356709		[learning rate: 0.001042]
	Learning Rate: 0.00104198
	LOSS [training: 0.0014898883315356709 | validation: 0.0019693383271343202]
	TIME [epoch: 8.27 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012524244835177938		[learning rate: 0.0010347]
	Learning Rate: 0.00103467
	LOSS [training: 0.0012524244835177938 | validation: 0.002387290000334396]
	TIME [epoch: 8.29 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001421530170832725		[learning rate: 0.0010274]
	Learning Rate: 0.0010274
	LOSS [training: 0.001421530170832725 | validation: 0.0023074620127046153]
	TIME [epoch: 8.29 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00113790479802295		[learning rate: 0.0010201]
	Learning Rate: 0.00102015
	LOSS [training: 0.00113790479802295 | validation: 0.0023827084300676146]
	TIME [epoch: 8.27 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013909482364992134		[learning rate: 0.0010129]
	Learning Rate: 0.00101292
	LOSS [training: 0.0013909482364992134 | validation: 0.001729630506063967]
	TIME [epoch: 8.27 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011466135377077623		[learning rate: 0.0010057]
	Learning Rate: 0.00100571
	LOSS [training: 0.0011466135377077623 | validation: 0.0018464473810220533]
	TIME [epoch: 8.27 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010720899906540068		[learning rate: 0.00099854]
	Learning Rate: 0.000998536
	LOSS [training: 0.0010720899906540068 | validation: 0.0021937968201250738]
	TIME [epoch: 8.27 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011894572923238974		[learning rate: 0.00099138]
	Learning Rate: 0.000991382
	LOSS [training: 0.0011894572923238974 | validation: 0.003003369527245923]
	TIME [epoch: 8.31 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001548569914565064		[learning rate: 0.00098425]
	Learning Rate: 0.000984253
	LOSS [training: 0.001548569914565064 | validation: 0.0026828631021195955]
	TIME [epoch: 8.27 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012047871509282193		[learning rate: 0.00097715]
	Learning Rate: 0.000977149
	LOSS [training: 0.0012047871509282193 | validation: 0.00152997356942147]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_1682.pth
	Model improved!!!
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001293464015457539		[learning rate: 0.00097007]
	Learning Rate: 0.000970069
	LOSS [training: 0.001293464015457539 | validation: 0.0016541427126135597]
	TIME [epoch: 8.27 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011589567630329897		[learning rate: 0.00096301]
	Learning Rate: 0.000963014
	LOSS [training: 0.0011589567630329897 | validation: 0.0018198799014902162]
	TIME [epoch: 8.27 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014267403132056627		[learning rate: 0.00095598]
	Learning Rate: 0.000955983
	LOSS [training: 0.0014267403132056627 | validation: 0.0017666599030523999]
	TIME [epoch: 8.28 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010878701511039517		[learning rate: 0.00094898]
	Learning Rate: 0.000948977
	LOSS [training: 0.0010878701511039517 | validation: 0.002680171108103889]
	TIME [epoch: 8.29 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013092306051856915		[learning rate: 0.000942]
	Learning Rate: 0.000941996
	LOSS [training: 0.0013092306051856915 | validation: 0.002321830078614337]
	TIME [epoch: 8.26 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012059313349007171		[learning rate: 0.00093504]
	Learning Rate: 0.00093504
	LOSS [training: 0.0012059313349007171 | validation: 0.002774679930543929]
	TIME [epoch: 8.26 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013843399191994506		[learning rate: 0.00092811]
	Learning Rate: 0.000928109
	LOSS [training: 0.0013843399191994506 | validation: 0.002600455973314084]
	TIME [epoch: 8.27 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001010295120539143		[learning rate: 0.0009212]
	Learning Rate: 0.000921202
	LOSS [training: 0.001010295120539143 | validation: 0.00226334866799266]
	TIME [epoch: 8.26 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013562716498326942		[learning rate: 0.00091432]
	Learning Rate: 0.000914321
	LOSS [training: 0.0013562716498326942 | validation: 0.0017092922542192215]
	TIME [epoch: 8.31 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012891474414891625		[learning rate: 0.00090746]
	Learning Rate: 0.000907464
	LOSS [training: 0.0012891474414891625 | validation: 0.001735443468490483]
	TIME [epoch: 8.26 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011449484801112268		[learning rate: 0.00090063]
	Learning Rate: 0.000900632
	LOSS [training: 0.0011449484801112268 | validation: 0.0018679580303532558]
	TIME [epoch: 8.26 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014542419052444176		[learning rate: 0.00089382]
	Learning Rate: 0.000893825
	LOSS [training: 0.0014542419052444176 | validation: 0.002170915219205821]
	TIME [epoch: 8.26 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015680092512233579		[learning rate: 0.00088704]
	Learning Rate: 0.000887043
	LOSS [training: 0.0015680092512233579 | validation: 0.0026387265329834834]
	TIME [epoch: 8.26 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013445602359796346		[learning rate: 0.00088029]
	Learning Rate: 0.000880285
	LOSS [training: 0.0013445602359796346 | validation: 0.0017914711712554128]
	TIME [epoch: 8.28 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014580394253574035		[learning rate: 0.00087355]
	Learning Rate: 0.000873553
	LOSS [training: 0.0014580394253574035 | validation: 0.0017975273355903382]
	TIME [epoch: 8.29 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008418210000185591		[learning rate: 0.00086685]
	Learning Rate: 0.000866846
	LOSS [training: 0.0008418210000185591 | validation: 0.002281225341959986]
	TIME [epoch: 8.26 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001044142019981994		[learning rate: 0.00086016]
	Learning Rate: 0.000860163
	LOSS [training: 0.001044142019981994 | validation: 0.0019699403474710353]
	TIME [epoch: 8.26 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011950580043783466		[learning rate: 0.00085351]
	Learning Rate: 0.000853506
	LOSS [training: 0.0011950580043783466 | validation: 0.0016761113613515555]
	TIME [epoch: 8.26 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013370749389568963		[learning rate: 0.00084687]
	Learning Rate: 0.000846874
	LOSS [training: 0.0013370749389568963 | validation: 0.002004492601580466]
	TIME [epoch: 8.26 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012505428527466798		[learning rate: 0.00084027]
	Learning Rate: 0.000840266
	LOSS [training: 0.0012505428527466798 | validation: 0.0026080461845967022]
	TIME [epoch: 8.29 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001283526930522799		[learning rate: 0.00083368]
	Learning Rate: 0.000833684
	LOSS [training: 0.001283526930522799 | validation: 0.0017951581105892]
	TIME [epoch: 8.26 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012666881739021908		[learning rate: 0.00082713]
	Learning Rate: 0.000827127
	LOSS [training: 0.0012666881739021908 | validation: 0.0020196008867329127]
	TIME [epoch: 8.26 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010533462317089278		[learning rate: 0.00082059]
	Learning Rate: 0.000820595
	LOSS [training: 0.0010533462317089278 | validation: 0.002155951065049875]
	TIME [epoch: 8.26 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012561558472288794		[learning rate: 0.00081409]
	Learning Rate: 0.000814088
	LOSS [training: 0.0012561558472288794 | validation: 0.0013364688398975462]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_1706.pth
	Model improved!!!
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008800768345769999		[learning rate: 0.00080761]
	Learning Rate: 0.000807606
	LOSS [training: 0.0008800768345769999 | validation: 0.002088864074951153]
	TIME [epoch: 8.27 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012420389703747133		[learning rate: 0.00080115]
	Learning Rate: 0.000801149
	LOSS [training: 0.0012420389703747133 | validation: 0.0015334564309636349]
	TIME [epoch: 8.28 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001123917977329314		[learning rate: 0.00079472]
	Learning Rate: 0.000794718
	LOSS [training: 0.001123917977329314 | validation: 0.0019348461435762278]
	TIME [epoch: 8.25 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011340279503409849		[learning rate: 0.00078831]
	Learning Rate: 0.000788312
	LOSS [training: 0.0011340279503409849 | validation: 0.0017156395465708176]
	TIME [epoch: 8.25 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012850982754239616		[learning rate: 0.00078193]
	Learning Rate: 0.00078193
	LOSS [training: 0.0012850982754239616 | validation: 0.002005772783949918]
	TIME [epoch: 8.25 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013619963006682475		[learning rate: 0.00077557]
	Learning Rate: 0.000775574
	LOSS [training: 0.0013619963006682475 | validation: 0.0017672418005049632]
	TIME [epoch: 8.25 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011724886152590548		[learning rate: 0.00076924]
	Learning Rate: 0.000769244
	LOSS [training: 0.0011724886152590548 | validation: 0.0021557373906439274]
	TIME [epoch: 8.29 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011979593013864225		[learning rate: 0.00076294]
	Learning Rate: 0.000762938
	LOSS [training: 0.0011979593013864225 | validation: 0.0016399249236941776]
	TIME [epoch: 8.26 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009101281140879668		[learning rate: 0.00075666]
	Learning Rate: 0.000756658
	LOSS [training: 0.0009101281140879668 | validation: 0.0015095142279659538]
	TIME [epoch: 8.25 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011117226997920846		[learning rate: 0.0007504]
	Learning Rate: 0.000750403
	LOSS [training: 0.0011117226997920846 | validation: 0.0015948211058575226]
	TIME [epoch: 8.25 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001072939291116441		[learning rate: 0.00074417]
	Learning Rate: 0.000744174
	LOSS [training: 0.001072939291116441 | validation: 0.0016584725812984003]
	TIME [epoch: 8.25 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012226965935133657		[learning rate: 0.00073797]
	Learning Rate: 0.000737969
	LOSS [training: 0.0012226965935133657 | validation: 0.0018641658030172053]
	TIME [epoch: 8.26 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011760956586947162		[learning rate: 0.00073179]
	Learning Rate: 0.00073179
	LOSS [training: 0.0011760956586947162 | validation: 0.0018714890205633933]
	TIME [epoch: 8.29 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011798850336267029		[learning rate: 0.00072564]
	Learning Rate: 0.000725637
	LOSS [training: 0.0011798850336267029 | validation: 0.002143888802507127]
	TIME [epoch: 8.26 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010377874962350575		[learning rate: 0.00071951]
	Learning Rate: 0.000719509
	LOSS [training: 0.0010377874962350575 | validation: 0.001762173574108333]
	TIME [epoch: 8.26 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010587338125023237		[learning rate: 0.00071341]
	Learning Rate: 0.000713406
	LOSS [training: 0.0010587338125023237 | validation: 0.0017336864561782886]
	TIME [epoch: 8.26 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010849583001774194		[learning rate: 0.00070733]
	Learning Rate: 0.000707328
	LOSS [training: 0.0010849583001774194 | validation: 0.001429248812160358]
	TIME [epoch: 8.26 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009292052595166122		[learning rate: 0.00070128]
	Learning Rate: 0.000701276
	LOSS [training: 0.0009292052595166122 | validation: 0.0021447967803395348]
	TIME [epoch: 8.29 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010590348092345625		[learning rate: 0.00069525]
	Learning Rate: 0.00069525
	LOSS [training: 0.0010590348092345625 | validation: 0.0019620953363381987]
	TIME [epoch: 8.26 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008555419964930992		[learning rate: 0.00068925]
	Learning Rate: 0.000689249
	LOSS [training: 0.0008555419964930992 | validation: 0.0019488798953984088]
	TIME [epoch: 8.25 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010951465049443365		[learning rate: 0.00068327]
	Learning Rate: 0.000683273
	LOSS [training: 0.0010951465049443365 | validation: 0.0018385960051923273]
	TIME [epoch: 8.26 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001093435042389678		[learning rate: 0.00067732]
	Learning Rate: 0.000677323
	LOSS [training: 0.001093435042389678 | validation: 0.0012527112899964506]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_1728.pth
	Model improved!!!
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010189624202630622		[learning rate: 0.0006714]
	Learning Rate: 0.000671398
	LOSS [training: 0.0010189624202630622 | validation: 0.0021818144123506144]
	TIME [epoch: 8.26 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000941332288246232		[learning rate: 0.0006655]
	Learning Rate: 0.000665499
	LOSS [training: 0.000941332288246232 | validation: 0.0016506633035491501]
	TIME [epoch: 8.29 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009913090607543147		[learning rate: 0.00065963]
	Learning Rate: 0.000659625
	LOSS [training: 0.0009913090607543147 | validation: 0.0015252941960370585]
	TIME [epoch: 8.26 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001038677726748489		[learning rate: 0.00065378]
	Learning Rate: 0.000653777
	LOSS [training: 0.001038677726748489 | validation: 0.002140743483616852]
	TIME [epoch: 8.25 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010237377263660544		[learning rate: 0.00064795]
	Learning Rate: 0.000647955
	LOSS [training: 0.0010237377263660544 | validation: 0.0016864978059872994]
	TIME [epoch: 8.26 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011842250755024967		[learning rate: 0.00064216]
	Learning Rate: 0.000642158
	LOSS [training: 0.0011842250755024967 | validation: 0.0013851978352748128]
	TIME [epoch: 8.25 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001059542187891317		[learning rate: 0.00063639]
	Learning Rate: 0.000636387
	LOSS [training: 0.001059542187891317 | validation: 0.0019391022215241092]
	TIME [epoch: 8.29 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011609000687837579		[learning rate: 0.00063064]
	Learning Rate: 0.000630641
	LOSS [training: 0.0011609000687837579 | validation: 0.0017950865173569372]
	TIME [epoch: 8.26 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010219159604422739		[learning rate: 0.00062492]
	Learning Rate: 0.000624921
	LOSS [training: 0.0010219159604422739 | validation: 0.001534919086739345]
	TIME [epoch: 8.25 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011675744974898906		[learning rate: 0.00061923]
	Learning Rate: 0.000619226
	LOSS [training: 0.0011675744974898906 | validation: 0.0015767364028932346]
	TIME [epoch: 8.25 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009534507964378929		[learning rate: 0.00061356]
	Learning Rate: 0.000613558
	LOSS [training: 0.0009534507964378929 | validation: 0.0022527802117352476]
	TIME [epoch: 8.25 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009395678674135486		[learning rate: 0.00060791]
	Learning Rate: 0.000607914
	LOSS [training: 0.0009395678674135486 | validation: 0.0021856922717289036]
	TIME [epoch: 8.27 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009574009711244303		[learning rate: 0.0006023]
	Learning Rate: 0.000602297
	LOSS [training: 0.0009574009711244303 | validation: 0.002102553769808437]
	TIME [epoch: 8.29 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010074382531514462		[learning rate: 0.00059671]
	Learning Rate: 0.000596705
	LOSS [training: 0.0010074382531514462 | validation: 0.0020445483124006468]
	TIME [epoch: 8.26 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010243391878584991		[learning rate: 0.00059114]
	Learning Rate: 0.000591139
	LOSS [training: 0.0010243391878584991 | validation: 0.0023268882265865118]
	TIME [epoch: 8.26 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013522330407642667		[learning rate: 0.0005856]
	Learning Rate: 0.000585599
	LOSS [training: 0.0013522330407642667 | validation: 0.0018400328917818883]
	TIME [epoch: 8.26 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008742166383554232		[learning rate: 0.00058008]
	Learning Rate: 0.000580085
	LOSS [training: 0.0008742166383554232 | validation: 0.001588421084333822]
	TIME [epoch: 8.25 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000967481383968211		[learning rate: 0.0005746]
	Learning Rate: 0.000574596
	LOSS [training: 0.000967481383968211 | validation: 0.0019979943967111495]
	TIME [epoch: 8.29 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010534815770466511		[learning rate: 0.00056913]
	Learning Rate: 0.000569133
	LOSS [training: 0.0010534815770466511 | validation: 0.0015535520920772115]
	TIME [epoch: 8.26 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009385301582576398		[learning rate: 0.0005637]
	Learning Rate: 0.000563696
	LOSS [training: 0.0009385301582576398 | validation: 0.0012620251697033488]
	TIME [epoch: 8.25 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009317978527177695		[learning rate: 0.00055828]
	Learning Rate: 0.000558285
	LOSS [training: 0.0009317978527177695 | validation: 0.0017938852882333639]
	TIME [epoch: 8.25 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001002264133062239		[learning rate: 0.0005529]
	Learning Rate: 0.000552899
	LOSS [training: 0.001002264133062239 | validation: 0.0022196895077180104]
	TIME [epoch: 8.25 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009638462685304158		[learning rate: 0.00054754]
	Learning Rate: 0.000547539
	LOSS [training: 0.0009638462685304158 | validation: 0.002090243835704391]
	TIME [epoch: 8.26 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011947022343859197		[learning rate: 0.00054221]
	Learning Rate: 0.000542206
	LOSS [training: 0.0011947022343859197 | validation: 0.0019912642040691457]
	TIME [epoch: 8.29 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001177327384198408		[learning rate: 0.0005369]
	Learning Rate: 0.000536898
	LOSS [training: 0.001177327384198408 | validation: 0.0020056619645741716]
	TIME [epoch: 8.26 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009726316907672528		[learning rate: 0.00053162]
	Learning Rate: 0.000531616
	LOSS [training: 0.0009726316907672528 | validation: 0.0020392914344572618]
	TIME [epoch: 8.25 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009346675549792439		[learning rate: 0.00052636]
	Learning Rate: 0.000526359
	LOSS [training: 0.0009346675549792439 | validation: 0.0020635268436592497]
	TIME [epoch: 8.25 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008268171352010189		[learning rate: 0.00052113]
	Learning Rate: 0.000521129
	LOSS [training: 0.0008268171352010189 | validation: 0.0018121181154348606]
	TIME [epoch: 8.25 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007003327846577076		[learning rate: 0.00051592]
	Learning Rate: 0.000515925
	LOSS [training: 0.0007003327846577076 | validation: 0.001480274281897901]
	TIME [epoch: 8.27 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008496888658094908		[learning rate: 0.00051075]
	Learning Rate: 0.000510746
	LOSS [training: 0.0008496888658094908 | validation: 0.001966001762337245]
	TIME [epoch: 8.28 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010414466685577466		[learning rate: 0.00050559]
	Learning Rate: 0.000505594
	LOSS [training: 0.0010414466685577466 | validation: 0.001389290670063252]
	TIME [epoch: 8.25 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008478391840170219		[learning rate: 0.00050047]
	Learning Rate: 0.000500468
	LOSS [training: 0.0008478391840170219 | validation: 0.0015042609707505896]
	TIME [epoch: 8.25 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007864015147703156		[learning rate: 0.00049537]
	Learning Rate: 0.000495367
	LOSS [training: 0.0007864015147703156 | validation: 0.0016166416152820781]
	TIME [epoch: 8.26 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009295040589037175		[learning rate: 0.00049029]
	Learning Rate: 0.000490293
	LOSS [training: 0.0009295040589037175 | validation: 0.0015708694694924505]
	TIME [epoch: 8.25 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011094804773639398		[learning rate: 0.00048524]
	Learning Rate: 0.000485244
	LOSS [training: 0.0011094804773639398 | validation: 0.002257459522015638]
	TIME [epoch: 8.29 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000905694660095079		[learning rate: 0.00048022]
	Learning Rate: 0.000480222
	LOSS [training: 0.000905694660095079 | validation: 0.0016244282746044059]
	TIME [epoch: 8.26 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001013162329609007		[learning rate: 0.00047523]
	Learning Rate: 0.000475226
	LOSS [training: 0.001013162329609007 | validation: 0.0015106444473506322]
	TIME [epoch: 8.26 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000983158736509281		[learning rate: 0.00047026]
	Learning Rate: 0.000470255
	LOSS [training: 0.000983158736509281 | validation: 0.0015459890308309383]
	TIME [epoch: 8.26 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008374784497763065		[learning rate: 0.00046531]
	Learning Rate: 0.000465311
	LOSS [training: 0.0008374784497763065 | validation: 0.0016225187569656116]
	TIME [epoch: 8.25 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000628199164273093		[learning rate: 0.00046039]
	Learning Rate: 0.000460393
	LOSS [training: 0.000628199164273093 | validation: 0.0016805074530219155]
	TIME [epoch: 8.26 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009990788221016654		[learning rate: 0.0004555]
	Learning Rate: 0.000455501
	LOSS [training: 0.0009990788221016654 | validation: 0.0012766246457150254]
	TIME [epoch: 8.29 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008639051448560797		[learning rate: 0.00045063]
	Learning Rate: 0.000450635
	LOSS [training: 0.0008639051448560797 | validation: 0.002143582378208291]
	TIME [epoch: 8.26 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009008747535709208		[learning rate: 0.00044579]
	Learning Rate: 0.000445795
	LOSS [training: 0.0009008747535709208 | validation: 0.0016433611991451685]
	TIME [epoch: 8.25 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009859023204299043		[learning rate: 0.00044098]
	Learning Rate: 0.000440981
	LOSS [training: 0.0009859023204299043 | validation: 0.0016052651093116817]
	TIME [epoch: 8.26 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009161821240627509		[learning rate: 0.00043619]
	Learning Rate: 0.000436194
	LOSS [training: 0.0009161821240627509 | validation: 0.0019026508914954884]
	TIME [epoch: 8.26 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008978404734729892		[learning rate: 0.00043143]
	Learning Rate: 0.000431432
	LOSS [training: 0.0008978404734729892 | validation: 0.0017010204895177507]
	TIME [epoch: 8.29 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000729045009378787		[learning rate: 0.0004267]
	Learning Rate: 0.000426697
	LOSS [training: 0.000729045009378787 | validation: 0.0016919300850578977]
	TIME [epoch: 8.26 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000792707206766969		[learning rate: 0.00042199]
	Learning Rate: 0.000421988
	LOSS [training: 0.000792707206766969 | validation: 0.0015720776759331656]
	TIME [epoch: 8.25 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008346800071997304		[learning rate: 0.00041731]
	Learning Rate: 0.000417305
	LOSS [training: 0.0008346800071997304 | validation: 0.0018593686638873372]
	TIME [epoch: 8.26 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000959299367641129		[learning rate: 0.00041265]
	Learning Rate: 0.000412649
	LOSS [training: 0.000959299367641129 | validation: 0.0016573573412299095]
	TIME [epoch: 8.26 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001059846165386921		[learning rate: 0.00040802]
	Learning Rate: 0.000408018
	LOSS [training: 0.001059846165386921 | validation: 0.0015703471438130343]
	TIME [epoch: 8.26 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001058086440238718		[learning rate: 0.00040341]
	Learning Rate: 0.000403414
	LOSS [training: 0.001058086440238718 | validation: 0.0012597603268166067]
	TIME [epoch: 8.29 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008457636629098055		[learning rate: 0.00039884]
	Learning Rate: 0.000398836
	LOSS [training: 0.0008457636629098055 | validation: 0.0019382627928175716]
	TIME [epoch: 8.26 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000888716537808507		[learning rate: 0.00039428]
	Learning Rate: 0.000394284
	LOSS [training: 0.000888716537808507 | validation: 0.0016744089354213355]
	TIME [epoch: 8.26 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010903579821557794		[learning rate: 0.00038976]
	Learning Rate: 0.000389759
	LOSS [training: 0.0010903579821557794 | validation: 0.0019756808467459148]
	TIME [epoch: 8.25 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000836818964981862		[learning rate: 0.00038526]
	Learning Rate: 0.00038526
	LOSS [training: 0.000836818964981862 | validation: 0.0015073272045998819]
	TIME [epoch: 8.26 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007057150390369982		[learning rate: 0.00038079]
	Learning Rate: 0.000380787
	LOSS [training: 0.0007057150390369982 | validation: 0.00186077154477932]
	TIME [epoch: 8.29 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008450241588422512		[learning rate: 0.00037634]
	Learning Rate: 0.000376341
	LOSS [training: 0.0008450241588422512 | validation: 0.0016745819951080065]
	TIME [epoch: 8.26 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000789463195794383		[learning rate: 0.00037192]
	Learning Rate: 0.00037192
	LOSS [training: 0.000789463195794383 | validation: 0.0015363629359454282]
	TIME [epoch: 8.25 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008880903391326278		[learning rate: 0.00036753]
	Learning Rate: 0.000367527
	LOSS [training: 0.0008880903391326278 | validation: 0.0018343211909408793]
	TIME [epoch: 8.25 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008253542703270884		[learning rate: 0.00036316]
	Learning Rate: 0.000363159
	LOSS [training: 0.0008253542703270884 | validation: 0.001617157322203715]
	TIME [epoch: 8.25 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009877860633176025		[learning rate: 0.00035882]
	Learning Rate: 0.000358818
	LOSS [training: 0.0009877860633176025 | validation: 0.001915740066746607]
	TIME [epoch: 8.25 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008127302999287218		[learning rate: 0.0003545]
	Learning Rate: 0.000354503
	LOSS [training: 0.0008127302999287218 | validation: 0.0015174106454979536]
	TIME [epoch: 8.29 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007851266872184594		[learning rate: 0.00035022]
	Learning Rate: 0.000350215
	LOSS [training: 0.0007851266872184594 | validation: 0.0012966731913145004]
	TIME [epoch: 8.26 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009766139658035193		[learning rate: 0.00034595]
	Learning Rate: 0.000345953
	LOSS [training: 0.0009766139658035193 | validation: 0.0013285331400810937]
	TIME [epoch: 8.25 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008728716026560114		[learning rate: 0.00034172]
	Learning Rate: 0.000341718
	LOSS [training: 0.0008728716026560114 | validation: 0.0016596116063499658]
	TIME [epoch: 8.25 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009623251916417081		[learning rate: 0.00033751]
	Learning Rate: 0.000337508
	LOSS [training: 0.0009623251916417081 | validation: 0.0015483653697197957]
	TIME [epoch: 8.26 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008971515566472128		[learning rate: 0.00033333]
	Learning Rate: 0.000333326
	LOSS [training: 0.0008971515566472128 | validation: 0.0013731198544359026]
	TIME [epoch: 8.27 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008481528898121453		[learning rate: 0.00032917]
	Learning Rate: 0.000329169
	LOSS [training: 0.0008481528898121453 | validation: 0.001788966732402395]
	TIME [epoch: 8.27 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008863792565436393		[learning rate: 0.00032504]
	Learning Rate: 0.00032504
	LOSS [training: 0.0008863792565436393 | validation: 0.0020790527794952193]
	TIME [epoch: 8.25 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009162144798709256		[learning rate: 0.00032094]
	Learning Rate: 0.000320936
	LOSS [training: 0.0009162144798709256 | validation: 0.0015564507159776177]
	TIME [epoch: 8.26 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009883653777772493		[learning rate: 0.00031686]
	Learning Rate: 0.000316859
	LOSS [training: 0.0009883653777772493 | validation: 0.0019562571332219633]
	TIME [epoch: 8.25 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009705564871326537		[learning rate: 0.00031281]
	Learning Rate: 0.000312809
	LOSS [training: 0.0009705564871326537 | validation: 0.0014123549867321224]
	TIME [epoch: 8.26 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009107802775478089		[learning rate: 0.00030879]
	Learning Rate: 0.000308785
	LOSS [training: 0.0009107802775478089 | validation: 0.0016111079050656887]
	TIME [epoch: 8.29 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008494194659971359		[learning rate: 0.00030479]
	Learning Rate: 0.000304788
	LOSS [training: 0.0008494194659971359 | validation: 0.0014971853882313536]
	TIME [epoch: 8.26 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008084168865163414		[learning rate: 0.00030082]
	Learning Rate: 0.000300817
	LOSS [training: 0.0008084168865163414 | validation: 0.00143689087258642]
	TIME [epoch: 8.25 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008887912687149872		[learning rate: 0.00029687]
	Learning Rate: 0.000296873
	LOSS [training: 0.0008887912687149872 | validation: 0.0015653484150193189]
	TIME [epoch: 8.25 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007594682683850049		[learning rate: 0.00029295]
	Learning Rate: 0.000292955
	LOSS [training: 0.0007594682683850049 | validation: 0.0015707096109981223]
	TIME [epoch: 8.25 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007118928611437465		[learning rate: 0.00028906]
	Learning Rate: 0.000289064
	LOSS [training: 0.0007118928611437465 | validation: 0.001374015490347399]
	TIME [epoch: 8.27 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007235802901367975		[learning rate: 0.0002852]
	Learning Rate: 0.000285199
	LOSS [training: 0.0007235802901367975 | validation: 0.0014830217010965807]
	TIME [epoch: 8.28 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008354251522309946		[learning rate: 0.00028136]
	Learning Rate: 0.000281361
	LOSS [training: 0.0008354251522309946 | validation: 0.0013996882414823953]
	TIME [epoch: 8.25 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001049772520206282		[learning rate: 0.00027755]
	Learning Rate: 0.000277549
	LOSS [training: 0.001049772520206282 | validation: 0.0017252538590916257]
	TIME [epoch: 8.26 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008425302825025262		[learning rate: 0.00027376]
	Learning Rate: 0.000273764
	LOSS [training: 0.0008425302825025262 | validation: 0.0015517150305612874]
	TIME [epoch: 8.26 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000740362662800103		[learning rate: 0.00027001]
	Learning Rate: 0.000270006
	LOSS [training: 0.000740362662800103 | validation: 0.0018330899012697923]
	TIME [epoch: 8.25 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010058882286587668		[learning rate: 0.00026627]
	Learning Rate: 0.000266274
	LOSS [training: 0.0010058882286587668 | validation: 0.0016689414305075226]
	TIME [epoch: 8.29 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008576144615864262		[learning rate: 0.00026257]
	Learning Rate: 0.000262569
	LOSS [training: 0.0008576144615864262 | validation: 0.0013454580133665601]
	TIME [epoch: 8.26 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009445981061765927		[learning rate: 0.00025889]
	Learning Rate: 0.000258891
	LOSS [training: 0.0009445981061765927 | validation: 0.0018316207856807136]
	TIME [epoch: 8.25 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007946255935908045		[learning rate: 0.00025524]
	Learning Rate: 0.000255239
	LOSS [training: 0.0007946255935908045 | validation: 0.0014447072961791927]
	TIME [epoch: 8.25 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008402736497800972		[learning rate: 0.00025161]
	Learning Rate: 0.000251614
	LOSS [training: 0.0008402736497800972 | validation: 0.0014227061396586676]
	TIME [epoch: 8.25 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001009129937412958		[learning rate: 0.00024802]
	Learning Rate: 0.000248016
	LOSS [training: 0.001009129937412958 | validation: 0.0014562384482766592]
	TIME [epoch: 8.26 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007594990307837558		[learning rate: 0.00024444]
	Learning Rate: 0.000244444
	LOSS [training: 0.0007594990307837558 | validation: 0.001383285053123007]
	TIME [epoch: 8.28 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009224069626707827		[learning rate: 0.0002409]
	Learning Rate: 0.000240899
	LOSS [training: 0.0009224069626707827 | validation: 0.0018819383872829025]
	TIME [epoch: 8.25 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008360439267965133		[learning rate: 0.00023738]
	Learning Rate: 0.00023738
	LOSS [training: 0.0008360439267965133 | validation: 0.0014212598236572483]
	TIME [epoch: 8.25 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008073042378177996		[learning rate: 0.00023389]
	Learning Rate: 0.000233889
	LOSS [training: 0.0008073042378177996 | validation: 0.0012842904805468525]
	TIME [epoch: 8.25 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009296013902530491		[learning rate: 0.00023042]
	Learning Rate: 0.000230424
	LOSS [training: 0.0009296013902530491 | validation: 0.0018408380137709566]
	TIME [epoch: 8.25 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000800875432295283		[learning rate: 0.00022699]
	Learning Rate: 0.000226985
	LOSS [training: 0.000800875432295283 | validation: 0.001476818689704854]
	TIME [epoch: 8.29 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010005064306715847		[learning rate: 0.00022357]
	Learning Rate: 0.000223574
	LOSS [training: 0.0010005064306715847 | validation: 0.0017851743852512483]
	TIME [epoch: 8.26 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007831203044353932		[learning rate: 0.00022019]
	Learning Rate: 0.000220189
	LOSS [training: 0.0007831203044353932 | validation: 0.0012380249617960403]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_1826.pth
	Model improved!!!
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006769670283793575		[learning rate: 0.00021683]
	Learning Rate: 0.000216831
	LOSS [training: 0.0006769670283793575 | validation: 0.002018061570042758]
	TIME [epoch: 8.26 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009136879933394089		[learning rate: 0.0002135]
	Learning Rate: 0.0002135
	LOSS [training: 0.0009136879933394089 | validation: 0.0015566597363218132]
	TIME [epoch: 8.25 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008308196637934308		[learning rate: 0.0002102]
	Learning Rate: 0.000210195
	LOSS [training: 0.0008308196637934308 | validation: 0.001541262020960125]
	TIME [epoch: 8.26 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008259130367183562		[learning rate: 0.00020692]
	Learning Rate: 0.000206917
	LOSS [training: 0.0008259130367183562 | validation: 0.0014031360079451343]
	TIME [epoch: 8.29 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009189491326841034		[learning rate: 0.00020367]
	Learning Rate: 0.000203667
	LOSS [training: 0.0009189491326841034 | validation: 0.0017320311634267008]
	TIME [epoch: 8.26 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000976521314220995		[learning rate: 0.00020044]
	Learning Rate: 0.000200442
	LOSS [training: 0.000976521314220995 | validation: 0.0014992174047642806]
	TIME [epoch: 8.26 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008287549673976063		[learning rate: 0.00019725]
	Learning Rate: 0.000197245
	LOSS [training: 0.0008287549673976063 | validation: 0.0016874331689197969]
	TIME [epoch: 8.26 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009059887666508755		[learning rate: 0.00019407]
	Learning Rate: 0.000194075
	LOSS [training: 0.0009059887666508755 | validation: 0.0017493028617067072]
	TIME [epoch: 8.26 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008350645944569195		[learning rate: 0.00019093]
	Learning Rate: 0.000190931
	LOSS [training: 0.0008350645944569195 | validation: 0.0014117034649788584]
	TIME [epoch: 8.29 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007166075074778551		[learning rate: 0.00018781]
	Learning Rate: 0.000187814
	LOSS [training: 0.0007166075074778551 | validation: 0.001271866920251556]
	TIME [epoch: 8.26 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008277411925355922		[learning rate: 0.00018472]
	Learning Rate: 0.000184724
	LOSS [training: 0.0008277411925355922 | validation: 0.0012246470652246453]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_1837.pth
	Model improved!!!
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000850288821338102		[learning rate: 0.00018166]
	Learning Rate: 0.000181661
	LOSS [training: 0.000850288821338102 | validation: 0.001257794703566698]
	TIME [epoch: 8.28 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007937600608164281		[learning rate: 0.00017862]
	Learning Rate: 0.000178624
	LOSS [training: 0.0007937600608164281 | validation: 0.0013720133389539546]
	TIME [epoch: 8.27 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009030583508179338		[learning rate: 0.00017561]
	Learning Rate: 0.000175615
	LOSS [training: 0.0009030583508179338 | validation: 0.0016751473093569516]
	TIME [epoch: 8.28 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008212652020388993		[learning rate: 0.00017263]
	Learning Rate: 0.000172632
	LOSS [training: 0.0008212652020388993 | validation: 0.0016126592012609242]
	TIME [epoch: 8.32 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008516348464524677		[learning rate: 0.00016968]
	Learning Rate: 0.000169677
	LOSS [training: 0.0008516348464524677 | validation: 0.0016236098827990687]
	TIME [epoch: 8.27 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000744651130436825		[learning rate: 0.00016675]
	Learning Rate: 0.000166748
	LOSS [training: 0.000744651130436825 | validation: 0.0011613547456395263]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_1843.pth
	Model improved!!!
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008609974629853155		[learning rate: 0.00016385]
	Learning Rate: 0.000163846
	LOSS [training: 0.0008609974629853155 | validation: 0.0013156872342091432]
	TIME [epoch: 8.27 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000865628993599688		[learning rate: 0.00016097]
	Learning Rate: 0.000160971
	LOSS [training: 0.000865628993599688 | validation: 0.0018095462347584165]
	TIME [epoch: 8.27 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007944690647530665		[learning rate: 0.00015812]
	Learning Rate: 0.000158123
	LOSS [training: 0.0007944690647530665 | validation: 0.001768928842422998]
	TIME [epoch: 8.3 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008674217556096853		[learning rate: 0.0001553]
	Learning Rate: 0.000155302
	LOSS [training: 0.0008674217556096853 | validation: 0.0014183562946218267]
	TIME [epoch: 8.27 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008598493067266585		[learning rate: 0.00015251]
	Learning Rate: 0.000152507
	LOSS [training: 0.0008598493067266585 | validation: 0.0014052260282583235]
	TIME [epoch: 8.27 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000957520942892844		[learning rate: 0.00014974]
	Learning Rate: 0.00014974
	LOSS [training: 0.000957520942892844 | validation: 0.0012401661636824172]
	TIME [epoch: 8.26 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008075022467102864		[learning rate: 0.000147]
	Learning Rate: 0.000147
	LOSS [training: 0.0008075022467102864 | validation: 0.0013413022652072827]
	TIME [epoch: 8.26 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008124901013006183		[learning rate: 0.00014429]
	Learning Rate: 0.000144286
	LOSS [training: 0.0008124901013006183 | validation: 0.0015509880207802988]
	TIME [epoch: 8.27 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008179178559627827		[learning rate: 0.0001416]
	Learning Rate: 0.0001416
	LOSS [training: 0.0008179178559627827 | validation: 0.0013422946366462743]
	TIME [epoch: 8.3 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009024192304296876		[learning rate: 0.00013894]
	Learning Rate: 0.00013894
	LOSS [training: 0.0009024192304296876 | validation: 0.0016167269440418484]
	TIME [epoch: 8.26 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005556233689708008		[learning rate: 0.00013631]
	Learning Rate: 0.000136308
	LOSS [training: 0.0005556233689708008 | validation: 0.0014041556822786277]
	TIME [epoch: 8.27 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006989404942859046		[learning rate: 0.0001337]
	Learning Rate: 0.000133702
	LOSS [training: 0.0006989404942859046 | validation: 0.001852684342025344]
	TIME [epoch: 8.27 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006910285298107188		[learning rate: 0.00013112]
	Learning Rate: 0.000131124
	LOSS [training: 0.0006910285298107188 | validation: 0.0013278476396051994]
	TIME [epoch: 8.27 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006901623648268365		[learning rate: 0.00012857]
	Learning Rate: 0.000128572
	LOSS [training: 0.0006901623648268365 | validation: 0.0014021231534342648]
	TIME [epoch: 8.3 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000730593478063196		[learning rate: 0.00012605]
	Learning Rate: 0.000126048
	LOSS [training: 0.000730593478063196 | validation: 0.0014877630886264512]
	TIME [epoch: 8.27 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006465225206691263		[learning rate: 0.00012355]
	Learning Rate: 0.00012355
	LOSS [training: 0.0006465225206691263 | validation: 0.001412133929877779]
	TIME [epoch: 8.27 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000758934510500651		[learning rate: 0.00012108]
	Learning Rate: 0.000121079
	LOSS [training: 0.000758934510500651 | validation: 0.001412893076170299]
	TIME [epoch: 8.26 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008053545107289908		[learning rate: 0.00011864]
	Learning Rate: 0.000118636
	LOSS [training: 0.0008053545107289908 | validation: 0.0015645404356530329]
	TIME [epoch: 8.26 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007397322549975154		[learning rate: 0.00011622]
	Learning Rate: 0.000116219
	LOSS [training: 0.0007397322549975154 | validation: 0.0012200126090349164]
	TIME [epoch: 8.27 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006502414274516147		[learning rate: 0.00011383]
	Learning Rate: 0.00011383
	LOSS [training: 0.0006502414274516147 | validation: 0.002007426732741115]
	TIME [epoch: 8.3 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007206185748828824		[learning rate: 0.00011147]
	Learning Rate: 0.000111468
	LOSS [training: 0.0007206185748828824 | validation: 0.0015494028958815838]
	TIME [epoch: 8.27 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006170805677507054		[learning rate: 0.00010913]
	Learning Rate: 0.000109132
	LOSS [training: 0.0006170805677507054 | validation: 0.0016750224150163797]
	TIME [epoch: 8.26 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000771079316875234		[learning rate: 0.00010682]
	Learning Rate: 0.000106824
	LOSS [training: 0.000771079316875234 | validation: 0.001568278749340667]
	TIME [epoch: 8.27 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007603486133127673		[learning rate: 0.00010454]
	Learning Rate: 0.000104543
	LOSS [training: 0.0007603486133127673 | validation: 0.001551343918101753]
	TIME [epoch: 8.26 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007276253195966293		[learning rate: 0.00010229]
	Learning Rate: 0.000102289
	LOSS [training: 0.0007276253195966293 | validation: 0.0016526618262615732]
	TIME [epoch: 8.3 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007337522099467137		[learning rate: 0.00010006]
	Learning Rate: 0.000100061
	LOSS [training: 0.0007337522099467137 | validation: 0.0012970052621224843]
	TIME [epoch: 8.27 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008945142018433976		[learning rate: 9.7861e-05]
	Learning Rate: 9.78614e-05
	LOSS [training: 0.0008945142018433976 | validation: 0.001398513768890644]
	TIME [epoch: 8.26 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007920199216292888		[learning rate: 9.5688e-05]
	Learning Rate: 9.56885e-05
	LOSS [training: 0.0007920199216292888 | validation: 0.0018659512362773968]
	TIME [epoch: 8.26 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008630315743802998		[learning rate: 9.3543e-05]
	Learning Rate: 9.35426e-05
	LOSS [training: 0.0008630315743802998 | validation: 0.0015421608455595958]
	TIME [epoch: 8.26 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008206410966482298		[learning rate: 9.1424e-05]
	Learning Rate: 9.14239e-05
	LOSS [training: 0.0008206410966482298 | validation: 0.0012654857663682798]
	TIME [epoch: 8.27 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005656573458416359		[learning rate: 8.9332e-05]
	Learning Rate: 8.93322e-05
	LOSS [training: 0.0005656573458416359 | validation: 0.0014574411626184444]
	TIME [epoch: 8.31 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008516859013797908		[learning rate: 8.7268e-05]
	Learning Rate: 8.72677e-05
	LOSS [training: 0.0008516859013797908 | validation: 0.0013270647511711582]
	TIME [epoch: 8.26 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009815992831291248		[learning rate: 8.523e-05]
	Learning Rate: 8.52303e-05
	LOSS [training: 0.0009815992831291248 | validation: 0.0012863402063081413]
	TIME [epoch: 8.27 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000807592227777719		[learning rate: 8.322e-05]
	Learning Rate: 8.322e-05
	LOSS [training: 0.000807592227777719 | validation: 0.0014860572042391072]
	TIME [epoch: 8.26 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007315937640602416		[learning rate: 8.1237e-05]
	Learning Rate: 8.12368e-05
	LOSS [training: 0.0007315937640602416 | validation: 0.0011085333434650826]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_1878.pth
	Model improved!!!
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000859161635518649		[learning rate: 7.9281e-05]
	Learning Rate: 7.92808e-05
	LOSS [training: 0.000859161635518649 | validation: 0.001694196869373278]
	TIME [epoch: 8.3 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000710857380172415		[learning rate: 7.7352e-05]
	Learning Rate: 7.73519e-05
	LOSS [training: 0.000710857380172415 | validation: 0.001715815620760056]
	TIME [epoch: 8.27 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006974123272213432		[learning rate: 7.545e-05]
	Learning Rate: 7.54501e-05
	LOSS [training: 0.0006974123272213432 | validation: 0.0011066170146930246]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_1881.pth
	Model improved!!!
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008617452687418465		[learning rate: 7.3575e-05]
	Learning Rate: 7.35755e-05
	LOSS [training: 0.0008617452687418465 | validation: 0.001775560396859902]
	TIME [epoch: 8.26 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008827423347692579		[learning rate: 7.1728e-05]
	Learning Rate: 7.1728e-05
	LOSS [training: 0.0008827423347692579 | validation: 0.0020323832602993806]
	TIME [epoch: 8.25 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000631563278588757		[learning rate: 6.9908e-05]
	Learning Rate: 6.99077e-05
	LOSS [training: 0.000631563278588757 | validation: 0.0015958605384335796]
	TIME [epoch: 8.26 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006905528905312684		[learning rate: 6.8115e-05]
	Learning Rate: 6.81146e-05
	LOSS [training: 0.0006905528905312684 | validation: 0.0015061821028553146]
	TIME [epoch: 8.29 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007839294324664068		[learning rate: 6.6349e-05]
	Learning Rate: 6.63486e-05
	LOSS [training: 0.0007839294324664068 | validation: 0.0009370302351366649]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_mmd3_20240701_180837/states/model_phi1_1a_v_mmd3_1886.pth
	Model improved!!!
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006675837044269828		[learning rate: 6.461e-05]
	Learning Rate: 6.46098e-05
	LOSS [training: 0.0006675837044269828 | validation: 0.0017744993190034562]
	TIME [epoch: 8.26 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007963791688614376		[learning rate: 6.2898e-05]
	Learning Rate: 6.28982e-05
	LOSS [training: 0.0007963791688614376 | validation: 0.0014760946599108528]
	TIME [epoch: 8.25 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008821671931517243		[learning rate: 6.1214e-05]
	Learning Rate: 6.12137e-05
	LOSS [training: 0.0008821671931517243 | validation: 0.0013417649076735946]
	TIME [epoch: 8.26 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007551626866159288		[learning rate: 5.9556e-05]
	Learning Rate: 5.95565e-05
	LOSS [training: 0.0007551626866159288 | validation: 0.0015206673067268113]
	TIME [epoch: 8.29 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007641195764918124		[learning rate: 5.7926e-05]
	Learning Rate: 5.79264e-05
	LOSS [training: 0.0007641195764918124 | validation: 0.001621672189263478]
	TIME [epoch: 8.26 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000596716684987788		[learning rate: 5.6324e-05]
	Learning Rate: 5.63235e-05
	LOSS [training: 0.000596716684987788 | validation: 0.0014628563461267995]
	TIME [epoch: 8.25 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007275286699971379		[learning rate: 5.4748e-05]
	Learning Rate: 5.47478e-05
	LOSS [training: 0.0007275286699971379 | validation: 0.0015487067156213091]
	TIME [epoch: 8.26 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006007520654929652		[learning rate: 5.3199e-05]
	Learning Rate: 5.31994e-05
	LOSS [training: 0.0006007520654929652 | validation: 0.0015181920647937366]
	TIME [epoch: 8.26 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008540236963415317		[learning rate: 5.1678e-05]
	Learning Rate: 5.16781e-05
	LOSS [training: 0.0008540236963415317 | validation: 0.0014070584870760454]
	TIME [epoch: 8.26 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007570994120075969		[learning rate: 5.0184e-05]
	Learning Rate: 5.0184e-05
	LOSS [training: 0.0007570994120075969 | validation: 0.001400283813906027]
	TIME [epoch: 8.29 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008245010783970464		[learning rate: 4.8717e-05]
	Learning Rate: 4.87172e-05
	LOSS [training: 0.0008245010783970464 | validation: 0.0015695141656135699]
	TIME [epoch: 8.26 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007409185598996183		[learning rate: 4.7278e-05]
	Learning Rate: 4.72776e-05
	LOSS [training: 0.0007409185598996183 | validation: 0.0017297603020339399]
	TIME [epoch: 8.25 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008172529058750807		[learning rate: 4.5865e-05]
	Learning Rate: 4.58652e-05
	LOSS [training: 0.0008172529058750807 | validation: 0.0013442264845028246]
	TIME [epoch: 8.26 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008894869330241155		[learning rate: 4.448e-05]
	Learning Rate: 4.448e-05
	LOSS [training: 0.0008894869330241155 | validation: 0.0017527570410131653]
	TIME [epoch: 8.25 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007998765820195857		[learning rate: 4.3122e-05]
	Learning Rate: 4.31221e-05
	LOSS [training: 0.0007998765820195857 | validation: 0.0015229024396684306]
	TIME [epoch: 8.29 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006561941371224019		[learning rate: 4.1791e-05]
	Learning Rate: 4.17914e-05
	LOSS [training: 0.0006561941371224019 | validation: 0.0013106690799759351]
	TIME [epoch: 8.26 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007756894803511759		[learning rate: 4.0488e-05]
	Learning Rate: 4.04879e-05
	LOSS [training: 0.0007756894803511759 | validation: 0.002372097550591299]
	TIME [epoch: 8.26 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007968150827529469		[learning rate: 3.9212e-05]
	Learning Rate: 3.92117e-05
	LOSS [training: 0.0007968150827529469 | validation: 0.0014524949142694465]
	TIME [epoch: 8.26 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007929726211645285		[learning rate: 3.7963e-05]
	Learning Rate: 3.79628e-05
	LOSS [training: 0.0007929726211645285 | validation: 0.0014999044409115]
	TIME [epoch: 8.26 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005675819541778677		[learning rate: 3.6741e-05]
	Learning Rate: 3.6741e-05
	LOSS [training: 0.0005675819541778677 | validation: 0.0013535180965612188]
	TIME [epoch: 8.26 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007125733678989608		[learning rate: 3.5547e-05]
	Learning Rate: 3.55466e-05
	LOSS [training: 0.0007125733678989608 | validation: 0.001671386455276104]
	TIME [epoch: 8.29 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006287312975204011		[learning rate: 3.4379e-05]
	Learning Rate: 3.43794e-05
	LOSS [training: 0.0006287312975204011 | validation: 0.0013846920600430268]
	TIME [epoch: 8.26 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010195150794674052		[learning rate: 3.3239e-05]
	Learning Rate: 3.32394e-05
	LOSS [training: 0.0010195150794674052 | validation: 0.0014660076208072807]
	TIME [epoch: 8.26 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008445448615014758		[learning rate: 3.2127e-05]
	Learning Rate: 3.21267e-05
	LOSS [training: 0.0008445448615014758 | validation: 0.001493731611416103]
	TIME [epoch: 8.26 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007096805345670762		[learning rate: 3.1041e-05]
	Learning Rate: 3.10413e-05
	LOSS [training: 0.0007096805345670762 | validation: 0.0012298629395853765]
	TIME [epoch: 8.26 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007483352818208752		[learning rate: 2.9983e-05]
	Learning Rate: 2.99831e-05
	LOSS [training: 0.0007483352818208752 | validation: 0.0015109532512223227]
	TIME [epoch: 8.28 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007119139987262402		[learning rate: 2.8952e-05]
	Learning Rate: 2.89522e-05
	LOSS [training: 0.0007119139987262402 | validation: 0.0010485525310524758]
	TIME [epoch: 8.28 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008912255702777054		[learning rate: 2.7949e-05]
	Learning Rate: 2.79486e-05
	LOSS [training: 0.0008912255702777054 | validation: 0.0011964885288793523]
	TIME [epoch: 8.25 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008840129132773908		[learning rate: 2.6972e-05]
	Learning Rate: 2.69723e-05
	LOSS [training: 0.0008840129132773908 | validation: 0.0012304524916831045]
	TIME [epoch: 8.25 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007212118158804728		[learning rate: 2.6023e-05]
	Learning Rate: 2.60232e-05
	LOSS [training: 0.0007212118158804728 | validation: 0.001828367499967979]
	TIME [epoch: 8.26 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000726248621533642		[learning rate: 2.5101e-05]
	Learning Rate: 2.51015e-05
	LOSS [training: 0.000726248621533642 | validation: 0.0015119255427015021]
	TIME [epoch: 8.26 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007343966776133364		[learning rate: 2.4207e-05]
	Learning Rate: 2.4207e-05
	LOSS [training: 0.0007343966776133364 | validation: 0.002021440168698389]
	TIME [epoch: 8.3 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00082358292017837		[learning rate: 2.334e-05]
	Learning Rate: 2.33398e-05
	LOSS [training: 0.00082358292017837 | validation: 0.0013939771881007602]
	TIME [epoch: 8.26 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008607805118870679		[learning rate: 2.25e-05]
	Learning Rate: 2.24999e-05
	LOSS [training: 0.0008607805118870679 | validation: 0.0010458738829810246]
	TIME [epoch: 8.26 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007922856120157498		[learning rate: 2.1687e-05]
	Learning Rate: 2.16873e-05
	LOSS [training: 0.0007922856120157498 | validation: 0.0015768768731000452]
	TIME [epoch: 8.26 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008706748432663461		[learning rate: 2.0902e-05]
	Learning Rate: 2.09019e-05
	LOSS [training: 0.0008706748432663461 | validation: 0.001517470570345023]
	TIME [epoch: 8.26 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005746915416205674		[learning rate: 2.0144e-05]
	Learning Rate: 2.01439e-05
	LOSS [training: 0.0005746915416205674 | validation: 0.0015388790890717807]
	TIME [epoch: 8.28 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000785162967910113		[learning rate: 1.9413e-05]
	Learning Rate: 1.94132e-05
	LOSS [training: 0.000785162967910113 | validation: 0.0014466062023532657]
	TIME [epoch: 8.29 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007632595156349862		[learning rate: 1.871e-05]
	Learning Rate: 1.87097e-05
	LOSS [training: 0.0007632595156349862 | validation: 0.0016220100359537531]
	TIME [epoch: 8.26 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007815436856311105		[learning rate: 1.8034e-05]
	Learning Rate: 1.80336e-05
	LOSS [training: 0.0007815436856311105 | validation: 0.0013455149034638128]
	TIME [epoch: 8.26 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00084807110398112		[learning rate: 1.7385e-05]
	Learning Rate: 1.73848e-05
	LOSS [training: 0.00084807110398112 | validation: 0.0013101413466094333]
	TIME [epoch: 8.26 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007482538730315888		[learning rate: 1.6763e-05]
	Learning Rate: 1.67633e-05
	LOSS [training: 0.0007482538730315888 | validation: 0.001845657595909505]
	TIME [epoch: 8.26 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006546338927640468		[learning rate: 1.6169e-05]
	Learning Rate: 1.61691e-05
	LOSS [training: 0.0006546338927640468 | validation: 0.0012113048328095193]
	TIME [epoch: 8.3 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007091932342692476		[learning rate: 1.5602e-05]
	Learning Rate: 1.56022e-05
	LOSS [training: 0.0007091932342692476 | validation: 0.0020593142696308203]
	TIME [epoch: 8.26 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007803468080139878		[learning rate: 1.5063e-05]
	Learning Rate: 1.50626e-05
	LOSS [training: 0.0007803468080139878 | validation: 0.0012529256292462155]
	TIME [epoch: 8.26 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006708660716262984		[learning rate: 1.455e-05]
	Learning Rate: 1.45503e-05
	LOSS [training: 0.0006708660716262984 | validation: 0.001500755223628076]
	TIME [epoch: 8.25 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006183250110794239		[learning rate: 1.4065e-05]
	Learning Rate: 1.40653e-05
	LOSS [training: 0.0006183250110794239 | validation: 0.0012610351681197791]
	TIME [epoch: 8.26 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007278152514643171		[learning rate: 1.3608e-05]
	Learning Rate: 1.36077e-05
	LOSS [training: 0.0007278152514643171 | validation: 0.0015515709460429212]
	TIME [epoch: 8.26 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007466726123193457		[learning rate: 1.3177e-05]
	Learning Rate: 1.31773e-05
	LOSS [training: 0.0007466726123193457 | validation: 0.0015182527924942574]
	TIME [epoch: 8.3 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008546185127347753		[learning rate: 1.2774e-05]
	Learning Rate: 1.27743e-05
	LOSS [training: 0.0008546185127347753 | validation: 0.001153616821267252]
	TIME [epoch: 8.26 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006551904117078564		[learning rate: 1.2399e-05]
	Learning Rate: 1.23986e-05
	LOSS [training: 0.0006551904117078564 | validation: 0.0017004204601554348]
	TIME [epoch: 8.26 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007070798984870228		[learning rate: 1.205e-05]
	Learning Rate: 1.20502e-05
	LOSS [training: 0.0007070798984870228 | validation: 0.001478843638707728]
	TIME [epoch: 8.26 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007961655444764178		[learning rate: 1.1729e-05]
	Learning Rate: 1.17292e-05
	LOSS [training: 0.0007961655444764178 | validation: 0.001786273988015961]
	TIME [epoch: 8.26 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006462291738504251		[learning rate: 1.1435e-05]
	Learning Rate: 1.14354e-05
	LOSS [training: 0.0006462291738504251 | validation: 0.0014356556995381428]
	TIME [epoch: 8.29 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008219889845785717		[learning rate: 1.1169e-05]
	Learning Rate: 1.1169e-05
	LOSS [training: 0.0008219889845785717 | validation: 0.001459593517554132]
	TIME [epoch: 8.27 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007271953405692617		[learning rate: 1.093e-05]
	Learning Rate: 1.09299e-05
	LOSS [training: 0.0007271953405692617 | validation: 0.0016050364001297189]
	TIME [epoch: 8.26 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009484479140255027		[learning rate: 1.0718e-05]
	Learning Rate: 1.07182e-05
	LOSS [training: 0.0009484479140255027 | validation: 0.0017675181932959607]
	TIME [epoch: 8.26 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006684464854818527		[learning rate: 1.0534e-05]
	Learning Rate: 1.05337e-05
	LOSS [training: 0.0006684464854818527 | validation: 0.0017004269511912708]
	TIME [epoch: 8.26 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000842188382117034		[learning rate: 1.0377e-05]
	Learning Rate: 1.03766e-05
	LOSS [training: 0.000842188382117034 | validation: 0.0013000349512694296]
	TIME [epoch: 8.27 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007705423524838294		[learning rate: 1.0247e-05]
	Learning Rate: 1.02468e-05
	LOSS [training: 0.0007705423524838294 | validation: 0.001964027049150567]
	TIME [epoch: 8.31 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006828753012323876		[learning rate: 1.0144e-05]
	Learning Rate: 1.01443e-05
	LOSS [training: 0.0006828753012323876 | validation: 0.0014800960649480528]
	TIME [epoch: 8.27 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006141484862264426		[learning rate: 1.0069e-05]
	Learning Rate: 1.00692e-05
	LOSS [training: 0.0006141484862264426 | validation: 0.0014317268965795904]
	TIME [epoch: 8.27 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006980190555820067		[learning rate: 1.0021e-05]
	Learning Rate: 1.00213e-05
	LOSS [training: 0.0006980190555820067 | validation: 0.0014794445374061473]
	TIME [epoch: 8.27 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007759053988813302		[learning rate: 1.0001e-05]
	Learning Rate: 1.00009e-05
	LOSS [training: 0.0007759053988813302 | validation: 0.001398041439160317]
	TIME [epoch: 8.27 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007219562287726136		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0007219562287726136 | validation: 0.001841865516455413]
	TIME [epoch: 8.3 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006398021772086188		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0006398021772086188 | validation: 0.001372605357779695]
	TIME [epoch: 8.27 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008920955486088056		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0008920955486088056 | validation: 0.0012137018002406066]
	TIME [epoch: 8.27 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007903810846800856		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0007903810846800856 | validation: 0.0015636012411483018]
	TIME [epoch: 8.26 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007749670374916022		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0007749670374916022 | validation: 0.0014334888572221677]
	TIME [epoch: 8.26 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00072893487837152		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.00072893487837152 | validation: 0.0015392072801539208]
	TIME [epoch: 8.27 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000842483669472281		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.000842483669472281 | validation: 0.0015849326152471343]
	TIME [epoch: 8.3 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007979142297429848		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0007979142297429848 | validation: 0.001344661158706799]
	TIME [epoch: 8.26 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007263827147384541		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0007263827147384541 | validation: 0.0012979889866674352]
	TIME [epoch: 8.26 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008465503248028317		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0008465503248028317 | validation: 0.0013088012784677591]
	TIME [epoch: 8.26 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007704778955383259		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0007704778955383259 | validation: 0.0009973144040842357]
	TIME [epoch: 8.26 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007814165966371989		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0007814165966371989 | validation: 0.0011275628324142611]
	TIME [epoch: 8.28 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007247843203422512		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0007247843203422512 | validation: 0.001327052510811347]
	TIME [epoch: 8.28 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008383737190397447		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0008383737190397447 | validation: 0.001531433723374441]
	TIME [epoch: 8.26 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006659921229874522		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0006659921229874522 | validation: 0.001457295126186601]
	TIME [epoch: 8.26 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007223074128045345		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0007223074128045345 | validation: 0.0015530067718838884]
	TIME [epoch: 8.26 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007550225368987007		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0007550225368987007 | validation: 0.0017481954741305394]
	TIME [epoch: 8.26 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007656009627271278		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0007656009627271278 | validation: 0.0012611782046093314]
	TIME [epoch: 8.3 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008320293004284612		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0008320293004284612 | validation: 0.0013817057353839612]
	TIME [epoch: 8.26 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006533457379398356		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0006533457379398356 | validation: 0.0016868149075307164]
	TIME [epoch: 8.26 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000844921364003133		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.000844921364003133 | validation: 0.0013735213199607514]
	TIME [epoch: 8.26 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006412020536554468		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0006412020536554468 | validation: 0.001225586752762646]
	TIME [epoch: 8.27 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008626728587889603		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0008626728587889603 | validation: 0.001338415274165943]
	TIME [epoch: 8.28 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008513174213978003		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0008513174213978003 | validation: 0.0017922037366325779]
	TIME [epoch: 8.29 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000678277723721487		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.000678277723721487 | validation: 0.0014110080330014137]
	TIME [epoch: 8.26 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008648834150427238		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0008648834150427238 | validation: 0.0015714219976712272]
	TIME [epoch: 8.27 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006651379961730744		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0006651379961730744 | validation: 0.0015097283078504527]
	TIME [epoch: 8.27 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008224448962986113		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0008224448962986113 | validation: 0.001622127394473619]
	TIME [epoch: 8.27 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00079896042084712		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.00079896042084712 | validation: 0.0015149788482383198]
	TIME [epoch: 8.3 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007174418759145378		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0007174418759145378 | validation: 0.0013681640425298198]
	TIME [epoch: 8.27 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000732884133013708		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.000732884133013708 | validation: 0.0015111656482424164]
	TIME [epoch: 8.26 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000794089464920267		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.000794089464920267 | validation: 0.0015564210832172956]
	TIME [epoch: 8.26 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007850111064076711		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0007850111064076711 | validation: 0.001665280270329867]
	TIME [epoch: 8.26 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007598769680955466		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0007598769680955466 | validation: 0.001434634750238051]
	TIME [epoch: 8.27 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008612044142440725		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0008612044142440725 | validation: 0.0015288542640968636]
	TIME [epoch: 8.3 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008036753612628664		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0008036753612628664 | validation: 0.0013967141090666874]
	TIME [epoch: 8.26 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00060452142102797		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.00060452142102797 | validation: 0.0015412093925406803]
	TIME [epoch: 8.26 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008186215037094733		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0008186215037094733 | validation: 0.0020769890160937197]
	TIME [epoch: 8.27 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000743928155374785		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.000743928155374785 | validation: 0.0013487631617646505]
	TIME [epoch: 8.26 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006744061761284981		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0006744061761284981 | validation: 0.001178896210506232]
	TIME [epoch: 8.3 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005857608059317099		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0005857608059317099 | validation: 0.0014017440376720184]
	TIME [epoch: 8.27 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006863507026093565		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0006863507026093565 | validation: 0.0014729774214925352]
	TIME [epoch: 8.26 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006996448482982715		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0006996448482982715 | validation: 0.0013133561500306454]
	TIME [epoch: 8.26 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008410004257490884		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0008410004257490884 | validation: 0.001642403221643022]
	TIME [epoch: 8.26 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007590884008296744		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0007590884008296744 | validation: 0.0016414051226013875]
	TIME [epoch: 8.27 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008069948558969314		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0008069948558969314 | validation: 0.0013217054679052422]
	TIME [epoch: 8.3 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007729759854921642		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0007729759854921642 | validation: 0.0018277828913652262]
	TIME [epoch: 8.26 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007479335642300312		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0007479335642300312 | validation: 0.0013738958495420287]
	TIME [epoch: 8.27 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008817036830694428		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0008817036830694428 | validation: 0.0010999035526932605]
	TIME [epoch: 8.27 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005779303315964342		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0005779303315964342 | validation: 0.0018546677950802585]
	TIME [epoch: 8.26 sec]
Finished training in 16860.945 seconds.
