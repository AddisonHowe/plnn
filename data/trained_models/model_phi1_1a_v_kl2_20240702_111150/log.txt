Args:
Namespace(name='model_phi1_1a_v_kl2', outdir='out/model_training/model_phi1_1a_v_kl2', training_data='data/training_data/data_phi1_1a/training', validation_data='data/training_data/data_phi1_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=10.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1338771418

Training model...

Saving initial model state to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.2962284383631		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.2962284383631 | validation: 12.21132449588692]
	TIME [epoch: 116 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.82710166921433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.82710166921433 | validation: 10.13211586030083]
	TIME [epoch: 7.81 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.121487253484567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.121487253484567 | validation: 9.900731793938121]
	TIME [epoch: 7.72 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.553119762191205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.553119762191205 | validation: 9.213190310430226]
	TIME [epoch: 7.73 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.258882136207257		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.258882136207257 | validation: 9.603501505712881]
	TIME [epoch: 7.68 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.157234713903316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.157234713903316 | validation: 9.080075434519273]
	TIME [epoch: 7.76 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.01949799374273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.01949799374273 | validation: 8.866801169974472]
	TIME [epoch: 7.76 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.191704893988847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.191704893988847 | validation: 9.360802616830089]
	TIME [epoch: 7.68 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.700213952893509		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.700213952893509 | validation: 8.630456727591266]
	TIME [epoch: 7.66 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.453852887059824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.453852887059824 | validation: 9.696868261461814]
	TIME [epoch: 7.71 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.711357122360679		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.711357122360679 | validation: 8.613436036775244]
	TIME [epoch: 7.77 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.316606731185222		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.316606731185222 | validation: 8.79144342357745]
	TIME [epoch: 7.7 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.263724172558036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.263724172558036 | validation: 8.31937687506424]
	TIME [epoch: 7.74 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.005764913762336		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.005764913762336 | validation: 8.634723401209264]
	TIME [epoch: 7.7 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.393685687326215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.393685687326215 | validation: 8.359110560115617]
	TIME [epoch: 7.76 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.929626079385603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.929626079385603 | validation: 8.077151324938365]
	TIME [epoch: 7.78 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.80856822861001		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.80856822861001 | validation: 7.9637050445809265]
	TIME [epoch: 7.73 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.618673828459887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.618673828459887 | validation: 7.5909609501871085]
	TIME [epoch: 7.74 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.50382199559006		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.50382199559006 | validation: 7.499331890209951]
	TIME [epoch: 7.79 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.319543901928374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.319543901928374 | validation: 7.56586177500098]
	TIME [epoch: 7.85 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.393325333304003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.393325333304003 | validation: 7.397385956996708]
	TIME [epoch: 7.82 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.28277738818219		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.28277738818219 | validation: 7.305737633143606]
	TIME [epoch: 7.82 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.237571426092596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.237571426092596 | validation: 7.162217480290067]
	TIME [epoch: 7.81 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.148564710821077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.148564710821077 | validation: 7.118076666067809]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.2099492034170165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.2099492034170165 | validation: 7.161147539388098]
	TIME [epoch: 7.83 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.364942791579321		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.364942791579321 | validation: 6.931941104836456]
	TIME [epoch: 7.81 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.034990757001459		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.034990757001459 | validation: 6.959677688427658]
	TIME [epoch: 7.79 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.113769106659661		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.113769106659661 | validation: 6.976816553708829]
	TIME [epoch: 7.79 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0868360016528555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.0868360016528555 | validation: 6.681347414738305]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.034984242114949		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.034984242114949 | validation: 6.686578427292712]
	TIME [epoch: 7.81 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.927914909613005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.927914909613005 | validation: 6.2745436686222185]
	TIME [epoch: 7.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.722057725629366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.722057725629366 | validation: 5.94814884274982]
	TIME [epoch: 7.82 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.818874208189195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.818874208189195 | validation: 5.724373317531757]
	TIME [epoch: 7.81 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.523174355903404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.523174355903404 | validation: 5.321429272129269]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.829170781991139		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.829170781991139 | validation: 5.540374405058519]
	TIME [epoch: 7.81 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.285610906830046		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.285610906830046 | validation: 7.307538762149686]
	TIME [epoch: 7.81 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.684572504323399		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.684572504323399 | validation: 5.21981886360291]
	TIME [epoch: 7.81 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.106608753419432		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.106608753419432 | validation: 5.01255968975083]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.5656537124586425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.5656537124586425 | validation: 5.040240519363504]
	TIME [epoch: 7.71 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.115530493888378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.115530493888378 | validation: 5.129162458261292]
	TIME [epoch: 7.7 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.038535175919145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.038535175919145 | validation: 5.264914964142959]
	TIME [epoch: 7.77 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.003979001211162		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.003979001211162 | validation: 4.958525476476]
	TIME [epoch: 7.79 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.187584245219845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.187584245219845 | validation: 5.684774034445512]
	TIME [epoch: 7.85 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.088837164763657		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.088837164763657 | validation: 4.929923662651657]
	TIME [epoch: 7.81 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.940450798626944		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.940450798626944 | validation: 4.940860950237868]
	TIME [epoch: 7.82 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.247270320365367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.247270320365367 | validation: 6.545315637721219]
	TIME [epoch: 7.73 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.596948123143409		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.596948123143409 | validation: 5.759658260108024]
	TIME [epoch: 7.8 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.926887873876888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.926887873876888 | validation: 5.124250965527901]
	TIME [epoch: 7.78 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.657879084174392		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.657879084174392 | validation: 5.351792518150884]
	TIME [epoch: 7.72 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.908356928760172		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.908356928760172 | validation: 5.098174902904844]
	TIME [epoch: 7.78 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.804309086421873		[learning rate: 0.0099823]
	Learning Rate: 0.0099823
	LOSS [training: 4.804309086421873 | validation: 4.778542045388072]
	TIME [epoch: 7.79 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.801011452666545		[learning rate: 0.0099588]
	Learning Rate: 0.00995876
	LOSS [training: 4.801011452666545 | validation: 4.566662738516889]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.541623638568124		[learning rate: 0.0099353]
	Learning Rate: 0.00993527
	LOSS [training: 4.541623638568124 | validation: 4.537149529474034]
	TIME [epoch: 7.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4745956493784185		[learning rate: 0.0099118]
	Learning Rate: 0.00991183
	LOSS [training: 4.4745956493784185 | validation: 4.663122101800131]
	TIME [epoch: 7.8 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.686786856505008		[learning rate: 0.0098884]
	Learning Rate: 0.00988845
	LOSS [training: 4.686786856505008 | validation: 4.603543055924948]
	TIME [epoch: 7.79 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.437865938022146		[learning rate: 0.0098651]
	Learning Rate: 0.00986512
	LOSS [training: 4.437865938022146 | validation: 5.279399549155667]
	TIME [epoch: 7.79 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.786156138442562		[learning rate: 0.0098419]
	Learning Rate: 0.00984185
	LOSS [training: 4.786156138442562 | validation: 4.777098103805596]
	TIME [epoch: 7.75 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.008849129959633		[learning rate: 0.0098186]
	Learning Rate: 0.00981864
	LOSS [training: 5.008849129959633 | validation: 4.828765858144287]
	TIME [epoch: 7.74 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.491761010791594		[learning rate: 0.0097955]
	Learning Rate: 0.00979548
	LOSS [training: 4.491761010791594 | validation: 6.6466110282907955]
	TIME [epoch: 7.72 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.782875497208447		[learning rate: 0.0097724]
	Learning Rate: 0.00977237
	LOSS [training: 5.782875497208447 | validation: 4.656750808234298]
	TIME [epoch: 7.69 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.373161031210056		[learning rate: 0.0097493]
	Learning Rate: 0.00974932
	LOSS [training: 4.373161031210056 | validation: 4.453581940115404]
	TIME [epoch: 7.75 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.173438498401213		[learning rate: 0.0097263]
	Learning Rate: 0.00972632
	LOSS [training: 4.173438498401213 | validation: 4.067471296057891]
	TIME [epoch: 7.72 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9457881665831787		[learning rate: 0.0097034]
	Learning Rate: 0.00970338
	LOSS [training: 3.9457881665831787 | validation: 3.972325264826577]
	TIME [epoch: 7.68 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.981692072333982		[learning rate: 0.0096805]
	Learning Rate: 0.00968049
	LOSS [training: 3.981692072333982 | validation: 3.881867329200432]
	TIME [epoch: 7.65 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.881550580681478		[learning rate: 0.0096577]
	Learning Rate: 0.00965766
	LOSS [training: 3.881550580681478 | validation: 4.000715947773241]
	TIME [epoch: 7.67 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.726626186202043		[learning rate: 0.0096349]
	Learning Rate: 0.00963488
	LOSS [training: 3.726626186202043 | validation: 3.376380254980192]
	TIME [epoch: 7.73 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7211456052929477		[learning rate: 0.0096121]
	Learning Rate: 0.00961215
	LOSS [training: 3.7211456052929477 | validation: 3.3155366740814607]
	TIME [epoch: 7.68 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4956996428733556		[learning rate: 0.0095895]
	Learning Rate: 0.00958948
	LOSS [training: 3.4956996428733556 | validation: 3.1936345195855447]
	TIME [epoch: 7.69 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.037823883378836		[learning rate: 0.0095669]
	Learning Rate: 0.00956686
	LOSS [training: 3.037823883378836 | validation: 3.584128688236553]
	TIME [epoch: 7.7 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5289988849016756		[learning rate: 0.0095443]
	Learning Rate: 0.00954429
	LOSS [training: 3.5289988849016756 | validation: 3.2218506438616012]
	TIME [epoch: 7.7 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8256053532576804		[learning rate: 0.0095218]
	Learning Rate: 0.00952177
	LOSS [training: 2.8256053532576804 | validation: 2.8520212846229103]
	TIME [epoch: 7.74 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8555922163068344		[learning rate: 0.0094993]
	Learning Rate: 0.00949931
	LOSS [training: 2.8555922163068344 | validation: 2.754521383731589]
	TIME [epoch: 7.67 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.560466136372501		[learning rate: 0.0094769]
	Learning Rate: 0.00947691
	LOSS [training: 2.560466136372501 | validation: 2.4906790295827426]
	TIME [epoch: 7.69 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.095590241549992		[learning rate: 0.0094546]
	Learning Rate: 0.00945455
	LOSS [training: 3.095590241549992 | validation: 3.5186606152710214]
	TIME [epoch: 7.67 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8929826612432303		[learning rate: 0.0094323]
	Learning Rate: 0.00943225
	LOSS [training: 2.8929826612432303 | validation: 3.048837357870802]
	TIME [epoch: 7.73 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4451664462757723		[learning rate: 0.00941]
	Learning Rate: 0.00941
	LOSS [training: 2.4451664462757723 | validation: 2.260454094129245]
	TIME [epoch: 7.74 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.329775161048076		[learning rate: 0.0093878]
	Learning Rate: 0.00938781
	LOSS [training: 2.329775161048076 | validation: 2.29566143872119]
	TIME [epoch: 7.69 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0600325957233268		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 2.0600325957233268 | validation: 2.213938833581606]
	TIME [epoch: 7.75 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.138221922410558		[learning rate: 0.0093436]
	Learning Rate: 0.00934357
	LOSS [training: 3.138221922410558 | validation: 2.1741360540386645]
	TIME [epoch: 8.01 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2296580150997065		[learning rate: 0.0093215]
	Learning Rate: 0.00932153
	LOSS [training: 2.2296580150997065 | validation: 2.1871287428923454]
	TIME [epoch: 7.74 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.205384549058536		[learning rate: 0.0092995]
	Learning Rate: 0.00929954
	LOSS [training: 2.205384549058536 | validation: 2.4048577343730395]
	TIME [epoch: 7.69 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.567477181587332		[learning rate: 0.0092776]
	Learning Rate: 0.00927761
	LOSS [training: 2.567477181587332 | validation: 2.2054589309142276]
	TIME [epoch: 7.72 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.058600593734179		[learning rate: 0.0092557]
	Learning Rate: 0.00925572
	LOSS [training: 2.058600593734179 | validation: 1.9781239239345352]
	TIME [epoch: 7.68 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9178401306610442		[learning rate: 0.0092339]
	Learning Rate: 0.00923389
	LOSS [training: 1.9178401306610442 | validation: 2.794118437157956]
	TIME [epoch: 7.68 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.48562087836442		[learning rate: 0.0092121]
	Learning Rate: 0.00921211
	LOSS [training: 2.48562087836442 | validation: 2.0447120119359976]
	TIME [epoch: 7.68 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7757572260308625		[learning rate: 0.0091904]
	Learning Rate: 0.00919038
	LOSS [training: 1.7757572260308625 | validation: 2.147123555438687]
	TIME [epoch: 7.67 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.109963123028776		[learning rate: 0.0091687]
	Learning Rate: 0.0091687
	LOSS [training: 2.109963123028776 | validation: 2.895299780768555]
	TIME [epoch: 7.63 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.177577932471284		[learning rate: 0.0091471]
	Learning Rate: 0.00914707
	LOSS [training: 2.177577932471284 | validation: 1.9866163629040807]
	TIME [epoch: 7.64 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0103053682287118		[learning rate: 0.0091255]
	Learning Rate: 0.00912549
	LOSS [training: 2.0103053682287118 | validation: 2.397195928911306]
	TIME [epoch: 7.67 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.328814968955839		[learning rate: 0.009104]
	Learning Rate: 0.00910397
	LOSS [training: 2.328814968955839 | validation: 3.02198417553741]
	TIME [epoch: 7.67 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.68560424707601		[learning rate: 0.0090825]
	Learning Rate: 0.00908249
	LOSS [training: 2.68560424707601 | validation: 2.3913728553994265]
	TIME [epoch: 7.69 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2129580047443		[learning rate: 0.0090611]
	Learning Rate: 0.00906107
	LOSS [training: 2.2129580047443 | validation: 2.868300900656025]
	TIME [epoch: 7.78 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3942625225054983		[learning rate: 0.0090397]
	Learning Rate: 0.0090397
	LOSS [training: 2.3942625225054983 | validation: 2.5131669352516024]
	TIME [epoch: 7.79 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2078105946567934		[learning rate: 0.0090184]
	Learning Rate: 0.00901837
	LOSS [training: 2.2078105946567934 | validation: 1.9655145946964159]
	TIME [epoch: 7.82 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.079866579348496		[learning rate: 0.0089971]
	Learning Rate: 0.0089971
	LOSS [training: 2.079866579348496 | validation: 3.1128244477460156]
	TIME [epoch: 7.8 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5178624583507165		[learning rate: 0.0089759]
	Learning Rate: 0.00897588
	LOSS [training: 2.5178624583507165 | validation: 1.939700063685499]
	TIME [epoch: 7.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2228016930727605		[learning rate: 0.0089547]
	Learning Rate: 0.0089547
	LOSS [training: 2.2228016930727605 | validation: 1.9134268076988477]
	TIME [epoch: 7.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0275649156797133		[learning rate: 0.0089336]
	Learning Rate: 0.00893358
	LOSS [training: 2.0275649156797133 | validation: 2.082500515281822]
	TIME [epoch: 7.8 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8853563279837908		[learning rate: 0.0089125]
	Learning Rate: 0.00891251
	LOSS [training: 1.8853563279837908 | validation: 3.026365700531896]
	TIME [epoch: 7.84 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.205826692451108		[learning rate: 0.0088915]
	Learning Rate: 0.00889149
	LOSS [training: 2.205826692451108 | validation: 2.2305970897843572]
	TIME [epoch: 7.79 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8818765391852317		[learning rate: 0.0088705]
	Learning Rate: 0.00887051
	LOSS [training: 1.8818765391852317 | validation: 1.665529960789618]
	TIME [epoch: 7.79 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6783786840949597		[learning rate: 0.0088496]
	Learning Rate: 0.00884959
	LOSS [training: 1.6783786840949597 | validation: 1.9043110145853357]
	TIME [epoch: 7.8 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8140092134946866		[learning rate: 0.0088287]
	Learning Rate: 0.00882871
	LOSS [training: 1.8140092134946866 | validation: 2.9261232246476547]
	TIME [epoch: 7.83 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0302188357250195		[learning rate: 0.0088079]
	Learning Rate: 0.00880789
	LOSS [training: 2.0302188357250195 | validation: 1.6550918674426407]
	TIME [epoch: 7.82 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4827618886282448		[learning rate: 0.0087871]
	Learning Rate: 0.00878711
	LOSS [training: 1.4827618886282448 | validation: 1.5722886858061986]
	TIME [epoch: 7.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_105.pth
	Model improved!!!
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.358861528411742		[learning rate: 0.0087664]
	Learning Rate: 0.00876638
	LOSS [training: 2.358861528411742 | validation: 1.7773893720188436]
	TIME [epoch: 7.79 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0743284996196723		[learning rate: 0.0087457]
	Learning Rate: 0.00874571
	LOSS [training: 2.0743284996196723 | validation: 1.597415407924449]
	TIME [epoch: 7.8 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7387841342601933		[learning rate: 0.0087251]
	Learning Rate: 0.00872508
	LOSS [training: 1.7387841342601933 | validation: 1.7094085442334137]
	TIME [epoch: 7.84 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5874875096165608		[learning rate: 0.0087045]
	Learning Rate: 0.00870449
	LOSS [training: 1.5874875096165608 | validation: 2.4811077258203893]
	TIME [epoch: 7.8 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8292434838784009		[learning rate: 0.008684]
	Learning Rate: 0.00868396
	LOSS [training: 1.8292434838784009 | validation: 1.8282499995753585]
	TIME [epoch: 7.8 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9012774725216857		[learning rate: 0.0086635]
	Learning Rate: 0.00866348
	LOSS [training: 1.9012774725216857 | validation: 2.0175452400283582]
	TIME [epoch: 7.7 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8935777809292316		[learning rate: 0.008643]
	Learning Rate: 0.00864304
	LOSS [training: 1.8935777809292316 | validation: 1.8902084046226797]
	TIME [epoch: 7.69 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9993224118365656		[learning rate: 0.0086227]
	Learning Rate: 0.00862265
	LOSS [training: 1.9993224118365656 | validation: 1.758552874065852]
	TIME [epoch: 7.78 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5714539323284662		[learning rate: 0.0086023]
	Learning Rate: 0.00860232
	LOSS [training: 1.5714539323284662 | validation: 1.6479615516327946]
	TIME [epoch: 7.8 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5945811662941076		[learning rate: 0.008582]
	Learning Rate: 0.00858202
	LOSS [training: 1.5945811662941076 | validation: 2.693703053190201]
	TIME [epoch: 7.8 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.196202753034944		[learning rate: 0.0085618]
	Learning Rate: 0.00856178
	LOSS [training: 2.196202753034944 | validation: 1.971992636727067]
	TIME [epoch: 7.8 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.727700963178439		[learning rate: 0.0085416]
	Learning Rate: 0.00854158
	LOSS [training: 1.727700963178439 | validation: 2.292614479520477]
	TIME [epoch: 7.82 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.771735191446181		[learning rate: 0.0085214]
	Learning Rate: 0.00852144
	LOSS [training: 1.771735191446181 | validation: 1.6886410045549516]
	TIME [epoch: 7.84 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4931283317607484		[learning rate: 0.0085013]
	Learning Rate: 0.00850134
	LOSS [training: 1.4931283317607484 | validation: 1.5701954388693693]
	TIME [epoch: 7.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_119.pth
	Model improved!!!
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.085386768197224		[learning rate: 0.0084813]
	Learning Rate: 0.00848128
	LOSS [training: 2.085386768197224 | validation: 1.7532081259744672]
	TIME [epoch: 7.8 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8089492719401508		[learning rate: 0.0084613]
	Learning Rate: 0.00846128
	LOSS [training: 1.8089492719401508 | validation: 1.7881397588169003]
	TIME [epoch: 7.8 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7949622980574866		[learning rate: 0.0084413]
	Learning Rate: 0.00844132
	LOSS [training: 1.7949622980574866 | validation: 2.2616756848843593]
	TIME [epoch: 7.84 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7782762657546058		[learning rate: 0.0084214]
	Learning Rate: 0.00842141
	LOSS [training: 1.7782762657546058 | validation: 1.6636691000012707]
	TIME [epoch: 7.81 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4492146669132668		[learning rate: 0.0084015]
	Learning Rate: 0.00840154
	LOSS [training: 1.4492146669132668 | validation: 1.5569052737202085]
	TIME [epoch: 7.81 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_124.pth
	Model improved!!!
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.592569072650308		[learning rate: 0.0083817]
	Learning Rate: 0.00838172
	LOSS [training: 1.592569072650308 | validation: 1.7023868669895215]
	TIME [epoch: 7.81 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1359563494228966		[learning rate: 0.008362]
	Learning Rate: 0.00836195
	LOSS [training: 2.1359563494228966 | validation: 2.3054281881322662]
	TIME [epoch: 7.8 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7454003286189996		[learning rate: 0.0083422]
	Learning Rate: 0.00834223
	LOSS [training: 1.7454003286189996 | validation: 1.8371412726846588]
	TIME [epoch: 7.84 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5031162168105605		[learning rate: 0.0083225]
	Learning Rate: 0.00832255
	LOSS [training: 1.5031162168105605 | validation: 2.123046031585973]
	TIME [epoch: 7.8 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7358627482422841		[learning rate: 0.0083029]
	Learning Rate: 0.00830292
	LOSS [training: 1.7358627482422841 | validation: 1.5798398497729407]
	TIME [epoch: 7.8 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.703859812939338		[learning rate: 0.0082833]
	Learning Rate: 0.00828333
	LOSS [training: 1.703859812939338 | validation: 2.1338107976783633]
	TIME [epoch: 7.72 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0164809348439365		[learning rate: 0.0082638]
	Learning Rate: 0.00826379
	LOSS [training: 2.0164809348439365 | validation: 1.67253653155533]
	TIME [epoch: 7.73 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6511272317121897		[learning rate: 0.0082443]
	Learning Rate: 0.0082443
	LOSS [training: 1.6511272317121897 | validation: 1.9316907314685876]
	TIME [epoch: 7.81 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6845768821158305		[learning rate: 0.0082249]
	Learning Rate: 0.00822485
	LOSS [training: 1.6845768821158305 | validation: 1.6386297754934005]
	TIME [epoch: 7.71 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5294769071449976		[learning rate: 0.0082055]
	Learning Rate: 0.00820545
	LOSS [training: 1.5294769071449976 | validation: 1.9555961371969754]
	TIME [epoch: 7.8 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6005695355665983		[learning rate: 0.0081861]
	Learning Rate: 0.0081861
	LOSS [training: 1.6005695355665983 | validation: 1.6852023137498557]
	TIME [epoch: 7.73 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7900350779393046		[learning rate: 0.0081668]
	Learning Rate: 0.00816679
	LOSS [training: 1.7900350779393046 | validation: 1.634970528378391]
	TIME [epoch: 7.72 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.719964706795845		[learning rate: 0.0081475]
	Learning Rate: 0.00814752
	LOSS [training: 1.719964706795845 | validation: 2.232740330749029]
	TIME [epoch: 7.79 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6717516135734374		[learning rate: 0.0081283]
	Learning Rate: 0.0081283
	LOSS [training: 1.6717516135734374 | validation: 1.8940929672531006]
	TIME [epoch: 7.8 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6260975005975926		[learning rate: 0.0081091]
	Learning Rate: 0.00810913
	LOSS [training: 1.6260975005975926 | validation: 2.15647855673363]
	TIME [epoch: 7.78 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5520260635650813		[learning rate: 0.00809]
	Learning Rate: 0.00809
	LOSS [training: 1.5520260635650813 | validation: 1.6792770866551303]
	TIME [epoch: 7.8 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5054013777100324		[learning rate: 0.0080709]
	Learning Rate: 0.00807092
	LOSS [training: 1.5054013777100324 | validation: 1.6823965053344494]
	TIME [epoch: 7.83 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4869385192845637		[learning rate: 0.0080519]
	Learning Rate: 0.00805188
	LOSS [training: 1.4869385192845637 | validation: 1.9666407494748361]
	TIME [epoch: 7.82 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6657149314575515		[learning rate: 0.0080329]
	Learning Rate: 0.00803289
	LOSS [training: 2.6657149314575515 | validation: 1.8922520891025054]
	TIME [epoch: 7.81 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.013421740583934		[learning rate: 0.0080139]
	Learning Rate: 0.00801394
	LOSS [training: 2.013421740583934 | validation: 1.728180961206973]
	TIME [epoch: 7.79 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4210579966454775		[learning rate: 0.007995]
	Learning Rate: 0.00799504
	LOSS [training: 1.4210579966454775 | validation: 1.620007272800231]
	TIME [epoch: 7.71 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5812984010003026		[learning rate: 0.0079762]
	Learning Rate: 0.00797618
	LOSS [training: 1.5812984010003026 | validation: 1.5537359643517226]
	TIME [epoch: 7.75 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_146.pth
	Model improved!!!
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.566051965791943		[learning rate: 0.0079574]
	Learning Rate: 0.00795736
	LOSS [training: 1.566051965791943 | validation: 2.089977454357197]
	TIME [epoch: 7.72 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5648457478758315		[learning rate: 0.0079386]
	Learning Rate: 0.00793859
	LOSS [training: 1.5648457478758315 | validation: 1.7246191884510367]
	TIME [epoch: 7.71 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3981305089073053		[learning rate: 0.0079199]
	Learning Rate: 0.00791987
	LOSS [training: 1.3981305089073053 | validation: 1.9942734005864835]
	TIME [epoch: 7.68 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6160155629535022		[learning rate: 0.0079012]
	Learning Rate: 0.00790119
	LOSS [training: 1.6160155629535022 | validation: 1.7821243456306253]
	TIME [epoch: 7.7 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.816822321128876		[learning rate: 0.0078825]
	Learning Rate: 0.00788255
	LOSS [training: 1.816822321128876 | validation: 1.9649473592807767]
	TIME [epoch: 7.72 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6291715894240184		[learning rate: 0.007864]
	Learning Rate: 0.00786396
	LOSS [training: 1.6291715894240184 | validation: 1.8254787499616278]
	TIME [epoch: 7.7 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5601159787514818		[learning rate: 0.0078454]
	Learning Rate: 0.00784541
	LOSS [training: 1.5601159787514818 | validation: 1.9152168824144047]
	TIME [epoch: 7.7 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7908381371206115		[learning rate: 0.0078269]
	Learning Rate: 0.0078269
	LOSS [training: 1.7908381371206115 | validation: 1.5058490603569366]
	TIME [epoch: 7.69 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_154.pth
	Model improved!!!
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.45667106137478		[learning rate: 0.0078084]
	Learning Rate: 0.00780844
	LOSS [training: 1.45667106137478 | validation: 1.9328816540331415]
	TIME [epoch: 7.71 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.998196510800869		[learning rate: 0.00779]
	Learning Rate: 0.00779002
	LOSS [training: 1.998196510800869 | validation: 1.8363579273828443]
	TIME [epoch: 7.75 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4787303158204668		[learning rate: 0.0077716]
	Learning Rate: 0.00777164
	LOSS [training: 1.4787303158204668 | validation: 1.4657692618431954]
	TIME [epoch: 7.67 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_157.pth
	Model improved!!!
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3698117079251921		[learning rate: 0.0077533]
	Learning Rate: 0.00775331
	LOSS [training: 1.3698117079251921 | validation: 2.2931644181303423]
	TIME [epoch: 7.72 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7256207497225218		[learning rate: 0.007735]
	Learning Rate: 0.00773502
	LOSS [training: 1.7256207497225218 | validation: 1.8269384723880622]
	TIME [epoch: 7.71 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5798434898745148		[learning rate: 0.0077168]
	Learning Rate: 0.00771678
	LOSS [training: 1.5798434898745148 | validation: 1.7150560980376794]
	TIME [epoch: 7.74 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.648180008675234		[learning rate: 0.0076986]
	Learning Rate: 0.00769857
	LOSS [training: 1.648180008675234 | validation: 1.6003516986331892]
	TIME [epoch: 7.76 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3991578901751396		[learning rate: 0.0076804]
	Learning Rate: 0.00768041
	LOSS [training: 1.3991578901751396 | validation: 1.8592259903207724]
	TIME [epoch: 7.72 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5118595016208025		[learning rate: 0.0076623]
	Learning Rate: 0.0076623
	LOSS [training: 1.5118595016208025 | validation: 1.5211479954685418]
	TIME [epoch: 7.73 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8905837880021858		[learning rate: 0.0076442]
	Learning Rate: 0.00764422
	LOSS [training: 1.8905837880021858 | validation: 1.55203793382807]
	TIME [epoch: 7.68 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4394522894324464		[learning rate: 0.0076262]
	Learning Rate: 0.00762619
	LOSS [training: 1.4394522894324464 | validation: 1.5623882364670783]
	TIME [epoch: 7.73 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4198995886380907		[learning rate: 0.0076082]
	Learning Rate: 0.0076082
	LOSS [training: 1.4198995886380907 | validation: 1.7421088994734213]
	TIME [epoch: 7.72 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5859509504722105		[learning rate: 0.0075903]
	Learning Rate: 0.00759025
	LOSS [training: 1.5859509504722105 | validation: 2.1521240447650705]
	TIME [epoch: 7.68 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7826438495457138		[learning rate: 0.0075724]
	Learning Rate: 0.00757235
	LOSS [training: 1.7826438495457138 | validation: 2.9280649363407036]
	TIME [epoch: 7.71 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1323771921314223		[learning rate: 0.0075545]
	Learning Rate: 0.00755449
	LOSS [training: 2.1323771921314223 | validation: 1.7648598249144496]
	TIME [epoch: 7.7 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4129092591612846		[learning rate: 0.0075367]
	Learning Rate: 0.00753667
	LOSS [training: 1.4129092591612846 | validation: 1.8573800264666533]
	TIME [epoch: 7.76 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5798764354500188		[learning rate: 0.0075189]
	Learning Rate: 0.00751889
	LOSS [training: 1.5798764354500188 | validation: 1.6274758500571456]
	TIME [epoch: 7.69 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4112373224104982		[learning rate: 0.0075012]
	Learning Rate: 0.00750116
	LOSS [training: 1.4112373224104982 | validation: 2.0942025541215084]
	TIME [epoch: 7.67 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.503975446838378		[learning rate: 0.0074835]
	Learning Rate: 0.00748346
	LOSS [training: 1.503975446838378 | validation: 1.924081857710678]
	TIME [epoch: 7.7 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7662073032182817		[learning rate: 0.0074658]
	Learning Rate: 0.00746581
	LOSS [training: 1.7662073032182817 | validation: 2.329473919878369]
	TIME [epoch: 7.68 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6094747386772865		[learning rate: 0.0074482]
	Learning Rate: 0.0074482
	LOSS [training: 1.6094747386772865 | validation: 1.5584172599786155]
	TIME [epoch: 7.75 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3793137230134138		[learning rate: 0.0074306]
	Learning Rate: 0.00743063
	LOSS [training: 1.3793137230134138 | validation: 1.5949345160441317]
	TIME [epoch: 7.75 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4474123462121824		[learning rate: 0.0074131]
	Learning Rate: 0.0074131
	LOSS [training: 1.4474123462121824 | validation: 1.5952646899247909]
	TIME [epoch: 7.74 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6301407658234386		[learning rate: 0.0073956]
	Learning Rate: 0.00739562
	LOSS [training: 1.6301407658234386 | validation: 1.8973750914574241]
	TIME [epoch: 7.79 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.593577517180656		[learning rate: 0.0073782]
	Learning Rate: 0.00737817
	LOSS [training: 1.593577517180656 | validation: 2.0207988003676127]
	TIME [epoch: 7.81 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.098657963663072		[learning rate: 0.0073608]
	Learning Rate: 0.00736077
	LOSS [training: 2.098657963663072 | validation: 1.9550795591802017]
	TIME [epoch: 7.85 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6168291928271699		[learning rate: 0.0073434]
	Learning Rate: 0.0073434
	LOSS [training: 1.6168291928271699 | validation: 1.7324392087835236]
	TIME [epoch: 7.81 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4707983866390038		[learning rate: 0.0073261]
	Learning Rate: 0.00732608
	LOSS [training: 1.4707983866390038 | validation: 1.6790400141233186]
	TIME [epoch: 7.81 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4146843746041293		[learning rate: 0.0073088]
	Learning Rate: 0.0073088
	LOSS [training: 1.4146843746041293 | validation: 1.6560660474178657]
	TIME [epoch: 7.81 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6547859168985344		[learning rate: 0.0072916]
	Learning Rate: 0.00729156
	LOSS [training: 1.6547859168985344 | validation: 1.4426642536178722]
	TIME [epoch: 7.82 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_184.pth
	Model improved!!!
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.279833392324403		[learning rate: 0.0072744]
	Learning Rate: 0.00727436
	LOSS [training: 1.279833392324403 | validation: 1.4767347443244287]
	TIME [epoch: 7.87 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2893250893528063		[learning rate: 0.0072572]
	Learning Rate: 0.0072572
	LOSS [training: 1.2893250893528063 | validation: 1.7277114914762528]
	TIME [epoch: 7.8 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.582466893571936		[learning rate: 0.0072401]
	Learning Rate: 0.00724008
	LOSS [training: 1.582466893571936 | validation: 1.8689760084689073]
	TIME [epoch: 7.8 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.641640173219122		[learning rate: 0.007223]
	Learning Rate: 0.007223
	LOSS [training: 1.641640173219122 | validation: 1.8800152301167175]
	TIME [epoch: 7.74 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3887198480117457		[learning rate: 0.007206]
	Learning Rate: 0.00720597
	LOSS [training: 1.3887198480117457 | validation: 1.4550055976895024]
	TIME [epoch: 7.73 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2866294765338886		[learning rate: 0.007189]
	Learning Rate: 0.00718897
	LOSS [training: 1.2866294765338886 | validation: 1.7187526350331603]
	TIME [epoch: 7.73 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4707909319631711		[learning rate: 0.007172]
	Learning Rate: 0.00717201
	LOSS [training: 1.4707909319631711 | validation: 1.823940151199064]
	TIME [epoch: 7.8 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4062391148740518		[learning rate: 0.0071551]
	Learning Rate: 0.00715509
	LOSS [training: 1.4062391148740518 | validation: 1.5105586551287167]
	TIME [epoch: 7.8 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4944991170473054		[learning rate: 0.0071382]
	Learning Rate: 0.00713822
	LOSS [training: 1.4944991170473054 | validation: 1.9503298377965335]
	TIME [epoch: 7.8 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6612732542089623		[learning rate: 0.0071214]
	Learning Rate: 0.00712138
	LOSS [training: 1.6612732542089623 | validation: 2.152860195814944]
	TIME [epoch: 7.85 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5419550655266177		[learning rate: 0.0071046]
	Learning Rate: 0.00710458
	LOSS [training: 1.5419550655266177 | validation: 1.5953166744069311]
	TIME [epoch: 7.81 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.570939626928192		[learning rate: 0.0070878]
	Learning Rate: 0.00708782
	LOSS [training: 1.570939626928192 | validation: 1.5367366615753992]
	TIME [epoch: 7.8 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3884569125500867		[learning rate: 0.0070711]
	Learning Rate: 0.0070711
	LOSS [training: 1.3884569125500867 | validation: 1.4751138313437755]
	TIME [epoch: 7.8 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2658488852354044		[learning rate: 0.0070544]
	Learning Rate: 0.00705442
	LOSS [training: 1.2658488852354044 | validation: 1.9246085268227018]
	TIME [epoch: 7.8 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5103450281828676		[learning rate: 0.0070378]
	Learning Rate: 0.00703778
	LOSS [training: 1.5103450281828676 | validation: 1.4092326851309744]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_199.pth
	Model improved!!!
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.28825843467826		[learning rate: 0.0070212]
	Learning Rate: 0.00702118
	LOSS [training: 1.28825843467826 | validation: 1.4284125283184728]
	TIME [epoch: 7.8 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3476173086208099		[learning rate: 0.0070046]
	Learning Rate: 0.00700462
	LOSS [training: 1.3476173086208099 | validation: 1.3831728518111026]
	TIME [epoch: 7.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_201.pth
	Model improved!!!
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.789142115373425		[learning rate: 0.0069881]
	Learning Rate: 0.0069881
	LOSS [training: 1.789142115373425 | validation: 1.590769728088945]
	TIME [epoch: 7.8 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.353014497017958		[learning rate: 0.0069716]
	Learning Rate: 0.00697161
	LOSS [training: 1.353014497017958 | validation: 1.6810804971727522]
	TIME [epoch: 7.82 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4528787840147008		[learning rate: 0.0069552]
	Learning Rate: 0.00695517
	LOSS [training: 1.4528787840147008 | validation: 1.5733427882327047]
	TIME [epoch: 7.84 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3788991005808864		[learning rate: 0.0069388]
	Learning Rate: 0.00693876
	LOSS [training: 1.3788991005808864 | validation: 1.503102464977983]
	TIME [epoch: 7.81 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6299888802630063		[learning rate: 0.0069224]
	Learning Rate: 0.00692239
	LOSS [training: 1.6299888802630063 | validation: 1.954588452068311]
	TIME [epoch: 7.81 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5988864739246988		[learning rate: 0.0069061]
	Learning Rate: 0.00690607
	LOSS [training: 1.5988864739246988 | validation: 1.5484591203671063]
	TIME [epoch: 7.8 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.328604025111635		[learning rate: 0.0068898]
	Learning Rate: 0.00688978
	LOSS [training: 1.328604025111635 | validation: 1.7456983939106316]
	TIME [epoch: 7.84 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4309233645925516		[learning rate: 0.0068735]
	Learning Rate: 0.00687352
	LOSS [training: 1.4309233645925516 | validation: 1.5380066591623263]
	TIME [epoch: 7.83 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3605419590121348		[learning rate: 0.0068573]
	Learning Rate: 0.00685731
	LOSS [training: 1.3605419590121348 | validation: 1.9598506765420898]
	TIME [epoch: 7.81 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4143135980478472		[learning rate: 0.0068411]
	Learning Rate: 0.00684114
	LOSS [training: 1.4143135980478472 | validation: 1.5891619757317172]
	TIME [epoch: 7.8 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4518301827079279		[learning rate: 0.006825]
	Learning Rate: 0.006825
	LOSS [training: 1.4518301827079279 | validation: 1.3700352246702456]
	TIME [epoch: 7.78 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_212.pth
	Model improved!!!
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2297733877460257		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 1.2297733877460257 | validation: 1.554953633650093]
	TIME [epoch: 7.79 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3262276926323588		[learning rate: 0.0067928]
	Learning Rate: 0.00679284
	LOSS [training: 1.3262276926323588 | validation: 2.255777449533837]
	TIME [epoch: 7.72 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4455317442832578		[learning rate: 0.0067768]
	Learning Rate: 0.00677681
	LOSS [training: 1.4455317442832578 | validation: 1.4623732715583557]
	TIME [epoch: 7.75 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3331262078648651		[learning rate: 0.0067608]
	Learning Rate: 0.00676083
	LOSS [training: 1.3331262078648651 | validation: 1.4943659271869756]
	TIME [epoch: 7.8 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2887626606710383		[learning rate: 0.0067449]
	Learning Rate: 0.00674488
	LOSS [training: 1.2887626606710383 | validation: 1.9153801543205562]
	TIME [epoch: 7.76 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.655680340552438		[learning rate: 0.006729]
	Learning Rate: 0.00672897
	LOSS [training: 1.655680340552438 | validation: 1.6437812669965348]
	TIME [epoch: 7.86 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4374643482446414		[learning rate: 0.0067131]
	Learning Rate: 0.0067131
	LOSS [training: 1.4374643482446414 | validation: 1.5145765824538473]
	TIME [epoch: 7.82 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2938715631818063		[learning rate: 0.0066973]
	Learning Rate: 0.00669726
	LOSS [training: 1.2938715631818063 | validation: 1.3650906895860295]
	TIME [epoch: 7.82 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_220.pth
	Model improved!!!
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4091881307439131		[learning rate: 0.0066815]
	Learning Rate: 0.00668147
	LOSS [training: 1.4091881307439131 | validation: 2.3304743204852407]
	TIME [epoch: 7.81 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6006996495322967		[learning rate: 0.0066657]
	Learning Rate: 0.00666571
	LOSS [training: 1.6006996495322967 | validation: 1.5123706993380566]
	TIME [epoch: 7.83 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3950543270814844		[learning rate: 0.00665]
	Learning Rate: 0.00664998
	LOSS [training: 1.3950543270814844 | validation: 1.6130901786931515]
	TIME [epoch: 7.85 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3239957875430617		[learning rate: 0.0066343]
	Learning Rate: 0.0066343
	LOSS [training: 1.3239957875430617 | validation: 1.4697659573424615]
	TIME [epoch: 7.8 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2253965898175159		[learning rate: 0.0066186]
	Learning Rate: 0.00661865
	LOSS [training: 1.2253965898175159 | validation: 1.4904196441108686]
	TIME [epoch: 7.81 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2838113744098103		[learning rate: 0.006603]
	Learning Rate: 0.00660304
	LOSS [training: 1.2838113744098103 | validation: 1.5272519627804693]
	TIME [epoch: 7.82 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3049226770960587		[learning rate: 0.0065875]
	Learning Rate: 0.00658746
	LOSS [training: 1.3049226770960587 | validation: 1.7467019440832428]
	TIME [epoch: 7.83 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.522405563906364		[learning rate: 0.0065719]
	Learning Rate: 0.00657192
	LOSS [training: 1.522405563906364 | validation: 2.167051645760911]
	TIME [epoch: 7.81 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.62270121301248		[learning rate: 0.0065564]
	Learning Rate: 0.00655642
	LOSS [training: 1.62270121301248 | validation: 1.8122032408127442]
	TIME [epoch: 7.78 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5003937072739295		[learning rate: 0.006541]
	Learning Rate: 0.00654095
	LOSS [training: 1.5003937072739295 | validation: 1.5627292381653484]
	TIME [epoch: 7.8 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2757590101558094		[learning rate: 0.0065255]
	Learning Rate: 0.00652552
	LOSS [training: 1.2757590101558094 | validation: 1.3699511399999125]
	TIME [epoch: 7.75 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.275129936288874		[learning rate: 0.0065101]
	Learning Rate: 0.00651013
	LOSS [training: 1.275129936288874 | validation: 1.5627383680299562]
	TIME [epoch: 7.84 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2383073076533466		[learning rate: 0.0064948]
	Learning Rate: 0.00649477
	LOSS [training: 1.2383073076533466 | validation: 1.408023557079531]
	TIME [epoch: 7.79 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4271176903099445		[learning rate: 0.0064795]
	Learning Rate: 0.00647945
	LOSS [training: 1.4271176903099445 | validation: 1.4851641570404717]
	TIME [epoch: 7.8 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3549374144509063		[learning rate: 0.0064642]
	Learning Rate: 0.00646417
	LOSS [training: 1.3549374144509063 | validation: 1.3959632970828144]
	TIME [epoch: 7.76 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5747856012794215		[learning rate: 0.0064489]
	Learning Rate: 0.00644892
	LOSS [training: 1.5747856012794215 | validation: 1.7154210773880674]
	TIME [epoch: 7.77 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3298232119162796		[learning rate: 0.0064337]
	Learning Rate: 0.00643371
	LOSS [training: 1.3298232119162796 | validation: 1.306004117179174]
	TIME [epoch: 7.76 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_237.pth
	Model improved!!!
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1627368216366305		[learning rate: 0.0064185]
	Learning Rate: 0.00641853
	LOSS [training: 1.1627368216366305 | validation: 1.826493452525143]
	TIME [epoch: 7.77 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3196909882419776		[learning rate: 0.0064034]
	Learning Rate: 0.00640339
	LOSS [training: 1.3196909882419776 | validation: 1.8115854357257628]
	TIME [epoch: 7.7 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4909874441986501		[learning rate: 0.0063883]
	Learning Rate: 0.00638829
	LOSS [training: 1.4909874441986501 | validation: 1.2868620225775316]
	TIME [epoch: 7.73 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_240.pth
	Model improved!!!
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.393438371131842		[learning rate: 0.0063732]
	Learning Rate: 0.00637322
	LOSS [training: 1.393438371131842 | validation: 2.170013968187746]
	TIME [epoch: 7.81 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.460560164486948		[learning rate: 0.0063582]
	Learning Rate: 0.00635819
	LOSS [training: 1.460560164486948 | validation: 1.411816489272233]
	TIME [epoch: 7.82 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2154251877193067		[learning rate: 0.0063432]
	Learning Rate: 0.00634319
	LOSS [training: 1.2154251877193067 | validation: 1.4454734220598917]
	TIME [epoch: 7.76 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2867705026862588		[learning rate: 0.0063282]
	Learning Rate: 0.00632823
	LOSS [training: 1.2867705026862588 | validation: 1.4790679812467302]
	TIME [epoch: 7.79 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.332877886061175		[learning rate: 0.0063133]
	Learning Rate: 0.0063133
	LOSS [training: 1.332877886061175 | validation: 1.714065742417939]
	TIME [epoch: 7.76 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2338187916991734		[learning rate: 0.0062984]
	Learning Rate: 0.00629841
	LOSS [training: 1.2338187916991734 | validation: 2.4754588278823366]
	TIME [epoch: 7.8 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6494376316642878		[learning rate: 0.0062836]
	Learning Rate: 0.00628355
	LOSS [training: 1.6494376316642878 | validation: 1.3468911762627513]
	TIME [epoch: 7.83 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1852380213684168		[learning rate: 0.0062687]
	Learning Rate: 0.00626873
	LOSS [training: 1.1852380213684168 | validation: 1.8351037562720927]
	TIME [epoch: 7.82 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2111346994821686		[learning rate: 0.0062539]
	Learning Rate: 0.00625394
	LOSS [training: 1.2111346994821686 | validation: 1.459041440699912]
	TIME [epoch: 7.78 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3950979683968872		[learning rate: 0.0062392]
	Learning Rate: 0.00623919
	LOSS [training: 1.3950979683968872 | validation: 1.3746412056300814]
	TIME [epoch: 7.81 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.197098261462775		[learning rate: 0.0062245]
	Learning Rate: 0.00622447
	LOSS [training: 1.197098261462775 | validation: 1.2879313408360704]
	TIME [epoch: 7.83 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3183236917526377		[learning rate: 0.0062098]
	Learning Rate: 0.00620979
	LOSS [training: 1.3183236917526377 | validation: 1.5537869814026415]
	TIME [epoch: 7.84 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.320293446541425		[learning rate: 0.0061951]
	Learning Rate: 0.00619514
	LOSS [training: 1.320293446541425 | validation: 1.1644861080654887]
	TIME [epoch: 7.79 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_253.pth
	Model improved!!!
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2464609365261108		[learning rate: 0.0061805]
	Learning Rate: 0.00618053
	LOSS [training: 1.2464609365261108 | validation: 2.4134515808326515]
	TIME [epoch: 7.7 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6369114992694698		[learning rate: 0.0061659]
	Learning Rate: 0.00616595
	LOSS [training: 1.6369114992694698 | validation: 1.763424467703897]
	TIME [epoch: 7.67 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1842128459336854		[learning rate: 0.0061514]
	Learning Rate: 0.00615141
	LOSS [training: 1.1842128459336854 | validation: 1.4923879788209682]
	TIME [epoch: 7.73 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.16028761413483		[learning rate: 0.0061369]
	Learning Rate: 0.0061369
	LOSS [training: 1.16028761413483 | validation: 1.3852583663312608]
	TIME [epoch: 7.7 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1933197964097069		[learning rate: 0.0061224]
	Learning Rate: 0.00612242
	LOSS [training: 1.1933197964097069 | validation: 1.5521670853157379]
	TIME [epoch: 7.74 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3591664244936346		[learning rate: 0.006108]
	Learning Rate: 0.00610798
	LOSS [training: 1.3591664244936346 | validation: 1.7508402865609833]
	TIME [epoch: 7.75 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.514176797936956		[learning rate: 0.0060936]
	Learning Rate: 0.00609357
	LOSS [training: 1.514176797936956 | validation: 1.726097663157033]
	TIME [epoch: 7.79 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.404823937209406		[learning rate: 0.0060792]
	Learning Rate: 0.0060792
	LOSS [training: 1.404823937209406 | validation: 1.4595847248272322]
	TIME [epoch: 7.81 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2305689109053066		[learning rate: 0.0060649]
	Learning Rate: 0.00606486
	LOSS [training: 1.2305689109053066 | validation: 1.2641258005210267]
	TIME [epoch: 7.7 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2500961309298844		[learning rate: 0.0060505]
	Learning Rate: 0.00605055
	LOSS [training: 1.2500961309298844 | validation: 1.2438933740017235]
	TIME [epoch: 7.71 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.297982745307276		[learning rate: 0.0060363]
	Learning Rate: 0.00603628
	LOSS [training: 1.297982745307276 | validation: 1.402004531875202]
	TIME [epoch: 7.78 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2408602224339347		[learning rate: 0.006022]
	Learning Rate: 0.00602204
	LOSS [training: 1.2408602224339347 | validation: 1.4541149244299367]
	TIME [epoch: 7.77 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.213216023533128		[learning rate: 0.0060078]
	Learning Rate: 0.00600783
	LOSS [training: 1.213216023533128 | validation: 1.3647962109897052]
	TIME [epoch: 7.85 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0584295514768425		[learning rate: 0.0059937]
	Learning Rate: 0.00599366
	LOSS [training: 1.0584295514768425 | validation: 1.3303470961389356]
	TIME [epoch: 7.81 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3212747688755357		[learning rate: 0.0059795]
	Learning Rate: 0.00597952
	LOSS [training: 1.3212747688755357 | validation: 1.6511184098160658]
	TIME [epoch: 7.81 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.12541789471459		[learning rate: 0.0059654]
	Learning Rate: 0.00596542
	LOSS [training: 1.12541789471459 | validation: 1.2411985353509967]
	TIME [epoch: 7.81 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3042776671124383		[learning rate: 0.0059513]
	Learning Rate: 0.00595135
	LOSS [training: 1.3042776671124383 | validation: 1.2188278129559045]
	TIME [epoch: 7.83 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3208308539949778		[learning rate: 0.0059373]
	Learning Rate: 0.00593731
	LOSS [training: 1.3208308539949778 | validation: 1.3791172693154956]
	TIME [epoch: 7.83 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0926624334193247		[learning rate: 0.0059233]
	Learning Rate: 0.00592331
	LOSS [training: 1.0926624334193247 | validation: 1.413659838963973]
	TIME [epoch: 7.82 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1612866869751752		[learning rate: 0.0059093]
	Learning Rate: 0.00590933
	LOSS [training: 1.1612866869751752 | validation: 2.0634564983315036]
	TIME [epoch: 7.81 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4991407087766404		[learning rate: 0.0058954]
	Learning Rate: 0.00589539
	LOSS [training: 1.4991407087766404 | validation: 1.6152936039343664]
	TIME [epoch: 7.81 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4043313716875503		[learning rate: 0.0058815]
	Learning Rate: 0.00588149
	LOSS [training: 1.4043313716875503 | validation: 1.3474132532182952]
	TIME [epoch: 7.85 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2551247615757186		[learning rate: 0.0058676]
	Learning Rate: 0.00586761
	LOSS [training: 1.2551247615757186 | validation: 3.836999402113394]
	TIME [epoch: 7.81 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7651168345677277		[learning rate: 0.0058538]
	Learning Rate: 0.00585377
	LOSS [training: 1.7651168345677277 | validation: 1.298305345139668]
	TIME [epoch: 7.81 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1419664208478415		[learning rate: 0.00584]
	Learning Rate: 0.00583996
	LOSS [training: 1.1419664208478415 | validation: 1.3119030362124087]
	TIME [epoch: 7.81 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0795010470710318		[learning rate: 0.0058262]
	Learning Rate: 0.00582619
	LOSS [training: 1.0795010470710318 | validation: 1.3400329877686823]
	TIME [epoch: 7.81 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1428563587191019		[learning rate: 0.0058124]
	Learning Rate: 0.00581245
	LOSS [training: 1.1428563587191019 | validation: 1.3758680916662462]
	TIME [epoch: 7.85 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1771687807858524		[learning rate: 0.0057987]
	Learning Rate: 0.00579874
	LOSS [training: 1.1771687807858524 | validation: 1.4093605546871921]
	TIME [epoch: 7.81 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2130825638415315		[learning rate: 0.0057851]
	Learning Rate: 0.00578506
	LOSS [training: 1.2130825638415315 | validation: 1.3721772209278134]
	TIME [epoch: 7.81 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5261200125222194		[learning rate: 0.0057714]
	Learning Rate: 0.00577141
	LOSS [training: 1.5261200125222194 | validation: 1.553130397077021]
	TIME [epoch: 7.81 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3460608477591607		[learning rate: 0.0057578]
	Learning Rate: 0.0057578
	LOSS [training: 1.3460608477591607 | validation: 1.4608245851056223]
	TIME [epoch: 7.81 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3646333301739664		[learning rate: 0.0057442]
	Learning Rate: 0.00574422
	LOSS [training: 1.3646333301739664 | validation: 1.2714288338499529]
	TIME [epoch: 7.85 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1889479638993095		[learning rate: 0.0057307]
	Learning Rate: 0.00573067
	LOSS [training: 1.1889479638993095 | validation: 1.2339926422769103]
	TIME [epoch: 7.76 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1100322855068274		[learning rate: 0.0057171]
	Learning Rate: 0.00571715
	LOSS [training: 1.1100322855068274 | validation: 1.3655461648792446]
	TIME [epoch: 7.74 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1007145300532621		[learning rate: 0.0057037]
	Learning Rate: 0.00570366
	LOSS [training: 1.1007145300532621 | validation: 1.2193242595532165]
	TIME [epoch: 7.72 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0690834190960636		[learning rate: 0.0056902]
	Learning Rate: 0.00569021
	LOSS [training: 1.0690834190960636 | validation: 1.2611518285274053]
	TIME [epoch: 7.82 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.159334036701086		[learning rate: 0.0056768]
	Learning Rate: 0.00567679
	LOSS [training: 1.159334036701086 | validation: 1.2608939424711876]
	TIME [epoch: 7.84 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1122640373236266		[learning rate: 0.0056634]
	Learning Rate: 0.0056634
	LOSS [training: 1.1122640373236266 | validation: 1.1839550430323582]
	TIME [epoch: 7.8 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.030518615820206		[learning rate: 0.00565]
	Learning Rate: 0.00565004
	LOSS [training: 1.030518615820206 | validation: 1.53188290529296]
	TIME [epoch: 7.81 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1359810570349702		[learning rate: 0.0056367]
	Learning Rate: 0.00563671
	LOSS [training: 1.1359810570349702 | validation: 1.468311404073512]
	TIME [epoch: 7.8 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0065380589389046		[learning rate: 0.0056234]
	Learning Rate: 0.00562341
	LOSS [training: 1.0065380589389046 | validation: 1.4279997140988463]
	TIME [epoch: 7.84 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0955198518937057		[learning rate: 0.0056101]
	Learning Rate: 0.00561015
	LOSS [training: 1.0955198518937057 | validation: 1.3251211696371237]
	TIME [epoch: 7.81 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0988321487125874		[learning rate: 0.0055969]
	Learning Rate: 0.00559691
	LOSS [training: 1.0988321487125874 | validation: 1.2421440717229848]
	TIME [epoch: 7.81 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0686374251313793		[learning rate: 0.0055837]
	Learning Rate: 0.00558371
	LOSS [training: 1.0686374251313793 | validation: 1.692496617436078]
	TIME [epoch: 7.81 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1428485867289564		[learning rate: 0.0055705]
	Learning Rate: 0.00557054
	LOSS [training: 1.1428485867289564 | validation: 1.3886892779923166]
	TIME [epoch: 7.79 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0162020843921336		[learning rate: 0.0055574]
	Learning Rate: 0.0055574
	LOSS [training: 1.0162020843921336 | validation: 1.1176127351881164]
	TIME [epoch: 7.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_299.pth
	Model improved!!!
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0467481884032506		[learning rate: 0.0055443]
	Learning Rate: 0.00554429
	LOSS [training: 1.0467481884032506 | validation: 1.1451726833341795]
	TIME [epoch: 7.74 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1253092990125177		[learning rate: 0.0055312]
	Learning Rate: 0.00553121
	LOSS [training: 1.1253092990125177 | validation: 1.5948574145045007]
	TIME [epoch: 7.8 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3558594748122645		[learning rate: 0.0055182]
	Learning Rate: 0.00551817
	LOSS [training: 1.3558594748122645 | validation: 1.1839077967513272]
	TIME [epoch: 7.8 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1957215924917461		[learning rate: 0.0055052]
	Learning Rate: 0.00550515
	LOSS [training: 1.1957215924917461 | validation: 1.3699445404792243]
	TIME [epoch: 7.81 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0760899854180503		[learning rate: 0.0054922]
	Learning Rate: 0.00549216
	LOSS [training: 1.0760899854180503 | validation: 1.4297131990963114]
	TIME [epoch: 7.81 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0169069312766776		[learning rate: 0.0054792]
	Learning Rate: 0.00547921
	LOSS [training: 1.0169069312766776 | validation: 1.1881380413248934]
	TIME [epoch: 7.82 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0488115419658128		[learning rate: 0.0054663]
	Learning Rate: 0.00546629
	LOSS [training: 1.0488115419658128 | validation: 1.4969932845750118]
	TIME [epoch: 7.81 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1012203569957661		[learning rate: 0.0054534]
	Learning Rate: 0.00545339
	LOSS [training: 1.1012203569957661 | validation: 1.7146152643500359]
	TIME [epoch: 7.8 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.181149447276632		[learning rate: 0.0054405]
	Learning Rate: 0.00544053
	LOSS [training: 1.181149447276632 | validation: 1.1371869742677285]
	TIME [epoch: 7.84 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9858573643144081		[learning rate: 0.0054277]
	Learning Rate: 0.00542769
	LOSS [training: 0.9858573643144081 | validation: 1.0439886551885371]
	TIME [epoch: 7.83 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_309.pth
	Model improved!!!
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9979575477176095		[learning rate: 0.0054149]
	Learning Rate: 0.00541489
	LOSS [training: 0.9979575477176095 | validation: 1.5872441876234786]
	TIME [epoch: 7.81 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4326169591420335		[learning rate: 0.0054021]
	Learning Rate: 0.00540212
	LOSS [training: 1.4326169591420335 | validation: 1.3728070957721252]
	TIME [epoch: 7.72 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1457208987222927		[learning rate: 0.0053894]
	Learning Rate: 0.00538938
	LOSS [training: 1.1457208987222927 | validation: 1.1804828702334271]
	TIME [epoch: 7.74 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1128781745836724		[learning rate: 0.0053767]
	Learning Rate: 0.00537666
	LOSS [training: 1.1128781745836724 | validation: 1.1253456396891495]
	TIME [epoch: 7.8 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9527228832004744		[learning rate: 0.005364]
	Learning Rate: 0.00536398
	LOSS [training: 0.9527228832004744 | validation: 1.3393883802461575]
	TIME [epoch: 7.75 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1436245971367531		[learning rate: 0.0053513]
	Learning Rate: 0.00535133
	LOSS [training: 1.1436245971367531 | validation: 1.0318551545221348]
	TIME [epoch: 7.81 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_315.pth
	Model improved!!!
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0832793769190439		[learning rate: 0.0053387]
	Learning Rate: 0.00533871
	LOSS [training: 1.0832793769190439 | validation: 1.2483669019082924]
	TIME [epoch: 7.8 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9762408631819708		[learning rate: 0.0053261]
	Learning Rate: 0.00532611
	LOSS [training: 0.9762408631819708 | validation: 1.0656328994725706]
	TIME [epoch: 7.8 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9990002886126741		[learning rate: 0.0053135]
	Learning Rate: 0.00531355
	LOSS [training: 0.9990002886126741 | validation: 1.1310585539082654]
	TIME [epoch: 7.8 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0213375263637805		[learning rate: 0.005301]
	Learning Rate: 0.00530101
	LOSS [training: 1.0213375263637805 | validation: 1.2127948690376507]
	TIME [epoch: 7.76 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3254399899848357		[learning rate: 0.0052885]
	Learning Rate: 0.00528851
	LOSS [training: 1.3254399899848357 | validation: 1.5816090633507556]
	TIME [epoch: 7.75 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2043301308140284		[learning rate: 0.005276]
	Learning Rate: 0.00527604
	LOSS [training: 1.2043301308140284 | validation: 1.2383344242424954]
	TIME [epoch: 7.73 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.03075462180864		[learning rate: 0.0052636]
	Learning Rate: 0.00526359
	LOSS [training: 1.03075462180864 | validation: 1.2587144536160535]
	TIME [epoch: 7.74 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1132662740969015		[learning rate: 0.0052512]
	Learning Rate: 0.00525117
	LOSS [training: 1.1132662740969015 | validation: 1.3713952264662148]
	TIME [epoch: 7.76 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.001860673027171		[learning rate: 0.0052388]
	Learning Rate: 0.00523879
	LOSS [training: 1.001860673027171 | validation: 1.0602439143037967]
	TIME [epoch: 7.78 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1188332185084437		[learning rate: 0.0052264]
	Learning Rate: 0.00522643
	LOSS [training: 1.1188332185084437 | validation: 1.0659768357546442]
	TIME [epoch: 7.75 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0336990577315575		[learning rate: 0.0052141]
	Learning Rate: 0.0052141
	LOSS [training: 1.0336990577315575 | validation: 1.0748518909214637]
	TIME [epoch: 7.72 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1292075875387486		[learning rate: 0.0052018]
	Learning Rate: 0.0052018
	LOSS [training: 1.1292075875387486 | validation: 1.2104170202371303]
	TIME [epoch: 7.78 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1492155442066831		[learning rate: 0.0051895]
	Learning Rate: 0.00518953
	LOSS [training: 1.1492155442066831 | validation: 1.1794896353781323]
	TIME [epoch: 7.81 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0383929548236266		[learning rate: 0.0051773]
	Learning Rate: 0.00517729
	LOSS [training: 1.0383929548236266 | validation: 1.0838910440723957]
	TIME [epoch: 7.76 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9326417233325589		[learning rate: 0.0051651]
	Learning Rate: 0.00516508
	LOSS [training: 0.9326417233325589 | validation: 1.4608900016941835]
	TIME [epoch: 7.83 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.139099453520611		[learning rate: 0.0051529]
	Learning Rate: 0.00515289
	LOSS [training: 1.139099453520611 | validation: 1.1262659727127637]
	TIME [epoch: 7.8 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.01831251446499		[learning rate: 0.0051407]
	Learning Rate: 0.00514074
	LOSS [training: 1.01831251446499 | validation: 0.9741407568349396]
	TIME [epoch: 7.8 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_332.pth
	Model improved!!!
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1350362907649914		[learning rate: 0.0051286]
	Learning Rate: 0.00512861
	LOSS [training: 1.1350362907649914 | validation: 1.1812555057578398]
	TIME [epoch: 7.82 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9843972047483834		[learning rate: 0.0051165]
	Learning Rate: 0.00511652
	LOSS [training: 0.9843972047483834 | validation: 1.0638364453705158]
	TIME [epoch: 7.78 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9487399409787614		[learning rate: 0.0051044]
	Learning Rate: 0.00510445
	LOSS [training: 0.9487399409787614 | validation: 1.1020308289804166]
	TIME [epoch: 7.75 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6491552977212083		[learning rate: 0.0050924]
	Learning Rate: 0.00509241
	LOSS [training: 1.6491552977212083 | validation: 2.22606902799936]
	TIME [epoch: 7.76 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6408944860704084		[learning rate: 0.0050804]
	Learning Rate: 0.00508039
	LOSS [training: 1.6408944860704084 | validation: 1.0990930944739103]
	TIME [epoch: 7.8 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0539474604052088		[learning rate: 0.0050684]
	Learning Rate: 0.00506841
	LOSS [training: 1.0539474604052088 | validation: 1.297363839602958]
	TIME [epoch: 7.8 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9483602516117285		[learning rate: 0.0050565]
	Learning Rate: 0.00505645
	LOSS [training: 0.9483602516117285 | validation: 0.9472726670344551]
	TIME [epoch: 7.76 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_339.pth
	Model improved!!!
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9143019862313103		[learning rate: 0.0050445]
	Learning Rate: 0.00504453
	LOSS [training: 0.9143019862313103 | validation: 0.9424180487132743]
	TIME [epoch: 7.81 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_340.pth
	Model improved!!!
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9266369912003349		[learning rate: 0.0050326]
	Learning Rate: 0.00503263
	LOSS [training: 0.9266369912003349 | validation: 1.247056031431795]
	TIME [epoch: 7.74 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9140891620712004		[learning rate: 0.0050208]
	Learning Rate: 0.00502076
	LOSS [training: 0.9140891620712004 | validation: 1.0452382663645208]
	TIME [epoch: 7.73 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9792414497731521		[learning rate: 0.0050089]
	Learning Rate: 0.00500891
	LOSS [training: 0.9792414497731521 | validation: 1.0661610525823906]
	TIME [epoch: 7.67 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9406064990353282		[learning rate: 0.0049971]
	Learning Rate: 0.0049971
	LOSS [training: 0.9406064990353282 | validation: 1.094409577253546]
	TIME [epoch: 7.69 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.100282786842684		[learning rate: 0.0049853]
	Learning Rate: 0.00498531
	LOSS [training: 1.100282786842684 | validation: 1.4038186467561298]
	TIME [epoch: 7.7 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9649448029368323		[learning rate: 0.0049736]
	Learning Rate: 0.00497355
	LOSS [training: 0.9649448029368323 | validation: 1.0441727866173443]
	TIME [epoch: 7.8 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1525906953607805		[learning rate: 0.0049618]
	Learning Rate: 0.00496182
	LOSS [training: 1.1525906953607805 | validation: 1.7311305057959938]
	TIME [epoch: 7.84 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0854393646440181		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 1.0854393646440181 | validation: 1.0627193873325895]
	TIME [epoch: 7.81 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8662508231000078		[learning rate: 0.0049384]
	Learning Rate: 0.00493844
	LOSS [training: 0.8662508231000078 | validation: 1.2085156353603914]
	TIME [epoch: 7.81 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0138377520945312		[learning rate: 0.0049268]
	Learning Rate: 0.00492679
	LOSS [training: 1.0138377520945312 | validation: 0.9881835227026845]
	TIME [epoch: 7.81 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9546332394476893		[learning rate: 0.0049152]
	Learning Rate: 0.00491517
	LOSS [training: 0.9546332394476893 | validation: 1.0857238452567906]
	TIME [epoch: 7.85 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8751127286698963		[learning rate: 0.0049036]
	Learning Rate: 0.00490357
	LOSS [training: 0.8751127286698963 | validation: 1.0653257510796688]
	TIME [epoch: 7.82 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8659558906502312		[learning rate: 0.004892]
	Learning Rate: 0.00489201
	LOSS [training: 0.8659558906502312 | validation: 1.1119621788604754]
	TIME [epoch: 7.81 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9741623263868292		[learning rate: 0.0048805]
	Learning Rate: 0.00488047
	LOSS [training: 0.9741623263868292 | validation: 1.261041789728609]
	TIME [epoch: 7.81 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9488258327563404		[learning rate: 0.004869]
	Learning Rate: 0.00486896
	LOSS [training: 0.9488258327563404 | validation: 1.1966550559686016]
	TIME [epoch: 7.81 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0034422778103886		[learning rate: 0.0048575]
	Learning Rate: 0.00485747
	LOSS [training: 1.0034422778103886 | validation: 0.9929103989727242]
	TIME [epoch: 7.85 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.900257226959178		[learning rate: 0.004846]
	Learning Rate: 0.00484601
	LOSS [training: 0.900257226959178 | validation: 1.062319734909198]
	TIME [epoch: 7.81 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9358388993795783		[learning rate: 0.0048346]
	Learning Rate: 0.00483458
	LOSS [training: 0.9358388993795783 | validation: 1.0782395726681915]
	TIME [epoch: 7.81 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8697582764710114		[learning rate: 0.0048232]
	Learning Rate: 0.00482318
	LOSS [training: 0.8697582764710114 | validation: 0.9862545997354683]
	TIME [epoch: 7.81 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8186232368920217		[learning rate: 0.0048118]
	Learning Rate: 0.0048118
	LOSS [training: 0.8186232368920217 | validation: 1.1607313845206941]
	TIME [epoch: 7.76 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9831391636336053		[learning rate: 0.0048005]
	Learning Rate: 0.00480045
	LOSS [training: 0.9831391636336053 | validation: 1.5596936091848979]
	TIME [epoch: 7.77 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.057456124325535		[learning rate: 0.0047891]
	Learning Rate: 0.00478913
	LOSS [training: 1.057456124325535 | validation: 1.0011077676982063]
	TIME [epoch: 7.73 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0868619069035557		[learning rate: 0.0047778]
	Learning Rate: 0.00477783
	LOSS [training: 1.0868619069035557 | validation: 1.131719239717341]
	TIME [epoch: 7.81 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9503309702473348		[learning rate: 0.0047666]
	Learning Rate: 0.00476656
	LOSS [training: 0.9503309702473348 | validation: 1.1825471742795068]
	TIME [epoch: 7.81 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9728679937318245		[learning rate: 0.0047553]
	Learning Rate: 0.00475532
	LOSS [training: 0.9728679937318245 | validation: 1.1412602908455207]
	TIME [epoch: 7.81 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9592970283895874		[learning rate: 0.0047441]
	Learning Rate: 0.0047441
	LOSS [training: 0.9592970283895874 | validation: 0.9087409167159568]
	TIME [epoch: 7.85 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_366.pth
	Model improved!!!
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8108267919662516		[learning rate: 0.0047329]
	Learning Rate: 0.00473291
	LOSS [training: 0.8108267919662516 | validation: 1.0185076467271488]
	TIME [epoch: 7.8 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9153940313349951		[learning rate: 0.0047217]
	Learning Rate: 0.00472175
	LOSS [training: 0.9153940313349951 | validation: 1.1844609966842927]
	TIME [epoch: 7.81 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9034867086505354		[learning rate: 0.0047106]
	Learning Rate: 0.00471061
	LOSS [training: 0.9034867086505354 | validation: 1.2337708779313412]
	TIME [epoch: 7.81 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0100560631111326		[learning rate: 0.0046995]
	Learning Rate: 0.0046995
	LOSS [training: 1.0100560631111326 | validation: 0.9786866036798852]
	TIME [epoch: 7.84 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8988090792221036		[learning rate: 0.0046884]
	Learning Rate: 0.00468841
	LOSS [training: 0.8988090792221036 | validation: 1.1425311215510017]
	TIME [epoch: 7.83 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8833743647307526		[learning rate: 0.0046774]
	Learning Rate: 0.00467735
	LOSS [training: 0.8833743647307526 | validation: 1.6800017725917433]
	TIME [epoch: 7.81 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3008004879206778		[learning rate: 0.0046663]
	Learning Rate: 0.00466632
	LOSS [training: 1.3008004879206778 | validation: 1.0507840345748898]
	TIME [epoch: 7.8 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.838433655437718		[learning rate: 0.0046553]
	Learning Rate: 0.00465531
	LOSS [training: 0.838433655437718 | validation: 1.0442660738898182]
	TIME [epoch: 7.8 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1438305430919198		[learning rate: 0.0046443]
	Learning Rate: 0.00464433
	LOSS [training: 1.1438305430919198 | validation: 0.9653867853886302]
	TIME [epoch: 7.84 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8143363482182211		[learning rate: 0.0046334]
	Learning Rate: 0.00463338
	LOSS [training: 0.8143363482182211 | validation: 0.8660322953489745]
	TIME [epoch: 7.81 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_376.pth
	Model improved!!!
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7994427139098874		[learning rate: 0.0046224]
	Learning Rate: 0.00462245
	LOSS [training: 0.7994427139098874 | validation: 1.0117289161529435]
	TIME [epoch: 7.81 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0002509760168714		[learning rate: 0.0046115]
	Learning Rate: 0.00461154
	LOSS [training: 1.0002509760168714 | validation: 1.4834366954897933]
	TIME [epoch: 7.82 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9684349260184828		[learning rate: 0.0046007]
	Learning Rate: 0.00460066
	LOSS [training: 0.9684349260184828 | validation: 0.9035503438961887]
	TIME [epoch: 7.82 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8585962537599797		[learning rate: 0.0045898]
	Learning Rate: 0.00458981
	LOSS [training: 0.8585962537599797 | validation: 1.2290466475331274]
	TIME [epoch: 7.87 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8789014619952016		[learning rate: 0.004579]
	Learning Rate: 0.00457899
	LOSS [training: 0.8789014619952016 | validation: 1.1145271396358067]
	TIME [epoch: 7.81 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9958046429296549		[learning rate: 0.0045682]
	Learning Rate: 0.00456818
	LOSS [training: 0.9958046429296549 | validation: 1.3254382088141448]
	TIME [epoch: 7.81 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9191026278178068		[learning rate: 0.0045574]
	Learning Rate: 0.00455741
	LOSS [training: 0.9191026278178068 | validation: 0.8567418932675822]
	TIME [epoch: 7.81 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_383.pth
	Model improved!!!
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8441528163104727		[learning rate: 0.0045467]
	Learning Rate: 0.00454666
	LOSS [training: 0.8441528163104727 | validation: 0.9395815130516576]
	TIME [epoch: 7.8 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8295363915605505		[learning rate: 0.0045359]
	Learning Rate: 0.00453593
	LOSS [training: 0.8295363915605505 | validation: 2.345698496878604]
	TIME [epoch: 7.78 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.374286969316283		[learning rate: 0.0045252]
	Learning Rate: 0.00452523
	LOSS [training: 1.374286969316283 | validation: 1.404801514326822]
	TIME [epoch: 7.75 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.888431285132012		[learning rate: 0.0045146]
	Learning Rate: 0.00451456
	LOSS [training: 0.888431285132012 | validation: 0.8755934241007662]
	TIME [epoch: 7.81 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9176319605624197		[learning rate: 0.0045039]
	Learning Rate: 0.00450391
	LOSS [training: 0.9176319605624197 | validation: 0.9556043673806724]
	TIME [epoch: 7.81 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8836080011405549		[learning rate: 0.0044933]
	Learning Rate: 0.00449329
	LOSS [training: 0.8836080011405549 | validation: 0.9227217819593354]
	TIME [epoch: 7.86 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8266414515552293		[learning rate: 0.0044827]
	Learning Rate: 0.00448269
	LOSS [training: 0.8266414515552293 | validation: 0.840657464944423]
	TIME [epoch: 7.83 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_390.pth
	Model improved!!!
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9323572150470507		[learning rate: 0.0044721]
	Learning Rate: 0.00447211
	LOSS [training: 0.9323572150470507 | validation: 1.1130850682875435]
	TIME [epoch: 7.82 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.812541827950791		[learning rate: 0.0044616]
	Learning Rate: 0.00446156
	LOSS [training: 0.812541827950791 | validation: 0.9009457997986867]
	TIME [epoch: 7.81 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7854590934803412		[learning rate: 0.004451]
	Learning Rate: 0.00445104
	LOSS [training: 0.7854590934803412 | validation: 0.7724566954857082]
	TIME [epoch: 7.82 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_393.pth
	Model improved!!!
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7375031985321487		[learning rate: 0.0044405]
	Learning Rate: 0.00444054
	LOSS [training: 0.7375031985321487 | validation: 0.7503128551276828]
	TIME [epoch: 7.88 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_394.pth
	Model improved!!!
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7003276580118214		[learning rate: 0.0044301]
	Learning Rate: 0.00443007
	LOSS [training: 0.7003276580118214 | validation: 0.9058539399619276]
	TIME [epoch: 7.82 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8432472217215432		[learning rate: 0.0044196]
	Learning Rate: 0.00441962
	LOSS [training: 0.8432472217215432 | validation: 1.0216572600860911]
	TIME [epoch: 7.82 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7764138085860289		[learning rate: 0.0044092]
	Learning Rate: 0.00440919
	LOSS [training: 0.7764138085860289 | validation: 0.8196860091615917]
	TIME [epoch: 7.82 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6691912763883238		[learning rate: 0.0043988]
	Learning Rate: 0.00439879
	LOSS [training: 0.6691912763883238 | validation: 0.7825262758425147]
	TIME [epoch: 7.83 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6017403712644971		[learning rate: 0.0043884]
	Learning Rate: 0.00438841
	LOSS [training: 0.6017403712644971 | validation: 0.7602634747765171]
	TIME [epoch: 7.84 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7088507902984394		[learning rate: 0.0043781]
	Learning Rate: 0.00437806
	LOSS [training: 0.7088507902984394 | validation: 1.2236183852371587]
	TIME [epoch: 7.82 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7448833696850896		[learning rate: 0.0043677]
	Learning Rate: 0.00436774
	LOSS [training: 0.7448833696850896 | validation: 0.7600367737837117]
	TIME [epoch: 7.79 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7080502871183222		[learning rate: 0.0043574]
	Learning Rate: 0.00435743
	LOSS [training: 0.7080502871183222 | validation: 0.8761623454037453]
	TIME [epoch: 7.74 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6574085021301197		[learning rate: 0.0043472]
	Learning Rate: 0.00434715
	LOSS [training: 0.6574085021301197 | validation: 0.7016753853501938]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_403.pth
	Model improved!!!
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6708624533712261		[learning rate: 0.0043369]
	Learning Rate: 0.0043369
	LOSS [training: 0.6708624533712261 | validation: 1.2356007519385948]
	TIME [epoch: 7.81 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8333362563106052		[learning rate: 0.0043267]
	Learning Rate: 0.00432667
	LOSS [training: 0.8333362563106052 | validation: 0.8527674365940441]
	TIME [epoch: 7.76 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6552111754542725		[learning rate: 0.0043165]
	Learning Rate: 0.00431646
	LOSS [training: 0.6552111754542725 | validation: 0.6123859258533111]
	TIME [epoch: 7.81 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_406.pth
	Model improved!!!
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6363690116726168		[learning rate: 0.0043063]
	Learning Rate: 0.00430628
	LOSS [training: 0.6363690116726168 | validation: 0.728926406776265]
	TIME [epoch: 7.79 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.742633963120434		[learning rate: 0.0042961]
	Learning Rate: 0.00429612
	LOSS [training: 0.742633963120434 | validation: 0.8568475353857921]
	TIME [epoch: 7.83 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6533032817343541		[learning rate: 0.004286]
	Learning Rate: 0.00428599
	LOSS [training: 0.6533032817343541 | validation: 0.6917703241119031]
	TIME [epoch: 7.78 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6748342903716996		[learning rate: 0.0042759]
	Learning Rate: 0.00427588
	LOSS [training: 0.6748342903716996 | validation: 0.6257912902439674]
	TIME [epoch: 7.77 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5673579767457315		[learning rate: 0.0042658]
	Learning Rate: 0.0042658
	LOSS [training: 0.5673579767457315 | validation: 0.8567031093298447]
	TIME [epoch: 7.76 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7672770587997872		[learning rate: 0.0042557]
	Learning Rate: 0.00425573
	LOSS [training: 0.7672770587997872 | validation: 0.6708012079841243]
	TIME [epoch: 7.8 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6526720671283688		[learning rate: 0.0042457]
	Learning Rate: 0.00424569
	LOSS [training: 0.6526720671283688 | validation: 0.7274788281428142]
	TIME [epoch: 7.87 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6111071962066053		[learning rate: 0.0042357]
	Learning Rate: 0.00423568
	LOSS [training: 0.6111071962066053 | validation: 0.5459345382221893]
	TIME [epoch: 7.82 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_414.pth
	Model improved!!!
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5521556585622686		[learning rate: 0.0042257]
	Learning Rate: 0.00422569
	LOSS [training: 0.5521556585622686 | validation: 0.7360618722633498]
	TIME [epoch: 7.78 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5537529345729348		[learning rate: 0.0042157]
	Learning Rate: 0.00421572
	LOSS [training: 0.5537529345729348 | validation: 0.6269164964104306]
	TIME [epoch: 7.81 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5742454322305264		[learning rate: 0.0042058]
	Learning Rate: 0.00420578
	LOSS [training: 0.5742454322305264 | validation: 0.732852709758562]
	TIME [epoch: 7.85 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6265413173803845		[learning rate: 0.0041959]
	Learning Rate: 0.00419585
	LOSS [training: 0.6265413173803845 | validation: 0.6514230459946089]
	TIME [epoch: 7.84 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5827406854212842		[learning rate: 0.004186]
	Learning Rate: 0.00418596
	LOSS [training: 0.5827406854212842 | validation: 0.5825691672576114]
	TIME [epoch: 7.82 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5605372322126708		[learning rate: 0.0041761]
	Learning Rate: 0.00417608
	LOSS [training: 0.5605372322126708 | validation: 0.571138394269193]
	TIME [epoch: 7.76 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.564201102965269		[learning rate: 0.0041662]
	Learning Rate: 0.00416623
	LOSS [training: 0.564201102965269 | validation: 0.5260298370186967]
	TIME [epoch: 7.79 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_421.pth
	Model improved!!!
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5658382993924198		[learning rate: 0.0041564]
	Learning Rate: 0.00415641
	LOSS [training: 0.5658382993924198 | validation: 0.5423830921722297]
	TIME [epoch: 7.87 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6407710710105785		[learning rate: 0.0041466]
	Learning Rate: 0.0041466
	LOSS [training: 0.6407710710105785 | validation: 0.6616484578204214]
	TIME [epoch: 7.82 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6798818076544044		[learning rate: 0.0041368]
	Learning Rate: 0.00413682
	LOSS [training: 0.6798818076544044 | validation: 0.5455027456787714]
	TIME [epoch: 7.82 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4687247544671407		[learning rate: 0.0041271]
	Learning Rate: 0.00412706
	LOSS [training: 0.4687247544671407 | validation: 0.8263063273242985]
	TIME [epoch: 7.77 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6967413133474195		[learning rate: 0.0041173]
	Learning Rate: 0.00411733
	LOSS [training: 0.6967413133474195 | validation: 2.0825725747018877]
	TIME [epoch: 7.82 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9838726768862922		[learning rate: 0.0041076]
	Learning Rate: 0.00410762
	LOSS [training: 0.9838726768862922 | validation: 0.7550842289278075]
	TIME [epoch: 7.84 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5297874139541049		[learning rate: 0.0040979]
	Learning Rate: 0.00409793
	LOSS [training: 0.5297874139541049 | validation: 0.5716355648790751]
	TIME [epoch: 7.83 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5825285833191471		[learning rate: 0.0040883]
	Learning Rate: 0.00408826
	LOSS [training: 0.5825285833191471 | validation: 0.5149823221444969]
	TIME [epoch: 7.82 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_429.pth
	Model improved!!!
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43149305669547305		[learning rate: 0.0040786]
	Learning Rate: 0.00407862
	LOSS [training: 0.43149305669547305 | validation: 0.5671180698751508]
	TIME [epoch: 7.79 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7083554543201596		[learning rate: 0.004069]
	Learning Rate: 0.004069
	LOSS [training: 0.7083554543201596 | validation: 0.9604090039138823]
	TIME [epoch: 7.75 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5667370731023363		[learning rate: 0.0040594]
	Learning Rate: 0.0040594
	LOSS [training: 0.5667370731023363 | validation: 0.5881811576164111]
	TIME [epoch: 7.86 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6425148883277402		[learning rate: 0.0040498]
	Learning Rate: 0.00404982
	LOSS [training: 0.6425148883277402 | validation: 0.7850820219138515]
	TIME [epoch: 7.77 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7533334543081975		[learning rate: 0.0040403]
	Learning Rate: 0.00404027
	LOSS [training: 0.7533334543081975 | validation: 0.5488105148682363]
	TIME [epoch: 7.76 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7149184758249664		[learning rate: 0.0040307]
	Learning Rate: 0.00403074
	LOSS [training: 0.7149184758249664 | validation: 0.8240236891664003]
	TIME [epoch: 7.76 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9137687638913573		[learning rate: 0.0040212]
	Learning Rate: 0.00402123
	LOSS [training: 0.9137687638913573 | validation: 0.7776436541920947]
	TIME [epoch: 7.86 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8786615908897044		[learning rate: 0.0040117]
	Learning Rate: 0.00401175
	LOSS [training: 0.8786615908897044 | validation: 0.6743413371596636]
	TIME [epoch: 7.85 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7346137323274338		[learning rate: 0.0040023]
	Learning Rate: 0.00400228
	LOSS [training: 0.7346137323274338 | validation: 0.6873247547561517]
	TIME [epoch: 7.82 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5611233122619858		[learning rate: 0.0039928]
	Learning Rate: 0.00399284
	LOSS [training: 0.5611233122619858 | validation: 0.5990459685521274]
	TIME [epoch: 7.82 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5677299737737915		[learning rate: 0.0039834]
	Learning Rate: 0.00398342
	LOSS [training: 0.5677299737737915 | validation: 0.6067206950391453]
	TIME [epoch: 7.81 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6065420481946819		[learning rate: 0.003974]
	Learning Rate: 0.00397403
	LOSS [training: 0.6065420481946819 | validation: 0.552861813487944]
	TIME [epoch: 7.87 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5644684357427456		[learning rate: 0.0039647]
	Learning Rate: 0.00396465
	LOSS [training: 0.5644684357427456 | validation: 0.45324657342438757]
	TIME [epoch: 7.83 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_442.pth
	Model improved!!!
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4563067395747187		[learning rate: 0.0039553]
	Learning Rate: 0.0039553
	LOSS [training: 0.4563067395747187 | validation: 0.636359881754173]
	TIME [epoch: 7.83 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4851778208121435		[learning rate: 0.003946]
	Learning Rate: 0.00394597
	LOSS [training: 0.4851778208121435 | validation: 0.5909723222069174]
	TIME [epoch: 7.83 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6379823282534309		[learning rate: 0.0039367]
	Learning Rate: 0.00393666
	LOSS [training: 0.6379823282534309 | validation: 0.4291350135120502]
	TIME [epoch: 7.82 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_445.pth
	Model improved!!!
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5180022531103822		[learning rate: 0.0039274]
	Learning Rate: 0.00392738
	LOSS [training: 0.5180022531103822 | validation: 0.5300365653333512]
	TIME [epoch: 7.81 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48683513821280433		[learning rate: 0.0039181]
	Learning Rate: 0.00391811
	LOSS [training: 0.48683513821280433 | validation: 0.584771251262427]
	TIME [epoch: 7.76 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5226418312975197		[learning rate: 0.0039089]
	Learning Rate: 0.00390887
	LOSS [training: 0.5226418312975197 | validation: 1.435778429513463]
	TIME [epoch: 7.81 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7047332443462493		[learning rate: 0.0038996]
	Learning Rate: 0.00389965
	LOSS [training: 0.7047332443462493 | validation: 0.6811246330477909]
	TIME [epoch: 7.82 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5171048916031926		[learning rate: 0.0038905]
	Learning Rate: 0.00389045
	LOSS [training: 0.5171048916031926 | validation: 0.5849505423802516]
	TIME [epoch: 7.83 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49124559690215425		[learning rate: 0.0038813]
	Learning Rate: 0.00388127
	LOSS [training: 0.49124559690215425 | validation: 0.44980459963266073]
	TIME [epoch: 7.85 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5182117180466328		[learning rate: 0.0038721]
	Learning Rate: 0.00387212
	LOSS [training: 0.5182117180466328 | validation: 1.379380885929709]
	TIME [epoch: 7.8 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7946285031634608		[learning rate: 0.003863]
	Learning Rate: 0.00386299
	LOSS [training: 0.7946285031634608 | validation: 0.40960241325837854]
	TIME [epoch: 7.76 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_453.pth
	Model improved!!!
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6337776856369316		[learning rate: 0.0038539]
	Learning Rate: 0.00385387
	LOSS [training: 0.6337776856369316 | validation: 0.5744763427626781]
	TIME [epoch: 7.75 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5509614290312593		[learning rate: 0.0038448]
	Learning Rate: 0.00384478
	LOSS [training: 0.5509614290312593 | validation: 0.6818349306944356]
	TIME [epoch: 7.75 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5472218342360156		[learning rate: 0.0038357]
	Learning Rate: 0.00383571
	LOSS [training: 0.5472218342360156 | validation: 1.5378402813170173]
	TIME [epoch: 7.76 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0711391374083443		[learning rate: 0.0038267]
	Learning Rate: 0.00382667
	LOSS [training: 1.0711391374083443 | validation: 0.628478750384702]
	TIME [epoch: 7.73 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5140527318359436		[learning rate: 0.0038176]
	Learning Rate: 0.00381764
	LOSS [training: 0.5140527318359436 | validation: 0.557186505344214]
	TIME [epoch: 7.72 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5157372429629912		[learning rate: 0.0038086]
	Learning Rate: 0.00380863
	LOSS [training: 0.5157372429629912 | validation: 0.5538032425695909]
	TIME [epoch: 7.73 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4680117656603081		[learning rate: 0.0037996]
	Learning Rate: 0.00379965
	LOSS [training: 0.4680117656603081 | validation: 0.5309630780912681]
	TIME [epoch: 7.86 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4803012908787432		[learning rate: 0.0037907]
	Learning Rate: 0.00379069
	LOSS [training: 0.4803012908787432 | validation: 0.5583191646958421]
	TIME [epoch: 7.83 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5128832826189595		[learning rate: 0.0037817]
	Learning Rate: 0.00378175
	LOSS [training: 0.5128832826189595 | validation: 0.45730926793687]
	TIME [epoch: 7.81 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5545626751622068		[learning rate: 0.0037728]
	Learning Rate: 0.00377283
	LOSS [training: 0.5545626751622068 | validation: 0.5986744743198881]
	TIME [epoch: 7.82 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49352802295280374		[learning rate: 0.0037639]
	Learning Rate: 0.00376393
	LOSS [training: 0.49352802295280374 | validation: 0.4372016338001458]
	TIME [epoch: 7.82 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6689083684794226		[learning rate: 0.003755]
	Learning Rate: 0.00375505
	LOSS [training: 0.6689083684794226 | validation: 0.4690376209655241]
	TIME [epoch: 7.85 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43821794674765346		[learning rate: 0.0037462]
	Learning Rate: 0.00374619
	LOSS [training: 0.43821794674765346 | validation: 0.3731069806891652]
	TIME [epoch: 7.83 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_466.pth
	Model improved!!!
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3926633572423921		[learning rate: 0.0037374]
	Learning Rate: 0.00373735
	LOSS [training: 0.3926633572423921 | validation: 0.6478622289770791]
	TIME [epoch: 7.82 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44720303725927824		[learning rate: 0.0037285]
	Learning Rate: 0.00372854
	LOSS [training: 0.44720303725927824 | validation: 0.40836502381878337]
	TIME [epoch: 7.81 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42332169133898256		[learning rate: 0.0037197]
	Learning Rate: 0.00371974
	LOSS [training: 0.42332169133898256 | validation: 0.6452313748437117]
	TIME [epoch: 7.82 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4588086926530395		[learning rate: 0.003711]
	Learning Rate: 0.00371097
	LOSS [training: 0.4588086926530395 | validation: 0.5739348543332656]
	TIME [epoch: 7.79 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5126872252507358		[learning rate: 0.0037022]
	Learning Rate: 0.00370221
	LOSS [training: 0.5126872252507358 | validation: 0.5205011270007529]
	TIME [epoch: 7.73 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46450884328017644		[learning rate: 0.0036935]
	Learning Rate: 0.00369348
	LOSS [training: 0.46450884328017644 | validation: 0.39827707437001636]
	TIME [epoch: 7.78 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7104399794277316		[learning rate: 0.0036848]
	Learning Rate: 0.00368477
	LOSS [training: 0.7104399794277316 | validation: 0.598938108406444]
	TIME [epoch: 7.82 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48519794182247333		[learning rate: 0.0036761]
	Learning Rate: 0.00367608
	LOSS [training: 0.48519794182247333 | validation: 0.5126652755645239]
	TIME [epoch: 7.83 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45267968560046956		[learning rate: 0.0036674]
	Learning Rate: 0.00366741
	LOSS [training: 0.45267968560046956 | validation: 0.5060755217148646]
	TIME [epoch: 7.83 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4002311291840116		[learning rate: 0.0036588]
	Learning Rate: 0.00365875
	LOSS [training: 0.4002311291840116 | validation: 0.5940608257166369]
	TIME [epoch: 7.81 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.543014280356183		[learning rate: 0.0036501]
	Learning Rate: 0.00365012
	LOSS [training: 0.543014280356183 | validation: 0.6057855966575882]
	TIME [epoch: 7.8 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5776387429915383		[learning rate: 0.0036415]
	Learning Rate: 0.00364151
	LOSS [training: 0.5776387429915383 | validation: 0.5938659836515421]
	TIME [epoch: 7.81 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5006925354300708		[learning rate: 0.0036329]
	Learning Rate: 0.00363292
	LOSS [training: 0.5006925354300708 | validation: 1.3919955920276268]
	TIME [epoch: 7.85 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8253854475567247		[learning rate: 0.0036244]
	Learning Rate: 0.00362436
	LOSS [training: 0.8253854475567247 | validation: 0.4646786042979234]
	TIME [epoch: 7.8 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48995172373451235		[learning rate: 0.0036158]
	Learning Rate: 0.00361581
	LOSS [training: 0.48995172373451235 | validation: 0.42818943505300433]
	TIME [epoch: 7.8 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4993706511157897		[learning rate: 0.0036073]
	Learning Rate: 0.00360728
	LOSS [training: 0.4993706511157897 | validation: 0.4504347323362055]
	TIME [epoch: 7.67 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47171780181050693		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.47171780181050693 | validation: 0.6119256632967471]
	TIME [epoch: 7.71 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4702383532235679		[learning rate: 0.0035903]
	Learning Rate: 0.00359028
	LOSS [training: 0.4702383532235679 | validation: 0.6690481268885649]
	TIME [epoch: 7.78 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4770967775037943		[learning rate: 0.0035818]
	Learning Rate: 0.00358181
	LOSS [training: 0.4770967775037943 | validation: 0.46581060070859903]
	TIME [epoch: 7.8 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.445548571180257		[learning rate: 0.0035734]
	Learning Rate: 0.00357336
	LOSS [training: 0.445548571180257 | validation: 0.40701150069477865]
	TIME [epoch: 7.78 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39597308608654774		[learning rate: 0.0035649]
	Learning Rate: 0.00356493
	LOSS [training: 0.39597308608654774 | validation: 0.42949913008754714]
	TIME [epoch: 7.71 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4640461019539038		[learning rate: 0.0035565]
	Learning Rate: 0.00355652
	LOSS [training: 0.4640461019539038 | validation: 0.5092129089451043]
	TIME [epoch: 7.76 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45737355660098167		[learning rate: 0.0035481]
	Learning Rate: 0.00354813
	LOSS [training: 0.45737355660098167 | validation: 0.3532385584612766]
	TIME [epoch: 7.84 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_489.pth
	Model improved!!!
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4317954011815255		[learning rate: 0.0035398]
	Learning Rate: 0.00353976
	LOSS [training: 0.4317954011815255 | validation: 0.4820198551635662]
	TIME [epoch: 7.83 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.545591090457421		[learning rate: 0.0035314]
	Learning Rate: 0.00353141
	LOSS [training: 0.545591090457421 | validation: 0.4774305426915836]
	TIME [epoch: 7.82 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5976055136596146		[learning rate: 0.0035231]
	Learning Rate: 0.00352308
	LOSS [training: 0.5976055136596146 | validation: 1.5158196067988412]
	TIME [epoch: 7.81 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9257058500778284		[learning rate: 0.0035148]
	Learning Rate: 0.00351477
	LOSS [training: 0.9257058500778284 | validation: 0.568334902617663]
	TIME [epoch: 7.85 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4598287960895912		[learning rate: 0.0035065]
	Learning Rate: 0.00350648
	LOSS [training: 0.4598287960895912 | validation: 0.49390716387882544]
	TIME [epoch: 7.84 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43266666310849167		[learning rate: 0.0034982]
	Learning Rate: 0.00349821
	LOSS [training: 0.43266666310849167 | validation: 0.5891099504164593]
	TIME [epoch: 7.82 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4901754601673863		[learning rate: 0.00349]
	Learning Rate: 0.00348996
	LOSS [training: 0.4901754601673863 | validation: 0.415904255808856]
	TIME [epoch: 7.82 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49776594649341704		[learning rate: 0.0034817]
	Learning Rate: 0.00348173
	LOSS [training: 0.49776594649341704 | validation: 0.8112827687192046]
	TIME [epoch: 7.83 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7782811987761293		[learning rate: 0.0034735]
	Learning Rate: 0.00347352
	LOSS [training: 0.7782811987761293 | validation: 0.7897975064463298]
	TIME [epoch: 7.86 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6135002465570819		[learning rate: 0.0034653]
	Learning Rate: 0.00346532
	LOSS [training: 0.6135002465570819 | validation: 0.45404322031037103]
	TIME [epoch: 7.77 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5458462285915031		[learning rate: 0.0034571]
	Learning Rate: 0.00345715
	LOSS [training: 0.5458462285915031 | validation: 0.7691171683734042]
	TIME [epoch: 7.81 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49478446724095726		[learning rate: 0.003449]
	Learning Rate: 0.00344899
	LOSS [training: 0.49478446724095726 | validation: 0.6460743554083113]
	TIME [epoch: 7.77 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5061934626188631		[learning rate: 0.0034409]
	Learning Rate: 0.00344086
	LOSS [training: 0.5061934626188631 | validation: 0.4623368065565847]
	TIME [epoch: 7.77 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5023390894360468		[learning rate: 0.0034327]
	Learning Rate: 0.00343274
	LOSS [training: 0.5023390894360468 | validation: 0.41958123150904286]
	TIME [epoch: 7.85 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42389689163458555		[learning rate: 0.0034246]
	Learning Rate: 0.00342464
	LOSS [training: 0.42389689163458555 | validation: 0.42982096328439673]
	TIME [epoch: 7.83 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6327124557626685		[learning rate: 0.0034166]
	Learning Rate: 0.00341657
	LOSS [training: 0.6327124557626685 | validation: 0.7116782348370728]
	TIME [epoch: 7.82 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7542803823932154		[learning rate: 0.0034085]
	Learning Rate: 0.00340851
	LOSS [training: 0.7542803823932154 | validation: 1.5320026979007308]
	TIME [epoch: 7.81 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9670919671433639		[learning rate: 0.0034005]
	Learning Rate: 0.00340047
	LOSS [training: 0.9670919671433639 | validation: 0.7775775101331182]
	TIME [epoch: 7.76 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5217736313300694		[learning rate: 0.0033924]
	Learning Rate: 0.00339244
	LOSS [training: 0.5217736313300694 | validation: 0.762718751143258]
	TIME [epoch: 7.81 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4289380018529044		[learning rate: 0.0033844]
	Learning Rate: 0.00338444
	LOSS [training: 0.4289380018529044 | validation: 0.4882277590477123]
	TIME [epoch: 7.81 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43922227467350766		[learning rate: 0.0033765]
	Learning Rate: 0.00337646
	LOSS [training: 0.43922227467350766 | validation: 0.4272381470627199]
	TIME [epoch: 7.79 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4888327903244442		[learning rate: 0.0033685]
	Learning Rate: 0.0033685
	LOSS [training: 0.4888327903244442 | validation: 0.3846767211011885]
	TIME [epoch: 7.72 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46888605155504554		[learning rate: 0.0033605]
	Learning Rate: 0.00336055
	LOSS [training: 0.46888605155504554 | validation: 0.5589050210759243]
	TIME [epoch: 7.76 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6353761830511423		[learning rate: 0.0033526]
	Learning Rate: 0.00335262
	LOSS [training: 0.6353761830511423 | validation: 0.6135782179130012]
	TIME [epoch: 7.77 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5120462160277062		[learning rate: 0.0033447]
	Learning Rate: 0.00334471
	LOSS [training: 0.5120462160277062 | validation: 0.5687368625055501]
	TIME [epoch: 7.8 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5120783836132038		[learning rate: 0.0033368]
	Learning Rate: 0.00333682
	LOSS [training: 0.5120783836132038 | validation: 0.3899223903429207]
	TIME [epoch: 7.81 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43380292137924703		[learning rate: 0.003329]
	Learning Rate: 0.00332895
	LOSS [training: 0.43380292137924703 | validation: 0.4147577710145468]
	TIME [epoch: 7.81 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3786477396356191		[learning rate: 0.0033211]
	Learning Rate: 0.0033211
	LOSS [training: 0.3786477396356191 | validation: 0.5158003746745976]
	TIME [epoch: 7.86 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45582813082752893		[learning rate: 0.0033133]
	Learning Rate: 0.00331327
	LOSS [training: 0.45582813082752893 | validation: 0.6419544434306079]
	TIME [epoch: 7.82 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.573891383264455		[learning rate: 0.0033055]
	Learning Rate: 0.00330545
	LOSS [training: 0.573891383264455 | validation: 0.38426666323061953]
	TIME [epoch: 7.81 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3332029788887765		[learning rate: 0.0032977]
	Learning Rate: 0.00329765
	LOSS [training: 0.3332029788887765 | validation: 0.35284503760492536]
	TIME [epoch: 7.78 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_520.pth
	Model improved!!!
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5707944609157481		[learning rate: 0.0032899]
	Learning Rate: 0.00328988
	LOSS [training: 0.5707944609157481 | validation: 0.38675455175939]
	TIME [epoch: 7.75 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39778129565640047		[learning rate: 0.0032821]
	Learning Rate: 0.00328212
	LOSS [training: 0.39778129565640047 | validation: 0.4566231687589449]
	TIME [epoch: 7.87 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43819725408572296		[learning rate: 0.0032744]
	Learning Rate: 0.00327437
	LOSS [training: 0.43819725408572296 | validation: 0.6020046076472021]
	TIME [epoch: 7.82 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5758095263937669		[learning rate: 0.0032666]
	Learning Rate: 0.00326665
	LOSS [training: 0.5758095263937669 | validation: 0.6494195055970493]
	TIME [epoch: 7.82 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7933450369342949		[learning rate: 0.0032589]
	Learning Rate: 0.00325894
	LOSS [training: 0.7933450369342949 | validation: 1.437829443951223]
	TIME [epoch: 7.82 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0008749626095084		[learning rate: 0.0032513]
	Learning Rate: 0.00325126
	LOSS [training: 1.0008749626095084 | validation: 0.5539418451608737]
	TIME [epoch: 7.81 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.482989028099167		[learning rate: 0.0032436]
	Learning Rate: 0.00324359
	LOSS [training: 0.482989028099167 | validation: 0.46402355683515767]
	TIME [epoch: 7.86 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41223016534196416		[learning rate: 0.0032359]
	Learning Rate: 0.00323594
	LOSS [training: 0.41223016534196416 | validation: 0.4704306777589675]
	TIME [epoch: 7.8 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3957295233208631		[learning rate: 0.0032283]
	Learning Rate: 0.0032283
	LOSS [training: 0.3957295233208631 | validation: 0.39555317905056425]
	TIME [epoch: 7.79 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40327722120515896		[learning rate: 0.0032207]
	Learning Rate: 0.00322069
	LOSS [training: 0.40327722120515896 | validation: 0.5847334776414872]
	TIME [epoch: 7.8 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4748404310288359		[learning rate: 0.0032131]
	Learning Rate: 0.00321309
	LOSS [training: 0.4748404310288359 | validation: 0.45573864969165967]
	TIME [epoch: 7.8 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45202930115649365		[learning rate: 0.0032055]
	Learning Rate: 0.00320551
	LOSS [training: 0.45202930115649365 | validation: 0.5947374242688919]
	TIME [epoch: 7.79 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4529089480351142		[learning rate: 0.003198]
	Learning Rate: 0.00319795
	LOSS [training: 0.4529089480351142 | validation: 0.3581514982212345]
	TIME [epoch: 7.76 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3361527209928454		[learning rate: 0.0031904]
	Learning Rate: 0.00319041
	LOSS [training: 0.3361527209928454 | validation: 0.4443540759234891]
	TIME [epoch: 7.81 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4562546762355465		[learning rate: 0.0031829]
	Learning Rate: 0.00318288
	LOSS [training: 0.4562546762355465 | validation: 0.4440742862190337]
	TIME [epoch: 7.8 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31044121086976206		[learning rate: 0.0031754]
	Learning Rate: 0.00317537
	LOSS [training: 0.31044121086976206 | validation: 0.3792839611046702]
	TIME [epoch: 7.85 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44098590159729883		[learning rate: 0.0031679]
	Learning Rate: 0.00316788
	LOSS [training: 0.44098590159729883 | validation: 0.393769468578641]
	TIME [epoch: 7.83 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49136388427245337		[learning rate: 0.0031604]
	Learning Rate: 0.00316041
	LOSS [training: 0.49136388427245337 | validation: 0.8640847894706839]
	TIME [epoch: 7.83 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6325238961139633		[learning rate: 0.003153]
	Learning Rate: 0.00315296
	LOSS [training: 0.6325238961139633 | validation: 0.4522665318622773]
	TIME [epoch: 7.77 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40220451957083586		[learning rate: 0.0031455]
	Learning Rate: 0.00314552
	LOSS [training: 0.40220451957083586 | validation: 0.4177479074298659]
	TIME [epoch: 7.77 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3850570439148214		[learning rate: 0.0031381]
	Learning Rate: 0.0031381
	LOSS [training: 0.3850570439148214 | validation: 0.5908935631667321]
	TIME [epoch: 7.84 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5422601854523941		[learning rate: 0.0031307]
	Learning Rate: 0.0031307
	LOSS [training: 0.5422601854523941 | validation: 0.41369533345400866]
	TIME [epoch: 7.81 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40256236915759297		[learning rate: 0.0031233]
	Learning Rate: 0.00312331
	LOSS [training: 0.40256236915759297 | validation: 0.38461061392213414]
	TIME [epoch: 7.82 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3976554343449251		[learning rate: 0.0031159]
	Learning Rate: 0.00311594
	LOSS [training: 0.3976554343449251 | validation: 0.3894342941543379]
	TIME [epoch: 7.82 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5837800125083845		[learning rate: 0.0031086]
	Learning Rate: 0.0031086
	LOSS [training: 0.5837800125083845 | validation: 0.4851086533885056]
	TIME [epoch: 7.83 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46634727462374076		[learning rate: 0.0031013]
	Learning Rate: 0.00310126
	LOSS [training: 0.46634727462374076 | validation: 0.6789654646329057]
	TIME [epoch: 7.86 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5759358462674853		[learning rate: 0.0030939]
	Learning Rate: 0.00309395
	LOSS [training: 0.5759358462674853 | validation: 0.3295178240179381]
	TIME [epoch: 7.81 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_547.pth
	Model improved!!!
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43057503739842495		[learning rate: 0.0030866]
	Learning Rate: 0.00308665
	LOSS [training: 0.43057503739842495 | validation: 0.421138255529772]
	TIME [epoch: 7.81 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3884042817226023		[learning rate: 0.0030794]
	Learning Rate: 0.00307937
	LOSS [training: 0.3884042817226023 | validation: 0.33464950838032026]
	TIME [epoch: 7.8 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3252602812178267		[learning rate: 0.0030721]
	Learning Rate: 0.0030721
	LOSS [training: 0.3252602812178267 | validation: 0.3546969351223719]
	TIME [epoch: 7.84 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38801472603153336		[learning rate: 0.0030649]
	Learning Rate: 0.00306486
	LOSS [training: 0.38801472603153336 | validation: 0.5278280181405058]
	TIME [epoch: 7.86 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4041872924378818		[learning rate: 0.0030576]
	Learning Rate: 0.00305763
	LOSS [training: 0.4041872924378818 | validation: 0.5281983748404299]
	TIME [epoch: 7.83 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4693774051500962		[learning rate: 0.0030504]
	Learning Rate: 0.00305042
	LOSS [training: 0.4693774051500962 | validation: 0.41718803890742284]
	TIME [epoch: 7.82 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4763830235095003		[learning rate: 0.0030432]
	Learning Rate: 0.00304322
	LOSS [training: 0.4763830235095003 | validation: 0.6863053867923326]
	TIME [epoch: 7.81 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4361470826367417		[learning rate: 0.003036]
	Learning Rate: 0.00303604
	LOSS [training: 0.4361470826367417 | validation: 0.3439784562578675]
	TIME [epoch: 7.84 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34425945112258916		[learning rate: 0.0030289]
	Learning Rate: 0.00302888
	LOSS [training: 0.34425945112258916 | validation: 0.44058432122150903]
	TIME [epoch: 7.81 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4153212275091275		[learning rate: 0.0030217]
	Learning Rate: 0.00302174
	LOSS [training: 0.4153212275091275 | validation: 0.43681196092585484]
	TIME [epoch: 7.78 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42382140299599075		[learning rate: 0.0030146]
	Learning Rate: 0.00301461
	LOSS [training: 0.42382140299599075 | validation: 0.41815293462260805]
	TIME [epoch: 7.8 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34663146172642023		[learning rate: 0.0030075]
	Learning Rate: 0.0030075
	LOSS [training: 0.34663146172642023 | validation: 0.33733738057831736]
	TIME [epoch: 7.82 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40736276056276594		[learning rate: 0.0030004]
	Learning Rate: 0.0030004
	LOSS [training: 0.40736276056276594 | validation: 0.4071419725179654]
	TIME [epoch: 7.87 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5801080709533508		[learning rate: 0.0029933]
	Learning Rate: 0.00299332
	LOSS [training: 0.5801080709533508 | validation: 0.8349699504530617]
	TIME [epoch: 7.81 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6781305913545395		[learning rate: 0.0029863]
	Learning Rate: 0.00298626
	LOSS [training: 0.6781305913545395 | validation: 0.5923724688071761]
	TIME [epoch: 7.78 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5037146233835319		[learning rate: 0.0029792]
	Learning Rate: 0.00297922
	LOSS [training: 0.5037146233835319 | validation: 0.6105617136834258]
	TIME [epoch: 7.81 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6503399576143677		[learning rate: 0.0029722]
	Learning Rate: 0.00297219
	LOSS [training: 0.6503399576143677 | validation: 1.1314180926880733]
	TIME [epoch: 7.81 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8425722107511465		[learning rate: 0.0029652]
	Learning Rate: 0.00296518
	LOSS [training: 0.8425722107511465 | validation: 0.6090081571004126]
	TIME [epoch: 7.88 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5626061093045435		[learning rate: 0.0029582]
	Learning Rate: 0.00295819
	LOSS [training: 0.5626061093045435 | validation: 0.4873931565871192]
	TIME [epoch: 7.83 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42409518578993227		[learning rate: 0.0029512]
	Learning Rate: 0.00295121
	LOSS [training: 0.42409518578993227 | validation: 0.4239299021835645]
	TIME [epoch: 7.82 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3858186618331121		[learning rate: 0.0029442]
	Learning Rate: 0.00294425
	LOSS [training: 0.3858186618331121 | validation: 0.3889869025844711]
	TIME [epoch: 7.82 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.365300658644684		[learning rate: 0.0029373]
	Learning Rate: 0.0029373
	LOSS [training: 0.365300658644684 | validation: 0.4467403983961419]
	TIME [epoch: 7.82 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3706395771130594		[learning rate: 0.0029304]
	Learning Rate: 0.00293037
	LOSS [training: 0.3706395771130594 | validation: 0.3680870425629166]
	TIME [epoch: 7.87 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3745145487073255		[learning rate: 0.0029235]
	Learning Rate: 0.00292346
	LOSS [training: 0.3745145487073255 | validation: 0.6765606959904398]
	TIME [epoch: 7.83 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4022557529563076		[learning rate: 0.0029166]
	Learning Rate: 0.00291657
	LOSS [training: 0.4022557529563076 | validation: 0.29547030305380234]
	TIME [epoch: 7.83 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_572.pth
	Model improved!!!
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3916685625325673		[learning rate: 0.0029097]
	Learning Rate: 0.00290969
	LOSS [training: 0.3916685625325673 | validation: 0.43123017730728297]
	TIME [epoch: 7.83 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38226890152819787		[learning rate: 0.0029028]
	Learning Rate: 0.00290282
	LOSS [training: 0.38226890152819787 | validation: 0.5993596630105607]
	TIME [epoch: 7.86 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44128347777466237		[learning rate: 0.002896]
	Learning Rate: 0.00289598
	LOSS [training: 0.44128347777466237 | validation: 0.415491138747734]
	TIME [epoch: 7.84 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4568923776902671		[learning rate: 0.0028891]
	Learning Rate: 0.00288914
	LOSS [training: 0.4568923776902671 | validation: 0.5222374230946405]
	TIME [epoch: 7.82 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39260421064329104		[learning rate: 0.0028823]
	Learning Rate: 0.00288233
	LOSS [training: 0.39260421064329104 | validation: 0.5002864546607686]
	TIME [epoch: 7.8 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43606617880910004		[learning rate: 0.0028755]
	Learning Rate: 0.00287553
	LOSS [training: 0.43606617880910004 | validation: 0.555684150463296]
	TIME [epoch: 7.8 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4161098515895987		[learning rate: 0.0028687]
	Learning Rate: 0.00286875
	LOSS [training: 0.4161098515895987 | validation: 0.3441357330042508]
	TIME [epoch: 7.87 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34684868287817605		[learning rate: 0.002862]
	Learning Rate: 0.00286198
	LOSS [training: 0.34684868287817605 | validation: 0.3057392426421026]
	TIME [epoch: 7.8 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3306787966656312		[learning rate: 0.0028552]
	Learning Rate: 0.00285523
	LOSS [training: 0.3306787966656312 | validation: 0.4741456961724393]
	TIME [epoch: 7.79 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7077084892817739		[learning rate: 0.0028485]
	Learning Rate: 0.00284849
	LOSS [training: 0.7077084892817739 | validation: 0.6793599339947458]
	TIME [epoch: 7.79 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5049647673620501		[learning rate: 0.0028418]
	Learning Rate: 0.00284178
	LOSS [training: 0.5049647673620501 | validation: 0.5821080717792386]
	TIME [epoch: 7.81 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44858109033539434		[learning rate: 0.0028351]
	Learning Rate: 0.00283507
	LOSS [training: 0.44858109033539434 | validation: 0.41129258874994185]
	TIME [epoch: 7.86 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4020111270866557		[learning rate: 0.0028284]
	Learning Rate: 0.00282838
	LOSS [training: 0.4020111270866557 | validation: 0.6158156805971906]
	TIME [epoch: 7.82 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40355824463434303		[learning rate: 0.0028217]
	Learning Rate: 0.00282171
	LOSS [training: 0.40355824463434303 | validation: 0.40335223721072766]
	TIME [epoch: 7.83 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3299956360736094		[learning rate: 0.0028151]
	Learning Rate: 0.00281506
	LOSS [training: 0.3299956360736094 | validation: 0.4792256746041062]
	TIME [epoch: 7.82 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29751630878215307		[learning rate: 0.0028084]
	Learning Rate: 0.00280842
	LOSS [training: 0.29751630878215307 | validation: 0.3639453102650446]
	TIME [epoch: 7.83 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33723762279670866		[learning rate: 0.0028018]
	Learning Rate: 0.00280179
	LOSS [training: 0.33723762279670866 | validation: 0.3603768779036278]
	TIME [epoch: 7.86 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30512867829622814		[learning rate: 0.0027952]
	Learning Rate: 0.00279518
	LOSS [training: 0.30512867829622814 | validation: 0.5319509791754433]
	TIME [epoch: 7.82 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4335477724913674		[learning rate: 0.0027886]
	Learning Rate: 0.00278859
	LOSS [training: 0.4335477724913674 | validation: 0.515963936226195]
	TIME [epoch: 7.81 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4257913323069639		[learning rate: 0.002782]
	Learning Rate: 0.00278201
	LOSS [training: 0.4257913323069639 | validation: 0.42851624864434634]
	TIME [epoch: 7.8 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3210555901328135		[learning rate: 0.0027754]
	Learning Rate: 0.00277545
	LOSS [training: 0.3210555901328135 | validation: 0.39425984905668554]
	TIME [epoch: 7.8 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33757324838654335		[learning rate: 0.0027689]
	Learning Rate: 0.0027689
	LOSS [training: 0.33757324838654335 | validation: 0.5211502031116506]
	TIME [epoch: 7.85 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36269337449901673		[learning rate: 0.0027624]
	Learning Rate: 0.00276237
	LOSS [training: 0.36269337449901673 | validation: 0.4142925897423446]
	TIME [epoch: 7.82 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4487453753452305		[learning rate: 0.0027559]
	Learning Rate: 0.00275586
	LOSS [training: 0.4487453753452305 | validation: 0.6938357020441644]
	TIME [epoch: 7.82 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5759914844558238		[learning rate: 0.0027494]
	Learning Rate: 0.00274936
	LOSS [training: 0.5759914844558238 | validation: 0.4870900263274354]
	TIME [epoch: 7.82 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38546533391081816		[learning rate: 0.0027429]
	Learning Rate: 0.00274287
	LOSS [training: 0.38546533391081816 | validation: 0.4944003425148511]
	TIME [epoch: 7.87 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5521735066493183		[learning rate: 0.0027364]
	Learning Rate: 0.0027364
	LOSS [training: 0.5521735066493183 | validation: 0.43352771743887375]
	TIME [epoch: 7.82 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45617406748428674		[learning rate: 0.0027299]
	Learning Rate: 0.00272994
	LOSS [training: 0.45617406748428674 | validation: 0.38411544118613594]
	TIME [epoch: 7.83 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3553924782763843		[learning rate: 0.0027235]
	Learning Rate: 0.00272351
	LOSS [training: 0.3553924782763843 | validation: 0.966153257884121]
	TIME [epoch: 7.81 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4514523865219028		[learning rate: 0.0027171]
	Learning Rate: 0.00271708
	LOSS [training: 0.4514523865219028 | validation: 0.35968715019757574]
	TIME [epoch: 7.78 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33446117424170363		[learning rate: 0.0027107]
	Learning Rate: 0.00271067
	LOSS [training: 0.33446117424170363 | validation: 0.41324133515124695]
	TIME [epoch: 7.86 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39157259801501243		[learning rate: 0.0027043]
	Learning Rate: 0.00270428
	LOSS [training: 0.39157259801501243 | validation: 0.3127035279543929]
	TIME [epoch: 7.79 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35759207217036926		[learning rate: 0.0026979]
	Learning Rate: 0.0026979
	LOSS [training: 0.35759207217036926 | validation: 0.2873659182391466]
	TIME [epoch: 7.7 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_605.pth
	Model improved!!!
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2885547703904698		[learning rate: 0.0026915]
	Learning Rate: 0.00269153
	LOSS [training: 0.2885547703904698 | validation: 0.2480667033903372]
	TIME [epoch: 7.69 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_606.pth
	Model improved!!!
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32287436273702935		[learning rate: 0.0026852]
	Learning Rate: 0.00268519
	LOSS [training: 0.32287436273702935 | validation: 0.35593249617277456]
	TIME [epoch: 7.73 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3849028332353277		[learning rate: 0.0026789]
	Learning Rate: 0.00267885
	LOSS [training: 0.3849028332353277 | validation: 0.49246827530877324]
	TIME [epoch: 7.8 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4142298857442396		[learning rate: 0.0026725]
	Learning Rate: 0.00267253
	LOSS [training: 0.4142298857442396 | validation: 1.0507244488602225]
	TIME [epoch: 7.82 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6092475965304811		[learning rate: 0.0026662]
	Learning Rate: 0.00266623
	LOSS [training: 0.6092475965304811 | validation: 0.5914027829207591]
	TIME [epoch: 7.82 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4590633315049659		[learning rate: 0.0026599]
	Learning Rate: 0.00265994
	LOSS [training: 0.4590633315049659 | validation: 0.4525458731741693]
	TIME [epoch: 7.81 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3852067752520141		[learning rate: 0.0026537]
	Learning Rate: 0.00265367
	LOSS [training: 0.3852067752520141 | validation: 0.3593978630753891]
	TIME [epoch: 7.85 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.325201726747931		[learning rate: 0.0026474]
	Learning Rate: 0.00264741
	LOSS [training: 0.325201726747931 | validation: 0.42304464590460833]
	TIME [epoch: 7.84 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3687681548022933		[learning rate: 0.0026412]
	Learning Rate: 0.00264116
	LOSS [training: 0.3687681548022933 | validation: 0.289953254085231]
	TIME [epoch: 7.82 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38516774609784915		[learning rate: 0.0026349]
	Learning Rate: 0.00263493
	LOSS [training: 0.38516774609784915 | validation: 0.34136885311374987]
	TIME [epoch: 7.75 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4091880880989126		[learning rate: 0.0026287]
	Learning Rate: 0.00262872
	LOSS [training: 0.4091880880989126 | validation: 0.4484738588090307]
	TIME [epoch: 7.79 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3252618839043559		[learning rate: 0.0026225]
	Learning Rate: 0.00262251
	LOSS [training: 0.3252618839043559 | validation: 0.39835027826785]
	TIME [epoch: 7.86 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3025771784564957		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.3025771784564957 | validation: 0.3017189559658616]
	TIME [epoch: 7.82 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3346389285657803		[learning rate: 0.0026102]
	Learning Rate: 0.00261016
	LOSS [training: 0.3346389285657803 | validation: 0.3614293195977405]
	TIME [epoch: 7.81 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.292836673704716		[learning rate: 0.002604]
	Learning Rate: 0.002604
	LOSS [training: 0.292836673704716 | validation: 0.36652702541596777]
	TIME [epoch: 7.8 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3818175253668239		[learning rate: 0.0025979]
	Learning Rate: 0.00259786
	LOSS [training: 0.3818175253668239 | validation: 0.3472966960906836]
	TIME [epoch: 7.81 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2908039988057439		[learning rate: 0.0025917]
	Learning Rate: 0.00259173
	LOSS [training: 0.2908039988057439 | validation: 0.32215356249805305]
	TIME [epoch: 7.85 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3010738447267769		[learning rate: 0.0025856]
	Learning Rate: 0.00258562
	LOSS [training: 0.3010738447267769 | validation: 0.4017716809281335]
	TIME [epoch: 7.81 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2923253543270434		[learning rate: 0.0025795]
	Learning Rate: 0.00257952
	LOSS [training: 0.2923253543270434 | validation: 0.2755314194881816]
	TIME [epoch: 7.82 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3125335816419652		[learning rate: 0.0025734]
	Learning Rate: 0.00257343
	LOSS [training: 0.3125335816419652 | validation: 0.3019426956455101]
	TIME [epoch: 7.81 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24943578978599257		[learning rate: 0.0025674]
	Learning Rate: 0.00256736
	LOSS [training: 0.24943578978599257 | validation: 0.30927771004768895]
	TIME [epoch: 7.99 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5435996626395205		[learning rate: 0.0025613]
	Learning Rate: 0.00256131
	LOSS [training: 0.5435996626395205 | validation: 0.37300104952657515]
	TIME [epoch: 7.86 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4426782748418261		[learning rate: 0.0025553]
	Learning Rate: 0.00255526
	LOSS [training: 0.4426782748418261 | validation: 0.32845032486618353]
	TIME [epoch: 7.82 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.324356711926684		[learning rate: 0.0025492]
	Learning Rate: 0.00254924
	LOSS [training: 0.324356711926684 | validation: 0.3401955707838721]
	TIME [epoch: 7.72 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2790893179104412		[learning rate: 0.0025432]
	Learning Rate: 0.00254322
	LOSS [training: 0.2790893179104412 | validation: 0.24647012864738982]
	TIME [epoch: 7.74 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_630.pth
	Model improved!!!
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2950677150792515		[learning rate: 0.0025372]
	Learning Rate: 0.00253722
	LOSS [training: 0.2950677150792515 | validation: 0.33257812871426434]
	TIME [epoch: 7.78 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2963908506093522		[learning rate: 0.0025312]
	Learning Rate: 0.00253124
	LOSS [training: 0.2963908506093522 | validation: 0.4090374834213364]
	TIME [epoch: 7.8 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41478689670760416		[learning rate: 0.0025253]
	Learning Rate: 0.00252527
	LOSS [training: 0.41478689670760416 | validation: 0.3431846780590888]
	TIME [epoch: 7.72 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30526768813712724		[learning rate: 0.0025193]
	Learning Rate: 0.00251931
	LOSS [training: 0.30526768813712724 | validation: 0.24320943989647614]
	TIME [epoch: 7.71 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_634.pth
	Model improved!!!
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35495793648560114		[learning rate: 0.0025134]
	Learning Rate: 0.00251337
	LOSS [training: 0.35495793648560114 | validation: 0.3743903003948611]
	TIME [epoch: 7.73 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4312073389110709		[learning rate: 0.0025074]
	Learning Rate: 0.00250744
	LOSS [training: 0.4312073389110709 | validation: 0.28800841248499126]
	TIME [epoch: 7.79 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2487209232926745		[learning rate: 0.0025015]
	Learning Rate: 0.00250153
	LOSS [training: 0.2487209232926745 | validation: 0.2697830294893169]
	TIME [epoch: 7.74 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3405775180470639		[learning rate: 0.0024956]
	Learning Rate: 0.00249563
	LOSS [training: 0.3405775180470639 | validation: 0.48329392120238235]
	TIME [epoch: 7.69 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3341154509402441		[learning rate: 0.0024897]
	Learning Rate: 0.00248974
	LOSS [training: 0.3341154509402441 | validation: 0.2759475770559814]
	TIME [epoch: 7.71 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2471529975738597		[learning rate: 0.0024839]
	Learning Rate: 0.00248387
	LOSS [training: 0.2471529975738597 | validation: 0.22887967593934117]
	TIME [epoch: 7.71 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_640.pth
	Model improved!!!
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45981188980018245		[learning rate: 0.002478]
	Learning Rate: 0.00247801
	LOSS [training: 0.45981188980018245 | validation: 0.4717850980426519]
	TIME [epoch: 7.83 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3873761331786183		[learning rate: 0.0024722]
	Learning Rate: 0.00247216
	LOSS [training: 0.3873761331786183 | validation: 0.3924819430667338]
	TIME [epoch: 7.76 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34632282997232		[learning rate: 0.0024663]
	Learning Rate: 0.00246633
	LOSS [training: 0.34632282997232 | validation: 0.43073580337891926]
	TIME [epoch: 7.76 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32210413197822363		[learning rate: 0.0024605]
	Learning Rate: 0.00246051
	LOSS [training: 0.32210413197822363 | validation: 0.27977576413832816]
	TIME [epoch: 7.77 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3012009181040135		[learning rate: 0.0024547]
	Learning Rate: 0.00245471
	LOSS [training: 0.3012009181040135 | validation: 0.3135582034546971]
	TIME [epoch: 7.78 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33079126707989454		[learning rate: 0.0024489]
	Learning Rate: 0.00244892
	LOSS [training: 0.33079126707989454 | validation: 0.4688258234051951]
	TIME [epoch: 7.81 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35846075914127573		[learning rate: 0.0024431]
	Learning Rate: 0.00244314
	LOSS [training: 0.35846075914127573 | validation: 0.3417907924221668]
	TIME [epoch: 7.76 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31365413133432907		[learning rate: 0.0024374]
	Learning Rate: 0.00243738
	LOSS [training: 0.31365413133432907 | validation: 0.3085928475566836]
	TIME [epoch: 7.74 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2949897116471031		[learning rate: 0.0024316]
	Learning Rate: 0.00243163
	LOSS [training: 0.2949897116471031 | validation: 0.5673993512762561]
	TIME [epoch: 7.76 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3601756046024964		[learning rate: 0.0024259]
	Learning Rate: 0.00242589
	LOSS [training: 0.3601756046024964 | validation: 0.3308480537329479]
	TIME [epoch: 7.8 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3149663833960522		[learning rate: 0.0024202]
	Learning Rate: 0.00242017
	LOSS [training: 0.3149663833960522 | validation: 0.29349265943284936]
	TIME [epoch: 7.8 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2736150729984683		[learning rate: 0.0024145]
	Learning Rate: 0.00241446
	LOSS [training: 0.2736150729984683 | validation: 0.4065146012448622]
	TIME [epoch: 7.76 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3606542729442669		[learning rate: 0.0024088]
	Learning Rate: 0.00240877
	LOSS [training: 0.3606542729442669 | validation: 0.3578634788371639]
	TIME [epoch: 7.76 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4012914345841339		[learning rate: 0.0024031]
	Learning Rate: 0.00240309
	LOSS [training: 0.4012914345841339 | validation: 0.3225024637166565]
	TIME [epoch: 7.76 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29713670833701394		[learning rate: 0.0023974]
	Learning Rate: 0.00239742
	LOSS [training: 0.29713670833701394 | validation: 0.32127201325852633]
	TIME [epoch: 7.77 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3193248395341604		[learning rate: 0.0023918]
	Learning Rate: 0.00239176
	LOSS [training: 0.3193248395341604 | validation: 1.0633326830798873]
	TIME [epoch: 7.76 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4875011662260806		[learning rate: 0.0023861]
	Learning Rate: 0.00238612
	LOSS [training: 0.4875011662260806 | validation: 0.9821288852651741]
	TIME [epoch: 7.74 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6879207086113122		[learning rate: 0.0023805]
	Learning Rate: 0.00238049
	LOSS [training: 0.6879207086113122 | validation: 0.7751907143949018]
	TIME [epoch: 7.77 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.554285211941872		[learning rate: 0.0023749]
	Learning Rate: 0.00237488
	LOSS [training: 0.554285211941872 | validation: 0.606303392874388]
	TIME [epoch: 7.77 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5346470251284241		[learning rate: 0.0023693]
	Learning Rate: 0.00236927
	LOSS [training: 0.5346470251284241 | validation: 0.5726707829606432]
	TIME [epoch: 7.8 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5451099550654286		[learning rate: 0.0023637]
	Learning Rate: 0.00236369
	LOSS [training: 0.5451099550654286 | validation: 0.590476327353744]
	TIME [epoch: 7.77 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5443411087315578		[learning rate: 0.0023581]
	Learning Rate: 0.00235811
	LOSS [training: 0.5443411087315578 | validation: 0.6462127612532568]
	TIME [epoch: 7.74 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49860290051989065		[learning rate: 0.0023525]
	Learning Rate: 0.00235255
	LOSS [training: 0.49860290051989065 | validation: 0.43409711061810635]
	TIME [epoch: 7.77 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4514107168397765		[learning rate: 0.002347]
	Learning Rate: 0.002347
	LOSS [training: 0.4514107168397765 | validation: 0.3687927246968349]
	TIME [epoch: 7.74 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3397671424521607		[learning rate: 0.0023415]
	Learning Rate: 0.00234146
	LOSS [training: 0.3397671424521607 | validation: 0.3114951380582922]
	TIME [epoch: 7.81 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.338580042602306		[learning rate: 0.0023359]
	Learning Rate: 0.00233594
	LOSS [training: 0.338580042602306 | validation: 0.2973008141582195]
	TIME [epoch: 7.76 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3064681806704166		[learning rate: 0.0023304]
	Learning Rate: 0.00233043
	LOSS [training: 0.3064681806704166 | validation: 0.25461140051770037]
	TIME [epoch: 7.74 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2770788201543999		[learning rate: 0.0023249]
	Learning Rate: 0.00232493
	LOSS [training: 0.2770788201543999 | validation: 0.46356009217995153]
	TIME [epoch: 7.77 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3189097520216559		[learning rate: 0.0023194]
	Learning Rate: 0.00231945
	LOSS [training: 0.3189097520216559 | validation: 0.4234750432696105]
	TIME [epoch: 7.75 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3017980959651891		[learning rate: 0.002314]
	Learning Rate: 0.00231398
	LOSS [training: 0.3017980959651891 | validation: 0.3043831841058529]
	TIME [epoch: 7.81 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25469473972104767		[learning rate: 0.0023085]
	Learning Rate: 0.00230852
	LOSS [training: 0.25469473972104767 | validation: 0.2994577852751529]
	TIME [epoch: 7.75 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2693302093240799		[learning rate: 0.0023031]
	Learning Rate: 0.00230307
	LOSS [training: 0.2693302093240799 | validation: 0.2511059679019896]
	TIME [epoch: 7.78 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2859735339264702		[learning rate: 0.0022976]
	Learning Rate: 0.00229764
	LOSS [training: 0.2859735339264702 | validation: 0.3170317834875917]
	TIME [epoch: 7.75 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.265604012533168		[learning rate: 0.0022922]
	Learning Rate: 0.00229222
	LOSS [training: 0.265604012533168 | validation: 0.391139898491361]
	TIME [epoch: 7.78 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31810709131022935		[learning rate: 0.0022868]
	Learning Rate: 0.00228681
	LOSS [training: 0.31810709131022935 | validation: 0.5287020311015977]
	TIME [epoch: 7.8 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36467273967726577		[learning rate: 0.0022814]
	Learning Rate: 0.00228142
	LOSS [training: 0.36467273967726577 | validation: 0.2781807834064933]
	TIME [epoch: 7.76 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26057258432823593		[learning rate: 0.002276]
	Learning Rate: 0.00227604
	LOSS [training: 0.26057258432823593 | validation: 0.34005034268158063]
	TIME [epoch: 7.77 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2674091557208816		[learning rate: 0.0022707]
	Learning Rate: 0.00227067
	LOSS [training: 0.2674091557208816 | validation: 0.20058368900337575]
	TIME [epoch: 7.76 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_678.pth
	Model improved!!!
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2516233759166817		[learning rate: 0.0022653]
	Learning Rate: 0.00226531
	LOSS [training: 0.2516233759166817 | validation: 0.33179185802142974]
	TIME [epoch: 7.78 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2328718690625886		[learning rate: 0.00226]
	Learning Rate: 0.00225997
	LOSS [training: 0.2328718690625886 | validation: 0.2124952816085191]
	TIME [epoch: 7.76 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3103858919994863		[learning rate: 0.0022546]
	Learning Rate: 0.00225464
	LOSS [training: 0.3103858919994863 | validation: 0.345251013274755]
	TIME [epoch: 7.75 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3563595422234652		[learning rate: 0.0022493]
	Learning Rate: 0.00224932
	LOSS [training: 0.3563595422234652 | validation: 0.6586458427326154]
	TIME [epoch: 7.74 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42231742194508515		[learning rate: 0.002244]
	Learning Rate: 0.00224401
	LOSS [training: 0.42231742194508515 | validation: 0.33779515006164446]
	TIME [epoch: 7.76 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26160943642145806		[learning rate: 0.0022387]
	Learning Rate: 0.00223872
	LOSS [training: 0.26160943642145806 | validation: 0.27352175369429876]
	TIME [epoch: 7.78 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2688288493165806		[learning rate: 0.0022334]
	Learning Rate: 0.00223344
	LOSS [training: 0.2688288493165806 | validation: 0.2898025134290527]
	TIME [epoch: 7.77 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33325574013714515		[learning rate: 0.0022282]
	Learning Rate: 0.00222817
	LOSS [training: 0.33325574013714515 | validation: 0.3780779784997529]
	TIME [epoch: 7.74 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2849574732136833		[learning rate: 0.0022229]
	Learning Rate: 0.00222292
	LOSS [training: 0.2849574732136833 | validation: 0.24856158456753535]
	TIME [epoch: 7.74 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21744445522568773		[learning rate: 0.0022177]
	Learning Rate: 0.00221767
	LOSS [training: 0.21744445522568773 | validation: 0.3079079179783081]
	TIME [epoch: 7.74 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2834021600517529		[learning rate: 0.0022124]
	Learning Rate: 0.00221244
	LOSS [training: 0.2834021600517529 | validation: 0.3934344839867199]
	TIME [epoch: 7.81 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30212444151166307		[learning rate: 0.0022072]
	Learning Rate: 0.00220722
	LOSS [training: 0.30212444151166307 | validation: 0.27310548999822415]
	TIME [epoch: 7.76 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25846291513178415		[learning rate: 0.002202]
	Learning Rate: 0.00220202
	LOSS [training: 0.25846291513178415 | validation: 0.3102408664041651]
	TIME [epoch: 7.71 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26296241694589867		[learning rate: 0.0021968]
	Learning Rate: 0.00219682
	LOSS [training: 0.26296241694589867 | validation: 0.27264717571537395]
	TIME [epoch: 7.73 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25105079840795036		[learning rate: 0.0021916]
	Learning Rate: 0.00219164
	LOSS [training: 0.25105079840795036 | validation: 0.2401613799232381]
	TIME [epoch: 7.75 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2455501274044294		[learning rate: 0.0021865]
	Learning Rate: 0.00218647
	LOSS [training: 0.2455501274044294 | validation: 0.23429538649769008]
	TIME [epoch: 7.8 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28392663379915095		[learning rate: 0.0021813]
	Learning Rate: 0.00218131
	LOSS [training: 0.28392663379915095 | validation: 0.3933726893848568]
	TIME [epoch: 7.73 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3213686726549337		[learning rate: 0.0021762]
	Learning Rate: 0.00217617
	LOSS [training: 0.3213686726549337 | validation: 0.39590964646202564]
	TIME [epoch: 7.73 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27590897088726934		[learning rate: 0.002171]
	Learning Rate: 0.00217103
	LOSS [training: 0.27590897088726934 | validation: 0.2749804645262328]
	TIME [epoch: 7.72 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21517355234827187		[learning rate: 0.0021659]
	Learning Rate: 0.00216591
	LOSS [training: 0.21517355234827187 | validation: 0.2433547303788215]
	TIME [epoch: 7.76 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2828226178826922		[learning rate: 0.0021608]
	Learning Rate: 0.0021608
	LOSS [training: 0.2828226178826922 | validation: 0.4656125434829744]
	TIME [epoch: 7.78 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3888610935869916		[learning rate: 0.0021557]
	Learning Rate: 0.00215571
	LOSS [training: 0.3888610935869916 | validation: 0.3695202699650003]
	TIME [epoch: 7.73 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29364400464462787		[learning rate: 0.0021506]
	Learning Rate: 0.00215062
	LOSS [training: 0.29364400464462787 | validation: 0.29296017467871427]
	TIME [epoch: 7.67 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2681663792427155		[learning rate: 0.0021455]
	Learning Rate: 0.00214555
	LOSS [training: 0.2681663792427155 | validation: 0.3690609224536181]
	TIME [epoch: 7.68 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.300491718076045		[learning rate: 0.0021405]
	Learning Rate: 0.00214049
	LOSS [training: 0.300491718076045 | validation: 0.26338094553873953]
	TIME [epoch: 7.75 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26379677343899693		[learning rate: 0.0021354]
	Learning Rate: 0.00213544
	LOSS [training: 0.26379677343899693 | validation: 0.3145978126560982]
	TIME [epoch: 7.67 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31538421111604753		[learning rate: 0.0021304]
	Learning Rate: 0.0021304
	LOSS [training: 0.31538421111604753 | validation: 0.42353016236163776]
	TIME [epoch: 7.66 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3477125697214985		[learning rate: 0.0021254]
	Learning Rate: 0.00212538
	LOSS [training: 0.3477125697214985 | validation: 0.32121831593779054]
	TIME [epoch: 7.67 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30683637844721623		[learning rate: 0.0021204]
	Learning Rate: 0.00212036
	LOSS [training: 0.30683637844721623 | validation: 0.32291196227023844]
	TIME [epoch: 7.71 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49727103455131205		[learning rate: 0.0021154]
	Learning Rate: 0.00211536
	LOSS [training: 0.49727103455131205 | validation: 0.4667263327546297]
	TIME [epoch: 7.72 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3607416749204294		[learning rate: 0.0021104]
	Learning Rate: 0.00211037
	LOSS [training: 0.3607416749204294 | validation: 0.3396785266065803]
	TIME [epoch: 7.67 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42977016890291114		[learning rate: 0.0021054]
	Learning Rate: 0.00210539
	LOSS [training: 0.42977016890291114 | validation: 0.31412591657996386]
	TIME [epoch: 7.67 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30861040676592455		[learning rate: 0.0021004]
	Learning Rate: 0.00210043
	LOSS [training: 0.30861040676592455 | validation: 0.3558250681021493]
	TIME [epoch: 7.67 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30531444013591447		[learning rate: 0.0020955]
	Learning Rate: 0.00209547
	LOSS [training: 0.30531444013591447 | validation: 0.41556919044436186]
	TIME [epoch: 7.7 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3832644844869272		[learning rate: 0.0020905]
	Learning Rate: 0.00209053
	LOSS [training: 0.3832644844869272 | validation: 0.31001068541083565]
	TIME [epoch: 7.72 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3072361777570424		[learning rate: 0.0020856]
	Learning Rate: 0.0020856
	LOSS [training: 0.3072361777570424 | validation: 0.2901533071509417]
	TIME [epoch: 7.67 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3026316740649018		[learning rate: 0.0020807]
	Learning Rate: 0.00208068
	LOSS [training: 0.3026316740649018 | validation: 0.3203445438583173]
	TIME [epoch: 7.66 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2771673924724147		[learning rate: 0.0020758]
	Learning Rate: 0.00207577
	LOSS [training: 0.2771673924724147 | validation: 0.3690007103387499]
	TIME [epoch: 7.7 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4017157236790627		[learning rate: 0.0020709]
	Learning Rate: 0.00207087
	LOSS [training: 0.4017157236790627 | validation: 0.4062191385888267]
	TIME [epoch: 7.66 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33016488173039193		[learning rate: 0.002066]
	Learning Rate: 0.00206599
	LOSS [training: 0.33016488173039193 | validation: 0.41566112336230654]
	TIME [epoch: 7.74 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3179405521390887		[learning rate: 0.0020611]
	Learning Rate: 0.00206112
	LOSS [training: 0.3179405521390887 | validation: 0.3300666477250774]
	TIME [epoch: 7.66 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2919121989267676		[learning rate: 0.0020563]
	Learning Rate: 0.00205626
	LOSS [training: 0.2919121989267676 | validation: 0.42201499951626276]
	TIME [epoch: 7.68 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32266664418137847		[learning rate: 0.0020514]
	Learning Rate: 0.0020514
	LOSS [training: 0.32266664418137847 | validation: 0.39227777610952297]
	TIME [epoch: 7.68 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2546191805526055		[learning rate: 0.0020466]
	Learning Rate: 0.00204657
	LOSS [training: 0.2546191805526055 | validation: 0.3144816276882778]
	TIME [epoch: 7.66 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2388471594682083		[learning rate: 0.0020417]
	Learning Rate: 0.00204174
	LOSS [training: 0.2388471594682083 | validation: 0.2408185931349039]
	TIME [epoch: 7.71 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22681055118407073		[learning rate: 0.0020369]
	Learning Rate: 0.00203692
	LOSS [training: 0.22681055118407073 | validation: 0.44732212227111245]
	TIME [epoch: 7.67 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4086204887602458		[learning rate: 0.0020321]
	Learning Rate: 0.00203212
	LOSS [training: 0.4086204887602458 | validation: 0.35543339600018153]
	TIME [epoch: 7.7 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2712495486707524		[learning rate: 0.0020273]
	Learning Rate: 0.00202732
	LOSS [training: 0.2712495486707524 | validation: 0.27563045690972005]
	TIME [epoch: 7.67 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30407968432851495		[learning rate: 0.0020225]
	Learning Rate: 0.00202254
	LOSS [training: 0.30407968432851495 | validation: 0.3612805428024368]
	TIME [epoch: 7.68 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2878736163991676		[learning rate: 0.0020178]
	Learning Rate: 0.00201777
	LOSS [training: 0.2878736163991676 | validation: 0.4351097843741409]
	TIME [epoch: 7.72 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2749707834843057		[learning rate: 0.002013]
	Learning Rate: 0.00201301
	LOSS [training: 0.2749707834843057 | validation: 0.3636344209455229]
	TIME [epoch: 7.67 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3024589809653622		[learning rate: 0.0020083]
	Learning Rate: 0.00200826
	LOSS [training: 0.3024589809653622 | validation: 0.31496162268855044]
	TIME [epoch: 7.68 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29756350004921206		[learning rate: 0.0020035]
	Learning Rate: 0.00200353
	LOSS [training: 0.29756350004921206 | validation: 0.29815855975110916]
	TIME [epoch: 7.67 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2874883178101675		[learning rate: 0.0019988]
	Learning Rate: 0.0019988
	LOSS [training: 0.2874883178101675 | validation: 0.7668783974988296]
	TIME [epoch: 7.68 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3292844580444872		[learning rate: 0.0019941]
	Learning Rate: 0.00199408
	LOSS [training: 0.3292844580444872 | validation: 0.31237606445585697]
	TIME [epoch: 7.71 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2392572306208847		[learning rate: 0.0019894]
	Learning Rate: 0.00198938
	LOSS [training: 0.2392572306208847 | validation: 0.2842686354973314]
	TIME [epoch: 7.69 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25388288527194275		[learning rate: 0.0019847]
	Learning Rate: 0.00198469
	LOSS [training: 0.25388288527194275 | validation: 0.24506892712970763]
	TIME [epoch: 7.67 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24081809017120692		[learning rate: 0.00198]
	Learning Rate: 0.00198001
	LOSS [training: 0.24081809017120692 | validation: 0.24295545548215264]
	TIME [epoch: 7.67 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30943175958458		[learning rate: 0.0019753]
	Learning Rate: 0.00197534
	LOSS [training: 0.30943175958458 | validation: 0.29957978207005953]
	TIME [epoch: 7.71 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2499066375718443		[learning rate: 0.0019707]
	Learning Rate: 0.00197068
	LOSS [training: 0.2499066375718443 | validation: 0.40345132442481835]
	TIME [epoch: 7.69 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24632691569000906		[learning rate: 0.001966]
	Learning Rate: 0.00196603
	LOSS [training: 0.24632691569000906 | validation: 0.2509752596549196]
	TIME [epoch: 7.69 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22574583809861518		[learning rate: 0.0019614]
	Learning Rate: 0.00196139
	LOSS [training: 0.22574583809861518 | validation: 0.3134911633577006]
	TIME [epoch: 7.68 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3155444672895204		[learning rate: 0.0019568]
	Learning Rate: 0.00195676
	LOSS [training: 0.3155444672895204 | validation: 0.5510677455557171]
	TIME [epoch: 7.67 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3085200484014184		[learning rate: 0.0019521]
	Learning Rate: 0.00195215
	LOSS [training: 0.3085200484014184 | validation: 0.2986463979308073]
	TIME [epoch: 7.73 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2167746344936795		[learning rate: 0.0019475]
	Learning Rate: 0.00194754
	LOSS [training: 0.2167746344936795 | validation: 0.2513826489460126]
	TIME [epoch: 7.71 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2176135737831401		[learning rate: 0.0019429]
	Learning Rate: 0.00194295
	LOSS [training: 0.2176135737831401 | validation: 0.24948871705076947]
	TIME [epoch: 7.69 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23504548105609452		[learning rate: 0.0019384]
	Learning Rate: 0.00193837
	LOSS [training: 0.23504548105609452 | validation: 0.42997754818410494]
	TIME [epoch: 7.69 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28595620266211513		[learning rate: 0.0019338]
	Learning Rate: 0.00193379
	LOSS [training: 0.28595620266211513 | validation: 0.4085415837472426]
	TIME [epoch: 7.68 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27833103705934104		[learning rate: 0.0019292]
	Learning Rate: 0.00192923
	LOSS [training: 0.27833103705934104 | validation: 0.2631232275728995]
	TIME [epoch: 7.73 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20672109523226337		[learning rate: 0.0019247]
	Learning Rate: 0.00192468
	LOSS [training: 0.20672109523226337 | validation: 0.2934542771821963]
	TIME [epoch: 7.69 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2183044660682052		[learning rate: 0.0019201]
	Learning Rate: 0.00192014
	LOSS [training: 0.2183044660682052 | validation: 0.186424495806631]
	TIME [epoch: 7.67 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_749.pth
	Model improved!!!
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1772691094129601		[learning rate: 0.0019156]
	Learning Rate: 0.00191561
	LOSS [training: 0.1772691094129601 | validation: 0.18889541695850937]
	TIME [epoch: 7.65 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19782341486470473		[learning rate: 0.0019111]
	Learning Rate: 0.00191109
	LOSS [training: 0.19782341486470473 | validation: 0.3526404745663898]
	TIME [epoch: 7.67 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2637248788097347		[learning rate: 0.0019066]
	Learning Rate: 0.00190659
	LOSS [training: 0.2637248788097347 | validation: 0.22080471078379516]
	TIME [epoch: 7.74 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2106559305441586		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.2106559305441586 | validation: 0.2447995742609437]
	TIME [epoch: 7.67 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1954602758463299		[learning rate: 0.0018976]
	Learning Rate: 0.0018976
	LOSS [training: 0.1954602758463299 | validation: 0.2589311723926496]
	TIME [epoch: 7.66 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21788552588888144		[learning rate: 0.0018931]
	Learning Rate: 0.00189313
	LOSS [training: 0.21788552588888144 | validation: 0.26864110361411525]
	TIME [epoch: 7.66 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24322496998040188		[learning rate: 0.0018887]
	Learning Rate: 0.00188866
	LOSS [training: 0.24322496998040188 | validation: 0.39176812811068096]
	TIME [epoch: 7.67 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30172320392968277		[learning rate: 0.0018842]
	Learning Rate: 0.00188421
	LOSS [training: 0.30172320392968277 | validation: 0.4068511657724009]
	TIME [epoch: 7.71 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.269624237143569		[learning rate: 0.0018798]
	Learning Rate: 0.00187976
	LOSS [training: 0.269624237143569 | validation: 0.2700286684021654]
	TIME [epoch: 7.66 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20174386135491698		[learning rate: 0.0018753]
	Learning Rate: 0.00187533
	LOSS [training: 0.20174386135491698 | validation: 0.1926618505840715]
	TIME [epoch: 7.66 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22853767712890666		[learning rate: 0.0018709]
	Learning Rate: 0.0018709
	LOSS [training: 0.22853767712890666 | validation: 0.20115415841406822]
	TIME [epoch: 7.66 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2427031098391887		[learning rate: 0.0018665]
	Learning Rate: 0.00186649
	LOSS [training: 0.2427031098391887 | validation: 0.32882522370777967]
	TIME [epoch: 7.7 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2573348508873952		[learning rate: 0.0018621]
	Learning Rate: 0.00186209
	LOSS [training: 0.2573348508873952 | validation: 0.2841979378391969]
	TIME [epoch: 7.7 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2192267717357646		[learning rate: 0.0018577]
	Learning Rate: 0.00185769
	LOSS [training: 0.2192267717357646 | validation: 0.21590006095756395]
	TIME [epoch: 7.66 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1774148491369781		[learning rate: 0.0018533]
	Learning Rate: 0.00185331
	LOSS [training: 0.1774148491369781 | validation: 0.2558578674486761]
	TIME [epoch: 7.65 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1944755649099836		[learning rate: 0.0018489]
	Learning Rate: 0.00184894
	LOSS [training: 0.1944755649099836 | validation: 0.20290160996636342]
	TIME [epoch: 7.71 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1827555919896865		[learning rate: 0.0018446]
	Learning Rate: 0.00184458
	LOSS [training: 0.1827555919896865 | validation: 0.4415445687912719]
	TIME [epoch: 7.69 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3701538892224343		[learning rate: 0.0018402]
	Learning Rate: 0.00184023
	LOSS [training: 0.3701538892224343 | validation: 0.29174902456439866]
	TIME [epoch: 7.68 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4098707189971081		[learning rate: 0.0018359]
	Learning Rate: 0.00183589
	LOSS [training: 0.4098707189971081 | validation: 0.6674277792203718]
	TIME [epoch: 7.67 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38188753479219056		[learning rate: 0.0018316]
	Learning Rate: 0.00183156
	LOSS [training: 0.38188753479219056 | validation: 0.4310131012831486]
	TIME [epoch: 7.67 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3078460941067667		[learning rate: 0.0018272]
	Learning Rate: 0.00182724
	LOSS [training: 0.3078460941067667 | validation: 0.3184688432823166]
	TIME [epoch: 7.68 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22772147253930267		[learning rate: 0.0018229]
	Learning Rate: 0.00182293
	LOSS [training: 0.22772147253930267 | validation: 0.22269534648182632]
	TIME [epoch: 7.71 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2634730596436058		[learning rate: 0.0018186]
	Learning Rate: 0.00181863
	LOSS [training: 0.2634730596436058 | validation: 0.3240274367394818]
	TIME [epoch: 7.66 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2756281026606698		[learning rate: 0.0018143]
	Learning Rate: 0.00181434
	LOSS [training: 0.2756281026606698 | validation: 0.3988721843983922]
	TIME [epoch: 7.67 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23938878345296427		[learning rate: 0.0018101]
	Learning Rate: 0.00181006
	LOSS [training: 0.23938878345296427 | validation: 0.26939915205246634]
	TIME [epoch: 7.66 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19333010171147455		[learning rate: 0.0018058]
	Learning Rate: 0.00180579
	LOSS [training: 0.19333010171147455 | validation: 0.2503417263986769]
	TIME [epoch: 7.66 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22188309399345227		[learning rate: 0.0018015]
	Learning Rate: 0.00180153
	LOSS [training: 0.22188309399345227 | validation: 0.21131346045648497]
	TIME [epoch: 7.71 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2763896391598439		[learning rate: 0.0017973]
	Learning Rate: 0.00179728
	LOSS [training: 0.2763896391598439 | validation: 0.302598570989145]
	TIME [epoch: 7.67 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2347374775439655		[learning rate: 0.001793]
	Learning Rate: 0.00179304
	LOSS [training: 0.2347374775439655 | validation: 0.23400453402108093]
	TIME [epoch: 7.69 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20605298518901305		[learning rate: 0.0017888]
	Learning Rate: 0.00178881
	LOSS [training: 0.20605298518901305 | validation: 0.17048813372814348]
	TIME [epoch: 7.66 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_779.pth
	Model improved!!!
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26117384678099015		[learning rate: 0.0017846]
	Learning Rate: 0.00178459
	LOSS [training: 0.26117384678099015 | validation: 0.2686257240552683]
	TIME [epoch: 7.66 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22586511616138347		[learning rate: 0.0017804]
	Learning Rate: 0.00178038
	LOSS [training: 0.22586511616138347 | validation: 0.2963995676252172]
	TIME [epoch: 7.71 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3308091192724055		[learning rate: 0.0017762]
	Learning Rate: 0.00177618
	LOSS [training: 0.3308091192724055 | validation: 0.9446427334571246]
	TIME [epoch: 7.69 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6997059162872126		[learning rate: 0.001772]
	Learning Rate: 0.00177199
	LOSS [training: 0.6997059162872126 | validation: 0.545798999006546]
	TIME [epoch: 7.67 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3673888784262978		[learning rate: 0.0017678]
	Learning Rate: 0.00176781
	LOSS [training: 0.3673888784262978 | validation: 0.38142812265681036]
	TIME [epoch: 7.65 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2914439241092581		[learning rate: 0.0017636]
	Learning Rate: 0.00176364
	LOSS [training: 0.2914439241092581 | validation: 0.3798728103970922]
	TIME [epoch: 7.66 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2682926285115345		[learning rate: 0.0017595]
	Learning Rate: 0.00175948
	LOSS [training: 0.2682926285115345 | validation: 0.3944788833006925]
	TIME [epoch: 7.71 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24932038116123934		[learning rate: 0.0017553]
	Learning Rate: 0.00175533
	LOSS [training: 0.24932038116123934 | validation: 0.26525405726004264]
	TIME [epoch: 7.77 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2215279539522965		[learning rate: 0.0017512]
	Learning Rate: 0.00175119
	LOSS [training: 0.2215279539522965 | validation: 0.21890044422423885]
	TIME [epoch: 7.66 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22209558447869238		[learning rate: 0.0017471]
	Learning Rate: 0.00174706
	LOSS [training: 0.22209558447869238 | validation: 0.3084996446404453]
	TIME [epoch: 7.66 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25975975443900406		[learning rate: 0.0017429]
	Learning Rate: 0.00174294
	LOSS [training: 0.25975975443900406 | validation: 0.28748277103897435]
	TIME [epoch: 7.68 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27931002785242265		[learning rate: 0.0017388]
	Learning Rate: 0.00173883
	LOSS [training: 0.27931002785242265 | validation: 0.3183653450619779]
	TIME [epoch: 7.71 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21189158532781388		[learning rate: 0.0017347]
	Learning Rate: 0.00173473
	LOSS [training: 0.21189158532781388 | validation: 0.2273297890122239]
	TIME [epoch: 7.69 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21792652297832207		[learning rate: 0.0017306]
	Learning Rate: 0.00173063
	LOSS [training: 0.21792652297832207 | validation: 0.2547511822384769]
	TIME [epoch: 7.66 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24330453650053765		[learning rate: 0.0017266]
	Learning Rate: 0.00172655
	LOSS [training: 0.24330453650053765 | validation: 0.34910745203501337]
	TIME [epoch: 7.65 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26148588258468386		[learning rate: 0.0017225]
	Learning Rate: 0.00172248
	LOSS [training: 0.26148588258468386 | validation: 0.20101265620687897]
	TIME [epoch: 7.67 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19692418821251312		[learning rate: 0.0017184]
	Learning Rate: 0.00171842
	LOSS [training: 0.19692418821251312 | validation: 0.2204770495666286]
	TIME [epoch: 7.72 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23216618660463445		[learning rate: 0.0017144]
	Learning Rate: 0.00171436
	LOSS [training: 0.23216618660463445 | validation: 0.26214013905097144]
	TIME [epoch: 7.65 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23414584376274186		[learning rate: 0.0017103]
	Learning Rate: 0.00171032
	LOSS [training: 0.23414584376274186 | validation: 0.28414388613051245]
	TIME [epoch: 7.65 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2700452346395365		[learning rate: 0.0017063]
	Learning Rate: 0.00170628
	LOSS [training: 0.2700452346395365 | validation: 0.3647220925193737]
	TIME [epoch: 7.65 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28400248389895877		[learning rate: 0.0017023]
	Learning Rate: 0.00170226
	LOSS [training: 0.28400248389895877 | validation: 0.6324520593223213]
	TIME [epoch: 7.69 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4404763334353319		[learning rate: 0.0016982]
	Learning Rate: 0.00169824
	LOSS [training: 0.4404763334353319 | validation: 0.523852561605295]
	TIME [epoch: 7.74 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4190177424645448		[learning rate: 0.0016942]
	Learning Rate: 0.00169424
	LOSS [training: 0.4190177424645448 | validation: 0.41178546525269694]
	TIME [epoch: 7.71 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35851652811374657		[learning rate: 0.0016902]
	Learning Rate: 0.00169024
	LOSS [training: 0.35851652811374657 | validation: 0.286597750789659]
	TIME [epoch: 7.71 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2714982722746614		[learning rate: 0.0016863]
	Learning Rate: 0.00168625
	LOSS [training: 0.2714982722746614 | validation: 0.43126469567702813]
	TIME [epoch: 7.71 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29390869014184373		[learning rate: 0.0016823]
	Learning Rate: 0.00168228
	LOSS [training: 0.29390869014184373 | validation: 0.30920986582189336]
	TIME [epoch: 7.75 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21324152126039533		[learning rate: 0.0016783]
	Learning Rate: 0.00167831
	LOSS [training: 0.21324152126039533 | validation: 0.36057457157932904]
	TIME [epoch: 7.7 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2338352132789555		[learning rate: 0.0016743]
	Learning Rate: 0.00167435
	LOSS [training: 0.2338352132789555 | validation: 0.32497416597820916]
	TIME [epoch: 7.7 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2118426776162065		[learning rate: 0.0016704]
	Learning Rate: 0.0016704
	LOSS [training: 0.2118426776162065 | validation: 0.4161923716028982]
	TIME [epoch: 7.69 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27554529769194014		[learning rate: 0.0016665]
	Learning Rate: 0.00166646
	LOSS [training: 0.27554529769194014 | validation: 0.20291781857325125]
	TIME [epoch: 7.73 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18553144437569638		[learning rate: 0.0016625]
	Learning Rate: 0.00166253
	LOSS [training: 0.18553144437569638 | validation: 0.2347415632615464]
	TIME [epoch: 7.78 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21325453392697324		[learning rate: 0.0016586]
	Learning Rate: 0.00165861
	LOSS [training: 0.21325453392697324 | validation: 0.20618582561652665]
	TIME [epoch: 7.72 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18767717088361577		[learning rate: 0.0016547]
	Learning Rate: 0.0016547
	LOSS [training: 0.18767717088361577 | validation: 0.22451724318610267]
	TIME [epoch: 7.7 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20411020682238554		[learning rate: 0.0016508]
	Learning Rate: 0.00165079
	LOSS [training: 0.20411020682238554 | validation: 0.21604099243542]
	TIME [epoch: 7.71 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3171270108730234		[learning rate: 0.0016469]
	Learning Rate: 0.0016469
	LOSS [training: 0.3171270108730234 | validation: 0.3501263690237277]
	TIME [epoch: 7.74 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4298852113643994		[learning rate: 0.001643]
	Learning Rate: 0.00164301
	LOSS [training: 0.4298852113643994 | validation: 0.48919541407671907]
	TIME [epoch: 7.76 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4147720766063951		[learning rate: 0.0016391]
	Learning Rate: 0.00163914
	LOSS [training: 0.4147720766063951 | validation: 0.46118027163091846]
	TIME [epoch: 7.7 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3723380734652053		[learning rate: 0.0016353]
	Learning Rate: 0.00163527
	LOSS [training: 0.3723380734652053 | validation: 0.25884909068122014]
	TIME [epoch: 7.71 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30307343654971614		[learning rate: 0.0016314]
	Learning Rate: 0.00163141
	LOSS [training: 0.30307343654971614 | validation: 0.3346028669421197]
	TIME [epoch: 7.73 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2708459085076712		[learning rate: 0.0016276]
	Learning Rate: 0.00162757
	LOSS [training: 0.2708459085076712 | validation: 0.31819725191862225]
	TIME [epoch: 7.74 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26167479242343894		[learning rate: 0.0016237]
	Learning Rate: 0.00162373
	LOSS [training: 0.26167479242343894 | validation: 0.26043047887570026]
	TIME [epoch: 7.76 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.236403173764705		[learning rate: 0.0016199]
	Learning Rate: 0.0016199
	LOSS [training: 0.236403173764705 | validation: 0.24109800860124567]
	TIME [epoch: 7.72 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21353955925061519		[learning rate: 0.0016161]
	Learning Rate: 0.00161608
	LOSS [training: 0.21353955925061519 | validation: 0.21065391609652023]
	TIME [epoch: 7.71 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20885153126138398		[learning rate: 0.0016123]
	Learning Rate: 0.00161226
	LOSS [training: 0.20885153126138398 | validation: 0.2208512467171102]
	TIME [epoch: 7.73 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1972348354319042		[learning rate: 0.0016085]
	Learning Rate: 0.00160846
	LOSS [training: 0.1972348354319042 | validation: 0.2513597019737501]
	TIME [epoch: 7.72 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39178929390684664		[learning rate: 0.0016047]
	Learning Rate: 0.00160467
	LOSS [training: 0.39178929390684664 | validation: 0.2266320424416739]
	TIME [epoch: 7.74 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19863229996621065		[learning rate: 0.0016009]
	Learning Rate: 0.00160088
	LOSS [training: 0.19863229996621065 | validation: 0.2225178399489398]
	TIME [epoch: 7.72 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23568666755758727		[learning rate: 0.0015971]
	Learning Rate: 0.0015971
	LOSS [training: 0.23568666755758727 | validation: 0.3280905924586477]
	TIME [epoch: 7.73 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22539929247343732		[learning rate: 0.0015933]
	Learning Rate: 0.00159334
	LOSS [training: 0.22539929247343732 | validation: 0.17639547170737033]
	TIME [epoch: 7.73 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20937741227876003		[learning rate: 0.0015896]
	Learning Rate: 0.00158958
	LOSS [training: 0.20937741227876003 | validation: 0.22957045208561855]
	TIME [epoch: 7.73 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3846162551831252		[learning rate: 0.0015858]
	Learning Rate: 0.00158583
	LOSS [training: 0.3846162551831252 | validation: 0.41466320883386876]
	TIME [epoch: 7.71 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34433237282905893		[learning rate: 0.0015821]
	Learning Rate: 0.00158209
	LOSS [training: 0.34433237282905893 | validation: 0.5043500816916966]
	TIME [epoch: 7.7 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2978714405370011		[learning rate: 0.0015784]
	Learning Rate: 0.00157836
	LOSS [training: 0.2978714405370011 | validation: 0.2400306944222083]
	TIME [epoch: 7.69 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2372995040175416		[learning rate: 0.0015746]
	Learning Rate: 0.00157463
	LOSS [training: 0.2372995040175416 | validation: 0.2271830363817594]
	TIME [epoch: 7.69 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19928283659895377		[learning rate: 0.0015709]
	Learning Rate: 0.00157092
	LOSS [training: 0.19928283659895377 | validation: 0.22048043956993602]
	TIME [epoch: 7.75 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2773546079214524		[learning rate: 0.0015672]
	Learning Rate: 0.00156721
	LOSS [training: 0.2773546079214524 | validation: 0.2677969689230993]
	TIME [epoch: 7.66 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24928846114099612		[learning rate: 0.0015635]
	Learning Rate: 0.00156352
	LOSS [training: 0.24928846114099612 | validation: 0.39929222750536647]
	TIME [epoch: 7.7 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2858123730409535		[learning rate: 0.0015598]
	Learning Rate: 0.00155983
	LOSS [training: 0.2858123730409535 | validation: 0.2909960567043004]
	TIME [epoch: 7.63 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2657885654953998		[learning rate: 0.0015561]
	Learning Rate: 0.00155615
	LOSS [training: 0.2657885654953998 | validation: 0.2522512032421517]
	TIME [epoch: 7.63 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2179870940044886		[learning rate: 0.0015525]
	Learning Rate: 0.00155248
	LOSS [training: 0.2179870940044886 | validation: 0.23588976041040616]
	TIME [epoch: 7.69 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25806751667416805		[learning rate: 0.0015488]
	Learning Rate: 0.00154882
	LOSS [training: 0.25806751667416805 | validation: 0.2273899310281861]
	TIME [epoch: 7.68 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17868482661151253		[learning rate: 0.0015452]
	Learning Rate: 0.00154516
	LOSS [training: 0.17868482661151253 | validation: 0.30686595763284774]
	TIME [epoch: 7.67 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22481650992931046		[learning rate: 0.0015415]
	Learning Rate: 0.00154152
	LOSS [training: 0.22481650992931046 | validation: 0.20168444940265426]
	TIME [epoch: 7.67 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23222364903315926		[learning rate: 0.0015379]
	Learning Rate: 0.00153788
	LOSS [training: 0.23222364903315926 | validation: 0.3131813157949572]
	TIME [epoch: 7.67 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2754563135878967		[learning rate: 0.0015343]
	Learning Rate: 0.00153425
	LOSS [training: 0.2754563135878967 | validation: 0.3115401640075095]
	TIME [epoch: 7.72 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31987497882481486		[learning rate: 0.0015306]
	Learning Rate: 0.00153064
	LOSS [training: 0.31987497882481486 | validation: 0.32688482130964436]
	TIME [epoch: 7.67 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24687329318691784		[learning rate: 0.001527]
	Learning Rate: 0.00152703
	LOSS [training: 0.24687329318691784 | validation: 0.24962671475869957]
	TIME [epoch: 7.63 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2079820460748333		[learning rate: 0.0015234]
	Learning Rate: 0.00152342
	LOSS [training: 0.2079820460748333 | validation: 0.19155714844593774]
	TIME [epoch: 7.7 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18962194434329352		[learning rate: 0.0015198]
	Learning Rate: 0.00151983
	LOSS [training: 0.18962194434329352 | validation: 0.21419861141373134]
	TIME [epoch: 7.66 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19352247831646158		[learning rate: 0.0015162]
	Learning Rate: 0.00151624
	LOSS [training: 0.19352247831646158 | validation: 0.2635123725273461]
	TIME [epoch: 7.71 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19912339875843327		[learning rate: 0.0015127]
	Learning Rate: 0.00151267
	LOSS [training: 0.19912339875843327 | validation: 0.21399483015259127]
	TIME [epoch: 7.71 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20933195366127375		[learning rate: 0.0015091]
	Learning Rate: 0.0015091
	LOSS [training: 0.20933195366127375 | validation: 0.24496098953495332]
	TIME [epoch: 7.65 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29420067760064583		[learning rate: 0.0015055]
	Learning Rate: 0.00150554
	LOSS [training: 0.29420067760064583 | validation: 0.36816156322442883]
	TIME [epoch: 7.63 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23907355147454334		[learning rate: 0.001502]
	Learning Rate: 0.00150199
	LOSS [training: 0.23907355147454334 | validation: 0.26700053140279734]
	TIME [epoch: 7.65 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19447437105833043		[learning rate: 0.0014984]
	Learning Rate: 0.00149845
	LOSS [training: 0.19447437105833043 | validation: 0.29691658883653965]
	TIME [epoch: 7.74 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2167863398690775		[learning rate: 0.0014949]
	Learning Rate: 0.00149491
	LOSS [training: 0.2167863398690775 | validation: 0.27124934045869453]
	TIME [epoch: 7.67 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.309794922962425		[learning rate: 0.0014914]
	Learning Rate: 0.00149139
	LOSS [training: 0.309794922962425 | validation: 0.31752292258589776]
	TIME [epoch: 7.67 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2915574037644377		[learning rate: 0.0014879]
	Learning Rate: 0.00148787
	LOSS [training: 0.2915574037644377 | validation: 0.20150648258599585]
	TIME [epoch: 7.68 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23835747905442878		[learning rate: 0.0014844]
	Learning Rate: 0.00148436
	LOSS [training: 0.23835747905442878 | validation: 0.2491790194974257]
	TIME [epoch: 7.68 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1989308277048534		[learning rate: 0.0014809]
	Learning Rate: 0.00148086
	LOSS [training: 0.1989308277048534 | validation: 0.23653501924936282]
	TIME [epoch: 7.74 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19596693402060572		[learning rate: 0.0014774]
	Learning Rate: 0.00147736
	LOSS [training: 0.19596693402060572 | validation: 0.2650882497217083]
	TIME [epoch: 7.67 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20209414055218133		[learning rate: 0.0014739]
	Learning Rate: 0.00147388
	LOSS [training: 0.20209414055218133 | validation: 0.23776872970072252]
	TIME [epoch: 7.65 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2177323171644483		[learning rate: 0.0014704]
	Learning Rate: 0.0014704
	LOSS [training: 0.2177323171644483 | validation: 0.2781866089672957]
	TIME [epoch: 7.67 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19988075662413174		[learning rate: 0.0014669]
	Learning Rate: 0.00146693
	LOSS [training: 0.19988075662413174 | validation: 0.21145556876382193]
	TIME [epoch: 7.73 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17788822287866018		[learning rate: 0.0014635]
	Learning Rate: 0.00146347
	LOSS [training: 0.17788822287866018 | validation: 0.19942182412656861]
	TIME [epoch: 7.67 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1772821890172693		[learning rate: 0.00146]
	Learning Rate: 0.00146002
	LOSS [training: 0.1772821890172693 | validation: 0.18725374573520953]
	TIME [epoch: 7.65 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18986915683966837		[learning rate: 0.0014566]
	Learning Rate: 0.00145658
	LOSS [training: 0.18986915683966837 | validation: 0.21534615059027712]
	TIME [epoch: 7.69 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19873785602031285		[learning rate: 0.0014531]
	Learning Rate: 0.00145314
	LOSS [training: 0.19873785602031285 | validation: 0.1843269511313936]
	TIME [epoch: 7.66 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1862244676444895		[learning rate: 0.0014497]
	Learning Rate: 0.00144971
	LOSS [training: 0.1862244676444895 | validation: 0.19353631471094923]
	TIME [epoch: 7.74 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19281374978926705		[learning rate: 0.0014463]
	Learning Rate: 0.00144629
	LOSS [training: 0.19281374978926705 | validation: 0.2556086564575373]
	TIME [epoch: 7.67 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4268078432867075		[learning rate: 0.0014429]
	Learning Rate: 0.00144288
	LOSS [training: 0.4268078432867075 | validation: 0.36746514475996805]
	TIME [epoch: 7.69 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3070990915060382		[learning rate: 0.0014395]
	Learning Rate: 0.00143948
	LOSS [training: 0.3070990915060382 | validation: 0.24455087255774355]
	TIME [epoch: 7.67 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20765177574637905		[learning rate: 0.0014361]
	Learning Rate: 0.00143608
	LOSS [training: 0.20765177574637905 | validation: 0.20164397413699492]
	TIME [epoch: 7.72 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18377689856774365		[learning rate: 0.0014327]
	Learning Rate: 0.0014327
	LOSS [training: 0.18377689856774365 | validation: 0.20394704984509565]
	TIME [epoch: 7.75 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1588884153298656		[learning rate: 0.0014293]
	Learning Rate: 0.00142932
	LOSS [training: 0.1588884153298656 | validation: 0.22100941592355164]
	TIME [epoch: 7.67 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18501881270998152		[learning rate: 0.0014259]
	Learning Rate: 0.00142594
	LOSS [training: 0.18501881270998152 | validation: 0.2161687291008334]
	TIME [epoch: 7.69 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3979222556727195		[learning rate: 0.0014226]
	Learning Rate: 0.00142258
	LOSS [training: 0.3979222556727195 | validation: 0.4848269096943868]
	TIME [epoch: 7.74 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3826344409423732		[learning rate: 0.0014192]
	Learning Rate: 0.00141923
	LOSS [training: 0.3826344409423732 | validation: 0.25224703872116605]
	TIME [epoch: 7.69 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2466472925395608		[learning rate: 0.0014159]
	Learning Rate: 0.00141588
	LOSS [training: 0.2466472925395608 | validation: 0.2477177011426483]
	TIME [epoch: 7.74 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20623494771773834		[learning rate: 0.0014125]
	Learning Rate: 0.00141254
	LOSS [training: 0.20623494771773834 | validation: 0.24143683951842848]
	TIME [epoch: 7.69 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22613131200656275		[learning rate: 0.0014092]
	Learning Rate: 0.00140921
	LOSS [training: 0.22613131200656275 | validation: 0.2334058234092224]
	TIME [epoch: 7.68 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl2_20240702_111150/states/model_phi1_1a_v_kl2_880.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 7100.224 seconds.
