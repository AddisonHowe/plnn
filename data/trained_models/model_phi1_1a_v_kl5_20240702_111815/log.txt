Args:
Namespace(name='model_phi1_1a_v_kl5', outdir='out/model_training/model_phi1_1a_v_kl5', training_data='data/training_data/data_phi1_1a/training', validation_data='data/training_data/data_phi1_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.1, weight_decay=0.9, clip=1.0, lr_schedule='warmup_cosine_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3927034863

Training model...

Saving initial model state to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.932791393093847		[learning rate: 0.01015]
	Learning Rate: 0.01015
	LOSS [training: 11.932791393093847 | validation: 11.010766706280481]
	TIME [epoch: 97.9 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.329303354670257		[learning rate: 0.01035]
	Learning Rate: 0.01035
	LOSS [training: 11.329303354670257 | validation: 10.76772487304061]
	TIME [epoch: 8.37 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.904121139338839		[learning rate: 0.01055]
	Learning Rate: 0.01055
	LOSS [training: 10.904121139338839 | validation: 10.741789380202784]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.930718166726983		[learning rate: 0.01075]
	Learning Rate: 0.01075
	LOSS [training: 10.930718166726983 | validation: 10.445574955728123]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.455786377218741		[learning rate: 0.01095]
	Learning Rate: 0.01095
	LOSS [training: 10.455786377218741 | validation: 10.792797198893243]
	TIME [epoch: 8.34 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.858547456136778		[learning rate: 0.01115]
	Learning Rate: 0.01115
	LOSS [training: 10.858547456136778 | validation: 9.350149461870028]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.28942779081337		[learning rate: 0.01135]
	Learning Rate: 0.01135
	LOSS [training: 10.28942779081337 | validation: 9.094038377890628]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.000026608634323		[learning rate: 0.01155]
	Learning Rate: 0.01155
	LOSS [training: 10.000026608634323 | validation: 9.80120728612308]
	TIME [epoch: 8.31 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.898317303196334		[learning rate: 0.01175]
	Learning Rate: 0.01175
	LOSS [training: 9.898317303196334 | validation: 8.5238845077786]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.450442544550647		[learning rate: 0.01195]
	Learning Rate: 0.01195
	LOSS [training: 9.450442544550647 | validation: 9.449139244798701]
	TIME [epoch: 8.31 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.668709866150003		[learning rate: 0.01215]
	Learning Rate: 0.01215
	LOSS [training: 9.668709866150003 | validation: 7.929521088155021]
	TIME [epoch: 8.35 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.154888312749609		[learning rate: 0.01235]
	Learning Rate: 0.01235
	LOSS [training: 9.154888312749609 | validation: 8.175351774451013]
	TIME [epoch: 8.31 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.041775222270307		[learning rate: 0.01255]
	Learning Rate: 0.01255
	LOSS [training: 9.041775222270307 | validation: 8.588580056313187]
	TIME [epoch: 8.31 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.02579624668518		[learning rate: 0.01275]
	Learning Rate: 0.01275
	LOSS [training: 9.02579624668518 | validation: 8.635942374672757]
	TIME [epoch: 8.31 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.031025579027132		[learning rate: 0.01295]
	Learning Rate: 0.01295
	LOSS [training: 9.031025579027132 | validation: 7.705724003946523]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.752365719909355		[learning rate: 0.01315]
	Learning Rate: 0.01315
	LOSS [training: 8.752365719909355 | validation: 7.638410874033749]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.344829181417358		[learning rate: 0.01335]
	Learning Rate: 0.01335
	LOSS [training: 8.344829181417358 | validation: 9.083840070086389]
	TIME [epoch: 8.32 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.450575762557609		[learning rate: 0.01355]
	Learning Rate: 0.01355
	LOSS [training: 8.450575762557609 | validation: 8.87347988639166]
	TIME [epoch: 8.29 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.380419173914769		[learning rate: 0.01375]
	Learning Rate: 0.01375
	LOSS [training: 8.380419173914769 | validation: 8.607109224519395]
	TIME [epoch: 8.29 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.077009847304675		[learning rate: 0.01395]
	Learning Rate: 0.01395
	LOSS [training: 8.077009847304675 | validation: 8.317603225312293]
	TIME [epoch: 8.3 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.774784647444115		[learning rate: 0.01415]
	Learning Rate: 0.01415
	LOSS [training: 7.774784647444115 | validation: 7.757162482765926]
	TIME [epoch: 8.3 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.85155606424039		[learning rate: 0.01435]
	Learning Rate: 0.01435
	LOSS [training: 7.85155606424039 | validation: 8.091144955333363]
	TIME [epoch: 8.34 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.499887993621655		[learning rate: 0.01455]
	Learning Rate: 0.01455
	LOSS [training: 7.499887993621655 | validation: 7.596166023883429]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.69071205343		[learning rate: 0.01475]
	Learning Rate: 0.01475
	LOSS [training: 7.69071205343 | validation: 7.421805273518263]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.276918815066831		[learning rate: 0.01495]
	Learning Rate: 0.01495
	LOSS [training: 7.276918815066831 | validation: 7.3420093743008366]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.392112100351387		[learning rate: 0.01515]
	Learning Rate: 0.01515
	LOSS [training: 7.392112100351387 | validation: 7.362937917736446]
	TIME [epoch: 8.29 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.217009512139709		[learning rate: 0.01535]
	Learning Rate: 0.01535
	LOSS [training: 7.217009512139709 | validation: 7.304220985225298]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.895000333507647		[learning rate: 0.01555]
	Learning Rate: 0.01555
	LOSS [training: 6.895000333507647 | validation: 6.925601920115198]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.791080877430093		[learning rate: 0.01575]
	Learning Rate: 0.01575
	LOSS [training: 6.791080877430093 | validation: 7.610874095237833]
	TIME [epoch: 8.3 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.328485874429001		[learning rate: 0.01595]
	Learning Rate: 0.01595
	LOSS [training: 7.328485874429001 | validation: 6.913984545827826]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.897333964558653		[learning rate: 0.01615]
	Learning Rate: 0.01615
	LOSS [training: 6.897333964558653 | validation: 7.2841727349503405]
	TIME [epoch: 8.29 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.898744732684623		[learning rate: 0.01635]
	Learning Rate: 0.01635
	LOSS [training: 6.898744732684623 | validation: 6.868851556364579]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.988586268429516		[learning rate: 0.01655]
	Learning Rate: 0.01655
	LOSS [training: 6.988586268429516 | validation: 6.914785452450101]
	TIME [epoch: 8.32 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.5209948647233675		[learning rate: 0.01675]
	Learning Rate: 0.01675
	LOSS [training: 6.5209948647233675 | validation: 6.8276783825949305]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.6960439738045014		[learning rate: 0.01695]
	Learning Rate: 0.01695
	LOSS [training: 6.6960439738045014 | validation: 7.126862513263585]
	TIME [epoch: 8.31 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.632998801845991		[learning rate: 0.01715]
	Learning Rate: 0.01715
	LOSS [training: 6.632998801845991 | validation: 6.96443451355074]
	TIME [epoch: 8.29 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.087507440165644		[learning rate: 0.01735]
	Learning Rate: 0.01735
	LOSS [training: 6.087507440165644 | validation: 6.784326589372085]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9043427662781856		[learning rate: 0.01755]
	Learning Rate: 0.01755
	LOSS [training: 5.9043427662781856 | validation: 7.584618146259309]
	TIME [epoch: 8.34 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.5424010316660155		[learning rate: 0.01775]
	Learning Rate: 0.01775
	LOSS [training: 6.5424010316660155 | validation: 6.7639301914492425]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0070995625695		[learning rate: 0.01795]
	Learning Rate: 0.01795
	LOSS [training: 6.0070995625695 | validation: 7.3223188759781195]
	TIME [epoch: 8.32 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.971884636397327		[learning rate: 0.01815]
	Learning Rate: 0.01815
	LOSS [training: 5.971884636397327 | validation: 6.91938185747795]
	TIME [epoch: 8.3 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.899120018751572		[learning rate: 0.01835]
	Learning Rate: 0.01835
	LOSS [training: 5.899120018751572 | validation: 6.842299953485396]
	TIME [epoch: 8.31 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.832746687919942		[learning rate: 0.01855]
	Learning Rate: 0.01855
	LOSS [training: 5.832746687919942 | validation: 7.114119524386194]
	TIME [epoch: 8.34 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8048761514207605		[learning rate: 0.01875]
	Learning Rate: 0.01875
	LOSS [training: 5.8048761514207605 | validation: 6.968632960094206]
	TIME [epoch: 8.32 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6858297517534355		[learning rate: 0.01895]
	Learning Rate: 0.01895
	LOSS [training: 5.6858297517534355 | validation: 7.45543891128049]
	TIME [epoch: 8.31 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.819092434173404		[learning rate: 0.01915]
	Learning Rate: 0.01915
	LOSS [training: 5.819092434173404 | validation: 7.137301272745447]
	TIME [epoch: 8.31 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.154560728308777		[learning rate: 0.01935]
	Learning Rate: 0.01935
	LOSS [training: 6.154560728308777 | validation: 6.806522557307275]
	TIME [epoch: 8.31 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.67051861561562		[learning rate: 0.01955]
	Learning Rate: 0.01955
	LOSS [training: 5.67051861561562 | validation: 6.663980589030713]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.512376412678314		[learning rate: 0.01975]
	Learning Rate: 0.01975
	LOSS [training: 5.512376412678314 | validation: 6.686032707840545]
	TIME [epoch: 8.35 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.3160375575352905		[learning rate: 0.01995]
	Learning Rate: 0.01995
	LOSS [training: 6.3160375575352905 | validation: 6.698244035420746]
	TIME [epoch: 8.31 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.755515044582121		[learning rate: 0.02]
	Learning Rate: 0.02
	LOSS [training: 5.755515044582121 | validation: 6.624397056986367]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.736547747057223		[learning rate: 0.02]
	Learning Rate: 0.02
	LOSS [training: 5.736547747057223 | validation: 7.456578892051571]
	TIME [epoch: 8.31 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.932452150432044		[learning rate: 0.02]
	Learning Rate: 0.0199999
	LOSS [training: 5.932452150432044 | validation: 6.807074716787571]
	TIME [epoch: 8.3 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.564970410659657		[learning rate: 0.02]
	Learning Rate: 0.0199998
	LOSS [training: 5.564970410659657 | validation: 6.974487976180422]
	TIME [epoch: 8.34 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.1814046567410745		[learning rate: 0.02]
	Learning Rate: 0.0199997
	LOSS [training: 6.1814046567410745 | validation: 6.9956149202605875]
	TIME [epoch: 8.32 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7772011616440695		[learning rate: 0.02]
	Learning Rate: 0.0199995
	LOSS [training: 5.7772011616440695 | validation: 7.147798003673826]
	TIME [epoch: 8.31 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.736823536255799		[learning rate: 0.019999]
	Learning Rate: 0.0199994
	LOSS [training: 5.736823536255799 | validation: 6.622845581385867]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.515904683652448		[learning rate: 0.019999]
	Learning Rate: 0.0199992
	LOSS [training: 5.515904683652448 | validation: 6.6606273188484035]
	TIME [epoch: 8.3 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.721926688221651		[learning rate: 0.019999]
	Learning Rate: 0.019999
	LOSS [training: 5.721926688221651 | validation: 6.689400090487023]
	TIME [epoch: 8.31 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.737567307715174		[learning rate: 0.019999]
	Learning Rate: 0.0199987
	LOSS [training: 5.737567307715174 | validation: 7.479096762948805]
	TIME [epoch: 8.35 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.840527486351644		[learning rate: 0.019998]
	Learning Rate: 0.0199984
	LOSS [training: 5.840527486351644 | validation: 6.377302971702445]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.533374883110437		[learning rate: 0.019998]
	Learning Rate: 0.0199981
	LOSS [training: 5.533374883110437 | validation: 4.907214512203565]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.886612314268918		[learning rate: 0.019998]
	Learning Rate: 0.0199978
	LOSS [training: 4.886612314268918 | validation: 4.708096266583631]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.394708207217775		[learning rate: 0.019997]
	Learning Rate: 0.0199974
	LOSS [training: 4.394708207217775 | validation: 4.133519115811676]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.734159109318541		[learning rate: 0.019997]
	Learning Rate: 0.019997
	LOSS [training: 4.734159109318541 | validation: 4.11285345870865]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.555688429145299		[learning rate: 0.019997]
	Learning Rate: 0.0199966
	LOSS [training: 4.555688429145299 | validation: 4.368578465933561]
	TIME [epoch: 8.32 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.2305719860956525		[learning rate: 0.019996]
	Learning Rate: 0.0199962
	LOSS [training: 4.2305719860956525 | validation: 4.239765923329331]
	TIME [epoch: 8.3 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.353856893945462		[learning rate: 0.019996]
	Learning Rate: 0.0199957
	LOSS [training: 4.353856893945462 | validation: 5.405041673602324]
	TIME [epoch: 8.31 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.500040876540344		[learning rate: 0.019995]
	Learning Rate: 0.0199952
	LOSS [training: 4.500040876540344 | validation: 3.955382311970638]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0848185329078035		[learning rate: 0.019995]
	Learning Rate: 0.0199947
	LOSS [training: 4.0848185329078035 | validation: 4.00976135017685]
	TIME [epoch: 8.31 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.206234221833433		[learning rate: 0.019994]
	Learning Rate: 0.0199941
	LOSS [training: 4.206234221833433 | validation: 3.8375492665176667]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.570599113082565		[learning rate: 0.019994]
	Learning Rate: 0.0199935
	LOSS [training: 4.570599113082565 | validation: 5.54662291371992]
	TIME [epoch: 8.3 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6046053234979745		[learning rate: 0.019993]
	Learning Rate: 0.0199929
	LOSS [training: 4.6046053234979745 | validation: 4.145206657235]
	TIME [epoch: 8.3 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.890308439488968		[learning rate: 0.019992]
	Learning Rate: 0.0199923
	LOSS [training: 3.890308439488968 | validation: 4.421294868798225]
	TIME [epoch: 8.29 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.813490870057297		[learning rate: 0.019992]
	Learning Rate: 0.0199916
	LOSS [training: 3.813490870057297 | validation: 4.832222780288813]
	TIME [epoch: 8.29 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.171400803224604		[learning rate: 0.019991]
	Learning Rate: 0.0199909
	LOSS [training: 4.171400803224604 | validation: 4.823431844765501]
	TIME [epoch: 8.33 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.244818910448821		[learning rate: 0.01999]
	Learning Rate: 0.0199902
	LOSS [training: 4.244818910448821 | validation: 4.203403524075564]
	TIME [epoch: 8.3 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.974565981812411		[learning rate: 0.019989]
	Learning Rate: 0.0199895
	LOSS [training: 3.974565981812411 | validation: 4.029801849079296]
	TIME [epoch: 8.29 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6693584444443728		[learning rate: 0.019989]
	Learning Rate: 0.0199887
	LOSS [training: 3.6693584444443728 | validation: 4.008222127137702]
	TIME [epoch: 8.29 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9834629311286816		[learning rate: 0.019988]
	Learning Rate: 0.0199879
	LOSS [training: 3.9834629311286816 | validation: 3.6475280695576973]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5223514178392508		[learning rate: 0.019987]
	Learning Rate: 0.0199871
	LOSS [training: 3.5223514178392508 | validation: 3.582361428863121]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.972767355780011		[learning rate: 0.019986]
	Learning Rate: 0.0199862
	LOSS [training: 3.972767355780011 | validation: 3.7795940805859325]
	TIME [epoch: 8.33 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5251589007369333		[learning rate: 0.019985]
	Learning Rate: 0.0199853
	LOSS [training: 3.5251589007369333 | validation: 3.416162803719688]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4019317668550295		[learning rate: 0.019984]
	Learning Rate: 0.0199844
	LOSS [training: 3.4019317668550295 | validation: 3.3060704871656856]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.641603550858413		[learning rate: 0.019984]
	Learning Rate: 0.0199835
	LOSS [training: 3.641603550858413 | validation: 3.892074269114646]
	TIME [epoch: 8.3 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2493568073855874		[learning rate: 0.019983]
	Learning Rate: 0.0199825
	LOSS [training: 3.2493568073855874 | validation: 3.854972171263559]
	TIME [epoch: 8.3 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3498171337007356		[learning rate: 0.019982]
	Learning Rate: 0.0199816
	LOSS [training: 3.3498171337007356 | validation: 3.047684688845]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4662792058369707		[learning rate: 0.019981]
	Learning Rate: 0.0199805
	LOSS [training: 3.4662792058369707 | validation: 3.670640252323636]
	TIME [epoch: 8.31 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.09099566960772		[learning rate: 0.019979]
	Learning Rate: 0.0199795
	LOSS [training: 3.09099566960772 | validation: 2.9004165772956494]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8417174485745593		[learning rate: 0.019978]
	Learning Rate: 0.0199784
	LOSS [training: 2.8417174485745593 | validation: 3.390490303167811]
	TIME [epoch: 8.31 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3573099946288374		[learning rate: 0.019977]
	Learning Rate: 0.0199773
	LOSS [training: 3.3573099946288374 | validation: 2.812822315832712]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7813882167074855		[learning rate: 0.019976]
	Learning Rate: 0.0199762
	LOSS [training: 2.7813882167074855 | validation: 3.4703638596996376]
	TIME [epoch: 8.32 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.736301506611009		[learning rate: 0.019975]
	Learning Rate: 0.019975
	LOSS [training: 2.736301506611009 | validation: 4.035629059255293]
	TIME [epoch: 8.31 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2438394183556065		[learning rate: 0.019974]
	Learning Rate: 0.0199739
	LOSS [training: 3.2438394183556065 | validation: 3.474870479296383]
	TIME [epoch: 8.3 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9223216516087063		[learning rate: 0.019973]
	Learning Rate: 0.0199727
	LOSS [training: 2.9223216516087063 | validation: 2.6346347598002287]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5260717013732776		[learning rate: 0.019971]
	Learning Rate: 0.0199714
	LOSS [training: 2.5260717013732776 | validation: 3.1540204151785303]
	TIME [epoch: 8.3 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.760979717456354		[learning rate: 0.01997]
	Learning Rate: 0.0199702
	LOSS [training: 2.760979717456354 | validation: 2.6783164127496306]
	TIME [epoch: 8.3 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3695645645016756		[learning rate: 0.019969]
	Learning Rate: 0.0199689
	LOSS [training: 2.3695645645016756 | validation: 2.7106174373089997]
	TIME [epoch: 8.35 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8534512953195286		[learning rate: 0.019968]
	Learning Rate: 0.0199675
	LOSS [training: 2.8534512953195286 | validation: 2.4091988638874637]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.482342441043503		[learning rate: 0.019966]
	Learning Rate: 0.0199662
	LOSS [training: 2.482342441043503 | validation: 2.494386734959505]
	TIME [epoch: 8.3 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6467926488424354		[learning rate: 0.019965]
	Learning Rate: 0.0199648
	LOSS [training: 2.6467926488424354 | validation: 2.2072791504907747]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8788323981735227		[learning rate: 0.019963]
	Learning Rate: 0.0199634
	LOSS [training: 2.8788323981735227 | validation: 2.363079249315966]
	TIME [epoch: 8.3 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0349864313757884		[learning rate: 0.019962]
	Learning Rate: 0.019962
	LOSS [training: 3.0349864313757884 | validation: 2.2700858937147466]
	TIME [epoch: 8.34 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3123209762589996		[learning rate: 0.019961]
	Learning Rate: 0.0199606
	LOSS [training: 2.3123209762589996 | validation: 2.504563693411046]
	TIME [epoch: 8.31 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.523262893366285		[learning rate: 0.019959]
	Learning Rate: 0.0199591
	LOSS [training: 2.523262893366285 | validation: 2.744618657611401]
	TIME [epoch: 8.29 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4868917809525954		[learning rate: 0.019958]
	Learning Rate: 0.0199576
	LOSS [training: 2.4868917809525954 | validation: 2.489881488028969]
	TIME [epoch: 8.3 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.446994469050459		[learning rate: 0.019956]
	Learning Rate: 0.019956
	LOSS [training: 2.446994469050459 | validation: 2.3193095664695402]
	TIME [epoch: 8.29 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3350517648699785		[learning rate: 0.019954]
	Learning Rate: 0.0199545
	LOSS [training: 2.3350517648699785 | validation: 2.516021342700907]
	TIME [epoch: 8.3 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4393275404812127		[learning rate: 0.019953]
	Learning Rate: 0.0199529
	LOSS [training: 2.4393275404812127 | validation: 2.3823141006865125]
	TIME [epoch: 8.34 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2786220957831778		[learning rate: 0.019951]
	Learning Rate: 0.0199513
	LOSS [training: 2.2786220957831778 | validation: 2.398240091910783]
	TIME [epoch: 8.3 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.273683443762458		[learning rate: 0.01995]
	Learning Rate: 0.0199496
	LOSS [training: 2.273683443762458 | validation: 2.0622920103623352]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_111.pth
	Model improved!!!
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2762105370736068		[learning rate: 0.019948]
	Learning Rate: 0.0199479
	LOSS [training: 2.2762105370736068 | validation: 2.292689531569927]
	TIME [epoch: 8.29 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.379278878171588		[learning rate: 0.019946]
	Learning Rate: 0.0199462
	LOSS [training: 2.379278878171588 | validation: 2.040712323606127]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_113.pth
	Model improved!!!
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2021975234017024		[learning rate: 0.019945]
	Learning Rate: 0.0199445
	LOSS [training: 2.2021975234017024 | validation: 2.016369258489993]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_114.pth
	Model improved!!!
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2956259673610018		[learning rate: 0.019943]
	Learning Rate: 0.0199428
	LOSS [training: 2.2956259673610018 | validation: 2.123175257473347]
	TIME [epoch: 8.31 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.253173118214144		[learning rate: 0.019941]
	Learning Rate: 0.019941
	LOSS [training: 2.253173118214144 | validation: 1.8927380563695808]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_116.pth
	Model improved!!!
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1148350592891654		[learning rate: 0.019939]
	Learning Rate: 0.0199392
	LOSS [training: 2.1148350592891654 | validation: 2.0175982503667758]
	TIME [epoch: 8.29 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.879973134621057		[learning rate: 0.019937]
	Learning Rate: 0.0199374
	LOSS [training: 1.879973134621057 | validation: 2.352378304895895]
	TIME [epoch: 8.29 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.304135644239059		[learning rate: 0.019935]
	Learning Rate: 0.0199355
	LOSS [training: 2.304135644239059 | validation: 1.823479244302961]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_119.pth
	Model improved!!!
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1744527318767775		[learning rate: 0.019934]
	Learning Rate: 0.0199336
	LOSS [training: 2.1744527318767775 | validation: 1.7044090437428134]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_120.pth
	Model improved!!!
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3035259457159465		[learning rate: 0.019932]
	Learning Rate: 0.0199317
	LOSS [training: 2.3035259457159465 | validation: 2.4190339154937432]
	TIME [epoch: 8.29 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3075847147155097		[learning rate: 0.01993]
	Learning Rate: 0.0199297
	LOSS [training: 2.3075847147155097 | validation: 1.771590722339543]
	TIME [epoch: 8.29 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1983025212661653		[learning rate: 0.019928]
	Learning Rate: 0.0199278
	LOSS [training: 2.1983025212661653 | validation: 2.24235323061412]
	TIME [epoch: 8.29 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2461868496875335		[learning rate: 0.019926]
	Learning Rate: 0.0199258
	LOSS [training: 2.2461868496875335 | validation: 1.824689165038965]
	TIME [epoch: 8.29 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8110519917825465		[learning rate: 0.019924]
	Learning Rate: 0.0199238
	LOSS [training: 1.8110519917825465 | validation: 1.9760021920121242]
	TIME [epoch: 8.32 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1421478560756433		[learning rate: 0.019922]
	Learning Rate: 0.0199217
	LOSS [training: 2.1421478560756433 | validation: 1.742939953472673]
	TIME [epoch: 8.3 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9616857474498095		[learning rate: 0.01992]
	Learning Rate: 0.0199196
	LOSS [training: 1.9616857474498095 | validation: 1.833256464898112]
	TIME [epoch: 8.28 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.019339371368036		[learning rate: 0.019918]
	Learning Rate: 0.0199175
	LOSS [training: 2.019339371368036 | validation: 1.7720566294151014]
	TIME [epoch: 8.29 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.219801468620596		[learning rate: 0.019915]
	Learning Rate: 0.0199154
	LOSS [training: 2.219801468620596 | validation: 1.8949360958446877]
	TIME [epoch: 8.29 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.244526117673053		[learning rate: 0.019913]
	Learning Rate: 0.0199132
	LOSS [training: 2.244526117673053 | validation: 1.6481633402842164]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_130.pth
	Model improved!!!
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.024327344452085		[learning rate: 0.019911]
	Learning Rate: 0.019911
	LOSS [training: 2.024327344452085 | validation: 1.7770119882789288]
	TIME [epoch: 8.33 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8140122922594557		[learning rate: 0.019909]
	Learning Rate: 0.0199088
	LOSS [training: 1.8140122922594557 | validation: 2.463658070812476]
	TIME [epoch: 8.29 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9244748394679418		[learning rate: 0.019907]
	Learning Rate: 0.0199066
	LOSS [training: 1.9244748394679418 | validation: 2.1416861785776256]
	TIME [epoch: 8.29 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.166604362178134		[learning rate: 0.019904]
	Learning Rate: 0.0199043
	LOSS [training: 2.166604362178134 | validation: 1.7992181055569716]
	TIME [epoch: 8.29 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0126341472246		[learning rate: 0.019902]
	Learning Rate: 0.019902
	LOSS [training: 2.0126341472246 | validation: 1.7416662616777583]
	TIME [epoch: 8.29 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.675790791207223		[learning rate: 0.0199]
	Learning Rate: 0.0198997
	LOSS [training: 1.675790791207223 | validation: 2.00051153015015]
	TIME [epoch: 8.35 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8772240803905125		[learning rate: 0.019897]
	Learning Rate: 0.0198974
	LOSS [training: 1.8772240803905125 | validation: 1.8098811830341344]
	TIME [epoch: 8.3 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4108130085622346		[learning rate: 0.019895]
	Learning Rate: 0.019895
	LOSS [training: 2.4108130085622346 | validation: 2.433913073563878]
	TIME [epoch: 8.28 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.023979376765503		[learning rate: 0.019893]
	Learning Rate: 0.0198926
	LOSS [training: 2.023979376765503 | validation: 2.8515647637123025]
	TIME [epoch: 8.28 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9076228721265993		[learning rate: 0.01989]
	Learning Rate: 0.0198901
	LOSS [training: 1.9076228721265993 | validation: 1.8381932066608935]
	TIME [epoch: 8.29 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7826409272504486		[learning rate: 0.019888]
	Learning Rate: 0.0198877
	LOSS [training: 1.7826409272504486 | validation: 1.4494050635051137]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8538962311792087		[learning rate: 0.019885]
	Learning Rate: 0.0198852
	LOSS [training: 1.8538962311792087 | validation: 2.3432676164374486]
	TIME [epoch: 8.33 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8935318755582724		[learning rate: 0.019883]
	Learning Rate: 0.0198827
	LOSS [training: 1.8935318755582724 | validation: 1.6684761417940677]
	TIME [epoch: 8.29 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6839166148999745		[learning rate: 0.01988]
	Learning Rate: 0.0198802
	LOSS [training: 1.6839166148999745 | validation: 2.720070095738694]
	TIME [epoch: 8.28 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9308031188700785		[learning rate: 0.019878]
	Learning Rate: 0.0198776
	LOSS [training: 1.9308031188700785 | validation: 1.6803437107085097]
	TIME [epoch: 8.29 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3417052831858536		[learning rate: 0.019875]
	Learning Rate: 0.019875
	LOSS [training: 2.3417052831858536 | validation: 2.959684422536087]
	TIME [epoch: 8.28 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2908757816980887		[learning rate: 0.019872]
	Learning Rate: 0.0198724
	LOSS [training: 2.2908757816980887 | validation: 1.3692178961824455]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_147.pth
	Model improved!!!
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.638615280460528		[learning rate: 0.01987]
	Learning Rate: 0.0198697
	LOSS [training: 1.638615280460528 | validation: 1.6165584592043962]
	TIME [epoch: 8.32 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6886634576731319		[learning rate: 0.019867]
	Learning Rate: 0.0198671
	LOSS [training: 1.6886634576731319 | validation: 1.599797449402842]
	TIME [epoch: 8.3 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7962324355680994		[learning rate: 0.019864]
	Learning Rate: 0.0198644
	LOSS [training: 1.7962324355680994 | validation: 1.577890641616924]
	TIME [epoch: 8.3 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.819280114013548		[learning rate: 0.019862]
	Learning Rate: 0.0198616
	LOSS [training: 1.819280114013548 | validation: 1.9449284110206504]
	TIME [epoch: 8.3 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.650100219750281		[learning rate: 0.019859]
	Learning Rate: 0.0198589
	LOSS [training: 2.650100219750281 | validation: 1.6685563121529587]
	TIME [epoch: 8.31 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7304464511262447		[learning rate: 0.019856]
	Learning Rate: 0.0198561
	LOSS [training: 1.7304464511262447 | validation: 2.4039581514789647]
	TIME [epoch: 8.36 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7979864196652313		[learning rate: 0.019853]
	Learning Rate: 0.0198533
	LOSS [training: 1.7979864196652313 | validation: 1.631849729542215]
	TIME [epoch: 8.3 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7610528588974799		[learning rate: 0.01985]
	Learning Rate: 0.0198505
	LOSS [training: 1.7610528588974799 | validation: 1.6150759068635683]
	TIME [epoch: 8.3 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6659445908531059		[learning rate: 0.019848]
	Learning Rate: 0.0198476
	LOSS [training: 1.6659445908531059 | validation: 1.7394208995725884]
	TIME [epoch: 8.3 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.214591403170968		[learning rate: 0.019845]
	Learning Rate: 0.0198447
	LOSS [training: 2.214591403170968 | validation: 1.578173291324317]
	TIME [epoch: 8.3 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6535152425766864		[learning rate: 0.019842]
	Learning Rate: 0.0198418
	LOSS [training: 1.6535152425766864 | validation: 1.6236065963359985]
	TIME [epoch: 8.33 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8476020216084066		[learning rate: 0.019839]
	Learning Rate: 0.0198388
	LOSS [training: 1.8476020216084066 | validation: 1.528659047757452]
	TIME [epoch: 8.31 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7823760342098844		[learning rate: 0.019836]
	Learning Rate: 0.0198359
	LOSS [training: 1.7823760342098844 | validation: 1.8204662800747973]
	TIME [epoch: 8.32 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7994346723131636		[learning rate: 0.019833]
	Learning Rate: 0.0198329
	LOSS [training: 1.7994346723131636 | validation: 3.0378065085432615]
	TIME [epoch: 8.29 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.052575374502015		[learning rate: 0.01983]
	Learning Rate: 0.0198299
	LOSS [training: 2.052575374502015 | validation: 1.3243089639270493]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_162.pth
	Model improved!!!
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5079764425550366		[learning rate: 0.019827]
	Learning Rate: 0.0198268
	LOSS [training: 1.5079764425550366 | validation: 2.122719016599177]
	TIME [epoch: 8.3 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8620259838962598		[learning rate: 0.019824]
	Learning Rate: 0.0198237
	LOSS [training: 1.8620259838962598 | validation: 1.9543049830728108]
	TIME [epoch: 8.34 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.879907045300321		[learning rate: 0.019821]
	Learning Rate: 0.0198206
	LOSS [training: 1.879907045300321 | validation: 2.0372832494480826]
	TIME [epoch: 8.3 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0818883054306765		[learning rate: 0.019818]
	Learning Rate: 0.0198175
	LOSS [training: 2.0818883054306765 | validation: 1.9722693578117396]
	TIME [epoch: 8.3 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.634466023502592		[learning rate: 0.019814]
	Learning Rate: 0.0198143
	LOSS [training: 1.634466023502592 | validation: 1.354569992075565]
	TIME [epoch: 8.3 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3827024959264227		[learning rate: 0.019811]
	Learning Rate: 0.0198112
	LOSS [training: 2.3827024959264227 | validation: 1.4494161693201233]
	TIME [epoch: 8.32 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7108547774667202		[learning rate: 0.019808]
	Learning Rate: 0.0198079
	LOSS [training: 1.7108547774667202 | validation: 1.736300626486516]
	TIME [epoch: 8.32 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7021000447879833		[learning rate: 0.019805]
	Learning Rate: 0.0198047
	LOSS [training: 1.7021000447879833 | validation: 1.1650408897650089]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_170.pth
	Model improved!!!
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4872825299837724		[learning rate: 0.019801]
	Learning Rate: 0.0198014
	LOSS [training: 1.4872825299837724 | validation: 1.6648428265695587]
	TIME [epoch: 8.29 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.679820857762354		[learning rate: 0.019798]
	Learning Rate: 0.0197982
	LOSS [training: 1.679820857762354 | validation: 2.286151220839905]
	TIME [epoch: 8.3 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9277207161377201		[learning rate: 0.019795]
	Learning Rate: 0.0197948
	LOSS [training: 1.9277207161377201 | validation: 1.688468334347125]
	TIME [epoch: 8.29 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9379969852889056		[learning rate: 0.019791]
	Learning Rate: 0.0197915
	LOSS [training: 1.9379969852889056 | validation: 1.4961880213541634]
	TIME [epoch: 8.29 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2531270602679614		[learning rate: 0.019788]
	Learning Rate: 0.0197881
	LOSS [training: 2.2531270602679614 | validation: 1.6815909678854633]
	TIME [epoch: 8.34 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8735346392448387		[learning rate: 0.019785]
	Learning Rate: 0.0197847
	LOSS [training: 1.8735346392448387 | validation: 1.7371518691681778]
	TIME [epoch: 8.3 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.549320924265172		[learning rate: 0.019781]
	Learning Rate: 0.0197813
	LOSS [training: 1.549320924265172 | validation: 1.3036238274568808]
	TIME [epoch: 8.29 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7572449181140186		[learning rate: 0.019778]
	Learning Rate: 0.0197778
	LOSS [training: 1.7572449181140186 | validation: 1.505177128678747]
	TIME [epoch: 8.32 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4660619671493191		[learning rate: 0.019774]
	Learning Rate: 0.0197744
	LOSS [training: 1.4660619671493191 | validation: 1.1945329948757606]
	TIME [epoch: 8.3 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5901154578502286		[learning rate: 0.019771]
	Learning Rate: 0.0197709
	LOSS [training: 1.5901154578502286 | validation: 1.9315835047125545]
	TIME [epoch: 8.31 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5152072778713248		[learning rate: 0.019767]
	Learning Rate: 0.0197673
	LOSS [training: 1.5152072778713248 | validation: 1.4948346100274565]
	TIME [epoch: 8.33 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.929625186872161		[learning rate: 0.019764]
	Learning Rate: 0.0197638
	LOSS [training: 1.929625186872161 | validation: 1.7947653477419656]
	TIME [epoch: 8.3 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5433792509588735		[learning rate: 0.01976]
	Learning Rate: 0.0197602
	LOSS [training: 1.5433792509588735 | validation: 1.8409395813297582]
	TIME [epoch: 8.3 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.082470960990135		[learning rate: 0.019757]
	Learning Rate: 0.0197566
	LOSS [training: 2.082470960990135 | validation: 1.5922294949476983]
	TIME [epoch: 8.3 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6164759275998641		[learning rate: 0.019753]
	Learning Rate: 0.0197529
	LOSS [training: 1.6164759275998641 | validation: 1.5900848282207074]
	TIME [epoch: 8.32 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6516846571229422		[learning rate: 0.019749]
	Learning Rate: 0.0197493
	LOSS [training: 1.6516846571229422 | validation: 1.5662301592430743]
	TIME [epoch: 8.33 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6053535499002607		[learning rate: 0.019746]
	Learning Rate: 0.0197456
	LOSS [training: 1.6053535499002607 | validation: 1.782223833661148]
	TIME [epoch: 8.31 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7256158241192585		[learning rate: 0.019742]
	Learning Rate: 0.0197419
	LOSS [training: 1.7256158241192585 | validation: 1.3212690575336443]
	TIME [epoch: 8.3 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4027803475925653		[learning rate: 0.019738]
	Learning Rate: 0.0197381
	LOSS [training: 1.4027803475925653 | validation: 2.7975244537656545]
	TIME [epoch: 8.3 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.782455776008433		[learning rate: 0.019734]
	Learning Rate: 0.0197343
	LOSS [training: 1.782455776008433 | validation: 1.8247039676974457]
	TIME [epoch: 8.3 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7224237959282085		[learning rate: 0.019731]
	Learning Rate: 0.0197305
	LOSS [training: 1.7224237959282085 | validation: 1.5255350307279585]
	TIME [epoch: 8.31 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.840808300677336		[learning rate: 0.019727]
	Learning Rate: 0.0197267
	LOSS [training: 1.840808300677336 | validation: 2.0376902331246987]
	TIME [epoch: 8.37 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7406229280576948		[learning rate: 0.019723]
	Learning Rate: 0.0197229
	LOSS [training: 1.7406229280576948 | validation: 1.2991201874454485]
	TIME [epoch: 8.3 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4426873895464767		[learning rate: 0.019719]
	Learning Rate: 0.019719
	LOSS [training: 1.4426873895464767 | validation: 1.3073602198629382]
	TIME [epoch: 8.3 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8519630557579523		[learning rate: 0.019715]
	Learning Rate: 0.0197151
	LOSS [training: 1.8519630557579523 | validation: 1.3968731954939941]
	TIME [epoch: 8.29 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.516056059157376		[learning rate: 0.019711]
	Learning Rate: 0.0197112
	LOSS [training: 1.516056059157376 | validation: 2.349894011078441]
	TIME [epoch: 8.3 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6714923401272577		[learning rate: 0.019707]
	Learning Rate: 0.0197072
	LOSS [training: 1.6714923401272577 | validation: 1.446275532926602]
	TIME [epoch: 8.33 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7664574843061909		[learning rate: 0.019703]
	Learning Rate: 0.0197032
	LOSS [training: 1.7664574843061909 | validation: 1.2126835219097836]
	TIME [epoch: 8.31 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2587859414688554		[learning rate: 0.019699]
	Learning Rate: 0.0196992
	LOSS [training: 2.2587859414688554 | validation: 2.0584720294561665]
	TIME [epoch: 8.3 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.575384890452543		[learning rate: 0.019695]
	Learning Rate: 0.0196952
	LOSS [training: 1.575384890452543 | validation: 1.7623715034900507]
	TIME [epoch: 8.3 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5319867748308433		[learning rate: 0.019691]
	Learning Rate: 0.0196911
	LOSS [training: 1.5319867748308433 | validation: 1.1711839206009649]
	TIME [epoch: 8.29 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3967359960538772		[learning rate: 0.019687]
	Learning Rate: 0.019687
	LOSS [training: 1.3967359960538772 | validation: 1.6839165630991793]
	TIME [epoch: 8.29 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5963472492077224		[learning rate: 0.019683]
	Learning Rate: 0.0196829
	LOSS [training: 1.5963472492077224 | validation: 2.557660955743869]
	TIME [epoch: 8.33 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8113539667446563		[learning rate: 0.019679]
	Learning Rate: 0.0196788
	LOSS [training: 1.8113539667446563 | validation: 2.2255568093189417]
	TIME [epoch: 8.3 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.642911076732252		[learning rate: 0.019675]
	Learning Rate: 0.0196746
	LOSS [training: 1.642911076732252 | validation: 1.1677961493276912]
	TIME [epoch: 8.29 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4751689875532619		[learning rate: 0.01967]
	Learning Rate: 0.0196704
	LOSS [training: 1.4751689875532619 | validation: 1.3635276030472192]
	TIME [epoch: 8.29 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3005038258216393		[learning rate: 0.019666]
	Learning Rate: 0.0196662
	LOSS [training: 1.3005038258216393 | validation: 2.1684280082560456]
	TIME [epoch: 8.29 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7136500501693859		[learning rate: 0.019662]
	Learning Rate: 0.0196619
	LOSS [training: 1.7136500501693859 | validation: 1.4081948825111483]
	TIME [epoch: 8.34 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.344224952673417		[learning rate: 0.019658]
	Learning Rate: 0.0196576
	LOSS [training: 1.344224952673417 | validation: 1.306470175130912]
	TIME [epoch: 8.31 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3225231468860308		[learning rate: 0.019653]
	Learning Rate: 0.0196533
	LOSS [training: 1.3225231468860308 | validation: 1.6111187646393517]
	TIME [epoch: 8.3 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.235292444777863		[learning rate: 0.019649]
	Learning Rate: 0.019649
	LOSS [training: 2.235292444777863 | validation: 2.5936989244430917]
	TIME [epoch: 8.3 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.776558826329406		[learning rate: 0.019645]
	Learning Rate: 0.0196447
	LOSS [training: 1.776558826329406 | validation: 1.8773933021531315]
	TIME [epoch: 8.3 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.77974998793276		[learning rate: 0.01964]
	Learning Rate: 0.0196403
	LOSS [training: 1.77974998793276 | validation: 1.3230247033562388]
	TIME [epoch: 8.29 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2500185337379461		[learning rate: 0.019636]
	Learning Rate: 0.0196359
	LOSS [training: 1.2500185337379461 | validation: 1.1300267854603017]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_214.pth
	Model improved!!!
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.435956119321693		[learning rate: 0.019631]
	Learning Rate: 0.0196314
	LOSS [training: 1.435956119321693 | validation: 1.3707880108450934]
	TIME [epoch: 8.3 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6268593147522425		[learning rate: 0.019627]
	Learning Rate: 0.019627
	LOSS [training: 1.6268593147522425 | validation: 1.3490550029275008]
	TIME [epoch: 8.29 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2780981662022242		[learning rate: 0.019622]
	Learning Rate: 0.0196225
	LOSS [training: 1.2780981662022242 | validation: 1.6091874881921173]
	TIME [epoch: 8.29 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5512727248310072		[learning rate: 0.019618]
	Learning Rate: 0.019618
	LOSS [training: 1.5512727248310072 | validation: 1.0197405143013083]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_218.pth
	Model improved!!!
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5329184934114468		[learning rate: 0.019613]
	Learning Rate: 0.0196134
	LOSS [training: 1.5329184934114468 | validation: 1.4723291682004032]
	TIME [epoch: 8.31 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6142940125610412		[learning rate: 0.019609]
	Learning Rate: 0.0196089
	LOSS [training: 1.6142940125610412 | validation: 1.200886982535148]
	TIME [epoch: 8.32 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3889344919133286		[learning rate: 0.019604]
	Learning Rate: 0.0196043
	LOSS [training: 2.3889344919133286 | validation: 2.2048086926742614]
	TIME [epoch: 8.3 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5595785233445607		[learning rate: 0.0196]
	Learning Rate: 0.0195997
	LOSS [training: 1.5595785233445607 | validation: 0.9475634514109077]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_222.pth
	Model improved!!!
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.597389060968228		[learning rate: 0.019595]
	Learning Rate: 0.019595
	LOSS [training: 1.597389060968228 | validation: 1.2835005073265977]
	TIME [epoch: 8.29 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.392116499074468		[learning rate: 0.01959]
	Learning Rate: 0.0195904
	LOSS [training: 1.392116499074468 | validation: 1.5108469504691246]
	TIME [epoch: 8.3 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5683734035642962		[learning rate: 0.019586]
	Learning Rate: 0.0195857
	LOSS [training: 1.5683734035642962 | validation: 1.4936255335890798]
	TIME [epoch: 8.34 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5277873593090578		[learning rate: 0.019581]
	Learning Rate: 0.0195809
	LOSS [training: 1.5277873593090578 | validation: 1.1441415535467545]
	TIME [epoch: 8.29 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5171557917186744		[learning rate: 0.019576]
	Learning Rate: 0.0195762
	LOSS [training: 1.5171557917186744 | validation: 0.9807712221251921]
	TIME [epoch: 8.29 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1963011387826177		[learning rate: 0.019571]
	Learning Rate: 0.0195714
	LOSS [training: 1.1963011387826177 | validation: 1.4874912613717037]
	TIME [epoch: 8.29 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4241110423553223		[learning rate: 0.019567]
	Learning Rate: 0.0195666
	LOSS [training: 1.4241110423553223 | validation: 1.7812320084046942]
	TIME [epoch: 8.29 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7064668318176397		[learning rate: 0.019562]
	Learning Rate: 0.0195618
	LOSS [training: 1.7064668318176397 | validation: 1.7197694786462079]
	TIME [epoch: 8.3 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2504327444680492		[learning rate: 0.019557]
	Learning Rate: 0.0195569
	LOSS [training: 1.2504327444680492 | validation: 1.1381024020755983]
	TIME [epoch: 8.34 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.362052248169249		[learning rate: 0.019552]
	Learning Rate: 0.0195521
	LOSS [training: 2.362052248169249 | validation: 1.5943655526459495]
	TIME [epoch: 8.29 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.990051275309979		[learning rate: 0.019547]
	Learning Rate: 0.0195472
	LOSS [training: 1.990051275309979 | validation: 1.4050206090712054]
	TIME [epoch: 8.3 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5442624384180956		[learning rate: 0.019542]
	Learning Rate: 0.0195422
	LOSS [training: 1.5442624384180956 | validation: 1.3475701576304928]
	TIME [epoch: 8.29 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2799606042532286		[learning rate: 0.019537]
	Learning Rate: 0.0195373
	LOSS [training: 1.2799606042532286 | validation: 1.3902772176164737]
	TIME [epoch: 8.29 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4756438299070744		[learning rate: 0.019532]
	Learning Rate: 0.0195323
	LOSS [training: 1.4756438299070744 | validation: 1.4248988913908769]
	TIME [epoch: 8.35 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3574194537253967		[learning rate: 0.019527]
	Learning Rate: 0.0195273
	LOSS [training: 1.3574194537253967 | validation: 1.105965758903603]
	TIME [epoch: 8.31 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5933803633207515		[learning rate: 0.019522]
	Learning Rate: 0.0195222
	LOSS [training: 1.5933803633207515 | validation: 1.4787502274041002]
	TIME [epoch: 8.29 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7814720738749723		[learning rate: 0.019517]
	Learning Rate: 0.0195172
	LOSS [training: 1.7814720738749723 | validation: 1.2677047521230713]
	TIME [epoch: 8.29 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3067512993129042		[learning rate: 0.019512]
	Learning Rate: 0.0195121
	LOSS [training: 1.3067512993129042 | validation: 1.07532802536674]
	TIME [epoch: 8.29 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3973731190185394		[learning rate: 0.019507]
	Learning Rate: 0.019507
	LOSS [training: 1.3973731190185394 | validation: 2.718302155991526]
	TIME [epoch: 8.29 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8508204933749315		[learning rate: 0.019502]
	Learning Rate: 0.0195018
	LOSS [training: 1.8508204933749315 | validation: 1.2564211154584832]
	TIME [epoch: 8.36 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.372664409324977		[learning rate: 0.019497]
	Learning Rate: 0.0194967
	LOSS [training: 1.372664409324977 | validation: 1.490499616148401]
	TIME [epoch: 8.36 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3097396062721236		[learning rate: 0.019491]
	Learning Rate: 0.0194915
	LOSS [training: 1.3097396062721236 | validation: 1.3863520919042467]
	TIME [epoch: 8.31 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.335757205149752		[learning rate: 0.019486]
	Learning Rate: 0.0194863
	LOSS [training: 1.335757205149752 | validation: 1.187836939497619]
	TIME [epoch: 8.31 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4523480059062062		[learning rate: 0.019481]
	Learning Rate: 0.019481
	LOSS [training: 1.4523480059062062 | validation: 1.4413100034132595]
	TIME [epoch: 8.31 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.417721479675336		[learning rate: 0.019476]
	Learning Rate: 0.0194757
	LOSS [training: 1.417721479675336 | validation: 1.3010750436604757]
	TIME [epoch: 8.33 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4488774258226869		[learning rate: 0.01947]
	Learning Rate: 0.0194705
	LOSS [training: 1.4488774258226869 | validation: 1.0541484754495256]
	TIME [epoch: 8.33 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3481812855688022		[learning rate: 0.019465]
	Learning Rate: 0.0194651
	LOSS [training: 1.3481812855688022 | validation: 1.2157368985890158]
	TIME [epoch: 8.31 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3711290993698633		[learning rate: 0.01946]
	Learning Rate: 0.0194598
	LOSS [training: 1.3711290993698633 | validation: 1.3480925215617618]
	TIME [epoch: 8.31 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2270995099014943		[learning rate: 0.019454]
	Learning Rate: 0.0194544
	LOSS [training: 1.2270995099014943 | validation: 1.2176543505666597]
	TIME [epoch: 8.33 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.491795486698761		[learning rate: 0.019449]
	Learning Rate: 0.019449
	LOSS [training: 1.491795486698761 | validation: 0.9694550941599676]
	TIME [epoch: 8.3 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2990962341931802		[learning rate: 0.019444]
	Learning Rate: 0.0194436
	LOSS [training: 1.2990962341931802 | validation: 0.8987746013571702]
	TIME [epoch: 8.35 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_253.pth
	Model improved!!!
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4524929066567926		[learning rate: 0.019438]
	Learning Rate: 0.0194381
	LOSS [training: 1.4524929066567926 | validation: 1.1300484995393156]
	TIME [epoch: 8.32 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1312626164050665		[learning rate: 0.019433]
	Learning Rate: 0.0194327
	LOSS [training: 1.1312626164050665 | validation: 2.3236767341243]
	TIME [epoch: 8.3 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4734468501183584		[learning rate: 0.019427]
	Learning Rate: 0.0194272
	LOSS [training: 1.4734468501183584 | validation: 1.4453105435459306]
	TIME [epoch: 8.3 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3553760600635296		[learning rate: 0.019422]
	Learning Rate: 0.0194216
	LOSS [training: 1.3553760600635296 | validation: 1.1064146098661896]
	TIME [epoch: 8.3 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4549936830291532		[learning rate: 0.019416]
	Learning Rate: 0.0194161
	LOSS [training: 1.4549936830291532 | validation: 1.2500173968575385]
	TIME [epoch: 8.34 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.31375910629213		[learning rate: 0.019411]
	Learning Rate: 0.0194105
	LOSS [training: 1.31375910629213 | validation: 1.2925104701355838]
	TIME [epoch: 8.33 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4464055863230174		[learning rate: 0.019405]
	Learning Rate: 0.0194049
	LOSS [training: 1.4464055863230174 | validation: 1.1240641576852093]
	TIME [epoch: 8.3 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.245189445793706		[learning rate: 0.019399]
	Learning Rate: 0.0193993
	LOSS [training: 1.245189445793706 | validation: 2.9867449954062826]
	TIME [epoch: 8.31 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0505091768033483		[learning rate: 0.019394]
	Learning Rate: 0.0193936
	LOSS [training: 2.0505091768033483 | validation: 2.5636766645509033]
	TIME [epoch: 8.3 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9134895539872077		[learning rate: 0.019388]
	Learning Rate: 0.0193879
	LOSS [training: 1.9134895539872077 | validation: 1.2506742363074677]
	TIME [epoch: 8.31 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2332155570008705		[learning rate: 0.019382]
	Learning Rate: 0.0193822
	LOSS [training: 1.2332155570008705 | validation: 1.2126474068578048]
	TIME [epoch: 8.35 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3947778177472623		[learning rate: 0.019376]
	Learning Rate: 0.0193765
	LOSS [training: 1.3947778177472623 | validation: 1.3214555973719206]
	TIME [epoch: 8.31 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.449213610449308		[learning rate: 0.019371]
	Learning Rate: 0.0193707
	LOSS [training: 1.449213610449308 | validation: 1.2263464586279222]
	TIME [epoch: 8.3 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1441327846836864		[learning rate: 0.019365]
	Learning Rate: 0.0193649
	LOSS [training: 1.1441327846836864 | validation: 0.8546484405273354]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_267.pth
	Model improved!!!
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5076166118733498		[learning rate: 0.019359]
	Learning Rate: 0.0193591
	LOSS [training: 1.5076166118733498 | validation: 1.1805220587584295]
	TIME [epoch: 8.36 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3169907509979448		[learning rate: 0.019353]
	Learning Rate: 0.0193533
	LOSS [training: 1.3169907509979448 | validation: 0.963823276498061]
	TIME [epoch: 8.36 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3880586481477384		[learning rate: 0.019347]
	Learning Rate: 0.0193474
	LOSS [training: 1.3880586481477384 | validation: 1.4344023902142728]
	TIME [epoch: 8.36 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3279446770475585		[learning rate: 0.019342]
	Learning Rate: 0.0193416
	LOSS [training: 1.3279446770475585 | validation: 1.119698390432721]
	TIME [epoch: 8.32 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3413968028666836		[learning rate: 0.019336]
	Learning Rate: 0.0193356
	LOSS [training: 1.3413968028666836 | validation: 1.1675713563786911]
	TIME [epoch: 8.33 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3199707177271038		[learning rate: 0.01933]
	Learning Rate: 0.0193297
	LOSS [training: 1.3199707177271038 | validation: 1.0717679800472326]
	TIME [epoch: 8.36 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4878520253174718		[learning rate: 0.019324]
	Learning Rate: 0.0193237
	LOSS [training: 1.4878520253174718 | validation: 1.1689431879759469]
	TIME [epoch: 8.33 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.364697803424565		[learning rate: 0.019318]
	Learning Rate: 0.0193178
	LOSS [training: 1.364697803424565 | validation: 1.1319861083539737]
	TIME [epoch: 8.38 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.527555883795581		[learning rate: 0.019312]
	Learning Rate: 0.0193117
	LOSS [training: 1.527555883795581 | validation: 1.2463346406450952]
	TIME [epoch: 8.32 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.557850671366664		[learning rate: 0.019306]
	Learning Rate: 0.0193057
	LOSS [training: 1.557850671366664 | validation: 1.343445417108161]
	TIME [epoch: 8.31 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6868245856584863		[learning rate: 0.0193]
	Learning Rate: 0.0192996
	LOSS [training: 1.6868245856584863 | validation: 3.3707317331519935]
	TIME [epoch: 8.3 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.091137860310483		[learning rate: 0.019294]
	Learning Rate: 0.0192935
	LOSS [training: 2.091137860310483 | validation: 1.710755189971369]
	TIME [epoch: 8.32 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3728545746972234		[learning rate: 0.019287]
	Learning Rate: 0.0192874
	LOSS [training: 1.3728545746972234 | validation: 1.1396869265980203]
	TIME [epoch: 8.35 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3912375964673367		[learning rate: 0.019281]
	Learning Rate: 0.0192813
	LOSS [training: 1.3912375964673367 | validation: 1.532876324081458]
	TIME [epoch: 8.33 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.257508040826748		[learning rate: 0.019275]
	Learning Rate: 0.0192751
	LOSS [training: 1.257508040826748 | validation: 3.3299777598111207]
	TIME [epoch: 8.34 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7130492007691747		[learning rate: 0.019269]
	Learning Rate: 0.0192689
	LOSS [training: 1.7130492007691747 | validation: 1.0134516517979424]
	TIME [epoch: 8.31 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1226152590500953		[learning rate: 0.019263]
	Learning Rate: 0.0192627
	LOSS [training: 1.1226152590500953 | validation: 0.9893384854858187]
	TIME [epoch: 8.33 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5539831847083794		[learning rate: 0.019256]
	Learning Rate: 0.0192565
	LOSS [training: 1.5539831847083794 | validation: 1.616428762149091]
	TIME [epoch: 8.3 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3574128654887254		[learning rate: 0.01925]
	Learning Rate: 0.0192502
	LOSS [training: 1.3574128654887254 | validation: 1.7818403926522521]
	TIME [epoch: 8.34 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.355316199745225		[learning rate: 0.019244]
	Learning Rate: 0.0192439
	LOSS [training: 1.355316199745225 | validation: 1.4956763141955665]
	TIME [epoch: 8.34 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.294215818537569		[learning rate: 0.019238]
	Learning Rate: 0.0192376
	LOSS [training: 1.294215818537569 | validation: 1.2262455900127311]
	TIME [epoch: 8.31 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2990854286582352		[learning rate: 0.019231]
	Learning Rate: 0.0192313
	LOSS [training: 1.2990854286582352 | validation: 1.5731465171454557]
	TIME [epoch: 8.31 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.406389582693067		[learning rate: 0.019225]
	Learning Rate: 0.0192249
	LOSS [training: 1.406389582693067 | validation: 1.1170023444342028]
	TIME [epoch: 8.33 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3000017029840054		[learning rate: 0.019218]
	Learning Rate: 0.0192185
	LOSS [training: 1.3000017029840054 | validation: 0.8996236569579239]
	TIME [epoch: 8.31 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2042854923649016		[learning rate: 0.019212]
	Learning Rate: 0.0192121
	LOSS [training: 1.2042854923649016 | validation: 1.1412965549934009]
	TIME [epoch: 8.36 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3081840956789832		[learning rate: 0.019206]
	Learning Rate: 0.0192056
	LOSS [training: 1.3081840956789832 | validation: 1.2428269124925944]
	TIME [epoch: 8.36 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7001258784936335		[learning rate: 0.019199]
	Learning Rate: 0.0191992
	LOSS [training: 1.7001258784936335 | validation: 1.0387420503629397]
	TIME [epoch: 8.33 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1095585262789238		[learning rate: 0.019193]
	Learning Rate: 0.0191927
	LOSS [training: 1.1095585262789238 | validation: 1.4228765048574272]
	TIME [epoch: 8.32 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4261427320160944		[learning rate: 0.019186]
	Learning Rate: 0.0191861
	LOSS [training: 1.4261427320160944 | validation: 1.2473247257650868]
	TIME [epoch: 8.31 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2296291392480234		[learning rate: 0.01918]
	Learning Rate: 0.0191796
	LOSS [training: 1.2296291392480234 | validation: 1.6031636830451435]
	TIME [epoch: 8.33 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.870772949529214		[learning rate: 0.019173]
	Learning Rate: 0.019173
	LOSS [training: 1.870772949529214 | validation: 1.0237031134739727]
	TIME [epoch: 8.33 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2014247755798098		[learning rate: 0.019166]
	Learning Rate: 0.0191664
	LOSS [training: 1.2014247755798098 | validation: 1.887143646264387]
	TIME [epoch: 8.31 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5996169622316618		[learning rate: 0.01916]
	Learning Rate: 0.0191598
	LOSS [training: 1.5996169622316618 | validation: 0.9617111641247149]
	TIME [epoch: 8.3 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1564124855831661		[learning rate: 0.019153]
	Learning Rate: 0.0191532
	LOSS [training: 1.1564124855831661 | validation: 1.1643337350667542]
	TIME [epoch: 8.31 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3610114792156538		[learning rate: 0.019146]
	Learning Rate: 0.0191465
	LOSS [training: 1.3610114792156538 | validation: 1.065641198379922]
	TIME [epoch: 8.3 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1937643072015438		[learning rate: 0.01914]
	Learning Rate: 0.0191398
	LOSS [training: 1.1937643072015438 | validation: 1.0423535604716547]
	TIME [epoch: 8.36 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.397773824133702		[learning rate: 0.019133]
	Learning Rate: 0.0191331
	LOSS [training: 1.397773824133702 | validation: 0.9451377677887461]
	TIME [epoch: 8.31 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1714285687388528		[learning rate: 0.019126]
	Learning Rate: 0.0191263
	LOSS [training: 1.1714285687388528 | validation: 1.1632651153382731]
	TIME [epoch: 8.31 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2837970170540238		[learning rate: 0.01912]
	Learning Rate: 0.0191196
	LOSS [training: 1.2837970170540238 | validation: 1.3979446499421444]
	TIME [epoch: 8.33 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2917661006403605		[learning rate: 0.019113]
	Learning Rate: 0.0191128
	LOSS [training: 1.2917661006403605 | validation: 1.0764378524951128]
	TIME [epoch: 8.32 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.137610413473423		[learning rate: 0.019106]
	Learning Rate: 0.019106
	LOSS [training: 1.137610413473423 | validation: 0.8988087574652223]
	TIME [epoch: 8.34 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1377759288479097		[learning rate: 0.019099]
	Learning Rate: 0.0190991
	LOSS [training: 1.1377759288479097 | validation: 2.2483156718869832]
	TIME [epoch: 8.32 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.450626372804824		[learning rate: 0.019092]
	Learning Rate: 0.0190922
	LOSS [training: 1.450626372804824 | validation: 1.3799529611577794]
	TIME [epoch: 8.3 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1479894015579923		[learning rate: 0.019085]
	Learning Rate: 0.0190853
	LOSS [training: 1.1479894015579923 | validation: 1.4910668968124456]
	TIME [epoch: 8.31 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2015316926615693		[learning rate: 0.019078]
	Learning Rate: 0.0190784
	LOSS [training: 1.2015316926615693 | validation: 2.8845943897695583]
	TIME [epoch: 8.28 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6094867438359102		[learning rate: 0.019071]
	Learning Rate: 0.0190715
	LOSS [training: 1.6094867438359102 | validation: 2.3800987359594385]
	TIME [epoch: 8.29 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3523931530978113		[learning rate: 0.019065]
	Learning Rate: 0.0190645
	LOSS [training: 1.3523931530978113 | validation: 1.2486678386746193]
	TIME [epoch: 8.36 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1587655912883001		[learning rate: 0.019058]
	Learning Rate: 0.0190575
	LOSS [training: 1.1587655912883001 | validation: 1.605847555830617]
	TIME [epoch: 8.31 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4874885585727133		[learning rate: 0.019051]
	Learning Rate: 0.0190505
	LOSS [training: 1.4874885585727133 | validation: 1.4346521706811737]
	TIME [epoch: 8.32 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4514806919194787		[learning rate: 0.019043]
	Learning Rate: 0.0190435
	LOSS [training: 1.4514806919194787 | validation: 1.4149745755037675]
	TIME [epoch: 8.3 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2699296575729127		[learning rate: 0.019036]
	Learning Rate: 0.0190364
	LOSS [training: 1.2699296575729127 | validation: 1.0345455776668264]
	TIME [epoch: 8.31 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2231480655950768		[learning rate: 0.019029]
	Learning Rate: 0.0190293
	LOSS [training: 1.2231480655950768 | validation: 1.48264279509096]
	TIME [epoch: 8.34 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7913281929985758		[learning rate: 0.019022]
	Learning Rate: 0.0190222
	LOSS [training: 1.7913281929985758 | validation: 0.9756194180852318]
	TIME [epoch: 8.37 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3525441571689638		[learning rate: 0.019015]
	Learning Rate: 0.019015
	LOSS [training: 1.3525441571689638 | validation: 1.5279210993857935]
	TIME [epoch: 8.32 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2473956709352096		[learning rate: 0.019008]
	Learning Rate: 0.0190079
	LOSS [training: 1.2473956709352096 | validation: 1.5758715122331854]
	TIME [epoch: 8.3 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1748800116094509		[learning rate: 0.019001]
	Learning Rate: 0.0190007
	LOSS [training: 1.1748800116094509 | validation: 0.7749338467113412]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_323.pth
	Model improved!!!
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3770816372511647		[learning rate: 0.018993]
	Learning Rate: 0.0189935
	LOSS [training: 1.3770816372511647 | validation: 1.850234713118546]
	TIME [epoch: 8.28 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4546678427189486		[learning rate: 0.018986]
	Learning Rate: 0.0189862
	LOSS [training: 2.4546678427189486 | validation: 1.8508764610065556]
	TIME [epoch: 8.31 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2507879138779687		[learning rate: 0.018979]
	Learning Rate: 0.018979
	LOSS [training: 1.2507879138779687 | validation: 1.2975472534744061]
	TIME [epoch: 8.31 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0621235212405498		[learning rate: 0.018972]
	Learning Rate: 0.0189717
	LOSS [training: 1.0621235212405498 | validation: 1.1185617224050586]
	TIME [epoch: 8.31 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.301716187956426		[learning rate: 0.018964]
	Learning Rate: 0.0189644
	LOSS [training: 1.301716187956426 | validation: 1.4764419570513256]
	TIME [epoch: 8.31 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2162951426644228		[learning rate: 0.018957]
	Learning Rate: 0.018957
	LOSS [training: 1.2162951426644228 | validation: 0.8565608792257255]
	TIME [epoch: 8.3 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2292607364035815		[learning rate: 0.01895]
	Learning Rate: 0.0189497
	LOSS [training: 1.2292607364035815 | validation: 0.9448098499443568]
	TIME [epoch: 8.3 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2211365632695443		[learning rate: 0.018942]
	Learning Rate: 0.0189423
	LOSS [training: 1.2211365632695443 | validation: 1.1621111083723321]
	TIME [epoch: 8.35 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.289392795307101		[learning rate: 0.018935]
	Learning Rate: 0.0189349
	LOSS [training: 1.289392795307101 | validation: 1.0872063992140961]
	TIME [epoch: 8.33 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0804003972336127		[learning rate: 0.018927]
	Learning Rate: 0.0189274
	LOSS [training: 1.0804003972336127 | validation: 0.7875583775584217]
	TIME [epoch: 8.32 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1824946088544654		[learning rate: 0.01892]
	Learning Rate: 0.01892
	LOSS [training: 1.1824946088544654 | validation: 1.1411518905381073]
	TIME [epoch: 8.29 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3053757192501487		[learning rate: 0.018912]
	Learning Rate: 0.0189125
	LOSS [training: 1.3053757192501487 | validation: 1.5740123544004199]
	TIME [epoch: 8.29 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3018768027344274		[learning rate: 0.018905]
	Learning Rate: 0.018905
	LOSS [training: 1.3018768027344274 | validation: 0.9351282781173111]
	TIME [epoch: 8.33 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2831141785243771		[learning rate: 0.018897]
	Learning Rate: 0.0188974
	LOSS [training: 1.2831141785243771 | validation: 1.1137552326395612]
	TIME [epoch: 8.32 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2079922621247758		[learning rate: 0.01889]
	Learning Rate: 0.0188899
	LOSS [training: 1.2079922621247758 | validation: 1.2002561915667225]
	TIME [epoch: 8.3 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.13819993777516		[learning rate: 0.018882]
	Learning Rate: 0.0188823
	LOSS [training: 1.13819993777516 | validation: 1.8246815858999086]
	TIME [epoch: 8.32 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.388984545702645		[learning rate: 0.018875]
	Learning Rate: 0.0188747
	LOSS [training: 1.388984545702645 | validation: 1.9885489107342642]
	TIME [epoch: 8.34 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1018006026556704		[learning rate: 0.018867]
	Learning Rate: 0.0188671
	LOSS [training: 1.1018006026556704 | validation: 2.109888044518814]
	TIME [epoch: 8.34 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3410851751796136		[learning rate: 0.018859]
	Learning Rate: 0.0188594
	LOSS [training: 1.3410851751796136 | validation: 1.4983308160746052]
	TIME [epoch: 8.32 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2791808476764452		[learning rate: 0.018852]
	Learning Rate: 0.0188517
	LOSS [training: 1.2791808476764452 | validation: 0.9654670343616143]
	TIME [epoch: 8.27 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.221542705112267		[learning rate: 0.018844]
	Learning Rate: 0.018844
	LOSS [training: 1.221542705112267 | validation: 1.0146541467194146]
	TIME [epoch: 8.27 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.103761740999007		[learning rate: 0.018836]
	Learning Rate: 0.0188363
	LOSS [training: 1.103761740999007 | validation: 0.9895281295871787]
	TIME [epoch: 8.27 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.297403132459893		[learning rate: 0.018829]
	Learning Rate: 0.0188286
	LOSS [training: 1.297403132459893 | validation: 1.0392601585985017]
	TIME [epoch: 8.3 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1115930051002363		[learning rate: 0.018821]
	Learning Rate: 0.0188208
	LOSS [training: 1.1115930051002363 | validation: 1.5920672089887988]
	TIME [epoch: 8.38 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.282719733661415		[learning rate: 0.018813]
	Learning Rate: 0.018813
	LOSS [training: 1.282719733661415 | validation: 1.0082214846397792]
	TIME [epoch: 8.34 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0307646262885541		[learning rate: 0.018805]
	Learning Rate: 0.0188052
	LOSS [training: 1.0307646262885541 | validation: 1.3274966290287482]
	TIME [epoch: 8.3 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2886451574540567		[learning rate: 0.018797]
	Learning Rate: 0.0187973
	LOSS [training: 1.2886451574540567 | validation: 1.079237497383494]
	TIME [epoch: 8.29 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9932899634032506		[learning rate: 0.018789]
	Learning Rate: 0.0187894
	LOSS [training: 0.9932899634032506 | validation: 1.1843181453378069]
	TIME [epoch: 8.29 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2371768839671107		[learning rate: 0.018782]
	Learning Rate: 0.0187815
	LOSS [training: 1.2371768839671107 | validation: 1.6299735467135965]
	TIME [epoch: 8.31 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1841395383776527		[learning rate: 0.018774]
	Learning Rate: 0.0187736
	LOSS [training: 1.1841395383776527 | validation: 0.9897481417774449]
	TIME [epoch: 8.36 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1983662553248708		[learning rate: 0.018766]
	Learning Rate: 0.0187657
	LOSS [training: 1.1983662553248708 | validation: 1.0547463940800959]
	TIME [epoch: 8.32 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3349195036262813		[learning rate: 0.018758]
	Learning Rate: 0.0187577
	LOSS [training: 1.3349195036262813 | validation: 2.0101107982218585]
	TIME [epoch: 8.31 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3477190166881141		[learning rate: 0.01875]
	Learning Rate: 0.0187497
	LOSS [training: 1.3477190166881141 | validation: 1.2076042645488996]
	TIME [epoch: 8.32 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1158611459538352		[learning rate: 0.018742]
	Learning Rate: 0.0187417
	LOSS [training: 1.1158611459538352 | validation: 1.0139758065390758]
	TIME [epoch: 8.3 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0631415659982408		[learning rate: 0.018734]
	Learning Rate: 0.0187337
	LOSS [training: 1.0631415659982408 | validation: 1.0314233073967343]
	TIME [epoch: 8.31 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3269196879829297		[learning rate: 0.018726]
	Learning Rate: 0.0187256
	LOSS [training: 1.3269196879829297 | validation: 0.9745312097761766]
	TIME [epoch: 8.33 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0735594766353957		[learning rate: 0.018718]
	Learning Rate: 0.0187175
	LOSS [training: 1.0735594766353957 | validation: 1.4349684134942227]
	TIME [epoch: 8.3 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3169853425535436		[learning rate: 0.018709]
	Learning Rate: 0.0187094
	LOSS [training: 1.3169853425535436 | validation: 1.4129636022069842]
	TIME [epoch: 8.35 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3906862712976795		[learning rate: 0.018701]
	Learning Rate: 0.0187013
	LOSS [training: 1.3906862712976795 | validation: 1.3783406625591477]
	TIME [epoch: 8.3 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0240644880388636		[learning rate: 0.018693]
	Learning Rate: 0.0186931
	LOSS [training: 1.0240644880388636 | validation: 0.9993711285572768]
	TIME [epoch: 8.31 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1568246075174446		[learning rate: 0.018685]
	Learning Rate: 0.0186849
	LOSS [training: 1.1568246075174446 | validation: 1.3559409418443829]
	TIME [epoch: 8.36 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0805955731811414		[learning rate: 0.018677]
	Learning Rate: 0.0186767
	LOSS [training: 2.0805955731811414 | validation: 0.8710287521016098]
	TIME [epoch: 8.34 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1186381473981026		[learning rate: 0.018668]
	Learning Rate: 0.0186685
	LOSS [training: 1.1186381473981026 | validation: 1.7005795133398252]
	TIME [epoch: 8.31 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4324131709446357		[learning rate: 0.01866]
	Learning Rate: 0.0186602
	LOSS [training: 1.4324131709446357 | validation: 0.9866722118078884]
	TIME [epoch: 8.32 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9117656487176999		[learning rate: 0.018652]
	Learning Rate: 0.018652
	LOSS [training: 0.9117656487176999 | validation: 0.9529026394873661]
	TIME [epoch: 8.3 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0793517939499362		[learning rate: 0.018644]
	Learning Rate: 0.0186437
	LOSS [training: 1.0793517939499362 | validation: 1.3186445696388422]
	TIME [epoch: 8.3 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0968658697040972		[learning rate: 0.018635]
	Learning Rate: 0.0186353
	LOSS [training: 1.0968658697040972 | validation: 0.853181629585183]
	TIME [epoch: 8.34 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0060378585381426		[learning rate: 0.018627]
	Learning Rate: 0.018627
	LOSS [training: 1.0060378585381426 | validation: 0.9877976783912861]
	TIME [epoch: 8.3 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1145467926823356		[learning rate: 0.018619]
	Learning Rate: 0.0186186
	LOSS [training: 1.1145467926823356 | validation: 1.4600801279712003]
	TIME [epoch: 8.28 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4292127163122428		[learning rate: 0.01861]
	Learning Rate: 0.0186102
	LOSS [training: 1.4292127163122428 | validation: 0.9244308264541726]
	TIME [epoch: 8.31 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2586823252149966		[learning rate: 0.018602]
	Learning Rate: 0.0186018
	LOSS [training: 1.2586823252149966 | validation: 0.6984969747069822]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_374.pth
	Model improved!!!
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0154635589018286		[learning rate: 0.018593]
	Learning Rate: 0.0185934
	LOSS [training: 1.0154635589018286 | validation: 1.245543691077558]
	TIME [epoch: 8.34 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0562253665831294		[learning rate: 0.018585]
	Learning Rate: 0.0185849
	LOSS [training: 1.0562253665831294 | validation: 1.0664015040525325]
	TIME [epoch: 8.32 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1195255374842035		[learning rate: 0.018576]
	Learning Rate: 0.0185764
	LOSS [training: 1.1195255374842035 | validation: 0.955601056195432]
	TIME [epoch: 8.32 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9801751491844835		[learning rate: 0.018568]
	Learning Rate: 0.0185679
	LOSS [training: 0.9801751491844835 | validation: 1.2556821740290134]
	TIME [epoch: 8.31 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.203136583168255		[learning rate: 0.018559]
	Learning Rate: 0.0185594
	LOSS [training: 1.203136583168255 | validation: 0.8892803398131006]
	TIME [epoch: 8.3 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8670437367193775		[learning rate: 0.018551]
	Learning Rate: 0.0185508
	LOSS [training: 0.8670437367193775 | validation: 0.870433723143668]
	TIME [epoch: 8.31 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2152294903544107		[learning rate: 0.018542]
	Learning Rate: 0.0185422
	LOSS [training: 1.2152294903544107 | validation: 0.9866043723482374]
	TIME [epoch: 8.34 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1743088958329508		[learning rate: 0.018534]
	Learning Rate: 0.0185336
	LOSS [training: 1.1743088958329508 | validation: 1.3376532922995108]
	TIME [epoch: 8.32 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.13080953997694		[learning rate: 0.018525]
	Learning Rate: 0.018525
	LOSS [training: 1.13080953997694 | validation: 0.9926309296251954]
	TIME [epoch: 8.33 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.172041414524599		[learning rate: 0.018516]
	Learning Rate: 0.0185163
	LOSS [training: 2.172041414524599 | validation: 3.2408737149813582]
	TIME [epoch: 8.31 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8531237071799174		[learning rate: 0.018508]
	Learning Rate: 0.0185077
	LOSS [training: 1.8531237071799174 | validation: 1.0722912994677534]
	TIME [epoch: 8.31 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0217895761299411		[learning rate: 0.018499]
	Learning Rate: 0.018499
	LOSS [training: 1.0217895761299411 | validation: 0.8071538281630173]
	TIME [epoch: 8.33 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.961595082155275		[learning rate: 0.01849]
	Learning Rate: 0.0184902
	LOSS [training: 0.961595082155275 | validation: 0.6968001277438596]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_387.pth
	Model improved!!!
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8194893575501863		[learning rate: 0.018481]
	Learning Rate: 0.0184815
	LOSS [training: 0.8194893575501863 | validation: 1.298930693314727]
	TIME [epoch: 8.31 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2049719604329905		[learning rate: 0.018473]
	Learning Rate: 0.0184727
	LOSS [training: 1.2049719604329905 | validation: 0.8639557168386567]
	TIME [epoch: 8.28 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8857895503007885		[learning rate: 0.018464]
	Learning Rate: 0.0184639
	LOSS [training: 0.8857895503007885 | validation: 1.0751849548974342]
	TIME [epoch: 8.3 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7255605824622755		[learning rate: 0.018455]
	Learning Rate: 0.0184551
	LOSS [training: 1.7255605824622755 | validation: 0.9935362241271097]
	TIME [epoch: 8.32 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1309944070151163		[learning rate: 0.018446]
	Learning Rate: 0.0184463
	LOSS [training: 1.1309944070151163 | validation: 0.7185996309124068]
	TIME [epoch: 8.34 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3002460818298207		[learning rate: 0.018437]
	Learning Rate: 0.0184374
	LOSS [training: 1.3002460818298207 | validation: 0.7842898630039585]
	TIME [epoch: 8.31 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9618208074995215		[learning rate: 0.018429]
	Learning Rate: 0.0184285
	LOSS [training: 0.9618208074995215 | validation: 0.7596443647361728]
	TIME [epoch: 8.3 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1774733388655467		[learning rate: 0.01842]
	Learning Rate: 0.0184196
	LOSS [training: 1.1774733388655467 | validation: 0.9225767274618815]
	TIME [epoch: 8.3 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9784558622485036		[learning rate: 0.018411]
	Learning Rate: 0.0184107
	LOSS [training: 0.9784558622485036 | validation: 1.1314725174696578]
	TIME [epoch: 8.33 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3813121519048184		[learning rate: 0.018402]
	Learning Rate: 0.0184017
	LOSS [training: 1.3813121519048184 | validation: 0.792433257240591]
	TIME [epoch: 8.34 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0784489451091508		[learning rate: 0.018393]
	Learning Rate: 0.0183928
	LOSS [training: 1.0784489451091508 | validation: 1.1783603356634402]
	TIME [epoch: 8.34 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0539468823747133		[learning rate: 0.018384]
	Learning Rate: 0.0183838
	LOSS [training: 1.0539468823747133 | validation: 1.0963620101130434]
	TIME [epoch: 8.3 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0926129942386664		[learning rate: 0.018375]
	Learning Rate: 0.0183747
	LOSS [training: 1.0926129942386664 | validation: 0.9653850667966034]
	TIME [epoch: 8.3 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2069053812057675		[learning rate: 0.018366]
	Learning Rate: 0.0183657
	LOSS [training: 1.2069053812057675 | validation: 1.0949798271399729]
	TIME [epoch: 8.29 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1489187764430373		[learning rate: 0.018357]
	Learning Rate: 0.0183566
	LOSS [training: 1.1489187764430373 | validation: 0.7999219554630854]
	TIME [epoch: 8.28 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1301674995684536		[learning rate: 0.018348]
	Learning Rate: 0.0183475
	LOSS [training: 1.1301674995684536 | validation: 1.7263539095392426]
	TIME [epoch: 8.35 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2220715167427219		[learning rate: 0.018338]
	Learning Rate: 0.0183384
	LOSS [training: 1.2220715167427219 | validation: 0.8229755701082633]
	TIME [epoch: 8.31 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0337939618339487		[learning rate: 0.018329]
	Learning Rate: 0.0183293
	LOSS [training: 1.0337939618339487 | validation: 1.2264330301878665]
	TIME [epoch: 8.31 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9894359781347628		[learning rate: 0.01832]
	Learning Rate: 0.0183201
	LOSS [training: 0.9894359781347628 | validation: 1.198893547798411]
	TIME [epoch: 8.3 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4110283221774433		[learning rate: 0.018311]
	Learning Rate: 0.0183109
	LOSS [training: 1.4110283221774433 | validation: 1.03913061065075]
	TIME [epoch: 8.3 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9355649585370075		[learning rate: 0.018302]
	Learning Rate: 0.0183017
	LOSS [training: 0.9355649585370075 | validation: 1.2502756445168015]
	TIME [epoch: 8.32 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1167767270457147		[learning rate: 0.018293]
	Learning Rate: 0.0182925
	LOSS [training: 1.1167767270457147 | validation: 1.752237646202824]
	TIME [epoch: 8.37 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3140647811610053		[learning rate: 0.018283]
	Learning Rate: 0.0182833
	LOSS [training: 1.3140647811610053 | validation: 1.0271259914799793]
	TIME [epoch: 8.32 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.167923470059494		[learning rate: 0.018274]
	Learning Rate: 0.018274
	LOSS [training: 1.167923470059494 | validation: 1.0174782853086348]
	TIME [epoch: 8.29 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.037342035403614		[learning rate: 0.018265]
	Learning Rate: 0.0182647
	LOSS [training: 1.037342035403614 | validation: 1.1033608167165727]
	TIME [epoch: 8.3 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3784528329139785		[learning rate: 0.018255]
	Learning Rate: 0.0182554
	LOSS [training: 1.3784528329139785 | validation: 1.0783273050269813]
	TIME [epoch: 8.3 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1144716499226952		[learning rate: 0.018246]
	Learning Rate: 0.018246
	LOSS [training: 1.1144716499226952 | validation: 1.179138074186191]
	TIME [epoch: 8.31 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9841789623914226		[learning rate: 0.018237]
	Learning Rate: 0.0182367
	LOSS [training: 0.9841789623914226 | validation: 0.7957694495011819]
	TIME [epoch: 8.31 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1029362535418794		[learning rate: 0.018227]
	Learning Rate: 0.0182273
	LOSS [training: 1.1029362535418794 | validation: 2.350811265541119]
	TIME [epoch: 8.31 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6549083974499723		[learning rate: 0.018218]
	Learning Rate: 0.0182179
	LOSS [training: 1.6549083974499723 | validation: 1.0131086966845193]
	TIME [epoch: 8.3 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.120718484402909		[learning rate: 0.018208]
	Learning Rate: 0.0182085
	LOSS [training: 1.120718484402909 | validation: 0.8076678342688591]
	TIME [epoch: 8.3 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9871419091159994		[learning rate: 0.018199]
	Learning Rate: 0.018199
	LOSS [training: 0.9871419091159994 | validation: 1.141807875396137]
	TIME [epoch: 8.31 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0658244922861229		[learning rate: 0.01819]
	Learning Rate: 0.0181895
	LOSS [training: 1.0658244922861229 | validation: 0.8315002782468499]
	TIME [epoch: 8.34 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.746021223808402		[learning rate: 0.01818]
	Learning Rate: 0.01818
	LOSS [training: 0.746021223808402 | validation: 2.856155887714423]
	TIME [epoch: 8.33 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1145285194874974		[learning rate: 0.018171]
	Learning Rate: 0.0181705
	LOSS [training: 2.1145285194874974 | validation: 1.1505516679990158]
	TIME [epoch: 8.32 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2228938725897203		[learning rate: 0.018161]
	Learning Rate: 0.018161
	LOSS [training: 1.2228938725897203 | validation: 1.141431202798576]
	TIME [epoch: 8.3 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0872202222418004		[learning rate: 0.018151]
	Learning Rate: 0.0181514
	LOSS [training: 1.0872202222418004 | validation: 1.32236059154739]
	TIME [epoch: 8.29 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0026421608472549		[learning rate: 0.018142]
	Learning Rate: 0.0181418
	LOSS [training: 1.0026421608472549 | validation: 0.9801025388518212]
	TIME [epoch: 8.32 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.078496877524036		[learning rate: 0.018132]
	Learning Rate: 0.0181322
	LOSS [training: 1.078496877524036 | validation: 0.980497522318991]
	TIME [epoch: 8.31 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.248629078109931		[learning rate: 0.018123]
	Learning Rate: 0.0181226
	LOSS [training: 1.248629078109931 | validation: 1.239918958558746]
	TIME [epoch: 8.31 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1435855552499774		[learning rate: 0.018113]
	Learning Rate: 0.0181129
	LOSS [training: 1.1435855552499774 | validation: 1.062990632062532]
	TIME [epoch: 8.31 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0169954492773001		[learning rate: 0.018103]
	Learning Rate: 0.0181032
	LOSS [training: 1.0169954492773001 | validation: 1.0249723563689148]
	TIME [epoch: 8.35 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0802739186888257		[learning rate: 0.018094]
	Learning Rate: 0.0180936
	LOSS [training: 1.0802739186888257 | validation: 0.9308875656094806]
	TIME [epoch: 8.28 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2004017826054298		[learning rate: 0.018084]
	Learning Rate: 0.0180838
	LOSS [training: 1.2004017826054298 | validation: 1.0933163319095538]
	TIME [epoch: 8.31 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.100399810401063		[learning rate: 0.018074]
	Learning Rate: 0.0180741
	LOSS [training: 1.100399810401063 | validation: 0.8420399890656991]
	TIME [epoch: 8.28 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0239672587877722		[learning rate: 0.018064]
	Learning Rate: 0.0180643
	LOSS [training: 1.0239672587877722 | validation: 1.0399152927613082]
	TIME [epoch: 8.27 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9976481949576098		[learning rate: 0.018055]
	Learning Rate: 0.0180545
	LOSS [training: 0.9976481949576098 | validation: 0.8074743930831727]
	TIME [epoch: 8.35 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2507868847588162		[learning rate: 0.018045]
	Learning Rate: 0.0180447
	LOSS [training: 1.2507868847588162 | validation: 0.816818495514575]
	TIME [epoch: 8.36 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8829554794604668		[learning rate: 0.018035]
	Learning Rate: 0.0180349
	LOSS [training: 0.8829554794604668 | validation: 1.5194090098060222]
	TIME [epoch: 8.34 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9608852184881994		[learning rate: 0.018025]
	Learning Rate: 0.0180251
	LOSS [training: 0.9608852184881994 | validation: 1.2811705160446474]
	TIME [epoch: 8.32 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3381965680956798		[learning rate: 0.018015]
	Learning Rate: 0.0180152
	LOSS [training: 1.3381965680956798 | validation: 0.843928059349221]
	TIME [epoch: 8.3 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2279117218214401		[learning rate: 0.018005]
	Learning Rate: 0.0180053
	LOSS [training: 1.2279117218214401 | validation: 1.7277057785694305]
	TIME [epoch: 8.3 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.241634505619804		[learning rate: 0.017995]
	Learning Rate: 0.0179954
	LOSS [training: 1.241634505619804 | validation: 0.9596670497169255]
	TIME [epoch: 8.32 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1843389692515045		[learning rate: 0.017985]
	Learning Rate: 0.0179854
	LOSS [training: 1.1843389692515045 | validation: 0.7029835002869939]
	TIME [epoch: 8.31 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0754537412785292		[learning rate: 0.017975]
	Learning Rate: 0.0179755
	LOSS [training: 1.0754537412785292 | validation: 0.9853402837507772]
	TIME [epoch: 8.38 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1016857791875698		[learning rate: 0.017965]
	Learning Rate: 0.0179655
	LOSS [training: 1.1016857791875698 | validation: 1.1421318410559185]
	TIME [epoch: 8.32 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0280728480824386		[learning rate: 0.017955]
	Learning Rate: 0.0179555
	LOSS [training: 1.0280728480824386 | validation: 0.9217836779858051]
	TIME [epoch: 8.3 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9338256574818452		[learning rate: 0.017945]
	Learning Rate: 0.0179455
	LOSS [training: 0.9338256574818452 | validation: 1.0447112861769696]
	TIME [epoch: 8.31 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1096188222377985		[learning rate: 0.017935]
	Learning Rate: 0.0179354
	LOSS [training: 1.1096188222377985 | validation: 0.7524297533192034]
	TIME [epoch: 8.32 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.465796272000028		[learning rate: 0.017925]
	Learning Rate: 0.0179253
	LOSS [training: 1.465796272000028 | validation: 1.823280332140876]
	TIME [epoch: 8.33 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1561513631768419		[learning rate: 0.017915]
	Learning Rate: 0.0179152
	LOSS [training: 1.1561513631768419 | validation: 0.8423444483261419]
	TIME [epoch: 8.35 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0183736019615826		[learning rate: 0.017905]
	Learning Rate: 0.0179051
	LOSS [training: 1.0183736019615826 | validation: 1.2499277995906064]
	TIME [epoch: 8.32 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0592747056067953		[learning rate: 0.017895]
	Learning Rate: 0.017895
	LOSS [training: 1.0592747056067953 | validation: 1.0575753092293791]
	TIME [epoch: 8.36 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0162460919733027		[learning rate: 0.017885]
	Learning Rate: 0.0178848
	LOSS [training: 1.0162460919733027 | validation: 0.7220521760966432]
	TIME [epoch: 8.32 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9814463399367314		[learning rate: 0.017875]
	Learning Rate: 0.0178747
	LOSS [training: 0.9814463399367314 | validation: 0.7262951792335091]
	TIME [epoch: 8.32 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0018342298202756		[learning rate: 0.017864]
	Learning Rate: 0.0178645
	LOSS [training: 1.0018342298202756 | validation: 0.7838467019141095]
	TIME [epoch: 8.34 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.782807992844614		[learning rate: 0.017854]
	Learning Rate: 0.0178542
	LOSS [training: 0.782807992844614 | validation: 1.3068173069181817]
	TIME [epoch: 8.32 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1477277169322557		[learning rate: 0.017844]
	Learning Rate: 0.017844
	LOSS [training: 1.1477277169322557 | validation: 1.339893590802128]
	TIME [epoch: 8.29 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1117533702743558		[learning rate: 0.017834]
	Learning Rate: 0.0178337
	LOSS [training: 1.1117533702743558 | validation: 1.0628504560684955]
	TIME [epoch: 8.32 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9157906982974042		[learning rate: 0.017823]
	Learning Rate: 0.0178235
	LOSS [training: 0.9157906982974042 | validation: 1.3205770341392193]
	TIME [epoch: 8.29 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1150408650523356		[learning rate: 0.017813]
	Learning Rate: 0.0178131
	LOSS [training: 1.1150408650523356 | validation: 0.7150219522255796]
	TIME [epoch: 8.32 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0099915502946446		[learning rate: 0.017803]
	Learning Rate: 0.0178028
	LOSS [training: 1.0099915502946446 | validation: 0.6540604228073673]
	TIME [epoch: 8.36 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_459.pth
	Model improved!!!
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.868502089315304		[learning rate: 0.017792]
	Learning Rate: 0.0177925
	LOSS [training: 0.868502089315304 | validation: 0.8861332557668272]
	TIME [epoch: 8.31 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.033157478441435		[learning rate: 0.017782]
	Learning Rate: 0.0177821
	LOSS [training: 1.033157478441435 | validation: 0.8891378679203705]
	TIME [epoch: 8.3 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8564789311996983		[learning rate: 0.017772]
	Learning Rate: 0.0177717
	LOSS [training: 0.8564789311996983 | validation: 0.8176946018708353]
	TIME [epoch: 8.3 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0368416136803769		[learning rate: 0.017761]
	Learning Rate: 0.0177613
	LOSS [training: 1.0368416136803769 | validation: 0.8944284763165704]
	TIME [epoch: 8.3 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8855750991123449		[learning rate: 0.017751]
	Learning Rate: 0.0177509
	LOSS [training: 0.8855750991123449 | validation: 0.6667399446597194]
	TIME [epoch: 8.34 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1301352454737519		[learning rate: 0.01774]
	Learning Rate: 0.0177404
	LOSS [training: 1.1301352454737519 | validation: 1.1457980022741578]
	TIME [epoch: 8.31 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0593192177422652		[learning rate: 0.01773]
	Learning Rate: 0.0177299
	LOSS [training: 1.0593192177422652 | validation: 0.7476904914558848]
	TIME [epoch: 8.3 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7919716615017044		[learning rate: 0.017719]
	Learning Rate: 0.0177194
	LOSS [training: 0.7919716615017044 | validation: 0.9801353014354811]
	TIME [epoch: 8.31 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9541968032352388		[learning rate: 0.017709]
	Learning Rate: 0.0177089
	LOSS [training: 0.9541968032352388 | validation: 1.312193641116401]
	TIME [epoch: 8.33 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9048305316366698		[learning rate: 0.017698]
	Learning Rate: 0.0176984
	LOSS [training: 0.9048305316366698 | validation: 1.199036709800446]
	TIME [epoch: 8.32 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9968612311246632		[learning rate: 0.017688]
	Learning Rate: 0.0176878
	LOSS [training: 0.9968612311246632 | validation: 0.7546027128147081]
	TIME [epoch: 8.35 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.024276803195499		[learning rate: 0.017677]
	Learning Rate: 0.0176772
	LOSS [training: 1.024276803195499 | validation: 0.6367780789252757]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_471.pth
	Model improved!!!
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9481201903312497		[learning rate: 0.017667]
	Learning Rate: 0.0176666
	LOSS [training: 0.9481201903312497 | validation: 0.5902043894105137]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_472.pth
	Model improved!!!
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8903158642515572		[learning rate: 0.017656]
	Learning Rate: 0.017656
	LOSS [training: 0.8903158642515572 | validation: 1.8003165971047816]
	TIME [epoch: 8.31 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.982589298017476		[learning rate: 0.017645]
	Learning Rate: 0.0176454
	LOSS [training: 0.982589298017476 | validation: 0.784253081433015]
	TIME [epoch: 8.28 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9800066745371534		[learning rate: 0.017635]
	Learning Rate: 0.0176347
	LOSS [training: 0.9800066745371534 | validation: 0.6335955181045582]
	TIME [epoch: 8.34 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.862719720664958		[learning rate: 0.017624]
	Learning Rate: 0.017624
	LOSS [training: 0.862719720664958 | validation: 0.5259490885936453]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_476.pth
	Model improved!!!
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8036888146470141		[learning rate: 0.017613]
	Learning Rate: 0.0176133
	LOSS [training: 0.8036888146470141 | validation: 0.8810472005825292]
	TIME [epoch: 8.31 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9844521049622117		[learning rate: 0.017603]
	Learning Rate: 0.0176026
	LOSS [training: 0.9844521049622117 | validation: 0.7252487354538524]
	TIME [epoch: 8.31 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.048044408331759		[learning rate: 0.017592]
	Learning Rate: 0.0175918
	LOSS [training: 1.048044408331759 | validation: 0.6353108139775339]
	TIME [epoch: 8.31 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7797017941650141		[learning rate: 0.017581]
	Learning Rate: 0.0175811
	LOSS [training: 0.7797017941650141 | validation: 0.6900602109754148]
	TIME [epoch: 8.32 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9487061456990151		[learning rate: 0.01757]
	Learning Rate: 0.0175703
	LOSS [training: 0.9487061456990151 | validation: 0.6834930114669056]
	TIME [epoch: 8.37 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9523458157146458		[learning rate: 0.017559]
	Learning Rate: 0.0175595
	LOSS [training: 0.9523458157146458 | validation: 0.8080727501400209]
	TIME [epoch: 8.32 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9090167078335911		[learning rate: 0.017549]
	Learning Rate: 0.0175486
	LOSS [training: 0.9090167078335911 | validation: 0.6760545047671012]
	TIME [epoch: 8.3 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7591085860907286		[learning rate: 0.017538]
	Learning Rate: 0.0175378
	LOSS [training: 0.7591085860907286 | validation: 1.096775868647085]
	TIME [epoch: 8.29 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0121039320701881		[learning rate: 0.017527]
	Learning Rate: 0.0175269
	LOSS [training: 1.0121039320701881 | validation: 0.4878982571607409]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_485.pth
	Model improved!!!
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1302297096155434		[learning rate: 0.017516]
	Learning Rate: 0.017516
	LOSS [training: 1.1302297096155434 | validation: 0.8679906555228996]
	TIME [epoch: 8.32 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7896560877104652		[learning rate: 0.017505]
	Learning Rate: 0.0175051
	LOSS [training: 0.7896560877104652 | validation: 0.9327275071043605]
	TIME [epoch: 8.3 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0576453882699521		[learning rate: 0.017494]
	Learning Rate: 0.0174942
	LOSS [training: 1.0576453882699521 | validation: 0.7509158426041816]
	TIME [epoch: 8.3 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9075464964226247		[learning rate: 0.017483]
	Learning Rate: 0.0174832
	LOSS [training: 0.9075464964226247 | validation: 1.1697878345267627]
	TIME [epoch: 8.31 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9782520486844936		[learning rate: 0.017472]
	Learning Rate: 0.0174722
	LOSS [training: 0.9782520486844936 | validation: 0.6960840691023595]
	TIME [epoch: 8.3 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0287327985157297		[learning rate: 0.017461]
	Learning Rate: 0.0174612
	LOSS [training: 1.0287327985157297 | validation: 0.7758272172794372]
	TIME [epoch: 8.31 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.947576679242188		[learning rate: 0.01745]
	Learning Rate: 0.0174502
	LOSS [training: 0.947576679242188 | validation: 0.7305294557059295]
	TIME [epoch: 8.34 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9357068945529604		[learning rate: 0.017439]
	Learning Rate: 0.0174392
	LOSS [training: 0.9357068945529604 | validation: 0.695709021514844]
	TIME [epoch: 8.33 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6966965462659573		[learning rate: 0.017428]
	Learning Rate: 0.0174281
	LOSS [training: 0.6966965462659573 | validation: 1.1579143304238122]
	TIME [epoch: 8.32 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1016838361260297		[learning rate: 0.017417]
	Learning Rate: 0.017417
	LOSS [training: 1.1016838361260297 | validation: 1.148304535605817]
	TIME [epoch: 8.3 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3594615577935247		[learning rate: 0.017406]
	Learning Rate: 0.0174059
	LOSS [training: 1.3594615577935247 | validation: 0.8483000395727867]
	TIME [epoch: 8.3 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9909876963949165		[learning rate: 0.017395]
	Learning Rate: 0.0173948
	LOSS [training: 0.9909876963949165 | validation: 0.8462298749497845]
	TIME [epoch: 8.33 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8622518076085987		[learning rate: 0.017384]
	Learning Rate: 0.0173837
	LOSS [training: 0.8622518076085987 | validation: 1.065901842537047]
	TIME [epoch: 8.3 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7933489060220442		[learning rate: 0.017373]
	Learning Rate: 0.0173725
	LOSS [training: 0.7933489060220442 | validation: 1.0992721343638627]
	TIME [epoch: 8.3 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8532129121867907		[learning rate: 0.017361]
	Learning Rate: 0.0173614
	LOSS [training: 0.8532129121867907 | validation: 0.6476739760231773]
	TIME [epoch: 8.33 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0604767439671274		[learning rate: 0.01735]
	Learning Rate: 0.0173502
	LOSS [training: 1.0604767439671274 | validation: 0.6360025898322093]
	TIME [epoch: 8.29 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2084001688115653		[learning rate: 0.017339]
	Learning Rate: 0.0173389
	LOSS [training: 1.2084001688115653 | validation: 1.1177543086688124]
	TIME [epoch: 8.3 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8640515176108942		[learning rate: 0.017328]
	Learning Rate: 0.0173277
	LOSS [training: 0.8640515176108942 | validation: 1.0883089784280884]
	TIME [epoch: 8.34 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0069248421738757		[learning rate: 0.017316]
	Learning Rate: 0.0173164
	LOSS [training: 1.0069248421738757 | validation: 0.9127346472799649]
	TIME [epoch: 8.3 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0001750854589002		[learning rate: 0.017305]
	Learning Rate: 0.0173052
	LOSS [training: 1.0001750854589002 | validation: 1.353349304561367]
	TIME [epoch: 8.33 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.227526635874964		[learning rate: 0.017294]
	Learning Rate: 0.0172939
	LOSS [training: 1.227526635874964 | validation: 1.3161002644944362]
	TIME [epoch: 8.31 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8640666529820513		[learning rate: 0.017283]
	Learning Rate: 0.0172826
	LOSS [training: 0.8640666529820513 | validation: 0.8534358881154664]
	TIME [epoch: 8.3 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0716426737097946		[learning rate: 0.017271]
	Learning Rate: 0.0172712
	LOSS [training: 1.0716426737097946 | validation: 0.6486029099882775]
	TIME [epoch: 8.31 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8184230848925892		[learning rate: 0.01726]
	Learning Rate: 0.0172599
	LOSS [training: 0.8184230848925892 | validation: 0.6289260687825338]
	TIME [epoch: 8.32 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9485228655433994		[learning rate: 0.017248]
	Learning Rate: 0.0172485
	LOSS [training: 0.9485228655433994 | validation: 0.7257045376325493]
	TIME [epoch: 8.29 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8368533837244367		[learning rate: 0.017237]
	Learning Rate: 0.0172371
	LOSS [training: 0.8368533837244367 | validation: 0.6227929666893776]
	TIME [epoch: 8.28 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8800100982702169		[learning rate: 0.017226]
	Learning Rate: 0.0172257
	LOSS [training: 0.8800100982702169 | validation: 0.7973864780101259]
	TIME [epoch: 8.32 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8760169082803175		[learning rate: 0.017214]
	Learning Rate: 0.0172142
	LOSS [training: 0.8760169082803175 | validation: 0.7031505687913269]
	TIME [epoch: 9.9 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.749332245661084		[learning rate: 0.017203]
	Learning Rate: 0.0172028
	LOSS [training: 0.749332245661084 | validation: 0.8647474135035145]
	TIME [epoch: 8.32 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.978364095580776		[learning rate: 0.017191]
	Learning Rate: 0.0171913
	LOSS [training: 0.978364095580776 | validation: 1.810780572848031]
	TIME [epoch: 8.28 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1059648183742599		[learning rate: 0.01718]
	Learning Rate: 0.0171798
	LOSS [training: 1.1059648183742599 | validation: 0.6807680812920727]
	TIME [epoch: 8.27 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9009988049353399		[learning rate: 0.017168]
	Learning Rate: 0.0171683
	LOSS [training: 0.9009988049353399 | validation: 0.7109573863782694]
	TIME [epoch: 8.27 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8229566266647987		[learning rate: 0.017157]
	Learning Rate: 0.0171567
	LOSS [training: 0.8229566266647987 | validation: 1.1488483767419742]
	TIME [epoch: 8.27 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8684599715971584		[learning rate: 0.017145]
	Learning Rate: 0.0171452
	LOSS [training: 0.8684599715971584 | validation: 0.8604027136660448]
	TIME [epoch: 8.28 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.940022654203537		[learning rate: 0.017134]
	Learning Rate: 0.0171336
	LOSS [training: 0.940022654203537 | validation: 0.6777310337121686]
	TIME [epoch: 8.3 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9487490752267211		[learning rate: 0.017122]
	Learning Rate: 0.017122
	LOSS [training: 0.9487490752267211 | validation: 0.7640181064351017]
	TIME [epoch: 8.27 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8728766086859823		[learning rate: 0.01711]
	Learning Rate: 0.0171104
	LOSS [training: 0.8728766086859823 | validation: 0.858663856143054]
	TIME [epoch: 8.27 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9450370596163205		[learning rate: 0.017099]
	Learning Rate: 0.0170988
	LOSS [training: 0.9450370596163205 | validation: 0.5677409712701951]
	TIME [epoch: 8.27 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7197670475187974		[learning rate: 0.017087]
	Learning Rate: 0.0170871
	LOSS [training: 0.7197670475187974 | validation: 0.7431094838459116]
	TIME [epoch: 8.27 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8382589286145105		[learning rate: 0.017075]
	Learning Rate: 0.0170755
	LOSS [training: 0.8382589286145105 | validation: 0.44026816209372005]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_525.pth
	Model improved!!!
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.81891633799334		[learning rate: 0.017064]
	Learning Rate: 0.0170638
	LOSS [training: 0.81891633799334 | validation: 0.6905616655077647]
	TIME [epoch: 8.29 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8512965548625828		[learning rate: 0.017052]
	Learning Rate: 0.0170521
	LOSS [training: 0.8512965548625828 | validation: 0.9609398697786597]
	TIME [epoch: 8.27 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0228778116674748		[learning rate: 0.01704]
	Learning Rate: 0.0170403
	LOSS [training: 1.0228778116674748 | validation: 2.295708482761711]
	TIME [epoch: 8.27 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.118295383764308		[learning rate: 0.017029]
	Learning Rate: 0.0170286
	LOSS [training: 1.118295383764308 | validation: 0.8216783201961027]
	TIME [epoch: 8.27 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9018330828605763		[learning rate: 0.017017]
	Learning Rate: 0.0170168
	LOSS [training: 0.9018330828605763 | validation: 1.1475602271152447]
	TIME [epoch: 8.27 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8429964417234979		[learning rate: 0.017005]
	Learning Rate: 0.017005
	LOSS [training: 0.8429964417234979 | validation: 1.0489719329520284]
	TIME [epoch: 8.31 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8930336074256485		[learning rate: 0.016993]
	Learning Rate: 0.0169932
	LOSS [training: 0.8930336074256485 | validation: 0.9724152976245644]
	TIME [epoch: 8.27 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0454600109181162		[learning rate: 0.016981]
	Learning Rate: 0.0169814
	LOSS [training: 1.0454600109181162 | validation: 0.9673102353941638]
	TIME [epoch: 8.27 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9337969505618949		[learning rate: 0.01697]
	Learning Rate: 0.0169695
	LOSS [training: 0.9337969505618949 | validation: 0.9368709249634987]
	TIME [epoch: 8.27 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.921356085024202		[learning rate: 0.016958]
	Learning Rate: 0.0169577
	LOSS [training: 0.921356085024202 | validation: 0.6488299465778296]
	TIME [epoch: 8.27 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.818814301448205		[learning rate: 0.016946]
	Learning Rate: 0.0169458
	LOSS [training: 0.818814301448205 | validation: 0.8151727427804517]
	TIME [epoch: 8.3 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7867675134458223		[learning rate: 0.016934]
	Learning Rate: 0.0169339
	LOSS [training: 0.7867675134458223 | validation: 0.614282777817694]
	TIME [epoch: 8.28 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9275945473569578		[learning rate: 0.016922]
	Learning Rate: 0.016922
	LOSS [training: 0.9275945473569578 | validation: 0.918109596251084]
	TIME [epoch: 8.27 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0182474379366602		[learning rate: 0.01691]
	Learning Rate: 0.01691
	LOSS [training: 1.0182474379366602 | validation: 0.9009793303580359]
	TIME [epoch: 8.27 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.082377930131637		[learning rate: 0.016898]
	Learning Rate: 0.0168981
	LOSS [training: 1.082377930131637 | validation: 0.5663383426381423]
	TIME [epoch: 8.27 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8401346857915615		[learning rate: 0.016886]
	Learning Rate: 0.0168861
	LOSS [training: 0.8401346857915615 | validation: 1.2205869263982674]
	TIME [epoch: 8.27 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.686176909938223		[learning rate: 0.016874]
	Learning Rate: 0.0168741
	LOSS [training: 2.686176909938223 | validation: 3.755371828938749]
	TIME [epoch: 8.31 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6855471478284731		[learning rate: 0.016862]
	Learning Rate: 0.0168621
	LOSS [training: 1.6855471478284731 | validation: 1.1255143882992749]
	TIME [epoch: 8.28 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9154960260477318		[learning rate: 0.01685]
	Learning Rate: 0.0168501
	LOSS [training: 0.9154960260477318 | validation: 1.046988707549212]
	TIME [epoch: 8.27 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9657062185337238		[learning rate: 0.016838]
	Learning Rate: 0.016838
	LOSS [training: 0.9657062185337238 | validation: 1.2207012653223654]
	TIME [epoch: 8.27 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0653804739120718		[learning rate: 0.016826]
	Learning Rate: 0.0168259
	LOSS [training: 1.0653804739120718 | validation: 1.0479423533706727]
	TIME [epoch: 8.27 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0955112619968106		[learning rate: 0.016814]
	Learning Rate: 0.0168138
	LOSS [training: 1.0955112619968106 | validation: 0.9158022624539058]
	TIME [epoch: 8.29 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0430553790880164		[learning rate: 0.016802]
	Learning Rate: 0.0168017
	LOSS [training: 1.0430553790880164 | validation: 0.7836158172193934]
	TIME [epoch: 8.31 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7746689136706704		[learning rate: 0.01679]
	Learning Rate: 0.0167896
	LOSS [training: 0.7746689136706704 | validation: 1.0904782885696043]
	TIME [epoch: 8.27 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1405842248837366		[learning rate: 0.016777]
	Learning Rate: 0.0167775
	LOSS [training: 1.1405842248837366 | validation: 0.9355289783782632]
	TIME [epoch: 8.27 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0569443481511889		[learning rate: 0.016765]
	Learning Rate: 0.0167653
	LOSS [training: 1.0569443481511889 | validation: 0.9715844879696892]
	TIME [epoch: 8.27 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0795537543624434		[learning rate: 0.016753]
	Learning Rate: 0.0167531
	LOSS [training: 1.0795537543624434 | validation: 1.171705637687606]
	TIME [epoch: 8.27 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0817525314942213		[learning rate: 0.016741]
	Learning Rate: 0.0167409
	LOSS [training: 3.0817525314942213 | validation: 5.343906379184318]
	TIME [epoch: 8.31 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.488430602356861		[learning rate: 0.016729]
	Learning Rate: 0.0167287
	LOSS [training: 5.488430602356861 | validation: 3.821884273465406]
	TIME [epoch: 8.28 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.190080292353887		[learning rate: 0.016716]
	Learning Rate: 0.0167165
	LOSS [training: 5.190080292353887 | validation: 6.024779335472956]
	TIME [epoch: 8.27 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.1680887294566595		[learning rate: 0.016704]
	Learning Rate: 0.0167042
	LOSS [training: 6.1680887294566595 | validation: 6.420457441059751]
	TIME [epoch: 8.27 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.649129122586371		[learning rate: 0.016692]
	Learning Rate: 0.0166919
	LOSS [training: 5.649129122586371 | validation: 6.3643833137448995]
	TIME [epoch: 8.27 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.476787680220855		[learning rate: 0.01668]
	Learning Rate: 0.0166796
	LOSS [training: 8.476787680220855 | validation: 8.327712103286729]
	TIME [epoch: 8.27 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.081843591042027		[learning rate: 0.016667]
	Learning Rate: 0.0166673
	LOSS [training: 9.081843591042027 | validation: 8.265930663916055]
	TIME [epoch: 8.3 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.316010017282075		[learning rate: 0.016655]
	Learning Rate: 0.016655
	LOSS [training: 9.316010017282075 | validation: 8.0446825512961]
	TIME [epoch: 8.27 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.045120695327322		[learning rate: 0.016643]
	Learning Rate: 0.0166427
	LOSS [training: 9.045120695327322 | validation: 8.143504123129395]
	TIME [epoch: 8.27 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.644831622417305		[learning rate: 0.01663]
	Learning Rate: 0.0166303
	LOSS [training: 9.644831622417305 | validation: 8.707671751064936]
	TIME [epoch: 8.27 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.58726653074569		[learning rate: 0.016618]
	Learning Rate: 0.0166179
	LOSS [training: 9.58726653074569 | validation: 8.852558161107783]
	TIME [epoch: 8.27 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.084247087228526		[learning rate: 0.016606]
	Learning Rate: 0.0166055
	LOSS [training: 9.084247087228526 | validation: 5.806563340515762]
	TIME [epoch: 8.3 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.759680553485797		[learning rate: 0.016593]
	Learning Rate: 0.0165931
	LOSS [training: 7.759680553485797 | validation: 5.244268933116478]
	TIME [epoch: 8.28 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.433561265527035		[learning rate: 0.016581]
	Learning Rate: 0.0165807
	LOSS [training: 6.433561265527035 | validation: 5.157743638193851]
	TIME [epoch: 8.27 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.875918026846348		[learning rate: 0.016568]
	Learning Rate: 0.0165682
	LOSS [training: 7.875918026846348 | validation: 8.787829021729227]
	TIME [epoch: 8.27 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.392345466569807		[learning rate: 0.016556]
	Learning Rate: 0.0165557
	LOSS [training: 9.392345466569807 | validation: 7.9202621276781375]
	TIME [epoch: 8.27 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.232979463527935		[learning rate: 0.016543]
	Learning Rate: 0.0165432
	LOSS [training: 8.232979463527935 | validation: 6.262376405114107]
	TIME [epoch: 8.27 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.94243306175442		[learning rate: 0.016531]
	Learning Rate: 0.0165307
	LOSS [training: 7.94243306175442 | validation: 8.557115155276037]
	TIME [epoch: 8.32 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.895558848694264		[learning rate: 0.016518]
	Learning Rate: 0.0165182
	LOSS [training: 8.895558848694264 | validation: 7.288664814947648]
	TIME [epoch: 8.27 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.7473301959180105		[learning rate: 0.016506]
	Learning Rate: 0.0165057
	LOSS [training: 7.7473301959180105 | validation: 6.15886774104502]
	TIME [epoch: 8.27 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.581356709433912		[learning rate: 0.016493]
	Learning Rate: 0.0164931
	LOSS [training: 6.581356709433912 | validation: 4.764912275270624]
	TIME [epoch: 8.26 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.974254228672555		[learning rate: 0.016481]
	Learning Rate: 0.0164805
	LOSS [training: 5.974254228672555 | validation: 5.195659059440819]
	TIME [epoch: 8.27 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.017042632836292		[learning rate: 0.016468]
	Learning Rate: 0.0164679
	LOSS [training: 6.017042632836292 | validation: 4.63610670099615]
	TIME [epoch: 8.28 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.985303355999931		[learning rate: 0.016455]
	Learning Rate: 0.0164553
	LOSS [training: 4.985303355999931 | validation: 4.685676100803305]
	TIME [epoch: 8.31 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.07096647460926		[learning rate: 0.016443]
	Learning Rate: 0.0164427
	LOSS [training: 5.07096647460926 | validation: 4.252860201134571]
	TIME [epoch: 8.27 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.682946832989739		[learning rate: 0.01643]
	Learning Rate: 0.01643
	LOSS [training: 5.682946832989739 | validation: 5.083995630233863]
	TIME [epoch: 8.27 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.855881814586227		[learning rate: 0.016417]
	Learning Rate: 0.0164173
	LOSS [training: 5.855881814586227 | validation: 4.528982300738606]
	TIME [epoch: 8.27 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.476686284443721		[learning rate: 0.016405]
	Learning Rate: 0.0164047
	LOSS [training: 6.476686284443721 | validation: 6.544630276458724]
	TIME [epoch: 8.27 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.068662113363787		[learning rate: 0.016392]
	Learning Rate: 0.016392
	LOSS [training: 6.068662113363787 | validation: 4.669014073483088]
	TIME [epoch: 8.3 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6883179999432425		[learning rate: 0.016379]
	Learning Rate: 0.0163792
	LOSS [training: 5.6883179999432425 | validation: 4.997432862758894]
	TIME [epoch: 8.28 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.313998873549058		[learning rate: 0.016366]
	Learning Rate: 0.0163665
	LOSS [training: 6.313998873549058 | validation: 5.748079748880903]
	TIME [epoch: 8.27 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.4229791897795705		[learning rate: 0.016354]
	Learning Rate: 0.0163537
	LOSS [training: 6.4229791897795705 | validation: 4.96538322806197]
	TIME [epoch: 8.26 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.4220662029294955		[learning rate: 0.016341]
	Learning Rate: 0.016341
	LOSS [training: 6.4220662029294955 | validation: 5.948074135457237]
	TIME [epoch: 8.27 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.901615408722471		[learning rate: 0.016328]
	Learning Rate: 0.0163282
	LOSS [training: 6.901615408722471 | validation: 5.992367179855661]
	TIME [epoch: 8.27 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.432649585801752		[learning rate: 0.016315]
	Learning Rate: 0.0163154
	LOSS [training: 6.432649585801752 | validation: 5.338935564741741]
	TIME [epoch: 8.31 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.926915686783257		[learning rate: 0.016303]
	Learning Rate: 0.0163025
	LOSS [training: 5.926915686783257 | validation: 4.480830795857292]
	TIME [epoch: 8.27 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.757252768082258		[learning rate: 0.01629]
	Learning Rate: 0.0162897
	LOSS [training: 5.757252768082258 | validation: 4.955735009474653]
	TIME [epoch: 8.27 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.915412745856363		[learning rate: 0.016277]
	Learning Rate: 0.0162768
	LOSS [training: 5.915412745856363 | validation: 4.882015126754137]
	TIME [epoch: 8.27 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.1315435000388705		[learning rate: 0.016264]
	Learning Rate: 0.016264
	LOSS [training: 6.1315435000388705 | validation: 6.476650497889768]
	TIME [epoch: 8.27 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.939494277474711		[learning rate: 0.016251]
	Learning Rate: 0.0162511
	LOSS [training: 6.939494277474711 | validation: 6.143549907034341]
	TIME [epoch: 8.3 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.06015656955093		[learning rate: 0.016238]
	Learning Rate: 0.0162382
	LOSS [training: 7.06015656955093 | validation: 6.75650234240487]
	TIME [epoch: 8.3 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.864401418306283		[learning rate: 0.016225]
	Learning Rate: 0.0162252
	LOSS [training: 7.864401418306283 | validation: 7.702165142361048]
	TIME [epoch: 8.28 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.94718400840177		[learning rate: 0.016212]
	Learning Rate: 0.0162123
	LOSS [training: 7.94718400840177 | validation: 7.493871977136942]
	TIME [epoch: 8.27 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.315296776406097		[learning rate: 0.016199]
	Learning Rate: 0.0161993
	LOSS [training: 8.315296776406097 | validation: 7.779541219086708]
	TIME [epoch: 8.27 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.443278075074758		[learning rate: 0.016186]
	Learning Rate: 0.0161864
	LOSS [training: 8.443278075074758 | validation: 8.735987408465384]
	TIME [epoch: 8.28 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.326116055068407		[learning rate: 0.016173]
	Learning Rate: 0.0161734
	LOSS [training: 8.326116055068407 | validation: 7.525617111603015]
	TIME [epoch: 8.32 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.59727299547273		[learning rate: 0.01616]
	Learning Rate: 0.0161603
	LOSS [training: 7.59727299547273 | validation: 6.920016366905722]
	TIME [epoch: 8.28 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.721005297939279		[learning rate: 0.016147]
	Learning Rate: 0.0161473
	LOSS [training: 6.721005297939279 | validation: 5.053410732569745]
	TIME [epoch: 8.27 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.56015374481687		[learning rate: 0.016134]
	Learning Rate: 0.0161343
	LOSS [training: 5.56015374481687 | validation: 5.479843954757859]
	TIME [epoch: 8.27 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.379227547518655		[learning rate: 0.016121]
	Learning Rate: 0.0161212
	LOSS [training: 5.379227547518655 | validation: 5.266495829571026]
	TIME [epoch: 8.28 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.138192368939671		[learning rate: 0.016108]
	Learning Rate: 0.0161081
	LOSS [training: 5.138192368939671 | validation: 5.473297079781546]
	TIME [epoch: 8.29 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.149993588303849		[learning rate: 0.016095]
	Learning Rate: 0.016095
	LOSS [training: 5.149993588303849 | validation: 4.866365740178541]
	TIME [epoch: 8.3 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.780350389902242		[learning rate: 0.016082]
	Learning Rate: 0.0160819
	LOSS [training: 4.780350389902242 | validation: 4.626371156181012]
	TIME [epoch: 8.27 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.714989513543945		[learning rate: 0.016069]
	Learning Rate: 0.0160688
	LOSS [training: 4.714989513543945 | validation: 3.8923171813187984]
	TIME [epoch: 8.27 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7856386039211873		[learning rate: 0.016056]
	Learning Rate: 0.0160556
	LOSS [training: 3.7856386039211873 | validation: 2.6934014184229484]
	TIME [epoch: 8.27 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.824068722105254		[learning rate: 0.016042]
	Learning Rate: 0.0160425
	LOSS [training: 2.824068722105254 | validation: 2.8095682603001193]
	TIME [epoch: 8.27 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.771787761592115		[learning rate: 0.016029]
	Learning Rate: 0.0160293
	LOSS [training: 2.771787761592115 | validation: 2.9494283700394135]
	TIME [epoch: 8.31 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.20977392819891		[learning rate: 0.016016]
	Learning Rate: 0.0160161
	LOSS [training: 3.20977392819891 | validation: 2.7941155048361153]
	TIME [epoch: 8.28 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2837947378733316		[learning rate: 0.016003]
	Learning Rate: 0.0160029
	LOSS [training: 3.2837947378733316 | validation: 2.301974694558581]
	TIME [epoch: 8.27 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.547177715639767		[learning rate: 0.01599]
	Learning Rate: 0.0159897
	LOSS [training: 2.547177715639767 | validation: 2.3545463335039027]
	TIME [epoch: 8.27 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.340645764009473		[learning rate: 0.015976]
	Learning Rate: 0.0159764
	LOSS [training: 2.340645764009473 | validation: 1.83124499909136]
	TIME [epoch: 8.27 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0326785656206825		[learning rate: 0.015963]
	Learning Rate: 0.0159632
	LOSS [training: 2.0326785656206825 | validation: 1.9744486358793076]
	TIME [epoch: 8.28 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9817898586724203		[learning rate: 0.01595]
	Learning Rate: 0.0159499
	LOSS [training: 1.9817898586724203 | validation: 1.5968554911666821]
	TIME [epoch: 8.33 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.644371857485095		[learning rate: 0.015937]
	Learning Rate: 0.0159366
	LOSS [training: 1.644371857485095 | validation: 1.4438073691179305]
	TIME [epoch: 8.28 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5608330371106203		[learning rate: 0.015923]
	Learning Rate: 0.0159233
	LOSS [training: 1.5608330371106203 | validation: 1.438855677300928]
	TIME [epoch: 8.28 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6929182036326496		[learning rate: 0.01591]
	Learning Rate: 0.01591
	LOSS [training: 1.6929182036326496 | validation: 1.2644349025892403]
	TIME [epoch: 8.27 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3868064019997093		[learning rate: 0.015897]
	Learning Rate: 0.0158966
	LOSS [training: 1.3868064019997093 | validation: 1.2807938471474603]
	TIME [epoch: 8.27 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.499228575078963		[learning rate: 0.015883]
	Learning Rate: 0.0158833
	LOSS [training: 1.499228575078963 | validation: 1.4083870289514644]
	TIME [epoch: 8.3 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.405724112340791		[learning rate: 0.01587]
	Learning Rate: 0.0158699
	LOSS [training: 1.405724112340791 | validation: 1.289099032912021]
	TIME [epoch: 8.29 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3614474272381738		[learning rate: 0.015856]
	Learning Rate: 0.0158565
	LOSS [training: 1.3614474272381738 | validation: 1.300420050148999]
	TIME [epoch: 8.28 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.248688695043212		[learning rate: 0.015843]
	Learning Rate: 0.0158431
	LOSS [training: 1.248688695043212 | validation: 1.3061227319097923]
	TIME [epoch: 8.27 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4900582015237214		[learning rate: 0.01583]
	Learning Rate: 0.0158297
	LOSS [training: 1.4900582015237214 | validation: 1.3952597509573503]
	TIME [epoch: 8.27 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.524814755106315		[learning rate: 0.015816]
	Learning Rate: 0.0158162
	LOSS [training: 1.524814755106315 | validation: 1.228439210735399]
	TIME [epoch: 8.28 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3721837044264606		[learning rate: 0.015803]
	Learning Rate: 0.0158028
	LOSS [training: 1.3721837044264606 | validation: 1.481956251892645]
	TIME [epoch: 8.32 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.393182956106922		[learning rate: 0.015789]
	Learning Rate: 0.0157893
	LOSS [training: 1.393182956106922 | validation: 1.0913282577982613]
	TIME [epoch: 8.28 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4012136321790016		[learning rate: 0.015776]
	Learning Rate: 0.0157758
	LOSS [training: 1.4012136321790016 | validation: 1.1605466393563195]
	TIME [epoch: 8.27 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3489416370560896		[learning rate: 0.015762]
	Learning Rate: 0.0157623
	LOSS [training: 1.3489416370560896 | validation: 1.1959068155485133]
	TIME [epoch: 8.27 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2978104704489053		[learning rate: 0.015749]
	Learning Rate: 0.0157488
	LOSS [training: 1.2978104704489053 | validation: 1.0395675154430664]
	TIME [epoch: 8.27 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2894818265942145		[learning rate: 0.015735]
	Learning Rate: 0.0157353
	LOSS [training: 1.2894818265942145 | validation: 1.071021335194266]
	TIME [epoch: 8.29 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.127794898822219		[learning rate: 0.015722]
	Learning Rate: 0.0157217
	LOSS [training: 1.127794898822219 | validation: 1.2796044762060985]
	TIME [epoch: 8.3 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2814173721895805		[learning rate: 0.015708]
	Learning Rate: 0.0157082
	LOSS [training: 1.2814173721895805 | validation: 1.6710562404982152]
	TIME [epoch: 8.28 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.526169771995567		[learning rate: 0.015695]
	Learning Rate: 0.0156946
	LOSS [training: 1.526169771995567 | validation: 1.2192467872446575]
	TIME [epoch: 8.27 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2971959724822733		[learning rate: 0.015681]
	Learning Rate: 0.015681
	LOSS [training: 1.2971959724822733 | validation: 1.1243431732808915]
	TIME [epoch: 8.28 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1394994371283274		[learning rate: 0.015667]
	Learning Rate: 0.0156674
	LOSS [training: 1.1394994371283274 | validation: 0.9895458427704591]
	TIME [epoch: 8.27 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1823219687102546		[learning rate: 0.015654]
	Learning Rate: 0.0156537
	LOSS [training: 1.1823219687102546 | validation: 0.9351054491729407]
	TIME [epoch: 8.32 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1157853556381103		[learning rate: 0.01564]
	Learning Rate: 0.0156401
	LOSS [training: 1.1157853556381103 | validation: 1.2591332891247644]
	TIME [epoch: 8.28 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0827853125183249		[learning rate: 0.015626]
	Learning Rate: 0.0156264
	LOSS [training: 1.0827853125183249 | validation: 0.8660800499970647]
	TIME [epoch: 8.28 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9832446911847699		[learning rate: 0.015613]
	Learning Rate: 0.0156128
	LOSS [training: 0.9832446911847699 | validation: 0.865058270182457]
	TIME [epoch: 8.28 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2472954834140824		[learning rate: 0.015599]
	Learning Rate: 0.0155991
	LOSS [training: 1.2472954834140824 | validation: 0.7542392491918798]
	TIME [epoch: 8.27 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9582653146607776		[learning rate: 0.015585]
	Learning Rate: 0.0155854
	LOSS [training: 0.9582653146607776 | validation: 0.7098872796381319]
	TIME [epoch: 8.28 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0876626417650306		[learning rate: 0.015572]
	Learning Rate: 0.0155717
	LOSS [training: 1.0876626417650306 | validation: 0.8247963817979476]
	TIME [epoch: 8.31 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9231799325457388		[learning rate: 0.015558]
	Learning Rate: 0.0155579
	LOSS [training: 0.9231799325457388 | validation: 0.8849224152107195]
	TIME [epoch: 8.28 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0084240321561786		[learning rate: 0.015544]
	Learning Rate: 0.0155442
	LOSS [training: 1.0084240321561786 | validation: 0.9410750859317034]
	TIME [epoch: 8.28 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8170462122757804		[learning rate: 0.01553]
	Learning Rate: 0.0155304
	LOSS [training: 0.8170462122757804 | validation: 0.901921820358524]
	TIME [epoch: 8.28 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9945683371556869		[learning rate: 0.015517]
	Learning Rate: 0.0155166
	LOSS [training: 0.9945683371556869 | validation: 1.3197298127050365]
	TIME [epoch: 8.27 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1148518652289607		[learning rate: 0.015503]
	Learning Rate: 0.0155028
	LOSS [training: 1.1148518652289607 | validation: 1.1255990242803944]
	TIME [epoch: 8.31 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.039464696489214		[learning rate: 0.015489]
	Learning Rate: 0.015489
	LOSS [training: 1.039464696489214 | validation: 0.9551126210041152]
	TIME [epoch: 8.29 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.85498059483713		[learning rate: 0.015475]
	Learning Rate: 0.0154752
	LOSS [training: 0.85498059483713 | validation: 0.9253257829612056]
	TIME [epoch: 8.27 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9624330272335767		[learning rate: 0.015461]
	Learning Rate: 0.0154614
	LOSS [training: 0.9624330272335767 | validation: 0.830536188307943]
	TIME [epoch: 8.27 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8970392054014928		[learning rate: 0.015448]
	Learning Rate: 0.0154475
	LOSS [training: 0.8970392054014928 | validation: 1.1578927159669505]
	TIME [epoch: 8.27 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9979791347111853		[learning rate: 0.015434]
	Learning Rate: 0.0154336
	LOSS [training: 0.9979791347111853 | validation: 0.9220626955073201]
	TIME [epoch: 8.28 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8306271327863064		[learning rate: 0.01542]
	Learning Rate: 0.0154198
	LOSS [training: 0.8306271327863064 | validation: 1.0044388693044537]
	TIME [epoch: 8.32 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9012025918886264		[learning rate: 0.015406]
	Learning Rate: 0.0154059
	LOSS [training: 0.9012025918886264 | validation: 0.8487009966049982]
	TIME [epoch: 8.28 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9930100615340491		[learning rate: 0.015392]
	Learning Rate: 0.0153919
	LOSS [training: 0.9930100615340491 | validation: 0.8196347142425546]
	TIME [epoch: 8.27 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9348317785811633		[learning rate: 0.015378]
	Learning Rate: 0.015378
	LOSS [training: 0.9348317785811633 | validation: 0.8950386930312306]
	TIME [epoch: 8.27 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9353639865149777		[learning rate: 0.015364]
	Learning Rate: 0.0153641
	LOSS [training: 0.9353639865149777 | validation: 0.6557649047508725]
	TIME [epoch: 8.28 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8056293036347997		[learning rate: 0.01535]
	Learning Rate: 0.0153501
	LOSS [training: 0.8056293036347997 | validation: 0.9205936877136408]
	TIME [epoch: 8.31 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8923405465993592		[learning rate: 0.015336]
	Learning Rate: 0.0153361
	LOSS [training: 0.8923405465993592 | validation: 0.8143187929135685]
	TIME [epoch: 8.29 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8554706035977909		[learning rate: 0.015322]
	Learning Rate: 0.0153222
	LOSS [training: 0.8554706035977909 | validation: 1.1559663707547099]
	TIME [epoch: 8.28 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9923665784630684		[learning rate: 0.015308]
	Learning Rate: 0.0153082
	LOSS [training: 0.9923665784630684 | validation: 1.03750832009987]
	TIME [epoch: 8.28 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8300286017324382		[learning rate: 0.015294]
	Learning Rate: 0.0152941
	LOSS [training: 0.8300286017324382 | validation: 0.5836170892224994]
	TIME [epoch: 8.28 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9566045241323218		[learning rate: 0.01528]
	Learning Rate: 0.0152801
	LOSS [training: 0.9566045241323218 | validation: 0.952929104806309]
	TIME [epoch: 8.27 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9126643936719324		[learning rate: 0.015266]
	Learning Rate: 0.0152661
	LOSS [training: 0.9126643936719324 | validation: 1.5329669898603018]
	TIME [epoch: 8.32 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8868469858298971		[learning rate: 0.015252]
	Learning Rate: 0.015252
	LOSS [training: 0.8868469858298971 | validation: 0.6924561159597346]
	TIME [epoch: 8.28 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8145428339478072		[learning rate: 0.015238]
	Learning Rate: 0.0152379
	LOSS [training: 0.8145428339478072 | validation: 0.6573097900106905]
	TIME [epoch: 8.27 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8159327165692117		[learning rate: 0.015224]
	Learning Rate: 0.0152238
	LOSS [training: 0.8159327165692117 | validation: 0.5994823989709124]
	TIME [epoch: 8.32 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8984247791570177		[learning rate: 0.01521]
	Learning Rate: 0.0152097
	LOSS [training: 0.8984247791570177 | validation: 0.7698930497318887]
	TIME [epoch: 8.27 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7894299966711882		[learning rate: 0.015196]
	Learning Rate: 0.0151956
	LOSS [training: 0.7894299966711882 | validation: 0.8149634388467748]
	TIME [epoch: 8.28 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6457359294824544		[learning rate: 0.015182]
	Learning Rate: 0.0151815
	LOSS [training: 0.6457359294824544 | validation: 1.7067271620985482]
	TIME [epoch: 8.31 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2625783197921567		[learning rate: 0.015167]
	Learning Rate: 0.0151674
	LOSS [training: 1.2625783197921567 | validation: 0.8679226263157196]
	TIME [epoch: 8.28 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8496063109920595		[learning rate: 0.015153]
	Learning Rate: 0.0151532
	LOSS [training: 0.8496063109920595 | validation: 0.63212632687437]
	TIME [epoch: 8.28 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8651152614412657		[learning rate: 0.015139]
	Learning Rate: 0.015139
	LOSS [training: 0.8651152614412657 | validation: 1.9116005557837006]
	TIME [epoch: 8.28 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1784829609891503		[learning rate: 0.015125]
	Learning Rate: 0.0151248
	LOSS [training: 1.1784829609891503 | validation: 1.1136760182782504]
	TIME [epoch: 8.28 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9110353467436072		[learning rate: 0.015111]
	Learning Rate: 0.0151106
	LOSS [training: 0.9110353467436072 | validation: 0.7180117202586855]
	TIME [epoch: 8.31 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8035624066056517		[learning rate: 0.015096]
	Learning Rate: 0.0150964
	LOSS [training: 0.8035624066056517 | validation: 0.6298785629398129]
	TIME [epoch: 8.3 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9223829381911615		[learning rate: 0.015082]
	Learning Rate: 0.0150822
	LOSS [training: 0.9223829381911615 | validation: 1.435681766767006]
	TIME [epoch: 8.28 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0679771207687088		[learning rate: 0.015068]
	Learning Rate: 0.015068
	LOSS [training: 1.0679771207687088 | validation: 0.7404382477040937]
	TIME [epoch: 8.28 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7836402923988688		[learning rate: 0.015054]
	Learning Rate: 0.0150537
	LOSS [training: 0.7836402923988688 | validation: 1.0096523153427936]
	TIME [epoch: 8.27 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8986268828668198		[learning rate: 0.015039]
	Learning Rate: 0.0150394
	LOSS [training: 0.8986268828668198 | validation: 0.6518248736121725]
	TIME [epoch: 8.28 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8106625375021206		[learning rate: 0.015025]
	Learning Rate: 0.0150251
	LOSS [training: 0.8106625375021206 | validation: 0.8046642482404334]
	TIME [epoch: 8.32 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.843169675261734		[learning rate: 0.015011]
	Learning Rate: 0.0150108
	LOSS [training: 0.843169675261734 | validation: 0.9544853567159237]
	TIME [epoch: 8.28 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8437895028008655		[learning rate: 0.014997]
	Learning Rate: 0.0149965
	LOSS [training: 0.8437895028008655 | validation: 1.1300509435726585]
	TIME [epoch: 8.27 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9032088237137681		[learning rate: 0.014982]
	Learning Rate: 0.0149822
	LOSS [training: 0.9032088237137681 | validation: 0.702425174950419]
	TIME [epoch: 8.28 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7363817438878386		[learning rate: 0.014968]
	Learning Rate: 0.0149679
	LOSS [training: 0.7363817438878386 | validation: 0.8291452134976517]
	TIME [epoch: 8.26 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8083272847044576		[learning rate: 0.014954]
	Learning Rate: 0.0149535
	LOSS [training: 0.8083272847044576 | validation: 0.644762474295993]
	TIME [epoch: 8.31 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8962439596261079		[learning rate: 0.014939]
	Learning Rate: 0.0149392
	LOSS [training: 0.8962439596261079 | validation: 0.7101343069237036]
	TIME [epoch: 8.29 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8816411125964921		[learning rate: 0.014925]
	Learning Rate: 0.0149248
	LOSS [training: 0.8816411125964921 | validation: 0.8488736888399753]
	TIME [epoch: 8.28 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7788742176670386		[learning rate: 0.01491]
	Learning Rate: 0.0149104
	LOSS [training: 0.7788742176670386 | validation: 0.81956258754044]
	TIME [epoch: 8.27 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8093840114384813		[learning rate: 0.014896]
	Learning Rate: 0.014896
	LOSS [training: 0.8093840114384813 | validation: 0.8040076465092663]
	TIME [epoch: 8.27 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7834699739077801		[learning rate: 0.014882]
	Learning Rate: 0.0148816
	LOSS [training: 0.7834699739077801 | validation: 0.6397904976461884]
	TIME [epoch: 8.27 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8822348680140663		[learning rate: 0.014867]
	Learning Rate: 0.0148671
	LOSS [training: 0.8822348680140663 | validation: 0.8306880796800833]
	TIME [epoch: 8.32 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.802065492279157		[learning rate: 0.014853]
	Learning Rate: 0.0148527
	LOSS [training: 0.802065492279157 | validation: 0.6764399230508349]
	TIME [epoch: 8.27 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8978799563171243		[learning rate: 0.014838]
	Learning Rate: 0.0148382
	LOSS [training: 0.8978799563171243 | validation: 0.846940998494015]
	TIME [epoch: 8.27 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7691946773699869		[learning rate: 0.014824]
	Learning Rate: 0.0148237
	LOSS [training: 0.7691946773699869 | validation: 0.7515934498834493]
	TIME [epoch: 8.28 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8340741660972553		[learning rate: 0.014809]
	Learning Rate: 0.0148093
	LOSS [training: 0.8340741660972553 | validation: 0.777485743701075]
	TIME [epoch: 8.28 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6870000155578637		[learning rate: 0.014795]
	Learning Rate: 0.0147948
	LOSS [training: 0.6870000155578637 | validation: 1.4639656608906813]
	TIME [epoch: 8.29 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8088725612631609		[learning rate: 0.01478]
	Learning Rate: 0.0147803
	LOSS [training: 0.8088725612631609 | validation: 0.874735442792786]
	TIME [epoch: 8.31 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8590600267215294		[learning rate: 0.014766]
	Learning Rate: 0.0147657
	LOSS [training: 0.8590600267215294 | validation: 0.8469090612697955]
	TIME [epoch: 8.28 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7648374794731725		[learning rate: 0.014751]
	Learning Rate: 0.0147512
	LOSS [training: 0.7648374794731725 | validation: 0.6860966372104005]
	TIME [epoch: 8.29 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7332556528303216		[learning rate: 0.014737]
	Learning Rate: 0.0147366
	LOSS [training: 0.7332556528303216 | validation: 0.5589056761050075]
	TIME [epoch: 8.28 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7190382785965576		[learning rate: 0.014722]
	Learning Rate: 0.0147221
	LOSS [training: 0.7190382785965576 | validation: 0.8374240357111176]
	TIME [epoch: 8.28 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8292148972052036		[learning rate: 0.014707]
	Learning Rate: 0.0147075
	LOSS [training: 0.8292148972052036 | validation: 0.5886208924794198]
	TIME [epoch: 8.32 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6188230837676691		[learning rate: 0.014693]
	Learning Rate: 0.0146929
	LOSS [training: 0.6188230837676691 | validation: 0.6835699211707233]
	TIME [epoch: 8.29 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8089892461482521		[learning rate: 0.014678]
	Learning Rate: 0.0146783
	LOSS [training: 0.8089892461482521 | validation: 0.7687960412329922]
	TIME [epoch: 8.28 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7419198770994445		[learning rate: 0.014664]
	Learning Rate: 0.0146637
	LOSS [training: 0.7419198770994445 | validation: 0.5800309027537519]
	TIME [epoch: 8.28 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6657925799996405		[learning rate: 0.014649]
	Learning Rate: 0.0146491
	LOSS [training: 0.6657925799996405 | validation: 1.0753189360354263]
	TIME [epoch: 8.28 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7690914666184587		[learning rate: 0.014634]
	Learning Rate: 0.0146344
	LOSS [training: 0.7690914666184587 | validation: 0.7635298911378077]
	TIME [epoch: 8.28 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8057519371617137		[learning rate: 0.01462]
	Learning Rate: 0.0146198
	LOSS [training: 0.8057519371617137 | validation: 0.6159649761271611]
	TIME [epoch: 8.32 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7849932259339011		[learning rate: 0.014605]
	Learning Rate: 0.0146051
	LOSS [training: 0.7849932259339011 | validation: 0.6817605119381438]
	TIME [epoch: 8.28 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7458600838307732		[learning rate: 0.01459]
	Learning Rate: 0.0145904
	LOSS [training: 0.7458600838307732 | validation: 0.705801094571216]
	TIME [epoch: 8.28 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7776456721189889		[learning rate: 0.014576]
	Learning Rate: 0.0145757
	LOSS [training: 0.7776456721189889 | validation: 0.8328191712126624]
	TIME [epoch: 8.28 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7665505319181997		[learning rate: 0.014561]
	Learning Rate: 0.014561
	LOSS [training: 0.7665505319181997 | validation: 0.7919681348768869]
	TIME [epoch: 8.28 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7079999220151041		[learning rate: 0.014546]
	Learning Rate: 0.0145463
	LOSS [training: 0.7079999220151041 | validation: 0.7454621519328076]
	TIME [epoch: 8.31 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7229920780637396		[learning rate: 0.014532]
	Learning Rate: 0.0145316
	LOSS [training: 0.7229920780637396 | validation: 0.7706309501179593]
	TIME [epoch: 8.3 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6835493351793414		[learning rate: 0.014517]
	Learning Rate: 0.0145168
	LOSS [training: 0.6835493351793414 | validation: 0.7897758539126675]
	TIME [epoch: 8.28 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.84539081859827		[learning rate: 0.014502]
	Learning Rate: 0.0145021
	LOSS [training: 0.84539081859827 | validation: 0.6286244593843863]
	TIME [epoch: 8.28 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8202612971194144		[learning rate: 0.014487]
	Learning Rate: 0.0144873
	LOSS [training: 0.8202612971194144 | validation: 0.9031680197786489]
	TIME [epoch: 8.28 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7156813881338085		[learning rate: 0.014473]
	Learning Rate: 0.0144726
	LOSS [training: 0.7156813881338085 | validation: 0.5843502917233885]
	TIME [epoch: 8.29 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7306172243764659		[learning rate: 0.014458]
	Learning Rate: 0.0144578
	LOSS [training: 0.7306172243764659 | validation: 0.5453886176973777]
	TIME [epoch: 8.32 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8761860752433231		[learning rate: 0.014443]
	Learning Rate: 0.014443
	LOSS [training: 0.8761860752433231 | validation: 0.4818684725109846]
	TIME [epoch: 8.29 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6001830067804081		[learning rate: 0.014428]
	Learning Rate: 0.0144281
	LOSS [training: 0.6001830067804081 | validation: 0.7273349209697342]
	TIME [epoch: 8.29 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8389517982242723		[learning rate: 0.014413]
	Learning Rate: 0.0144133
	LOSS [training: 0.8389517982242723 | validation: 0.9627131773588055]
	TIME [epoch: 8.28 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8628509340580629		[learning rate: 0.014398]
	Learning Rate: 0.0143985
	LOSS [training: 0.8628509340580629 | validation: 0.6731896861530989]
	TIME [epoch: 8.28 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7438011589173902		[learning rate: 0.014384]
	Learning Rate: 0.0143836
	LOSS [training: 0.7438011589173902 | validation: 0.7208792430379888]
	TIME [epoch: 8.3 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6261518298244781		[learning rate: 0.014369]
	Learning Rate: 0.0143688
	LOSS [training: 0.6261518298244781 | validation: 0.7871403063762353]
	TIME [epoch: 8.31 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8079694844607634		[learning rate: 0.014354]
	Learning Rate: 0.0143539
	LOSS [training: 0.8079694844607634 | validation: 0.8307322365750491]
	TIME [epoch: 8.28 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7753422286667435		[learning rate: 0.014339]
	Learning Rate: 0.014339
	LOSS [training: 0.7753422286667435 | validation: 0.6861227127879816]
	TIME [epoch: 8.28 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6786329614163817		[learning rate: 0.014324]
	Learning Rate: 0.0143241
	LOSS [training: 0.6786329614163817 | validation: 0.6764946702113479]
	TIME [epoch: 8.28 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7874409569159843		[learning rate: 0.014309]
	Learning Rate: 0.0143092
	LOSS [training: 0.7874409569159843 | validation: 0.7386438843299923]
	TIME [epoch: 8.28 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7294955519433168		[learning rate: 0.014294]
	Learning Rate: 0.0142943
	LOSS [training: 0.7294955519433168 | validation: 0.8072634115133693]
	TIME [epoch: 8.33 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.727866456274108		[learning rate: 0.014279]
	Learning Rate: 0.0142793
	LOSS [training: 0.727866456274108 | validation: 0.6566944135427338]
	TIME [epoch: 8.29 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.677859537563049		[learning rate: 0.014264]
	Learning Rate: 0.0142644
	LOSS [training: 0.677859537563049 | validation: 0.665455515467672]
	TIME [epoch: 8.28 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6936602522395025		[learning rate: 0.014249]
	Learning Rate: 0.0142494
	LOSS [training: 0.6936602522395025 | validation: 0.5618843055757661]
	TIME [epoch: 8.29 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7147859601048818		[learning rate: 0.014234]
	Learning Rate: 0.0142345
	LOSS [training: 0.7147859601048818 | validation: 0.7095740432915025]
	TIME [epoch: 8.28 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6993604297526848		[learning rate: 0.014219]
	Learning Rate: 0.0142195
	LOSS [training: 0.6993604297526848 | validation: 0.4779092110072764]
	TIME [epoch: 8.29 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6894326123598382		[learning rate: 0.014205]
	Learning Rate: 0.0142045
	LOSS [training: 0.6894326123598382 | validation: 0.7535777598365099]
	TIME [epoch: 8.32 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7669732010314496		[learning rate: 0.01419]
	Learning Rate: 0.0141895
	LOSS [training: 0.7669732010314496 | validation: 0.7378202377664629]
	TIME [epoch: 8.29 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7259380182744347		[learning rate: 0.014174]
	Learning Rate: 0.0141745
	LOSS [training: 0.7259380182744347 | validation: 0.7394679814202167]
	TIME [epoch: 8.28 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7214117717605115		[learning rate: 0.014159]
	Learning Rate: 0.0141595
	LOSS [training: 0.7214117717605115 | validation: 0.8379937763344008]
	TIME [epoch: 8.28 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6286663769896532		[learning rate: 0.014144]
	Learning Rate: 0.0141444
	LOSS [training: 0.6286663769896532 | validation: 0.6186232609413465]
	TIME [epoch: 8.28 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.705380233264723		[learning rate: 0.014129]
	Learning Rate: 0.0141294
	LOSS [training: 0.705380233264723 | validation: 0.5804256568003915]
	TIME [epoch: 8.31 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6642766940061304		[learning rate: 0.014114]
	Learning Rate: 0.0141143
	LOSS [training: 0.6642766940061304 | validation: 0.774090685718102]
	TIME [epoch: 8.3 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7300300695308605		[learning rate: 0.014099]
	Learning Rate: 0.0140992
	LOSS [training: 0.7300300695308605 | validation: 0.6241983910184516]
	TIME [epoch: 8.28 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6379006156899504		[learning rate: 0.014084]
	Learning Rate: 0.0140842
	LOSS [training: 0.6379006156899504 | validation: 0.6858800808540146]
	TIME [epoch: 8.28 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6825440890018403		[learning rate: 0.014069]
	Learning Rate: 0.0140691
	LOSS [training: 0.6825440890018403 | validation: 0.7934120880188587]
	TIME [epoch: 8.28 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6397295911169213		[learning rate: 0.014054]
	Learning Rate: 0.014054
	LOSS [training: 0.6397295911169213 | validation: 0.6709890717815999]
	TIME [epoch: 8.28 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8963253923677665		[learning rate: 0.014039]
	Learning Rate: 0.0140389
	LOSS [training: 0.8963253923677665 | validation: 0.6692277610805251]
	TIME [epoch: 8.32 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6732146645395661		[learning rate: 0.014024]
	Learning Rate: 0.0140237
	LOSS [training: 0.6732146645395661 | validation: 0.6333016338804086]
	TIME [epoch: 8.28 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6477581443308326		[learning rate: 0.014009]
	Learning Rate: 0.0140086
	LOSS [training: 0.6477581443308326 | validation: 0.5872869667166238]
	TIME [epoch: 8.28 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.801570047828513		[learning rate: 0.013993]
	Learning Rate: 0.0139934
	LOSS [training: 0.801570047828513 | validation: 0.43810900690373555]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_752.pth
	Model improved!!!
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6516360314438756		[learning rate: 0.013978]
	Learning Rate: 0.0139783
	LOSS [training: 0.6516360314438756 | validation: 0.5498354638051702]
	TIME [epoch: 8.28 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6030024851306706		[learning rate: 0.013963]
	Learning Rate: 0.0139631
	LOSS [training: 0.6030024851306706 | validation: 0.48327752302233584]
	TIME [epoch: 8.31 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.711406475492333		[learning rate: 0.013948]
	Learning Rate: 0.0139479
	LOSS [training: 0.711406475492333 | validation: 0.7597092717455018]
	TIME [epoch: 8.29 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7351999214639945		[learning rate: 0.013933]
	Learning Rate: 0.0139327
	LOSS [training: 0.7351999214639945 | validation: 0.6037111347897408]
	TIME [epoch: 8.28 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5802863592011532		[learning rate: 0.013918]
	Learning Rate: 0.0139175
	LOSS [training: 0.5802863592011532 | validation: 0.6885218130550865]
	TIME [epoch: 8.28 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.64782344415037		[learning rate: 0.013902]
	Learning Rate: 0.0139023
	LOSS [training: 0.64782344415037 | validation: 0.6426737803252665]
	TIME [epoch: 8.28 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6475596983747993		[learning rate: 0.013887]
	Learning Rate: 0.0138871
	LOSS [training: 0.6475596983747993 | validation: 0.7185342146571794]
	TIME [epoch: 8.29 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7621515575178809		[learning rate: 0.013872]
	Learning Rate: 0.0138719
	LOSS [training: 0.7621515575178809 | validation: 0.5861549692520833]
	TIME [epoch: 8.32 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6534361050495159		[learning rate: 0.013857]
	Learning Rate: 0.0138566
	LOSS [training: 0.6534361050495159 | validation: 0.6305366870540592]
	TIME [epoch: 8.28 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7601819810760102		[learning rate: 0.013841]
	Learning Rate: 0.0138414
	LOSS [training: 0.7601819810760102 | validation: 0.738341409515211]
	TIME [epoch: 8.28 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6466656081913615		[learning rate: 0.013826]
	Learning Rate: 0.0138261
	LOSS [training: 0.6466656081913615 | validation: 0.3910672396708751]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_763.pth
	Model improved!!!
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6602313232923669		[learning rate: 0.013811]
	Learning Rate: 0.0138108
	LOSS [training: 0.6602313232923669 | validation: 0.6717583834763874]
	TIME [epoch: 8.28 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5841687306939772		[learning rate: 0.013796]
	Learning Rate: 0.0137955
	LOSS [training: 0.5841687306939772 | validation: 0.7277844621882854]
	TIME [epoch: 8.31 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7684035545095598		[learning rate: 0.01378]
	Learning Rate: 0.0137802
	LOSS [training: 0.7684035545095598 | validation: 0.5864890187133625]
	TIME [epoch: 8.29 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6266247547453773		[learning rate: 0.013765]
	Learning Rate: 0.0137649
	LOSS [training: 0.6266247547453773 | validation: 0.6994454965067309]
	TIME [epoch: 8.28 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7283036578592099		[learning rate: 0.01375]
	Learning Rate: 0.0137496
	LOSS [training: 0.7283036578592099 | validation: 0.45978766497395157]
	TIME [epoch: 8.28 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6919504782027243		[learning rate: 0.013734]
	Learning Rate: 0.0137343
	LOSS [training: 0.6919504782027243 | validation: 0.5998820364840574]
	TIME [epoch: 8.27 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6999323625521116		[learning rate: 0.013719]
	Learning Rate: 0.013719
	LOSS [training: 0.6999323625521116 | validation: 0.6968943299469879]
	TIME [epoch: 8.27 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.698252221504919		[learning rate: 0.013704]
	Learning Rate: 0.0137036
	LOSS [training: 0.698252221504919 | validation: 0.6655022513354342]
	TIME [epoch: 8.31 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.685208406208421		[learning rate: 0.013688]
	Learning Rate: 0.0136882
	LOSS [training: 0.685208406208421 | validation: 0.5711205762340307]
	TIME [epoch: 8.28 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7326984896825905		[learning rate: 0.013673]
	Learning Rate: 0.0136729
	LOSS [training: 0.7326984896825905 | validation: 0.5936215509311362]
	TIME [epoch: 8.27 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5897693584398944		[learning rate: 0.013657]
	Learning Rate: 0.0136575
	LOSS [training: 0.5897693584398944 | validation: 0.5733818249076967]
	TIME [epoch: 8.28 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48246786852239804		[learning rate: 0.013642]
	Learning Rate: 0.0136421
	LOSS [training: 0.48246786852239804 | validation: 0.5326692392692356]
	TIME [epoch: 8.28 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.773600618883826		[learning rate: 0.013627]
	Learning Rate: 0.0136267
	LOSS [training: 0.773600618883826 | validation: 0.5882007047697975]
	TIME [epoch: 8.29 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6321195099272879		[learning rate: 0.013611]
	Learning Rate: 0.0136113
	LOSS [training: 0.6321195099272879 | validation: 0.5972550046690634]
	TIME [epoch: 8.31 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6394099864856766		[learning rate: 0.013596]
	Learning Rate: 0.0135959
	LOSS [training: 0.6394099864856766 | validation: 0.4745461684483324]
	TIME [epoch: 8.28 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7120339084622589		[learning rate: 0.01358]
	Learning Rate: 0.0135805
	LOSS [training: 0.7120339084622589 | validation: 0.48320675549827863]
	TIME [epoch: 8.28 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5799766904082918		[learning rate: 0.013565]
	Learning Rate: 0.013565
	LOSS [training: 0.5799766904082918 | validation: 0.5072504147718131]
	TIME [epoch: 8.28 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6060988564903285		[learning rate: 0.01355]
	Learning Rate: 0.0135496
	LOSS [training: 0.6060988564903285 | validation: 0.7995813337623724]
	TIME [epoch: 8.27 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6034590859130395		[learning rate: 0.013534]
	Learning Rate: 0.0135341
	LOSS [training: 0.6034590859130395 | validation: 0.456531546318038]
	TIME [epoch: 8.31 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6817615605871237		[learning rate: 0.013519]
	Learning Rate: 0.0135186
	LOSS [training: 0.6817615605871237 | validation: 0.4934227678530182]
	TIME [epoch: 8.29 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6503354306644358		[learning rate: 0.013503]
	Learning Rate: 0.0135032
	LOSS [training: 0.6503354306644358 | validation: 0.5727802842989034]
	TIME [epoch: 8.28 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6210353019803734		[learning rate: 0.013488]
	Learning Rate: 0.0134877
	LOSS [training: 0.6210353019803734 | validation: 0.721990404118408]
	TIME [epoch: 8.28 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7437677863636075		[learning rate: 0.013472]
	Learning Rate: 0.0134722
	LOSS [training: 0.7437677863636075 | validation: 0.5331249847426205]
	TIME [epoch: 8.28 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6189963632298457		[learning rate: 0.013457]
	Learning Rate: 0.0134567
	LOSS [training: 0.6189963632298457 | validation: 0.7812735782140713]
	TIME [epoch: 8.28 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.605010215073982		[learning rate: 0.013441]
	Learning Rate: 0.0134412
	LOSS [training: 0.605010215073982 | validation: 0.7781052027636526]
	TIME [epoch: 8.32 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6369265802606499		[learning rate: 0.013426]
	Learning Rate: 0.0134256
	LOSS [training: 0.6369265802606499 | validation: 0.4640767255250277]
	TIME [epoch: 8.28 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.689568025684851		[learning rate: 0.01341]
	Learning Rate: 0.0134101
	LOSS [training: 0.689568025684851 | validation: 0.44192000272918897]
	TIME [epoch: 8.28 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5618319490300712		[learning rate: 0.013395]
	Learning Rate: 0.0133946
	LOSS [training: 0.5618319490300712 | validation: 0.9802676915235051]
	TIME [epoch: 8.29 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7705473425969307		[learning rate: 0.013379]
	Learning Rate: 0.013379
	LOSS [training: 0.7705473425969307 | validation: 0.7753379264723466]
	TIME [epoch: 8.29 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8063127120863877		[learning rate: 0.013363]
	Learning Rate: 0.0133635
	LOSS [training: 0.8063127120863877 | validation: 0.6034047690535783]
	TIME [epoch: 8.31 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6235169358128323		[learning rate: 0.013348]
	Learning Rate: 0.0133479
	LOSS [training: 0.6235169358128323 | validation: 0.5033783459732081]
	TIME [epoch: 8.3 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6958953607853562		[learning rate: 0.013332]
	Learning Rate: 0.0133323
	LOSS [training: 0.6958953607853562 | validation: 0.40861689515867916]
	TIME [epoch: 8.28 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5529173000091231		[learning rate: 0.013317]
	Learning Rate: 0.0133167
	LOSS [training: 0.5529173000091231 | validation: 0.5820443740607695]
	TIME [epoch: 8.28 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6419191438465014		[learning rate: 0.013301]
	Learning Rate: 0.0133011
	LOSS [training: 0.6419191438465014 | validation: 0.8944941081871944]
	TIME [epoch: 8.28 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7168915205770805		[learning rate: 0.013286]
	Learning Rate: 0.0132855
	LOSS [training: 0.7168915205770805 | validation: 0.5174734127727207]
	TIME [epoch: 8.28 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6540558701574523		[learning rate: 0.01327]
	Learning Rate: 0.0132699
	LOSS [training: 0.6540558701574523 | validation: 0.7722867450810996]
	TIME [epoch: 8.32 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.658296080949214		[learning rate: 0.013254]
	Learning Rate: 0.0132543
	LOSS [training: 0.658296080949214 | validation: 0.5822703923299273]
	TIME [epoch: 8.28 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5887241756378538		[learning rate: 0.013239]
	Learning Rate: 0.0132386
	LOSS [training: 0.5887241756378538 | validation: 0.5977749591522807]
	TIME [epoch: 8.28 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6923910924226477		[learning rate: 0.013223]
	Learning Rate: 0.013223
	LOSS [training: 0.6923910924226477 | validation: 0.5334360832575509]
	TIME [epoch: 8.28 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6044395766766797		[learning rate: 0.013207]
	Learning Rate: 0.0132074
	LOSS [training: 0.6044395766766797 | validation: 0.5771372297026363]
	TIME [epoch: 8.27 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5618662863491694		[learning rate: 0.013192]
	Learning Rate: 0.0131917
	LOSS [training: 0.5618662863491694 | validation: 0.7075246755068918]
	TIME [epoch: 8.3 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6782557893987042		[learning rate: 0.013176]
	Learning Rate: 0.013176
	LOSS [training: 0.6782557893987042 | validation: 0.5854486849900841]
	TIME [epoch: 8.31 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43356042333184025		[learning rate: 0.01316]
	Learning Rate: 0.0131603
	LOSS [training: 0.43356042333184025 | validation: 0.6672416928114999]
	TIME [epoch: 8.28 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1436502458951319		[learning rate: 0.013145]
	Learning Rate: 0.0131447
	LOSS [training: 1.1436502458951319 | validation: 2.0765112647362702]
	TIME [epoch: 8.28 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6298850386770063		[learning rate: 0.013129]
	Learning Rate: 0.013129
	LOSS [training: 2.6298850386770063 | validation: 2.22108466799917]
	TIME [epoch: 8.28 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.044228869307348		[learning rate: 0.013113]
	Learning Rate: 0.0131133
	LOSS [training: 4.044228869307348 | validation: 3.175991007243998]
	TIME [epoch: 8.28 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.066184993218939		[learning rate: 0.013098]
	Learning Rate: 0.0130976
	LOSS [training: 4.066184993218939 | validation: 4.080874461344344]
	TIME [epoch: 8.31 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.107506286339171		[learning rate: 0.013082]
	Learning Rate: 0.0130818
	LOSS [training: 5.107506286339171 | validation: 4.139681507386626]
	TIME [epoch: 8.29 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.260770897643169		[learning rate: 0.013066]
	Learning Rate: 0.0130661
	LOSS [training: 5.260770897643169 | validation: 3.9654959247695]
	TIME [epoch: 8.28 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.389515778521437		[learning rate: 0.01305]
	Learning Rate: 0.0130504
	LOSS [training: 3.389515778521437 | validation: 1.1347327832106693]
	TIME [epoch: 8.28 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0727267703244836		[learning rate: 0.013035]
	Learning Rate: 0.0130346
	LOSS [training: 1.0727267703244836 | validation: 0.5977239370027598]
	TIME [epoch: 8.28 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.589697291571007		[learning rate: 0.013019]
	Learning Rate: 0.0130189
	LOSS [training: 0.589697291571007 | validation: 0.46526839100764644]
	TIME [epoch: 8.28 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7136788597003101		[learning rate: 0.013003]
	Learning Rate: 0.0130031
	LOSS [training: 0.7136788597003101 | validation: 0.6854539403518803]
	TIME [epoch: 8.32 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5709425449321114		[learning rate: 0.012987]
	Learning Rate: 0.0129873
	LOSS [training: 0.5709425449321114 | validation: 0.34902004788126295]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_817.pth
	Model improved!!!
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5621358355742859		[learning rate: 0.012972]
	Learning Rate: 0.0129716
	LOSS [training: 0.5621358355742859 | validation: 0.48788816774355154]
	TIME [epoch: 8.28 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5855462300649827		[learning rate: 0.012956]
	Learning Rate: 0.0129558
	LOSS [training: 0.5855462300649827 | validation: 0.5643266797811299]
	TIME [epoch: 8.27 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6700943293441876		[learning rate: 0.01294]
	Learning Rate: 0.01294
	LOSS [training: 0.6700943293441876 | validation: 0.6306085677691438]
	TIME [epoch: 8.27 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6570303897690855		[learning rate: 0.012924]
	Learning Rate: 0.0129242
	LOSS [training: 0.6570303897690855 | validation: 0.6245686857620165]
	TIME [epoch: 8.31 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.721349299525648		[learning rate: 0.012908]
	Learning Rate: 0.0129084
	LOSS [training: 0.721349299525648 | validation: 0.49245125451067295]
	TIME [epoch: 8.29 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6187210055022202		[learning rate: 0.012893]
	Learning Rate: 0.0128926
	LOSS [training: 0.6187210055022202 | validation: 0.6834616437313128]
	TIME [epoch: 8.28 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6618533298676167		[learning rate: 0.012877]
	Learning Rate: 0.0128767
	LOSS [training: 0.6618533298676167 | validation: 0.5686770383055564]
	TIME [epoch: 8.26 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6238753427525314		[learning rate: 0.012861]
	Learning Rate: 0.0128609
	LOSS [training: 0.6238753427525314 | validation: 0.6194402946431357]
	TIME [epoch: 8.27 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5821304223667481		[learning rate: 0.012845]
	Learning Rate: 0.0128451
	LOSS [training: 0.5821304223667481 | validation: 0.66686182064426]
	TIME [epoch: 8.28 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6433202051370271		[learning rate: 0.012829]
	Learning Rate: 0.0128292
	LOSS [training: 0.6433202051370271 | validation: 0.7416427972957786]
	TIME [epoch: 8.32 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9319682771414873		[learning rate: 0.012813]
	Learning Rate: 0.0128133
	LOSS [training: 0.9319682771414873 | validation: 0.8094724346815352]
	TIME [epoch: 8.28 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7173865875134698		[learning rate: 0.012797]
	Learning Rate: 0.0127975
	LOSS [training: 0.7173865875134698 | validation: 0.5512924422059554]
	TIME [epoch: 8.27 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6021209787271455		[learning rate: 0.012782]
	Learning Rate: 0.0127816
	LOSS [training: 0.6021209787271455 | validation: 0.6056057183850853]
	TIME [epoch: 8.27 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5927293656886559		[learning rate: 0.012766]
	Learning Rate: 0.0127657
	LOSS [training: 0.5927293656886559 | validation: 0.6234628630556386]
	TIME [epoch: 8.28 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6271433664987701		[learning rate: 0.01275]
	Learning Rate: 0.0127498
	LOSS [training: 0.6271433664987701 | validation: 0.57911994527104]
	TIME [epoch: 8.31 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6083050345734975		[learning rate: 0.012734]
	Learning Rate: 0.0127339
	LOSS [training: 0.6083050345734975 | validation: 0.5327172933284412]
	TIME [epoch: 8.3 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49170677941880014		[learning rate: 0.012718]
	Learning Rate: 0.012718
	LOSS [training: 0.49170677941880014 | validation: 0.6546816018973312]
	TIME [epoch: 8.28 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.606431795775149		[learning rate: 0.012702]
	Learning Rate: 0.0127021
	LOSS [training: 0.606431795775149 | validation: 0.5667206868031567]
	TIME [epoch: 8.27 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7904468088033328		[learning rate: 0.012686]
	Learning Rate: 0.0126862
	LOSS [training: 0.7904468088033328 | validation: 0.6175930348633702]
	TIME [epoch: 8.28 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7054644187427379		[learning rate: 0.01267]
	Learning Rate: 0.0126703
	LOSS [training: 0.7054644187427379 | validation: 0.753126505541539]
	TIME [epoch: 8.28 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6106416820677364		[learning rate: 0.012654]
	Learning Rate: 0.0126544
	LOSS [training: 0.6106416820677364 | validation: 0.8834335378673486]
	TIME [epoch: 8.32 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6651456179924199		[learning rate: 0.012638]
	Learning Rate: 0.0126384
	LOSS [training: 0.6651456179924199 | validation: 0.6931046251422155]
	TIME [epoch: 8.28 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6861933423385103		[learning rate: 0.012622]
	Learning Rate: 0.0126225
	LOSS [training: 0.6861933423385103 | validation: 0.4316173581907866]
	TIME [epoch: 8.27 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6785405288978916		[learning rate: 0.012607]
	Learning Rate: 0.0126065
	LOSS [training: 0.6785405288978916 | validation: 0.49403192049234695]
	TIME [epoch: 8.28 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6073549706991708		[learning rate: 0.012591]
	Learning Rate: 0.0125906
	LOSS [training: 0.6073549706991708 | validation: 0.6248485729262045]
	TIME [epoch: 8.27 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6148447801926704		[learning rate: 0.012575]
	Learning Rate: 0.0125746
	LOSS [training: 0.6148447801926704 | validation: 0.5914371069490982]
	TIME [epoch: 8.28 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6389169464633777		[learning rate: 0.012559]
	Learning Rate: 0.0125586
	LOSS [training: 0.6389169464633777 | validation: 0.9087288282113691]
	TIME [epoch: 8.31 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6399539972574444		[learning rate: 0.012543]
	Learning Rate: 0.0125426
	LOSS [training: 0.6399539972574444 | validation: 0.4485495030469122]
	TIME [epoch: 8.28 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6153296456707777		[learning rate: 0.012527]
	Learning Rate: 0.0125267
	LOSS [training: 0.6153296456707777 | validation: 0.7217574807713918]
	TIME [epoch: 8.28 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.582022183784635		[learning rate: 0.012511]
	Learning Rate: 0.0125107
	LOSS [training: 0.582022183784635 | validation: 0.6191277126879785]
	TIME [epoch: 8.28 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5810219186272436		[learning rate: 0.012495]
	Learning Rate: 0.0124947
	LOSS [training: 0.5810219186272436 | validation: 0.5626919717356582]
	TIME [epoch: 8.27 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5874398820647211		[learning rate: 0.012479]
	Learning Rate: 0.0124786
	LOSS [training: 0.5874398820647211 | validation: 0.5297850726560825]
	TIME [epoch: 8.31 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6738456329186353		[learning rate: 0.012463]
	Learning Rate: 0.0124626
	LOSS [training: 0.6738456329186353 | validation: 0.6329363175706668]
	TIME [epoch: 8.29 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6105492185704802		[learning rate: 0.012447]
	Learning Rate: 0.0124466
	LOSS [training: 0.6105492185704802 | validation: 0.6000463077090803]
	TIME [epoch: 8.27 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6609152466110352		[learning rate: 0.012431]
	Learning Rate: 0.0124306
	LOSS [training: 0.6609152466110352 | validation: 0.5176584036741856]
	TIME [epoch: 8.27 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5824731734522145		[learning rate: 0.012415]
	Learning Rate: 0.0124145
	LOSS [training: 0.5824731734522145 | validation: 0.8445584592841533]
	TIME [epoch: 8.28 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.648585683291141		[learning rate: 0.012399]
	Learning Rate: 0.0123985
	LOSS [training: 0.648585683291141 | validation: 0.4488743725648513]
	TIME [epoch: 8.27 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.619068800589198		[learning rate: 0.012382]
	Learning Rate: 0.0123825
	LOSS [training: 0.619068800589198 | validation: 0.425765688191467]
	TIME [epoch: 8.32 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5262300456020338		[learning rate: 0.012366]
	Learning Rate: 0.0123664
	LOSS [training: 0.5262300456020338 | validation: 0.3996014112051912]
	TIME [epoch: 8.28 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6726259514172593		[learning rate: 0.01235]
	Learning Rate: 0.0123503
	LOSS [training: 0.6726259514172593 | validation: 0.4141483617454391]
	TIME [epoch: 8.28 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6538937669756109		[learning rate: 0.012334]
	Learning Rate: 0.0123343
	LOSS [training: 0.6538937669756109 | validation: 0.4620845791979783]
	TIME [epoch: 8.27 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5952715244267783		[learning rate: 0.012318]
	Learning Rate: 0.0123182
	LOSS [training: 0.5952715244267783 | validation: 0.4724114705514337]
	TIME [epoch: 8.27 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5590829184888447		[learning rate: 0.012302]
	Learning Rate: 0.0123021
	LOSS [training: 0.5590829184888447 | validation: 0.45118332041506204]
	TIME [epoch: 8.31 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5736278588062669		[learning rate: 0.012286]
	Learning Rate: 0.012286
	LOSS [training: 0.5736278588062669 | validation: 0.3715839290956848]
	TIME [epoch: 8.29 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.552760244196806		[learning rate: 0.01227]
	Learning Rate: 0.0122699
	LOSS [training: 0.552760244196806 | validation: 0.3849529302488861]
	TIME [epoch: 8.28 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6236685666444515		[learning rate: 0.012254]
	Learning Rate: 0.0122538
	LOSS [training: 0.6236685666444515 | validation: 0.6206823542457786]
	TIME [epoch: 8.27 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5684687210573711		[learning rate: 0.012238]
	Learning Rate: 0.0122377
	LOSS [training: 0.5684687210573711 | validation: 1.5758903346215352]
	TIME [epoch: 8.28 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.720610961746899		[learning rate: 0.012222]
	Learning Rate: 0.0122216
	LOSS [training: 2.720610961746899 | validation: 2.3129420489000285]
	TIME [epoch: 8.27 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5588295055043924		[learning rate: 0.012205]
	Learning Rate: 0.0122055
	LOSS [training: 3.5588295055043924 | validation: 2.6270725912198563]
	TIME [epoch: 8.33 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5333026248828396		[learning rate: 0.012189]
	Learning Rate: 0.0121894
	LOSS [training: 3.5333026248828396 | validation: 3.481563254678966]
	TIME [epoch: 8.28 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.0765130561782055		[learning rate: 0.012173]
	Learning Rate: 0.0121732
	LOSS [training: 5.0765130561782055 | validation: 3.9442733514743713]
	TIME [epoch: 8.28 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.31943547482539		[learning rate: 0.012157]
	Learning Rate: 0.0121571
	LOSS [training: 5.31943547482539 | validation: 5.045555145451504]
	TIME [epoch: 8.28 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.7995210685768575		[learning rate: 0.012141]
	Learning Rate: 0.012141
	LOSS [training: 6.7995210685768575 | validation: 6.18797922981347]
	TIME [epoch: 8.28 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.994080966946364		[learning rate: 0.012125]
	Learning Rate: 0.0121248
	LOSS [training: 5.994080966946364 | validation: 5.744613839878312]
	TIME [epoch: 8.29 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.279572127897462		[learning rate: 0.012109]
	Learning Rate: 0.0121087
	LOSS [training: 7.279572127897462 | validation: 8.96075324040132]
	TIME [epoch: 8.31 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.722072859612855		[learning rate: 0.012093]
	Learning Rate: 0.0120925
	LOSS [training: 9.722072859612855 | validation: 10.77854878531504]
	TIME [epoch: 8.28 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.48434634516811		[learning rate: 0.012076]
	Learning Rate: 0.0120763
	LOSS [training: 10.48434634516811 | validation: 10.641551490676306]
	TIME [epoch: 8.28 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.493965906218733		[learning rate: 0.01206]
	Learning Rate: 0.0120602
	LOSS [training: 10.493965906218733 | validation: 11.058291425453413]
	TIME [epoch: 8.28 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.594873903081663		[learning rate: 0.012044]
	Learning Rate: 0.012044
	LOSS [training: 10.594873903081663 | validation: 11.477165840312505]
	TIME [epoch: 8.27 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.559858526523097		[learning rate: 0.012028]
	Learning Rate: 0.0120278
	LOSS [training: 10.559858526523097 | validation: 10.590424759902618]
	TIME [epoch: 8.31 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.927544246034875		[learning rate: 0.012012]
	Learning Rate: 0.0120116
	LOSS [training: 9.927544246034875 | validation: 10.867353921314457]
	TIME [epoch: 8.29 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.714300688882213		[learning rate: 0.011995]
	Learning Rate: 0.0119954
	LOSS [training: 8.714300688882213 | validation: 7.792696226658236]
	TIME [epoch: 8.28 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.719772965738246		[learning rate: 0.011979]
	Learning Rate: 0.0119792
	LOSS [training: 3.719772965738246 | validation: 2.2502151453580455]
	TIME [epoch: 8.28 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.509784468737085		[learning rate: 0.011963]
	Learning Rate: 0.011963
	LOSS [training: 1.509784468737085 | validation: 1.8063581625157985]
	TIME [epoch: 8.28 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.352100082036788		[learning rate: 0.011947]
	Learning Rate: 0.0119468
	LOSS [training: 1.352100082036788 | validation: 1.487661072488661]
	TIME [epoch: 8.28 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1917775039257354		[learning rate: 0.011931]
	Learning Rate: 0.0119306
	LOSS [training: 1.1917775039257354 | validation: 1.4873544602591346]
	TIME [epoch: 8.32 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2981472453284408		[learning rate: 0.011914]
	Learning Rate: 0.0119144
	LOSS [training: 1.2981472453284408 | validation: 1.5613996444142861]
	TIME [epoch: 8.29 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2378164649856704		[learning rate: 0.011898]
	Learning Rate: 0.0118982
	LOSS [training: 1.2378164649856704 | validation: 1.4196901518361655]
	TIME [epoch: 8.27 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9741917594366918		[learning rate: 0.011882]
	Learning Rate: 0.0118819
	LOSS [training: 0.9741917594366918 | validation: 2.303938293314615]
	TIME [epoch: 8.28 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2307036492418906		[learning rate: 0.011866]
	Learning Rate: 0.0118657
	LOSS [training: 1.2307036492418906 | validation: 1.2856472833670805]
	TIME [epoch: 8.28 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1917877360972964		[learning rate: 0.011849]
	Learning Rate: 0.0118495
	LOSS [training: 1.1917877360972964 | validation: 0.8171422991360255]
	TIME [epoch: 8.3 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8154177623437362		[learning rate: 0.011833]
	Learning Rate: 0.0118332
	LOSS [training: 0.8154177623437362 | validation: 1.2149196422966035]
	TIME [epoch: 8.29 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8803779439905335		[learning rate: 0.011817]
	Learning Rate: 0.011817
	LOSS [training: 0.8803779439905335 | validation: 1.1188523720061463]
	TIME [epoch: 8.28 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8326144458364747		[learning rate: 0.011801]
	Learning Rate: 0.0118007
	LOSS [training: 0.8326144458364747 | validation: 0.5886641767907057]
	TIME [epoch: 8.27 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7291477115767507		[learning rate: 0.011784]
	Learning Rate: 0.0117844
	LOSS [training: 0.7291477115767507 | validation: 0.907232706179838]
	TIME [epoch: 8.27 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9285411192342026		[learning rate: 0.011768]
	Learning Rate: 0.0117682
	LOSS [training: 0.9285411192342026 | validation: 0.9021895094392494]
	TIME [epoch: 8.28 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7242830533277679		[learning rate: 0.011752]
	Learning Rate: 0.0117519
	LOSS [training: 0.7242830533277679 | validation: 0.6827229819581961]
	TIME [epoch: 8.32 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.697934746238536		[learning rate: 0.011736]
	Learning Rate: 0.0117356
	LOSS [training: 0.697934746238536 | validation: 0.6409713718765497]
	TIME [epoch: 8.27 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.65641164343354		[learning rate: 0.011719]
	Learning Rate: 0.0117194
	LOSS [training: 0.65641164343354 | validation: 0.5142858345607791]
	TIME [epoch: 8.28 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5715962054557745		[learning rate: 0.011703]
	Learning Rate: 0.0117031
	LOSS [training: 0.5715962054557745 | validation: 0.5605768555759725]
	TIME [epoch: 8.27 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5679063978684302		[learning rate: 0.011687]
	Learning Rate: 0.0116868
	LOSS [training: 0.5679063978684302 | validation: 0.52193863995761]
	TIME [epoch: 8.27 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5630076442798398		[learning rate: 0.01167]
	Learning Rate: 0.0116705
	LOSS [training: 0.5630076442798398 | validation: 0.5139572903948337]
	TIME [epoch: 8.29 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6334672513447113		[learning rate: 0.011654]
	Learning Rate: 0.0116542
	LOSS [training: 0.6334672513447113 | validation: 0.611777832624471]
	TIME [epoch: 8.31 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6072281041951185		[learning rate: 0.011638]
	Learning Rate: 0.0116379
	LOSS [training: 0.6072281041951185 | validation: 0.4405866529468535]
	TIME [epoch: 8.28 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.542158113182552		[learning rate: 0.011622]
	Learning Rate: 0.0116216
	LOSS [training: 0.542158113182552 | validation: 0.8780662235973351]
	TIME [epoch: 8.27 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6950510564962766		[learning rate: 0.011605]
	Learning Rate: 0.0116053
	LOSS [training: 0.6950510564962766 | validation: 0.4746148680031983]
	TIME [epoch: 8.27 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5760851533168523		[learning rate: 0.011589]
	Learning Rate: 0.011589
	LOSS [training: 0.5760851533168523 | validation: 0.6096585180941017]
	TIME [epoch: 8.27 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6397873022939156		[learning rate: 0.011573]
	Learning Rate: 0.0115726
	LOSS [training: 0.6397873022939156 | validation: 0.3830035422844465]
	TIME [epoch: 8.32 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6614353145050078		[learning rate: 0.011556]
	Learning Rate: 0.0115563
	LOSS [training: 0.6614353145050078 | validation: 0.45312726746090015]
	TIME [epoch: 8.27 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6221781232026332		[learning rate: 0.01154]
	Learning Rate: 0.01154
	LOSS [training: 0.6221781232026332 | validation: 0.6003667154285053]
	TIME [epoch: 8.27 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.774576345494303		[learning rate: 0.011524]
	Learning Rate: 0.0115237
	LOSS [training: 1.774576345494303 | validation: 1.7770546825947267]
	TIME [epoch: 8.27 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9393773780145533		[learning rate: 0.011507]
	Learning Rate: 0.0115073
	LOSS [training: 2.9393773780145533 | validation: 1.6989011269929497]
	TIME [epoch: 8.27 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5502875025812504		[learning rate: 0.011491]
	Learning Rate: 0.011491
	LOSS [training: 2.5502875025812504 | validation: 3.3325633303468987]
	TIME [epoch: 8.29 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.039225196003952		[learning rate: 0.011475]
	Learning Rate: 0.0114746
	LOSS [training: 3.039225196003952 | validation: 1.373134164000128]
	TIME [epoch: 8.31 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.273553816283136		[learning rate: 0.011458]
	Learning Rate: 0.0114583
	LOSS [training: 2.273553816283136 | validation: 1.3595719840629328]
	TIME [epoch: 8.28 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.482584782087442		[learning rate: 0.011442]
	Learning Rate: 0.0114419
	LOSS [training: 2.482584782087442 | validation: 1.7445393938573623]
	TIME [epoch: 8.27 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.968590452139697		[learning rate: 0.011426]
	Learning Rate: 0.0114256
	LOSS [training: 2.968590452139697 | validation: 2.4447387149545468]
	TIME [epoch: 8.27 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2116806496990034		[learning rate: 0.011409]
	Learning Rate: 0.0114092
	LOSS [training: 3.2116806496990034 | validation: 1.8719641958813509]
	TIME [epoch: 8.28 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6018779550626028		[learning rate: 0.011393]
	Learning Rate: 0.0113929
	LOSS [training: 2.6018779550626028 | validation: 1.6706082091703591]
	TIME [epoch: 8.31 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0808719749114335		[learning rate: 0.011376]
	Learning Rate: 0.0113765
	LOSS [training: 2.0808719749114335 | validation: 1.091580778346637]
	TIME [epoch: 8.29 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4287110086433241		[learning rate: 0.01136]
	Learning Rate: 0.0113601
	LOSS [training: 1.4287110086433241 | validation: 1.2359692987429582]
	TIME [epoch: 8.27 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5486464542844474		[learning rate: 0.011344]
	Learning Rate: 0.0113437
	LOSS [training: 1.5486464542844474 | validation: 1.0003251267553617]
	TIME [epoch: 8.27 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3503612321153295		[learning rate: 0.011327]
	Learning Rate: 0.0113274
	LOSS [training: 1.3503612321153295 | validation: 0.9363546357212794]
	TIME [epoch: 8.28 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2549924126860594		[learning rate: 0.011311]
	Learning Rate: 0.011311
	LOSS [training: 1.2549924126860594 | validation: 1.067207073843243]
	TIME [epoch: 8.28 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3476461823023662		[learning rate: 0.011295]
	Learning Rate: 0.0112946
	LOSS [training: 1.3476461823023662 | validation: 1.169753168291931]
	TIME [epoch: 8.33 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3498696795797827		[learning rate: 0.011278]
	Learning Rate: 0.0112782
	LOSS [training: 1.3498696795797827 | validation: 1.1726103036486977]
	TIME [epoch: 8.28 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.280778804776749		[learning rate: 0.011262]
	Learning Rate: 0.0112618
	LOSS [training: 1.280778804776749 | validation: 1.0367420963728875]
	TIME [epoch: 8.27 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.717708837826541		[learning rate: 0.011245]
	Learning Rate: 0.0112454
	LOSS [training: 1.717708837826541 | validation: 1.8550106671348376]
	TIME [epoch: 8.28 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7806863037771503		[learning rate: 0.011229]
	Learning Rate: 0.011229
	LOSS [training: 2.7806863037771503 | validation: 1.5809841250875252]
	TIME [epoch: 8.27 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6562690234736064		[learning rate: 0.011213]
	Learning Rate: 0.0112126
	LOSS [training: 1.6562690234736064 | validation: 0.9780577175499927]
	TIME [epoch: 8.3 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9156367671310545		[learning rate: 0.011196]
	Learning Rate: 0.0111962
	LOSS [training: 0.9156367671310545 | validation: 0.6767308839902293]
	TIME [epoch: 8.3 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9260121887640018		[learning rate: 0.01118]
	Learning Rate: 0.0111798
	LOSS [training: 0.9260121887640018 | validation: 0.6689169484860684]
	TIME [epoch: 8.27 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7085468838100197		[learning rate: 0.011163]
	Learning Rate: 0.0111634
	LOSS [training: 0.7085468838100197 | validation: 0.5843658517340274]
	TIME [epoch: 8.28 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6637103780398602		[learning rate: 0.011147]
	Learning Rate: 0.011147
	LOSS [training: 0.6637103780398602 | validation: 0.5591346827331918]
	TIME [epoch: 8.27 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1035182126347332		[learning rate: 0.011131]
	Learning Rate: 0.0111305
	LOSS [training: 1.1035182126347332 | validation: 0.529513596434596]
	TIME [epoch: 8.26 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6837812232249164		[learning rate: 0.011114]
	Learning Rate: 0.0111141
	LOSS [training: 0.6837812232249164 | validation: 0.6196284337319151]
	TIME [epoch: 8.31 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6493925039024856		[learning rate: 0.011098]
	Learning Rate: 0.0110977
	LOSS [training: 0.6493925039024856 | validation: 0.6974524629472902]
	TIME [epoch: 8.27 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6389948033987413		[learning rate: 0.011081]
	Learning Rate: 0.0110813
	LOSS [training: 0.6389948033987413 | validation: 0.551471764723853]
	TIME [epoch: 8.26 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5722025416621249		[learning rate: 0.011065]
	Learning Rate: 0.0110648
	LOSS [training: 0.5722025416621249 | validation: 0.45675373383379037]
	TIME [epoch: 8.26 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6507640731966188		[learning rate: 0.011048]
	Learning Rate: 0.0110484
	LOSS [training: 0.6507640731966188 | validation: 0.5530812617092077]
	TIME [epoch: 8.27 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5792664026156458		[learning rate: 0.011032]
	Learning Rate: 0.011032
	LOSS [training: 0.5792664026156458 | validation: 0.5288020291770819]
	TIME [epoch: 8.27 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6640896525278396		[learning rate: 0.011016]
	Learning Rate: 0.0110155
	LOSS [training: 0.6640896525278396 | validation: 0.4160580044800143]
	TIME [epoch: 8.3 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6680571760972033		[learning rate: 0.010999]
	Learning Rate: 0.0109991
	LOSS [training: 0.6680571760972033 | validation: 0.9415600015473404]
	TIME [epoch: 8.27 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6444106352674648		[learning rate: 0.010983]
	Learning Rate: 0.0109826
	LOSS [training: 0.6444106352674648 | validation: 0.39584773729634504]
	TIME [epoch: 8.27 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7001439112129513		[learning rate: 0.010966]
	Learning Rate: 0.0109662
	LOSS [training: 0.7001439112129513 | validation: 0.5005890092559924]
	TIME [epoch: 8.27 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6138030992313908		[learning rate: 0.01095]
	Learning Rate: 0.0109497
	LOSS [training: 0.6138030992313908 | validation: 0.6702752732314103]
	TIME [epoch: 8.26 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5821419994197158		[learning rate: 0.010933]
	Learning Rate: 0.0109333
	LOSS [training: 0.5821419994197158 | validation: 0.45555108390733756]
	TIME [epoch: 8.3 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5108705308024593		[learning rate: 0.010917]
	Learning Rate: 0.0109168
	LOSS [training: 0.5108705308024593 | validation: 0.5586807591168748]
	TIME [epoch: 8.28 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5769922856293788		[learning rate: 0.0109]
	Learning Rate: 0.0109004
	LOSS [training: 0.5769922856293788 | validation: 0.7347747040099832]
	TIME [epoch: 8.26 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5551627100481207		[learning rate: 0.010884]
	Learning Rate: 0.0108839
	LOSS [training: 0.5551627100481207 | validation: 0.9171879542818772]
	TIME [epoch: 8.26 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6278565572573023		[learning rate: 0.010867]
	Learning Rate: 0.0108674
	LOSS [training: 0.6278565572573023 | validation: 0.6434758180002604]
	TIME [epoch: 8.26 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5851173502562146		[learning rate: 0.010851]
	Learning Rate: 0.010851
	LOSS [training: 0.5851173502562146 | validation: 0.9702403150434106]
	TIME [epoch: 8.27 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7198935228770879		[learning rate: 0.010834]
	Learning Rate: 0.0108345
	LOSS [training: 0.7198935228770879 | validation: 0.535030461188069]
	TIME [epoch: 8.31 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5159519072518566		[learning rate: 0.010818]
	Learning Rate: 0.010818
	LOSS [training: 0.5159519072518566 | validation: 0.5823436671454446]
	TIME [epoch: 8.27 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5893546453355293		[learning rate: 0.010802]
	Learning Rate: 0.0108016
	LOSS [training: 0.5893546453355293 | validation: 0.5097373544134296]
	TIME [epoch: 8.26 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5200086977929438		[learning rate: 0.010785]
	Learning Rate: 0.0107851
	LOSS [training: 0.5200086977929438 | validation: 0.4641580966015897]
	TIME [epoch: 8.26 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5088260460405802		[learning rate: 0.010769]
	Learning Rate: 0.0107686
	LOSS [training: 0.5088260460405802 | validation: 0.4768406083010116]
	TIME [epoch: 8.27 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5155067666513233		[learning rate: 0.010752]
	Learning Rate: 0.0107521
	LOSS [training: 0.5155067666513233 | validation: 0.44479199551228443]
	TIME [epoch: 8.3 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4921859580103296		[learning rate: 0.010736]
	Learning Rate: 0.0107356
	LOSS [training: 0.4921859580103296 | validation: 0.5750709240651684]
	TIME [epoch: 8.27 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5607966800778692		[learning rate: 0.010719]
	Learning Rate: 0.0107192
	LOSS [training: 0.5607966800778692 | validation: 0.34502461318164146]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_957.pth
	Model improved!!!
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4945236493157754		[learning rate: 0.010703]
	Learning Rate: 0.0107027
	LOSS [training: 0.4945236493157754 | validation: 0.4055342726611758]
	TIME [epoch: 8.27 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42905884028681085		[learning rate: 0.010686]
	Learning Rate: 0.0106862
	LOSS [training: 0.42905884028681085 | validation: 0.6365342424321159]
	TIME [epoch: 8.55 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5950780398389736		[learning rate: 0.01067]
	Learning Rate: 0.0106697
	LOSS [training: 0.5950780398389736 | validation: 0.45651058739418937]
	TIME [epoch: 8.28 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4440214704934955		[learning rate: 0.010653]
	Learning Rate: 0.0106532
	LOSS [training: 0.4440214704934955 | validation: 0.37269665523974727]
	TIME [epoch: 8.31 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5103548225258074		[learning rate: 0.010637]
	Learning Rate: 0.0106367
	LOSS [training: 0.5103548225258074 | validation: 0.5319565033851589]
	TIME [epoch: 8.28 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5369412848077236		[learning rate: 0.01062]
	Learning Rate: 0.0106202
	LOSS [training: 0.5369412848077236 | validation: 0.3761717693615594]
	TIME [epoch: 8.27 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.514648452420306		[learning rate: 0.010604]
	Learning Rate: 0.0106037
	LOSS [training: 0.514648452420306 | validation: 0.4072902752090643]
	TIME [epoch: 8.27 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5050757500250644		[learning rate: 0.010587]
	Learning Rate: 0.0105872
	LOSS [training: 0.5050757500250644 | validation: 0.4156076367162835]
	TIME [epoch: 8.27 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4904855820105908		[learning rate: 0.010571]
	Learning Rate: 0.0105707
	LOSS [training: 0.4904855820105908 | validation: 0.5463032322531025]
	TIME [epoch: 8.29 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5924363862319862		[learning rate: 0.010554]
	Learning Rate: 0.0105542
	LOSS [training: 0.5924363862319862 | validation: 0.5300690012799403]
	TIME [epoch: 8.3 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4873820761854051		[learning rate: 0.010538]
	Learning Rate: 0.0105377
	LOSS [training: 0.4873820761854051 | validation: 0.4070738891033343]
	TIME [epoch: 8.27 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4662830423410944		[learning rate: 0.010521]
	Learning Rate: 0.0105212
	LOSS [training: 0.4662830423410944 | validation: 0.48769263411689157]
	TIME [epoch: 8.27 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.510807346961244		[learning rate: 0.010505]
	Learning Rate: 0.0105047
	LOSS [training: 0.510807346961244 | validation: 0.4021029035753755]
	TIME [epoch: 8.27 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4660958716405268		[learning rate: 0.010488]
	Learning Rate: 0.0104882
	LOSS [training: 0.4660958716405268 | validation: 0.39024939888132126]
	TIME [epoch: 8.27 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4880926268937493		[learning rate: 0.010472]
	Learning Rate: 0.0104717
	LOSS [training: 0.4880926268937493 | validation: 0.3994709737534517]
	TIME [epoch: 8.31 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44065371764407235		[learning rate: 0.010455]
	Learning Rate: 0.0104552
	LOSS [training: 0.44065371764407235 | validation: 0.40003770156603335]
	TIME [epoch: 8.28 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5181791493699817		[learning rate: 0.010439]
	Learning Rate: 0.0104387
	LOSS [training: 0.5181791493699817 | validation: 0.5449673506679363]
	TIME [epoch: 8.27 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.500563964209789		[learning rate: 0.010422]
	Learning Rate: 0.0104222
	LOSS [training: 0.500563964209789 | validation: 0.4438975844286055]
	TIME [epoch: 8.27 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5655986538954796		[learning rate: 0.010406]
	Learning Rate: 0.0104057
	LOSS [training: 0.5655986538954796 | validation: 0.4312206323411913]
	TIME [epoch: 8.27 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5261214773978936		[learning rate: 0.010389]
	Learning Rate: 0.0103891
	LOSS [training: 0.5261214773978936 | validation: 0.40358399079264606]
	TIME [epoch: 8.28 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4524883317306365		[learning rate: 0.010373]
	Learning Rate: 0.0103726
	LOSS [training: 0.4524883317306365 | validation: 0.4024340974249224]
	TIME [epoch: 8.31 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6057640855917389		[learning rate: 0.010356]
	Learning Rate: 0.0103561
	LOSS [training: 0.6057640855917389 | validation: 0.5692061910703536]
	TIME [epoch: 8.27 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49149703101922215		[learning rate: 0.01034]
	Learning Rate: 0.0103396
	LOSS [training: 0.49149703101922215 | validation: 0.3832196822897715]
	TIME [epoch: 8.27 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3994559325292533		[learning rate: 0.010323]
	Learning Rate: 0.0103231
	LOSS [training: 0.3994559325292533 | validation: 0.5043062499186248]
	TIME [epoch: 8.27 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5063967174205741		[learning rate: 0.010307]
	Learning Rate: 0.0103066
	LOSS [training: 0.5063967174205741 | validation: 1.1443981167530906]
	TIME [epoch: 8.27 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9788638639236226		[learning rate: 0.01029]
	Learning Rate: 0.01029
	LOSS [training: 0.9788638639236226 | validation: 0.6213890683647229]
	TIME [epoch: 8.3 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5999330836314616		[learning rate: 0.010274]
	Learning Rate: 0.0102735
	LOSS [training: 0.5999330836314616 | validation: 0.5195284840152701]
	TIME [epoch: 8.29 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5893083786967946		[learning rate: 0.010257]
	Learning Rate: 0.010257
	LOSS [training: 0.5893083786967946 | validation: 0.4172482981190103]
	TIME [epoch: 8.27 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5810012337072284		[learning rate: 0.01024]
	Learning Rate: 0.0102405
	LOSS [training: 0.5810012337072284 | validation: 0.5603539071487276]
	TIME [epoch: 8.27 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.609306820756231		[learning rate: 0.010224]
	Learning Rate: 0.010224
	LOSS [training: 0.609306820756231 | validation: 0.38174404810276263]
	TIME [epoch: 8.27 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6642862818877708		[learning rate: 0.010207]
	Learning Rate: 0.0102074
	LOSS [training: 0.6642862818877708 | validation: 0.5424319516894147]
	TIME [epoch: 8.28 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5948111619171819		[learning rate: 0.010191]
	Learning Rate: 0.0101909
	LOSS [training: 0.5948111619171819 | validation: 0.49264015282513063]
	TIME [epoch: 8.32 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5755572674290118		[learning rate: 0.010174]
	Learning Rate: 0.0101744
	LOSS [training: 0.5755572674290118 | validation: 0.4893860491005688]
	TIME [epoch: 8.28 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5348021753882412		[learning rate: 0.010158]
	Learning Rate: 0.0101579
	LOSS [training: 0.5348021753882412 | validation: 0.3916280588933534]
	TIME [epoch: 8.27 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.478472709192002		[learning rate: 0.010141]
	Learning Rate: 0.0101413
	LOSS [training: 0.478472709192002 | validation: 0.4291947521089129]
	TIME [epoch: 8.27 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5275550421889884		[learning rate: 0.010125]
	Learning Rate: 0.0101248
	LOSS [training: 0.5275550421889884 | validation: 0.535121369640043]
	TIME [epoch: 8.27 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5198867299422542		[learning rate: 0.010108]
	Learning Rate: 0.0101083
	LOSS [training: 0.5198867299422542 | validation: 0.36178887175031293]
	TIME [epoch: 8.3 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4042038822958841		[learning rate: 0.010092]
	Learning Rate: 0.0100918
	LOSS [training: 0.4042038822958841 | validation: 0.8720110687790482]
	TIME [epoch: 8.29 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6606504521989073		[learning rate: 0.010075]
	Learning Rate: 0.0100752
	LOSS [training: 0.6606504521989073 | validation: 0.4391231184308803]
	TIME [epoch: 8.27 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.464195392895925		[learning rate: 0.010059]
	Learning Rate: 0.0100587
	LOSS [training: 0.464195392895925 | validation: 0.446972126978515]
	TIME [epoch: 8.27 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4460182610653676		[learning rate: 0.010042]
	Learning Rate: 0.0100422
	LOSS [training: 0.4460182610653676 | validation: 0.5096894706027142]
	TIME [epoch: 8.27 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6564920735142484		[learning rate: 0.010026]
	Learning Rate: 0.0100257
	LOSS [training: 0.6564920735142484 | validation: 0.5327490096486005]
	TIME [epoch: 8.27 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4762435035904721		[learning rate: 0.010009]
	Learning Rate: 0.0100091
	LOSS [training: 0.4762435035904721 | validation: 0.38293285149881384]
	TIME [epoch: 8.32 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42485985865768716		[learning rate: 0.0099926]
	Learning Rate: 0.00999261
	LOSS [training: 0.42485985865768716 | validation: 0.3500670240303827]
	TIME [epoch: 8.28 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6296972289662096		[learning rate: 0.0099761]
	Learning Rate: 0.00997608
	LOSS [training: 0.6296972289662096 | validation: 0.3701126769229677]
	TIME [epoch: 8.27 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49771269318488665		[learning rate: 0.0099596]
	Learning Rate: 0.00995955
	LOSS [training: 0.49771269318488665 | validation: 0.28679447728377383]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_1003.pth
	Model improved!!!
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42102463189479467		[learning rate: 0.009943]
	Learning Rate: 0.00994303
	LOSS [training: 0.42102463189479467 | validation: 0.4925572652018776]
	TIME [epoch: 8.28 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5277619576569637		[learning rate: 0.0099265]
	Learning Rate: 0.0099265
	LOSS [training: 0.5277619576569637 | validation: 0.29028809230361646]
	TIME [epoch: 8.3 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45900836158412056		[learning rate: 0.00991]
	Learning Rate: 0.00990997
	LOSS [training: 0.45900836158412056 | validation: 0.3337054478954901]
	TIME [epoch: 8.3 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3808547109426551		[learning rate: 0.0098934]
	Learning Rate: 0.00989345
	LOSS [training: 0.3808547109426551 | validation: 0.9932543643993523]
	TIME [epoch: 8.28 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6109220466186364		[learning rate: 0.0098769]
	Learning Rate: 0.00987692
	LOSS [training: 0.6109220466186364 | validation: 0.38702189516352625]
	TIME [epoch: 8.28 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41953392507086695		[learning rate: 0.0098604]
	Learning Rate: 0.0098604
	LOSS [training: 0.41953392507086695 | validation: 0.34828396266122486]
	TIME [epoch: 8.28 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4232737930595805		[learning rate: 0.0098439]
	Learning Rate: 0.00984387
	LOSS [training: 0.4232737930595805 | validation: 0.34070577199531227]
	TIME [epoch: 8.28 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46187732211342114		[learning rate: 0.0098274]
	Learning Rate: 0.00982735
	LOSS [training: 0.46187732211342114 | validation: 0.32187427842520644]
	TIME [epoch: 8.32 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4761528329382133		[learning rate: 0.0098108]
	Learning Rate: 0.00981083
	LOSS [training: 0.4761528329382133 | validation: 0.2669463028961768]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_1012.pth
	Model improved!!!
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46189082548546856		[learning rate: 0.0097943]
	Learning Rate: 0.0097943
	LOSS [training: 0.46189082548546856 | validation: 0.37851192221371655]
	TIME [epoch: 8.27 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45454609566036996		[learning rate: 0.0097778]
	Learning Rate: 0.00977778
	LOSS [training: 0.45454609566036996 | validation: 0.3000878446618067]
	TIME [epoch: 8.27 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33025872257917754		[learning rate: 0.0097613]
	Learning Rate: 0.00976126
	LOSS [training: 0.33025872257917754 | validation: 0.34999028886504524]
	TIME [epoch: 8.27 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49871535891376667		[learning rate: 0.0097447]
	Learning Rate: 0.00974474
	LOSS [training: 0.49871535891376667 | validation: 0.3710315414785932]
	TIME [epoch: 8.28 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4386456861892397		[learning rate: 0.0097282]
	Learning Rate: 0.00972822
	LOSS [training: 0.4386456861892397 | validation: 0.27142539156208045]
	TIME [epoch: 8.3 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39489866087568165		[learning rate: 0.0097117]
	Learning Rate: 0.0097117
	LOSS [training: 0.39489866087568165 | validation: 0.40374001899232265]
	TIME [epoch: 8.27 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44636213261281865		[learning rate: 0.0096952]
	Learning Rate: 0.00969518
	LOSS [training: 0.44636213261281865 | validation: 0.37351893289631116]
	TIME [epoch: 8.27 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37609753059635875		[learning rate: 0.0096787]
	Learning Rate: 0.00967866
	LOSS [training: 0.37609753059635875 | validation: 0.2797306382848496]
	TIME [epoch: 8.27 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3906555748396482		[learning rate: 0.0096621]
	Learning Rate: 0.00966214
	LOSS [training: 0.3906555748396482 | validation: 0.5540679234025921]
	TIME [epoch: 8.26 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6268549308421247		[learning rate: 0.0096456]
	Learning Rate: 0.00964563
	LOSS [training: 0.6268549308421247 | validation: 0.36735624092420105]
	TIME [epoch: 8.31 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33720083806472934		[learning rate: 0.0096291]
	Learning Rate: 0.00962911
	LOSS [training: 0.33720083806472934 | validation: 0.4369374419787523]
	TIME [epoch: 8.28 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5025804290004282		[learning rate: 0.0096126]
	Learning Rate: 0.0096126
	LOSS [training: 0.5025804290004282 | validation: 0.2372565420023303]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_1024.pth
	Model improved!!!
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3765882164502886		[learning rate: 0.0095961]
	Learning Rate: 0.00959609
	LOSS [training: 0.3765882164502886 | validation: 0.47126683604070535]
	TIME [epoch: 8.26 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6289935739926787		[learning rate: 0.0095796]
	Learning Rate: 0.00957957
	LOSS [training: 0.6289935739926787 | validation: 0.3014686083040028]
	TIME [epoch: 8.26 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3783157590950866		[learning rate: 0.0095631]
	Learning Rate: 0.00956306
	LOSS [training: 0.3783157590950866 | validation: 0.36185516624039316]
	TIME [epoch: 8.27 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48565560153922105		[learning rate: 0.0095466]
	Learning Rate: 0.00954655
	LOSS [training: 0.48565560153922105 | validation: 0.2734712292520583]
	TIME [epoch: 8.31 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4283273807299846		[learning rate: 0.00953]
	Learning Rate: 0.00953004
	LOSS [training: 0.4283273807299846 | validation: 0.3511178305426574]
	TIME [epoch: 8.27 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41413166053646927		[learning rate: 0.0095135]
	Learning Rate: 0.00951354
	LOSS [training: 0.41413166053646927 | validation: 0.5174844707425059]
	TIME [epoch: 8.26 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40044362091710356		[learning rate: 0.009497]
	Learning Rate: 0.00949703
	LOSS [training: 0.40044362091710356 | validation: 0.38284451553365784]
	TIME [epoch: 8.26 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48783339449052565		[learning rate: 0.0094805]
	Learning Rate: 0.00948053
	LOSS [training: 0.48783339449052565 | validation: 0.3650764275423507]
	TIME [epoch: 8.26 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4215721602098185		[learning rate: 0.009464]
	Learning Rate: 0.00946402
	LOSS [training: 0.4215721602098185 | validation: 0.3292182869266005]
	TIME [epoch: 8.3 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4084518921043624		[learning rate: 0.0094475]
	Learning Rate: 0.00944752
	LOSS [training: 0.4084518921043624 | validation: 0.516810771803712]
	TIME [epoch: 8.29 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4362786792144158		[learning rate: 0.009431]
	Learning Rate: 0.00943102
	LOSS [training: 0.4362786792144158 | validation: 0.35942432798661805]
	TIME [epoch: 8.27 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43749900455254803		[learning rate: 0.0094145]
	Learning Rate: 0.00941452
	LOSS [training: 0.43749900455254803 | validation: 0.2742134996823611]
	TIME [epoch: 8.27 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4073476426901991		[learning rate: 0.009398]
	Learning Rate: 0.00939803
	LOSS [training: 0.4073476426901991 | validation: 0.2545323937923705]
	TIME [epoch: 8.27 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4349618804685628		[learning rate: 0.0093815]
	Learning Rate: 0.00938153
	LOSS [training: 0.4349618804685628 | validation: 0.4607786718146636]
	TIME [epoch: 8.27 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43386808211909444		[learning rate: 0.009365]
	Learning Rate: 0.00936504
	LOSS [training: 0.43386808211909444 | validation: 0.33412410354926614]
	TIME [epoch: 8.31 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39486121718158007		[learning rate: 0.0093485]
	Learning Rate: 0.00934855
	LOSS [training: 0.39486121718158007 | validation: 0.219733505474493]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_1040.pth
	Model improved!!!
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31451429709949735		[learning rate: 0.0093321]
	Learning Rate: 0.00933206
	LOSS [training: 0.31451429709949735 | validation: 0.28438868174092957]
	TIME [epoch: 8.27 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42623351953336347		[learning rate: 0.0093156]
	Learning Rate: 0.00931557
	LOSS [training: 0.42623351953336347 | validation: 0.4961645291965513]
	TIME [epoch: 8.26 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46928814288443604		[learning rate: 0.0092991]
	Learning Rate: 0.00929908
	LOSS [training: 0.46928814288443604 | validation: 0.2700502041205517]
	TIME [epoch: 8.26 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28774977819471775		[learning rate: 0.0092826]
	Learning Rate: 0.0092826
	LOSS [training: 0.28774977819471775 | validation: 0.34361619605997606]
	TIME [epoch: 8.31 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5111633412918355		[learning rate: 0.0092661]
	Learning Rate: 0.00926612
	LOSS [training: 0.5111633412918355 | validation: 0.4312503856554296]
	TIME [epoch: 8.3 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4561895258014		[learning rate: 0.0092496]
	Learning Rate: 0.00924964
	LOSS [training: 0.4561895258014 | validation: 0.6516106968995967]
	TIME [epoch: 8.26 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47211410174113505		[learning rate: 0.0092332]
	Learning Rate: 0.00923316
	LOSS [training: 0.47211410174113505 | validation: 0.3280531134956186]
	TIME [epoch: 8.26 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5144590595200819		[learning rate: 0.0092167]
	Learning Rate: 0.00921668
	LOSS [training: 0.5144590595200819 | validation: 0.4403335017944333]
	TIME [epoch: 8.26 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.415804638562466		[learning rate: 0.0092002]
	Learning Rate: 0.00920021
	LOSS [training: 0.415804638562466 | validation: 0.314884926053469]
	TIME [epoch: 8.26 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.433337376397178		[learning rate: 0.0091837]
	Learning Rate: 0.00918374
	LOSS [training: 0.433337376397178 | validation: 0.27272267116710347]
	TIME [epoch: 8.31 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39987636108198477		[learning rate: 0.0091673]
	Learning Rate: 0.00916727
	LOSS [training: 0.39987636108198477 | validation: 0.5292558118006854]
	TIME [epoch: 8.26 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4435334128127202		[learning rate: 0.0091508]
	Learning Rate: 0.0091508
	LOSS [training: 0.4435334128127202 | validation: 0.5606796397018727]
	TIME [epoch: 8.26 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5035051461002551		[learning rate: 0.0091343]
	Learning Rate: 0.00913434
	LOSS [training: 0.5035051461002551 | validation: 0.3708932597996529]
	TIME [epoch: 8.26 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3359033888428621		[learning rate: 0.0091179]
	Learning Rate: 0.00911787
	LOSS [training: 0.3359033888428621 | validation: 0.3641072717434216]
	TIME [epoch: 8.26 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40996811315993736		[learning rate: 0.0091014]
	Learning Rate: 0.00910141
	LOSS [training: 0.40996811315993736 | validation: 0.3756873511134493]
	TIME [epoch: 8.27 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3858226435812458		[learning rate: 0.009085]
	Learning Rate: 0.00908496
	LOSS [training: 0.3858226435812458 | validation: 0.3036554972331923]
	TIME [epoch: 8.3 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4075654369462334		[learning rate: 0.0090685]
	Learning Rate: 0.0090685
	LOSS [training: 0.4075654369462334 | validation: 0.4284461732958238]
	TIME [epoch: 8.26 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4291224512253312		[learning rate: 0.009052]
	Learning Rate: 0.00905205
	LOSS [training: 0.4291224512253312 | validation: 0.3872343890599237]
	TIME [epoch: 8.26 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39454651882254355		[learning rate: 0.0090356]
	Learning Rate: 0.0090356
	LOSS [training: 0.39454651882254355 | validation: 0.3062754845525888]
	TIME [epoch: 8.26 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29175402204335965		[learning rate: 0.0090192]
	Learning Rate: 0.00901915
	LOSS [training: 0.29175402204335965 | validation: 0.6351590984784896]
	TIME [epoch: 8.26 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3285235566609613		[learning rate: 0.0090027]
	Learning Rate: 0.00900271
	LOSS [training: 0.3285235566609613 | validation: 0.3377111342504814]
	TIME [epoch: 8.3 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5337619509039453		[learning rate: 0.0089863]
	Learning Rate: 0.00898627
	LOSS [training: 0.5337619509039453 | validation: 0.5054390063926082]
	TIME [epoch: 8.27 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4106691916141054		[learning rate: 0.0089698]
	Learning Rate: 0.00896983
	LOSS [training: 0.4106691916141054 | validation: 0.38365169700326407]
	TIME [epoch: 8.26 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4288202299213048		[learning rate: 0.0089534]
	Learning Rate: 0.00895339
	LOSS [training: 0.4288202299213048 | validation: 0.342023771321962]
	TIME [epoch: 8.26 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39461706166292915		[learning rate: 0.008937]
	Learning Rate: 0.00893696
	LOSS [training: 0.39461706166292915 | validation: 0.2631558041169108]
	TIME [epoch: 8.26 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38350571559974383		[learning rate: 0.0089205]
	Learning Rate: 0.00892053
	LOSS [training: 0.38350571559974383 | validation: 0.4370450317082343]
	TIME [epoch: 8.27 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34770248166725815		[learning rate: 0.0089041]
	Learning Rate: 0.0089041
	LOSS [training: 0.34770248166725815 | validation: 0.43365671190219884]
	TIME [epoch: 8.31 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4022310358630924		[learning rate: 0.0088877]
	Learning Rate: 0.00888767
	LOSS [training: 0.4022310358630924 | validation: 0.6604078448029043]
	TIME [epoch: 8.26 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5000866656660287		[learning rate: 0.0088713]
	Learning Rate: 0.00887125
	LOSS [training: 0.5000866656660287 | validation: 0.41819714524038637]
	TIME [epoch: 8.26 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3819964114938118		[learning rate: 0.0088548]
	Learning Rate: 0.00885484
	LOSS [training: 0.3819964114938118 | validation: 0.34872813672255065]
	TIME [epoch: 8.26 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40850914509158204		[learning rate: 0.0088384]
	Learning Rate: 0.00883842
	LOSS [training: 0.40850914509158204 | validation: 0.4777029731865907]
	TIME [epoch: 8.26 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2911300538771405		[learning rate: 0.008822]
	Learning Rate: 0.00882201
	LOSS [training: 0.2911300538771405 | validation: 0.398409242176451]
	TIME [epoch: 8.29 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4238255840883873		[learning rate: 0.0088056]
	Learning Rate: 0.0088056
	LOSS [training: 0.4238255840883873 | validation: 0.29254791528204754]
	TIME [epoch: 8.28 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4095221554199499		[learning rate: 0.0087892]
	Learning Rate: 0.00878919
	LOSS [training: 0.4095221554199499 | validation: 0.4176295140345306]
	TIME [epoch: 8.26 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3798213033916051		[learning rate: 0.0087728]
	Learning Rate: 0.00877279
	LOSS [training: 0.3798213033916051 | validation: 0.3994566894598927]
	TIME [epoch: 8.26 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33136744696731		[learning rate: 0.0087564]
	Learning Rate: 0.00875639
	LOSS [training: 0.33136744696731 | validation: 0.36897845450363687]
	TIME [epoch: 8.26 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42945251028104015		[learning rate: 0.00874]
	Learning Rate: 0.00874
	LOSS [training: 0.42945251028104015 | validation: 0.2764129170346781]
	TIME [epoch: 8.26 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3618881505406623		[learning rate: 0.0087236]
	Learning Rate: 0.00872361
	LOSS [training: 0.3618881505406623 | validation: 0.329343206619036]
	TIME [epoch: 8.31 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36167000814830585		[learning rate: 0.0087072]
	Learning Rate: 0.00870722
	LOSS [training: 0.36167000814830585 | validation: 0.40183025660516575]
	TIME [epoch: 8.27 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3883269254077889		[learning rate: 0.0086908]
	Learning Rate: 0.00869083
	LOSS [training: 0.3883269254077889 | validation: 0.3689669606108832]
	TIME [epoch: 8.26 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3645355296101556		[learning rate: 0.0086745]
	Learning Rate: 0.00867445
	LOSS [training: 0.3645355296101556 | validation: 0.33537451212546965]
	TIME [epoch: 8.26 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2832025784257401		[learning rate: 0.0086581]
	Learning Rate: 0.00865807
	LOSS [training: 0.2832025784257401 | validation: 0.36187142678874584]
	TIME [epoch: 8.26 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3605226481315906		[learning rate: 0.0086417]
	Learning Rate: 0.0086417
	LOSS [training: 0.3605226481315906 | validation: 0.511594471878661]
	TIME [epoch: 8.28 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4470904049722998		[learning rate: 0.0086253]
	Learning Rate: 0.00862533
	LOSS [training: 0.4470904049722998 | validation: 0.3835913897505448]
	TIME [epoch: 8.3 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39569767142121093		[learning rate: 0.008609]
	Learning Rate: 0.00860896
	LOSS [training: 0.39569767142121093 | validation: 0.35340582466828263]
	TIME [epoch: 8.27 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3751217203276399		[learning rate: 0.0085926]
	Learning Rate: 0.0085926
	LOSS [training: 0.3751217203276399 | validation: 0.32842178617504497]
	TIME [epoch: 8.27 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29142002408937795		[learning rate: 0.0085762]
	Learning Rate: 0.00857624
	LOSS [training: 0.29142002408937795 | validation: 0.4240008017511628]
	TIME [epoch: 8.26 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28184792432369754		[learning rate: 0.0085599]
	Learning Rate: 0.00855989
	LOSS [training: 0.28184792432369754 | validation: 0.49310714134512407]
	TIME [epoch: 8.27 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42880951745669704		[learning rate: 0.0085435]
	Learning Rate: 0.00854354
	LOSS [training: 0.42880951745669704 | validation: 0.31342483440621227]
	TIME [epoch: 8.3 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4404283384905392		[learning rate: 0.0085272]
	Learning Rate: 0.00852719
	LOSS [training: 0.4404283384905392 | validation: 0.3408436042571099]
	TIME [epoch: 8.31 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3849852409338594		[learning rate: 0.0085108]
	Learning Rate: 0.00851085
	LOSS [training: 0.3849852409338594 | validation: 0.6990584924280323]
	TIME [epoch: 8.26 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4062478714112299		[learning rate: 0.0084945]
	Learning Rate: 0.00849451
	LOSS [training: 0.4062478714112299 | validation: 0.30488010134836124]
	TIME [epoch: 8.27 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44936366218762247		[learning rate: 0.0084782]
	Learning Rate: 0.00847817
	LOSS [training: 0.44936366218762247 | validation: 0.3666614914481797]
	TIME [epoch: 8.27 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38640115616153525		[learning rate: 0.0084618]
	Learning Rate: 0.00846184
	LOSS [training: 0.38640115616153525 | validation: 0.6111774143630629]
	TIME [epoch: 8.27 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.395106602077028		[learning rate: 0.0084455]
	Learning Rate: 0.00844552
	LOSS [training: 0.395106602077028 | validation: 0.41782965923633497]
	TIME [epoch: 8.31 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38309176955698543		[learning rate: 0.0084292]
	Learning Rate: 0.0084292
	LOSS [training: 0.38309176955698543 | validation: 0.4039235344200015]
	TIME [epoch: 8.27 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4686788780478071		[learning rate: 0.0084129]
	Learning Rate: 0.00841288
	LOSS [training: 0.4686788780478071 | validation: 0.36745674124530703]
	TIME [epoch: 8.26 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3488560529086324		[learning rate: 0.0083966]
	Learning Rate: 0.00839657
	LOSS [training: 0.3488560529086324 | validation: 0.3054764785012114]
	TIME [epoch: 8.26 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3372614586745675		[learning rate: 0.0083803]
	Learning Rate: 0.00838026
	LOSS [training: 0.3372614586745675 | validation: 0.3240069491585087]
	TIME [epoch: 8.27 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3506013476458776		[learning rate: 0.008364]
	Learning Rate: 0.00836395
	LOSS [training: 0.3506013476458776 | validation: 0.29945938274933753]
	TIME [epoch: 8.3 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3281710078333676		[learning rate: 0.0083477]
	Learning Rate: 0.00834765
	LOSS [training: 0.3281710078333676 | validation: 0.24479332793422603]
	TIME [epoch: 8.28 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27440518448829077		[learning rate: 0.0083314]
	Learning Rate: 0.00833136
	LOSS [training: 0.27440518448829077 | validation: 0.2084745740511757]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_1102.pth
	Model improved!!!
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4493060269559548		[learning rate: 0.0083151]
	Learning Rate: 0.00831507
	LOSS [training: 0.4493060269559548 | validation: 0.3429699610088752]
	TIME [epoch: 8.26 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37243895749690725		[learning rate: 0.0082988]
	Learning Rate: 0.00829878
	LOSS [training: 0.37243895749690725 | validation: 0.3505429109542524]
	TIME [epoch: 8.25 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2892453478904636		[learning rate: 0.0082825]
	Learning Rate: 0.0082825
	LOSS [training: 0.2892453478904636 | validation: 0.4765514080738526]
	TIME [epoch: 8.26 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4279967559918072		[learning rate: 0.0082662]
	Learning Rate: 0.00826622
	LOSS [training: 0.4279967559918072 | validation: 0.20385005508739615]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_1106.pth
	Model improved!!!
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4161575972644523		[learning rate: 0.0082499]
	Learning Rate: 0.00824995
	LOSS [training: 0.4161575972644523 | validation: 0.2950915497416728]
	TIME [epoch: 8.27 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34667066739543617		[learning rate: 0.0082337]
	Learning Rate: 0.00823368
	LOSS [training: 0.34667066739543617 | validation: 0.3137296636040725]
	TIME [epoch: 8.27 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3896964312675364		[learning rate: 0.0082174]
	Learning Rate: 0.00821742
	LOSS [training: 0.3896964312675364 | validation: 0.26943819005693526]
	TIME [epoch: 8.27 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3031664924129958		[learning rate: 0.0082012]
	Learning Rate: 0.00820116
	LOSS [training: 0.3031664924129958 | validation: 0.35639990203742644]
	TIME [epoch: 8.27 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.392405473200366		[learning rate: 0.0081849]
	Learning Rate: 0.00818491
	LOSS [training: 0.392405473200366 | validation: 0.2620233493875913]
	TIME [epoch: 8.3 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3003310563638344		[learning rate: 0.0081687]
	Learning Rate: 0.00816866
	LOSS [training: 0.3003310563638344 | validation: 0.5226302291143227]
	TIME [epoch: 8.29 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4821658049533746		[learning rate: 0.0081524]
	Learning Rate: 0.00815242
	LOSS [training: 0.4821658049533746 | validation: 0.3467096377951985]
	TIME [epoch: 8.27 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3521990830618443		[learning rate: 0.0081362]
	Learning Rate: 0.00813618
	LOSS [training: 0.3521990830618443 | validation: 0.2812593908876174]
	TIME [epoch: 8.27 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3592635490267532		[learning rate: 0.00812]
	Learning Rate: 0.00811995
	LOSS [training: 0.3592635490267532 | validation: 0.25425458381167076]
	TIME [epoch: 8.27 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34093068748582134		[learning rate: 0.0081037]
	Learning Rate: 0.00810372
	LOSS [training: 0.34093068748582134 | validation: 0.4545486013556671]
	TIME [epoch: 8.27 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3562729484900733		[learning rate: 0.0080875]
	Learning Rate: 0.0080875
	LOSS [training: 0.3562729484900733 | validation: 0.4129233836650284]
	TIME [epoch: 8.32 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3492935168790178		[learning rate: 0.0080713]
	Learning Rate: 0.00807128
	LOSS [training: 0.3492935168790178 | validation: 0.354161761307004]
	TIME [epoch: 8.27 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3312667753539586		[learning rate: 0.0080551]
	Learning Rate: 0.00805507
	LOSS [training: 0.3312667753539586 | validation: 0.2889831182282844]
	TIME [epoch: 8.27 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34643416935304844		[learning rate: 0.0080389]
	Learning Rate: 0.00803887
	LOSS [training: 0.34643416935304844 | validation: 0.3695296530272643]
	TIME [epoch: 8.27 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4683875644065581		[learning rate: 0.0080227]
	Learning Rate: 0.00802267
	LOSS [training: 0.4683875644065581 | validation: 0.7029097531660642]
	TIME [epoch: 8.27 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.492796380207667		[learning rate: 0.0080065]
	Learning Rate: 0.00800647
	LOSS [training: 0.492796380207667 | validation: 0.2877721193195639]
	TIME [epoch: 8.29 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33080969977439106		[learning rate: 0.0079903]
	Learning Rate: 0.00799028
	LOSS [training: 0.33080969977439106 | validation: 0.29431747877879466]
	TIME [epoch: 8.3 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28964434461548094		[learning rate: 0.0079741]
	Learning Rate: 0.0079741
	LOSS [training: 0.28964434461548094 | validation: 0.29524088802866144]
	TIME [epoch: 8.27 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3243639803494091		[learning rate: 0.0079579]
	Learning Rate: 0.00795792
	LOSS [training: 0.3243639803494091 | validation: 0.3010253386541838]
	TIME [epoch: 8.27 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4841703070675346		[learning rate: 0.0079417]
	Learning Rate: 0.00794174
	LOSS [training: 0.4841703070675346 | validation: 0.29029785131964236]
	TIME [epoch: 8.27 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36392313323331626		[learning rate: 0.0079256]
	Learning Rate: 0.00792558
	LOSS [training: 0.36392313323331626 | validation: 0.3590033766162103]
	TIME [epoch: 8.27 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36185124086264764		[learning rate: 0.0079094]
	Learning Rate: 0.00790941
	LOSS [training: 0.36185124086264764 | validation: 0.29584249102577787]
	TIME [epoch: 8.31 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45324014469020835		[learning rate: 0.0078933]
	Learning Rate: 0.00789326
	LOSS [training: 0.45324014469020835 | validation: 0.4368325169621394]
	TIME [epoch: 8.27 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34294134157380496		[learning rate: 0.0078771]
	Learning Rate: 0.00787711
	LOSS [training: 0.34294134157380496 | validation: 0.3137539660334213]
	TIME [epoch: 8.27 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2883482050765766		[learning rate: 0.007861]
	Learning Rate: 0.00786096
	LOSS [training: 0.2883482050765766 | validation: 0.3073306306146595]
	TIME [epoch: 8.27 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3017872295049613		[learning rate: 0.0078448]
	Learning Rate: 0.00784482
	LOSS [training: 0.3017872295049613 | validation: 0.3475520168177657]
	TIME [epoch: 8.27 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4296152601112139		[learning rate: 0.0078287]
	Learning Rate: 0.00782869
	LOSS [training: 0.4296152601112139 | validation: 0.39782965761156597]
	TIME [epoch: 8.27 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3324090106887872		[learning rate: 0.0078126]
	Learning Rate: 0.00781256
	LOSS [training: 0.3324090106887872 | validation: 0.42149859790552247]
	TIME [epoch: 8.31 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3228519417792028		[learning rate: 0.0077964]
	Learning Rate: 0.00779644
	LOSS [training: 0.3228519417792028 | validation: 0.3532734297609992]
	TIME [epoch: 8.27 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31726664534008914		[learning rate: 0.0077803]
	Learning Rate: 0.00778033
	LOSS [training: 0.31726664534008914 | validation: 0.349442229176421]
	TIME [epoch: 8.27 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3575178582780626		[learning rate: 0.0077642]
	Learning Rate: 0.00776422
	LOSS [training: 0.3575178582780626 | validation: 0.3130063620035166]
	TIME [epoch: 8.27 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3014802845127881		[learning rate: 0.0077481]
	Learning Rate: 0.00774812
	LOSS [training: 0.3014802845127881 | validation: 0.2890590865637381]
	TIME [epoch: 8.27 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3164073117094695		[learning rate: 0.007732]
	Learning Rate: 0.00773202
	LOSS [training: 0.3164073117094695 | validation: 0.24103546782177696]
	TIME [epoch: 8.3 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3763704271843138		[learning rate: 0.0077159]
	Learning Rate: 0.00771593
	LOSS [training: 0.3763704271843138 | validation: 0.2857206550560672]
	TIME [epoch: 8.29 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2974429014590967		[learning rate: 0.0076998]
	Learning Rate: 0.00769985
	LOSS [training: 0.2974429014590967 | validation: 0.2792660063981359]
	TIME [epoch: 8.27 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3342575364362532		[learning rate: 0.0076838]
	Learning Rate: 0.00768377
	LOSS [training: 0.3342575364362532 | validation: 0.2669847420238769]
	TIME [epoch: 8.27 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2759853851884901		[learning rate: 0.0076677]
	Learning Rate: 0.0076677
	LOSS [training: 0.2759853851884901 | validation: 0.2762880645646332]
	TIME [epoch: 8.27 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38311520933527254		[learning rate: 0.0076516]
	Learning Rate: 0.00765163
	LOSS [training: 0.38311520933527254 | validation: 0.38376346783667986]
	TIME [epoch: 8.33 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3925866408320773		[learning rate: 0.0076356]
	Learning Rate: 0.00763557
	LOSS [training: 0.3925866408320773 | validation: 0.24217103583115895]
	TIME [epoch: 8.31 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3233124467379354		[learning rate: 0.0076195]
	Learning Rate: 0.00761952
	LOSS [training: 0.3233124467379354 | validation: 0.17808618278371224]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_1146.pth
	Model improved!!!
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39060772260800414		[learning rate: 0.0076035]
	Learning Rate: 0.00760347
	LOSS [training: 0.39060772260800414 | validation: 0.23298488295718542]
	TIME [epoch: 8.27 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3339548980065029		[learning rate: 0.0075874]
	Learning Rate: 0.00758744
	LOSS [training: 0.3339548980065029 | validation: 0.41234299369085026]
	TIME [epoch: 8.26 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3468018256242487		[learning rate: 0.0075714]
	Learning Rate: 0.0075714
	LOSS [training: 0.3468018256242487 | validation: 0.37927920676437743]
	TIME [epoch: 8.27 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2982763687098616		[learning rate: 0.0075554]
	Learning Rate: 0.00755538
	LOSS [training: 0.2982763687098616 | validation: 0.37282081352874397]
	TIME [epoch: 8.3 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40053338947804923		[learning rate: 0.0075394]
	Learning Rate: 0.00753936
	LOSS [training: 0.40053338947804923 | validation: 0.29448688958437197]
	TIME [epoch: 8.29 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25565163232861965		[learning rate: 0.0075233]
	Learning Rate: 0.00752335
	LOSS [training: 0.25565163232861965 | validation: 0.2510964535157585]
	TIME [epoch: 8.27 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35589181845221307		[learning rate: 0.0075073]
	Learning Rate: 0.00750734
	LOSS [training: 0.35589181845221307 | validation: 0.40788501334418625]
	TIME [epoch: 8.26 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38404412968040447		[learning rate: 0.0074913]
	Learning Rate: 0.00749134
	LOSS [training: 0.38404412968040447 | validation: 0.35425896578567334]
	TIME [epoch: 8.27 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34488587004537724		[learning rate: 0.0074754]
	Learning Rate: 0.00747535
	LOSS [training: 0.34488587004537724 | validation: 0.3381284698299786]
	TIME [epoch: 8.27 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3124501094981592		[learning rate: 0.0074594]
	Learning Rate: 0.00745937
	LOSS [training: 0.3124501094981592 | validation: 0.33494219424248217]
	TIME [epoch: 8.32 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3086554943816448		[learning rate: 0.0074434]
	Learning Rate: 0.00744339
	LOSS [training: 0.3086554943816448 | validation: 0.2905154806549514]
	TIME [epoch: 8.28 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33229160079429254		[learning rate: 0.0074274]
	Learning Rate: 0.00742742
	LOSS [training: 0.33229160079429254 | validation: 0.3620812322247402]
	TIME [epoch: 8.27 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3019866792143094		[learning rate: 0.0074115]
	Learning Rate: 0.00741145
	LOSS [training: 0.3019866792143094 | validation: 0.40878066991537665]
	TIME [epoch: 8.27 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3374973277735164		[learning rate: 0.0073955]
	Learning Rate: 0.0073955
	LOSS [training: 0.3374973277735164 | validation: 0.18730923584332668]
	TIME [epoch: 8.27 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4022643950332495		[learning rate: 0.0073795]
	Learning Rate: 0.00737955
	LOSS [training: 0.4022643950332495 | validation: 0.3447431851705144]
	TIME [epoch: 8.28 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3321757463865098		[learning rate: 0.0073636]
	Learning Rate: 0.0073636
	LOSS [training: 0.3321757463865098 | validation: 0.26706715058634756]
	TIME [epoch: 8.3 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28279396849410887		[learning rate: 0.0073477]
	Learning Rate: 0.00734767
	LOSS [training: 0.28279396849410887 | validation: 0.3100470179221544]
	TIME [epoch: 8.27 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3033405101772046		[learning rate: 0.0073317]
	Learning Rate: 0.00733174
	LOSS [training: 0.3033405101772046 | validation: 0.34020575841661976]
	TIME [epoch: 8.27 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31722335781313615		[learning rate: 0.0073158]
	Learning Rate: 0.00731582
	LOSS [training: 0.31722335781313615 | validation: 0.2643718686616256]
	TIME [epoch: 8.27 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29999232643697954		[learning rate: 0.0072999]
	Learning Rate: 0.00729991
	LOSS [training: 0.29999232643697954 | validation: 0.33181851721903055]
	TIME [epoch: 8.27 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28945899323892577		[learning rate: 0.007284]
	Learning Rate: 0.007284
	LOSS [training: 0.28945899323892577 | validation: 0.29008661804426583]
	TIME [epoch: 8.31 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2805050056107712		[learning rate: 0.0072681]
	Learning Rate: 0.0072681
	LOSS [training: 0.2805050056107712 | validation: 0.2808274686196297]
	TIME [epoch: 8.28 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25646779401708814		[learning rate: 0.0072522]
	Learning Rate: 0.00725221
	LOSS [training: 0.25646779401708814 | validation: 0.35376859278302186]
	TIME [epoch: 8.27 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37573385363633793		[learning rate: 0.0072363]
	Learning Rate: 0.00723633
	LOSS [training: 0.37573385363633793 | validation: 0.2216230079560384]
	TIME [epoch: 8.27 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23437390336042532		[learning rate: 0.0072205]
	Learning Rate: 0.00722045
	LOSS [training: 0.23437390336042532 | validation: 0.5626521587033563]
	TIME [epoch: 8.27 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37256894836856363		[learning rate: 0.0072046]
	Learning Rate: 0.00720458
	LOSS [training: 0.37256894836856363 | validation: 0.24913541289873908]
	TIME [epoch: 8.27 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38180286560395804		[learning rate: 0.0071887]
	Learning Rate: 0.00718872
	LOSS [training: 0.38180286560395804 | validation: 0.45006241184533086]
	TIME [epoch: 8.32 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34946837138909714		[learning rate: 0.0071729]
	Learning Rate: 0.00717287
	LOSS [training: 0.34946837138909714 | validation: 0.1860434743648799]
	TIME [epoch: 8.27 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3132343224744641		[learning rate: 0.007157]
	Learning Rate: 0.00715702
	LOSS [training: 0.3132343224744641 | validation: 0.22799025454462132]
	TIME [epoch: 8.27 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30686591468842883		[learning rate: 0.0071412]
	Learning Rate: 0.00714119
	LOSS [training: 0.30686591468842883 | validation: 0.2841199944979351]
	TIME [epoch: 8.27 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35114623448090443		[learning rate: 0.0071254]
	Learning Rate: 0.00712536
	LOSS [training: 0.35114623448090443 | validation: 0.2117196073070896]
	TIME [epoch: 8.27 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22078470621658802		[learning rate: 0.0071095]
	Learning Rate: 0.00710954
	LOSS [training: 0.22078470621658802 | validation: 0.16836853496610946]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_1178.pth
	Model improved!!!
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3087306132897635		[learning rate: 0.0070937]
	Learning Rate: 0.00709372
	LOSS [training: 0.3087306132897635 | validation: 0.3794314756396987]
	TIME [epoch: 8.28 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3314626496443888		[learning rate: 0.0070779]
	Learning Rate: 0.00707792
	LOSS [training: 0.3314626496443888 | validation: 0.283841687848326]
	TIME [epoch: 8.27 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2794933889152114		[learning rate: 0.0070621]
	Learning Rate: 0.00706212
	LOSS [training: 0.2794933889152114 | validation: 0.2922268766320919]
	TIME [epoch: 8.26 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3276199593576428		[learning rate: 0.0070463]
	Learning Rate: 0.00704633
	LOSS [training: 0.3276199593576428 | validation: 0.23551615274795545]
	TIME [epoch: 8.26 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3218188004268602		[learning rate: 0.0070305]
	Learning Rate: 0.00703055
	LOSS [training: 0.3218188004268602 | validation: 0.3964555978250395]
	TIME [epoch: 8.27 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3620080147299889		[learning rate: 0.0070148]
	Learning Rate: 0.00701477
	LOSS [training: 0.3620080147299889 | validation: 0.24608768180754023]
	TIME [epoch: 8.31 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29579654286786		[learning rate: 0.006999]
	Learning Rate: 0.00699901
	LOSS [training: 0.29579654286786 | validation: 0.276748686020688]
	TIME [epoch: 8.27 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2935843029360021		[learning rate: 0.0069833]
	Learning Rate: 0.00698325
	LOSS [training: 0.2935843029360021 | validation: 0.29412388365200537]
	TIME [epoch: 8.27 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3008698666528782		[learning rate: 0.0069675]
	Learning Rate: 0.0069675
	LOSS [training: 0.3008698666528782 | validation: 0.27439000200296293]
	TIME [epoch: 8.27 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.305774388957635		[learning rate: 0.0069518]
	Learning Rate: 0.00695176
	LOSS [training: 0.305774388957635 | validation: 0.29407499003260446]
	TIME [epoch: 8.26 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22572383143167984		[learning rate: 0.006936]
	Learning Rate: 0.00693603
	LOSS [training: 0.22572383143167984 | validation: 0.4960242841590653]
	TIME [epoch: 8.3 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3813626171713007		[learning rate: 0.0069203]
	Learning Rate: 0.0069203
	LOSS [training: 0.3813626171713007 | validation: 0.35063010080578516]
	TIME [epoch: 8.28 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23021649439357136		[learning rate: 0.0069046]
	Learning Rate: 0.00690459
	LOSS [training: 0.23021649439357136 | validation: 0.2740321571171246]
	TIME [epoch: 8.26 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3490065407797625		[learning rate: 0.0068889]
	Learning Rate: 0.00688888
	LOSS [training: 0.3490065407797625 | validation: 0.35607901930353447]
	TIME [epoch: 8.27 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.306994226536575		[learning rate: 0.0068732]
	Learning Rate: 0.00687318
	LOSS [training: 0.306994226536575 | validation: 0.24087364311021886]
	TIME [epoch: 8.26 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2763342613248389		[learning rate: 0.0068575]
	Learning Rate: 0.00685749
	LOSS [training: 0.2763342613248389 | validation: 0.3054134239476059]
	TIME [epoch: 8.26 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30510652469962035		[learning rate: 0.0068418]
	Learning Rate: 0.00684181
	LOSS [training: 0.30510652469962035 | validation: 0.2657395060800749]
	TIME [epoch: 8.31 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.289590068276101		[learning rate: 0.0068261]
	Learning Rate: 0.00682614
	LOSS [training: 0.289590068276101 | validation: 0.327779501753841]
	TIME [epoch: 8.27 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33891283088625357		[learning rate: 0.0068105]
	Learning Rate: 0.00681048
	LOSS [training: 0.33891283088625357 | validation: 0.3056518976172019]
	TIME [epoch: 8.26 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32124595012067014		[learning rate: 0.0067948]
	Learning Rate: 0.00679482
	LOSS [training: 0.32124595012067014 | validation: 0.25960333106140265]
	TIME [epoch: 8.26 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29982705554054695		[learning rate: 0.0067792]
	Learning Rate: 0.00677917
	LOSS [training: 0.29982705554054695 | validation: 0.368008520056309]
	TIME [epoch: 8.26 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30259631830847633		[learning rate: 0.0067635]
	Learning Rate: 0.00676354
	LOSS [training: 0.30259631830847633 | validation: 0.2508033738479941]
	TIME [epoch: 8.28 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3020187439032895		[learning rate: 0.0067479]
	Learning Rate: 0.00674791
	LOSS [training: 0.3020187439032895 | validation: 0.28739410149217914]
	TIME [epoch: 8.3 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4068553135502893		[learning rate: 0.0067323]
	Learning Rate: 0.00673229
	LOSS [training: 0.4068553135502893 | validation: 0.3300412592733308]
	TIME [epoch: 8.26 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30803340941207336		[learning rate: 0.0067167]
	Learning Rate: 0.00671668
	LOSS [training: 0.30803340941207336 | validation: 0.27025552984536816]
	TIME [epoch: 8.26 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2619914578682171		[learning rate: 0.0067011]
	Learning Rate: 0.00670108
	LOSS [training: 0.2619914578682171 | validation: 0.2635021598643642]
	TIME [epoch: 8.27 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2514748981895206		[learning rate: 0.0066855]
	Learning Rate: 0.00668548
	LOSS [training: 0.2514748981895206 | validation: 0.381717380469075]
	TIME [epoch: 8.27 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27906755165819763		[learning rate: 0.0066699]
	Learning Rate: 0.0066699
	LOSS [training: 0.27906755165819763 | validation: 0.39086302196637707]
	TIME [epoch: 8.3 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3085002567070525		[learning rate: 0.0066543]
	Learning Rate: 0.00665432
	LOSS [training: 0.3085002567070525 | validation: 0.25634539954233815]
	TIME [epoch: 8.28 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30251542742527904		[learning rate: 0.0066388]
	Learning Rate: 0.00663876
	LOSS [training: 0.30251542742527904 | validation: 0.20717749980164427]
	TIME [epoch: 8.26 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26324636622704956		[learning rate: 0.0066232]
	Learning Rate: 0.0066232
	LOSS [training: 0.26324636622704956 | validation: 0.285173719221371]
	TIME [epoch: 8.27 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25310953763325017		[learning rate: 0.0066077]
	Learning Rate: 0.00660765
	LOSS [training: 0.25310953763325017 | validation: 0.24940119991273188]
	TIME [epoch: 8.28 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2848573160337512		[learning rate: 0.0065921]
	Learning Rate: 0.00659212
	LOSS [training: 0.2848573160337512 | validation: 0.4018085335887338]
	TIME [epoch: 8.27 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3190167436688828		[learning rate: 0.0065766]
	Learning Rate: 0.00657659
	LOSS [training: 0.3190167436688828 | validation: 0.46833141284708846]
	TIME [epoch: 8.31 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26677423542692447		[learning rate: 0.0065611]
	Learning Rate: 0.00656107
	LOSS [training: 0.26677423542692447 | validation: 0.24399034063535752]
	TIME [epoch: 8.27 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31521936585342253		[learning rate: 0.0065456]
	Learning Rate: 0.00654556
	LOSS [training: 0.31521936585342253 | validation: 0.3425595332444875]
	TIME [epoch: 8.26 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25880122299734676		[learning rate: 0.0065301]
	Learning Rate: 0.00653006
	LOSS [training: 0.25880122299734676 | validation: 0.3040775603471316]
	TIME [epoch: 8.27 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24225005852543885		[learning rate: 0.0065146]
	Learning Rate: 0.00651457
	LOSS [training: 0.24225005852543885 | validation: 0.20741575312493143]
	TIME [epoch: 8.27 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26640495432614003		[learning rate: 0.0064991]
	Learning Rate: 0.00649909
	LOSS [training: 0.26640495432614003 | validation: 0.37302969404139125]
	TIME [epoch: 8.3 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2633708234394556		[learning rate: 0.0064836]
	Learning Rate: 0.00648362
	LOSS [training: 0.2633708234394556 | validation: 0.21514297290354542]
	TIME [epoch: 8.28 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32523284491484405		[learning rate: 0.0064682]
	Learning Rate: 0.00646815
	LOSS [training: 0.32523284491484405 | validation: 0.25854709751538363]
	TIME [epoch: 8.27 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27344709460354194		[learning rate: 0.0064527]
	Learning Rate: 0.0064527
	LOSS [training: 0.27344709460354194 | validation: 0.24066682163442382]
	TIME [epoch: 8.27 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28920623864911077		[learning rate: 0.0064373]
	Learning Rate: 0.00643726
	LOSS [training: 0.28920623864911077 | validation: 0.3036124284892352]
	TIME [epoch: 8.27 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29548384616946416		[learning rate: 0.0064218]
	Learning Rate: 0.00642183
	LOSS [training: 0.29548384616946416 | validation: 0.3019119137150381]
	TIME [epoch: 8.27 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22097372382434335		[learning rate: 0.0064064]
	Learning Rate: 0.0064064
	LOSS [training: 0.22097372382434335 | validation: 0.2989067836318456]
	TIME [epoch: 8.31 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33527805669764654		[learning rate: 0.006391]
	Learning Rate: 0.00639099
	LOSS [training: 0.33527805669764654 | validation: 0.20028976108610524]
	TIME [epoch: 8.27 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2788201789738196		[learning rate: 0.0063756]
	Learning Rate: 0.00637559
	LOSS [training: 0.2788201789738196 | validation: 0.27634121332281236]
	TIME [epoch: 8.27 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24152619377005669		[learning rate: 0.0063602]
	Learning Rate: 0.00636019
	LOSS [training: 0.24152619377005669 | validation: 0.2995520503328616]
	TIME [epoch: 8.27 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27354052219309205		[learning rate: 0.0063448]
	Learning Rate: 0.00634481
	LOSS [training: 0.27354052219309205 | validation: 0.3234607308091795]
	TIME [epoch: 8.27 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26435054874554337		[learning rate: 0.0063294]
	Learning Rate: 0.00632944
	LOSS [training: 0.26435054874554337 | validation: 0.3146280515267927]
	TIME [epoch: 8.28 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2895967249550061		[learning rate: 0.0063141]
	Learning Rate: 0.00631407
	LOSS [training: 0.2895967249550061 | validation: 0.22117893716757978]
	TIME [epoch: 8.31 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23321187959419024		[learning rate: 0.0062987]
	Learning Rate: 0.00629872
	LOSS [training: 0.23321187959419024 | validation: 0.2187442633026394]
	TIME [epoch: 8.27 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27532576493925504		[learning rate: 0.0062834]
	Learning Rate: 0.00628338
	LOSS [training: 0.27532576493925504 | validation: 0.25712107347511304]
	TIME [epoch: 8.27 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2385819500449861		[learning rate: 0.006268]
	Learning Rate: 0.00626804
	LOSS [training: 0.2385819500449861 | validation: 0.268128753664657]
	TIME [epoch: 8.27 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19750502374893059		[learning rate: 0.0062527]
	Learning Rate: 0.00625272
	LOSS [training: 0.19750502374893059 | validation: 0.24730922293298954]
	TIME [epoch: 8.27 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2569548933912202		[learning rate: 0.0062374]
	Learning Rate: 0.00623741
	LOSS [training: 0.2569548933912202 | validation: 0.21137248120905278]
	TIME [epoch: 8.3 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33557084375021295		[learning rate: 0.0062221]
	Learning Rate: 0.00622211
	LOSS [training: 0.33557084375021295 | validation: 0.2294968357775366]
	TIME [epoch: 8.28 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23609538725247647		[learning rate: 0.0062068]
	Learning Rate: 0.00620681
	LOSS [training: 0.23609538725247647 | validation: 0.3712318057837215]
	TIME [epoch: 8.27 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2692080157982908		[learning rate: 0.0061915]
	Learning Rate: 0.00619153
	LOSS [training: 0.2692080157982908 | validation: 0.3849393576000565]
	TIME [epoch: 8.27 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23337024683584107		[learning rate: 0.0061763]
	Learning Rate: 0.00617626
	LOSS [training: 0.23337024683584107 | validation: 0.1756653498533173]
	TIME [epoch: 8.27 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2902385900204105		[learning rate: 0.006161]
	Learning Rate: 0.006161
	LOSS [training: 0.2902385900204105 | validation: 0.2809831788327884]
	TIME [epoch: 8.27 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31483527155468943		[learning rate: 0.0061458]
	Learning Rate: 0.00614575
	LOSS [training: 0.31483527155468943 | validation: 0.27690207135629286]
	TIME [epoch: 8.32 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2612570695697684		[learning rate: 0.0061305]
	Learning Rate: 0.00613051
	LOSS [training: 0.2612570695697684 | validation: 0.31434353029895157]
	TIME [epoch: 8.26 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28938197623351636		[learning rate: 0.0061153]
	Learning Rate: 0.00611528
	LOSS [training: 0.28938197623351636 | validation: 0.2432068332851564]
	TIME [epoch: 8.27 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21430094833710467		[learning rate: 0.0061001]
	Learning Rate: 0.00610007
	LOSS [training: 0.21430094833710467 | validation: 0.25043777305722176]
	TIME [epoch: 8.26 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34861349798005825		[learning rate: 0.0060849]
	Learning Rate: 0.00608486
	LOSS [training: 0.34861349798005825 | validation: 0.26461987468802745]
	TIME [epoch: 8.27 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30505708590088443		[learning rate: 0.0060697]
	Learning Rate: 0.00606966
	LOSS [training: 0.30505708590088443 | validation: 0.2519910994369984]
	TIME [epoch: 8.32 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28042792128987903		[learning rate: 0.0060545]
	Learning Rate: 0.00605447
	LOSS [training: 0.28042792128987903 | validation: 0.29915618600893495]
	TIME [epoch: 8.28 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37463956716654045		[learning rate: 0.0060393]
	Learning Rate: 0.0060393
	LOSS [training: 0.37463956716654045 | validation: 0.2537423926378145]
	TIME [epoch: 8.27 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42473011662172866		[learning rate: 0.0060241]
	Learning Rate: 0.00602413
	LOSS [training: 0.42473011662172866 | validation: 0.2510169025895801]
	TIME [epoch: 8.26 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25973412257550615		[learning rate: 0.006009]
	Learning Rate: 0.00600898
	LOSS [training: 0.25973412257550615 | validation: 0.16933879903744983]
	TIME [epoch: 8.26 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24222435250868107		[learning rate: 0.0059938]
	Learning Rate: 0.00599384
	LOSS [training: 0.24222435250868107 | validation: 0.23316316824631805]
	TIME [epoch: 8.26 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3524113414087767		[learning rate: 0.0059787]
	Learning Rate: 0.00597871
	LOSS [training: 0.3524113414087767 | validation: 0.24860970686304806]
	TIME [epoch: 8.31 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26170564796718576		[learning rate: 0.0059636]
	Learning Rate: 0.00596359
	LOSS [training: 0.26170564796718576 | validation: 0.16586819918431955]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_1252.pth
	Model improved!!!
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20922908712347377		[learning rate: 0.0059485]
	Learning Rate: 0.00594848
	LOSS [training: 0.20922908712347377 | validation: 0.3578788231660306]
	TIME [epoch: 8.28 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30566454068074606		[learning rate: 0.0059334]
	Learning Rate: 0.00593338
	LOSS [training: 0.30566454068074606 | validation: 0.22375149307590309]
	TIME [epoch: 8.27 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21875557254529518		[learning rate: 0.0059183]
	Learning Rate: 0.00591829
	LOSS [training: 0.21875557254529518 | validation: 0.24429993401807892]
	TIME [epoch: 8.26 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27518840521019017		[learning rate: 0.0059032]
	Learning Rate: 0.00590321
	LOSS [training: 0.27518840521019017 | validation: 0.48667371241095403]
	TIME [epoch: 8.3 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.299490288826752		[learning rate: 0.0058881]
	Learning Rate: 0.00588815
	LOSS [training: 0.299490288826752 | validation: 0.13640737483395732]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_1257.pth
	Model improved!!!
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2336579580715137		[learning rate: 0.0058731]
	Learning Rate: 0.00587309
	LOSS [training: 0.2336579580715137 | validation: 0.17216732734034637]
	TIME [epoch: 8.27 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2870423332536753		[learning rate: 0.0058581]
	Learning Rate: 0.00585805
	LOSS [training: 0.2870423332536753 | validation: 0.15293498779767722]
	TIME [epoch: 8.26 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23790557673941348		[learning rate: 0.005843]
	Learning Rate: 0.00584302
	LOSS [training: 0.23790557673941348 | validation: 0.20236538782272073]
	TIME [epoch: 8.26 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22232100395936474		[learning rate: 0.005828]
	Learning Rate: 0.005828
	LOSS [training: 0.22232100395936474 | validation: 0.26319215715623556]
	TIME [epoch: 8.27 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29090572873244575		[learning rate: 0.005813]
	Learning Rate: 0.00581299
	LOSS [training: 0.29090572873244575 | validation: 0.17620992295494992]
	TIME [epoch: 8.31 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22325952589130865		[learning rate: 0.005798]
	Learning Rate: 0.005798
	LOSS [training: 0.22325952589130865 | validation: 0.24635057285470383]
	TIME [epoch: 8.26 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21830425636009035		[learning rate: 0.005783]
	Learning Rate: 0.00578301
	LOSS [training: 0.21830425636009035 | validation: 0.30858351528049427]
	TIME [epoch: 8.26 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.338626590554511		[learning rate: 0.005768]
	Learning Rate: 0.00576804
	LOSS [training: 0.338626590554511 | validation: 0.24177586803338597]
	TIME [epoch: 8.25 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27432384932364773		[learning rate: 0.0057531]
	Learning Rate: 0.00575307
	LOSS [training: 0.27432384932364773 | validation: 0.1808606194927913]
	TIME [epoch: 8.26 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2220349796201942		[learning rate: 0.0057381]
	Learning Rate: 0.00573812
	LOSS [training: 0.2220349796201942 | validation: 0.1948404018299485]
	TIME [epoch: 8.28 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24490614433909258		[learning rate: 0.0057232]
	Learning Rate: 0.00572318
	LOSS [training: 0.24490614433909258 | validation: 0.24397302648592]
	TIME [epoch: 8.3 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23061588716259807		[learning rate: 0.0057083]
	Learning Rate: 0.00570826
	LOSS [training: 0.23061588716259807 | validation: 0.24629641460870155]
	TIME [epoch: 8.26 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2523548100936147		[learning rate: 0.0056933]
	Learning Rate: 0.00569334
	LOSS [training: 0.2523548100936147 | validation: 0.22759895791162932]
	TIME [epoch: 8.26 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19869399896162812		[learning rate: 0.0056784]
	Learning Rate: 0.00567844
	LOSS [training: 0.19869399896162812 | validation: 0.22861456200386243]
	TIME [epoch: 8.26 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24205063016208717		[learning rate: 0.0056635]
	Learning Rate: 0.00566355
	LOSS [training: 0.24205063016208717 | validation: 0.27524494742292094]
	TIME [epoch: 8.26 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3548675357294446		[learning rate: 0.0056487]
	Learning Rate: 0.00564867
	LOSS [training: 0.3548675357294446 | validation: 0.29430726311678257]
	TIME [epoch: 8.3 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2607797802408749		[learning rate: 0.0056338]
	Learning Rate: 0.0056338
	LOSS [training: 0.2607797802408749 | validation: 0.23103024257218757]
	TIME [epoch: 8.27 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22101548238693708		[learning rate: 0.0056189]
	Learning Rate: 0.00561894
	LOSS [training: 0.22101548238693708 | validation: 0.20407556060452692]
	TIME [epoch: 8.26 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2508086396092537		[learning rate: 0.0056041]
	Learning Rate: 0.0056041
	LOSS [training: 0.2508086396092537 | validation: 0.14799127303860776]
	TIME [epoch: 8.26 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.212218709120855		[learning rate: 0.0055893]
	Learning Rate: 0.00558927
	LOSS [training: 0.212218709120855 | validation: 0.19750266118951582]
	TIME [epoch: 8.26 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21640996041306523		[learning rate: 0.0055744]
	Learning Rate: 0.00557445
	LOSS [training: 0.21640996041306523 | validation: 0.18233842534930694]
	TIME [epoch: 8.27 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19873976286883804		[learning rate: 0.0055596]
	Learning Rate: 0.00555964
	LOSS [training: 0.19873976286883804 | validation: 0.18504739981537863]
	TIME [epoch: 8.3 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2688518524584411		[learning rate: 0.0055448]
	Learning Rate: 0.00554484
	LOSS [training: 0.2688518524584411 | validation: 0.26891094202981536]
	TIME [epoch: 8.26 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23902213989381366		[learning rate: 0.0055301]
	Learning Rate: 0.00553006
	LOSS [training: 0.23902213989381366 | validation: 0.3224996345671635]
	TIME [epoch: 8.29 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24194707074229205		[learning rate: 0.0055153]
	Learning Rate: 0.00551529
	LOSS [training: 0.24194707074229205 | validation: 0.3111715825484001]
	TIME [epoch: 8.27 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27578941514864524		[learning rate: 0.0055005]
	Learning Rate: 0.00550053
	LOSS [training: 0.27578941514864524 | validation: 0.21794213873130436]
	TIME [epoch: 8.26 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17842103193859582		[learning rate: 0.0054858]
	Learning Rate: 0.00548578
	LOSS [training: 0.17842103193859582 | validation: 0.27347694128725497]
	TIME [epoch: 8.29 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22260056197144307		[learning rate: 0.005471]
	Learning Rate: 0.00547105
	LOSS [training: 0.22260056197144307 | validation: 0.2570292823162933]
	TIME [epoch: 8.28 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27267220454372754		[learning rate: 0.0054563]
	Learning Rate: 0.00545632
	LOSS [training: 0.27267220454372754 | validation: 0.27778430202472826]
	TIME [epoch: 8.26 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22416703722367182		[learning rate: 0.0054416]
	Learning Rate: 0.00544161
	LOSS [training: 0.22416703722367182 | validation: 0.13658465771262288]
	TIME [epoch: 8.26 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20922981802175167		[learning rate: 0.0054269]
	Learning Rate: 0.00542692
	LOSS [training: 0.20922981802175167 | validation: 0.2116402993281231]
	TIME [epoch: 8.26 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23865779834027198		[learning rate: 0.0054122]
	Learning Rate: 0.00541223
	LOSS [training: 0.23865779834027198 | validation: 0.21361480933532262]
	TIME [epoch: 8.25 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2339814215326446		[learning rate: 0.0053976]
	Learning Rate: 0.00539756
	LOSS [training: 0.2339814215326446 | validation: 0.192698495876387]
	TIME [epoch: 8.3 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2252913049226124		[learning rate: 0.0053829]
	Learning Rate: 0.0053829
	LOSS [training: 0.2252913049226124 | validation: 0.24885031004912156]
	TIME [epoch: 8.26 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.252368335246576		[learning rate: 0.0053683]
	Learning Rate: 0.00536825
	LOSS [training: 0.252368335246576 | validation: 0.2193810242035797]
	TIME [epoch: 8.27 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21413995882953657		[learning rate: 0.0053536]
	Learning Rate: 0.00535362
	LOSS [training: 0.21413995882953657 | validation: 0.24352404307042513]
	TIME [epoch: 8.26 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19252610871003736		[learning rate: 0.005339]
	Learning Rate: 0.005339
	LOSS [training: 0.19252610871003736 | validation: 0.26811533331647025]
	TIME [epoch: 8.26 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2345563219546189		[learning rate: 0.0053244]
	Learning Rate: 0.00532439
	LOSS [training: 0.2345563219546189 | validation: 0.25734622794166295]
	TIME [epoch: 8.28 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24014529724783196		[learning rate: 0.0053098]
	Learning Rate: 0.00530979
	LOSS [training: 0.24014529724783196 | validation: 0.16970142258939053]
	TIME [epoch: 8.29 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19755683190566298		[learning rate: 0.0052952]
	Learning Rate: 0.00529521
	LOSS [training: 0.19755683190566298 | validation: 0.2338563526813424]
	TIME [epoch: 8.27 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2470215636063921		[learning rate: 0.0052806]
	Learning Rate: 0.00528064
	LOSS [training: 0.2470215636063921 | validation: 0.2269619811228243]
	TIME [epoch: 8.27 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21070509552419728		[learning rate: 0.0052661]
	Learning Rate: 0.00526608
	LOSS [training: 0.21070509552419728 | validation: 0.18820701003930523]
	TIME [epoch: 8.25 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22686260242438264		[learning rate: 0.0052515]
	Learning Rate: 0.00525154
	LOSS [training: 0.22686260242438264 | validation: 0.2760415106558818]
	TIME [epoch: 8.27 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29933680562855686		[learning rate: 0.005237]
	Learning Rate: 0.00523701
	LOSS [training: 0.29933680562855686 | validation: 0.2561405459400724]
	TIME [epoch: 8.32 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2069139610072793		[learning rate: 0.0052225]
	Learning Rate: 0.00522249
	LOSS [training: 0.2069139610072793 | validation: 0.21808743481306364]
	TIME [epoch: 8.26 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3607618047732292		[learning rate: 0.005208]
	Learning Rate: 0.00520799
	LOSS [training: 0.3607618047732292 | validation: 0.1716319201987111]
	TIME [epoch: 8.27 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2059757944066724		[learning rate: 0.0051935]
	Learning Rate: 0.00519349
	LOSS [training: 0.2059757944066724 | validation: 0.28169712537705094]
	TIME [epoch: 8.26 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21316203866353145		[learning rate: 0.005179]
	Learning Rate: 0.00517901
	LOSS [training: 0.21316203866353145 | validation: 0.1787656714329001]
	TIME [epoch: 8.25 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2841563264146847		[learning rate: 0.0051645]
	Learning Rate: 0.00516455
	LOSS [training: 0.2841563264146847 | validation: 0.3617454738023145]
	TIME [epoch: 8.27 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27799585756521483		[learning rate: 0.0051501]
	Learning Rate: 0.0051501
	LOSS [training: 0.27799585756521483 | validation: 0.33813550552975763]
	TIME [epoch: 8.3 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2880823710925844		[learning rate: 0.0051357]
	Learning Rate: 0.00513566
	LOSS [training: 0.2880823710925844 | validation: 0.2288446555651315]
	TIME [epoch: 8.26 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2578610605427104		[learning rate: 0.0051212]
	Learning Rate: 0.00512123
	LOSS [training: 0.2578610605427104 | validation: 0.31581752533819685]
	TIME [epoch: 8.26 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2512884285593976		[learning rate: 0.0051068]
	Learning Rate: 0.00510682
	LOSS [training: 0.2512884285593976 | validation: 0.2902327622679653]
	TIME [epoch: 8.26 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2549038544993208		[learning rate: 0.0050924]
	Learning Rate: 0.00509242
	LOSS [training: 0.2549038544993208 | validation: 0.3593564990648821]
	TIME [epoch: 8.26 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2733940963868704		[learning rate: 0.005078]
	Learning Rate: 0.00507803
	LOSS [training: 0.2733940963868704 | validation: 0.5383629088407644]
	TIME [epoch: 8.3 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31019198179362467		[learning rate: 0.0050637]
	Learning Rate: 0.00506366
	LOSS [training: 0.31019198179362467 | validation: 0.24951622248822988]
	TIME [epoch: 8.28 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18805514841005783		[learning rate: 0.0050493]
	Learning Rate: 0.0050493
	LOSS [training: 0.18805514841005783 | validation: 0.20877033280652174]
	TIME [epoch: 8.25 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22408990506424864		[learning rate: 0.005035]
	Learning Rate: 0.00503496
	LOSS [training: 0.22408990506424864 | validation: 0.21709522264667647]
	TIME [epoch: 8.27 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21543536163969246		[learning rate: 0.0050206]
	Learning Rate: 0.00502063
	LOSS [training: 0.21543536163969246 | validation: 0.20162344317961606]
	TIME [epoch: 8.26 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2368560785860278		[learning rate: 0.0050063]
	Learning Rate: 0.00500631
	LOSS [training: 0.2368560785860278 | validation: 0.24329613655172544]
	TIME [epoch: 8.27 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19186475561432326		[learning rate: 0.004992]
	Learning Rate: 0.004992
	LOSS [training: 0.19186475561432326 | validation: 0.2276654402165187]
	TIME [epoch: 8.31 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21721660487420835		[learning rate: 0.0049777]
	Learning Rate: 0.00497771
	LOSS [training: 0.21721660487420835 | validation: 0.4098055761741499]
	TIME [epoch: 8.27 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23209071104756368		[learning rate: 0.0049634]
	Learning Rate: 0.00496344
	LOSS [training: 0.23209071104756368 | validation: 0.24986002124156026]
	TIME [epoch: 8.26 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18387907657757088		[learning rate: 0.0049492]
	Learning Rate: 0.00494917
	LOSS [training: 0.18387907657757088 | validation: 0.21465921205306987]
	TIME [epoch: 8.26 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23350240517060092		[learning rate: 0.0049349]
	Learning Rate: 0.00493492
	LOSS [training: 0.23350240517060092 | validation: 0.2516990140826572]
	TIME [epoch: 8.26 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21612941579512557		[learning rate: 0.0049207]
	Learning Rate: 0.00492069
	LOSS [training: 0.21612941579512557 | validation: 0.19440121107252517]
	TIME [epoch: 8.3 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19161589277129676		[learning rate: 0.0049065]
	Learning Rate: 0.00490647
	LOSS [training: 0.19161589277129676 | validation: 0.23646293856016073]
	TIME [epoch: 8.27 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21690468436915053		[learning rate: 0.0048923]
	Learning Rate: 0.00489226
	LOSS [training: 0.21690468436915053 | validation: 0.22751278045475462]
	TIME [epoch: 8.26 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1849226498962881		[learning rate: 0.0048781]
	Learning Rate: 0.00487807
	LOSS [training: 0.1849226498962881 | validation: 0.2635040579657898]
	TIME [epoch: 8.26 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22658070548428305		[learning rate: 0.0048639]
	Learning Rate: 0.00486389
	LOSS [training: 0.22658070548428305 | validation: 0.23491833798504105]
	TIME [epoch: 8.25 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21466474162979637		[learning rate: 0.0048497]
	Learning Rate: 0.00484972
	LOSS [training: 0.21466474162979637 | validation: 0.23574904693850118]
	TIME [epoch: 8.26 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17934121899148303		[learning rate: 0.0048356]
	Learning Rate: 0.00483557
	LOSS [training: 0.17934121899148303 | validation: 0.24122551588474947]
	TIME [epoch: 8.31 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2618346512148913		[learning rate: 0.0048214]
	Learning Rate: 0.00482143
	LOSS [training: 0.2618346512148913 | validation: 0.23360389110896718]
	TIME [epoch: 8.27 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.215093944112195		[learning rate: 0.0048073]
	Learning Rate: 0.00480731
	LOSS [training: 0.215093944112195 | validation: 0.216300234804095]
	TIME [epoch: 8.26 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2265204567499734		[learning rate: 0.0047932]
	Learning Rate: 0.0047932
	LOSS [training: 0.2265204567499734 | validation: 0.341471485673459]
	TIME [epoch: 8.26 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2613757135589321		[learning rate: 0.0047791]
	Learning Rate: 0.0047791
	LOSS [training: 0.2613757135589321 | validation: 0.21733076297860815]
	TIME [epoch: 8.25 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2074400263639972		[learning rate: 0.004765]
	Learning Rate: 0.00476502
	LOSS [training: 0.2074400263639972 | validation: 0.21405599333024505]
	TIME [epoch: 8.27 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19525117352260263		[learning rate: 0.004751]
	Learning Rate: 0.00475096
	LOSS [training: 0.19525117352260263 | validation: 0.39035096359217847]
	TIME [epoch: 8.3 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23904444644312178		[learning rate: 0.0047369]
	Learning Rate: 0.00473691
	LOSS [training: 0.23904444644312178 | validation: 0.2939684998926796]
	TIME [epoch: 8.27 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22010707375456132		[learning rate: 0.0047229]
	Learning Rate: 0.00472287
	LOSS [training: 0.22010707375456132 | validation: 0.22108259848380846]
	TIME [epoch: 8.26 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18188286571248763		[learning rate: 0.0047088]
	Learning Rate: 0.00470885
	LOSS [training: 0.18188286571248763 | validation: 0.2513938550939698]
	TIME [epoch: 8.27 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19335652704254952		[learning rate: 0.0046948]
	Learning Rate: 0.00469484
	LOSS [training: 0.19335652704254952 | validation: 0.160432929009793]
	TIME [epoch: 8.26 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19707960466799718		[learning rate: 0.0046808]
	Learning Rate: 0.00468084
	LOSS [training: 0.19707960466799718 | validation: 0.3419535582882436]
	TIME [epoch: 8.3 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3266216743540078		[learning rate: 0.0046669]
	Learning Rate: 0.00466686
	LOSS [training: 0.3266216743540078 | validation: 0.19578244862345695]
	TIME [epoch: 8.27 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1904897708044365		[learning rate: 0.0046529]
	Learning Rate: 0.0046529
	LOSS [training: 0.1904897708044365 | validation: 0.15524212604198068]
	TIME [epoch: 8.26 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.189348642753314		[learning rate: 0.0046389]
	Learning Rate: 0.00463895
	LOSS [training: 0.189348642753314 | validation: 0.3327985409412606]
	TIME [epoch: 8.26 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2741019379572754		[learning rate: 0.004625]
	Learning Rate: 0.00462501
	LOSS [training: 0.2741019379572754 | validation: 0.2461208623882732]
	TIME [epoch: 8.26 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21940155137633774		[learning rate: 0.0046111]
	Learning Rate: 0.00461109
	LOSS [training: 0.21940155137633774 | validation: 0.16832102526898401]
	TIME [epoch: 8.26 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1667653855883439		[learning rate: 0.0045972]
	Learning Rate: 0.00459719
	LOSS [training: 0.1667653855883439 | validation: 0.26878189893877846]
	TIME [epoch: 8.3 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21676689588209685		[learning rate: 0.0045833]
	Learning Rate: 0.0045833
	LOSS [training: 0.21676689588209685 | validation: 0.16694036207960977]
	TIME [epoch: 8.26 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24499340724366553		[learning rate: 0.0045694]
	Learning Rate: 0.00456942
	LOSS [training: 0.24499340724366553 | validation: 0.19203120607907098]
	TIME [epoch: 8.26 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19460917115041262		[learning rate: 0.0045556]
	Learning Rate: 0.00455556
	LOSS [training: 0.19460917115041262 | validation: 0.24374719128053157]
	TIME [epoch: 8.26 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24968016699000972		[learning rate: 0.0045417]
	Learning Rate: 0.00454171
	LOSS [training: 0.24968016699000972 | validation: 0.374392913734503]
	TIME [epoch: 8.26 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30788230810016254		[learning rate: 0.0045279]
	Learning Rate: 0.00452788
	LOSS [training: 0.30788230810016254 | validation: 0.4234446477330316]
	TIME [epoch: 8.3 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2588921853483336		[learning rate: 0.0045141]
	Learning Rate: 0.00451406
	LOSS [training: 0.2588921853483336 | validation: 0.22697059122628632]
	TIME [epoch: 8.28 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26049171096112544		[learning rate: 0.0045003]
	Learning Rate: 0.00450026
	LOSS [training: 0.26049171096112544 | validation: 0.142505756308697]
	TIME [epoch: 8.26 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22428484147531388		[learning rate: 0.0044865]
	Learning Rate: 0.00448648
	LOSS [training: 0.22428484147531388 | validation: 0.20848756982101724]
	TIME [epoch: 8.26 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28282279681754885		[learning rate: 0.0044727]
	Learning Rate: 0.0044727
	LOSS [training: 0.28282279681754885 | validation: 0.28107695511039066]
	TIME [epoch: 8.25 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23288048827387545		[learning rate: 0.0044589]
	Learning Rate: 0.00445895
	LOSS [training: 0.23288048827387545 | validation: 0.18410684087531437]
	TIME [epoch: 8.26 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20254826651888425		[learning rate: 0.0044452]
	Learning Rate: 0.00444521
	LOSS [training: 0.20254826651888425 | validation: 0.1399982998193881]
	TIME [epoch: 8.3 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18825695528460024		[learning rate: 0.0044315]
	Learning Rate: 0.00443148
	LOSS [training: 0.18825695528460024 | validation: 0.26325562361516747]
	TIME [epoch: 8.26 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2366356166663134		[learning rate: 0.0044178]
	Learning Rate: 0.00441777
	LOSS [training: 0.2366356166663134 | validation: 0.16525773864600116]
	TIME [epoch: 8.25 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18852117321239856		[learning rate: 0.0044041]
	Learning Rate: 0.00440407
	LOSS [training: 0.18852117321239856 | validation: 0.15675372256574388]
	TIME [epoch: 8.27 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20004190078665404		[learning rate: 0.0043904]
	Learning Rate: 0.00439039
	LOSS [training: 0.20004190078665404 | validation: 0.1689117978238105]
	TIME [epoch: 8.26 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17512980942819287		[learning rate: 0.0043767]
	Learning Rate: 0.00437673
	LOSS [training: 0.17512980942819287 | validation: 0.18959639179949972]
	TIME [epoch: 8.27 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19362715324347482		[learning rate: 0.0043631]
	Learning Rate: 0.00436308
	LOSS [training: 0.19362715324347482 | validation: 0.17664311612232658]
	TIME [epoch: 8.3 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19172260262831714		[learning rate: 0.0043494]
	Learning Rate: 0.00434945
	LOSS [training: 0.19172260262831714 | validation: 0.34427469482490647]
	TIME [epoch: 8.26 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19975203273515701		[learning rate: 0.0043358]
	Learning Rate: 0.00433583
	LOSS [training: 0.19975203273515701 | validation: 0.14648171710060276]
	TIME [epoch: 8.26 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16829743480406195		[learning rate: 0.0043222]
	Learning Rate: 0.00432222
	LOSS [training: 0.16829743480406195 | validation: 0.19801376652605227]
	TIME [epoch: 8.25 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21177096370465567		[learning rate: 0.0043086]
	Learning Rate: 0.00430864
	LOSS [training: 0.21177096370465567 | validation: 0.2405548416791875]
	TIME [epoch: 8.26 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18126201636114259		[learning rate: 0.0042951]
	Learning Rate: 0.00429506
	LOSS [training: 0.18126201636114259 | validation: 0.1685185261924911]
	TIME [epoch: 8.4 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17458863477229195		[learning rate: 0.0042815]
	Learning Rate: 0.00428151
	LOSS [training: 0.17458863477229195 | validation: 0.17983183975934808]
	TIME [epoch: 8.26 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17801684544065813		[learning rate: 0.004268]
	Learning Rate: 0.00426797
	LOSS [training: 0.17801684544065813 | validation: 0.26515275705849345]
	TIME [epoch: 8.26 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21374308465809738		[learning rate: 0.0042544]
	Learning Rate: 0.00425444
	LOSS [training: 0.21374308465809738 | validation: 0.19457239810530633]
	TIME [epoch: 8.26 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17508799728706254		[learning rate: 0.0042409]
	Learning Rate: 0.00424093
	LOSS [training: 0.17508799728706254 | validation: 0.18629562144962694]
	TIME [epoch: 8.27 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1818118442512346		[learning rate: 0.0042274]
	Learning Rate: 0.00422744
	LOSS [training: 0.1818118442512346 | validation: 0.17103049548317367]
	TIME [epoch: 8.27 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22009906003273694		[learning rate: 0.004214]
	Learning Rate: 0.00421396
	LOSS [training: 0.22009906003273694 | validation: 0.1817137885495131]
	TIME [epoch: 8.3 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17045538660316423		[learning rate: 0.0042005]
	Learning Rate: 0.0042005
	LOSS [training: 0.17045538660316423 | validation: 0.17557673582047695]
	TIME [epoch: 8.27 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16110317529813964		[learning rate: 0.0041871]
	Learning Rate: 0.00418705
	LOSS [training: 0.16110317529813964 | validation: 0.1382408583518274]
	TIME [epoch: 8.27 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15679134674896317		[learning rate: 0.0041736]
	Learning Rate: 0.00417362
	LOSS [training: 0.15679134674896317 | validation: 0.18404808567510778]
	TIME [epoch: 8.25 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15422790601846748		[learning rate: 0.0041602]
	Learning Rate: 0.00416021
	LOSS [training: 0.15422790601846748 | validation: 0.23827405129761806]
	TIME [epoch: 8.25 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25249029274121726		[learning rate: 0.0041468]
	Learning Rate: 0.00414681
	LOSS [training: 0.25249029274121726 | validation: 0.16792807277357863]
	TIME [epoch: 8.3 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16596803819099754		[learning rate: 0.0041334]
	Learning Rate: 0.00413343
	LOSS [training: 0.16596803819099754 | validation: 0.16969149618562343]
	TIME [epoch: 8.27 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20005150325278045		[learning rate: 0.0041201]
	Learning Rate: 0.00412006
	LOSS [training: 0.20005150325278045 | validation: 0.15607562981884227]
	TIME [epoch: 8.27 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17682540335697158		[learning rate: 0.0041067]
	Learning Rate: 0.00410671
	LOSS [training: 0.17682540335697158 | validation: 0.14939172592127725]
	TIME [epoch: 8.26 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15334952435767563		[learning rate: 0.0040934]
	Learning Rate: 0.00409338
	LOSS [training: 0.15334952435767563 | validation: 0.141017815013965]
	TIME [epoch: 8.26 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16374248565879196		[learning rate: 0.0040801]
	Learning Rate: 0.00408006
	LOSS [training: 0.16374248565879196 | validation: 0.11787388913950533]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_1384.pth
	Model improved!!!
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17205054007547682		[learning rate: 0.0040668]
	Learning Rate: 0.00406676
	LOSS [training: 0.17205054007547682 | validation: 0.18988977886959768]
	TIME [epoch: 8.33 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1641873385148872		[learning rate: 0.0040535]
	Learning Rate: 0.00405347
	LOSS [training: 0.1641873385148872 | validation: 0.17372674752143855]
	TIME [epoch: 8.28 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20524600936701592		[learning rate: 0.0040402]
	Learning Rate: 0.00404021
	LOSS [training: 0.20524600936701592 | validation: 0.1268199297560093]
	TIME [epoch: 8.28 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1821057139744797		[learning rate: 0.004027]
	Learning Rate: 0.00402695
	LOSS [training: 0.1821057139744797 | validation: 0.1460440103609589]
	TIME [epoch: 8.28 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18037477773742855		[learning rate: 0.0040137]
	Learning Rate: 0.00401372
	LOSS [training: 0.18037477773742855 | validation: 0.19762931382017315]
	TIME [epoch: 8.28 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15936595570305137		[learning rate: 0.0040005]
	Learning Rate: 0.0040005
	LOSS [training: 0.15936595570305137 | validation: 0.20603874136003186]
	TIME [epoch: 8.31 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2106868875466526		[learning rate: 0.0039873]
	Learning Rate: 0.00398729
	LOSS [training: 0.2106868875466526 | validation: 0.17379067574767812]
	TIME [epoch: 8.29 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17681458069069322		[learning rate: 0.0039741]
	Learning Rate: 0.00397411
	LOSS [training: 0.17681458069069322 | validation: 0.2132769479979619]
	TIME [epoch: 8.28 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1760760809381479		[learning rate: 0.0039609]
	Learning Rate: 0.00396093
	LOSS [training: 0.1760760809381479 | validation: 0.16480423427904983]
	TIME [epoch: 8.28 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1429718494108336		[learning rate: 0.0039478]
	Learning Rate: 0.00394778
	LOSS [training: 0.1429718494108336 | validation: 0.16639295193155895]
	TIME [epoch: 8.28 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1624583830321395		[learning rate: 0.0039346]
	Learning Rate: 0.00393464
	LOSS [training: 0.1624583830321395 | validation: 0.1831862678943618]
	TIME [epoch: 8.27 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1682768748878102		[learning rate: 0.0039215]
	Learning Rate: 0.00392152
	LOSS [training: 0.1682768748878102 | validation: 0.1677340031868814]
	TIME [epoch: 8.32 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18142032481889864		[learning rate: 0.0039084]
	Learning Rate: 0.00390842
	LOSS [training: 0.18142032481889864 | validation: 0.17519591456183106]
	TIME [epoch: 8.28 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19448727261345572		[learning rate: 0.0038953]
	Learning Rate: 0.00389533
	LOSS [training: 0.19448727261345572 | validation: 0.17198454394425877]
	TIME [epoch: 8.27 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13089501794939462		[learning rate: 0.0038823]
	Learning Rate: 0.00388226
	LOSS [training: 0.13089501794939462 | validation: 0.17488745675690515]
	TIME [epoch: 8.27 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2010979311416951		[learning rate: 0.0038692]
	Learning Rate: 0.0038692
	LOSS [training: 0.2010979311416951 | validation: 0.16990096198732774]
	TIME [epoch: 8.28 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1537087204303237		[learning rate: 0.0038562]
	Learning Rate: 0.00385617
	LOSS [training: 0.1537087204303237 | validation: 0.11338781251254816]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_1401.pth
	Model improved!!!
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16330674093805994		[learning rate: 0.0038431]
	Learning Rate: 0.00384315
	LOSS [training: 0.16330674093805994 | validation: 0.19263376028640702]
	TIME [epoch: 8.29 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.186930816523074		[learning rate: 0.0038301]
	Learning Rate: 0.00383014
	LOSS [training: 0.186930816523074 | validation: 0.14509092581524]
	TIME [epoch: 8.27 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1759620764453031		[learning rate: 0.0038172]
	Learning Rate: 0.00381716
	LOSS [training: 0.1759620764453031 | validation: 0.18201804466177604]
	TIME [epoch: 8.27 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18213186223232208		[learning rate: 0.0038042]
	Learning Rate: 0.00380419
	LOSS [training: 0.18213186223232208 | validation: 0.13652401924424162]
	TIME [epoch: 8.27 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1528623061810554		[learning rate: 0.0037912]
	Learning Rate: 0.00379123
	LOSS [training: 0.1528623061810554 | validation: 0.15425454068555172]
	TIME [epoch: 8.26 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19579754612437072		[learning rate: 0.0037783]
	Learning Rate: 0.0037783
	LOSS [training: 0.19579754612437072 | validation: 0.16516307949177134]
	TIME [epoch: 8.31 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1785822829068081		[learning rate: 0.0037654]
	Learning Rate: 0.00376538
	LOSS [training: 0.1785822829068081 | validation: 0.18982988958814317]
	TIME [epoch: 8.27 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1903484784754897		[learning rate: 0.0037525]
	Learning Rate: 0.00375248
	LOSS [training: 0.1903484784754897 | validation: 0.1305979421070724]
	TIME [epoch: 8.26 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13112726913944617		[learning rate: 0.0037396]
	Learning Rate: 0.00373959
	LOSS [training: 0.13112726913944617 | validation: 0.13468538817491743]
	TIME [epoch: 8.26 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15709668969544663		[learning rate: 0.0037267]
	Learning Rate: 0.00372672
	LOSS [training: 0.15709668969544663 | validation: 0.19293903971460832]
	TIME [epoch: 8.26 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16027248067356403		[learning rate: 0.0037139]
	Learning Rate: 0.00371387
	LOSS [training: 0.16027248067356403 | validation: 0.1508347696775495]
	TIME [epoch: 8.27 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.190020586946283		[learning rate: 0.003701]
	Learning Rate: 0.00370104
	LOSS [training: 0.190020586946283 | validation: 0.19334009313184045]
	TIME [epoch: 8.3 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.188211861374947		[learning rate: 0.0036882]
	Learning Rate: 0.00368822
	LOSS [training: 0.188211861374947 | validation: 0.12238466235254385]
	TIME [epoch: 8.26 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1566433733989438		[learning rate: 0.0036754]
	Learning Rate: 0.00367542
	LOSS [training: 0.1566433733989438 | validation: 0.13374083868332304]
	TIME [epoch: 8.26 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19639852236855332		[learning rate: 0.0036626]
	Learning Rate: 0.00366264
	LOSS [training: 0.19639852236855332 | validation: 0.23813861303739384]
	TIME [epoch: 8.27 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23492864405590752		[learning rate: 0.0036499]
	Learning Rate: 0.00364988
	LOSS [training: 0.23492864405590752 | validation: 0.14374933071538828]
	TIME [epoch: 8.26 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17044972418530005		[learning rate: 0.0036371]
	Learning Rate: 0.00363713
	LOSS [training: 0.17044972418530005 | validation: 0.12752816934811845]
	TIME [epoch: 8.3 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1510859824759227		[learning rate: 0.0036244]
	Learning Rate: 0.0036244
	LOSS [training: 0.1510859824759227 | validation: 0.2806396253008486]
	TIME [epoch: 8.27 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1575772285545673		[learning rate: 0.0036117]
	Learning Rate: 0.00361169
	LOSS [training: 0.1575772285545673 | validation: 0.15600419144534156]
	TIME [epoch: 8.26 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15074979737276373		[learning rate: 0.003599]
	Learning Rate: 0.003599
	LOSS [training: 0.15074979737276373 | validation: 0.2984495988515832]
	TIME [epoch: 8.26 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2383792294722763		[learning rate: 0.0035863]
	Learning Rate: 0.00358632
	LOSS [training: 0.2383792294722763 | validation: 0.13604840228789322]
	TIME [epoch: 8.26 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15723272236317415		[learning rate: 0.0035737]
	Learning Rate: 0.00357366
	LOSS [training: 0.15723272236317415 | validation: 0.13769839237115322]
	TIME [epoch: 8.26 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1495574463602969		[learning rate: 0.003561]
	Learning Rate: 0.00356102
	LOSS [training: 0.1495574463602969 | validation: 0.1953408843010399]
	TIME [epoch: 8.3 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19423118891997282		[learning rate: 0.0035484]
	Learning Rate: 0.00354839
	LOSS [training: 0.19423118891997282 | validation: 0.15917159222804061]
	TIME [epoch: 8.26 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17174275547846313		[learning rate: 0.0035358]
	Learning Rate: 0.00353579
	LOSS [training: 0.17174275547846313 | validation: 0.18072794452599422]
	TIME [epoch: 8.26 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16770530622694937		[learning rate: 0.0035232]
	Learning Rate: 0.0035232
	LOSS [training: 0.16770530622694937 | validation: 0.18347169635565186]
	TIME [epoch: 8.27 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17061222445729612		[learning rate: 0.0035106]
	Learning Rate: 0.00351063
	LOSS [training: 0.17061222445729612 | validation: 0.16727894582607913]
	TIME [epoch: 8.26 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17019222603999148		[learning rate: 0.0034981]
	Learning Rate: 0.00349807
	LOSS [training: 0.17019222603999148 | validation: 0.22149053720669956]
	TIME [epoch: 8.33 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15217770024638178		[learning rate: 0.0034855]
	Learning Rate: 0.00348554
	LOSS [training: 0.15217770024638178 | validation: 0.13570370235140897]
	TIME [epoch: 8.28 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19157354402671906		[learning rate: 0.003473]
	Learning Rate: 0.00347302
	LOSS [training: 0.19157354402671906 | validation: 0.17175557644067044]
	TIME [epoch: 8.26 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1532310209387284		[learning rate: 0.0034605]
	Learning Rate: 0.00346052
	LOSS [training: 0.1532310209387284 | validation: 0.13911612617207736]
	TIME [epoch: 8.26 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19371159873244187		[learning rate: 0.003448]
	Learning Rate: 0.00344804
	LOSS [training: 0.19371159873244187 | validation: 0.17001633303103747]
	TIME [epoch: 8.27 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14859084860100985		[learning rate: 0.0034356]
	Learning Rate: 0.00343557
	LOSS [training: 0.14859084860100985 | validation: 0.19591054674255168]
	TIME [epoch: 8.27 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1863475388232575		[learning rate: 0.0034231]
	Learning Rate: 0.00342313
	LOSS [training: 0.1863475388232575 | validation: 0.2436090253528908]
	TIME [epoch: 8.31 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1582839261095199		[learning rate: 0.0034107]
	Learning Rate: 0.0034107
	LOSS [training: 0.1582839261095199 | validation: 0.14837886625692284]
	TIME [epoch: 8.27 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17875299739991235		[learning rate: 0.0033983]
	Learning Rate: 0.00339829
	LOSS [training: 0.17875299739991235 | validation: 0.11867512748716494]
	TIME [epoch: 8.27 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15614150643243335		[learning rate: 0.0033859]
	Learning Rate: 0.0033859
	LOSS [training: 0.15614150643243335 | validation: 0.13009853650369624]
	TIME [epoch: 8.26 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1492630752060689		[learning rate: 0.0033735]
	Learning Rate: 0.00337352
	LOSS [training: 0.1492630752060689 | validation: 0.16647894769152938]
	TIME [epoch: 8.26 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17656699391578873		[learning rate: 0.0033612]
	Learning Rate: 0.00336117
	LOSS [training: 0.17656699391578873 | validation: 0.13674669829382416]
	TIME [epoch: 8.27 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16531291367570317		[learning rate: 0.0033488]
	Learning Rate: 0.00334883
	LOSS [training: 0.16531291367570317 | validation: 0.21765404137617847]
	TIME [epoch: 8.3 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1953983914402584		[learning rate: 0.0033365]
	Learning Rate: 0.00333651
	LOSS [training: 0.1953983914402584 | validation: 0.17225264664702317]
	TIME [epoch: 8.26 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1726732007990734		[learning rate: 0.0033242]
	Learning Rate: 0.00332421
	LOSS [training: 0.1726732007990734 | validation: 0.1443301106432932]
	TIME [epoch: 8.26 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17110828318512578		[learning rate: 0.0033119]
	Learning Rate: 0.00331192
	LOSS [training: 0.17110828318512578 | validation: 0.16180093146409455]
	TIME [epoch: 8.27 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14507487792005247		[learning rate: 0.0032997]
	Learning Rate: 0.00329966
	LOSS [training: 0.14507487792005247 | validation: 0.16918445761672157]
	TIME [epoch: 8.26 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17193968059673836		[learning rate: 0.0032874]
	Learning Rate: 0.00328741
	LOSS [training: 0.17193968059673836 | validation: 0.17417878538445766]
	TIME [epoch: 8.3 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15036442791108912		[learning rate: 0.0032752]
	Learning Rate: 0.00327518
	LOSS [training: 0.15036442791108912 | validation: 0.13790334418820116]
	TIME [epoch: 8.28 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1569988824363372		[learning rate: 0.003263]
	Learning Rate: 0.00326298
	LOSS [training: 0.1569988824363372 | validation: 0.19432876176540564]
	TIME [epoch: 8.26 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1788683758453068		[learning rate: 0.0032508]
	Learning Rate: 0.00325078
	LOSS [training: 0.1788683758453068 | validation: 0.12318026195450028]
	TIME [epoch: 8.26 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17686183178828424		[learning rate: 0.0032386]
	Learning Rate: 0.00323861
	LOSS [training: 0.17686183178828424 | validation: 0.14620973565790174]
	TIME [epoch: 8.27 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13471334589223002		[learning rate: 0.0032265]
	Learning Rate: 0.00322646
	LOSS [training: 0.13471334589223002 | validation: 0.1147064734703332]
	TIME [epoch: 8.26 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13019593689816197		[learning rate: 0.0032143]
	Learning Rate: 0.00321432
	LOSS [training: 0.13019593689816197 | validation: 0.1759383025110897]
	TIME [epoch: 8.3 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1515646576361747		[learning rate: 0.0032022]
	Learning Rate: 0.0032022
	LOSS [training: 0.1515646576361747 | validation: 0.17481912741681824]
	TIME [epoch: 8.27 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17313999401460567		[learning rate: 0.0031901]
	Learning Rate: 0.00319011
	LOSS [training: 0.17313999401460567 | validation: 0.19023673844251737]
	TIME [epoch: 8.26 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15220463055071753		[learning rate: 0.003178]
	Learning Rate: 0.00317803
	LOSS [training: 0.15220463055071753 | validation: 0.1718086908139148]
	TIME [epoch: 8.26 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1505171841636396		[learning rate: 0.003166]
	Learning Rate: 0.00316596
	LOSS [training: 0.1505171841636396 | validation: 0.13615309846128557]
	TIME [epoch: 8.26 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12904033608690274		[learning rate: 0.0031539]
	Learning Rate: 0.00315392
	LOSS [training: 0.12904033608690274 | validation: 0.1575708979519056]
	TIME [epoch: 8.29 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16559969149784404		[learning rate: 0.0031419]
	Learning Rate: 0.0031419
	LOSS [training: 0.16559969149784404 | validation: 0.15046215766837062]
	TIME [epoch: 8.28 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15714109754937086		[learning rate: 0.0031299]
	Learning Rate: 0.00312989
	LOSS [training: 0.15714109754937086 | validation: 0.18540993959883362]
	TIME [epoch: 8.26 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15847991350471957		[learning rate: 0.0031179]
	Learning Rate: 0.00311791
	LOSS [training: 0.15847991350471957 | validation: 0.14022481470351456]
	TIME [epoch: 8.26 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11528993240093315		[learning rate: 0.0031059]
	Learning Rate: 0.00310594
	LOSS [training: 0.11528993240093315 | validation: 0.1459452656070156]
	TIME [epoch: 8.26 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12648141773499597		[learning rate: 0.003094]
	Learning Rate: 0.00309399
	LOSS [training: 0.12648141773499597 | validation: 0.15426665828950809]
	TIME [epoch: 8.26 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17235639457077817		[learning rate: 0.0030821]
	Learning Rate: 0.00308206
	LOSS [training: 0.17235639457077817 | validation: 0.11713650393635025]
	TIME [epoch: 8.31 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14873371477122965		[learning rate: 0.0030701]
	Learning Rate: 0.00307015
	LOSS [training: 0.14873371477122965 | validation: 0.140210289424614]
	TIME [epoch: 8.26 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12137166538368516		[learning rate: 0.0030583]
	Learning Rate: 0.00305826
	LOSS [training: 0.12137166538368516 | validation: 0.13837578454241387]
	TIME [epoch: 8.26 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1462882708474779		[learning rate: 0.0030464]
	Learning Rate: 0.00304639
	LOSS [training: 0.1462882708474779 | validation: 0.1375201349755099]
	TIME [epoch: 8.26 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1266540951807339		[learning rate: 0.0030345]
	Learning Rate: 0.00303453
	LOSS [training: 0.1266540951807339 | validation: 0.15669884767602188]
	TIME [epoch: 8.26 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13226467884881232		[learning rate: 0.0030227]
	Learning Rate: 0.0030227
	LOSS [training: 0.13226467884881232 | validation: 0.15673840664667543]
	TIME [epoch: 8.28 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1643832678359857		[learning rate: 0.0030109]
	Learning Rate: 0.00301088
	LOSS [training: 0.1643832678359857 | validation: 0.1273792927812454]
	TIME [epoch: 8.3 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1538532942079905		[learning rate: 0.0029991]
	Learning Rate: 0.00299908
	LOSS [training: 0.1538532942079905 | validation: 0.24849619336371198]
	TIME [epoch: 8.26 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18788156383385413		[learning rate: 0.0029873]
	Learning Rate: 0.00298731
	LOSS [training: 0.18788156383385413 | validation: 0.2094359617299584]
	TIME [epoch: 8.26 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1505646634188395		[learning rate: 0.0029755]
	Learning Rate: 0.00297555
	LOSS [training: 0.1505646634188395 | validation: 0.165902371357353]
	TIME [epoch: 8.27 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15457788421237792		[learning rate: 0.0029638]
	Learning Rate: 0.00296381
	LOSS [training: 0.15457788421237792 | validation: 0.12451569240782093]
	TIME [epoch: 8.26 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14262951225199577		[learning rate: 0.0029521]
	Learning Rate: 0.00295209
	LOSS [training: 0.14262951225199577 | validation: 0.11592994471914986]
	TIME [epoch: 8.31 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14561163306086813		[learning rate: 0.0029404]
	Learning Rate: 0.00294039
	LOSS [training: 0.14561163306086813 | validation: 0.11966334321761393]
	TIME [epoch: 8.27 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13212207732197237		[learning rate: 0.0029287]
	Learning Rate: 0.00292871
	LOSS [training: 0.13212207732197237 | validation: 0.17653849755478654]
	TIME [epoch: 8.26 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14391303651083634		[learning rate: 0.002917]
	Learning Rate: 0.00291705
	LOSS [training: 0.14391303651083634 | validation: 0.13786597430930658]
	TIME [epoch: 8.26 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12226717423579392		[learning rate: 0.0029054]
	Learning Rate: 0.0029054
	LOSS [training: 0.12226717423579392 | validation: 0.12339737416958368]
	TIME [epoch: 8.26 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17355830291133753		[learning rate: 0.0028938]
	Learning Rate: 0.00289378
	LOSS [training: 0.17355830291133753 | validation: 0.12058801841612485]
	TIME [epoch: 8.27 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1445710131062621		[learning rate: 0.0028822]
	Learning Rate: 0.00288218
	LOSS [training: 0.1445710131062621 | validation: 0.14115790403918876]
	TIME [epoch: 8.31 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14171599042430907		[learning rate: 0.0028706]
	Learning Rate: 0.00287059
	LOSS [training: 0.14171599042430907 | validation: 0.11605587904106368]
	TIME [epoch: 8.27 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13751176944377305		[learning rate: 0.002859]
	Learning Rate: 0.00285903
	LOSS [training: 0.13751176944377305 | validation: 0.13977845791478904]
	TIME [epoch: 8.26 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15515129021351085		[learning rate: 0.0028475]
	Learning Rate: 0.00284748
	LOSS [training: 0.15515129021351085 | validation: 0.12093367179112091]
	TIME [epoch: 8.26 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12070351528848877		[learning rate: 0.002836]
	Learning Rate: 0.00283596
	LOSS [training: 0.12070351528848877 | validation: 0.15663078862159346]
	TIME [epoch: 8.26 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14782170504892617		[learning rate: 0.0028245]
	Learning Rate: 0.00282445
	LOSS [training: 0.14782170504892617 | validation: 0.142422870964144]
	TIME [epoch: 8.29 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16113959313690562		[learning rate: 0.002813]
	Learning Rate: 0.00281297
	LOSS [training: 0.16113959313690562 | validation: 0.1490281204675458]
	TIME [epoch: 8.28 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14847867865226577		[learning rate: 0.0028015]
	Learning Rate: 0.0028015
	LOSS [training: 0.14847867865226577 | validation: 0.1511721618387342]
	TIME [epoch: 8.27 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14348094486183166		[learning rate: 0.0027901]
	Learning Rate: 0.00279005
	LOSS [training: 0.14348094486183166 | validation: 0.12911126414978702]
	TIME [epoch: 8.26 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11505444023617956		[learning rate: 0.0027786]
	Learning Rate: 0.00277863
	LOSS [training: 0.11505444023617956 | validation: 0.1348325701358598]
	TIME [epoch: 8.26 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12655394155314587		[learning rate: 0.0027672]
	Learning Rate: 0.00276722
	LOSS [training: 0.12655394155314587 | validation: 0.11658986814204733]
	TIME [epoch: 8.27 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13060996950762782		[learning rate: 0.0027558]
	Learning Rate: 0.00275583
	LOSS [training: 0.13060996950762782 | validation: 0.12216552049682908]
	TIME [epoch: 8.31 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11298253096294847		[learning rate: 0.0027445]
	Learning Rate: 0.00274446
	LOSS [training: 0.11298253096294847 | validation: 0.13744549246227455]
	TIME [epoch: 8.27 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1434344481552535		[learning rate: 0.0027331]
	Learning Rate: 0.00273312
	LOSS [training: 0.1434344481552535 | validation: 0.13084623080664465]
	TIME [epoch: 8.26 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13171925297823972		[learning rate: 0.0027218]
	Learning Rate: 0.00272179
	LOSS [training: 0.13171925297823972 | validation: 0.16719243323514088]
	TIME [epoch: 8.26 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13379606675167852		[learning rate: 0.0027105]
	Learning Rate: 0.00271048
	LOSS [training: 0.13379606675167852 | validation: 0.136141010710552]
	TIME [epoch: 8.27 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12809650551679824		[learning rate: 0.0026992]
	Learning Rate: 0.00269919
	LOSS [training: 0.12809650551679824 | validation: 0.17467502769917026]
	TIME [epoch: 8.28 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14812695842420975		[learning rate: 0.0026879]
	Learning Rate: 0.00268792
	LOSS [training: 0.14812695842420975 | validation: 0.1627927236257643]
	TIME [epoch: 8.29 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13891301436284137		[learning rate: 0.0026767]
	Learning Rate: 0.00267667
	LOSS [training: 0.13891301436284137 | validation: 0.10721180969915539]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_1498.pth
	Model improved!!!
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13788968071173155		[learning rate: 0.0026654]
	Learning Rate: 0.00266545
	LOSS [training: 0.13788968071173155 | validation: 0.13506385151777617]
	TIME [epoch: 8.27 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12879182623024588		[learning rate: 0.0026542]
	Learning Rate: 0.00265424
	LOSS [training: 0.12879182623024588 | validation: 0.1332502327930773]
	TIME [epoch: 8.27 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12781753284912914		[learning rate: 0.0026431]
	Learning Rate: 0.00264305
	LOSS [training: 0.12781753284912914 | validation: 0.1297318187408882]
	TIME [epoch: 8.27 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13204953616728493		[learning rate: 0.0026319]
	Learning Rate: 0.00263188
	LOSS [training: 0.13204953616728493 | validation: 0.13242005589421665]
	TIME [epoch: 8.31 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1323356603557009		[learning rate: 0.0026207]
	Learning Rate: 0.00262073
	LOSS [training: 0.1323356603557009 | validation: 0.13682132128396718]
	TIME [epoch: 8.26 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14410477156053153		[learning rate: 0.0026096]
	Learning Rate: 0.00260961
	LOSS [training: 0.14410477156053153 | validation: 0.13970373620560086]
	TIME [epoch: 8.26 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.163576759776841		[learning rate: 0.0025985]
	Learning Rate: 0.0025985
	LOSS [training: 0.163576759776841 | validation: 0.23779891823697097]
	TIME [epoch: 8.26 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16078612720941862		[learning rate: 0.0025874]
	Learning Rate: 0.00258741
	LOSS [training: 0.16078612720941862 | validation: 0.11592659035859276]
	TIME [epoch: 8.26 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13602910950880479		[learning rate: 0.0025763]
	Learning Rate: 0.00257635
	LOSS [training: 0.13602910950880479 | validation: 0.12893162728655566]
	TIME [epoch: 8.28 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14873413321177936		[learning rate: 0.0025653]
	Learning Rate: 0.0025653
	LOSS [training: 0.14873413321177936 | validation: 0.13908731276191916]
	TIME [epoch: 8.29 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14305789888374704		[learning rate: 0.0025543]
	Learning Rate: 0.00255427
	LOSS [training: 0.14305789888374704 | validation: 0.1718066607684231]
	TIME [epoch: 8.26 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12623755673026923		[learning rate: 0.0025433]
	Learning Rate: 0.00254327
	LOSS [training: 0.12623755673026923 | validation: 0.14020367470863615]
	TIME [epoch: 8.26 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1563080991720948		[learning rate: 0.0025323]
	Learning Rate: 0.00253228
	LOSS [training: 0.1563080991720948 | validation: 0.18151091860844382]
	TIME [epoch: 8.26 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12931393890588677		[learning rate: 0.0025213]
	Learning Rate: 0.00252132
	LOSS [training: 0.12931393890588677 | validation: 0.1316352022653157]
	TIME [epoch: 8.26 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.131922432018961		[learning rate: 0.0025104]
	Learning Rate: 0.00251037
	LOSS [training: 0.131922432018961 | validation: 0.14703180473319846]
	TIME [epoch: 8.3 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12793789978027018		[learning rate: 0.0024994]
	Learning Rate: 0.00249945
	LOSS [training: 0.12793789978027018 | validation: 0.15894482195943405]
	TIME [epoch: 8.27 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14420686952847217		[learning rate: 0.0024885]
	Learning Rate: 0.00248855
	LOSS [training: 0.14420686952847217 | validation: 0.14704063720541619]
	TIME [epoch: 8.26 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15623538440946183		[learning rate: 0.0024777]
	Learning Rate: 0.00247766
	LOSS [training: 0.15623538440946183 | validation: 0.13998757787934688]
	TIME [epoch: 8.26 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13872761844509157		[learning rate: 0.0024668]
	Learning Rate: 0.0024668
	LOSS [training: 0.13872761844509157 | validation: 0.13195579338378186]
	TIME [epoch: 8.26 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1270581930494571		[learning rate: 0.002456]
	Learning Rate: 0.00245596
	LOSS [training: 0.1270581930494571 | validation: 0.11966029596756546]
	TIME [epoch: 8.26 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1289625023827453		[learning rate: 0.0024451]
	Learning Rate: 0.00244514
	LOSS [training: 0.1289625023827453 | validation: 0.13779453971619987]
	TIME [epoch: 8.31 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1206321137586498		[learning rate: 0.0024343]
	Learning Rate: 0.00243434
	LOSS [training: 0.1206321137586498 | validation: 0.1745553927835563]
	TIME [epoch: 8.26 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13256058620637037		[learning rate: 0.0024236]
	Learning Rate: 0.00242356
	LOSS [training: 0.13256058620637037 | validation: 0.12754068482182182]
	TIME [epoch: 8.26 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13521063025779878		[learning rate: 0.0024128]
	Learning Rate: 0.0024128
	LOSS [training: 0.13521063025779878 | validation: 0.17260191849059237]
	TIME [epoch: 8.26 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1321172067754699		[learning rate: 0.0024021]
	Learning Rate: 0.00240206
	LOSS [training: 0.1321172067754699 | validation: 0.14018340248036826]
	TIME [epoch: 8.26 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11687460489553728		[learning rate: 0.0023913]
	Learning Rate: 0.00239134
	LOSS [training: 0.11687460489553728 | validation: 0.1360706701911689]
	TIME [epoch: 8.29 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12064068359018806		[learning rate: 0.0023806]
	Learning Rate: 0.00238065
	LOSS [training: 0.12064068359018806 | validation: 0.20237625815967714]
	TIME [epoch: 8.28 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13979124683695837		[learning rate: 0.00237]
	Learning Rate: 0.00236997
	LOSS [training: 0.13979124683695837 | validation: 0.1682678037598352]
	TIME [epoch: 8.26 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13266227850924536		[learning rate: 0.0023593]
	Learning Rate: 0.00235931
	LOSS [training: 0.13266227850924536 | validation: 0.12099952311385967]
	TIME [epoch: 8.26 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1260256358927123		[learning rate: 0.0023487]
	Learning Rate: 0.00234868
	LOSS [training: 0.1260256358927123 | validation: 0.11895754369884903]
	TIME [epoch: 8.26 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11354445157816817		[learning rate: 0.0023381]
	Learning Rate: 0.00233807
	LOSS [training: 0.11354445157816817 | validation: 0.13067268558959455]
	TIME [epoch: 8.26 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12199196478132479		[learning rate: 0.0023275]
	Learning Rate: 0.00232748
	LOSS [training: 0.12199196478132479 | validation: 0.17342396739264726]
	TIME [epoch: 8.3 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14705577996997096		[learning rate: 0.0023169]
	Learning Rate: 0.0023169
	LOSS [training: 0.14705577996997096 | validation: 0.12308667447997124]
	TIME [epoch: 8.26 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15079189674366822		[learning rate: 0.0023064]
	Learning Rate: 0.00230635
	LOSS [training: 0.15079189674366822 | validation: 0.1396152555390579]
	TIME [epoch: 8.26 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12494995048807538		[learning rate: 0.0022958]
	Learning Rate: 0.00229583
	LOSS [training: 0.12494995048807538 | validation: 0.13883039936634656]
	TIME [epoch: 8.26 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13063382289698988		[learning rate: 0.0022853]
	Learning Rate: 0.00228532
	LOSS [training: 0.13063382289698988 | validation: 0.12212147949780623]
	TIME [epoch: 8.25 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14203931701147546		[learning rate: 0.0022748]
	Learning Rate: 0.00227483
	LOSS [training: 0.14203931701147546 | validation: 0.12273559511977272]
	TIME [epoch: 8.27 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13396285559904064		[learning rate: 0.0022644]
	Learning Rate: 0.00226436
	LOSS [training: 0.13396285559904064 | validation: 0.12140051115111052]
	TIME [epoch: 8.28 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11419321068870814		[learning rate: 0.0022539]
	Learning Rate: 0.00225392
	LOSS [training: 0.11419321068870814 | validation: 0.1674892572501742]
	TIME [epoch: 8.26 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14082627894164934		[learning rate: 0.0022435]
	Learning Rate: 0.0022435
	LOSS [training: 0.14082627894164934 | validation: 0.13108497364031388]
	TIME [epoch: 8.26 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11311319965181575		[learning rate: 0.0022331]
	Learning Rate: 0.00223309
	LOSS [training: 0.11311319965181575 | validation: 0.17449554651344729]
	TIME [epoch: 8.26 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15048839544775794		[learning rate: 0.0022227]
	Learning Rate: 0.00222271
	LOSS [training: 0.15048839544775794 | validation: 0.143935899544752]
	TIME [epoch: 8.26 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13826668139850784		[learning rate: 0.0022124]
	Learning Rate: 0.00221235
	LOSS [training: 0.13826668139850784 | validation: 0.16250932046077]
	TIME [epoch: 8.3 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11853259629324493		[learning rate: 0.002202]
	Learning Rate: 0.00220202
	LOSS [training: 0.11853259629324493 | validation: 0.1302740123775852]
	TIME [epoch: 8.27 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12124549464679234		[learning rate: 0.0021917]
	Learning Rate: 0.0021917
	LOSS [training: 0.12124549464679234 | validation: 0.11366454406687074]
	TIME [epoch: 8.26 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10972005050792166		[learning rate: 0.0021814]
	Learning Rate: 0.0021814
	LOSS [training: 0.10972005050792166 | validation: 0.13808158417501035]
	TIME [epoch: 8.26 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13275371239289557		[learning rate: 0.0021711]
	Learning Rate: 0.00217113
	LOSS [training: 0.13275371239289557 | validation: 0.141043012156697]
	TIME [epoch: 8.26 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12226606173899794		[learning rate: 0.0021609]
	Learning Rate: 0.00216088
	LOSS [training: 0.12226606173899794 | validation: 0.1390384606072276]
	TIME [epoch: 8.27 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10881577546274944		[learning rate: 0.0021506]
	Learning Rate: 0.00215064
	LOSS [training: 0.10881577546274944 | validation: 0.17108507118043143]
	TIME [epoch: 8.3 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13914548849133238		[learning rate: 0.0021404]
	Learning Rate: 0.00214043
	LOSS [training: 0.13914548849133238 | validation: 0.1367891855691567]
	TIME [epoch: 8.27 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11458567279402496		[learning rate: 0.0021302]
	Learning Rate: 0.00213025
	LOSS [training: 0.11458567279402496 | validation: 0.13476741460803643]
	TIME [epoch: 8.26 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12525532626131664		[learning rate: 0.0021201]
	Learning Rate: 0.00212008
	LOSS [training: 0.12525532626131664 | validation: 0.1332120734742437]
	TIME [epoch: 8.26 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1075023298279785		[learning rate: 0.0021099]
	Learning Rate: 0.00210993
	LOSS [training: 0.1075023298279785 | validation: 0.14956883552172381]
	TIME [epoch: 8.26 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11137869436996732		[learning rate: 0.0020998]
	Learning Rate: 0.00209981
	LOSS [training: 0.11137869436996732 | validation: 0.14957296534224193]
	TIME [epoch: 8.3 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11822417836278115		[learning rate: 0.0020897]
	Learning Rate: 0.00208971
	LOSS [training: 0.11822417836278115 | validation: 0.13708227933379352]
	TIME [epoch: 8.28 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13459962251915006		[learning rate: 0.0020796]
	Learning Rate: 0.00207963
	LOSS [training: 0.13459962251915006 | validation: 0.13931055948419538]
	TIME [epoch: 8.26 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.120436184161681		[learning rate: 0.0020696]
	Learning Rate: 0.00206957
	LOSS [training: 0.120436184161681 | validation: 0.12976191186733932]
	TIME [epoch: 8.26 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11013887039305376		[learning rate: 0.0020595]
	Learning Rate: 0.00205953
	LOSS [training: 0.11013887039305376 | validation: 0.11432467197758014]
	TIME [epoch: 8.27 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10046096667265403		[learning rate: 0.0020495]
	Learning Rate: 0.00204952
	LOSS [training: 0.10046096667265403 | validation: 0.13616992217023305]
	TIME [epoch: 8.26 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14838261898567073		[learning rate: 0.0020395]
	Learning Rate: 0.00203952
	LOSS [training: 0.14838261898567073 | validation: 0.12180666653620917]
	TIME [epoch: 8.31 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12091908046829032		[learning rate: 0.0020296]
	Learning Rate: 0.00202955
	LOSS [training: 0.12091908046829032 | validation: 0.11894414982573108]
	TIME [epoch: 8.27 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10086760868194981		[learning rate: 0.0020196]
	Learning Rate: 0.0020196
	LOSS [training: 0.10086760868194981 | validation: 0.10819902133076749]
	TIME [epoch: 8.27 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10248238679423126		[learning rate: 0.0020097]
	Learning Rate: 0.00200967
	LOSS [training: 0.10248238679423126 | validation: 0.11252453940702511]
	TIME [epoch: 8.26 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11046710861535493		[learning rate: 0.0019998]
	Learning Rate: 0.00199977
	LOSS [training: 0.11046710861535493 | validation: 0.11734862490525416]
	TIME [epoch: 8.26 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11413976126572084		[learning rate: 0.0019899]
	Learning Rate: 0.00198988
	LOSS [training: 0.11413976126572084 | validation: 0.123841022993046]
	TIME [epoch: 8.3 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11382245143679816		[learning rate: 0.00198]
	Learning Rate: 0.00198002
	LOSS [training: 0.11382245143679816 | validation: 0.11631666473046248]
	TIME [epoch: 8.28 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10624319169792733		[learning rate: 0.0019702]
	Learning Rate: 0.00197018
	LOSS [training: 0.10624319169792733 | validation: 0.1249840472812836]
	TIME [epoch: 8.26 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1136240774611082		[learning rate: 0.0019604]
	Learning Rate: 0.00196036
	LOSS [training: 0.1136240774611082 | validation: 0.12507145606094675]
	TIME [epoch: 8.26 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11513430143173184		[learning rate: 0.0019506]
	Learning Rate: 0.00195056
	LOSS [training: 0.11513430143173184 | validation: 0.11687182734190077]
	TIME [epoch: 8.26 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11515477938549919		[learning rate: 0.0019408]
	Learning Rate: 0.00194079
	LOSS [training: 0.11515477938549919 | validation: 0.13927643115617186]
	TIME [epoch: 8.27 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13567324957118404		[learning rate: 0.001931]
	Learning Rate: 0.00193103
	LOSS [training: 0.13567324957118404 | validation: 0.16108331788605618]
	TIME [epoch: 8.31 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14731076317237893		[learning rate: 0.0019213]
	Learning Rate: 0.0019213
	LOSS [training: 0.14731076317237893 | validation: 0.11964263220329738]
	TIME [epoch: 8.27 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1084324779644827		[learning rate: 0.0019116]
	Learning Rate: 0.0019116
	LOSS [training: 0.1084324779644827 | validation: 0.117654285993927]
	TIME [epoch: 8.26 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10578383059059766		[learning rate: 0.0019019]
	Learning Rate: 0.00190191
	LOSS [training: 0.10578383059059766 | validation: 0.12727080385608072]
	TIME [epoch: 8.27 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11841289563626359		[learning rate: 0.0018922]
	Learning Rate: 0.00189225
	LOSS [training: 0.11841289563626359 | validation: 0.15624758817205836]
	TIME [epoch: 8.26 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12775784105245766		[learning rate: 0.0018826]
	Learning Rate: 0.0018826
	LOSS [training: 0.12775784105245766 | validation: 0.12451921833057858]
	TIME [epoch: 8.28 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10717678692590243		[learning rate: 0.001873]
	Learning Rate: 0.00187298
	LOSS [training: 0.10717678692590243 | validation: 0.09982148976688465]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_1575.pth
	Model improved!!!
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1049514771901028		[learning rate: 0.0018634]
	Learning Rate: 0.00186339
	LOSS [training: 0.1049514771901028 | validation: 0.1471776041287235]
	TIME [epoch: 8.27 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12205788816292235		[learning rate: 0.0018538]
	Learning Rate: 0.00185381
	LOSS [training: 0.12205788816292235 | validation: 0.10379158086610615]
	TIME [epoch: 8.26 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10279416259167062		[learning rate: 0.0018443]
	Learning Rate: 0.00184426
	LOSS [training: 0.10279416259167062 | validation: 0.13730732675659596]
	TIME [epoch: 8.26 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10683281960033963		[learning rate: 0.0018347]
	Learning Rate: 0.00183473
	LOSS [training: 0.10683281960033963 | validation: 0.11152922331645843]
	TIME [epoch: 8.26 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11250430079075763		[learning rate: 0.0018252]
	Learning Rate: 0.00182522
	LOSS [training: 0.11250430079075763 | validation: 0.10118008582200176]
	TIME [epoch: 8.29 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1181570718742133		[learning rate: 0.0018157]
	Learning Rate: 0.00181573
	LOSS [training: 0.1181570718742133 | validation: 0.12877905200027695]
	TIME [epoch: 8.27 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10705034059569252		[learning rate: 0.0018063]
	Learning Rate: 0.00180627
	LOSS [training: 0.10705034059569252 | validation: 0.11773147133880521]
	TIME [epoch: 8.26 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11000770484177065		[learning rate: 0.0017968]
	Learning Rate: 0.00179683
	LOSS [training: 0.11000770484177065 | validation: 0.14747627954563675]
	TIME [epoch: 8.26 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12475952478137116		[learning rate: 0.0017874]
	Learning Rate: 0.00178741
	LOSS [training: 0.12475952478137116 | validation: 0.13485144354365006]
	TIME [epoch: 8.26 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10465054372896393		[learning rate: 0.001778]
	Learning Rate: 0.00177801
	LOSS [training: 0.10465054372896393 | validation: 0.13583451082199383]
	TIME [epoch: 8.27 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12291562329543086		[learning rate: 0.0017686]
	Learning Rate: 0.00176864
	LOSS [training: 0.12291562329543086 | validation: 0.1206155172716449]
	TIME [epoch: 8.31 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1061293175110211		[learning rate: 0.0017593]
	Learning Rate: 0.00175929
	LOSS [training: 0.1061293175110211 | validation: 0.1018545895065529]
	TIME [epoch: 8.26 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10486645330208119		[learning rate: 0.00175]
	Learning Rate: 0.00174996
	LOSS [training: 0.10486645330208119 | validation: 0.11634099557932154]
	TIME [epoch: 8.26 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10921268916689966		[learning rate: 0.0017407]
	Learning Rate: 0.00174065
	LOSS [training: 0.10921268916689966 | validation: 0.17794170591806885]
	TIME [epoch: 8.26 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13391315366160259		[learning rate: 0.0017314]
	Learning Rate: 0.00173137
	LOSS [training: 0.13391315366160259 | validation: 0.12343842397526145]
	TIME [epoch: 8.25 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11875996023670451		[learning rate: 0.0017221]
	Learning Rate: 0.00172211
	LOSS [training: 0.11875996023670451 | validation: 0.12295723854949359]
	TIME [epoch: 8.29 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12050369803496767		[learning rate: 0.0017129]
	Learning Rate: 0.00171287
	LOSS [training: 0.12050369803496767 | validation: 0.1261506930258493]
	TIME [epoch: 8.27 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12419054385102618		[learning rate: 0.0017037]
	Learning Rate: 0.00170365
	LOSS [training: 0.12419054385102618 | validation: 0.10278172220658739]
	TIME [epoch: 8.27 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10827720099360083		[learning rate: 0.0016945]
	Learning Rate: 0.00169446
	LOSS [training: 0.10827720099360083 | validation: 0.12361894373685661]
	TIME [epoch: 8.25 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11967464648687602		[learning rate: 0.0016853]
	Learning Rate: 0.00168529
	LOSS [training: 0.11967464648687602 | validation: 0.12070960572451535]
	TIME [epoch: 8.26 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1096891042260795		[learning rate: 0.0016761]
	Learning Rate: 0.00167614
	LOSS [training: 0.1096891042260795 | validation: 0.11704937855930964]
	TIME [epoch: 8.26 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11622001741372813		[learning rate: 0.001667]
	Learning Rate: 0.00166702
	LOSS [training: 0.11622001741372813 | validation: 0.12289851613351094]
	TIME [epoch: 8.3 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11490145919786982		[learning rate: 0.0016579]
	Learning Rate: 0.00165792
	LOSS [training: 0.11490145919786982 | validation: 0.10332618438225882]
	TIME [epoch: 8.26 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10290371069096418		[learning rate: 0.0016488]
	Learning Rate: 0.00164884
	LOSS [training: 0.10290371069096418 | validation: 0.11463828300636872]
	TIME [epoch: 8.26 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10682731319565081		[learning rate: 0.0016398]
	Learning Rate: 0.00163978
	LOSS [training: 0.10682731319565081 | validation: 0.10889830039220061]
	TIME [epoch: 8.25 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10013403254014147		[learning rate: 0.0016307]
	Learning Rate: 0.00163075
	LOSS [training: 0.10013403254014147 | validation: 0.1594430073834905]
	TIME [epoch: 8.27 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1142579233439744		[learning rate: 0.0016217]
	Learning Rate: 0.00162174
	LOSS [training: 0.1142579233439744 | validation: 0.1209485817723315]
	TIME [epoch: 8.3 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1157434364895192		[learning rate: 0.0016128]
	Learning Rate: 0.00161275
	LOSS [training: 0.1157434364895192 | validation: 0.11236854433124052]
	TIME [epoch: 8.28 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1048941919775789		[learning rate: 0.0016038]
	Learning Rate: 0.00160379
	LOSS [training: 0.1048941919775789 | validation: 0.11563405487210482]
	TIME [epoch: 8.27 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10197013896432303		[learning rate: 0.0015948]
	Learning Rate: 0.00159484
	LOSS [training: 0.10197013896432303 | validation: 0.10526089449732931]
	TIME [epoch: 8.26 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10591616739090534		[learning rate: 0.0015859]
	Learning Rate: 0.00158593
	LOSS [training: 0.10591616739090534 | validation: 0.10334102675221075]
	TIME [epoch: 8.29 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13098860365290727		[learning rate: 0.001577]
	Learning Rate: 0.00157703
	LOSS [training: 0.13098860365290727 | validation: 0.12203817273536757]
	TIME [epoch: 8.26 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10235689162047445		[learning rate: 0.0015682]
	Learning Rate: 0.00156816
	LOSS [training: 0.10235689162047445 | validation: 0.1270237960148145]
	TIME [epoch: 8.31 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09916151638526405		[learning rate: 0.0015593]
	Learning Rate: 0.00155931
	LOSS [training: 0.09916151638526405 | validation: 0.11988481973295398]
	TIME [epoch: 8.26 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1102652878129492		[learning rate: 0.0015505]
	Learning Rate: 0.00155048
	LOSS [training: 0.1102652878129492 | validation: 0.12832269807179753]
	TIME [epoch: 8.26 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09517763758156378		[learning rate: 0.0015417]
	Learning Rate: 0.00154168
	LOSS [training: 0.09517763758156378 | validation: 0.10129907590036936]
	TIME [epoch: 8.26 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10288862012942096		[learning rate: 0.0015329]
	Learning Rate: 0.0015329
	LOSS [training: 0.10288862012942096 | validation: 0.14178753310754136]
	TIME [epoch: 8.26 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12871723036173355		[learning rate: 0.0015241]
	Learning Rate: 0.00152414
	LOSS [training: 0.12871723036173355 | validation: 0.09743537930925429]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_1613.pth
	Model improved!!!
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10323772823128974		[learning rate: 0.0015154]
	Learning Rate: 0.00151541
	LOSS [training: 0.10323772823128974 | validation: 0.10067185557748115]
	TIME [epoch: 8.3 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1005291577923008		[learning rate: 0.0015067]
	Learning Rate: 0.0015067
	LOSS [training: 0.1005291577923008 | validation: 0.10211154476569673]
	TIME [epoch: 8.27 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11347340747245671		[learning rate: 0.001498]
	Learning Rate: 0.00149801
	LOSS [training: 0.11347340747245671 | validation: 0.1280288794059179]
	TIME [epoch: 8.27 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1242753911333755		[learning rate: 0.0014893]
	Learning Rate: 0.00148934
	LOSS [training: 0.1242753911333755 | validation: 0.14535203193318347]
	TIME [epoch: 8.26 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11523638124365673		[learning rate: 0.0014807]
	Learning Rate: 0.0014807
	LOSS [training: 0.11523638124365673 | validation: 0.10760806888008138]
	TIME [epoch: 8.26 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11350826937843872		[learning rate: 0.0014721]
	Learning Rate: 0.00147209
	LOSS [training: 0.11350826937843872 | validation: 0.10347094208338514]
	TIME [epoch: 8.31 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0996066146555612		[learning rate: 0.0014635]
	Learning Rate: 0.00146349
	LOSS [training: 0.0996066146555612 | validation: 0.11350322274472838]
	TIME [epoch: 8.27 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10663234897647535		[learning rate: 0.0014549]
	Learning Rate: 0.00145492
	LOSS [training: 0.10663234897647535 | validation: 0.13178402657615113]
	TIME [epoch: 8.27 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10913763045733749		[learning rate: 0.0014464]
	Learning Rate: 0.00144637
	LOSS [training: 0.10913763045733749 | validation: 0.11088486196560818]
	TIME [epoch: 8.27 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10078260686914452		[learning rate: 0.0014378]
	Learning Rate: 0.00143785
	LOSS [training: 0.10078260686914452 | validation: 0.11079431638215614]
	TIME [epoch: 8.27 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1003567419569942		[learning rate: 0.0014293]
	Learning Rate: 0.00142935
	LOSS [training: 0.1003567419569942 | validation: 0.1210252996142209]
	TIME [epoch: 8.28 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1241463929963928		[learning rate: 0.0014209]
	Learning Rate: 0.00142087
	LOSS [training: 0.1241463929963928 | validation: 0.11541369571475474]
	TIME [epoch: 8.31 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09646465643600369		[learning rate: 0.0014124]
	Learning Rate: 0.00141242
	LOSS [training: 0.09646465643600369 | validation: 0.11422581093952722]
	TIME [epoch: 8.27 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10013105907620456		[learning rate: 0.001404]
	Learning Rate: 0.00140399
	LOSS [training: 0.10013105907620456 | validation: 0.1317305588352123]
	TIME [epoch: 8.27 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11988801841275787		[learning rate: 0.0013956]
	Learning Rate: 0.00139558
	LOSS [training: 0.11988801841275787 | validation: 0.11795149840750163]
	TIME [epoch: 8.27 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09851616341980432		[learning rate: 0.0013872]
	Learning Rate: 0.0013872
	LOSS [training: 0.09851616341980432 | validation: 0.10790854148491877]
	TIME [epoch: 8.27 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09307364081421482		[learning rate: 0.0013788]
	Learning Rate: 0.00137884
	LOSS [training: 0.09307364081421482 | validation: 0.12299427883752556]
	TIME [epoch: 8.31 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10337274123736892		[learning rate: 0.0013705]
	Learning Rate: 0.0013705
	LOSS [training: 0.10337274123736892 | validation: 0.13255687549649117]
	TIME [epoch: 8.28 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10096491359229592		[learning rate: 0.0013622]
	Learning Rate: 0.00136219
	LOSS [training: 0.10096491359229592 | validation: 0.11944203250415605]
	TIME [epoch: 8.27 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09725365211462794		[learning rate: 0.0013539]
	Learning Rate: 0.0013539
	LOSS [training: 0.09725365211462794 | validation: 0.11268772690435946]
	TIME [epoch: 8.27 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10793491493841308		[learning rate: 0.0013456]
	Learning Rate: 0.00134564
	LOSS [training: 0.10793491493841308 | validation: 0.10739048335870655]
	TIME [epoch: 8.27 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08841962648487908		[learning rate: 0.0013374]
	Learning Rate: 0.00133739
	LOSS [training: 0.08841962648487908 | validation: 0.09379522054021984]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_1635.pth
	Model improved!!!
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10012015941731267		[learning rate: 0.0013292]
	Learning Rate: 0.00132918
	LOSS [training: 0.10012015941731267 | validation: 0.10462887323276304]
	TIME [epoch: 8.32 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09793959765548053		[learning rate: 0.001321]
	Learning Rate: 0.00132098
	LOSS [training: 0.09793959765548053 | validation: 0.1067799564163785]
	TIME [epoch: 8.27 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0931000425787717		[learning rate: 0.0013128]
	Learning Rate: 0.00131281
	LOSS [training: 0.0931000425787717 | validation: 0.12716424616642916]
	TIME [epoch: 8.31 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10595148490158546		[learning rate: 0.0013047]
	Learning Rate: 0.00130466
	LOSS [training: 0.10595148490158546 | validation: 0.12771418455900738]
	TIME [epoch: 8.27 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09837065391138768		[learning rate: 0.0012965]
	Learning Rate: 0.00129654
	LOSS [training: 0.09837065391138768 | validation: 0.13586366197909241]
	TIME [epoch: 8.27 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1068390464940259		[learning rate: 0.0012884]
	Learning Rate: 0.00128844
	LOSS [training: 0.1068390464940259 | validation: 0.12901665766887938]
	TIME [epoch: 8.3 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09910460918843149		[learning rate: 0.0012804]
	Learning Rate: 0.00128037
	LOSS [training: 0.09910460918843149 | validation: 0.13085963614893895]
	TIME [epoch: 8.28 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10699930582222766		[learning rate: 0.0012723]
	Learning Rate: 0.00127232
	LOSS [training: 0.10699930582222766 | validation: 0.11138605649665381]
	TIME [epoch: 8.28 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10370937623007523		[learning rate: 0.0012643]
	Learning Rate: 0.00126429
	LOSS [training: 0.10370937623007523 | validation: 0.1273835013884152]
	TIME [epoch: 8.27 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09911424163425935		[learning rate: 0.0012563]
	Learning Rate: 0.00125629
	LOSS [training: 0.09911424163425935 | validation: 0.11787852911954323]
	TIME [epoch: 8.27 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09511244935467843		[learning rate: 0.0012483]
	Learning Rate: 0.00124831
	LOSS [training: 0.09511244935467843 | validation: 0.11702513029024895]
	TIME [epoch: 8.27 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10005678967233075		[learning rate: 0.0012404]
	Learning Rate: 0.00124035
	LOSS [training: 0.10005678967233075 | validation: 0.11418779912807654]
	TIME [epoch: 8.31 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10317742341772737		[learning rate: 0.0012324]
	Learning Rate: 0.00123242
	LOSS [training: 0.10317742341772737 | validation: 0.12127394149532118]
	TIME [epoch: 8.27 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10024617349444463		[learning rate: 0.0012245]
	Learning Rate: 0.00122451
	LOSS [training: 0.10024617349444463 | validation: 0.11034110045610626]
	TIME [epoch: 8.27 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09894064735933741		[learning rate: 0.0012166]
	Learning Rate: 0.00121663
	LOSS [training: 0.09894064735933741 | validation: 0.10927094172866013]
	TIME [epoch: 8.27 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10676755436471597		[learning rate: 0.0012088]
	Learning Rate: 0.00120877
	LOSS [training: 0.10676755436471597 | validation: 0.1262838862739023]
	TIME [epoch: 8.27 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10255951389943599		[learning rate: 0.0012009]
	Learning Rate: 0.00120093
	LOSS [training: 0.10255951389943599 | validation: 0.1448426669202923]
	TIME [epoch: 8.29 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12038615123975292		[learning rate: 0.0011931]
	Learning Rate: 0.00119312
	LOSS [training: 0.12038615123975292 | validation: 0.12068076760632909]
	TIME [epoch: 8.3 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10282074375540635		[learning rate: 0.0011853]
	Learning Rate: 0.00118533
	LOSS [training: 0.10282074375540635 | validation: 0.10636047031481152]
	TIME [epoch: 8.27 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09384619619701876		[learning rate: 0.0011776]
	Learning Rate: 0.00117757
	LOSS [training: 0.09384619619701876 | validation: 0.1189030698145605]
	TIME [epoch: 8.27 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0871221938979808		[learning rate: 0.0011698]
	Learning Rate: 0.00116983
	LOSS [training: 0.0871221938979808 | validation: 0.1513522081908562]
	TIME [epoch: 8.27 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11434254271750033		[learning rate: 0.0011621]
	Learning Rate: 0.00116211
	LOSS [training: 0.11434254271750033 | validation: 0.1411869886340603]
	TIME [epoch: 8.27 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11034707176162159		[learning rate: 0.0011544]
	Learning Rate: 0.00115442
	LOSS [training: 0.11034707176162159 | validation: 0.11743377217743287]
	TIME [epoch: 8.31 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09926963765817112		[learning rate: 0.0011468]
	Learning Rate: 0.00114676
	LOSS [training: 0.09926963765817112 | validation: 0.1206541237799979]
	TIME [epoch: 8.27 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1022343261694555		[learning rate: 0.0011391]
	Learning Rate: 0.00113911
	LOSS [training: 0.1022343261694555 | validation: 0.10876600905522198]
	TIME [epoch: 8.27 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09715525658743548		[learning rate: 0.0011315]
	Learning Rate: 0.0011315
	LOSS [training: 0.09715525658743548 | validation: 0.11315860339238676]
	TIME [epoch: 8.27 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08895659366878278		[learning rate: 0.0011239]
	Learning Rate: 0.0011239
	LOSS [training: 0.08895659366878278 | validation: 0.11891439706855575]
	TIME [epoch: 8.26 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09929385913964929		[learning rate: 0.0011163]
	Learning Rate: 0.00111633
	LOSS [training: 0.09929385913964929 | validation: 0.11170165744691331]
	TIME [epoch: 8.28 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09218328612305142		[learning rate: 0.0011088]
	Learning Rate: 0.00110879
	LOSS [training: 0.09218328612305142 | validation: 0.1133136586020443]
	TIME [epoch: 8.31 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10270428745381138		[learning rate: 0.0011013]
	Learning Rate: 0.00110127
	LOSS [training: 0.10270428745381138 | validation: 0.10702078031128504]
	TIME [epoch: 8.27 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1011373473304625		[learning rate: 0.0010938]
	Learning Rate: 0.00109377
	LOSS [training: 0.1011373473304625 | validation: 0.1232336545039924]
	TIME [epoch: 8.27 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10286947968549956		[learning rate: 0.0010863]
	Learning Rate: 0.0010863
	LOSS [training: 0.10286947968549956 | validation: 0.12014194343532729]
	TIME [epoch: 8.27 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0954793482565651		[learning rate: 0.0010788]
	Learning Rate: 0.00107885
	LOSS [training: 0.0954793482565651 | validation: 0.11206979173304232]
	TIME [epoch: 8.27 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10236830818578019		[learning rate: 0.0010714]
	Learning Rate: 0.00107143
	LOSS [training: 0.10236830818578019 | validation: 0.13614649676727286]
	TIME [epoch: 8.3 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10142032514387539		[learning rate: 0.001064]
	Learning Rate: 0.00106403
	LOSS [training: 0.10142032514387539 | validation: 0.10536666781373316]
	TIME [epoch: 8.28 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08526550637772362		[learning rate: 0.0010567]
	Learning Rate: 0.00105665
	LOSS [training: 0.08526550637772362 | validation: 0.12498403303175348]
	TIME [epoch: 8.27 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09794885047914646		[learning rate: 0.0010493]
	Learning Rate: 0.0010493
	LOSS [training: 0.09794885047914646 | validation: 0.1265920629335529]
	TIME [epoch: 8.28 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09643967488476372		[learning rate: 0.001042]
	Learning Rate: 0.00104198
	LOSS [training: 0.09643967488476372 | validation: 0.1301380704421608]
	TIME [epoch: 8.27 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10935186312653666		[learning rate: 0.0010347]
	Learning Rate: 0.00103467
	LOSS [training: 0.10935186312653666 | validation: 0.14145717801095178]
	TIME [epoch: 8.28 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09981812528094339		[learning rate: 0.0010274]
	Learning Rate: 0.0010274
	LOSS [training: 0.09981812528094339 | validation: 0.14063881084072202]
	TIME [epoch: 8.32 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0985512808349621		[learning rate: 0.0010201]
	Learning Rate: 0.00102015
	LOSS [training: 0.0985512808349621 | validation: 0.1171010047831455]
	TIME [epoch: 8.28 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09601959996799171		[learning rate: 0.0010129]
	Learning Rate: 0.00101292
	LOSS [training: 0.09601959996799171 | validation: 0.10941583918361508]
	TIME [epoch: 8.27 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1058847247681535		[learning rate: 0.0010057]
	Learning Rate: 0.00100571
	LOSS [training: 0.1058847247681535 | validation: 0.12314202004898367]
	TIME [epoch: 8.27 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09424196294806003		[learning rate: 0.00099854]
	Learning Rate: 0.000998536
	LOSS [training: 0.09424196294806003 | validation: 0.12660705193380425]
	TIME [epoch: 8.27 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09529526460045587		[learning rate: 0.00099138]
	Learning Rate: 0.000991382
	LOSS [training: 0.09529526460045587 | validation: 0.11664243748539535]
	TIME [epoch: 8.3 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11679780015130993		[learning rate: 0.00098425]
	Learning Rate: 0.000984253
	LOSS [training: 0.11679780015130993 | validation: 0.11315206829700697]
	TIME [epoch: 8.29 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10108604180069174		[learning rate: 0.00097715]
	Learning Rate: 0.000977149
	LOSS [training: 0.10108604180069174 | validation: 0.11141264629848632]
	TIME [epoch: 8.28 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09009321944815754		[learning rate: 0.00097007]
	Learning Rate: 0.000970069
	LOSS [training: 0.09009321944815754 | validation: 0.11015172464765396]
	TIME [epoch: 8.27 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08914922234363673		[learning rate: 0.00096301]
	Learning Rate: 0.000963014
	LOSS [training: 0.08914922234363673 | validation: 0.11386250834194468]
	TIME [epoch: 8.27 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09286062551515362		[learning rate: 0.00095598]
	Learning Rate: 0.000955983
	LOSS [training: 0.09286062551515362 | validation: 0.11172239112619484]
	TIME [epoch: 8.27 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10533928951333442		[learning rate: 0.00094898]
	Learning Rate: 0.000948977
	LOSS [training: 0.10533928951333442 | validation: 0.10901039406256423]
	TIME [epoch: 8.32 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10024324015339744		[learning rate: 0.000942]
	Learning Rate: 0.000941996
	LOSS [training: 0.10024324015339744 | validation: 0.11266383014973948]
	TIME [epoch: 8.27 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09528615687332422		[learning rate: 0.00093504]
	Learning Rate: 0.00093504
	LOSS [training: 0.09528615687332422 | validation: 0.106475688289994]
	TIME [epoch: 8.27 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09413552749216193		[learning rate: 0.00092811]
	Learning Rate: 0.000928109
	LOSS [training: 0.09413552749216193 | validation: 0.12887148360131617]
	TIME [epoch: 8.27 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10647188474310242		[learning rate: 0.0009212]
	Learning Rate: 0.000921202
	LOSS [training: 0.10647188474310242 | validation: 0.13076618160827586]
	TIME [epoch: 8.27 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09820163916367819		[learning rate: 0.00091432]
	Learning Rate: 0.000914321
	LOSS [training: 0.09820163916367819 | validation: 0.10889018520946239]
	TIME [epoch: 8.28 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10736641675094824		[learning rate: 0.00090746]
	Learning Rate: 0.000907464
	LOSS [training: 0.10736641675094824 | validation: 0.11091640118447933]
	TIME [epoch: 8.31 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09463062218657062		[learning rate: 0.00090063]
	Learning Rate: 0.000900632
	LOSS [training: 0.09463062218657062 | validation: 0.1139456091203058]
	TIME [epoch: 8.27 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09207854952674645		[learning rate: 0.00089382]
	Learning Rate: 0.000893825
	LOSS [training: 0.09207854952674645 | validation: 0.12163231655055208]
	TIME [epoch: 8.27 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10613310021895599		[learning rate: 0.00088704]
	Learning Rate: 0.000887043
	LOSS [training: 0.10613310021895599 | validation: 0.13327849001505815]
	TIME [epoch: 8.27 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10154419769000689		[learning rate: 0.00088029]
	Learning Rate: 0.000880285
	LOSS [training: 0.10154419769000689 | validation: 0.13520730930949082]
	TIME [epoch: 8.27 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10867508619333974		[learning rate: 0.00087355]
	Learning Rate: 0.000873553
	LOSS [training: 0.10867508619333974 | validation: 0.1147370510770195]
	TIME [epoch: 8.31 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1058680495463213		[learning rate: 0.00086685]
	Learning Rate: 0.000866846
	LOSS [training: 0.1058680495463213 | validation: 0.11258388061145966]
	TIME [epoch: 8.29 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09909292357016113		[learning rate: 0.00086016]
	Learning Rate: 0.000860163
	LOSS [training: 0.09909292357016113 | validation: 0.12535849404692498]
	TIME [epoch: 8.27 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10251362014280524		[learning rate: 0.00085351]
	Learning Rate: 0.000853506
	LOSS [training: 0.10251362014280524 | validation: 0.11109143850719241]
	TIME [epoch: 8.27 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10994383196791821		[learning rate: 0.00084687]
	Learning Rate: 0.000846874
	LOSS [training: 0.10994383196791821 | validation: 0.11567385177080067]
	TIME [epoch: 8.26 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10397260936195915		[learning rate: 0.00084027]
	Learning Rate: 0.000840266
	LOSS [training: 0.10397260936195915 | validation: 0.11792826646072546]
	TIME [epoch: 8.27 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10155122310975534		[learning rate: 0.00083368]
	Learning Rate: 0.000833684
	LOSS [training: 0.10155122310975534 | validation: 0.11957088046731232]
	TIME [epoch: 8.3 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10144402091130711		[learning rate: 0.00082713]
	Learning Rate: 0.000827127
	LOSS [training: 0.10144402091130711 | validation: 0.11119363959717324]
	TIME [epoch: 8.26 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10584026093822206		[learning rate: 0.00082059]
	Learning Rate: 0.000820595
	LOSS [training: 0.10584026093822206 | validation: 0.11459375614975473]
	TIME [epoch: 8.26 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08863625679211233		[learning rate: 0.00081409]
	Learning Rate: 0.000814088
	LOSS [training: 0.08863625679211233 | validation: 0.10603947709016978]
	TIME [epoch: 8.26 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09103082576297675		[learning rate: 0.00080761]
	Learning Rate: 0.000807606
	LOSS [training: 0.09103082576297675 | validation: 0.10135961057989795]
	TIME [epoch: 8.27 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09409889802129973		[learning rate: 0.00080115]
	Learning Rate: 0.000801149
	LOSS [training: 0.09409889802129973 | validation: 0.10590851999231743]
	TIME [epoch: 8.31 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08713686246982252		[learning rate: 0.00079472]
	Learning Rate: 0.000794718
	LOSS [training: 0.08713686246982252 | validation: 0.1106482660769037]
	TIME [epoch: 8.28 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08824307488324183		[learning rate: 0.00078831]
	Learning Rate: 0.000788312
	LOSS [training: 0.08824307488324183 | validation: 0.11123822486621264]
	TIME [epoch: 8.26 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09645640763601977		[learning rate: 0.00078193]
	Learning Rate: 0.00078193
	LOSS [training: 0.09645640763601977 | validation: 0.11137795624392685]
	TIME [epoch: 8.26 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09229538409309372		[learning rate: 0.00077557]
	Learning Rate: 0.000775574
	LOSS [training: 0.09229538409309372 | validation: 0.1067948812055296]
	TIME [epoch: 8.27 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1185061077106514		[learning rate: 0.00076924]
	Learning Rate: 0.000769244
	LOSS [training: 0.1185061077106514 | validation: 0.1160413559444523]
	TIME [epoch: 8.27 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09848467902615275		[learning rate: 0.00076294]
	Learning Rate: 0.000762938
	LOSS [training: 0.09848467902615275 | validation: 0.10282062892249398]
	TIME [epoch: 8.31 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08529713638284266		[learning rate: 0.00075666]
	Learning Rate: 0.000756658
	LOSS [training: 0.08529713638284266 | validation: 0.10047052144517225]
	TIME [epoch: 8.26 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09006789695903891		[learning rate: 0.0007504]
	Learning Rate: 0.000750403
	LOSS [training: 0.09006789695903891 | validation: 0.10793893508809047]
	TIME [epoch: 8.27 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09446154285881704		[learning rate: 0.00074417]
	Learning Rate: 0.000744174
	LOSS [training: 0.09446154285881704 | validation: 0.09731067510299193]
	TIME [epoch: 8.27 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0901816352980577		[learning rate: 0.00073797]
	Learning Rate: 0.000737969
	LOSS [training: 0.0901816352980577 | validation: 0.11755212788462199]
	TIME [epoch: 8.27 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09007334262529071		[learning rate: 0.00073179]
	Learning Rate: 0.00073179
	LOSS [training: 0.09007334262529071 | validation: 0.09809557778183618]
	TIME [epoch: 8.3 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09089485369896988		[learning rate: 0.00072564]
	Learning Rate: 0.000725637
	LOSS [training: 0.09089485369896988 | validation: 0.1123076083462046]
	TIME [epoch: 8.28 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08719497191286359		[learning rate: 0.00071951]
	Learning Rate: 0.000719509
	LOSS [training: 0.08719497191286359 | validation: 0.09053584794211698]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_1721.pth
	Model improved!!!
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08330773983410986		[learning rate: 0.00071341]
	Learning Rate: 0.000713406
	LOSS [training: 0.08330773983410986 | validation: 0.09928107649236884]
	TIME [epoch: 8.27 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0840436059579435		[learning rate: 0.00070733]
	Learning Rate: 0.000707328
	LOSS [training: 0.0840436059579435 | validation: 0.1191062124416449]
	TIME [epoch: 8.26 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08785832400365857		[learning rate: 0.00070128]
	Learning Rate: 0.000701276
	LOSS [training: 0.08785832400365857 | validation: 0.1008606410371671]
	TIME [epoch: 8.26 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0877867108619222		[learning rate: 0.00069525]
	Learning Rate: 0.00069525
	LOSS [training: 0.0877867108619222 | validation: 0.09846316345110892]
	TIME [epoch: 8.31 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08935098545911069		[learning rate: 0.00068925]
	Learning Rate: 0.000689249
	LOSS [training: 0.08935098545911069 | validation: 0.09279687284278015]
	TIME [epoch: 8.27 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0953437070752103		[learning rate: 0.00068327]
	Learning Rate: 0.000683273
	LOSS [training: 0.0953437070752103 | validation: 0.10403988274369792]
	TIME [epoch: 8.27 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08586479440633128		[learning rate: 0.00067732]
	Learning Rate: 0.000677323
	LOSS [training: 0.08586479440633128 | validation: 0.09282028475460202]
	TIME [epoch: 8.26 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09100369208657888		[learning rate: 0.0006714]
	Learning Rate: 0.000671398
	LOSS [training: 0.09100369208657888 | validation: 0.11088806457685546]
	TIME [epoch: 8.26 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08617889479514909		[learning rate: 0.0006655]
	Learning Rate: 0.000665499
	LOSS [training: 0.08617889479514909 | validation: 0.10060799240081858]
	TIME [epoch: 8.28 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08375996628426227		[learning rate: 0.00065963]
	Learning Rate: 0.000659625
	LOSS [training: 0.08375996628426227 | validation: 0.1024466805802914]
	TIME [epoch: 8.29 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09296734563027376		[learning rate: 0.00065378]
	Learning Rate: 0.000653777
	LOSS [training: 0.09296734563027376 | validation: 0.0952303779289678]
	TIME [epoch: 8.26 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09346172677645337		[learning rate: 0.00064795]
	Learning Rate: 0.000647955
	LOSS [training: 0.09346172677645337 | validation: 0.10043378531531671]
	TIME [epoch: 8.27 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09082344317127292		[learning rate: 0.00064216]
	Learning Rate: 0.000642158
	LOSS [training: 0.09082344317127292 | validation: 0.10547523612816079]
	TIME [epoch: 8.26 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.095952099904047		[learning rate: 0.00063639]
	Learning Rate: 0.000636387
	LOSS [training: 0.095952099904047 | validation: 0.12358148513379788]
	TIME [epoch: 8.26 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09675533499837147		[learning rate: 0.00063064]
	Learning Rate: 0.000630641
	LOSS [training: 0.09675533499837147 | validation: 0.10352088373029211]
	TIME [epoch: 8.3 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08558957093356852		[learning rate: 0.00062492]
	Learning Rate: 0.000624921
	LOSS [training: 0.08558957093356852 | validation: 0.09896190989128902]
	TIME [epoch: 8.28 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08936065404939424		[learning rate: 0.00061923]
	Learning Rate: 0.000619226
	LOSS [training: 0.08936065404939424 | validation: 0.10589431011371739]
	TIME [epoch: 8.26 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08218319258867095		[learning rate: 0.00061356]
	Learning Rate: 0.000613558
	LOSS [training: 0.08218319258867095 | validation: 0.10022573511367541]
	TIME [epoch: 8.26 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08898895803833073		[learning rate: 0.00060791]
	Learning Rate: 0.000607914
	LOSS [training: 0.08898895803833073 | validation: 0.08906404857205744]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_1740.pth
	Model improved!!!
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08445158852039968		[learning rate: 0.0006023]
	Learning Rate: 0.000602297
	LOSS [training: 0.08445158852039968 | validation: 0.10264948968646058]
	TIME [epoch: 8.28 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09195872958869512		[learning rate: 0.00059671]
	Learning Rate: 0.000596705
	LOSS [training: 0.09195872958869512 | validation: 0.10550696718046068]
	TIME [epoch: 8.3 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08618795450223753		[learning rate: 0.00059114]
	Learning Rate: 0.000591139
	LOSS [training: 0.08618795450223753 | validation: 0.10563561003701225]
	TIME [epoch: 8.27 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08695562379644063		[learning rate: 0.0005856]
	Learning Rate: 0.000585599
	LOSS [training: 0.08695562379644063 | validation: 0.09760384307335782]
	TIME [epoch: 8.26 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08135992153141772		[learning rate: 0.00058008]
	Learning Rate: 0.000580085
	LOSS [training: 0.08135992153141772 | validation: 0.1050803395953269]
	TIME [epoch: 8.27 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08938739883628088		[learning rate: 0.0005746]
	Learning Rate: 0.000574596
	LOSS [training: 0.08938739883628088 | validation: 0.11218115801035426]
	TIME [epoch: 8.26 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08867445036098165		[learning rate: 0.00056913]
	Learning Rate: 0.000569133
	LOSS [training: 0.08867445036098165 | validation: 0.09861940971451655]
	TIME [epoch: 8.3 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09045833764435476		[learning rate: 0.0005637]
	Learning Rate: 0.000563696
	LOSS [training: 0.09045833764435476 | validation: 0.1055178278323857]
	TIME [epoch: 8.26 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08632285572114246		[learning rate: 0.00055828]
	Learning Rate: 0.000558285
	LOSS [training: 0.08632285572114246 | validation: 0.09124440824720517]
	TIME [epoch: 8.26 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08562956269832875		[learning rate: 0.0005529]
	Learning Rate: 0.000552899
	LOSS [training: 0.08562956269832875 | validation: 0.10922678022691995]
	TIME [epoch: 8.26 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08865579487166986		[learning rate: 0.00054754]
	Learning Rate: 0.000547539
	LOSS [training: 0.08865579487166986 | validation: 0.09683285016578755]
	TIME [epoch: 8.26 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08590130804744281		[learning rate: 0.00054221]
	Learning Rate: 0.000542206
	LOSS [training: 0.08590130804744281 | validation: 0.10990603793503345]
	TIME [epoch: 8.26 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08756653205813733		[learning rate: 0.0005369]
	Learning Rate: 0.000536898
	LOSS [training: 0.08756653205813733 | validation: 0.10271288404801927]
	TIME [epoch: 8.3 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08713510751840689		[learning rate: 0.00053162]
	Learning Rate: 0.000531616
	LOSS [training: 0.08713510751840689 | validation: 0.10305096595502518]
	TIME [epoch: 8.27 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08233643837932167		[learning rate: 0.00052636]
	Learning Rate: 0.000526359
	LOSS [training: 0.08233643837932167 | validation: 0.09389497166940154]
	TIME [epoch: 8.26 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08531941323626938		[learning rate: 0.00052113]
	Learning Rate: 0.000521129
	LOSS [training: 0.08531941323626938 | validation: 0.09169247082779458]
	TIME [epoch: 8.26 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09282986680312114		[learning rate: 0.00051592]
	Learning Rate: 0.000515925
	LOSS [training: 0.09282986680312114 | validation: 0.09374410774024791]
	TIME [epoch: 8.26 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08669182937189918		[learning rate: 0.00051075]
	Learning Rate: 0.000510746
	LOSS [training: 0.08669182937189918 | validation: 0.09728763141862015]
	TIME [epoch: 8.29 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08941943223669982		[learning rate: 0.00050559]
	Learning Rate: 0.000505594
	LOSS [training: 0.08941943223669982 | validation: 0.10721568289627259]
	TIME [epoch: 8.28 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.089343281766886		[learning rate: 0.00050047]
	Learning Rate: 0.000500468
	LOSS [training: 0.089343281766886 | validation: 0.10187065089478856]
	TIME [epoch: 8.27 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09203794471405291		[learning rate: 0.00049537]
	Learning Rate: 0.000495367
	LOSS [training: 0.09203794471405291 | validation: 0.09550609867142948]
	TIME [epoch: 8.26 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08838742094360792		[learning rate: 0.00049029]
	Learning Rate: 0.000490293
	LOSS [training: 0.08838742094360792 | validation: 0.10337066794272377]
	TIME [epoch: 8.26 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08803171995555459		[learning rate: 0.00048524]
	Learning Rate: 0.000485244
	LOSS [training: 0.08803171995555459 | validation: 0.08347499735657833]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_kl5_20240702_111815/states/model_phi1_1a_v_kl5_1763.pth
	Model improved!!!
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07936939239241517		[learning rate: 0.00048022]
	Learning Rate: 0.000480222
	LOSS [training: 0.07936939239241517 | validation: 0.10456535503644782]
	TIME [epoch: 8.32 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08340750551788595		[learning rate: 0.00047523]
	Learning Rate: 0.000475226
	LOSS [training: 0.08340750551788595 | validation: 0.11735021235921479]
	TIME [epoch: 8.27 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08251848763411107		[learning rate: 0.00047026]
	Learning Rate: 0.000470255
	LOSS [training: 0.08251848763411107 | validation: 0.0991253411747792]
	TIME [epoch: 8.27 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08234011616469727		[learning rate: 0.00046531]
	Learning Rate: 0.000465311
	LOSS [training: 0.08234011616469727 | validation: 0.10779789975871086]
	TIME [epoch: 8.26 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08564341502390163		[learning rate: 0.00046039]
	Learning Rate: 0.000460393
	LOSS [training: 0.08564341502390163 | validation: 0.09191389694957189]
	TIME [epoch: 8.26 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08264332892989151		[learning rate: 0.0004555]
	Learning Rate: 0.000455501
	LOSS [training: 0.08264332892989151 | validation: 0.08796419682219374]
	TIME [epoch: 8.3 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0896958600816537		[learning rate: 0.00045063]
	Learning Rate: 0.000450635
	LOSS [training: 0.0896958600816537 | validation: 0.10128132453374213]
	TIME [epoch: 8.28 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08338604060918674		[learning rate: 0.00044579]
	Learning Rate: 0.000445795
	LOSS [training: 0.08338604060918674 | validation: 0.11212639950494298]
	TIME [epoch: 8.26 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08442941512418368		[learning rate: 0.00044098]
	Learning Rate: 0.000440981
	LOSS [training: 0.08442941512418368 | validation: 0.10962186061974416]
	TIME [epoch: 8.26 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08229249278968544		[learning rate: 0.00043619]
	Learning Rate: 0.000436194
	LOSS [training: 0.08229249278968544 | validation: 0.09606482379019698]
	TIME [epoch: 8.25 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08888542445957404		[learning rate: 0.00043143]
	Learning Rate: 0.000431432
	LOSS [training: 0.08888542445957404 | validation: 0.09586097014068289]
	TIME [epoch: 8.26 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08266809769683736		[learning rate: 0.0004267]
	Learning Rate: 0.000426697
	LOSS [training: 0.08266809769683736 | validation: 0.09734707212864593]
	TIME [epoch: 8.31 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08362221555546176		[learning rate: 0.00042199]
	Learning Rate: 0.000421988
	LOSS [training: 0.08362221555546176 | validation: 0.09158646331882792]
	TIME [epoch: 8.26 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08296588481741077		[learning rate: 0.00041731]
	Learning Rate: 0.000417305
	LOSS [training: 0.08296588481741077 | validation: 0.10237890545128756]
	TIME [epoch: 8.25 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08106873334910365		[learning rate: 0.00041265]
	Learning Rate: 0.000412649
	LOSS [training: 0.08106873334910365 | validation: 0.09799004718192281]
	TIME [epoch: 8.26 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0817330360799479		[learning rate: 0.00040802]
	Learning Rate: 0.000408018
	LOSS [training: 0.0817330360799479 | validation: 0.10356907032469287]
	TIME [epoch: 8.25 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08502114681500113		[learning rate: 0.00040341]
	Learning Rate: 0.000403414
	LOSS [training: 0.08502114681500113 | validation: 0.10701025008789615]
	TIME [epoch: 8.28 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08902935163584041		[learning rate: 0.00039884]
	Learning Rate: 0.000398836
	LOSS [training: 0.08902935163584041 | validation: 0.10818001476354994]
	TIME [epoch: 8.3 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08341799826989515		[learning rate: 0.00039428]
	Learning Rate: 0.000394284
	LOSS [training: 0.08341799826989515 | validation: 0.09727196962032203]
	TIME [epoch: 8.26 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08033944043811282		[learning rate: 0.00038976]
	Learning Rate: 0.000389759
	LOSS [training: 0.08033944043811282 | validation: 0.08359219256413454]
	TIME [epoch: 8.26 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08683946890127259		[learning rate: 0.00038526]
	Learning Rate: 0.00038526
	LOSS [training: 0.08683946890127259 | validation: 0.10554547024393528]
	TIME [epoch: 8.26 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08438221538979844		[learning rate: 0.00038079]
	Learning Rate: 0.000380787
	LOSS [training: 0.08438221538979844 | validation: 0.09868661650102373]
	TIME [epoch: 8.26 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08905895641791128		[learning rate: 0.00037634]
	Learning Rate: 0.000376341
	LOSS [training: 0.08905895641791128 | validation: 0.08767664379310175]
	TIME [epoch: 8.31 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08503528391419432		[learning rate: 0.00037192]
	Learning Rate: 0.00037192
	LOSS [training: 0.08503528391419432 | validation: 0.09941468913721335]
	TIME [epoch: 8.27 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08446083491032907		[learning rate: 0.00036753]
	Learning Rate: 0.000367527
	LOSS [training: 0.08446083491032907 | validation: 0.10010090437960129]
	TIME [epoch: 8.26 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08388462297647913		[learning rate: 0.00036316]
	Learning Rate: 0.000363159
	LOSS [training: 0.08388462297647913 | validation: 0.09931449977662918]
	TIME [epoch: 8.26 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0862537417323859		[learning rate: 0.00035882]
	Learning Rate: 0.000358818
	LOSS [training: 0.0862537417323859 | validation: 0.1107724616869947]
	TIME [epoch: 8.27 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08385016736042968		[learning rate: 0.0003545]
	Learning Rate: 0.000354503
	LOSS [training: 0.08385016736042968 | validation: 0.10760791691176076]
	TIME [epoch: 8.26 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08896385211006504		[learning rate: 0.00035022]
	Learning Rate: 0.000350215
	LOSS [training: 0.08896385211006504 | validation: 0.10425021827458575]
	TIME [epoch: 8.31 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08371768061144552		[learning rate: 0.00034595]
	Learning Rate: 0.000345953
	LOSS [training: 0.08371768061144552 | validation: 0.1018263403439369]
	TIME [epoch: 8.26 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08608872515409409		[learning rate: 0.00034172]
	Learning Rate: 0.000341718
	LOSS [training: 0.08608872515409409 | validation: 0.10181562566985822]
	TIME [epoch: 8.26 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08603481349854708		[learning rate: 0.00033751]
	Learning Rate: 0.000337508
	LOSS [training: 0.08603481349854708 | validation: 0.10696885320469149]
	TIME [epoch: 8.26 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08460487697731343		[learning rate: 0.00033333]
	Learning Rate: 0.000333326
	LOSS [training: 0.08460487697731343 | validation: 0.10094850538401688]
	TIME [epoch: 8.27 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0892501132117535		[learning rate: 0.00032917]
	Learning Rate: 0.000329169
	LOSS [training: 0.0892501132117535 | validation: 0.11689665027992575]
	TIME [epoch: 8.29 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08898810125689188		[learning rate: 0.00032504]
	Learning Rate: 0.00032504
	LOSS [training: 0.08898810125689188 | validation: 0.08876806675183768]
	TIME [epoch: 8.29 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0870435081374739		[learning rate: 0.00032094]
	Learning Rate: 0.000320936
	LOSS [training: 0.0870435081374739 | validation: 0.09849159515207544]
	TIME [epoch: 8.26 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08363407934702383		[learning rate: 0.00031686]
	Learning Rate: 0.000316859
	LOSS [training: 0.08363407934702383 | validation: 0.0994530360988012]
	TIME [epoch: 8.26 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08066627921021709		[learning rate: 0.00031281]
	Learning Rate: 0.000312809
	LOSS [training: 0.08066627921021709 | validation: 0.09766873581059912]
	TIME [epoch: 8.27 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08442263426060516		[learning rate: 0.00030879]
	Learning Rate: 0.000308785
	LOSS [training: 0.08442263426060516 | validation: 0.09569958765624328]
	TIME [epoch: 8.27 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08490086294200319		[learning rate: 0.00030479]
	Learning Rate: 0.000304788
	LOSS [training: 0.08490086294200319 | validation: 0.10122044656708408]
	TIME [epoch: 8.31 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08329138780339174		[learning rate: 0.00030082]
	Learning Rate: 0.000300817
	LOSS [training: 0.08329138780339174 | validation: 0.10386768332537905]
	TIME [epoch: 8.27 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08145977482904132		[learning rate: 0.00029687]
	Learning Rate: 0.000296873
	LOSS [training: 0.08145977482904132 | validation: 0.09875318251229323]
	TIME [epoch: 8.26 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0830672819993324		[learning rate: 0.00029295]
	Learning Rate: 0.000292955
	LOSS [training: 0.0830672819993324 | validation: 0.0983124824568762]
	TIME [epoch: 8.26 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08427363039550552		[learning rate: 0.00028906]
	Learning Rate: 0.000289064
	LOSS [training: 0.08427363039550552 | validation: 0.1162790044983065]
	TIME [epoch: 8.26 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08791911336698045		[learning rate: 0.0002852]
	Learning Rate: 0.000285199
	LOSS [training: 0.08791911336698045 | validation: 0.11028994867623437]
	TIME [epoch: 8.29 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0939860332813259		[learning rate: 0.00028136]
	Learning Rate: 0.000281361
	LOSS [training: 0.0939860332813259 | validation: 0.09704069407082741]
	TIME [epoch: 8.28 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08605457580656564		[learning rate: 0.00027755]
	Learning Rate: 0.000277549
	LOSS [training: 0.08605457580656564 | validation: 0.0962648743941131]
	TIME [epoch: 8.27 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08716546726157078		[learning rate: 0.00027376]
	Learning Rate: 0.000273764
	LOSS [training: 0.08716546726157078 | validation: 0.10334351032349054]
	TIME [epoch: 8.27 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08774846567502538		[learning rate: 0.00027001]
	Learning Rate: 0.000270006
	LOSS [training: 0.08774846567502538 | validation: 0.10139092020170407]
	TIME [epoch: 8.26 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08685832892891573		[learning rate: 0.00026627]
	Learning Rate: 0.000266274
	LOSS [training: 0.08685832892891573 | validation: 0.11391558206941713]
	TIME [epoch: 8.26 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08475922755971638		[learning rate: 0.00026257]
	Learning Rate: 0.000262569
	LOSS [training: 0.08475922755971638 | validation: 0.09891174357150676]
	TIME [epoch: 8.31 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08730815771910302		[learning rate: 0.00025889]
	Learning Rate: 0.000258891
	LOSS [training: 0.08730815771910302 | validation: 0.11286569593986112]
	TIME [epoch: 8.27 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0850140676730205		[learning rate: 0.00025524]
	Learning Rate: 0.000255239
	LOSS [training: 0.0850140676730205 | validation: 0.11200307015973003]
	TIME [epoch: 8.26 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08961765610110607		[learning rate: 0.00025161]
	Learning Rate: 0.000251614
	LOSS [training: 0.08961765610110607 | validation: 0.09983660090523472]
	TIME [epoch: 8.27 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08999623663894228		[learning rate: 0.00024802]
	Learning Rate: 0.000248016
	LOSS [training: 0.08999623663894228 | validation: 0.10833888316455462]
	TIME [epoch: 8.26 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08512120046183146		[learning rate: 0.00024444]
	Learning Rate: 0.000244444
	LOSS [training: 0.08512120046183146 | validation: 0.0938681588233572]
	TIME [epoch: 8.28 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08862424515696679		[learning rate: 0.0002409]
	Learning Rate: 0.000240899
	LOSS [training: 0.08862424515696679 | validation: 0.11167930126099365]
	TIME [epoch: 8.31 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09203451033196595		[learning rate: 0.00023738]
	Learning Rate: 0.00023738
	LOSS [training: 0.09203451033196595 | validation: 0.10784378729550435]
	TIME [epoch: 8.27 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0853366439569391		[learning rate: 0.00023389]
	Learning Rate: 0.000233889
	LOSS [training: 0.0853366439569391 | validation: 0.09604780400018925]
	TIME [epoch: 8.27 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08386466656993131		[learning rate: 0.00023042]
	Learning Rate: 0.000230424
	LOSS [training: 0.08386466656993131 | validation: 0.10094458430932937]
	TIME [epoch: 8.27 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08605743258058379		[learning rate: 0.00022699]
	Learning Rate: 0.000226985
	LOSS [training: 0.08605743258058379 | validation: 0.0981902897025547]
	TIME [epoch: 8.27 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08175974642011265		[learning rate: 0.00022357]
	Learning Rate: 0.000223574
	LOSS [training: 0.08175974642011265 | validation: 0.11238258707412374]
	TIME [epoch: 8.31 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08203399305609467		[learning rate: 0.00022019]
	Learning Rate: 0.000220189
	LOSS [training: 0.08203399305609467 | validation: 0.09789468375099707]
	TIME [epoch: 8.28 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08159773799089408		[learning rate: 0.00021683]
	Learning Rate: 0.000216831
	LOSS [training: 0.08159773799089408 | validation: 0.09655262546919588]
	TIME [epoch: 8.27 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07970340691645635		[learning rate: 0.0002135]
	Learning Rate: 0.0002135
	LOSS [training: 0.07970340691645635 | validation: 0.10593833632329905]
	TIME [epoch: 8.28 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08608982872044756		[learning rate: 0.0002102]
	Learning Rate: 0.000210195
	LOSS [training: 0.08608982872044756 | validation: 0.10299704647809443]
	TIME [epoch: 8.27 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08539845580402916		[learning rate: 0.00020692]
	Learning Rate: 0.000206917
	LOSS [training: 0.08539845580402916 | validation: 0.10969649195815181]
	TIME [epoch: 8.28 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08102387743898326		[learning rate: 0.00020367]
	Learning Rate: 0.000203667
	LOSS [training: 0.08102387743898326 | validation: 0.10192836166348884]
	TIME [epoch: 8.32 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08425737950074767		[learning rate: 0.00020044]
	Learning Rate: 0.000200442
	LOSS [training: 0.08425737950074767 | validation: 0.09763135475828011]
	TIME [epoch: 8.27 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08897308168418344		[learning rate: 0.00019725]
	Learning Rate: 0.000197245
	LOSS [training: 0.08897308168418344 | validation: 0.1030095508393149]
	TIME [epoch: 8.27 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09021369790711502		[learning rate: 0.00019407]
	Learning Rate: 0.000194075
	LOSS [training: 0.09021369790711502 | validation: 0.1040960787412815]
	TIME [epoch: 8.27 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0856854111824538		[learning rate: 0.00019093]
	Learning Rate: 0.000190931
	LOSS [training: 0.0856854111824538 | validation: 0.0932382458636718]
	TIME [epoch: 8.28 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0845975343517801		[learning rate: 0.00018781]
	Learning Rate: 0.000187814
	LOSS [training: 0.0845975343517801 | validation: 0.08702154190675906]
	TIME [epoch: 8.31 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08705754949986506		[learning rate: 0.00018472]
	Learning Rate: 0.000184724
	LOSS [training: 0.08705754949986506 | validation: 0.1076874181305234]
	TIME [epoch: 8.29 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08660368641715753		[learning rate: 0.00018166]
	Learning Rate: 0.000181661
	LOSS [training: 0.08660368641715753 | validation: 0.09300476466588903]
	TIME [epoch: 8.28 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0861813197499471		[learning rate: 0.00017862]
	Learning Rate: 0.000178624
	LOSS [training: 0.0861813197499471 | validation: 0.10576444287806432]
	TIME [epoch: 8.28 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08298366242683426		[learning rate: 0.00017561]
	Learning Rate: 0.000175615
	LOSS [training: 0.08298366242683426 | validation: 0.1000093833651253]
	TIME [epoch: 8.28 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08367965116641593		[learning rate: 0.00017263]
	Learning Rate: 0.000172632
	LOSS [training: 0.08367965116641593 | validation: 0.09854890201107087]
	TIME [epoch: 8.28 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08136651374713856		[learning rate: 0.00016968]
	Learning Rate: 0.000169677
	LOSS [training: 0.08136651374713856 | validation: 0.10342780685988207]
	TIME [epoch: 8.32 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08457551522472562		[learning rate: 0.00016675]
	Learning Rate: 0.000166748
	LOSS [training: 0.08457551522472562 | validation: 0.10175429108509247]
	TIME [epoch: 8.28 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08004184553317789		[learning rate: 0.00016385]
	Learning Rate: 0.000163846
	LOSS [training: 0.08004184553317789 | validation: 0.10256685335539166]
	TIME [epoch: 8.28 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08101408047237532		[learning rate: 0.00016097]
	Learning Rate: 0.000160971
	LOSS [training: 0.08101408047237532 | validation: 0.09815443864021081]
	TIME [epoch: 8.28 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0841897151446527		[learning rate: 0.00015812]
	Learning Rate: 0.000158123
	LOSS [training: 0.0841897151446527 | validation: 0.09338735821474181]
	TIME [epoch: 8.28 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08513384610756612		[learning rate: 0.0001553]
	Learning Rate: 0.000155302
	LOSS [training: 0.08513384610756612 | validation: 0.09630302305473047]
	TIME [epoch: 8.3 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08302699608944793		[learning rate: 0.00015251]
	Learning Rate: 0.000152507
	LOSS [training: 0.08302699608944793 | validation: 0.09812821054581009]
	TIME [epoch: 8.31 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08444861486365567		[learning rate: 0.00014974]
	Learning Rate: 0.00014974
	LOSS [training: 0.08444861486365567 | validation: 0.09784761812566244]
	TIME [epoch: 8.28 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08004498902162566		[learning rate: 0.000147]
	Learning Rate: 0.000147
	LOSS [training: 0.08004498902162566 | validation: 0.1134152228056615]
	TIME [epoch: 8.28 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08153218566984594		[learning rate: 0.00014429]
	Learning Rate: 0.000144286
	LOSS [training: 0.08153218566984594 | validation: 0.10723985912894751]
	TIME [epoch: 8.28 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0827262314367189		[learning rate: 0.0001416]
	Learning Rate: 0.0001416
	LOSS [training: 0.0827262314367189 | validation: 0.09726202589977698]
	TIME [epoch: 8.28 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08737337585887553		[learning rate: 0.00013894]
	Learning Rate: 0.00013894
	LOSS [training: 0.08737337585887553 | validation: 0.09306918287780808]
	TIME [epoch: 8.32 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08301739109127299		[learning rate: 0.00013631]
	Learning Rate: 0.000136308
	LOSS [training: 0.08301739109127299 | validation: 0.09818954727832402]
	TIME [epoch: 8.28 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08469854963557046		[learning rate: 0.0001337]
	Learning Rate: 0.000133702
	LOSS [training: 0.08469854963557046 | validation: 0.11151275820596096]
	TIME [epoch: 8.27 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0846312553354009		[learning rate: 0.00013112]
	Learning Rate: 0.000131124
	LOSS [training: 0.0846312553354009 | validation: 0.10094889022201754]
	TIME [epoch: 8.28 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08632979181979794		[learning rate: 0.00012857]
	Learning Rate: 0.000128572
	LOSS [training: 0.08632979181979794 | validation: 0.09207252820256717]
	TIME [epoch: 8.28 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08054882922320244		[learning rate: 0.00012605]
	Learning Rate: 0.000126048
	LOSS [training: 0.08054882922320244 | validation: 0.10220396271343064]
	TIME [epoch: 8.29 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08652813423369503		[learning rate: 0.00012355]
	Learning Rate: 0.00012355
	LOSS [training: 0.08652813423369503 | validation: 0.09747136246359484]
	TIME [epoch: 8.31 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08657628474579357		[learning rate: 0.00012108]
	Learning Rate: 0.000121079
	LOSS [training: 0.08657628474579357 | validation: 0.10992961441752902]
	TIME [epoch: 8.28 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08378190735804192		[learning rate: 0.00011864]
	Learning Rate: 0.000118636
	LOSS [training: 0.08378190735804192 | validation: 0.09750114063856252]
	TIME [epoch: 8.28 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08560284509276653		[learning rate: 0.00011622]
	Learning Rate: 0.000116219
	LOSS [training: 0.08560284509276653 | validation: 0.11098477135321966]
	TIME [epoch: 8.28 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08350280038403404		[learning rate: 0.00011383]
	Learning Rate: 0.00011383
	LOSS [training: 0.08350280038403404 | validation: 0.1060068427498891]
	TIME [epoch: 8.27 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08243839215475281		[learning rate: 0.00011147]
	Learning Rate: 0.000111468
	LOSS [training: 0.08243839215475281 | validation: 0.09688776881437441]
	TIME [epoch: 8.3 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08236634407839745		[learning rate: 0.00010913]
	Learning Rate: 0.000109132
	LOSS [training: 0.08236634407839745 | validation: 0.0960652529766156]
	TIME [epoch: 8.3 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08099943413291058		[learning rate: 0.00010682]
	Learning Rate: 0.000106824
	LOSS [training: 0.08099943413291058 | validation: 0.10234032460532932]
	TIME [epoch: 8.28 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08358740175043164		[learning rate: 0.00010454]
	Learning Rate: 0.000104543
	LOSS [training: 0.08358740175043164 | validation: 0.09264917811478551]
	TIME [epoch: 8.27 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08086266256312521		[learning rate: 0.00010229]
	Learning Rate: 0.000102289
	LOSS [training: 0.08086266256312521 | validation: 0.09999880771171434]
	TIME [epoch: 8.28 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08377151735845334		[learning rate: 0.00010006]
	Learning Rate: 0.000100061
	LOSS [training: 0.08377151735845334 | validation: 0.09338187239897136]
	TIME [epoch: 8.28 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0829178681922111		[learning rate: 9.7861e-05]
	Learning Rate: 9.78614e-05
	LOSS [training: 0.0829178681922111 | validation: 0.08912581792023774]
	TIME [epoch: 8.33 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07602590706994479		[learning rate: 9.5688e-05]
	Learning Rate: 9.56885e-05
	LOSS [training: 0.07602590706994479 | validation: 0.08746994015807306]
	TIME [epoch: 8.28 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08365863259596815		[learning rate: 9.3543e-05]
	Learning Rate: 9.35426e-05
	LOSS [training: 0.08365863259596815 | validation: 0.09078293635531506]
	TIME [epoch: 8.28 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0829349805039804		[learning rate: 9.1424e-05]
	Learning Rate: 9.14239e-05
	LOSS [training: 0.0829349805039804 | validation: 0.09332351801209612]
	TIME [epoch: 8.28 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08712677876481065		[learning rate: 8.9332e-05]
	Learning Rate: 8.93322e-05
	LOSS [training: 0.08712677876481065 | validation: 0.09977498291053064]
	TIME [epoch: 8.28 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0803138475611397		[learning rate: 8.7268e-05]
	Learning Rate: 8.72677e-05
	LOSS [training: 0.0803138475611397 | validation: 0.09691267661227927]
	TIME [epoch: 8.3 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08535456513852058		[learning rate: 8.523e-05]
	Learning Rate: 8.52303e-05
	LOSS [training: 0.08535456513852058 | validation: 0.10190268712034845]
	TIME [epoch: 8.3 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07807605385809141		[learning rate: 8.322e-05]
	Learning Rate: 8.322e-05
	LOSS [training: 0.07807605385809141 | validation: 0.09467664153565936]
	TIME [epoch: 8.28 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08028989112561288		[learning rate: 8.1237e-05]
	Learning Rate: 8.12368e-05
	LOSS [training: 0.08028989112561288 | validation: 0.10598567629842637]
	TIME [epoch: 8.28 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08375014225913661		[learning rate: 7.9281e-05]
	Learning Rate: 7.92808e-05
	LOSS [training: 0.08375014225913661 | validation: 0.09885704118660815]
	TIME [epoch: 8.28 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08351802157868729		[learning rate: 7.7352e-05]
	Learning Rate: 7.73519e-05
	LOSS [training: 0.08351802157868729 | validation: 0.09637739148107946]
	TIME [epoch: 8.27 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08308440685617219		[learning rate: 7.545e-05]
	Learning Rate: 7.54501e-05
	LOSS [training: 0.08308440685617219 | validation: 0.09812690658566559]
	TIME [epoch: 8.32 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07922895588242451		[learning rate: 7.3575e-05]
	Learning Rate: 7.35755e-05
	LOSS [training: 0.07922895588242451 | validation: 0.09561536391023037]
	TIME [epoch: 8.28 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07797949619117601		[learning rate: 7.1728e-05]
	Learning Rate: 7.1728e-05
	LOSS [training: 0.07797949619117601 | validation: 0.1081818919628807]
	TIME [epoch: 8.27 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07989660290152034		[learning rate: 6.9908e-05]
	Learning Rate: 6.99077e-05
	LOSS [training: 0.07989660290152034 | validation: 0.10467361848150913]
	TIME [epoch: 8.28 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08360653031147418		[learning rate: 6.8115e-05]
	Learning Rate: 6.81146e-05
	LOSS [training: 0.08360653031147418 | validation: 0.10448869270889014]
	TIME [epoch: 8.28 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0784349190927804		[learning rate: 6.6349e-05]
	Learning Rate: 6.63486e-05
	LOSS [training: 0.0784349190927804 | validation: 0.10223851956720292]
	TIME [epoch: 8.28 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07963850005986396		[learning rate: 6.461e-05]
	Learning Rate: 6.46098e-05
	LOSS [training: 0.07963850005986396 | validation: 0.11255935115072872]
	TIME [epoch: 8.31 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07485480988035678		[learning rate: 6.2898e-05]
	Learning Rate: 6.28982e-05
	LOSS [training: 0.07485480988035678 | validation: 0.09271259430497567]
	TIME [epoch: 8.28 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07887406666378008		[learning rate: 6.1214e-05]
	Learning Rate: 6.12137e-05
	LOSS [training: 0.07887406666378008 | validation: 0.09783530751203662]
	TIME [epoch: 8.28 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08145358886302953		[learning rate: 5.9556e-05]
	Learning Rate: 5.95565e-05
	LOSS [training: 0.08145358886302953 | validation: 0.09788088629189859]
	TIME [epoch: 8.28 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08595850653457056		[learning rate: 5.7926e-05]
	Learning Rate: 5.79264e-05
	LOSS [training: 0.08595850653457056 | validation: 0.08910050515609079]
	TIME [epoch: 8.28 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08255882639643763		[learning rate: 5.6324e-05]
	Learning Rate: 5.63235e-05
	LOSS [training: 0.08255882639643763 | validation: 0.0934226575998007]
	TIME [epoch: 8.31 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08122956953690547		[learning rate: 5.4748e-05]
	Learning Rate: 5.47478e-05
	LOSS [training: 0.08122956953690547 | validation: 0.09754637131155391]
	TIME [epoch: 8.29 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08128386007745615		[learning rate: 5.3199e-05]
	Learning Rate: 5.31994e-05
	LOSS [training: 0.08128386007745615 | validation: 0.0922402349120282]
	TIME [epoch: 8.28 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08221768432180956		[learning rate: 5.1678e-05]
	Learning Rate: 5.16781e-05
	LOSS [training: 0.08221768432180956 | validation: 0.10037133698389342]
	TIME [epoch: 8.27 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08122964161872528		[learning rate: 5.0184e-05]
	Learning Rate: 5.0184e-05
	LOSS [training: 0.08122964161872528 | validation: 0.10880716559820736]
	TIME [epoch: 8.28 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08034179249834598		[learning rate: 4.8717e-05]
	Learning Rate: 4.87172e-05
	LOSS [training: 0.08034179249834598 | validation: 0.09460569163549093]
	TIME [epoch: 8.28 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08282718435224087		[learning rate: 4.7278e-05]
	Learning Rate: 4.72776e-05
	LOSS [training: 0.08282718435224087 | validation: 0.09389424811629793]
	TIME [epoch: 8.33 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08110104915926036		[learning rate: 4.5865e-05]
	Learning Rate: 4.58652e-05
	LOSS [training: 0.08110104915926036 | validation: 0.10115998124899583]
	TIME [epoch: 8.27 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07975404456170089		[learning rate: 4.448e-05]
	Learning Rate: 4.448e-05
	LOSS [training: 0.07975404456170089 | validation: 0.10023937133029537]
	TIME [epoch: 8.27 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0814929572000242		[learning rate: 4.3122e-05]
	Learning Rate: 4.31221e-05
	LOSS [training: 0.0814929572000242 | validation: 0.10585904530498497]
	TIME [epoch: 8.27 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07846574470516811		[learning rate: 4.1791e-05]
	Learning Rate: 4.17914e-05
	LOSS [training: 0.07846574470516811 | validation: 0.10071493781882122]
	TIME [epoch: 8.28 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08367506032504715		[learning rate: 4.0488e-05]
	Learning Rate: 4.04879e-05
	LOSS [training: 0.08367506032504715 | validation: 0.1017925856073639]
	TIME [epoch: 8.31 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08386761091463082		[learning rate: 3.9212e-05]
	Learning Rate: 3.92117e-05
	LOSS [training: 0.08386761091463082 | validation: 0.10013162900206873]
	TIME [epoch: 8.29 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08351013534922068		[learning rate: 3.7963e-05]
	Learning Rate: 3.79628e-05
	LOSS [training: 0.08351013534922068 | validation: 0.11031740917730642]
	TIME [epoch: 8.28 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0825681375623466		[learning rate: 3.6741e-05]
	Learning Rate: 3.6741e-05
	LOSS [training: 0.0825681375623466 | validation: 0.09356258141393786]
	TIME [epoch: 8.27 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08254053432543162		[learning rate: 3.5547e-05]
	Learning Rate: 3.55466e-05
	LOSS [training: 0.08254053432543162 | validation: 0.09639582304922072]
	TIME [epoch: 8.27 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08123879404208932		[learning rate: 3.4379e-05]
	Learning Rate: 3.43794e-05
	LOSS [training: 0.08123879404208932 | validation: 0.0950593888207324]
	TIME [epoch: 8.28 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0796671413416337		[learning rate: 3.3239e-05]
	Learning Rate: 3.32394e-05
	LOSS [training: 0.0796671413416337 | validation: 0.10405693299183355]
	TIME [epoch: 8.32 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08059341412448955		[learning rate: 3.2127e-05]
	Learning Rate: 3.21267e-05
	LOSS [training: 0.08059341412448955 | validation: 0.10336259401536495]
	TIME [epoch: 8.28 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07854090351850196		[learning rate: 3.1041e-05]
	Learning Rate: 3.10413e-05
	LOSS [training: 0.07854090351850196 | validation: 0.10318962047246627]
	TIME [epoch: 8.27 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08393578123278443		[learning rate: 2.9983e-05]
	Learning Rate: 2.99831e-05
	LOSS [training: 0.08393578123278443 | validation: 0.1031939445391272]
	TIME [epoch: 8.28 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08429713281923316		[learning rate: 2.8952e-05]
	Learning Rate: 2.89522e-05
	LOSS [training: 0.08429713281923316 | validation: 0.10273687100938368]
	TIME [epoch: 8.27 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08129982943491659		[learning rate: 2.7949e-05]
	Learning Rate: 2.79486e-05
	LOSS [training: 0.08129982943491659 | validation: 0.1019919967320125]
	TIME [epoch: 8.3 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08225576702277576		[learning rate: 2.6972e-05]
	Learning Rate: 2.69723e-05
	LOSS [training: 0.08225576702277576 | validation: 0.10343528260377638]
	TIME [epoch: 8.28 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07673631379402411		[learning rate: 2.6023e-05]
	Learning Rate: 2.60232e-05
	LOSS [training: 0.07673631379402411 | validation: 0.09968433644214786]
	TIME [epoch: 8.27 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08295007626437853		[learning rate: 2.5101e-05]
	Learning Rate: 2.51015e-05
	LOSS [training: 0.08295007626437853 | validation: 0.10142849129685141]
	TIME [epoch: 8.27 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08321523537232206		[learning rate: 2.4207e-05]
	Learning Rate: 2.4207e-05
	LOSS [training: 0.08321523537232206 | validation: 0.08656803488310776]
	TIME [epoch: 8.27 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07903814296122023		[learning rate: 2.334e-05]
	Learning Rate: 2.33398e-05
	LOSS [training: 0.07903814296122023 | validation: 0.0926683587832288]
	TIME [epoch: 8.27 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08387362698945204		[learning rate: 2.25e-05]
	Learning Rate: 2.24999e-05
	LOSS [training: 0.08387362698945204 | validation: 0.09780103589007064]
	TIME [epoch: 8.32 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07918560397541509		[learning rate: 2.1687e-05]
	Learning Rate: 2.16873e-05
	LOSS [training: 0.07918560397541509 | validation: 0.10908204048618791]
	TIME [epoch: 8.27 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07704940815976544		[learning rate: 2.0902e-05]
	Learning Rate: 2.09019e-05
	LOSS [training: 0.07704940815976544 | validation: 0.08722858445639917]
	TIME [epoch: 8.26 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07928025113603902		[learning rate: 2.0144e-05]
	Learning Rate: 2.01439e-05
	LOSS [training: 0.07928025113603902 | validation: 0.0996545192385132]
	TIME [epoch: 8.27 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08451735961126344		[learning rate: 1.9413e-05]
	Learning Rate: 1.94132e-05
	LOSS [training: 0.08451735961126344 | validation: 0.10195719519383817]
	TIME [epoch: 8.26 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0808957539975751		[learning rate: 1.871e-05]
	Learning Rate: 1.87097e-05
	LOSS [training: 0.0808957539975751 | validation: 0.0943909958628372]
	TIME [epoch: 8.28 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08152606691639742		[learning rate: 1.8034e-05]
	Learning Rate: 1.80336e-05
	LOSS [training: 0.08152606691639742 | validation: 0.09957837569899289]
	TIME [epoch: 8.29 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0804067942310922		[learning rate: 1.7385e-05]
	Learning Rate: 1.73848e-05
	LOSS [training: 0.0804067942310922 | validation: 0.09978913348794868]
	TIME [epoch: 8.27 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07802953664074863		[learning rate: 1.6763e-05]
	Learning Rate: 1.67633e-05
	LOSS [training: 0.07802953664074863 | validation: 0.10033093766489938]
	TIME [epoch: 8.26 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08303159035368558		[learning rate: 1.6169e-05]
	Learning Rate: 1.61691e-05
	LOSS [training: 0.08303159035368558 | validation: 0.09321192761473283]
	TIME [epoch: 8.26 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07957482025584826		[learning rate: 1.5602e-05]
	Learning Rate: 1.56022e-05
	LOSS [training: 0.07957482025584826 | validation: 0.10069310271325732]
	TIME [epoch: 8.26 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08203565034109916		[learning rate: 1.5063e-05]
	Learning Rate: 1.50626e-05
	LOSS [training: 0.08203565034109916 | validation: 0.08794396070566009]
	TIME [epoch: 8.3 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07811394939380756		[learning rate: 1.455e-05]
	Learning Rate: 1.45503e-05
	LOSS [training: 0.07811394939380756 | validation: 0.11272398418654225]
	TIME [epoch: 8.27 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08098266403195514		[learning rate: 1.4065e-05]
	Learning Rate: 1.40653e-05
	LOSS [training: 0.08098266403195514 | validation: 0.09786755194376551]
	TIME [epoch: 8.26 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08263525346162254		[learning rate: 1.3608e-05]
	Learning Rate: 1.36077e-05
	LOSS [training: 0.08263525346162254 | validation: 0.0900474649313574]
	TIME [epoch: 8.26 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07918184605797242		[learning rate: 1.3177e-05]
	Learning Rate: 1.31773e-05
	LOSS [training: 0.07918184605797242 | validation: 0.10341515196666856]
	TIME [epoch: 8.26 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08411183504607957		[learning rate: 1.2774e-05]
	Learning Rate: 1.27743e-05
	LOSS [training: 0.08411183504607957 | validation: 0.10210306694863908]
	TIME [epoch: 8.26 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08233875212432384		[learning rate: 1.2399e-05]
	Learning Rate: 1.23986e-05
	LOSS [training: 0.08233875212432384 | validation: 0.10025537618281072]
	TIME [epoch: 8.3 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07992402081832377		[learning rate: 1.205e-05]
	Learning Rate: 1.20502e-05
	LOSS [training: 0.07992402081832377 | validation: 0.09753330030512]
	TIME [epoch: 8.26 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0824217202214938		[learning rate: 1.1729e-05]
	Learning Rate: 1.17292e-05
	LOSS [training: 0.0824217202214938 | validation: 0.09204271904913586]
	TIME [epoch: 8.26 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08361771596182557		[learning rate: 1.1435e-05]
	Learning Rate: 1.14354e-05
	LOSS [training: 0.08361771596182557 | validation: 0.10811405487166678]
	TIME [epoch: 8.26 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07824752484975617		[learning rate: 1.1169e-05]
	Learning Rate: 1.1169e-05
	LOSS [training: 0.07824752484975617 | validation: 0.09519450962668939]
	TIME [epoch: 8.27 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07876646373643023		[learning rate: 1.093e-05]
	Learning Rate: 1.09299e-05
	LOSS [training: 0.07876646373643023 | validation: 0.09178338034575356]
	TIME [epoch: 8.29 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0824122190797188		[learning rate: 1.0718e-05]
	Learning Rate: 1.07182e-05
	LOSS [training: 0.0824122190797188 | validation: 0.09512737892045273]
	TIME [epoch: 8.28 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08369443946425684		[learning rate: 1.0534e-05]
	Learning Rate: 1.05337e-05
	LOSS [training: 0.08369443946425684 | validation: 0.09712899436132877]
	TIME [epoch: 8.26 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08335659677043153		[learning rate: 1.0377e-05]
	Learning Rate: 1.03766e-05
	LOSS [training: 0.08335659677043153 | validation: 0.10681439230702258]
	TIME [epoch: 8.26 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08081639447371751		[learning rate: 1.0247e-05]
	Learning Rate: 1.02468e-05
	LOSS [training: 0.08081639447371751 | validation: 0.08972616002196063]
	TIME [epoch: 8.26 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08167362045545994		[learning rate: 1.0144e-05]
	Learning Rate: 1.01443e-05
	LOSS [training: 0.08167362045545994 | validation: 0.0962545960662938]
	TIME [epoch: 8.27 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07813737323754844		[learning rate: 1.0069e-05]
	Learning Rate: 1.00692e-05
	LOSS [training: 0.07813737323754844 | validation: 0.09237009538850688]
	TIME [epoch: 8.31 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07812911797529297		[learning rate: 1.0021e-05]
	Learning Rate: 1.00213e-05
	LOSS [training: 0.07812911797529297 | validation: 0.09079153170346826]
	TIME [epoch: 8.27 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08323205859377086		[learning rate: 1.0001e-05]
	Learning Rate: 1.00009e-05
	LOSS [training: 0.08323205859377086 | validation: 0.09173030400627094]
	TIME [epoch: 8.26 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07932356337589393		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.07932356337589393 | validation: 0.10025072557646786]
	TIME [epoch: 8.26 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07632879933029234		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.07632879933029234 | validation: 0.09059788291844643]
	TIME [epoch: 8.26 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08004723566508234		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.08004723566508234 | validation: 0.09081698651771603]
	TIME [epoch: 8.29 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08003439079529522		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.08003439079529522 | validation: 0.09468560400061166]
	TIME [epoch: 8.28 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0758647190157472		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0758647190157472 | validation: 0.10069796969054212]
	TIME [epoch: 8.26 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07920890963995689		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.07920890963995689 | validation: 0.09099691906231708]
	TIME [epoch: 8.26 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08111238445216959		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.08111238445216959 | validation: 0.09163996691422463]
	TIME [epoch: 8.26 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08064529076604252		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.08064529076604252 | validation: 0.09707618456380387]
	TIME [epoch: 8.26 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08219542774141042		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.08219542774141042 | validation: 0.09784252757201252]
	TIME [epoch: 8.31 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08131771296782313		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.08131771296782313 | validation: 0.10356184051631001]
	TIME [epoch: 8.27 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08030182235293425		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.08030182235293425 | validation: 0.09940643279643452]
	TIME [epoch: 8.26 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07597380746733663		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.07597380746733663 | validation: 0.10421156193899803]
	TIME [epoch: 8.26 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07909362445838825		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.07909362445838825 | validation: 0.09709543746717675]
	TIME [epoch: 8.26 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0814308723478438		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0814308723478438 | validation: 0.08760915629031493]
	TIME [epoch: 8.27 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07897384577033352		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.07897384577033352 | validation: 0.0962045172668307]
	TIME [epoch: 8.3 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07420986956820977		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.07420986956820977 | validation: 0.09693941517738285]
	TIME [epoch: 8.26 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08300580375232103		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.08300580375232103 | validation: 0.10354984065564192]
	TIME [epoch: 8.26 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0776190374684949		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0776190374684949 | validation: 0.09758227971326122]
	TIME [epoch: 8.26 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0795648844319112		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0795648844319112 | validation: 0.09981416931699091]
	TIME [epoch: 8.26 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0781083292112057		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0781083292112057 | validation: 0.0948300172645699]
	TIME [epoch: 8.31 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07859428961024241		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.07859428961024241 | validation: 0.09779245189317912]
	TIME [epoch: 8.28 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0822281637511814		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0822281637511814 | validation: 0.09420143554556341]
	TIME [epoch: 8.27 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0826482963270974		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0826482963270974 | validation: 0.10503511527385193]
	TIME [epoch: 8.26 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07849279658850336		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.07849279658850336 | validation: 0.09484482001825091]
	TIME [epoch: 8.27 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07831604949028678		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.07831604949028678 | validation: 0.08765606542194135]
	TIME [epoch: 8.27 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08159100064921276		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.08159100064921276 | validation: 0.09691686774586508]
	TIME [epoch: 8.31 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08224108033672407		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.08224108033672407 | validation: 0.09433520308027896]
	TIME [epoch: 8.26 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08130536584609767		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.08130536584609767 | validation: 0.10017798235409323]
	TIME [epoch: 8.27 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07891315543091193		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.07891315543091193 | validation: 0.08631242244595291]
	TIME [epoch: 8.26 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07811760296786562		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.07811760296786562 | validation: 0.09189819174584021]
	TIME [epoch: 8.26 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0802660884071411		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0802660884071411 | validation: 0.10273581602237952]
	TIME [epoch: 8.3 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.077973331905093		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.077973331905093 | validation: 0.1023899270650089]
	TIME [epoch: 8.28 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08386267714474895		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.08386267714474895 | validation: 0.10361117544554047]
	TIME [epoch: 8.26 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08484255681790297		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.08484255681790297 | validation: 0.08990792876323167]
	TIME [epoch: 8.26 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0765921599000186		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0765921599000186 | validation: 0.09669983753686981]
	TIME [epoch: 8.26 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.077131976534134		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.077131976534134 | validation: 0.09671401002992241]
	TIME [epoch: 8.26 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08137904750828408		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.08137904750828408 | validation: 0.09645247522849612]
	TIME [epoch: 8.31 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07989007213483257		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.07989007213483257 | validation: 0.0982608595342288]
	TIME [epoch: 8.27 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07979320314453278		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.07979320314453278 | validation: 0.10511762593706446]
	TIME [epoch: 8.27 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08185952717884339		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.08185952717884339 | validation: 0.0885912226348713]
	TIME [epoch: 8.26 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08016553757664231		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.08016553757664231 | validation: 0.08901030743888526]
	TIME [epoch: 8.26 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0772878420607705		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0772878420607705 | validation: 0.1033988800371616]
	TIME [epoch: 8.28 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07502781006867429		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.07502781006867429 | validation: 0.09400854281814779]
	TIME [epoch: 8.3 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08346259586354966		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.08346259586354966 | validation: 0.09808459112435733]
	TIME [epoch: 8.27 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07969161345757378		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.07969161345757378 | validation: 0.09279259169060845]
	TIME [epoch: 8.26 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07761103084538673		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.07761103084538673 | validation: 0.0944824379817154]
	TIME [epoch: 8.26 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08149514427190402		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.08149514427190402 | validation: 0.08532316753718215]
	TIME [epoch: 8.26 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0823170283468817		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.0823170283468817 | validation: 0.10176858570159256]
	TIME [epoch: 8.3 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07850242789856822		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.07850242789856822 | validation: 0.09250575596176108]
	TIME [epoch: 8.28 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08487520173805713		[learning rate: 1e-05]
	Learning Rate: 1e-05
	LOSS [training: 0.08487520173805713 | validation: 0.09855512929280627]
	TIME [epoch: 8.26 sec]
Finished training in 16806.489 seconds.
