Args:
Namespace(name='model_phi2_1a_v2', outdir='out/model_training/model_phi2_1a_v2', training_data='data/training_data/data_phi2_1a/training', validation_data='data/training_data/data_phi2_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.3, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1586404302

Training model...

Saving initial model state to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.099993802278986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.099993802278986 | validation: 6.209099655614304]
	TIME [epoch: 152 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.589027573262102		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.589027573262102 | validation: 4.025478253866633]
	TIME [epoch: 6.63 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.546979022732428		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.546979022732428 | validation: 6.816527598588747]
	TIME [epoch: 6.55 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9081964805308567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9081964805308567 | validation: 2.587423076171172]
	TIME [epoch: 6.62 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.791239459043999		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.791239459043999 | validation: 2.39748384746581]
	TIME [epoch: 6.57 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8405382446001632		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8405382446001632 | validation: 2.149033459654189]
	TIME [epoch: 6.57 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.701753660402454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.701753660402454 | validation: 2.4284825990043837]
	TIME [epoch: 6.57 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.696310692097979		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.696310692097979 | validation: 2.41060174352722]
	TIME [epoch: 6.54 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.46135580574455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.46135580574455 | validation: 1.9765036811118883]
	TIME [epoch: 6.58 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2418416454454335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2418416454454335 | validation: 3.044374591502515]
	TIME [epoch: 6.56 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.491190342730851		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.491190342730851 | validation: 2.2661871451222435]
	TIME [epoch: 6.53 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.380296779065646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.380296779065646 | validation: 1.953337487671155]
	TIME [epoch: 6.54 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.912928118574039		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.912928118574039 | validation: 2.259805530489222]
	TIME [epoch: 6.55 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.643508380685275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.643508380685275 | validation: 2.0150342800925407]
	TIME [epoch: 6.55 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.29531302982448		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.29531302982448 | validation: 1.8778461698227846]
	TIME [epoch: 6.62 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5993046961232427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5993046961232427 | validation: 1.9960587244935593]
	TIME [epoch: 6.57 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.491027830215548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.491027830215548 | validation: 1.8099965016303314]
	TIME [epoch: 6.56 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.370267599945015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.370267599945015 | validation: 3.1971378813867313]
	TIME [epoch: 6.55 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4452885574950924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4452885574950924 | validation: 1.8703860048514658]
	TIME [epoch: 6.55 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2971083257854277		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2971083257854277 | validation: 1.7933390987349007]
	TIME [epoch: 6.58 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.576163325131198		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.576163325131198 | validation: 2.1548677316538862]
	TIME [epoch: 6.58 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4249696405594334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4249696405594334 | validation: 2.235389243410542]
	TIME [epoch: 6.54 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.456858282458878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.456858282458878 | validation: 2.7763387164615723]
	TIME [epoch: 6.56 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.202660744339037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.202660744339037 | validation: 1.8137116679028524]
	TIME [epoch: 6.54 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1524452809825894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1524452809825894 | validation: 1.7847873150345253]
	TIME [epoch: 6.53 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.095768564362377		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.095768564362377 | validation: 2.2578167275522185]
	TIME [epoch: 6.59 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.107485856686514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.107485856686514 | validation: 1.8124472305350943]
	TIME [epoch: 6.55 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.059610545618645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.059610545618645 | validation: 3.7395564016564817]
	TIME [epoch: 6.54 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7827811432885694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7827811432885694 | validation: 1.634069141977292]
	TIME [epoch: 6.54 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.044696832942215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.044696832942215 | validation: 1.5905200840834361]
	TIME [epoch: 6.52 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.032039017792439		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.032039017792439 | validation: 1.778793293806287]
	TIME [epoch: 6.54 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2900799415221114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2900799415221114 | validation: 1.7115067509712003]
	TIME [epoch: 6.55 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2884234823461336		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2884234823461336 | validation: 1.7632282619885995]
	TIME [epoch: 6.53 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8478334248019226		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8478334248019226 | validation: 1.7516471902443436]
	TIME [epoch: 6.5 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8605524029505456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8605524029505456 | validation: 1.6790991069730863]
	TIME [epoch: 6.52 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9725604111713788		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9725604111713788 | validation: 1.6044643828436844]
	TIME [epoch: 6.52 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1198069121114873		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1198069121114873 | validation: 1.5137127763979885]
	TIME [epoch: 6.55 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7850543955195093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7850543955195093 | validation: 1.6561537986812869]
	TIME [epoch: 6.54 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8771146577529698		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8771146577529698 | validation: 1.5186545383397174]
	TIME [epoch: 6.53 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7769688796859195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7769688796859195 | validation: 1.5040110861386395]
	TIME [epoch: 6.52 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8423152403355971		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8423152403355971 | validation: 1.457546741797688]
	TIME [epoch: 6.53 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9066616898198228		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9066616898198228 | validation: 2.124610600443156]
	TIME [epoch: 6.53 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.926237582226324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.926237582226324 | validation: 2.933302267857125]
	TIME [epoch: 6.54 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.280398607884922		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.280398607884922 | validation: 1.6987501979615158]
	TIME [epoch: 6.5 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9587595670880362		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9587595670880362 | validation: 1.4453488027329668]
	TIME [epoch: 6.51 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7323034600005465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7323034600005465 | validation: 1.4223319571564617]
	TIME [epoch: 6.54 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7120262379876912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7120262379876912 | validation: 5.992288366907813]
	TIME [epoch: 6.53 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7433184620160396		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7433184620160396 | validation: 1.562373267178958]
	TIME [epoch: 6.56 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7787896778814385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7787896778814385 | validation: 1.4442718683804738]
	TIME [epoch: 6.56 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6834367382527553		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6834367382527553 | validation: 1.363233816944559]
	TIME [epoch: 6.54 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7268938701186585		[learning rate: 0.0099811]
	Learning Rate: 0.00998112
	LOSS [training: 1.7268938701186585 | validation: 1.4443549225476535]
	TIME [epoch: 6.54 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9989437826660361		[learning rate: 0.0099576]
	Learning Rate: 0.00995758
	LOSS [training: 1.9989437826660361 | validation: 1.827481756388888]
	TIME [epoch: 6.55 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8593169105214309		[learning rate: 0.0099341]
	Learning Rate: 0.00993409
	LOSS [training: 1.8593169105214309 | validation: 1.609974701859118]
	TIME [epoch: 6.54 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7502948967322631		[learning rate: 0.0099107]
	Learning Rate: 0.00991066
	LOSS [training: 1.7502948967322631 | validation: 1.3451688895312752]
	TIME [epoch: 6.58 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.784482504689775		[learning rate: 0.0098873]
	Learning Rate: 0.00988728
	LOSS [training: 1.784482504689775 | validation: 1.3630267988386207]
	TIME [epoch: 6.54 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6489605155701927		[learning rate: 0.009864]
	Learning Rate: 0.00986396
	LOSS [training: 1.6489605155701927 | validation: 2.0358134443670965]
	TIME [epoch: 6.53 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8426442455016532		[learning rate: 0.0098407]
	Learning Rate: 0.00984069
	LOSS [training: 1.8426442455016532 | validation: 1.5487495800983977]
	TIME [epoch: 6.53 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7637770995586641		[learning rate: 0.0098175]
	Learning Rate: 0.00981748
	LOSS [training: 1.7637770995586641 | validation: 1.4459912234172982]
	TIME [epoch: 6.52 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7827129965608424		[learning rate: 0.0097943]
	Learning Rate: 0.00979432
	LOSS [training: 1.7827129965608424 | validation: 1.6087635407684275]
	TIME [epoch: 6.54 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8524436656619165		[learning rate: 0.0097712]
	Learning Rate: 0.00977122
	LOSS [training: 1.8524436656619165 | validation: 1.4491727646992674]
	TIME [epoch: 6.56 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6501799628126494		[learning rate: 0.0097482]
	Learning Rate: 0.00974817
	LOSS [training: 1.6501799628126494 | validation: 1.322954148536574]
	TIME [epoch: 6.53 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7714586754010995		[learning rate: 0.0097252]
	Learning Rate: 0.00972517
	LOSS [training: 1.7714586754010995 | validation: 1.5965976124300036]
	TIME [epoch: 6.53 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7393634926306145		[learning rate: 0.0097022]
	Learning Rate: 0.00970223
	LOSS [training: 1.7393634926306145 | validation: 1.4035065903613715]
	TIME [epoch: 6.53 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7073034775762146		[learning rate: 0.0096793]
	Learning Rate: 0.00967935
	LOSS [training: 1.7073034775762146 | validation: 1.662644455612772]
	TIME [epoch: 6.53 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.710179089074467		[learning rate: 0.0096565]
	Learning Rate: 0.00965652
	LOSS [training: 1.710179089074467 | validation: 1.410980360131448]
	TIME [epoch: 6.55 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.686055953268704		[learning rate: 0.0096337]
	Learning Rate: 0.00963374
	LOSS [training: 1.686055953268704 | validation: 1.434603203019352]
	TIME [epoch: 6.55 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7077526843019606		[learning rate: 0.009611]
	Learning Rate: 0.00961101
	LOSS [training: 1.7077526843019606 | validation: 1.3571661542574796]
	TIME [epoch: 6.53 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.722829096298905		[learning rate: 0.0095883]
	Learning Rate: 0.00958834
	LOSS [training: 1.722829096298905 | validation: 1.3747646748736355]
	TIME [epoch: 6.53 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6277837561364308		[learning rate: 0.0095657]
	Learning Rate: 0.00956573
	LOSS [training: 1.6277837561364308 | validation: 1.41446944488253]
	TIME [epoch: 6.53 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.748002403539133		[learning rate: 0.0095432]
	Learning Rate: 0.00954316
	LOSS [training: 1.748002403539133 | validation: 3.212740206593166]
	TIME [epoch: 6.53 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1126198980483264		[learning rate: 0.0095207]
	Learning Rate: 0.00952065
	LOSS [training: 2.1126198980483264 | validation: 1.45950110468578]
	TIME [epoch: 6.56 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6042654077940093		[learning rate: 0.0094982]
	Learning Rate: 0.00949819
	LOSS [training: 1.6042654077940093 | validation: 1.3544289185896532]
	TIME [epoch: 6.54 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.610471837463066		[learning rate: 0.0094758]
	Learning Rate: 0.00947579
	LOSS [training: 1.610471837463066 | validation: 1.269370408526147]
	TIME [epoch: 6.53 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6957386947184183		[learning rate: 0.0094534]
	Learning Rate: 0.00945344
	LOSS [training: 1.6957386947184183 | validation: 1.2810344813026222]
	TIME [epoch: 6.53 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6045955218689723		[learning rate: 0.0094311]
	Learning Rate: 0.00943114
	LOSS [training: 1.6045955218689723 | validation: 1.2867597362866778]
	TIME [epoch: 6.54 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.573467892966197		[learning rate: 0.0094089]
	Learning Rate: 0.00940889
	LOSS [training: 1.573467892966197 | validation: 1.307791264838185]
	TIME [epoch: 6.52 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6101484756307674		[learning rate: 0.0093867]
	Learning Rate: 0.0093867
	LOSS [training: 1.6101484756307674 | validation: 1.6654980077035866]
	TIME [epoch: 6.57 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6960389122380026		[learning rate: 0.0093646]
	Learning Rate: 0.00936456
	LOSS [training: 1.6960389122380026 | validation: 1.4533889417865946]
	TIME [epoch: 6.54 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6253264105252203		[learning rate: 0.0093425]
	Learning Rate: 0.00934247
	LOSS [training: 1.6253264105252203 | validation: 1.2595686436824414]
	TIME [epoch: 6.53 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6741270300750906		[learning rate: 0.0093204]
	Learning Rate: 0.00932043
	LOSS [training: 1.6741270300750906 | validation: 1.2746311276599638]
	TIME [epoch: 6.52 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7298750717102027		[learning rate: 0.0092984]
	Learning Rate: 0.00929844
	LOSS [training: 1.7298750717102027 | validation: 3.921349759711572]
	TIME [epoch: 6.51 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.546647803193614		[learning rate: 0.0092765]
	Learning Rate: 0.00927651
	LOSS [training: 2.546647803193614 | validation: 1.4086893596096202]
	TIME [epoch: 6.55 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6744484335839502		[learning rate: 0.0092546]
	Learning Rate: 0.00925463
	LOSS [training: 1.6744484335839502 | validation: 1.754231357217013]
	TIME [epoch: 6.54 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6859267906124575		[learning rate: 0.0092328]
	Learning Rate: 0.0092328
	LOSS [training: 1.6859267906124575 | validation: 1.2758454370441952]
	TIME [epoch: 6.53 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.531816406992012		[learning rate: 0.009211]
	Learning Rate: 0.00921102
	LOSS [training: 1.531816406992012 | validation: 1.2577240761777992]
	TIME [epoch: 6.53 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.541431486337834		[learning rate: 0.0091893]
	Learning Rate: 0.00918929
	LOSS [training: 1.541431486337834 | validation: 1.284252245528934]
	TIME [epoch: 6.53 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5380323427161202		[learning rate: 0.0091676]
	Learning Rate: 0.00916762
	LOSS [training: 1.5380323427161202 | validation: 1.5341679550031544]
	TIME [epoch: 6.51 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6664404712669014		[learning rate: 0.009146]
	Learning Rate: 0.00914599
	LOSS [training: 1.6664404712669014 | validation: 1.7898642987073194]
	TIME [epoch: 6.59 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.644842859245934		[learning rate: 0.0091244]
	Learning Rate: 0.00912442
	LOSS [training: 1.644842859245934 | validation: 1.2756647674613653]
	TIME [epoch: 6.53 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5492798199347089		[learning rate: 0.0091029]
	Learning Rate: 0.00910289
	LOSS [training: 1.5492798199347089 | validation: 1.2447394164976666]
	TIME [epoch: 6.54 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.533581552412467		[learning rate: 0.0090814]
	Learning Rate: 0.00908142
	LOSS [training: 1.533581552412467 | validation: 1.6033550229510245]
	TIME [epoch: 6.52 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7012626563477729		[learning rate: 0.00906]
	Learning Rate: 0.00906
	LOSS [training: 1.7012626563477729 | validation: 1.3366821736740642]
	TIME [epoch: 6.52 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6127716395415337		[learning rate: 0.0090386]
	Learning Rate: 0.00903863
	LOSS [training: 1.6127716395415337 | validation: 1.2798545334093292]
	TIME [epoch: 6.54 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5905803837477228		[learning rate: 0.0090173]
	Learning Rate: 0.00901731
	LOSS [training: 1.5905803837477228 | validation: 1.2607777456380431]
	TIME [epoch: 6.55 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4941007869804834		[learning rate: 0.008996]
	Learning Rate: 0.00899604
	LOSS [training: 1.4941007869804834 | validation: 1.2309937386942256]
	TIME [epoch: 6.51 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6845880498235069		[learning rate: 0.0089748]
	Learning Rate: 0.00897482
	LOSS [training: 1.6845880498235069 | validation: 1.3262447360718508]
	TIME [epoch: 6.52 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6858908155098722		[learning rate: 0.0089536]
	Learning Rate: 0.00895365
	LOSS [training: 1.6858908155098722 | validation: 1.4278203771283529]
	TIME [epoch: 6.53 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7290287456285849		[learning rate: 0.0089325]
	Learning Rate: 0.00893253
	LOSS [training: 1.7290287456285849 | validation: 1.2685595406329546]
	TIME [epoch: 6.55 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5467402262349133		[learning rate: 0.0089115]
	Learning Rate: 0.00891146
	LOSS [training: 1.5467402262349133 | validation: 1.336543103066483]
	TIME [epoch: 6.59 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.55123936063308		[learning rate: 0.0088904]
	Learning Rate: 0.00889044
	LOSS [training: 1.55123936063308 | validation: 1.3975730713088685]
	TIME [epoch: 6.57 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5564833163375795		[learning rate: 0.0088695]
	Learning Rate: 0.00886946
	LOSS [training: 1.5564833163375795 | validation: 1.3583785773937613]
	TIME [epoch: 6.54 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5366745447439745		[learning rate: 0.0088485]
	Learning Rate: 0.00884854
	LOSS [training: 1.5366745447439745 | validation: 1.4070947664882032]
	TIME [epoch: 6.56 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7576116241616462		[learning rate: 0.0088277]
	Learning Rate: 0.00882767
	LOSS [training: 1.7576116241616462 | validation: 1.2509979559850564]
	TIME [epoch: 6.56 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.644685669685412		[learning rate: 0.0088068]
	Learning Rate: 0.00880685
	LOSS [training: 1.644685669685412 | validation: 1.8040168187529935]
	TIME [epoch: 6.57 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6562034607469254		[learning rate: 0.0087861]
	Learning Rate: 0.00878607
	LOSS [training: 1.6562034607469254 | validation: 1.2768043286944373]
	TIME [epoch: 6.61 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.496914126592629		[learning rate: 0.0087653]
	Learning Rate: 0.00876535
	LOSS [training: 1.496914126592629 | validation: 1.1992958561017018]
	TIME [epoch: 6.52 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.488539408939359		[learning rate: 0.0087447]
	Learning Rate: 0.00874467
	LOSS [training: 1.488539408939359 | validation: 1.2091927883773108]
	TIME [epoch: 6.52 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4542339669120576		[learning rate: 0.008724]
	Learning Rate: 0.00872405
	LOSS [training: 1.4542339669120576 | validation: 1.322066534065879]
	TIME [epoch: 6.53 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4805598037573557		[learning rate: 0.0087035]
	Learning Rate: 0.00870347
	LOSS [training: 1.4805598037573557 | validation: 1.240617315530872]
	TIME [epoch: 6.55 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4823871165730018		[learning rate: 0.0086829]
	Learning Rate: 0.00868294
	LOSS [training: 1.4823871165730018 | validation: 1.1830326270738123]
	TIME [epoch: 6.55 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_110.pth
	Model improved!!!
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4879240329235117		[learning rate: 0.0086625]
	Learning Rate: 0.00866246
	LOSS [training: 1.4879240329235117 | validation: 1.3514859112291537]
	TIME [epoch: 6.57 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.472886031438642		[learning rate: 0.008642]
	Learning Rate: 0.00864202
	LOSS [training: 1.472886031438642 | validation: 1.229884349431972]
	TIME [epoch: 6.56 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.470459871748533		[learning rate: 0.0086216]
	Learning Rate: 0.00862164
	LOSS [training: 1.470459871748533 | validation: 1.1892269035005478]
	TIME [epoch: 6.55 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5293099973910893		[learning rate: 0.0086013]
	Learning Rate: 0.0086013
	LOSS [training: 1.5293099973910893 | validation: 1.280823917896814]
	TIME [epoch: 6.53 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7675262074897966		[learning rate: 0.008581]
	Learning Rate: 0.00858101
	LOSS [training: 1.7675262074897966 | validation: 1.5698155149892807]
	TIME [epoch: 6.55 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5249854114978727		[learning rate: 0.0085608]
	Learning Rate: 0.00856077
	LOSS [training: 1.5249854114978727 | validation: 1.1489297288771811]
	TIME [epoch: 6.6 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_116.pth
	Model improved!!!
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4420211947112498		[learning rate: 0.0085406]
	Learning Rate: 0.00854058
	LOSS [training: 1.4420211947112498 | validation: 1.1622238699471743]
	TIME [epoch: 6.58 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6325860922415711		[learning rate: 0.0085204]
	Learning Rate: 0.00852043
	LOSS [training: 1.6325860922415711 | validation: 1.695962511701814]
	TIME [epoch: 6.55 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5722253268564372		[learning rate: 0.0085003]
	Learning Rate: 0.00850033
	LOSS [training: 1.5722253268564372 | validation: 1.1147282904843863]
	TIME [epoch: 6.54 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_119.pth
	Model improved!!!
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4746731907706372		[learning rate: 0.0084803]
	Learning Rate: 0.00848028
	LOSS [training: 1.4746731907706372 | validation: 1.2369125717988128]
	TIME [epoch: 6.54 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4800765137184317		[learning rate: 0.0084603]
	Learning Rate: 0.00846028
	LOSS [training: 1.4800765137184317 | validation: 1.1453826886521026]
	TIME [epoch: 6.57 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5501872735435736		[learning rate: 0.0084403]
	Learning Rate: 0.00844032
	LOSS [training: 1.5501872735435736 | validation: 1.2142934463949575]
	TIME [epoch: 6.59 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4431797937636315		[learning rate: 0.0084204]
	Learning Rate: 0.00842041
	LOSS [training: 1.4431797937636315 | validation: 1.2027372606209705]
	TIME [epoch: 6.57 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4535954327888447		[learning rate: 0.0084005]
	Learning Rate: 0.00840055
	LOSS [training: 1.4535954327888447 | validation: 1.1299223423287577]
	TIME [epoch: 6.54 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3578390326354466		[learning rate: 0.0083807]
	Learning Rate: 0.00838073
	LOSS [training: 1.3578390326354466 | validation: 1.1401791982306562]
	TIME [epoch: 6.54 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.417741487784447		[learning rate: 0.008361]
	Learning Rate: 0.00836096
	LOSS [training: 1.417741487784447 | validation: 1.2818274715376852]
	TIME [epoch: 6.55 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4490523595113245		[learning rate: 0.0083412]
	Learning Rate: 0.00834124
	LOSS [training: 1.4490523595113245 | validation: 1.196481988540412]
	TIME [epoch: 6.56 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3521274016345641		[learning rate: 0.0083216]
	Learning Rate: 0.00832157
	LOSS [training: 1.3521274016345641 | validation: 1.0947984336514114]
	TIME [epoch: 6.56 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.35612026706256		[learning rate: 0.0083019]
	Learning Rate: 0.00830194
	LOSS [training: 1.35612026706256 | validation: 1.3409000853003135]
	TIME [epoch: 6.54 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5730226207735167		[learning rate: 0.0082824]
	Learning Rate: 0.00828236
	LOSS [training: 1.5730226207735167 | validation: 1.1393381697660174]
	TIME [epoch: 6.53 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.328798631861405		[learning rate: 0.0082628]
	Learning Rate: 0.00826282
	LOSS [training: 1.328798631861405 | validation: 1.1540126013744085]
	TIME [epoch: 6.55 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3639361997936301		[learning rate: 0.0082433]
	Learning Rate: 0.00824333
	LOSS [training: 1.3639361997936301 | validation: 1.10535781073532]
	TIME [epoch: 6.56 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5910429766139536		[learning rate: 0.0082239]
	Learning Rate: 0.00822388
	LOSS [training: 1.5910429766139536 | validation: 1.2789211060718662]
	TIME [epoch: 6.57 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.461242655520855		[learning rate: 0.0082045]
	Learning Rate: 0.00820448
	LOSS [training: 1.461242655520855 | validation: 1.5964015104403986]
	TIME [epoch: 6.57 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5661110214605765		[learning rate: 0.0081851]
	Learning Rate: 0.00818513
	LOSS [training: 1.5661110214605765 | validation: 1.114066331148382]
	TIME [epoch: 6.53 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3491224596740803		[learning rate: 0.0081658]
	Learning Rate: 0.00816582
	LOSS [training: 1.3491224596740803 | validation: 1.0758179901228515]
	TIME [epoch: 6.54 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_136.pth
	Model improved!!!
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5724747921946958		[learning rate: 0.0081466]
	Learning Rate: 0.00814656
	LOSS [training: 1.5724747921946958 | validation: 1.18639947415224]
	TIME [epoch: 6.56 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3626910502368934		[learning rate: 0.0081273]
	Learning Rate: 0.00812735
	LOSS [training: 1.3626910502368934 | validation: 1.0259517964275706]
	TIME [epoch: 6.57 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_138.pth
	Model improved!!!
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4505720008494032		[learning rate: 0.0081082]
	Learning Rate: 0.00810817
	LOSS [training: 1.4505720008494032 | validation: 1.0352121595547386]
	TIME [epoch: 6.6 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2501982393772617		[learning rate: 0.008089]
	Learning Rate: 0.00808905
	LOSS [training: 1.2501982393772617 | validation: 1.066153037719672]
	TIME [epoch: 6.57 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3778833373238422		[learning rate: 0.00807]
	Learning Rate: 0.00806997
	LOSS [training: 1.3778833373238422 | validation: 1.0506935599757103]
	TIME [epoch: 6.56 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2837464093772204		[learning rate: 0.0080509]
	Learning Rate: 0.00805093
	LOSS [training: 1.2837464093772204 | validation: 0.983247232091208]
	TIME [epoch: 6.57 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_142.pth
	Model improved!!!
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2683389628861614		[learning rate: 0.0080319]
	Learning Rate: 0.00803194
	LOSS [training: 1.2683389628861614 | validation: 1.0293449804389796]
	TIME [epoch: 6.56 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.345147689843697		[learning rate: 0.008013]
	Learning Rate: 0.00801299
	LOSS [training: 1.345147689843697 | validation: 1.001624442771067]
	TIME [epoch: 6.6 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.222732325891725		[learning rate: 0.0079941]
	Learning Rate: 0.00799409
	LOSS [training: 1.222732325891725 | validation: 1.1007123115319415]
	TIME [epoch: 6.57 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3523393945755031		[learning rate: 0.0079752]
	Learning Rate: 0.00797524
	LOSS [training: 1.3523393945755031 | validation: 0.9521609565776827]
	TIME [epoch: 6.55 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_146.pth
	Model improved!!!
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.212539447146797		[learning rate: 0.0079564]
	Learning Rate: 0.00795642
	LOSS [training: 1.212539447146797 | validation: 0.8968363605446044]
	TIME [epoch: 6.54 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_147.pth
	Model improved!!!
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4266351154538486		[learning rate: 0.0079377]
	Learning Rate: 0.00793766
	LOSS [training: 1.4266351154538486 | validation: 0.989696700753617]
	TIME [epoch: 6.54 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2368067482766096		[learning rate: 0.0079189]
	Learning Rate: 0.00791893
	LOSS [training: 1.2368067482766096 | validation: 0.9182227889929009]
	TIME [epoch: 6.55 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1557667282697905		[learning rate: 0.0079003]
	Learning Rate: 0.00790025
	LOSS [training: 1.1557667282697905 | validation: 0.963482335446572]
	TIME [epoch: 6.58 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4957281618026936		[learning rate: 0.0078816]
	Learning Rate: 0.00788162
	LOSS [training: 1.4957281618026936 | validation: 1.3909516517574314]
	TIME [epoch: 6.54 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5400850383708407		[learning rate: 0.007863]
	Learning Rate: 0.00786303
	LOSS [training: 1.5400850383708407 | validation: 0.9940070966142873]
	TIME [epoch: 6.55 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2067719998661042		[learning rate: 0.0078445]
	Learning Rate: 0.00784448
	LOSS [training: 1.2067719998661042 | validation: 0.8431736054012042]
	TIME [epoch: 6.56 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_153.pth
	Model improved!!!
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2302720019643847		[learning rate: 0.007826]
	Learning Rate: 0.00782597
	LOSS [training: 1.2302720019643847 | validation: 0.92720619449169]
	TIME [epoch: 6.56 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1375529725184037		[learning rate: 0.0078075]
	Learning Rate: 0.00780751
	LOSS [training: 1.1375529725184037 | validation: 0.8263482524662938]
	TIME [epoch: 6.57 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_155.pth
	Model improved!!!
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.16106747340817		[learning rate: 0.0077891]
	Learning Rate: 0.0077891
	LOSS [training: 1.16106747340817 | validation: 1.2253511501389]
	TIME [epoch: 6.57 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1929583094922838		[learning rate: 0.0077707]
	Learning Rate: 0.00777072
	LOSS [training: 1.1929583094922838 | validation: 0.7841061854928597]
	TIME [epoch: 6.54 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_157.pth
	Model improved!!!
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1489138433492059		[learning rate: 0.0077524]
	Learning Rate: 0.00775239
	LOSS [training: 1.1489138433492059 | validation: 0.9665271898237527]
	TIME [epoch: 6.54 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6793314477428762		[learning rate: 0.0077341]
	Learning Rate: 0.00773411
	LOSS [training: 1.6793314477428762 | validation: 0.9267318198550019]
	TIME [epoch: 6.54 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0781205529044935		[learning rate: 0.0077159]
	Learning Rate: 0.00771586
	LOSS [training: 1.0781205529044935 | validation: 0.7814616946526974]
	TIME [epoch: 6.55 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_160.pth
	Model improved!!!
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0352762848178731		[learning rate: 0.0076977]
	Learning Rate: 0.00769766
	LOSS [training: 1.0352762848178731 | validation: 0.7239288360163252]
	TIME [epoch: 6.58 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_161.pth
	Model improved!!!
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0330679434518681		[learning rate: 0.0076795]
	Learning Rate: 0.00767951
	LOSS [training: 1.0330679434518681 | validation: 0.7380340305520867]
	TIME [epoch: 6.54 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0160371905780332		[learning rate: 0.0076614]
	Learning Rate: 0.00766139
	LOSS [training: 1.0160371905780332 | validation: 0.943453548472704]
	TIME [epoch: 6.53 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2575003361335173		[learning rate: 0.0076433]
	Learning Rate: 0.00764332
	LOSS [training: 1.2575003361335173 | validation: 0.773732268851131]
	TIME [epoch: 6.52 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5984579777044232		[learning rate: 0.0076253]
	Learning Rate: 0.00762529
	LOSS [training: 1.5984579777044232 | validation: 0.7958904992693854]
	TIME [epoch: 6.51 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0203786470210063		[learning rate: 0.0076073]
	Learning Rate: 0.0076073
	LOSS [training: 1.0203786470210063 | validation: 0.6997534739298927]
	TIME [epoch: 6.54 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_166.pth
	Model improved!!!
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9526819321373063		[learning rate: 0.0075894]
	Learning Rate: 0.00758936
	LOSS [training: 0.9526819321373063 | validation: 0.6744502827590153]
	TIME [epoch: 6.56 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_167.pth
	Model improved!!!
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9648079352054533		[learning rate: 0.0075715]
	Learning Rate: 0.00757146
	LOSS [training: 0.9648079352054533 | validation: 0.7336321833105879]
	TIME [epoch: 6.54 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9733763469708588		[learning rate: 0.0075536]
	Learning Rate: 0.0075536
	LOSS [training: 0.9733763469708588 | validation: 0.8077540805304456]
	TIME [epoch: 6.53 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0510122789919447		[learning rate: 0.0075358]
	Learning Rate: 0.00753578
	LOSS [training: 1.0510122789919447 | validation: 0.6567154729864968]
	TIME [epoch: 6.53 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_170.pth
	Model improved!!!
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9361434711513803		[learning rate: 0.007518]
	Learning Rate: 0.007518
	LOSS [training: 0.9361434711513803 | validation: 0.6749701617006313]
	TIME [epoch: 6.54 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9331609044783662		[learning rate: 0.0075003]
	Learning Rate: 0.00750027
	LOSS [training: 0.9331609044783662 | validation: 0.7839828495647885]
	TIME [epoch: 6.58 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.961529273200776		[learning rate: 0.0074826]
	Learning Rate: 0.00748258
	LOSS [training: 0.961529273200776 | validation: 0.7061593054049999]
	TIME [epoch: 6.54 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9662286230632947		[learning rate: 0.0074649]
	Learning Rate: 0.00746493
	LOSS [training: 0.9662286230632947 | validation: 2.6065044270014375]
	TIME [epoch: 6.54 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6484779858562633		[learning rate: 0.0074473]
	Learning Rate: 0.00744732
	LOSS [training: 1.6484779858562633 | validation: 0.6656768890720577]
	TIME [epoch: 6.54 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9401546612909305		[learning rate: 0.0074298]
	Learning Rate: 0.00742975
	LOSS [training: 0.9401546612909305 | validation: 0.7213325825294867]
	TIME [epoch: 6.54 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9217819003729263		[learning rate: 0.0074122]
	Learning Rate: 0.00741223
	LOSS [training: 0.9217819003729263 | validation: 0.6272285710094988]
	TIME [epoch: 6.55 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_177.pth
	Model improved!!!
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.913412510225901		[learning rate: 0.0073947]
	Learning Rate: 0.00739474
	LOSS [training: 0.913412510225901 | validation: 0.6447239209535134]
	TIME [epoch: 6.57 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9321155231867632		[learning rate: 0.0073773]
	Learning Rate: 0.0073773
	LOSS [training: 0.9321155231867632 | validation: 0.6743068543262933]
	TIME [epoch: 6.54 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9559349039012746		[learning rate: 0.0073599]
	Learning Rate: 0.0073599
	LOSS [training: 0.9559349039012746 | validation: 0.6552391331477307]
	TIME [epoch: 6.54 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.956011809575697		[learning rate: 0.0073425]
	Learning Rate: 0.00734254
	LOSS [training: 0.956011809575697 | validation: 0.7431163219763639]
	TIME [epoch: 6.53 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9512763347404979		[learning rate: 0.0073252]
	Learning Rate: 0.00732522
	LOSS [training: 0.9512763347404979 | validation: 0.710312431998454]
	TIME [epoch: 6.54 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0930725935373864		[learning rate: 0.0073079]
	Learning Rate: 0.00730794
	LOSS [training: 1.0930725935373864 | validation: 0.6620687076557593]
	TIME [epoch: 6.56 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2674682573322678		[learning rate: 0.0072907]
	Learning Rate: 0.0072907
	LOSS [training: 1.2674682573322678 | validation: 0.816026373075307]
	TIME [epoch: 6.56 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.02212448023564		[learning rate: 0.0072735]
	Learning Rate: 0.0072735
	LOSS [training: 1.02212448023564 | validation: 0.690570919364824]
	TIME [epoch: 6.53 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0572452890290183		[learning rate: 0.0072563]
	Learning Rate: 0.00725635
	LOSS [training: 1.0572452890290183 | validation: 0.6435732788167949]
	TIME [epoch: 6.54 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9669636656921934		[learning rate: 0.0072392]
	Learning Rate: 0.00723923
	LOSS [training: 0.9669636656921934 | validation: 0.65260311471411]
	TIME [epoch: 6.54 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9356613305996863		[learning rate: 0.0072222]
	Learning Rate: 0.00722215
	LOSS [training: 0.9356613305996863 | validation: 0.7049241668557276]
	TIME [epoch: 6.54 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9075704663674772		[learning rate: 0.0072051]
	Learning Rate: 0.00720512
	LOSS [training: 0.9075704663674772 | validation: 0.601848464824411]
	TIME [epoch: 6.59 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_189.pth
	Model improved!!!
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9036975913096768		[learning rate: 0.0071881]
	Learning Rate: 0.00718812
	LOSS [training: 0.9036975913096768 | validation: 0.684331281781357]
	TIME [epoch: 6.59 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9201991715397743		[learning rate: 0.0071712]
	Learning Rate: 0.00717117
	LOSS [training: 0.9201991715397743 | validation: 0.6563931915170571]
	TIME [epoch: 6.58 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9939016399643663		[learning rate: 0.0071542]
	Learning Rate: 0.00715425
	LOSS [training: 0.9939016399643663 | validation: 0.8118577623398249]
	TIME [epoch: 6.58 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9521815467024762		[learning rate: 0.0071374]
	Learning Rate: 0.00713737
	LOSS [training: 0.9521815467024762 | validation: 0.6103556550752575]
	TIME [epoch: 6.58 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9113349855626645		[learning rate: 0.0071205]
	Learning Rate: 0.00712054
	LOSS [training: 0.9113349855626645 | validation: 0.6537231859077861]
	TIME [epoch: 6.59 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8901344917210692		[learning rate: 0.0071037]
	Learning Rate: 0.00710374
	LOSS [training: 0.8901344917210692 | validation: 0.7011566302552057]
	TIME [epoch: 6.62 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9374424454504711		[learning rate: 0.007087]
	Learning Rate: 0.00708698
	LOSS [training: 0.9374424454504711 | validation: 0.6280660318242242]
	TIME [epoch: 6.58 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9156110127658987		[learning rate: 0.0070703]
	Learning Rate: 0.00707027
	LOSS [training: 0.9156110127658987 | validation: 0.6915094867745601]
	TIME [epoch: 6.58 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.94614344191736		[learning rate: 0.0070536]
	Learning Rate: 0.00705359
	LOSS [training: 0.94614344191736 | validation: 0.6105688757069045]
	TIME [epoch: 6.58 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9173207446586599		[learning rate: 0.007037]
	Learning Rate: 0.00703695
	LOSS [training: 0.9173207446586599 | validation: 0.6136004862322202]
	TIME [epoch: 6.57 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.899104751514686		[learning rate: 0.0070204]
	Learning Rate: 0.00702035
	LOSS [training: 0.899104751514686 | validation: 0.7007169683007928]
	TIME [epoch: 6.62 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2849186791718545		[learning rate: 0.0070038]
	Learning Rate: 0.00700379
	LOSS [training: 1.2849186791718545 | validation: 0.9270151973477243]
	TIME [epoch: 6.59 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1781480443936239		[learning rate: 0.0069873]
	Learning Rate: 0.00698727
	LOSS [training: 1.1781480443936239 | validation: 1.161917061567654]
	TIME [epoch: 6.58 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1327256507388719		[learning rate: 0.0069708]
	Learning Rate: 0.00697079
	LOSS [training: 1.1327256507388719 | validation: 0.8863488830317876]
	TIME [epoch: 6.58 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9725751072304962		[learning rate: 0.0069543]
	Learning Rate: 0.00695435
	LOSS [training: 0.9725751072304962 | validation: 0.6187491478384668]
	TIME [epoch: 6.58 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8948466657397398		[learning rate: 0.0069379]
	Learning Rate: 0.00693794
	LOSS [training: 0.8948466657397398 | validation: 0.6144102427777777]
	TIME [epoch: 6.58 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9559002703542874		[learning rate: 0.0069216]
	Learning Rate: 0.00692158
	LOSS [training: 0.9559002703542874 | validation: 0.6346216949504437]
	TIME [epoch: 6.62 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8958593229507574		[learning rate: 0.0069053]
	Learning Rate: 0.00690525
	LOSS [training: 0.8958593229507574 | validation: 0.6114477686346613]
	TIME [epoch: 6.58 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8602583335514995		[learning rate: 0.006889]
	Learning Rate: 0.00688896
	LOSS [training: 0.8602583335514995 | validation: 0.6226720126989382]
	TIME [epoch: 6.58 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9022264804526486		[learning rate: 0.0068727]
	Learning Rate: 0.00687271
	LOSS [training: 0.9022264804526486 | validation: 0.5774739239624119]
	TIME [epoch: 6.58 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_209.pth
	Model improved!!!
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8882784376656268		[learning rate: 0.0068565]
	Learning Rate: 0.0068565
	LOSS [training: 0.8882784376656268 | validation: 0.5837409799771822]
	TIME [epoch: 6.58 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.887325770481673		[learning rate: 0.0068403]
	Learning Rate: 0.00684033
	LOSS [training: 0.887325770481673 | validation: 0.5708780753474009]
	TIME [epoch: 6.6 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_211.pth
	Model improved!!!
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8663573555691162		[learning rate: 0.0068242]
	Learning Rate: 0.00682419
	LOSS [training: 0.8663573555691162 | validation: 0.6346345268399682]
	TIME [epoch: 6.61 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9919436884069508		[learning rate: 0.0068081]
	Learning Rate: 0.0068081
	LOSS [training: 0.9919436884069508 | validation: 0.6156736035433537]
	TIME [epoch: 6.57 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8805248266777799		[learning rate: 0.006792]
	Learning Rate: 0.00679204
	LOSS [training: 0.8805248266777799 | validation: 0.5528639418595653]
	TIME [epoch: 6.57 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_214.pth
	Model improved!!!
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8833557741983302		[learning rate: 0.006776]
	Learning Rate: 0.00677601
	LOSS [training: 0.8833557741983302 | validation: 0.555689412291735]
	TIME [epoch: 6.58 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8547101336944933		[learning rate: 0.00676]
	Learning Rate: 0.00676003
	LOSS [training: 0.8547101336944933 | validation: 0.5817081040870314]
	TIME [epoch: 6.58 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.849400524165624		[learning rate: 0.0067441]
	Learning Rate: 0.00674409
	LOSS [training: 0.849400524165624 | validation: 0.568698158557026]
	TIME [epoch: 6.63 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9311139864511404		[learning rate: 0.0067282]
	Learning Rate: 0.00672818
	LOSS [training: 0.9311139864511404 | validation: 0.5688269202031139]
	TIME [epoch: 6.59 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8442326962179629		[learning rate: 0.0067123]
	Learning Rate: 0.00671231
	LOSS [training: 0.8442326962179629 | validation: 0.5775033087792147]
	TIME [epoch: 6.55 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.881016724917339		[learning rate: 0.0066965]
	Learning Rate: 0.00669647
	LOSS [training: 0.881016724917339 | validation: 0.5727360191863486]
	TIME [epoch: 6.54 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8607569893579656		[learning rate: 0.0066807]
	Learning Rate: 0.00668068
	LOSS [training: 0.8607569893579656 | validation: 0.6444981870328721]
	TIME [epoch: 6.58 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8793143603418929		[learning rate: 0.0066649]
	Learning Rate: 0.00666492
	LOSS [training: 0.8793143603418929 | validation: 0.6518899373833111]
	TIME [epoch: 6.6 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9980464362052025		[learning rate: 0.0066492]
	Learning Rate: 0.0066492
	LOSS [training: 0.9980464362052025 | validation: 0.6355147547899956]
	TIME [epoch: 6.62 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1454580286005727		[learning rate: 0.0066335]
	Learning Rate: 0.00663351
	LOSS [training: 1.1454580286005727 | validation: 0.594758116490646]
	TIME [epoch: 6.59 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8505944590645477		[learning rate: 0.0066179]
	Learning Rate: 0.00661787
	LOSS [training: 0.8505944590645477 | validation: 0.6638845462155132]
	TIME [epoch: 6.57 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8487524621077768		[learning rate: 0.0066023]
	Learning Rate: 0.00660226
	LOSS [training: 0.8487524621077768 | validation: 0.31908451230490753]
	TIME [epoch: 6.57 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_226.pth
	Model improved!!!
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7487704899144436		[learning rate: 0.0065867]
	Learning Rate: 0.00658668
	LOSS [training: 0.7487704899144436 | validation: 0.5612784601654044]
	TIME [epoch: 6.56 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7609370397179243		[learning rate: 0.0065711]
	Learning Rate: 0.00657114
	LOSS [training: 0.7609370397179243 | validation: 0.5129269833422369]
	TIME [epoch: 6.59 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49348552528016115		[learning rate: 0.0065556]
	Learning Rate: 0.00655564
	LOSS [training: 0.49348552528016115 | validation: 0.2881501541684113]
	TIME [epoch: 6.58 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_229.pth
	Model improved!!!
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4508117568394178		[learning rate: 0.0065402]
	Learning Rate: 0.00654018
	LOSS [training: 0.4508117568394178 | validation: 0.38987637963849586]
	TIME [epoch: 6.57 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3536035616977123		[learning rate: 0.0065248]
	Learning Rate: 0.00652475
	LOSS [training: 0.3536035616977123 | validation: 0.27977500681944006]
	TIME [epoch: 6.56 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_231.pth
	Model improved!!!
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8951620593296606		[learning rate: 0.0065094]
	Learning Rate: 0.00650936
	LOSS [training: 0.8951620593296606 | validation: 0.4516135746948361]
	TIME [epoch: 6.57 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4963825621320847		[learning rate: 0.006494]
	Learning Rate: 0.00649401
	LOSS [training: 0.4963825621320847 | validation: 0.265125777958023]
	TIME [epoch: 6.57 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_233.pth
	Model improved!!!
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34443531936296334		[learning rate: 0.0064787]
	Learning Rate: 0.00647869
	LOSS [training: 0.34443531936296334 | validation: 0.2376427644543327]
	TIME [epoch: 6.6 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_234.pth
	Model improved!!!
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31438028100358806		[learning rate: 0.0064634]
	Learning Rate: 0.00646341
	LOSS [training: 0.31438028100358806 | validation: 0.20964675385246764]
	TIME [epoch: 6.55 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_235.pth
	Model improved!!!
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5057010970164025		[learning rate: 0.0064482]
	Learning Rate: 0.00644816
	LOSS [training: 0.5057010970164025 | validation: 0.8968385372780923]
	TIME [epoch: 6.55 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7511711568975834		[learning rate: 0.006433]
	Learning Rate: 0.00643295
	LOSS [training: 0.7511711568975834 | validation: 0.8782597224262636]
	TIME [epoch: 6.55 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49189855144573924		[learning rate: 0.0064178]
	Learning Rate: 0.00641778
	LOSS [training: 0.49189855144573924 | validation: 0.2421471410849359]
	TIME [epoch: 6.55 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0557618696528506		[learning rate: 0.0064026]
	Learning Rate: 0.00640264
	LOSS [training: 1.0557618696528506 | validation: 0.4824187773661435]
	TIME [epoch: 6.59 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42453962806121737		[learning rate: 0.0063875]
	Learning Rate: 0.00638754
	LOSS [training: 0.42453962806121737 | validation: 0.22339779414188526]
	TIME [epoch: 6.56 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.090256997558231		[learning rate: 0.0063725]
	Learning Rate: 0.00637247
	LOSS [training: 1.090256997558231 | validation: 0.8902151747208319]
	TIME [epoch: 6.55 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8020995835816569		[learning rate: 0.0063574]
	Learning Rate: 0.00635744
	LOSS [training: 0.8020995835816569 | validation: 0.35714375022131506]
	TIME [epoch: 6.55 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3567657194867365		[learning rate: 0.0063424]
	Learning Rate: 0.00634244
	LOSS [training: 0.3567657194867365 | validation: 0.22769133935211028]
	TIME [epoch: 6.55 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22469745920536077		[learning rate: 0.0063275]
	Learning Rate: 0.00632748
	LOSS [training: 0.22469745920536077 | validation: 0.2085829152544417]
	TIME [epoch: 6.55 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_244.pth
	Model improved!!!
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24953933096822753		[learning rate: 0.0063126]
	Learning Rate: 0.00631255
	LOSS [training: 0.24953933096822753 | validation: 0.3291365348513149]
	TIME [epoch: 6.6 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29584136698878033		[learning rate: 0.0062977]
	Learning Rate: 0.00629766
	LOSS [training: 0.29584136698878033 | validation: 0.26872952236584957]
	TIME [epoch: 6.56 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30355089523063344		[learning rate: 0.0062828]
	Learning Rate: 0.00628281
	LOSS [training: 0.30355089523063344 | validation: 0.21281642125833494]
	TIME [epoch: 6.56 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24636881211495282		[learning rate: 0.006268]
	Learning Rate: 0.00626799
	LOSS [training: 0.24636881211495282 | validation: 0.198621912650362]
	TIME [epoch: 6.56 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_248.pth
	Model improved!!!
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22688746396076426		[learning rate: 0.0062532]
	Learning Rate: 0.0062532
	LOSS [training: 0.22688746396076426 | validation: 0.2367545302058356]
	TIME [epoch: 6.55 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2869501407919867		[learning rate: 0.0062385]
	Learning Rate: 0.00623845
	LOSS [training: 0.2869501407919867 | validation: 0.2233462039575233]
	TIME [epoch: 6.56 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23878371676991855		[learning rate: 0.0062237]
	Learning Rate: 0.00622374
	LOSS [training: 0.23878371676991855 | validation: 0.3563722639801779]
	TIME [epoch: 6.57 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2907921793132455		[learning rate: 0.0062091]
	Learning Rate: 0.00620906
	LOSS [training: 0.2907921793132455 | validation: 0.1704090764900983]
	TIME [epoch: 6.54 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_252.pth
	Model improved!!!
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3739513080705401		[learning rate: 0.0061944]
	Learning Rate: 0.00619441
	LOSS [training: 0.3739513080705401 | validation: 0.2654725836372809]
	TIME [epoch: 6.54 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23703583152692778		[learning rate: 0.0061798]
	Learning Rate: 0.0061798
	LOSS [training: 0.23703583152692778 | validation: 0.21149772218461618]
	TIME [epoch: 6.54 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21275942015176597		[learning rate: 0.0061652]
	Learning Rate: 0.00616522
	LOSS [training: 0.21275942015176597 | validation: 0.17815113321218093]
	TIME [epoch: 6.54 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22476132374202207		[learning rate: 0.0061507]
	Learning Rate: 0.00615068
	LOSS [training: 0.22476132374202207 | validation: 0.21336803797308246]
	TIME [epoch: 6.58 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2266185582063772		[learning rate: 0.0061362]
	Learning Rate: 0.00613617
	LOSS [training: 0.2266185582063772 | validation: 0.17424987480557835]
	TIME [epoch: 6.55 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21267649693801216		[learning rate: 0.0061217]
	Learning Rate: 0.0061217
	LOSS [training: 0.21267649693801216 | validation: 0.15821261460879416]
	TIME [epoch: 6.54 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_258.pth
	Model improved!!!
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1867371507489226		[learning rate: 0.0061073]
	Learning Rate: 0.00610726
	LOSS [training: 0.1867371507489226 | validation: 0.2320474804767343]
	TIME [epoch: 6.55 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24715839949051072		[learning rate: 0.0060929]
	Learning Rate: 0.00609285
	LOSS [training: 0.24715839949051072 | validation: 0.25004790300208024]
	TIME [epoch: 6.55 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5197327682354888		[learning rate: 0.0060785]
	Learning Rate: 0.00607848
	LOSS [training: 0.5197327682354888 | validation: 0.3272879350537311]
	TIME [epoch: 6.55 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3106027440670338		[learning rate: 0.0060641]
	Learning Rate: 0.00606414
	LOSS [training: 0.3106027440670338 | validation: 0.1590628329909874]
	TIME [epoch: 6.58 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1891458363672471		[learning rate: 0.0060498]
	Learning Rate: 0.00604984
	LOSS [training: 0.1891458363672471 | validation: 0.14929315129670173]
	TIME [epoch: 6.55 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_263.pth
	Model improved!!!
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4538536450857382		[learning rate: 0.0060356]
	Learning Rate: 0.00603556
	LOSS [training: 0.4538536450857382 | validation: 1.270322491575845]
	TIME [epoch: 6.54 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5761198958044412		[learning rate: 0.0060213]
	Learning Rate: 0.00602133
	LOSS [training: 0.5761198958044412 | validation: 0.22355696499224642]
	TIME [epoch: 6.55 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23840768943682997		[learning rate: 0.0060071]
	Learning Rate: 0.00600712
	LOSS [training: 0.23840768943682997 | validation: 0.18987767756586632]
	TIME [epoch: 6.53 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3726272786690915		[learning rate: 0.005993]
	Learning Rate: 0.00599296
	LOSS [training: 0.3726272786690915 | validation: 0.2942285815681895]
	TIME [epoch: 6.57 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22363597513627304		[learning rate: 0.0059788]
	Learning Rate: 0.00597882
	LOSS [training: 0.22363597513627304 | validation: 0.2766008251768028]
	TIME [epoch: 6.57 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22017584353408332		[learning rate: 0.0059647]
	Learning Rate: 0.00596472
	LOSS [training: 0.22017584353408332 | validation: 0.1844388297727112]
	TIME [epoch: 6.53 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20960700571575516		[learning rate: 0.0059506]
	Learning Rate: 0.00595065
	LOSS [training: 0.20960700571575516 | validation: 0.16383063652982605]
	TIME [epoch: 6.55 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2063549263480841		[learning rate: 0.0059366]
	Learning Rate: 0.00593661
	LOSS [training: 0.2063549263480841 | validation: 0.19500324618102288]
	TIME [epoch: 6.54 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21078166634863477		[learning rate: 0.0059226]
	Learning Rate: 0.00592261
	LOSS [training: 0.21078166634863477 | validation: 0.2925767842244603]
	TIME [epoch: 6.53 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25830548542285725		[learning rate: 0.0059086]
	Learning Rate: 0.00590863
	LOSS [training: 0.25830548542285725 | validation: 0.17900120337365988]
	TIME [epoch: 6.55 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22191264929927587		[learning rate: 0.0058947]
	Learning Rate: 0.0058947
	LOSS [training: 0.22191264929927587 | validation: 0.14102468307195576]
	TIME [epoch: 6.52 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_274.pth
	Model improved!!!
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20407400853431498		[learning rate: 0.0058808]
	Learning Rate: 0.00588079
	LOSS [training: 0.20407400853431498 | validation: 0.18252651495872518]
	TIME [epoch: 6.55 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17433676714602914		[learning rate: 0.0058669]
	Learning Rate: 0.00586692
	LOSS [training: 0.17433676714602914 | validation: 0.1558249965351277]
	TIME [epoch: 6.56 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.192513959282695		[learning rate: 0.0058531]
	Learning Rate: 0.00585308
	LOSS [training: 0.192513959282695 | validation: 0.17354790396961162]
	TIME [epoch: 6.56 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6420113152591665		[learning rate: 0.0058393]
	Learning Rate: 0.00583928
	LOSS [training: 0.6420113152591665 | validation: 0.6218504244033181]
	TIME [epoch: 6.57 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7022750787678352		[learning rate: 0.0058255]
	Learning Rate: 0.0058255
	LOSS [training: 0.7022750787678352 | validation: 0.4883629331263196]
	TIME [epoch: 6.59 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4767600794390325		[learning rate: 0.0058118]
	Learning Rate: 0.00581176
	LOSS [training: 0.4767600794390325 | validation: 0.3093008365395337]
	TIME [epoch: 6.56 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30529481879456083		[learning rate: 0.0057981]
	Learning Rate: 0.00579805
	LOSS [training: 0.30529481879456083 | validation: 0.2778312089479432]
	TIME [epoch: 6.56 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5133505656124621		[learning rate: 0.0057844]
	Learning Rate: 0.00578438
	LOSS [training: 0.5133505656124621 | validation: 0.3153574595674352]
	TIME [epoch: 6.56 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24264567299475778		[learning rate: 0.0057707]
	Learning Rate: 0.00577073
	LOSS [training: 0.24264567299475778 | validation: 0.1429912557610018]
	TIME [epoch: 6.56 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18741984118720992		[learning rate: 0.0057571]
	Learning Rate: 0.00575712
	LOSS [training: 0.18741984118720992 | validation: 0.16037729742931334]
	TIME [epoch: 6.59 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22693523982093816		[learning rate: 0.0057435]
	Learning Rate: 0.00574354
	LOSS [training: 0.22693523982093816 | validation: 0.23866111124097433]
	TIME [epoch: 6.58 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3111566590521456		[learning rate: 0.00573]
	Learning Rate: 0.00572999
	LOSS [training: 0.3111566590521456 | validation: 0.14855976673832647]
	TIME [epoch: 6.56 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18218939080364727		[learning rate: 0.0057165]
	Learning Rate: 0.00571647
	LOSS [training: 0.18218939080364727 | validation: 0.14592640201889903]
	TIME [epoch: 6.56 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16129462769912054		[learning rate: 0.005703]
	Learning Rate: 0.00570299
	LOSS [training: 0.16129462769912054 | validation: 0.1276926759755269]
	TIME [epoch: 6.56 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_288.pth
	Model improved!!!
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17334169741985997		[learning rate: 0.0056895]
	Learning Rate: 0.00568954
	LOSS [training: 0.17334169741985997 | validation: 0.16351050087505695]
	TIME [epoch: 6.56 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3151449346460682		[learning rate: 0.0056761]
	Learning Rate: 0.00567612
	LOSS [training: 0.3151449346460682 | validation: 0.20015047915053824]
	TIME [epoch: 6.58 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27164324332365214		[learning rate: 0.0056627]
	Learning Rate: 0.00566273
	LOSS [training: 0.27164324332365214 | validation: 0.17569964885279254]
	TIME [epoch: 6.57 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5182628801254745		[learning rate: 0.0056494]
	Learning Rate: 0.00564937
	LOSS [training: 0.5182628801254745 | validation: 0.22625980855185046]
	TIME [epoch: 6.56 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23348034220495753		[learning rate: 0.005636]
	Learning Rate: 0.00563604
	LOSS [training: 0.23348034220495753 | validation: 0.14379209414731295]
	TIME [epoch: 6.55 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19755241217028174		[learning rate: 0.0056227]
	Learning Rate: 0.00562275
	LOSS [training: 0.19755241217028174 | validation: 0.1600203660672985]
	TIME [epoch: 6.55 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18305796681452582		[learning rate: 0.0056095]
	Learning Rate: 0.00560949
	LOSS [training: 0.18305796681452582 | validation: 0.12980721293765576]
	TIME [epoch: 6.56 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14880167356574225		[learning rate: 0.0055963]
	Learning Rate: 0.00559625
	LOSS [training: 0.14880167356574225 | validation: 0.15652358315305964]
	TIME [epoch: 6.6 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2705726698891878		[learning rate: 0.0055831]
	Learning Rate: 0.00558305
	LOSS [training: 0.2705726698891878 | validation: 0.14928998985562392]
	TIME [epoch: 6.56 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21341684868109576		[learning rate: 0.0055699]
	Learning Rate: 0.00556988
	LOSS [training: 0.21341684868109576 | validation: 0.13297430336617244]
	TIME [epoch: 6.56 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1372447650714997		[learning rate: 0.0055567]
	Learning Rate: 0.00555674
	LOSS [training: 0.1372447650714997 | validation: 0.1184475964461776]
	TIME [epoch: 6.56 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_299.pth
	Model improved!!!
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1995493482580054		[learning rate: 0.0055436]
	Learning Rate: 0.00554364
	LOSS [training: 0.1995493482580054 | validation: 0.1383413118713902]
	TIME [epoch: 6.56 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22607404666285852		[learning rate: 0.0055306]
	Learning Rate: 0.00553056
	LOSS [training: 0.22607404666285852 | validation: 0.36538617637335036]
	TIME [epoch: 6.57 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4159626202003076		[learning rate: 0.0055175]
	Learning Rate: 0.00551752
	LOSS [training: 0.4159626202003076 | validation: 0.2122044166305258]
	TIME [epoch: 6.59 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17668908579248743		[learning rate: 0.0055045]
	Learning Rate: 0.0055045
	LOSS [training: 0.17668908579248743 | validation: 0.15333877038043223]
	TIME [epoch: 6.56 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16266774059625086		[learning rate: 0.0054915]
	Learning Rate: 0.00549152
	LOSS [training: 0.16266774059625086 | validation: 0.11225392787398733]
	TIME [epoch: 6.56 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_304.pth
	Model improved!!!
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15167515750492164		[learning rate: 0.0054786]
	Learning Rate: 0.00547856
	LOSS [training: 0.15167515750492164 | validation: 0.14222254543410504]
	TIME [epoch: 6.54 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18668044026685765		[learning rate: 0.0054656]
	Learning Rate: 0.00546564
	LOSS [training: 0.18668044026685765 | validation: 0.13852215524818404]
	TIME [epoch: 6.55 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16107994334851838		[learning rate: 0.0054527]
	Learning Rate: 0.00545275
	LOSS [training: 0.16107994334851838 | validation: 0.1306693498005474]
	TIME [epoch: 6.59 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21279221516851382		[learning rate: 0.0054399]
	Learning Rate: 0.00543988
	LOSS [training: 0.21279221516851382 | validation: 0.4945867886982005]
	TIME [epoch: 6.56 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24847108521673622		[learning rate: 0.0054271]
	Learning Rate: 0.00542705
	LOSS [training: 0.24847108521673622 | validation: 0.15486838774587508]
	TIME [epoch: 6.54 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15103293927760614		[learning rate: 0.0054143]
	Learning Rate: 0.00541425
	LOSS [training: 0.15103293927760614 | validation: 0.13901025787757337]
	TIME [epoch: 6.55 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16594292120832613		[learning rate: 0.0054015]
	Learning Rate: 0.00540148
	LOSS [training: 0.16594292120832613 | validation: 0.13624068138630754]
	TIME [epoch: 6.55 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16810110560330602		[learning rate: 0.0053887]
	Learning Rate: 0.00538874
	LOSS [training: 0.16810110560330602 | validation: 0.21324597630439684]
	TIME [epoch: 6.55 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4475108541272858		[learning rate: 0.005376]
	Learning Rate: 0.00537603
	LOSS [training: 0.4475108541272858 | validation: 0.1361298565550066]
	TIME [epoch: 6.59 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14549327540012996		[learning rate: 0.0053633]
	Learning Rate: 0.00536335
	LOSS [training: 0.14549327540012996 | validation: 0.09023325000816998]
	TIME [epoch: 6.56 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_314.pth
	Model improved!!!
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1267509852470093		[learning rate: 0.0053507]
	Learning Rate: 0.00535069
	LOSS [training: 0.1267509852470093 | validation: 0.1276524826833163]
	TIME [epoch: 6.55 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14709472794870193		[learning rate: 0.0053381]
	Learning Rate: 0.00533807
	LOSS [training: 0.14709472794870193 | validation: 0.11297135098844875]
	TIME [epoch: 6.54 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15334285197274944		[learning rate: 0.0053255]
	Learning Rate: 0.00532548
	LOSS [training: 0.15334285197274944 | validation: 0.14014255747587473]
	TIME [epoch: 6.54 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17108554435939066		[learning rate: 0.0053129]
	Learning Rate: 0.00531292
	LOSS [training: 0.17108554435939066 | validation: 0.11313628734471617]
	TIME [epoch: 6.55 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12950857466257268		[learning rate: 0.0053004]
	Learning Rate: 0.00530039
	LOSS [training: 0.12950857466257268 | validation: 0.11953784262909684]
	TIME [epoch: 6.58 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14096015673981552		[learning rate: 0.0052879]
	Learning Rate: 0.00528789
	LOSS [training: 0.14096015673981552 | validation: 0.18458248732844512]
	TIME [epoch: 6.54 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1727472367030859		[learning rate: 0.0052754]
	Learning Rate: 0.00527541
	LOSS [training: 0.1727472367030859 | validation: 0.17531198287196137]
	TIME [epoch: 6.54 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4778766121266833		[learning rate: 0.005263]
	Learning Rate: 0.00526297
	LOSS [training: 0.4778766121266833 | validation: 0.40555667509541793]
	TIME [epoch: 6.54 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.268179725284828		[learning rate: 0.0052506]
	Learning Rate: 0.00525055
	LOSS [training: 0.268179725284828 | validation: 0.11278458904044035]
	TIME [epoch: 6.54 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18836335982010566		[learning rate: 0.0052382]
	Learning Rate: 0.00523817
	LOSS [training: 0.18836335982010566 | validation: 0.18762252951483016]
	TIME [epoch: 6.56 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17215433641627728		[learning rate: 0.0052258]
	Learning Rate: 0.00522581
	LOSS [training: 0.17215433641627728 | validation: 0.17146609968337811]
	TIME [epoch: 6.56 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15684788328923618		[learning rate: 0.0052135]
	Learning Rate: 0.00521349
	LOSS [training: 0.15684788328923618 | validation: 0.09517755697064274]
	TIME [epoch: 6.54 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.139116382938518		[learning rate: 0.0052012]
	Learning Rate: 0.00520119
	LOSS [training: 0.139116382938518 | validation: 0.08976229392186061]
	TIME [epoch: 6.54 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_327.pth
	Model improved!!!
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11326138450321117		[learning rate: 0.0051889]
	Learning Rate: 0.00518892
	LOSS [training: 0.11326138450321117 | validation: 0.08159090370123774]
	TIME [epoch: 6.53 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_328.pth
	Model improved!!!
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1597818498216546		[learning rate: 0.0051767]
	Learning Rate: 0.00517668
	LOSS [training: 0.1597818498216546 | validation: 0.16659917476498404]
	TIME [epoch: 6.52 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15823239922032703		[learning rate: 0.0051645]
	Learning Rate: 0.00516447
	LOSS [training: 0.15823239922032703 | validation: 0.17568699512653374]
	TIME [epoch: 6.56 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13624228565679045		[learning rate: 0.0051523]
	Learning Rate: 0.00515229
	LOSS [training: 0.13624228565679045 | validation: 0.11364667515127809]
	TIME [epoch: 6.54 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11391922917175754		[learning rate: 0.0051401]
	Learning Rate: 0.00514013
	LOSS [training: 0.11391922917175754 | validation: 0.08490584052788436]
	TIME [epoch: 6.53 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17076480977315697		[learning rate: 0.005128]
	Learning Rate: 0.00512801
	LOSS [training: 0.17076480977315697 | validation: 0.14255708437810868]
	TIME [epoch: 6.52 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15259095568242018		[learning rate: 0.0051159]
	Learning Rate: 0.00511591
	LOSS [training: 0.15259095568242018 | validation: 0.13231827196684773]
	TIME [epoch: 6.52 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13220716386270237		[learning rate: 0.0051038]
	Learning Rate: 0.00510384
	LOSS [training: 0.13220716386270237 | validation: 0.09336422014217996]
	TIME [epoch: 6.54 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14852587692255917		[learning rate: 0.0050918]
	Learning Rate: 0.00509181
	LOSS [training: 0.14852587692255917 | validation: 0.1334155304438816]
	TIME [epoch: 6.56 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15251864855355815		[learning rate: 0.0050798]
	Learning Rate: 0.00507979
	LOSS [training: 0.15251864855355815 | validation: 0.11736342314457963]
	TIME [epoch: 6.52 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11523082119023946		[learning rate: 0.0050678]
	Learning Rate: 0.00506781
	LOSS [training: 0.11523082119023946 | validation: 0.08349583828651083]
	TIME [epoch: 6.52 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11699034124586419		[learning rate: 0.0050559]
	Learning Rate: 0.00505586
	LOSS [training: 0.11699034124586419 | validation: 0.12105656978096184]
	TIME [epoch: 6.53 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12261992488756061		[learning rate: 0.0050439]
	Learning Rate: 0.00504393
	LOSS [training: 0.12261992488756061 | validation: 0.09114787861540917]
	TIME [epoch: 6.52 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1195073949464355		[learning rate: 0.005032]
	Learning Rate: 0.00503203
	LOSS [training: 0.1195073949464355 | validation: 0.34069474908276304]
	TIME [epoch: 6.56 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21052495906865434		[learning rate: 0.0050202]
	Learning Rate: 0.00502016
	LOSS [training: 0.21052495906865434 | validation: 0.11605770490179522]
	TIME [epoch: 6.54 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13540329401912934		[learning rate: 0.0050083]
	Learning Rate: 0.00500832
	LOSS [training: 0.13540329401912934 | validation: 0.08049357012836392]
	TIME [epoch: 6.53 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_343.pth
	Model improved!!!
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2053997244903763		[learning rate: 0.0049965]
	Learning Rate: 0.00499651
	LOSS [training: 0.2053997244903763 | validation: 0.3065855301812104]
	TIME [epoch: 6.51 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26425808316014		[learning rate: 0.0049847]
	Learning Rate: 0.00498472
	LOSS [training: 0.26425808316014 | validation: 0.10533227951287039]
	TIME [epoch: 6.51 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12097996483901467		[learning rate: 0.004973]
	Learning Rate: 0.00497296
	LOSS [training: 0.12097996483901467 | validation: 0.1272403198522295]
	TIME [epoch: 6.53 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13184007415947568		[learning rate: 0.0049612]
	Learning Rate: 0.00496123
	LOSS [training: 0.13184007415947568 | validation: 0.12451929228765697]
	TIME [epoch: 6.55 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12324280455617084		[learning rate: 0.0049495]
	Learning Rate: 0.00494953
	LOSS [training: 0.12324280455617084 | validation: 0.11844355877596202]
	TIME [epoch: 6.52 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18945310822097922		[learning rate: 0.0049379]
	Learning Rate: 0.00493786
	LOSS [training: 0.18945310822097922 | validation: 0.26079953678919165]
	TIME [epoch: 6.52 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23166345350530318		[learning rate: 0.0049262]
	Learning Rate: 0.00492621
	LOSS [training: 0.23166345350530318 | validation: 0.1317257169787279]
	TIME [epoch: 6.52 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20828575582529787		[learning rate: 0.0049146]
	Learning Rate: 0.00491459
	LOSS [training: 0.20828575582529787 | validation: 0.22707796881247932]
	TIME [epoch: 6.52 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19003244784317963		[learning rate: 0.004903]
	Learning Rate: 0.004903
	LOSS [training: 0.19003244784317963 | validation: 0.12950561395446356]
	TIME [epoch: 6.53 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20575207835311762		[learning rate: 0.0048914]
	Learning Rate: 0.00489143
	LOSS [training: 0.20575207835311762 | validation: 0.07339941112235135]
	TIME [epoch: 6.55 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_353.pth
	Model improved!!!
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1340539521348953		[learning rate: 0.0048799]
	Learning Rate: 0.00487989
	LOSS [training: 0.1340539521348953 | validation: 0.0918421478818901]
	TIME [epoch: 6.52 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11932303838916725		[learning rate: 0.0048684]
	Learning Rate: 0.00486838
	LOSS [training: 0.11932303838916725 | validation: 0.11312226342173254]
	TIME [epoch: 6.52 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1191198860908255		[learning rate: 0.0048569]
	Learning Rate: 0.0048569
	LOSS [training: 0.1191198860908255 | validation: 0.1020953843588392]
	TIME [epoch: 6.52 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11957562273967477		[learning rate: 0.0048454]
	Learning Rate: 0.00484544
	LOSS [training: 0.11957562273967477 | validation: 0.08941189579296416]
	TIME [epoch: 6.52 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11548300332346917		[learning rate: 0.004834]
	Learning Rate: 0.00483401
	LOSS [training: 0.11548300332346917 | validation: 0.09163377721617375]
	TIME [epoch: 6.55 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.143046152790586		[learning rate: 0.0048226]
	Learning Rate: 0.00482261
	LOSS [training: 0.143046152790586 | validation: 0.09562876140388556]
	TIME [epoch: 6.53 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1123048063900773		[learning rate: 0.0048112]
	Learning Rate: 0.00481123
	LOSS [training: 0.1123048063900773 | validation: 0.09277468808140293]
	TIME [epoch: 6.52 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1194768980777656		[learning rate: 0.0047999]
	Learning Rate: 0.00479988
	LOSS [training: 0.1194768980777656 | validation: 0.11503933069514108]
	TIME [epoch: 6.52 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1251189763683071		[learning rate: 0.0047886]
	Learning Rate: 0.00478856
	LOSS [training: 0.1251189763683071 | validation: 0.07296414837726245]
	TIME [epoch: 6.52 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_362.pth
	Model improved!!!
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16057465257698966		[learning rate: 0.0047773]
	Learning Rate: 0.00477727
	LOSS [training: 0.16057465257698966 | validation: 0.2994209041576985]
	TIME [epoch: 6.53 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4603032009196374		[learning rate: 0.004766]
	Learning Rate: 0.004766
	LOSS [training: 0.4603032009196374 | validation: 0.37474618466777865]
	TIME [epoch: 6.56 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2602356642667524		[learning rate: 0.0047548]
	Learning Rate: 0.00475476
	LOSS [training: 0.2602356642667524 | validation: 0.34691602688121653]
	TIME [epoch: 6.52 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2754102152643754		[learning rate: 0.0047435]
	Learning Rate: 0.00474354
	LOSS [training: 0.2754102152643754 | validation: 0.13469160614355383]
	TIME [epoch: 6.52 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14856671927201323		[learning rate: 0.0047324]
	Learning Rate: 0.00473235
	LOSS [training: 0.14856671927201323 | validation: 0.11212201607375721]
	TIME [epoch: 6.52 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11608322947429044		[learning rate: 0.0047212]
	Learning Rate: 0.00472119
	LOSS [training: 0.11608322947429044 | validation: 0.0858740138684713]
	TIME [epoch: 6.52 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17820170945985842		[learning rate: 0.0047101]
	Learning Rate: 0.00471005
	LOSS [training: 0.17820170945985842 | validation: 0.40760229416796645]
	TIME [epoch: 6.53 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1927369356942682		[learning rate: 0.0046989]
	Learning Rate: 0.00469894
	LOSS [training: 0.1927369356942682 | validation: 0.08224421644649446]
	TIME [epoch: 6.56 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22016319624259442		[learning rate: 0.0046879]
	Learning Rate: 0.00468786
	LOSS [training: 0.22016319624259442 | validation: 0.1909204308774889]
	TIME [epoch: 6.52 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13970227565105936		[learning rate: 0.0046768]
	Learning Rate: 0.0046768
	LOSS [training: 0.13970227565105936 | validation: 0.07826581401957572]
	TIME [epoch: 6.52 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10617983934211488		[learning rate: 0.0046658]
	Learning Rate: 0.00466577
	LOSS [training: 0.10617983934211488 | validation: 0.1998186565302999]
	TIME [epoch: 6.52 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15131752988247266		[learning rate: 0.0046548]
	Learning Rate: 0.00465476
	LOSS [training: 0.15131752988247266 | validation: 0.08961696553176414]
	TIME [epoch: 6.52 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1379175917391755		[learning rate: 0.0046438]
	Learning Rate: 0.00464378
	LOSS [training: 0.1379175917391755 | validation: 0.5781594634212299]
	TIME [epoch: 6.55 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4012287570452148		[learning rate: 0.0046328]
	Learning Rate: 0.00463283
	LOSS [training: 0.4012287570452148 | validation: 0.193556859578553]
	TIME [epoch: 6.54 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2748596697058244		[learning rate: 0.0046219]
	Learning Rate: 0.0046219
	LOSS [training: 0.2748596697058244 | validation: 0.1765973812630935]
	TIME [epoch: 6.52 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19901083005167083		[learning rate: 0.004611]
	Learning Rate: 0.004611
	LOSS [training: 0.19901083005167083 | validation: 0.17244145457806104]
	TIME [epoch: 6.52 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15515727472999002		[learning rate: 0.0046001]
	Learning Rate: 0.00460012
	LOSS [training: 0.15515727472999002 | validation: 0.07987964137897938]
	TIME [epoch: 6.52 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0894057272476372		[learning rate: 0.0045893]
	Learning Rate: 0.00458927
	LOSS [training: 0.0894057272476372 | validation: 0.11653156566850349]
	TIME [epoch: 6.52 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11403463188044234		[learning rate: 0.0045784]
	Learning Rate: 0.00457844
	LOSS [training: 0.11403463188044234 | validation: 0.0913655334970756]
	TIME [epoch: 6.56 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13053585306065865		[learning rate: 0.0045676]
	Learning Rate: 0.00456765
	LOSS [training: 0.13053585306065865 | validation: 0.5802776177127948]
	TIME [epoch: 6.52 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2935749818530758		[learning rate: 0.0045569]
	Learning Rate: 0.00455687
	LOSS [training: 0.2935749818530758 | validation: 0.0951229720586495]
	TIME [epoch: 6.52 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09194199610435043		[learning rate: 0.0045461]
	Learning Rate: 0.00454612
	LOSS [training: 0.09194199610435043 | validation: 0.06768550693608308]
	TIME [epoch: 6.5 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_384.pth
	Model improved!!!
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.111100804010724		[learning rate: 0.0045354]
	Learning Rate: 0.0045354
	LOSS [training: 0.111100804010724 | validation: 0.1347238000693765]
	TIME [epoch: 6.51 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11082333865667346		[learning rate: 0.0045247]
	Learning Rate: 0.0045247
	LOSS [training: 0.11082333865667346 | validation: 0.0816695387947569]
	TIME [epoch: 6.53 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2724179170660178		[learning rate: 0.004514]
	Learning Rate: 0.00451403
	LOSS [training: 0.2724179170660178 | validation: 0.1919097048343747]
	TIME [epoch: 6.56 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1344938220528949		[learning rate: 0.0045034]
	Learning Rate: 0.00450338
	LOSS [training: 0.1344938220528949 | validation: 0.08553325203336264]
	TIME [epoch: 6.53 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11038925649297826		[learning rate: 0.0044928]
	Learning Rate: 0.00449276
	LOSS [training: 0.11038925649297826 | validation: 0.07923278911920478]
	TIME [epoch: 6.52 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4375999571158527		[learning rate: 0.0044822]
	Learning Rate: 0.00448216
	LOSS [training: 0.4375999571158527 | validation: 0.15332077576188224]
	TIME [epoch: 6.52 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13496802822755638		[learning rate: 0.0044716]
	Learning Rate: 0.00447159
	LOSS [training: 0.13496802822755638 | validation: 0.08306783720988598]
	TIME [epoch: 6.52 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1042234394882793		[learning rate: 0.004461]
	Learning Rate: 0.00446104
	LOSS [training: 0.1042234394882793 | validation: 0.06733107254876246]
	TIME [epoch: 6.55 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_392.pth
	Model improved!!!
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10370041954960296		[learning rate: 0.0044505]
	Learning Rate: 0.00445051
	LOSS [training: 0.10370041954960296 | validation: 0.1015641007112727]
	TIME [epoch: 6.54 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10880599324544496		[learning rate: 0.00444]
	Learning Rate: 0.00444002
	LOSS [training: 0.10880599324544496 | validation: 0.0858375151124731]
	TIME [epoch: 6.52 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3725749882462669		[learning rate: 0.0044295]
	Learning Rate: 0.00442954
	LOSS [training: 0.3725749882462669 | validation: 0.44747228239297065]
	TIME [epoch: 6.52 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29364564516547964		[learning rate: 0.0044191]
	Learning Rate: 0.00441909
	LOSS [training: 0.29364564516547964 | validation: 0.11938103715282823]
	TIME [epoch: 6.52 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.123949402366611		[learning rate: 0.0044087]
	Learning Rate: 0.00440867
	LOSS [training: 0.123949402366611 | validation: 0.10189641625886917]
	TIME [epoch: 6.52 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10509406656830529		[learning rate: 0.0043983]
	Learning Rate: 0.00439827
	LOSS [training: 0.10509406656830529 | validation: 0.07133219287867683]
	TIME [epoch: 6.58 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09751835475988076		[learning rate: 0.0043879]
	Learning Rate: 0.0043879
	LOSS [training: 0.09751835475988076 | validation: 0.06423600392142276]
	TIME [epoch: 6.53 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_399.pth
	Model improved!!!
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16612519961500244		[learning rate: 0.0043775]
	Learning Rate: 0.00437755
	LOSS [training: 0.16612519961500244 | validation: 0.12610965075455555]
	TIME [epoch: 6.59 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09031066643832868		[learning rate: 0.0043672]
	Learning Rate: 0.00436722
	LOSS [training: 0.09031066643832868 | validation: 0.07833630467281051]
	TIME [epoch: 6.58 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10000614743213807		[learning rate: 0.0043569]
	Learning Rate: 0.00435692
	LOSS [training: 0.10000614743213807 | validation: 0.06584623812985436]
	TIME [epoch: 6.58 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09989474210799221		[learning rate: 0.0043466]
	Learning Rate: 0.00434664
	LOSS [training: 0.09989474210799221 | validation: 0.07666879076949425]
	TIME [epoch: 6.6 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09699654122193513		[learning rate: 0.0043364]
	Learning Rate: 0.00433639
	LOSS [training: 0.09699654122193513 | validation: 0.07172378992289932]
	TIME [epoch: 6.62 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0934948006827607		[learning rate: 0.0043262]
	Learning Rate: 0.00432616
	LOSS [training: 0.0934948006827607 | validation: 0.10352124597814416]
	TIME [epoch: 6.58 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10053139409852611		[learning rate: 0.004316]
	Learning Rate: 0.00431596
	LOSS [training: 0.10053139409852611 | validation: 0.13599440749506547]
	TIME [epoch: 6.58 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11480440149177344		[learning rate: 0.0043058]
	Learning Rate: 0.00430577
	LOSS [training: 0.11480440149177344 | validation: 0.061029032467850186]
	TIME [epoch: 6.58 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_407.pth
	Model improved!!!
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09311866821981704		[learning rate: 0.0042956]
	Learning Rate: 0.00429562
	LOSS [training: 0.09311866821981704 | validation: 0.0726394671796814]
	TIME [epoch: 6.59 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10564760758059735		[learning rate: 0.0042855]
	Learning Rate: 0.00428549
	LOSS [training: 0.10564760758059735 | validation: 0.06663906894414608]
	TIME [epoch: 6.62 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10146841286452062		[learning rate: 0.0042754]
	Learning Rate: 0.00427538
	LOSS [training: 0.10146841286452062 | validation: 0.06412168014550303]
	TIME [epoch: 6.59 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11436151269731394		[learning rate: 0.0042653]
	Learning Rate: 0.00426529
	LOSS [training: 0.11436151269731394 | validation: 0.09634356751768802]
	TIME [epoch: 6.58 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09729329721275529		[learning rate: 0.0042552]
	Learning Rate: 0.00425523
	LOSS [training: 0.09729329721275529 | validation: 0.06445122574014672]
	TIME [epoch: 6.58 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07704672635405134		[learning rate: 0.0042452]
	Learning Rate: 0.00424519
	LOSS [training: 0.07704672635405134 | validation: 0.10062333341401589]
	TIME [epoch: 6.58 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23514414463664696		[learning rate: 0.0042352]
	Learning Rate: 0.00423518
	LOSS [training: 0.23514414463664696 | validation: 0.46431177170563304]
	TIME [epoch: 6.58 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3420702644010539		[learning rate: 0.0042252]
	Learning Rate: 0.00422519
	LOSS [training: 0.3420702644010539 | validation: 0.1261566062495648]
	TIME [epoch: 6.62 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12791339224712686		[learning rate: 0.0042152]
	Learning Rate: 0.00421522
	LOSS [training: 0.12791339224712686 | validation: 0.08185693681104245]
	TIME [epoch: 6.59 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1217021532292335		[learning rate: 0.0042053]
	Learning Rate: 0.00420528
	LOSS [training: 0.1217021532292335 | validation: 0.1798969872478452]
	TIME [epoch: 6.58 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1088874358264712		[learning rate: 0.0041954]
	Learning Rate: 0.00419536
	LOSS [training: 0.1088874358264712 | validation: 0.07265816198194741]
	TIME [epoch: 6.58 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0780035472141821		[learning rate: 0.0041855]
	Learning Rate: 0.00418546
	LOSS [training: 0.0780035472141821 | validation: 0.05637112567401253]
	TIME [epoch: 6.58 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_419.pth
	Model improved!!!
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11182708850356511		[learning rate: 0.0041756]
	Learning Rate: 0.00417559
	LOSS [training: 0.11182708850356511 | validation: 0.08099433031763029]
	TIME [epoch: 6.59 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10065507329654381		[learning rate: 0.0041657]
	Learning Rate: 0.00416574
	LOSS [training: 0.10065507329654381 | validation: 0.0891331408914791]
	TIME [epoch: 6.61 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12248402587205898		[learning rate: 0.0041559]
	Learning Rate: 0.00415592
	LOSS [training: 0.12248402587205898 | validation: 0.04891219122741888]
	TIME [epoch: 6.57 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_422.pth
	Model improved!!!
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08493115764873778		[learning rate: 0.0041461]
	Learning Rate: 0.00414611
	LOSS [training: 0.08493115764873778 | validation: 0.12354356230414489]
	TIME [epoch: 6.57 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10835772318850441		[learning rate: 0.0041363]
	Learning Rate: 0.00413633
	LOSS [training: 0.10835772318850441 | validation: 0.08650468568795519]
	TIME [epoch: 6.56 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14556479387443255		[learning rate: 0.0041266]
	Learning Rate: 0.00412657
	LOSS [training: 0.14556479387443255 | validation: 0.07303752170351208]
	TIME [epoch: 6.56 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07697263526529728		[learning rate: 0.0041168]
	Learning Rate: 0.00411684
	LOSS [training: 0.07697263526529728 | validation: 0.09823628977774441]
	TIME [epoch: 6.59 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0984468126026006		[learning rate: 0.0041071]
	Learning Rate: 0.00410713
	LOSS [training: 0.0984468126026006 | validation: 0.08987028045006167]
	TIME [epoch: 6.59 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1015215125789144		[learning rate: 0.0040974]
	Learning Rate: 0.00409744
	LOSS [training: 0.1015215125789144 | validation: 0.07121343804829061]
	TIME [epoch: 6.56 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23128746970590877		[learning rate: 0.0040878]
	Learning Rate: 0.00408778
	LOSS [training: 0.23128746970590877 | validation: 0.47611856725757934]
	TIME [epoch: 6.56 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7508573563537192		[learning rate: 0.0040781]
	Learning Rate: 0.00407813
	LOSS [training: 0.7508573563537192 | validation: 0.48455636833988974]
	TIME [epoch: 6.56 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7473924785207805		[learning rate: 0.0040685]
	Learning Rate: 0.00406851
	LOSS [training: 0.7473924785207805 | validation: 0.5148163411160496]
	TIME [epoch: 6.56 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7357851449631454		[learning rate: 0.0040589]
	Learning Rate: 0.00405892
	LOSS [training: 0.7357851449631454 | validation: 0.46473293498311896]
	TIME [epoch: 6.6 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43686812814719894		[learning rate: 0.0040493]
	Learning Rate: 0.00404934
	LOSS [training: 0.43686812814719894 | validation: 0.15804206039060978]
	TIME [epoch: 6.57 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14265553098839406		[learning rate: 0.0040398]
	Learning Rate: 0.00403979
	LOSS [training: 0.14265553098839406 | validation: 0.07685862333987017]
	TIME [epoch: 6.56 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09358565883099615		[learning rate: 0.0040303]
	Learning Rate: 0.00403026
	LOSS [training: 0.09358565883099615 | validation: 0.07394955615896878]
	TIME [epoch: 6.56 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08710434690962887		[learning rate: 0.0040208]
	Learning Rate: 0.00402076
	LOSS [training: 0.08710434690962887 | validation: 0.1505127463794862]
	TIME [epoch: 6.56 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11766206077344665		[learning rate: 0.0040113]
	Learning Rate: 0.00401127
	LOSS [training: 0.11766206077344665 | validation: 0.4224205372851425]
	TIME [epoch: 6.57 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2530147029480948		[learning rate: 0.0040018]
	Learning Rate: 0.00400181
	LOSS [training: 0.2530147029480948 | validation: 0.25870507881229393]
	TIME [epoch: 6.57 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14414712053829037		[learning rate: 0.0039924]
	Learning Rate: 0.00399237
	LOSS [training: 0.14414712053829037 | validation: 0.06947154112504726]
	TIME [epoch: 6.53 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12102265920456409		[learning rate: 0.003983]
	Learning Rate: 0.00398295
	LOSS [training: 0.12102265920456409 | validation: 0.07671282274284874]
	TIME [epoch: 6.55 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19399348084717394		[learning rate: 0.0039736]
	Learning Rate: 0.00397356
	LOSS [training: 0.19399348084717394 | validation: 0.11614634588137987]
	TIME [epoch: 6.57 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11455388449432927		[learning rate: 0.0039642]
	Learning Rate: 0.00396418
	LOSS [training: 0.11455388449432927 | validation: 0.09042429101620772]
	TIME [epoch: 6.56 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09132950545290038		[learning rate: 0.0039548]
	Learning Rate: 0.00395483
	LOSS [training: 0.09132950545290038 | validation: 0.05935284447316934]
	TIME [epoch: 6.59 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09091309730827152		[learning rate: 0.0039455]
	Learning Rate: 0.0039455
	LOSS [training: 0.09091309730827152 | validation: 0.062093604485493364]
	TIME [epoch: 6.59 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07737751372492774		[learning rate: 0.0039362]
	Learning Rate: 0.0039362
	LOSS [training: 0.07737751372492774 | validation: 0.07359013574520035]
	TIME [epoch: 6.56 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09474046945298827		[learning rate: 0.0039269]
	Learning Rate: 0.00392691
	LOSS [training: 0.09474046945298827 | validation: 0.07027663485158767]
	TIME [epoch: 6.56 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08599951851601693		[learning rate: 0.0039176]
	Learning Rate: 0.00391765
	LOSS [training: 0.08599951851601693 | validation: 0.16731629816130197]
	TIME [epoch: 6.56 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15247716078056237		[learning rate: 0.0039084]
	Learning Rate: 0.00390841
	LOSS [training: 0.15247716078056237 | validation: 0.12024184427697521]
	TIME [epoch: 6.55 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11549881422980124		[learning rate: 0.0038992]
	Learning Rate: 0.00389919
	LOSS [training: 0.11549881422980124 | validation: 0.05885340674534645]
	TIME [epoch: 6.59 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10465202326702339		[learning rate: 0.00389]
	Learning Rate: 0.00388999
	LOSS [training: 0.10465202326702339 | validation: 0.11898686185334746]
	TIME [epoch: 6.56 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14253156871298672		[learning rate: 0.0038808]
	Learning Rate: 0.00388082
	LOSS [training: 0.14253156871298672 | validation: 0.11846556163754363]
	TIME [epoch: 6.55 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21809650568597383		[learning rate: 0.0038717]
	Learning Rate: 0.00387166
	LOSS [training: 0.21809650568597383 | validation: 0.1446862169614652]
	TIME [epoch: 6.55 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22972200591953307		[learning rate: 0.0038625]
	Learning Rate: 0.00386253
	LOSS [training: 0.22972200591953307 | validation: 0.21293384621781986]
	TIME [epoch: 6.55 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20173251135911013		[learning rate: 0.0038534]
	Learning Rate: 0.00385342
	LOSS [training: 0.20173251135911013 | validation: 0.15661427932074046]
	TIME [epoch: 6.56 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20455820293547555		[learning rate: 0.0038443]
	Learning Rate: 0.00384433
	LOSS [training: 0.20455820293547555 | validation: 0.09144432108183999]
	TIME [epoch: 6.59 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09757387261534003		[learning rate: 0.0038353]
	Learning Rate: 0.00383526
	LOSS [training: 0.09757387261534003 | validation: 0.0734120058158948]
	TIME [epoch: 6.55 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0914632125270878		[learning rate: 0.0038262]
	Learning Rate: 0.00382621
	LOSS [training: 0.0914632125270878 | validation: 0.10744538642076218]
	TIME [epoch: 6.55 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09851169985990502		[learning rate: 0.0038172]
	Learning Rate: 0.00381719
	LOSS [training: 0.09851169985990502 | validation: 0.06755127843707673]
	TIME [epoch: 6.55 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20406694501237516		[learning rate: 0.0038082]
	Learning Rate: 0.00380818
	LOSS [training: 0.20406694501237516 | validation: 0.11744230345352903]
	TIME [epoch: 6.55 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10508501135746684		[learning rate: 0.0037992]
	Learning Rate: 0.0037992
	LOSS [training: 0.10508501135746684 | validation: 0.09173614102139735]
	TIME [epoch: 6.56 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10106323878367388		[learning rate: 0.0037902]
	Learning Rate: 0.00379024
	LOSS [training: 0.10106323878367388 | validation: 0.1166535650581958]
	TIME [epoch: 6.58 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10849071889607417		[learning rate: 0.0037813]
	Learning Rate: 0.0037813
	LOSS [training: 0.10849071889607417 | validation: 0.07392760377851888]
	TIME [epoch: 6.55 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10118026553632246		[learning rate: 0.0037724]
	Learning Rate: 0.00377238
	LOSS [training: 0.10118026553632246 | validation: 0.10115207510943983]
	TIME [epoch: 6.55 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1955732626602104		[learning rate: 0.0037635]
	Learning Rate: 0.00376348
	LOSS [training: 0.1955732626602104 | validation: 0.15827088199615325]
	TIME [epoch: 6.55 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13526703471007945		[learning rate: 0.0037546]
	Learning Rate: 0.0037546
	LOSS [training: 0.13526703471007945 | validation: 0.06843165486383888]
	TIME [epoch: 6.55 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1770932856262564		[learning rate: 0.0037457]
	Learning Rate: 0.00374575
	LOSS [training: 0.1770932856262564 | validation: 0.09715401289620913]
	TIME [epoch: 6.59 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11705064942524794		[learning rate: 0.0037369]
	Learning Rate: 0.00373691
	LOSS [training: 0.11705064942524794 | validation: 0.0745781012197528]
	TIME [epoch: 6.56 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10068435406631367		[learning rate: 0.0037281]
	Learning Rate: 0.0037281
	LOSS [training: 0.10068435406631367 | validation: 0.07961130425419859]
	TIME [epoch: 6.55 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09590766629901026		[learning rate: 0.0037193]
	Learning Rate: 0.0037193
	LOSS [training: 0.09590766629901026 | validation: 0.050074678347668995]
	TIME [epoch: 6.55 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09452269412249945		[learning rate: 0.0037105]
	Learning Rate: 0.00371053
	LOSS [training: 0.09452269412249945 | validation: 0.08388053830096076]
	TIME [epoch: 6.55 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09323092620219212		[learning rate: 0.0037018]
	Learning Rate: 0.00370178
	LOSS [training: 0.09323092620219212 | validation: 0.11987867307050362]
	TIME [epoch: 6.56 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0939164458800332		[learning rate: 0.003693]
	Learning Rate: 0.00369304
	LOSS [training: 0.0939164458800332 | validation: 0.10776446478880969]
	TIME [epoch: 6.59 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14757769237029536		[learning rate: 0.0036843]
	Learning Rate: 0.00368433
	LOSS [training: 0.14757769237029536 | validation: 0.0735153609004893]
	TIME [epoch: 6.56 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08578394712301023		[learning rate: 0.0036756]
	Learning Rate: 0.00367564
	LOSS [training: 0.08578394712301023 | validation: 0.05952741414295707]
	TIME [epoch: 6.55 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09151045291175568		[learning rate: 0.003667]
	Learning Rate: 0.00366697
	LOSS [training: 0.09151045291175568 | validation: 0.07498804128839737]
	TIME [epoch: 6.56 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1055119910293217		[learning rate: 0.0036583]
	Learning Rate: 0.00365832
	LOSS [training: 0.1055119910293217 | validation: 0.06429728587319664]
	TIME [epoch: 6.56 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13698986665821322		[learning rate: 0.0036497]
	Learning Rate: 0.00364969
	LOSS [training: 0.13698986665821322 | validation: 0.12154938513709798]
	TIME [epoch: 6.57 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1116505204327213		[learning rate: 0.0036411]
	Learning Rate: 0.00364108
	LOSS [training: 0.1116505204327213 | validation: 0.07104202231694967]
	TIME [epoch: 6.6 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10188220388976565		[learning rate: 0.0036325]
	Learning Rate: 0.0036325
	LOSS [training: 0.10188220388976565 | validation: 0.0788002411973329]
	TIME [epoch: 6.56 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09444495792376753		[learning rate: 0.0036239]
	Learning Rate: 0.00362393
	LOSS [training: 0.09444495792376753 | validation: 0.0687316491115204]
	TIME [epoch: 6.57 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09901945320897243		[learning rate: 0.0036154]
	Learning Rate: 0.00361538
	LOSS [training: 0.09901945320897243 | validation: 0.06719220762404632]
	TIME [epoch: 6.56 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09267163447848085		[learning rate: 0.0036069]
	Learning Rate: 0.00360685
	LOSS [training: 0.09267163447848085 | validation: 0.05955372563428435]
	TIME [epoch: 6.56 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10736679319478534		[learning rate: 0.0035983]
	Learning Rate: 0.00359834
	LOSS [training: 0.10736679319478534 | validation: 0.06249704770010331]
	TIME [epoch: 6.6 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09029003694961388		[learning rate: 0.0035899]
	Learning Rate: 0.00358986
	LOSS [training: 0.09029003694961388 | validation: 0.08170705240113693]
	TIME [epoch: 6.57 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08123782520462768		[learning rate: 0.0035814]
	Learning Rate: 0.00358139
	LOSS [training: 0.08123782520462768 | validation: 0.15200041567600608]
	TIME [epoch: 6.57 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09526656414800436		[learning rate: 0.0035729]
	Learning Rate: 0.00357294
	LOSS [training: 0.09526656414800436 | validation: 0.05320764905789368]
	TIME [epoch: 6.57 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07265395457360721		[learning rate: 0.0035645]
	Learning Rate: 0.00356451
	LOSS [training: 0.07265395457360721 | validation: 0.07648500639829303]
	TIME [epoch: 6.57 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12641400040827122		[learning rate: 0.0035561]
	Learning Rate: 0.0035561
	LOSS [training: 0.12641400040827122 | validation: 0.11822237490794563]
	TIME [epoch: 6.58 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08783055467309109		[learning rate: 0.0035477]
	Learning Rate: 0.00354771
	LOSS [training: 0.08783055467309109 | validation: 0.21556077346446706]
	TIME [epoch: 6.62 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16161961065414537		[learning rate: 0.0035393]
	Learning Rate: 0.00353935
	LOSS [training: 0.16161961065414537 | validation: 0.05397656592131495]
	TIME [epoch: 6.57 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08026091607292073		[learning rate: 0.003531]
	Learning Rate: 0.003531
	LOSS [training: 0.08026091607292073 | validation: 0.08259225452410439]
	TIME [epoch: 6.58 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08475560752721971		[learning rate: 0.0035227]
	Learning Rate: 0.00352267
	LOSS [training: 0.08475560752721971 | validation: 0.08693559718302361]
	TIME [epoch: 6.57 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08896799891368616		[learning rate: 0.0035144]
	Learning Rate: 0.00351436
	LOSS [training: 0.08896799891368616 | validation: 0.05343801633055187]
	TIME [epoch: 6.53 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11126571403085314		[learning rate: 0.0035061]
	Learning Rate: 0.00350607
	LOSS [training: 0.11126571403085314 | validation: 0.09924049134447976]
	TIME [epoch: 6.54 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10372165379996659		[learning rate: 0.0034978]
	Learning Rate: 0.0034978
	LOSS [training: 0.10372165379996659 | validation: 0.07799541854752384]
	TIME [epoch: 6.61 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08834862150403602		[learning rate: 0.0034895]
	Learning Rate: 0.00348955
	LOSS [training: 0.08834862150403602 | validation: 0.041032305365427346]
	TIME [epoch: 6.57 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_496.pth
	Model improved!!!
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07576938424373568		[learning rate: 0.0034813]
	Learning Rate: 0.00348132
	LOSS [training: 0.07576938424373568 | validation: 0.05782804652405045]
	TIME [epoch: 6.56 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0896333920984346		[learning rate: 0.0034731]
	Learning Rate: 0.00347311
	LOSS [training: 0.0896333920984346 | validation: 0.046322493004519426]
	TIME [epoch: 6.55 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07728948703739805		[learning rate: 0.0034649]
	Learning Rate: 0.00346491
	LOSS [training: 0.07728948703739805 | validation: 0.049853479951402296]
	TIME [epoch: 6.55 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09163364227876396		[learning rate: 0.0034567]
	Learning Rate: 0.00345674
	LOSS [training: 0.09163364227876396 | validation: 0.05005092572495415]
	TIME [epoch: 6.59 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05748292338862855		[learning rate: 0.0034486]
	Learning Rate: 0.00344859
	LOSS [training: 0.05748292338862855 | validation: 0.052316481994836794]
	TIME [epoch: 6.56 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09416700683201115		[learning rate: 0.0034405]
	Learning Rate: 0.00344045
	LOSS [training: 0.09416700683201115 | validation: 0.0815792045211768]
	TIME [epoch: 6.55 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08967647866790021		[learning rate: 0.0034323]
	Learning Rate: 0.00343234
	LOSS [training: 0.08967647866790021 | validation: 0.10901772742793667]
	TIME [epoch: 6.55 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18345409446411268		[learning rate: 0.0034242]
	Learning Rate: 0.00342424
	LOSS [training: 0.18345409446411268 | validation: 0.27237207047586587]
	TIME [epoch: 6.56 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2836578085109572		[learning rate: 0.0034162]
	Learning Rate: 0.00341616
	LOSS [training: 0.2836578085109572 | validation: 0.16328985584100314]
	TIME [epoch: 6.56 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15074959608103403		[learning rate: 0.0034081]
	Learning Rate: 0.0034081
	LOSS [training: 0.15074959608103403 | validation: 0.13835389318308405]
	TIME [epoch: 6.6 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1263049351755679		[learning rate: 0.0034001]
	Learning Rate: 0.00340006
	LOSS [training: 0.1263049351755679 | validation: 0.09104882486584695]
	TIME [epoch: 6.55 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09064013506688509		[learning rate: 0.003392]
	Learning Rate: 0.00339204
	LOSS [training: 0.09064013506688509 | validation: 0.06138534087413472]
	TIME [epoch: 6.56 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0798890514511233		[learning rate: 0.003384]
	Learning Rate: 0.00338404
	LOSS [training: 0.0798890514511233 | validation: 0.06350529694841309]
	TIME [epoch: 6.55 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08805436535328123		[learning rate: 0.0033761]
	Learning Rate: 0.00337606
	LOSS [training: 0.08805436535328123 | validation: 0.0688923301456476]
	TIME [epoch: 6.55 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13670646631436875		[learning rate: 0.0033681]
	Learning Rate: 0.0033681
	LOSS [training: 0.13670646631436875 | validation: 0.13141643094845482]
	TIME [epoch: 6.56 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13541198591312117		[learning rate: 0.0033602]
	Learning Rate: 0.00336015
	LOSS [training: 0.13541198591312117 | validation: 0.09932842876672512]
	TIME [epoch: 6.59 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10726949691817977		[learning rate: 0.0033522]
	Learning Rate: 0.00335223
	LOSS [training: 0.10726949691817977 | validation: 0.07681940459916521]
	TIME [epoch: 6.55 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10910421057959392		[learning rate: 0.0033443]
	Learning Rate: 0.00334432
	LOSS [training: 0.10910421057959392 | validation: 0.09308116629806126]
	TIME [epoch: 6.55 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5502184656603143		[learning rate: 0.0033364]
	Learning Rate: 0.00333643
	LOSS [training: 0.5502184656603143 | validation: 0.15097444175852714]
	TIME [epoch: 6.56 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24424628269524784		[learning rate: 0.0033286]
	Learning Rate: 0.00332856
	LOSS [training: 0.24424628269524784 | validation: 0.20092342336723848]
	TIME [epoch: 6.54 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1691999718217469		[learning rate: 0.0033207]
	Learning Rate: 0.00332071
	LOSS [training: 0.1691999718217469 | validation: 0.07602428543483128]
	TIME [epoch: 6.57 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17348018100139478		[learning rate: 0.0033129]
	Learning Rate: 0.00331288
	LOSS [training: 0.17348018100139478 | validation: 0.09748123366907588]
	TIME [epoch: 6.55 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1162321635878236		[learning rate: 0.0033051]
	Learning Rate: 0.00330506
	LOSS [training: 0.1162321635878236 | validation: 0.07543789088251684]
	TIME [epoch: 6.54 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1006660327510918		[learning rate: 0.0032973]
	Learning Rate: 0.00329727
	LOSS [training: 0.1006660327510918 | validation: 0.06597703313096392]
	TIME [epoch: 6.54 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09805730757367309		[learning rate: 0.0032895]
	Learning Rate: 0.00328949
	LOSS [training: 0.09805730757367309 | validation: 0.058703806549281076]
	TIME [epoch: 6.54 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08037757301080174		[learning rate: 0.0032817]
	Learning Rate: 0.00328173
	LOSS [training: 0.08037757301080174 | validation: 0.06251541865227109]
	TIME [epoch: 6.54 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07745502139337157		[learning rate: 0.003274]
	Learning Rate: 0.00327399
	LOSS [training: 0.07745502139337157 | validation: 0.06411397135225]
	TIME [epoch: 6.58 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11519087711020384		[learning rate: 0.0032663]
	Learning Rate: 0.00326626
	LOSS [training: 0.11519087711020384 | validation: 0.10532427238930729]
	TIME [epoch: 6.55 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10066859681497134		[learning rate: 0.0032586]
	Learning Rate: 0.00325856
	LOSS [training: 0.10066859681497134 | validation: 0.08008894999608965]
	TIME [epoch: 6.54 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24380616169034397		[learning rate: 0.0032509]
	Learning Rate: 0.00325087
	LOSS [training: 0.24380616169034397 | validation: 0.08900131500514513]
	TIME [epoch: 6.54 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12828321727659522		[learning rate: 0.0032432]
	Learning Rate: 0.0032432
	LOSS [training: 0.12828321727659522 | validation: 0.10328297145238505]
	TIME [epoch: 6.54 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10567283739219502		[learning rate: 0.0032356]
	Learning Rate: 0.00323555
	LOSS [training: 0.10567283739219502 | validation: 0.07230731991060363]
	TIME [epoch: 6.55 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09010001485001701		[learning rate: 0.0032279]
	Learning Rate: 0.00322792
	LOSS [training: 0.09010001485001701 | validation: 0.05586096203430677]
	TIME [epoch: 6.58 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08103897756711152		[learning rate: 0.0032203]
	Learning Rate: 0.00322031
	LOSS [training: 0.08103897756711152 | validation: 0.07833829622889518]
	TIME [epoch: 6.55 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07944896808854775		[learning rate: 0.0032127]
	Learning Rate: 0.00321271
	LOSS [training: 0.07944896808854775 | validation: 0.061339680534502214]
	TIME [epoch: 6.54 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07741764045186375		[learning rate: 0.0032051]
	Learning Rate: 0.00320513
	LOSS [training: 0.07741764045186375 | validation: 0.0747156338226799]
	TIME [epoch: 6.54 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09835258826589817		[learning rate: 0.0031976]
	Learning Rate: 0.00319757
	LOSS [training: 0.09835258826589817 | validation: 0.06122402281576233]
	TIME [epoch: 6.55 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08344019653345827		[learning rate: 0.00319]
	Learning Rate: 0.00319003
	LOSS [training: 0.08344019653345827 | validation: 0.08573447780012756]
	TIME [epoch: 6.58 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09223061294350285		[learning rate: 0.0031825]
	Learning Rate: 0.00318251
	LOSS [training: 0.09223061294350285 | validation: 0.07439623359204649]
	TIME [epoch: 6.57 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09377320927886176		[learning rate: 0.003175]
	Learning Rate: 0.003175
	LOSS [training: 0.09377320927886176 | validation: 0.07681266467918113]
	TIME [epoch: 6.55 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1619684346772233		[learning rate: 0.0031675]
	Learning Rate: 0.00316751
	LOSS [training: 0.1619684346772233 | validation: 0.2158075797675777]
	TIME [epoch: 6.53 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24815952192377164		[learning rate: 0.00316]
	Learning Rate: 0.00316004
	LOSS [training: 0.24815952192377164 | validation: 0.18829944073897303]
	TIME [epoch: 6.54 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14792882595741613		[learning rate: 0.0031526]
	Learning Rate: 0.00315258
	LOSS [training: 0.14792882595741613 | validation: 0.1252711646803941]
	TIME [epoch: 6.55 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11339430721483816		[learning rate: 0.0031451]
	Learning Rate: 0.00314515
	LOSS [training: 0.11339430721483816 | validation: 0.07394212191360904]
	TIME [epoch: 6.58 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10827901768888279		[learning rate: 0.0031377]
	Learning Rate: 0.00313773
	LOSS [training: 0.10827901768888279 | validation: 0.06910473496990073]
	TIME [epoch: 6.53 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11345720152360808		[learning rate: 0.0031303]
	Learning Rate: 0.00313033
	LOSS [training: 0.11345720152360808 | validation: 0.10971319176496344]
	TIME [epoch: 6.54 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11539467704896082		[learning rate: 0.0031229]
	Learning Rate: 0.00312294
	LOSS [training: 0.11539467704896082 | validation: 0.07881257495673676]
	TIME [epoch: 6.54 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16184971078761318		[learning rate: 0.0031156]
	Learning Rate: 0.00311558
	LOSS [training: 0.16184971078761318 | validation: 0.1791412195489296]
	TIME [epoch: 6.55 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14560234702289404		[learning rate: 0.0031082]
	Learning Rate: 0.00310823
	LOSS [training: 0.14560234702289404 | validation: 0.08120277461468042]
	TIME [epoch: 6.56 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1712063530681147		[learning rate: 0.0031009]
	Learning Rate: 0.0031009
	LOSS [training: 0.1712063530681147 | validation: 0.10066945181968874]
	TIME [epoch: 6.6 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08253148742571652		[learning rate: 0.0030936]
	Learning Rate: 0.00309358
	LOSS [training: 0.08253148742571652 | validation: 0.050954103510045215]
	TIME [epoch: 6.55 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07493469198805994		[learning rate: 0.0030863]
	Learning Rate: 0.00308628
	LOSS [training: 0.07493469198805994 | validation: 0.0445184684537368]
	TIME [epoch: 6.53 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10887992747513345		[learning rate: 0.003079]
	Learning Rate: 0.003079
	LOSS [training: 0.10887992747513345 | validation: 0.2622824345924485]
	TIME [epoch: 6.5 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15403086083888215		[learning rate: 0.0030717]
	Learning Rate: 0.00307174
	LOSS [training: 0.15403086083888215 | validation: 0.11601675543156534]
	TIME [epoch: 6.55 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09880837070249116		[learning rate: 0.0030645]
	Learning Rate: 0.0030645
	LOSS [training: 0.09880837070249116 | validation: 0.05992077024415978]
	TIME [epoch: 6.59 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08764120521572434		[learning rate: 0.0030573]
	Learning Rate: 0.00305727
	LOSS [training: 0.08764120521572434 | validation: 0.059671866064787436]
	TIME [epoch: 6.56 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07858358641814303		[learning rate: 0.0030501]
	Learning Rate: 0.00305006
	LOSS [training: 0.07858358641814303 | validation: 0.04983905407640646]
	TIME [epoch: 6.55 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09966699293122475		[learning rate: 0.0030429]
	Learning Rate: 0.00304286
	LOSS [training: 0.09966699293122475 | validation: 0.07570014311905894]
	TIME [epoch: 6.56 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07878360783471558		[learning rate: 0.0030357]
	Learning Rate: 0.00303568
	LOSS [training: 0.07878360783471558 | validation: 0.06550176204794958]
	TIME [epoch: 6.54 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07758614924571364		[learning rate: 0.0030285]
	Learning Rate: 0.00302852
	LOSS [training: 0.07758614924571364 | validation: 0.06520694366265598]
	TIME [epoch: 6.56 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07991062843033483		[learning rate: 0.0030214]
	Learning Rate: 0.00302138
	LOSS [training: 0.07991062843033483 | validation: 0.04600256560982247]
	TIME [epoch: 6.58 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14057065546450598		[learning rate: 0.0030143]
	Learning Rate: 0.00301425
	LOSS [training: 0.14057065546450598 | validation: 0.07367004939172155]
	TIME [epoch: 6.56 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07615016806946193		[learning rate: 0.0030071]
	Learning Rate: 0.00300714
	LOSS [training: 0.07615016806946193 | validation: 0.04463917941678657]
	TIME [epoch: 6.54 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08677355420585091		[learning rate: 0.003]
	Learning Rate: 0.00300005
	LOSS [training: 0.08677355420585091 | validation: 0.09268514663069485]
	TIME [epoch: 6.54 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12016141964812885		[learning rate: 0.002993]
	Learning Rate: 0.00299297
	LOSS [training: 0.12016141964812885 | validation: 0.094457985708922]
	TIME [epoch: 6.53 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09947264361243886		[learning rate: 0.0029859]
	Learning Rate: 0.00298591
	LOSS [training: 0.09947264361243886 | validation: 0.06078684665048345]
	TIME [epoch: 6.55 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0761473777417619		[learning rate: 0.0029789]
	Learning Rate: 0.00297887
	LOSS [training: 0.0761473777417619 | validation: 0.07746397538798477]
	TIME [epoch: 6.57 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0760945349186017		[learning rate: 0.0029718]
	Learning Rate: 0.00297184
	LOSS [training: 0.0760945349186017 | validation: 0.04505442763056071]
	TIME [epoch: 6.55 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06591963316233217		[learning rate: 0.0029648]
	Learning Rate: 0.00296483
	LOSS [training: 0.06591963316233217 | validation: 0.054170262647380056]
	TIME [epoch: 6.55 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08210584175586653		[learning rate: 0.0029578]
	Learning Rate: 0.00295784
	LOSS [training: 0.08210584175586653 | validation: 0.08171818821392449]
	TIME [epoch: 6.55 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08926672480839969		[learning rate: 0.0029509]
	Learning Rate: 0.00295086
	LOSS [training: 0.08926672480839969 | validation: 0.06298938289464162]
	TIME [epoch: 6.53 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12408425013844118		[learning rate: 0.0029439]
	Learning Rate: 0.0029439
	LOSS [training: 0.12408425013844118 | validation: 0.12225042913994588]
	TIME [epoch: 6.56 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10015620911469425		[learning rate: 0.002937]
	Learning Rate: 0.00293696
	LOSS [training: 0.10015620911469425 | validation: 0.059581897385272226]
	TIME [epoch: 6.58 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07543409975038708		[learning rate: 0.00293]
	Learning Rate: 0.00293003
	LOSS [training: 0.07543409975038708 | validation: 0.05872205664694219]
	TIME [epoch: 6.55 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08563048350821918		[learning rate: 0.0029231]
	Learning Rate: 0.00292312
	LOSS [training: 0.08563048350821918 | validation: 0.0644503003962973]
	TIME [epoch: 6.55 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07642773484023405		[learning rate: 0.0029162]
	Learning Rate: 0.00291622
	LOSS [training: 0.07642773484023405 | validation: 0.06639054967712059]
	TIME [epoch: 6.54 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10643205777276202		[learning rate: 0.0029093]
	Learning Rate: 0.00290934
	LOSS [training: 0.10643205777276202 | validation: 0.07462735955893149]
	TIME [epoch: 6.55 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07812302428779445		[learning rate: 0.0029025]
	Learning Rate: 0.00290248
	LOSS [training: 0.07812302428779445 | validation: 0.051473052971158645]
	TIME [epoch: 6.59 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08576118338727153		[learning rate: 0.0028956]
	Learning Rate: 0.00289563
	LOSS [training: 0.08576118338727153 | validation: 0.05649767056333499]
	TIME [epoch: 6.54 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07320164887697296		[learning rate: 0.0028888]
	Learning Rate: 0.0028888
	LOSS [training: 0.07320164887697296 | validation: 0.07469756606862785]
	TIME [epoch: 6.53 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08174013110158543		[learning rate: 0.002882]
	Learning Rate: 0.00288199
	LOSS [training: 0.08174013110158543 | validation: 0.15264352231306288]
	TIME [epoch: 6.55 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10090105230082372		[learning rate: 0.0028752]
	Learning Rate: 0.00287519
	LOSS [training: 0.10090105230082372 | validation: 0.09132197968655209]
	TIME [epoch: 6.54 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1358837292400353		[learning rate: 0.0028684]
	Learning Rate: 0.00286841
	LOSS [training: 0.1358837292400353 | validation: 0.08877234514771985]
	TIME [epoch: 6.55 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17267786058924348		[learning rate: 0.0028616]
	Learning Rate: 0.00286164
	LOSS [training: 0.17267786058924348 | validation: 0.23085461079457925]
	TIME [epoch: 6.59 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2567203632835088		[learning rate: 0.0028549]
	Learning Rate: 0.00285489
	LOSS [training: 0.2567203632835088 | validation: 0.28620656484818946]
	TIME [epoch: 6.52 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22847717499160397		[learning rate: 0.0028482]
	Learning Rate: 0.00284816
	LOSS [training: 0.22847717499160397 | validation: 0.18659108096283278]
	TIME [epoch: 6.52 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14549459118562014		[learning rate: 0.0028414]
	Learning Rate: 0.00284144
	LOSS [training: 0.14549459118562014 | validation: 0.10055574796663477]
	TIME [epoch: 6.54 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14485522142313084		[learning rate: 0.0028347]
	Learning Rate: 0.00283474
	LOSS [training: 0.14485522142313084 | validation: 0.17651043766673485]
	TIME [epoch: 6.52 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19860267430753137		[learning rate: 0.0028281]
	Learning Rate: 0.00282805
	LOSS [training: 0.19860267430753137 | validation: 0.33614160203713417]
	TIME [epoch: 6.55 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1910541596488797		[learning rate: 0.0028214]
	Learning Rate: 0.00282138
	LOSS [training: 0.1910541596488797 | validation: 0.0922957983872735]
	TIME [epoch: 6.55 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08869890581780394		[learning rate: 0.0028147]
	Learning Rate: 0.00281472
	LOSS [training: 0.08869890581780394 | validation: 0.06187692375053515]
	TIME [epoch: 6.52 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0734607416244312		[learning rate: 0.0028081]
	Learning Rate: 0.00280808
	LOSS [training: 0.0734607416244312 | validation: 0.06939019067911033]
	TIME [epoch: 6.52 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07893224075602914		[learning rate: 0.0028015]
	Learning Rate: 0.00280146
	LOSS [training: 0.07893224075602914 | validation: 0.0910570186070187]
	TIME [epoch: 6.53 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10975303633756439		[learning rate: 0.0027949]
	Learning Rate: 0.00279485
	LOSS [training: 0.10975303633756439 | validation: 0.04849789025020964]
	TIME [epoch: 6.54 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07809407628741512		[learning rate: 0.0027883]
	Learning Rate: 0.00278826
	LOSS [training: 0.07809407628741512 | validation: 0.05169495819015505]
	TIME [epoch: 6.57 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08048176003518362		[learning rate: 0.0027817]
	Learning Rate: 0.00278168
	LOSS [training: 0.08048176003518362 | validation: 0.0636451578535675]
	TIME [epoch: 6.54 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07487551538392391		[learning rate: 0.0027751]
	Learning Rate: 0.00277512
	LOSS [training: 0.07487551538392391 | validation: 0.04750256081001966]
	TIME [epoch: 6.52 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09367797050294062		[learning rate: 0.0027686]
	Learning Rate: 0.00276858
	LOSS [training: 0.09367797050294062 | validation: 0.07948074038252864]
	TIME [epoch: 6.52 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.076883028214892		[learning rate: 0.002762]
	Learning Rate: 0.00276205
	LOSS [training: 0.076883028214892 | validation: 0.033664707862370934]
	TIME [epoch: 6.53 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_595.pth
	Model improved!!!
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06364177758088592		[learning rate: 0.0027555]
	Learning Rate: 0.00275553
	LOSS [training: 0.06364177758088592 | validation: 0.04887412675983885]
	TIME [epoch: 6.52 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06906343764825676		[learning rate: 0.002749]
	Learning Rate: 0.00274903
	LOSS [training: 0.06906343764825676 | validation: 0.053295412650650256]
	TIME [epoch: 6.57 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07294155475670891		[learning rate: 0.0027425]
	Learning Rate: 0.00274255
	LOSS [training: 0.07294155475670891 | validation: 0.05388082323020505]
	TIME [epoch: 6.52 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11638763472137341		[learning rate: 0.0027361]
	Learning Rate: 0.00273608
	LOSS [training: 0.11638763472137341 | validation: 0.17579135974529392]
	TIME [epoch: 6.54 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10996011942312207		[learning rate: 0.0027296]
	Learning Rate: 0.00272962
	LOSS [training: 0.10996011942312207 | validation: 0.1195138641861496]
	TIME [epoch: 6.54 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14939674060699512		[learning rate: 0.0027232]
	Learning Rate: 0.00272318
	LOSS [training: 0.14939674060699512 | validation: 0.14117248836239776]
	TIME [epoch: 6.53 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3121252851838618		[learning rate: 0.0027168]
	Learning Rate: 0.00271676
	LOSS [training: 0.3121252851838618 | validation: 0.1882771992204992]
	TIME [epoch: 6.53 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17260804478466607		[learning rate: 0.0027104]
	Learning Rate: 0.00271035
	LOSS [training: 0.17260804478466607 | validation: 0.09588846793833597]
	TIME [epoch: 6.53 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09187626724177045		[learning rate: 0.002704]
	Learning Rate: 0.00270396
	LOSS [training: 0.09187626724177045 | validation: 0.07322296735702802]
	TIME [epoch: 6.51 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07895879860090255		[learning rate: 0.0026976]
	Learning Rate: 0.00269758
	LOSS [training: 0.07895879860090255 | validation: 0.052355664987181305]
	TIME [epoch: 6.53 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07901736748821239		[learning rate: 0.0026912]
	Learning Rate: 0.00269122
	LOSS [training: 0.07901736748821239 | validation: 0.07427757451401487]
	TIME [epoch: 6.53 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10399110278360282		[learning rate: 0.0026849]
	Learning Rate: 0.00268487
	LOSS [training: 0.10399110278360282 | validation: 0.4364659762047589]
	TIME [epoch: 6.52 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6333366445341959		[learning rate: 0.0026785]
	Learning Rate: 0.00267854
	LOSS [training: 0.6333366445341959 | validation: 0.4207955760053734]
	TIME [epoch: 6.56 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2546660771733048		[learning rate: 0.0026722]
	Learning Rate: 0.00267222
	LOSS [training: 0.2546660771733048 | validation: 0.07986822677993867]
	TIME [epoch: 6.56 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08136408425191798		[learning rate: 0.0026659]
	Learning Rate: 0.00266591
	LOSS [training: 0.08136408425191798 | validation: 0.06998062910243222]
	TIME [epoch: 6.52 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07946614603597205		[learning rate: 0.0026596]
	Learning Rate: 0.00265963
	LOSS [training: 0.07946614603597205 | validation: 0.05761564634384974]
	TIME [epoch: 6.53 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13246406487936618		[learning rate: 0.0026534]
	Learning Rate: 0.00265335
	LOSS [training: 0.13246406487936618 | validation: 0.0652864600257014]
	TIME [epoch: 6.53 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07756771204928406		[learning rate: 0.0026471]
	Learning Rate: 0.00264709
	LOSS [training: 0.07756771204928406 | validation: 0.06288678377607423]
	TIME [epoch: 6.54 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07683157663816885		[learning rate: 0.0026408]
	Learning Rate: 0.00264085
	LOSS [training: 0.07683157663816885 | validation: 0.06924792417968802]
	TIME [epoch: 6.58 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09374858575227221		[learning rate: 0.0026346]
	Learning Rate: 0.00263462
	LOSS [training: 0.09374858575227221 | validation: 0.051735240901740226]
	TIME [epoch: 6.54 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0836419214922134		[learning rate: 0.0026284]
	Learning Rate: 0.00262841
	LOSS [training: 0.0836419214922134 | validation: 0.10108963471955541]
	TIME [epoch: 6.53 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08763451694555788		[learning rate: 0.0026222]
	Learning Rate: 0.00262221
	LOSS [training: 0.08763451694555788 | validation: 0.044530734587677444]
	TIME [epoch: 6.55 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14090156669084894		[learning rate: 0.002616]
	Learning Rate: 0.00261602
	LOSS [training: 0.14090156669084894 | validation: 0.3796990056469886]
	TIME [epoch: 6.53 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23861771724226247		[learning rate: 0.0026098]
	Learning Rate: 0.00260985
	LOSS [training: 0.23861771724226247 | validation: 0.10875262804639177]
	TIME [epoch: 6.54 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11770858882570608		[learning rate: 0.0026037]
	Learning Rate: 0.00260369
	LOSS [training: 0.11770858882570608 | validation: 0.06618167481793594]
	TIME [epoch: 6.58 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10199743304434375		[learning rate: 0.0025976]
	Learning Rate: 0.00259755
	LOSS [training: 0.10199743304434375 | validation: 0.08105117088175884]
	TIME [epoch: 6.52 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0952532822828828		[learning rate: 0.0025914]
	Learning Rate: 0.00259142
	LOSS [training: 0.0952532822828828 | validation: 0.06890093930072846]
	TIME [epoch: 6.53 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10640476558824123		[learning rate: 0.0025853]
	Learning Rate: 0.00258531
	LOSS [training: 0.10640476558824123 | validation: 0.09816456055807875]
	TIME [epoch: 6.54 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0945148458788854		[learning rate: 0.0025792]
	Learning Rate: 0.00257921
	LOSS [training: 0.0945148458788854 | validation: 0.0560661789708578]
	TIME [epoch: 6.54 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08401032042796264		[learning rate: 0.0025731]
	Learning Rate: 0.00257313
	LOSS [training: 0.08401032042796264 | validation: 0.10978058469540077]
	TIME [epoch: 6.56 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1942822044238618		[learning rate: 0.0025671]
	Learning Rate: 0.00256706
	LOSS [training: 0.1942822044238618 | validation: 0.2581276183847742]
	TIME [epoch: 6.55 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22531485671860887		[learning rate: 0.002561]
	Learning Rate: 0.002561
	LOSS [training: 0.22531485671860887 | validation: 0.24079305358758302]
	TIME [epoch: 6.54 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3306548432862412		[learning rate: 0.002555]
	Learning Rate: 0.00255496
	LOSS [training: 0.3306548432862412 | validation: 0.24245175679870573]
	TIME [epoch: 6.54 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1583703342006199		[learning rate: 0.0025489]
	Learning Rate: 0.00254894
	LOSS [training: 0.1583703342006199 | validation: 0.08803581663532883]
	TIME [epoch: 6.52 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11686844455785983		[learning rate: 0.0025429]
	Learning Rate: 0.00254292
	LOSS [training: 0.11686844455785983 | validation: 0.25039421023067865]
	TIME [epoch: 6.53 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14885623640167878		[learning rate: 0.0025369]
	Learning Rate: 0.00253693
	LOSS [training: 0.14885623640167878 | validation: 0.05393401189256358]
	TIME [epoch: 6.57 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06852699646513022		[learning rate: 0.0025309]
	Learning Rate: 0.00253094
	LOSS [training: 0.06852699646513022 | validation: 0.037470365880051565]
	TIME [epoch: 6.55 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12332440712189277		[learning rate: 0.002525]
	Learning Rate: 0.00252497
	LOSS [training: 0.12332440712189277 | validation: 0.04516545092201022]
	TIME [epoch: 6.53 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06581980147474202		[learning rate: 0.002519]
	Learning Rate: 0.00251901
	LOSS [training: 0.06581980147474202 | validation: 0.05685482174014077]
	TIME [epoch: 6.52 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06883370760587579		[learning rate: 0.0025131]
	Learning Rate: 0.00251307
	LOSS [training: 0.06883370760587579 | validation: 0.07037610534360032]
	TIME [epoch: 6.53 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08472980114617373		[learning rate: 0.0025071]
	Learning Rate: 0.00250715
	LOSS [training: 0.08472980114617373 | validation: 0.0640595964082996]
	TIME [epoch: 6.55 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07194046907920335		[learning rate: 0.0025012]
	Learning Rate: 0.00250123
	LOSS [training: 0.07194046907920335 | validation: 0.04831857770888812]
	TIME [epoch: 6.57 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05903121472465807		[learning rate: 0.0024953]
	Learning Rate: 0.00249533
	LOSS [training: 0.05903121472465807 | validation: 0.05776900926209523]
	TIME [epoch: 6.52 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0764575963137083		[learning rate: 0.0024894]
	Learning Rate: 0.00248945
	LOSS [training: 0.0764575963137083 | validation: 0.06336088889940839]
	TIME [epoch: 6.54 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07227557516471558		[learning rate: 0.0024836]
	Learning Rate: 0.00248357
	LOSS [training: 0.07227557516471558 | validation: 0.04932704564130779]
	TIME [epoch: 6.54 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0781611366372424		[learning rate: 0.0024777]
	Learning Rate: 0.00247771
	LOSS [training: 0.0781611366372424 | validation: 0.05150627612358495]
	TIME [epoch: 6.53 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07697127384546319		[learning rate: 0.0024719]
	Learning Rate: 0.00247187
	LOSS [training: 0.07697127384546319 | validation: 0.06442781883361354]
	TIME [epoch: 6.56 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0739163293066761		[learning rate: 0.002466]
	Learning Rate: 0.00246604
	LOSS [training: 0.0739163293066761 | validation: 0.10949785173191526]
	TIME [epoch: 6.56 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09215919863767127		[learning rate: 0.0024602]
	Learning Rate: 0.00246022
	LOSS [training: 0.09215919863767127 | validation: 0.04183680534095568]
	TIME [epoch: 6.53 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06822578502461925		[learning rate: 0.0024544]
	Learning Rate: 0.00245442
	LOSS [training: 0.06822578502461925 | validation: 0.06001725974945059]
	TIME [epoch: 6.54 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08445129133507008		[learning rate: 0.0024486]
	Learning Rate: 0.00244863
	LOSS [training: 0.08445129133507008 | validation: 0.05347412491653833]
	TIME [epoch: 6.52 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13504488186980407		[learning rate: 0.0024429]
	Learning Rate: 0.00244285
	LOSS [training: 0.13504488186980407 | validation: 0.0841726028765965]
	TIME [epoch: 6.53 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08869865453305255		[learning rate: 0.0024371]
	Learning Rate: 0.00243709
	LOSS [training: 0.08869865453305255 | validation: 0.07499213587304143]
	TIME [epoch: 6.57 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08278562228726352		[learning rate: 0.0024313]
	Learning Rate: 0.00243134
	LOSS [training: 0.08278562228726352 | validation: 0.05879420156040444]
	TIME [epoch: 6.55 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07721912105527888		[learning rate: 0.0024256]
	Learning Rate: 0.00242561
	LOSS [training: 0.07721912105527888 | validation: 0.06612983068913199]
	TIME [epoch: 6.53 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07916855385394919		[learning rate: 0.0024199]
	Learning Rate: 0.00241989
	LOSS [training: 0.07916855385394919 | validation: 0.07359878713498616]
	TIME [epoch: 6.55 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06887296372008689		[learning rate: 0.0024142]
	Learning Rate: 0.00241418
	LOSS [training: 0.06887296372008689 | validation: 0.05106121825292027]
	TIME [epoch: 6.53 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0891474460725044		[learning rate: 0.0024085]
	Learning Rate: 0.00240848
	LOSS [training: 0.0891474460725044 | validation: 0.0805743596061006]
	TIME [epoch: 6.56 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07813451963088051		[learning rate: 0.0024028]
	Learning Rate: 0.0024028
	LOSS [training: 0.07813451963088051 | validation: 0.07532319427464676]
	TIME [epoch: 6.57 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07612104427043186		[learning rate: 0.0023971]
	Learning Rate: 0.00239713
	LOSS [training: 0.07612104427043186 | validation: 0.0780502407438215]
	TIME [epoch: 6.54 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08965434045882889		[learning rate: 0.0023915]
	Learning Rate: 0.00239148
	LOSS [training: 0.08965434045882889 | validation: 0.09278849178991881]
	TIME [epoch: 6.53 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07794911322786324		[learning rate: 0.0023858]
	Learning Rate: 0.00238584
	LOSS [training: 0.07794911322786324 | validation: 0.0543314032936121]
	TIME [epoch: 6.53 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07820870290636431		[learning rate: 0.0023802]
	Learning Rate: 0.00238021
	LOSS [training: 0.07820870290636431 | validation: 0.08021781810523419]
	TIME [epoch: 6.49 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0940892091867758		[learning rate: 0.0023746]
	Learning Rate: 0.0023746
	LOSS [training: 0.0940892091867758 | validation: 0.05326640356150071]
	TIME [epoch: 6.56 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0828778637424616		[learning rate: 0.002369]
	Learning Rate: 0.00236899
	LOSS [training: 0.0828778637424616 | validation: 0.05448426007186648]
	TIME [epoch: 6.58 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0718177066483416		[learning rate: 0.0023634]
	Learning Rate: 0.00236341
	LOSS [training: 0.0718177066483416 | validation: 0.06401637986773803]
	TIME [epoch: 6.55 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07366345176634863		[learning rate: 0.0023578]
	Learning Rate: 0.00235783
	LOSS [training: 0.07366345176634863 | validation: 0.0741675172380141]
	TIME [epoch: 6.53 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07546240864305265		[learning rate: 0.0023523]
	Learning Rate: 0.00235227
	LOSS [training: 0.07546240864305265 | validation: 0.07406629223321007]
	TIME [epoch: 6.52 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08577188855434312		[learning rate: 0.0023467]
	Learning Rate: 0.00234672
	LOSS [training: 0.08577188855434312 | validation: 0.04703048808485871]
	TIME [epoch: 6.52 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09117416344848572		[learning rate: 0.0023412]
	Learning Rate: 0.00234119
	LOSS [training: 0.09117416344848572 | validation: 0.053973806256670004]
	TIME [epoch: 6.56 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06444465966253575		[learning rate: 0.0023357]
	Learning Rate: 0.00233566
	LOSS [training: 0.06444465966253575 | validation: 0.04399732063842248]
	TIME [epoch: 6.55 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06414049291432741		[learning rate: 0.0023302]
	Learning Rate: 0.00233015
	LOSS [training: 0.06414049291432741 | validation: 0.09244272009888788]
	TIME [epoch: 6.54 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10364164778083369		[learning rate: 0.0023247]
	Learning Rate: 0.00232466
	LOSS [training: 0.10364164778083369 | validation: 0.044095180585888]
	TIME [epoch: 6.54 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06050860852730883		[learning rate: 0.0023192]
	Learning Rate: 0.00231917
	LOSS [training: 0.06050860852730883 | validation: 0.04619432637899811]
	TIME [epoch: 6.54 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07584344232885054		[learning rate: 0.0023137]
	Learning Rate: 0.0023137
	LOSS [training: 0.07584344232885054 | validation: 0.057313673896485395]
	TIME [epoch: 6.53 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08193013800163813		[learning rate: 0.0023082]
	Learning Rate: 0.00230825
	LOSS [training: 0.08193013800163813 | validation: 0.04346141969952876]
	TIME [epoch: 6.58 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06974595365058772		[learning rate: 0.0023028]
	Learning Rate: 0.0023028
	LOSS [training: 0.06974595365058772 | validation: 0.07630979972167654]
	TIME [epoch: 6.54 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0917273678970472		[learning rate: 0.0022974]
	Learning Rate: 0.00229737
	LOSS [training: 0.0917273678970472 | validation: 0.05413654204688309]
	TIME [epoch: 6.53 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07011319779774874		[learning rate: 0.0022919]
	Learning Rate: 0.00229195
	LOSS [training: 0.07011319779774874 | validation: 0.05460906271244299]
	TIME [epoch: 6.55 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06896594855031765		[learning rate: 0.0022865]
	Learning Rate: 0.00228654
	LOSS [training: 0.06896594855031765 | validation: 0.07253967629374546]
	TIME [epoch: 6.54 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0734300208412691		[learning rate: 0.0022811]
	Learning Rate: 0.00228115
	LOSS [training: 0.0734300208412691 | validation: 0.054668969333669874]
	TIME [epoch: 6.54 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05935319011939959		[learning rate: 0.0022758]
	Learning Rate: 0.00227577
	LOSS [training: 0.05935319011939959 | validation: 0.038638610387308495]
	TIME [epoch: 6.57 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07224827395724903		[learning rate: 0.0022704]
	Learning Rate: 0.0022704
	LOSS [training: 0.07224827395724903 | validation: 0.046997487142825894]
	TIME [epoch: 6.55 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11743638752141969		[learning rate: 0.002265]
	Learning Rate: 0.00226505
	LOSS [training: 0.11743638752141969 | validation: 0.15258290834430582]
	TIME [epoch: 6.55 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0849814870540449		[learning rate: 0.0022597]
	Learning Rate: 0.0022597
	LOSS [training: 0.0849814870540449 | validation: 0.051042787021134954]
	TIME [epoch: 6.55 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06866065493699527		[learning rate: 0.0022544]
	Learning Rate: 0.00225437
	LOSS [training: 0.06866065493699527 | validation: 0.04561520893994048]
	TIME [epoch: 6.55 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07044141834539804		[learning rate: 0.0022491]
	Learning Rate: 0.00224905
	LOSS [training: 0.07044141834539804 | validation: 0.10155216317561033]
	TIME [epoch: 6.56 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09171919723358775		[learning rate: 0.0022437]
	Learning Rate: 0.00224375
	LOSS [training: 0.09171919723358775 | validation: 0.05934636233653539]
	TIME [epoch: 6.55 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07673262752440019		[learning rate: 0.0022385]
	Learning Rate: 0.00223846
	LOSS [training: 0.07673262752440019 | validation: 0.051376426118742546]
	TIME [epoch: 6.54 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07427823411598843		[learning rate: 0.0022332]
	Learning Rate: 0.00223318
	LOSS [training: 0.07427823411598843 | validation: 0.04646350902719209]
	TIME [epoch: 6.52 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0649052222726129		[learning rate: 0.0022279]
	Learning Rate: 0.00222791
	LOSS [training: 0.0649052222726129 | validation: 0.04506725267986044]
	TIME [epoch: 6.53 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059832702262557345		[learning rate: 0.0022227]
	Learning Rate: 0.00222265
	LOSS [training: 0.059832702262557345 | validation: 0.0410724229719296]
	TIME [epoch: 6.55 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061044408184129616		[learning rate: 0.0022174]
	Learning Rate: 0.00221741
	LOSS [training: 0.061044408184129616 | validation: 0.06340808171452833]
	TIME [epoch: 6.57 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06896688705225086		[learning rate: 0.0022122]
	Learning Rate: 0.00221218
	LOSS [training: 0.06896688705225086 | validation: 0.046189739354412174]
	TIME [epoch: 6.53 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06193073000740722		[learning rate: 0.002207]
	Learning Rate: 0.00220696
	LOSS [training: 0.06193073000740722 | validation: 0.04270324399281829]
	TIME [epoch: 6.53 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07043924797451086		[learning rate: 0.0022018]
	Learning Rate: 0.00220176
	LOSS [training: 0.07043924797451086 | validation: 0.048810996799838954]
	TIME [epoch: 6.55 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061485493666764014		[learning rate: 0.0021966]
	Learning Rate: 0.00219656
	LOSS [training: 0.061485493666764014 | validation: 0.057840981455728385]
	TIME [epoch: 6.52 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34768669357457976		[learning rate: 0.0021914]
	Learning Rate: 0.00219138
	LOSS [training: 0.34768669357457976 | validation: 0.4489332746020951]
	TIME [epoch: 6.56 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2581950186278103		[learning rate: 0.0021862]
	Learning Rate: 0.00218621
	LOSS [training: 0.2581950186278103 | validation: 0.12528162815935054]
	TIME [epoch: 6.57 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11658697713891883		[learning rate: 0.0021811]
	Learning Rate: 0.00218106
	LOSS [training: 0.11658697713891883 | validation: 0.09759647185010897]
	TIME [epoch: 6.54 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08142120807912337		[learning rate: 0.0021759]
	Learning Rate: 0.00217591
	LOSS [training: 0.08142120807912337 | validation: 0.054099196706647514]
	TIME [epoch: 6.55 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08285821784379091		[learning rate: 0.0021708]
	Learning Rate: 0.00217078
	LOSS [training: 0.08285821784379091 | validation: 0.09970853656303849]
	TIME [epoch: 6.54 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10754977763641908		[learning rate: 0.0021657]
	Learning Rate: 0.00216566
	LOSS [training: 0.10754977763641908 | validation: 0.0918065796731638]
	TIME [epoch: 6.53 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11392820803130514		[learning rate: 0.0021605]
	Learning Rate: 0.00216055
	LOSS [training: 0.11392820803130514 | validation: 0.5126809288963698]
	TIME [epoch: 6.54 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7040900491064118		[learning rate: 0.0021555]
	Learning Rate: 0.00215545
	LOSS [training: 0.7040900491064118 | validation: 0.42444095903158047]
	TIME [epoch: 6.56 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6413431832350823		[learning rate: 0.0021504]
	Learning Rate: 0.00215037
	LOSS [training: 0.6413431832350823 | validation: 0.4347711861517591]
	TIME [epoch: 6.52 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6185229403007548		[learning rate: 0.0021453]
	Learning Rate: 0.0021453
	LOSS [training: 0.6185229403007548 | validation: 0.19917118940608114]
	TIME [epoch: 6.52 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12708591560720559		[learning rate: 0.0021402]
	Learning Rate: 0.00214024
	LOSS [training: 0.12708591560720559 | validation: 0.07539602052170102]
	TIME [epoch: 6.52 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08798185807960732		[learning rate: 0.0021352]
	Learning Rate: 0.00213519
	LOSS [training: 0.08798185807960732 | validation: 0.10261177992552488]
	TIME [epoch: 6.53 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11811850585574404		[learning rate: 0.0021302]
	Learning Rate: 0.00213015
	LOSS [training: 0.11811850585574404 | validation: 0.11027690301839344]
	TIME [epoch: 6.58 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13193639112619066		[learning rate: 0.0021251]
	Learning Rate: 0.00212513
	LOSS [training: 0.13193639112619066 | validation: 0.10684839372706617]
	TIME [epoch: 6.54 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11639272622771415		[learning rate: 0.0021201]
	Learning Rate: 0.00212011
	LOSS [training: 0.11639272622771415 | validation: 0.0650240055655238]
	TIME [epoch: 6.55 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17349065082051157		[learning rate: 0.0021151]
	Learning Rate: 0.00211511
	LOSS [training: 0.17349065082051157 | validation: 0.37020731526960365]
	TIME [epoch: 6.52 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2811302803323952		[learning rate: 0.0021101]
	Learning Rate: 0.00211012
	LOSS [training: 0.2811302803323952 | validation: 0.061152161530371854]
	TIME [epoch: 6.54 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06122880800272966		[learning rate: 0.0021051]
	Learning Rate: 0.00210515
	LOSS [training: 0.06122880800272966 | validation: 0.045261763182656824]
	TIME [epoch: 6.53 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06036163994471002		[learning rate: 0.0021002]
	Learning Rate: 0.00210018
	LOSS [training: 0.06036163994471002 | validation: 0.06885092950126229]
	TIME [epoch: 6.58 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06463329881558699		[learning rate: 0.0020952]
	Learning Rate: 0.00209523
	LOSS [training: 0.06463329881558699 | validation: 0.04259247936845373]
	TIME [epoch: 6.51 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07948204783447346		[learning rate: 0.0020903]
	Learning Rate: 0.00209028
	LOSS [training: 0.07948204783447346 | validation: 0.048858829146907104]
	TIME [epoch: 6.5 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06969374336784688		[learning rate: 0.0020854]
	Learning Rate: 0.00208535
	LOSS [training: 0.06969374336784688 | validation: 0.052230421990413764]
	TIME [epoch: 6.51 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057674833460501895		[learning rate: 0.0020804]
	Learning Rate: 0.00208043
	LOSS [training: 0.057674833460501895 | validation: 0.03817369466356557]
	TIME [epoch: 6.53 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05402019932637758		[learning rate: 0.0020755]
	Learning Rate: 0.00207553
	LOSS [training: 0.05402019932637758 | validation: 0.07291695140381665]
	TIME [epoch: 6.53 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0675992417956058		[learning rate: 0.0020706]
	Learning Rate: 0.00207063
	LOSS [training: 0.0675992417956058 | validation: 0.0489256689355069]
	TIME [epoch: 6.54 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061415222709210474		[learning rate: 0.0020657]
	Learning Rate: 0.00206575
	LOSS [training: 0.061415222709210474 | validation: 0.07489772745571699]
	TIME [epoch: 6.5 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06449202308113336		[learning rate: 0.0020609]
	Learning Rate: 0.00206087
	LOSS [training: 0.06449202308113336 | validation: 0.048364332884844305]
	TIME [epoch: 6.51 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06841381053152036		[learning rate: 0.002056]
	Learning Rate: 0.00205601
	LOSS [training: 0.06841381053152036 | validation: 0.08071409252409326]
	TIME [epoch: 6.51 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08991981609004786		[learning rate: 0.0020512]
	Learning Rate: 0.00205116
	LOSS [training: 0.08991981609004786 | validation: 0.049622836997796765]
	TIME [epoch: 6.51 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0737442498384029		[learning rate: 0.0020463]
	Learning Rate: 0.00204632
	LOSS [training: 0.0737442498384029 | validation: 0.04358590283367802]
	TIME [epoch: 6.55 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06899513962222606		[learning rate: 0.0020415]
	Learning Rate: 0.0020415
	LOSS [training: 0.06899513962222606 | validation: 0.0676957183713357]
	TIME [epoch: 6.53 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0859697970701592		[learning rate: 0.0020367]
	Learning Rate: 0.00203668
	LOSS [training: 0.0859697970701592 | validation: 0.08261285875558556]
	TIME [epoch: 6.53 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09341247000716987		[learning rate: 0.0020319]
	Learning Rate: 0.00203188
	LOSS [training: 0.09341247000716987 | validation: 0.04852883652509986]
	TIME [epoch: 6.5 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06448471312897067		[learning rate: 0.0020271]
	Learning Rate: 0.00202708
	LOSS [training: 0.06448471312897067 | validation: 0.043187717879427046]
	TIME [epoch: 6.51 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06015907732411049		[learning rate: 0.0020223]
	Learning Rate: 0.0020223
	LOSS [training: 0.06015907732411049 | validation: 0.039292592427292355]
	TIME [epoch: 6.5 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05445703547823868		[learning rate: 0.0020175]
	Learning Rate: 0.00201753
	LOSS [training: 0.05445703547823868 | validation: 0.047972124291504284]
	TIME [epoch: 6.53 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06226673436834198		[learning rate: 0.0020128]
	Learning Rate: 0.00201277
	LOSS [training: 0.06226673436834198 | validation: 0.07163692818163864]
	TIME [epoch: 6.51 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10454130215016606		[learning rate: 0.002008]
	Learning Rate: 0.00200803
	LOSS [training: 0.10454130215016606 | validation: 0.07570243092616151]
	TIME [epoch: 6.51 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07997189754536563		[learning rate: 0.0020033]
	Learning Rate: 0.00200329
	LOSS [training: 0.07997189754536563 | validation: 0.0487492456799895]
	TIME [epoch: 6.52 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05832183865482262		[learning rate: 0.0019986]
	Learning Rate: 0.00199856
	LOSS [training: 0.05832183865482262 | validation: 0.029871847499186335]
	TIME [epoch: 6.5 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_732.pth
	Model improved!!!
EPOCH 733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06930836086406363		[learning rate: 0.0019938]
	Learning Rate: 0.00199385
	LOSS [training: 0.06930836086406363 | validation: 0.05141876734363054]
	TIME [epoch: 6.52 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07845299249650983		[learning rate: 0.0019891]
	Learning Rate: 0.00198915
	LOSS [training: 0.07845299249650983 | validation: 0.040869552958055506]
	TIME [epoch: 6.53 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06787375205253887		[learning rate: 0.0019845]
	Learning Rate: 0.00198445
	LOSS [training: 0.06787375205253887 | validation: 0.04175152782675511]
	TIME [epoch: 6.5 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06979144371509427		[learning rate: 0.0019798]
	Learning Rate: 0.00197977
	LOSS [training: 0.06979144371509427 | validation: 0.045177942645784105]
	TIME [epoch: 6.49 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06253738890946933		[learning rate: 0.0019751]
	Learning Rate: 0.0019751
	LOSS [training: 0.06253738890946933 | validation: 0.04812799191294878]
	TIME [epoch: 6.49 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.062331758932909966		[learning rate: 0.0019704]
	Learning Rate: 0.00197044
	LOSS [training: 0.062331758932909966 | validation: 0.04687734236575402]
	TIME [epoch: 6.5 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08205047750948163		[learning rate: 0.0019658]
	Learning Rate: 0.0019658
	LOSS [training: 0.08205047750948163 | validation: 0.04856973617145889]
	TIME [epoch: 6.54 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05771636394596018		[learning rate: 0.0019612]
	Learning Rate: 0.00196116
	LOSS [training: 0.05771636394596018 | validation: 0.034452431851160675]
	TIME [epoch: 6.52 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07509558125294795		[learning rate: 0.0019565]
	Learning Rate: 0.00195653
	LOSS [training: 0.07509558125294795 | validation: 0.059487969770604554]
	TIME [epoch: 6.5 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06331856881491489		[learning rate: 0.0019519]
	Learning Rate: 0.00195192
	LOSS [training: 0.06331856881491489 | validation: 0.03474266008032509]
	TIME [epoch: 6.5 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05360741019073055		[learning rate: 0.0019473]
	Learning Rate: 0.00194731
	LOSS [training: 0.05360741019073055 | validation: 0.04629450284936214]
	TIME [epoch: 6.5 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.051835413450573284		[learning rate: 0.0019427]
	Learning Rate: 0.00194272
	LOSS [training: 0.051835413450573284 | validation: 0.044093158249531174]
	TIME [epoch: 6.5 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0537438063915547		[learning rate: 0.0019381]
	Learning Rate: 0.00193814
	LOSS [training: 0.0537438063915547 | validation: 0.04941905060918537]
	TIME [epoch: 6.55 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0590385346186193		[learning rate: 0.0019336]
	Learning Rate: 0.00193357
	LOSS [training: 0.0590385346186193 | validation: 0.040229054992994104]
	TIME [epoch: 6.53 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0689325642748069		[learning rate: 0.001929]
	Learning Rate: 0.001929
	LOSS [training: 0.0689325642748069 | validation: 0.0513087178784193]
	TIME [epoch: 6.51 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059960503167994804		[learning rate: 0.0019245]
	Learning Rate: 0.00192445
	LOSS [training: 0.059960503167994804 | validation: 0.0852059796476404]
	TIME [epoch: 6.51 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10364437028220697		[learning rate: 0.0019199]
	Learning Rate: 0.00191992
	LOSS [training: 0.10364437028220697 | validation: 0.08737317157422964]
	TIME [epoch: 6.5 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07695294104870164		[learning rate: 0.0019154]
	Learning Rate: 0.00191539
	LOSS [training: 0.07695294104870164 | validation: 0.03734210309365381]
	TIME [epoch: 6.52 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06459842417391867		[learning rate: 0.0019109]
	Learning Rate: 0.00191087
	LOSS [training: 0.06459842417391867 | validation: 0.06571747758627629]
	TIME [epoch: 6.53 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08109801785050563		[learning rate: 0.0019064]
	Learning Rate: 0.00190636
	LOSS [training: 0.08109801785050563 | validation: 0.054707593889035844]
	TIME [epoch: 6.5 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12328854178422155		[learning rate: 0.0019019]
	Learning Rate: 0.00190186
	LOSS [training: 0.12328854178422155 | validation: 0.0898522965249339]
	TIME [epoch: 6.51 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22023025599771429		[learning rate: 0.0018974]
	Learning Rate: 0.00189738
	LOSS [training: 0.22023025599771429 | validation: 0.27160366033012767]
	TIME [epoch: 6.49 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1469512400285958		[learning rate: 0.0018929]
	Learning Rate: 0.0018929
	LOSS [training: 0.1469512400285958 | validation: 0.09725398948850103]
	TIME [epoch: 6.5 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10162028597660691		[learning rate: 0.0018884]
	Learning Rate: 0.00188844
	LOSS [training: 0.10162028597660691 | validation: 0.06243263498186195]
	TIME [epoch: 6.51 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0755811042497597		[learning rate: 0.001884]
	Learning Rate: 0.00188398
	LOSS [training: 0.0755811042497597 | validation: 0.03933183412434935]
	TIME [epoch: 6.56 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07434352156516373		[learning rate: 0.0018795]
	Learning Rate: 0.00187954
	LOSS [training: 0.07434352156516373 | validation: 0.061051551767965936]
	TIME [epoch: 6.49 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07192729556170202		[learning rate: 0.0018751]
	Learning Rate: 0.00187511
	LOSS [training: 0.07192729556170202 | validation: 0.061643552823097233]
	TIME [epoch: 6.51 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07073945762725178		[learning rate: 0.0018707]
	Learning Rate: 0.00187068
	LOSS [training: 0.07073945762725178 | validation: 0.049699586834488114]
	TIME [epoch: 6.5 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059651008183260947		[learning rate: 0.0018663]
	Learning Rate: 0.00186627
	LOSS [training: 0.059651008183260947 | validation: 0.0626912200329047]
	TIME [epoch: 6.5 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07093350586232702		[learning rate: 0.0018619]
	Learning Rate: 0.00186187
	LOSS [training: 0.07093350586232702 | validation: 0.05578640812044938]
	TIME [epoch: 6.52 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0744441645075011		[learning rate: 0.0018575]
	Learning Rate: 0.00185748
	LOSS [training: 0.0744441645075011 | validation: 0.07868686197376432]
	TIME [epoch: 6.53 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1564125412828146		[learning rate: 0.0018531]
	Learning Rate: 0.00185309
	LOSS [training: 0.1564125412828146 | validation: 0.10262396632607103]
	TIME [epoch: 6.52 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09481166075588263		[learning rate: 0.0018487]
	Learning Rate: 0.00184872
	LOSS [training: 0.09481166075588263 | validation: 0.05304319994593988]
	TIME [epoch: 6.52 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06096255988218267		[learning rate: 0.0018444]
	Learning Rate: 0.00184436
	LOSS [training: 0.06096255988218267 | validation: 0.029067261158872204]
	TIME [epoch: 6.49 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_766.pth
	Model improved!!!
EPOCH 767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.051960657890821646		[learning rate: 0.00184]
	Learning Rate: 0.00184001
	LOSS [training: 0.051960657890821646 | validation: 0.03974665928428614]
	TIME [epoch: 6.5 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05822043209674893		[learning rate: 0.0018357]
	Learning Rate: 0.00183567
	LOSS [training: 0.05822043209674893 | validation: 0.026491970631107902]
	TIME [epoch: 6.53 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_768.pth
	Model improved!!!
EPOCH 769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060158532866331715		[learning rate: 0.0018313]
	Learning Rate: 0.00183134
	LOSS [training: 0.060158532866331715 | validation: 0.045316648192918516]
	TIME [epoch: 6.53 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05855184616171609		[learning rate: 0.001827]
	Learning Rate: 0.00182702
	LOSS [training: 0.05855184616171609 | validation: 0.050231320157476535]
	TIME [epoch: 6.49 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07737327695828283		[learning rate: 0.0018227]
	Learning Rate: 0.00182271
	LOSS [training: 0.07737327695828283 | validation: 0.03837627571690801]
	TIME [epoch: 6.51 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04837371071537745		[learning rate: 0.0018184]
	Learning Rate: 0.00181841
	LOSS [training: 0.04837371071537745 | validation: 0.0367967566812701]
	TIME [epoch: 6.51 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06067197607462167		[learning rate: 0.0018141]
	Learning Rate: 0.00181412
	LOSS [training: 0.06067197607462167 | validation: 0.0878437245618143]
	TIME [epoch: 6.51 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061329137626419186		[learning rate: 0.0018098]
	Learning Rate: 0.00180984
	LOSS [training: 0.061329137626419186 | validation: 0.05240138345256752]
	TIME [epoch: 6.56 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06038106373537794		[learning rate: 0.0018056]
	Learning Rate: 0.00180557
	LOSS [training: 0.06038106373537794 | validation: 0.03502840856030917]
	TIME [epoch: 6.5 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04690795609960892		[learning rate: 0.0018013]
	Learning Rate: 0.00180132
	LOSS [training: 0.04690795609960892 | validation: 0.04013454180981263]
	TIME [epoch: 6.49 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06379447011377096		[learning rate: 0.0017971]
	Learning Rate: 0.00179707
	LOSS [training: 0.06379447011377096 | validation: 0.07279913830708273]
	TIME [epoch: 6.49 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0735369394407291		[learning rate: 0.0017928]
	Learning Rate: 0.00179283
	LOSS [training: 0.0735369394407291 | validation: 0.0509280672507158]
	TIME [epoch: 6.52 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055575991933494585		[learning rate: 0.0017886]
	Learning Rate: 0.0017886
	LOSS [training: 0.055575991933494585 | validation: 0.03998966731072216]
	TIME [epoch: 6.59 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060619614296090994		[learning rate: 0.0017844]
	Learning Rate: 0.00178438
	LOSS [training: 0.060619614296090994 | validation: 0.04136957180611617]
	TIME [epoch: 6.51 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055974094817979735		[learning rate: 0.0017802]
	Learning Rate: 0.00178017
	LOSS [training: 0.055974094817979735 | validation: 0.03376378918466421]
	TIME [epoch: 6.5 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05606132228038817		[learning rate: 0.001776]
	Learning Rate: 0.00177597
	LOSS [training: 0.05606132228038817 | validation: 0.04062355477162767]
	TIME [epoch: 6.49 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05454783396744942		[learning rate: 0.0017718]
	Learning Rate: 0.00177178
	LOSS [training: 0.05454783396744942 | validation: 0.02993881794204855]
	TIME [epoch: 6.51 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.051031958121637785		[learning rate: 0.0017676]
	Learning Rate: 0.0017676
	LOSS [training: 0.051031958121637785 | validation: 0.03529666800287901]
	TIME [epoch: 6.5 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06018893585618832		[learning rate: 0.0017634]
	Learning Rate: 0.00176343
	LOSS [training: 0.06018893585618832 | validation: 0.034106290758489824]
	TIME [epoch: 6.53 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05334351078011338		[learning rate: 0.0017593]
	Learning Rate: 0.00175927
	LOSS [training: 0.05334351078011338 | validation: 0.04767752819059047]
	TIME [epoch: 6.52 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05699241008622148		[learning rate: 0.0017551]
	Learning Rate: 0.00175512
	LOSS [training: 0.05699241008622148 | validation: 0.03632232681299968]
	TIME [epoch: 6.49 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12601905395754762		[learning rate: 0.001751]
	Learning Rate: 0.00175098
	LOSS [training: 0.12601905395754762 | validation: 0.020913838839177513]
	TIME [epoch: 6.51 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_788.pth
	Model improved!!!
EPOCH 789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053292929455282564		[learning rate: 0.0017469]
	Learning Rate: 0.00174685
	LOSS [training: 0.053292929455282564 | validation: 0.053600332972766236]
	TIME [epoch: 6.52 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06586717405307574		[learning rate: 0.0017427]
	Learning Rate: 0.00174273
	LOSS [training: 0.06586717405307574 | validation: 0.05049335875047792]
	TIME [epoch: 6.52 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053065970540126385		[learning rate: 0.0017386]
	Learning Rate: 0.00173862
	LOSS [training: 0.053065970540126385 | validation: 0.046367981509873604]
	TIME [epoch: 6.53 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05782727201839786		[learning rate: 0.0017345]
	Learning Rate: 0.00173452
	LOSS [training: 0.05782727201839786 | validation: 0.04032639183422775]
	TIME [epoch: 6.52 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05130773004535729		[learning rate: 0.0017304]
	Learning Rate: 0.00173043
	LOSS [training: 0.05130773004535729 | validation: 0.04002893644483081]
	TIME [epoch: 6.5 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.048345739627015626		[learning rate: 0.0017263]
	Learning Rate: 0.00172635
	LOSS [training: 0.048345739627015626 | validation: 0.03863590437648848]
	TIME [epoch: 6.5 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05134857942982971		[learning rate: 0.0017223]
	Learning Rate: 0.00172228
	LOSS [training: 0.05134857942982971 | validation: 0.02764794114798528]
	TIME [epoch: 6.5 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06388743065074788		[learning rate: 0.0017182]
	Learning Rate: 0.00171821
	LOSS [training: 0.06388743065074788 | validation: 0.09168155803030931]
	TIME [epoch: 6.53 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0722316874908365		[learning rate: 0.0017142]
	Learning Rate: 0.00171416
	LOSS [training: 0.0722316874908365 | validation: 0.07419646390517412]
	TIME [epoch: 6.52 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07701691246448994		[learning rate: 0.0017101]
	Learning Rate: 0.00171012
	LOSS [training: 0.07701691246448994 | validation: 0.031863206707116176]
	TIME [epoch: 6.5 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04343195936089326		[learning rate: 0.0017061]
	Learning Rate: 0.00170608
	LOSS [training: 0.04343195936089326 | validation: 0.03497425999187298]
	TIME [epoch: 6.5 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05269828676088216		[learning rate: 0.0017021]
	Learning Rate: 0.00170206
	LOSS [training: 0.05269828676088216 | validation: 0.06325183490059476]
	TIME [epoch: 6.51 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1260459160746812		[learning rate: 0.001698]
	Learning Rate: 0.00169804
	LOSS [training: 0.1260459160746812 | validation: 0.09691157660133175]
	TIME [epoch: 6.52 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10712909693882225		[learning rate: 0.001694]
	Learning Rate: 0.00169404
	LOSS [training: 0.10712909693882225 | validation: 0.09780071720750216]
	TIME [epoch: 6.54 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.079047785807096		[learning rate: 0.00169]
	Learning Rate: 0.00169004
	LOSS [training: 0.079047785807096 | validation: 0.04386333417521315]
	TIME [epoch: 6.5 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06224219072143279		[learning rate: 0.0016861]
	Learning Rate: 0.00168606
	LOSS [training: 0.06224219072143279 | validation: 0.04023403217427311]
	TIME [epoch: 6.5 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060921903149748546		[learning rate: 0.0016821]
	Learning Rate: 0.00168208
	LOSS [training: 0.060921903149748546 | validation: 0.0495310974079081]
	TIME [epoch: 6.52 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058825337528210286		[learning rate: 0.0016781]
	Learning Rate: 0.00167811
	LOSS [training: 0.058825337528210286 | validation: 0.0355983417741101]
	TIME [epoch: 6.51 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08157273859381307		[learning rate: 0.0016742]
	Learning Rate: 0.00167415
	LOSS [training: 0.08157273859381307 | validation: 0.07460567417115997]
	TIME [epoch: 6.51 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09784840213380945		[learning rate: 0.0016702]
	Learning Rate: 0.0016702
	LOSS [training: 0.09784840213380945 | validation: 0.20184331365879782]
	TIME [epoch: 6.56 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3219215821017596		[learning rate: 0.0016663]
	Learning Rate: 0.00166626
	LOSS [training: 0.3219215821017596 | validation: 0.384923415503462]
	TIME [epoch: 6.52 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2452919637415099		[learning rate: 0.0016623]
	Learning Rate: 0.00166233
	LOSS [training: 0.2452919637415099 | validation: 0.10602481773772578]
	TIME [epoch: 6.52 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11883876904737681		[learning rate: 0.0016584]
	Learning Rate: 0.00165841
	LOSS [training: 0.11883876904737681 | validation: 0.08250693110354754]
	TIME [epoch: 6.52 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07786087566613717		[learning rate: 0.0016545]
	Learning Rate: 0.0016545
	LOSS [training: 0.07786087566613717 | validation: 0.08498950422392414]
	TIME [epoch: 6.52 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07945031207216169		[learning rate: 0.0016506]
	Learning Rate: 0.0016506
	LOSS [training: 0.07945031207216169 | validation: 0.04967875963308624]
	TIME [epoch: 6.53 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07084416510091059		[learning rate: 0.0016467]
	Learning Rate: 0.0016467
	LOSS [training: 0.07084416510091059 | validation: 0.042875809263079184]
	TIME [epoch: 6.55 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06114021095898241		[learning rate: 0.0016428]
	Learning Rate: 0.00164282
	LOSS [training: 0.06114021095898241 | validation: 0.040015590541439924]
	TIME [epoch: 6.49 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05793816112882784		[learning rate: 0.0016389]
	Learning Rate: 0.00163894
	LOSS [training: 0.05793816112882784 | validation: 0.03312295878659778]
	TIME [epoch: 6.51 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04981233725077082		[learning rate: 0.0016351]
	Learning Rate: 0.00163508
	LOSS [training: 0.04981233725077082 | validation: 0.05096772745362503]
	TIME [epoch: 6.52 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08019363688704025		[learning rate: 0.0016312]
	Learning Rate: 0.00163122
	LOSS [training: 0.08019363688704025 | validation: 0.04420480181478423]
	TIME [epoch: 6.51 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061484796008221064		[learning rate: 0.0016274]
	Learning Rate: 0.00162737
	LOSS [training: 0.061484796008221064 | validation: 0.07130765946339171]
	TIME [epoch: 6.54 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06839404056852129		[learning rate: 0.0016235]
	Learning Rate: 0.00162353
	LOSS [training: 0.06839404056852129 | validation: 0.04197557726601313]
	TIME [epoch: 6.53 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07000683162769575		[learning rate: 0.0016197]
	Learning Rate: 0.0016197
	LOSS [training: 0.07000683162769575 | validation: 0.06845486942980654]
	TIME [epoch: 6.51 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061772142246574124		[learning rate: 0.0016159]
	Learning Rate: 0.00161588
	LOSS [training: 0.061772142246574124 | validation: 0.03745893267229316]
	TIME [epoch: 6.5 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04941859390563704		[learning rate: 0.0016121]
	Learning Rate: 0.00161207
	LOSS [training: 0.04941859390563704 | validation: 0.04114133653021306]
	TIME [epoch: 6.51 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04794768516480052		[learning rate: 0.0016083]
	Learning Rate: 0.00160827
	LOSS [training: 0.04794768516480052 | validation: 0.02651367742980368]
	TIME [epoch: 6.51 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0464329016098871		[learning rate: 0.0016045]
	Learning Rate: 0.00160448
	LOSS [training: 0.0464329016098871 | validation: 0.04489190159730494]
	TIME [epoch: 6.55 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06115167891303049		[learning rate: 0.0016007]
	Learning Rate: 0.00160069
	LOSS [training: 0.06115167891303049 | validation: 0.03791077997629445]
	TIME [epoch: 6.52 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22045608319795956		[learning rate: 0.0015969]
	Learning Rate: 0.00159692
	LOSS [training: 0.22045608319795956 | validation: 0.05581401438886315]
	TIME [epoch: 6.52 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.049771492168654334		[learning rate: 0.0015931]
	Learning Rate: 0.00159315
	LOSS [training: 0.049771492168654334 | validation: 0.05018699442729818]
	TIME [epoch: 6.5 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0757243051935872		[learning rate: 0.0015894]
	Learning Rate: 0.00158939
	LOSS [training: 0.0757243051935872 | validation: 0.041115747327959876]
	TIME [epoch: 6.53 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10191981550169656		[learning rate: 0.0015856]
	Learning Rate: 0.00158564
	LOSS [training: 0.10191981550169656 | validation: 0.06243370511195589]
	TIME [epoch: 6.54 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.052243092339416874		[learning rate: 0.0015819]
	Learning Rate: 0.0015819
	LOSS [training: 0.052243092339416874 | validation: 0.07203344541202664]
	TIME [epoch: 6.56 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06205685068774851		[learning rate: 0.0015782]
	Learning Rate: 0.00157817
	LOSS [training: 0.06205685068774851 | validation: 0.026072576510242616]
	TIME [epoch: 6.53 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03602536404346884		[learning rate: 0.0015744]
	Learning Rate: 0.00157445
	LOSS [training: 0.03602536404346884 | validation: 0.011923198340230153]
	TIME [epoch: 6.52 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_833.pth
	Model improved!!!
EPOCH 834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13485096399726576		[learning rate: 0.0015707]
	Learning Rate: 0.00157073
	LOSS [training: 0.13485096399726576 | validation: 0.3180639343548434]
	TIME [epoch: 6.52 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3979013442396772		[learning rate: 0.001567]
	Learning Rate: 0.00156703
	LOSS [training: 0.3979013442396772 | validation: 0.1514540909944048]
	TIME [epoch: 6.52 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09168292659112695		[learning rate: 0.0015633]
	Learning Rate: 0.00156333
	LOSS [training: 0.09168292659112695 | validation: 0.020236579675704334]
	TIME [epoch: 6.53 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16658670749851465		[learning rate: 0.0015596]
	Learning Rate: 0.00155964
	LOSS [training: 0.16658670749851465 | validation: 0.10539617935997622]
	TIME [epoch: 6.54 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0713096842573176		[learning rate: 0.001556]
	Learning Rate: 0.00155597
	LOSS [training: 0.0713096842573176 | validation: 0.03250657313669715]
	TIME [epoch: 6.52 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.044589295237280994		[learning rate: 0.0015523]
	Learning Rate: 0.0015523
	LOSS [training: 0.044589295237280994 | validation: 0.022880811221075156]
	TIME [epoch: 6.5 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04139290990672633		[learning rate: 0.0015486]
	Learning Rate: 0.00154863
	LOSS [training: 0.04139290990672633 | validation: 0.04829171984014166]
	TIME [epoch: 6.52 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060974647294459464		[learning rate: 0.001545]
	Learning Rate: 0.00154498
	LOSS [training: 0.060974647294459464 | validation: 0.04368847422092343]
	TIME [epoch: 6.52 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0572266443590073		[learning rate: 0.0015413]
	Learning Rate: 0.00154134
	LOSS [training: 0.0572266443590073 | validation: 0.03597487399692353]
	TIME [epoch: 6.56 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08031235224324028		[learning rate: 0.0015377]
	Learning Rate: 0.0015377
	LOSS [training: 0.08031235224324028 | validation: 0.23641152811877253]
	TIME [epoch: 6.51 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18389708064880644		[learning rate: 0.0015341]
	Learning Rate: 0.00153407
	LOSS [training: 0.18389708064880644 | validation: 0.1128660921854743]
	TIME [epoch: 6.49 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1086686972460221		[learning rate: 0.0015305]
	Learning Rate: 0.00153045
	LOSS [training: 0.1086686972460221 | validation: 0.07398318055167225]
	TIME [epoch: 6.5 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.072361890596727		[learning rate: 0.0015268]
	Learning Rate: 0.00152684
	LOSS [training: 0.072361890596727 | validation: 0.08642317752659931]
	TIME [epoch: 6.52 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10956108514442757		[learning rate: 0.0015232]
	Learning Rate: 0.00152324
	LOSS [training: 0.10956108514442757 | validation: 0.09040941074537603]
	TIME [epoch: 6.52 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08347246421931985		[learning rate: 0.0015196]
	Learning Rate: 0.00151965
	LOSS [training: 0.08347246421931985 | validation: 0.052039167544077]
	TIME [epoch: 6.55 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06469426668779943		[learning rate: 0.0015161]
	Learning Rate: 0.00151607
	LOSS [training: 0.06469426668779943 | validation: 0.05007932234791304]
	TIME [epoch: 6.5 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.051249722939516795		[learning rate: 0.0015125]
	Learning Rate: 0.00151249
	LOSS [training: 0.051249722939516795 | validation: 0.041769295667938515]
	TIME [epoch: 6.5 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061949864171010074		[learning rate: 0.0015089]
	Learning Rate: 0.00150892
	LOSS [training: 0.061949864171010074 | validation: 0.047544411252224014]
	TIME [epoch: 6.49 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06380365495218478		[learning rate: 0.0015054]
	Learning Rate: 0.00150536
	LOSS [training: 0.06380365495218478 | validation: 0.08306483111526218]
	TIME [epoch: 6.5 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07534270761407809		[learning rate: 0.0015018]
	Learning Rate: 0.00150181
	LOSS [training: 0.07534270761407809 | validation: 0.07583296955662477]
	TIME [epoch: 6.52 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07224194020561116		[learning rate: 0.0014983]
	Learning Rate: 0.00149827
	LOSS [training: 0.07224194020561116 | validation: 0.034505491350074385]
	TIME [epoch: 6.55 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055643548495341165		[learning rate: 0.0014947]
	Learning Rate: 0.00149473
	LOSS [training: 0.055643548495341165 | validation: 0.029176192077025737]
	TIME [epoch: 6.52 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.049302102514987185		[learning rate: 0.0014912]
	Learning Rate: 0.00149121
	LOSS [training: 0.049302102514987185 | validation: 0.029529428009379154]
	TIME [epoch: 6.52 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040436093111711216		[learning rate: 0.0014877]
	Learning Rate: 0.00148769
	LOSS [training: 0.040436093111711216 | validation: 0.024651668564717236]
	TIME [epoch: 6.52 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04630356229613475		[learning rate: 0.0014842]
	Learning Rate: 0.00148418
	LOSS [training: 0.04630356229613475 | validation: 0.03006388070374473]
	TIME [epoch: 6.52 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.062213247083699644		[learning rate: 0.0014807]
	Learning Rate: 0.00148068
	LOSS [training: 0.062213247083699644 | validation: 0.073686133549604]
	TIME [epoch: 6.56 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05345587242843185		[learning rate: 0.0014772]
	Learning Rate: 0.00147719
	LOSS [training: 0.05345587242843185 | validation: 0.04629935316419646]
	TIME [epoch: 6.51 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07731197558446007		[learning rate: 0.0014737]
	Learning Rate: 0.0014737
	LOSS [training: 0.07731197558446007 | validation: 0.049950432449146334]
	TIME [epoch: 6.52 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06800884239738444		[learning rate: 0.0014702]
	Learning Rate: 0.00147023
	LOSS [training: 0.06800884239738444 | validation: 0.03629299747407336]
	TIME [epoch: 6.52 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04930741742194521		[learning rate: 0.0014668]
	Learning Rate: 0.00146676
	LOSS [training: 0.04930741742194521 | validation: 0.04032534699877399]
	TIME [epoch: 6.52 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060719032484358906		[learning rate: 0.0014633]
	Learning Rate: 0.0014633
	LOSS [training: 0.060719032484358906 | validation: 0.08590301006233042]
	TIME [epoch: 6.53 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06013995802067412		[learning rate: 0.0014598]
	Learning Rate: 0.00145985
	LOSS [training: 0.06013995802067412 | validation: 0.04292855565608883]
	TIME [epoch: 6.56 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05829901677455614		[learning rate: 0.0014564]
	Learning Rate: 0.0014564
	LOSS [training: 0.05829901677455614 | validation: 0.10784312672730931]
	TIME [epoch: 6.52 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08918644570689951		[learning rate: 0.001453]
	Learning Rate: 0.00145297
	LOSS [training: 0.08918644570689951 | validation: 0.06004902005591825]
	TIME [epoch: 6.52 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12528316051080252		[learning rate: 0.0014495]
	Learning Rate: 0.00144954
	LOSS [training: 0.12528316051080252 | validation: 0.14626619191584897]
	TIME [epoch: 6.51 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11471631464183904		[learning rate: 0.0014461]
	Learning Rate: 0.00144612
	LOSS [training: 0.11471631464183904 | validation: 0.07890038574852333]
	TIME [epoch: 6.52 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07390475647840897		[learning rate: 0.0014427]
	Learning Rate: 0.00144271
	LOSS [training: 0.07390475647840897 | validation: 0.04432593921340219]
	TIME [epoch: 6.53 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05795388617825029		[learning rate: 0.0014393]
	Learning Rate: 0.00143931
	LOSS [training: 0.05795388617825029 | validation: 0.08017089725471957]
	TIME [epoch: 6.55 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08367012218319128		[learning rate: 0.0014359]
	Learning Rate: 0.00143591
	LOSS [training: 0.08367012218319128 | validation: 0.049957612072299644]
	TIME [epoch: 6.51 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16651136216800524		[learning rate: 0.0014325]
	Learning Rate: 0.00143253
	LOSS [training: 0.16651136216800524 | validation: 0.0388141482395086]
	TIME [epoch: 6.51 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05449806443116095		[learning rate: 0.0014291]
	Learning Rate: 0.00142915
	LOSS [training: 0.05449806443116095 | validation: 0.03390565679472835]
	TIME [epoch: 6.52 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0412791585107062		[learning rate: 0.0014258]
	Learning Rate: 0.00142578
	LOSS [training: 0.0412791585107062 | validation: 0.033276779064327425]
	TIME [epoch: 6.5 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03780450508650094		[learning rate: 0.0014224]
	Learning Rate: 0.00142241
	LOSS [training: 0.03780450508650094 | validation: 0.025839950681930485]
	TIME [epoch: 6.52 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.049589023007755494		[learning rate: 0.0014191]
	Learning Rate: 0.00141906
	LOSS [training: 0.049589023007755494 | validation: 0.041901288165836964]
	TIME [epoch: 6.53 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055494600171506224		[learning rate: 0.0014157]
	Learning Rate: 0.00141571
	LOSS [training: 0.055494600171506224 | validation: 0.05044847165062407]
	TIME [epoch: 6.51 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.051040482907654026		[learning rate: 0.0014124]
	Learning Rate: 0.00141237
	LOSS [training: 0.051040482907654026 | validation: 0.01625319626709893]
	TIME [epoch: 6.52 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053634020402131034		[learning rate: 0.001409]
	Learning Rate: 0.00140904
	LOSS [training: 0.053634020402131034 | validation: 0.05069346548317753]
	TIME [epoch: 6.51 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0902801927466336		[learning rate: 0.0014057]
	Learning Rate: 0.00140572
	LOSS [training: 0.0902801927466336 | validation: 0.0887311300316164]
	TIME [epoch: 6.52 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0613504633591271		[learning rate: 0.0014024]
	Learning Rate: 0.0014024
	LOSS [training: 0.0613504633591271 | validation: 0.04788962291330025]
	TIME [epoch: 6.55 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08412814848454944		[learning rate: 0.0013991]
	Learning Rate: 0.00139909
	LOSS [training: 0.08412814848454944 | validation: 0.044418403432856704]
	TIME [epoch: 6.53 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05747959218580877		[learning rate: 0.0013958]
	Learning Rate: 0.00139579
	LOSS [training: 0.05747959218580877 | validation: 0.03176771261387936]
	TIME [epoch: 6.52 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04973573911968572		[learning rate: 0.0013925]
	Learning Rate: 0.0013925
	LOSS [training: 0.04973573911968572 | validation: 0.054547249318959205]
	TIME [epoch: 6.53 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06665801535063362		[learning rate: 0.0013892]
	Learning Rate: 0.00138921
	LOSS [training: 0.06665801535063362 | validation: 0.042244409356096996]
	TIME [epoch: 6.5 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05174635739610365		[learning rate: 0.0013859]
	Learning Rate: 0.00138594
	LOSS [training: 0.05174635739610365 | validation: 0.036240373244271845]
	TIME [epoch: 6.53 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05360054380345628		[learning rate: 0.0013827]
	Learning Rate: 0.00138267
	LOSS [training: 0.05360054380345628 | validation: 0.037129561331391114]
	TIME [epoch: 6.55 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05706363622503656		[learning rate: 0.0013794]
	Learning Rate: 0.00137941
	LOSS [training: 0.05706363622503656 | validation: 0.09252054348475211]
	TIME [epoch: 6.52 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08194507693740968		[learning rate: 0.0013762]
	Learning Rate: 0.00137615
	LOSS [training: 0.08194507693740968 | validation: 0.03792644562690313]
	TIME [epoch: 6.52 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050192367689583614		[learning rate: 0.0013729]
	Learning Rate: 0.00137291
	LOSS [training: 0.050192367689583614 | validation: 0.039360032272048984]
	TIME [epoch: 6.52 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07185325529881317		[learning rate: 0.0013697]
	Learning Rate: 0.00136967
	LOSS [training: 0.07185325529881317 | validation: 0.0757142176619689]
	TIME [epoch: 6.52 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05382719067136765		[learning rate: 0.0013664]
	Learning Rate: 0.00136644
	LOSS [training: 0.05382719067136765 | validation: 0.04728363373127384]
	TIME [epoch: 6.55 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.062312704174211433		[learning rate: 0.0013632]
	Learning Rate: 0.00136321
	LOSS [training: 0.062312704174211433 | validation: 0.03026999311790764]
	TIME [epoch: 6.53 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05954947992728602		[learning rate: 0.00136]
	Learning Rate: 0.00136
	LOSS [training: 0.05954947992728602 | validation: 0.09868562925773286]
	TIME [epoch: 6.52 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06314823233323562		[learning rate: 0.0013568]
	Learning Rate: 0.00135679
	LOSS [training: 0.06314823233323562 | validation: 0.04263549324298836]
	TIME [epoch: 6.52 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05047885128089702		[learning rate: 0.0013536]
	Learning Rate: 0.00135359
	LOSS [training: 0.05047885128089702 | validation: 0.057784084713199776]
	TIME [epoch: 6.51 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050523921784742555		[learning rate: 0.0013504]
	Learning Rate: 0.0013504
	LOSS [training: 0.050523921784742555 | validation: 0.036967587229718366]
	TIME [epoch: 6.5 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05432416615077233		[learning rate: 0.0013472]
	Learning Rate: 0.00134721
	LOSS [training: 0.05432416615077233 | validation: 0.0443214319891738]
	TIME [epoch: 6.56 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05974166521148093		[learning rate: 0.001344]
	Learning Rate: 0.00134403
	LOSS [training: 0.05974166521148093 | validation: 0.05719030509198371]
	TIME [epoch: 6.53 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04824097681451335		[learning rate: 0.0013409]
	Learning Rate: 0.00134086
	LOSS [training: 0.04824097681451335 | validation: 0.026059298584976687]
	TIME [epoch: 6.52 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0480547534125613		[learning rate: 0.0013377]
	Learning Rate: 0.0013377
	LOSS [training: 0.0480547534125613 | validation: 0.03613396366665696]
	TIME [epoch: 6.5 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11312695176519108		[learning rate: 0.0013345]
	Learning Rate: 0.00133455
	LOSS [training: 0.11312695176519108 | validation: 0.07554937722884156]
	TIME [epoch: 6.52 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07984230438578725		[learning rate: 0.0013314]
	Learning Rate: 0.0013314
	LOSS [training: 0.07984230438578725 | validation: 0.03002557038738572]
	TIME [epoch: 6.53 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033960905778356795		[learning rate: 0.0013283]
	Learning Rate: 0.00132826
	LOSS [training: 0.033960905778356795 | validation: 0.025869081522255335]
	TIME [epoch: 6.54 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04104332406724008		[learning rate: 0.0013251]
	Learning Rate: 0.00132512
	LOSS [training: 0.04104332406724008 | validation: 0.026494874880587545]
	TIME [epoch: 6.51 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03622819367619186		[learning rate: 0.001322]
	Learning Rate: 0.001322
	LOSS [training: 0.03622819367619186 | validation: 0.11336800848446654]
	TIME [epoch: 6.51 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09349343079250474		[learning rate: 0.0013189]
	Learning Rate: 0.00131888
	LOSS [training: 0.09349343079250474 | validation: 0.032759918445377484]
	TIME [epoch: 6.51 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05288154371581717		[learning rate: 0.0013158]
	Learning Rate: 0.00131577
	LOSS [training: 0.05288154371581717 | validation: 0.0699093124316183]
	TIME [epoch: 6.52 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05476316854046327		[learning rate: 0.0013127]
	Learning Rate: 0.00131266
	LOSS [training: 0.05476316854046327 | validation: 0.039882674212123395]
	TIME [epoch: 6.52 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05175469334625884		[learning rate: 0.0013096]
	Learning Rate: 0.00130957
	LOSS [training: 0.05175469334625884 | validation: 0.039257511064664644]
	TIME [epoch: 6.56 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04727191893821554		[learning rate: 0.0013065]
	Learning Rate: 0.00130648
	LOSS [training: 0.04727191893821554 | validation: 0.033893876297544756]
	TIME [epoch: 6.51 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04790860524367062		[learning rate: 0.0013034]
	Learning Rate: 0.0013034
	LOSS [training: 0.04790860524367062 | validation: 0.04843673842116798]
	TIME [epoch: 6.5 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04951440653805912		[learning rate: 0.0013003]
	Learning Rate: 0.00130032
	LOSS [training: 0.04951440653805912 | validation: 0.0533371329700857]
	TIME [epoch: 6.5 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06670375390169499		[learning rate: 0.0012973]
	Learning Rate: 0.00129726
	LOSS [training: 0.06670375390169499 | validation: 0.045926041998100055]
	TIME [epoch: 6.52 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06159440138797682		[learning rate: 0.0012942]
	Learning Rate: 0.0012942
	LOSS [training: 0.06159440138797682 | validation: 0.09121687544665313]
	TIME [epoch: 6.53 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06670480859085497		[learning rate: 0.0012911]
	Learning Rate: 0.00129114
	LOSS [training: 0.06670480859085497 | validation: 0.041218876448814654]
	TIME [epoch: 6.54 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05123022246799119		[learning rate: 0.0012881]
	Learning Rate: 0.0012881
	LOSS [training: 0.05123022246799119 | validation: 0.032390821466543096]
	TIME [epoch: 6.51 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0576757304789783		[learning rate: 0.0012851]
	Learning Rate: 0.00128506
	LOSS [training: 0.0576757304789783 | validation: 0.028085020868766183]
	TIME [epoch: 6.52 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06559966218335281		[learning rate: 0.001282]
	Learning Rate: 0.00128203
	LOSS [training: 0.06559966218335281 | validation: 0.08630840283559993]
	TIME [epoch: 6.52 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05899573799389304		[learning rate: 0.001279]
	Learning Rate: 0.001279
	LOSS [training: 0.05899573799389304 | validation: 0.033422426118096225]
	TIME [epoch: 6.52 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040101278697908645		[learning rate: 0.001276]
	Learning Rate: 0.00127599
	LOSS [training: 0.040101278697908645 | validation: 0.04383169392831632]
	TIME [epoch: 6.55 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.049704247643518794		[learning rate: 0.001273]
	Learning Rate: 0.00127298
	LOSS [training: 0.049704247643518794 | validation: 0.03272669175120636]
	TIME [epoch: 6.51 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.047735015187953055		[learning rate: 0.00127]
	Learning Rate: 0.00126997
	LOSS [training: 0.047735015187953055 | validation: 0.03985900998866738]
	TIME [epoch: 6.52 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0518273815247328		[learning rate: 0.001267]
	Learning Rate: 0.00126698
	LOSS [training: 0.0518273815247328 | validation: 0.03564577083201154]
	TIME [epoch: 6.52 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.045910188183514895		[learning rate: 0.001264]
	Learning Rate: 0.00126399
	LOSS [training: 0.045910188183514895 | validation: 0.040508964292236924]
	TIME [epoch: 6.52 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06181244032365972		[learning rate: 0.001261]
	Learning Rate: 0.00126101
	LOSS [training: 0.06181244032365972 | validation: 0.04458648623050689]
	TIME [epoch: 6.52 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0498067629997959		[learning rate: 0.001258]
	Learning Rate: 0.00125803
	LOSS [training: 0.0498067629997959 | validation: 0.04176946551105376]
	TIME [epoch: 6.55 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.051039066824775256		[learning rate: 0.0012551]
	Learning Rate: 0.00125507
	LOSS [training: 0.051039066824775256 | validation: 0.03880736174320063]
	TIME [epoch: 6.52 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04765328720359918		[learning rate: 0.0012521]
	Learning Rate: 0.00125211
	LOSS [training: 0.04765328720359918 | validation: 0.03765160514899767]
	TIME [epoch: 6.5 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05837837641439718		[learning rate: 0.0012492]
	Learning Rate: 0.00124915
	LOSS [training: 0.05837837641439718 | validation: 0.0703611941300501]
	TIME [epoch: 6.51 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0696833534607118		[learning rate: 0.0012462]
	Learning Rate: 0.00124621
	LOSS [training: 0.0696833534607118 | validation: 0.034021016249557966]
	TIME [epoch: 6.52 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05407339962484968		[learning rate: 0.0012433]
	Learning Rate: 0.00124327
	LOSS [training: 0.05407339962484968 | validation: 0.041491914712130394]
	TIME [epoch: 6.52 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05103783016539961		[learning rate: 0.0012403]
	Learning Rate: 0.00124033
	LOSS [training: 0.05103783016539961 | validation: 0.03824936922646438]
	TIME [epoch: 6.53 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04845595148869184		[learning rate: 0.0012374]
	Learning Rate: 0.00123741
	LOSS [training: 0.04845595148869184 | validation: 0.033731963190645003]
	TIME [epoch: 6.52 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06367287017145662		[learning rate: 0.0012345]
	Learning Rate: 0.00123449
	LOSS [training: 0.06367287017145662 | validation: 0.03939894936078862]
	TIME [epoch: 6.52 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05558839752898087		[learning rate: 0.0012316]
	Learning Rate: 0.00123158
	LOSS [training: 0.05558839752898087 | validation: 0.045110375457008384]
	TIME [epoch: 6.5 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05323870901711238		[learning rate: 0.0012287]
	Learning Rate: 0.00122867
	LOSS [training: 0.05323870901711238 | validation: 0.04215922381727226]
	TIME [epoch: 6.51 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04851273029241858		[learning rate: 0.0012258]
	Learning Rate: 0.00122577
	LOSS [training: 0.04851273029241858 | validation: 0.02009929873420825]
	TIME [epoch: 6.54 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05286977368035015		[learning rate: 0.0012229]
	Learning Rate: 0.00122288
	LOSS [training: 0.05286977368035015 | validation: 0.03836101153366122]
	TIME [epoch: 6.51 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05578079292646162		[learning rate: 0.00122]
	Learning Rate: 0.00122
	LOSS [training: 0.05578079292646162 | validation: 0.042603423139326906]
	TIME [epoch: 6.51 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05784210966848448		[learning rate: 0.0012171]
	Learning Rate: 0.00121712
	LOSS [training: 0.05784210966848448 | validation: 0.06203866180180827]
	TIME [epoch: 6.52 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06895946165498208		[learning rate: 0.0012142]
	Learning Rate: 0.00121425
	LOSS [training: 0.06895946165498208 | validation: 0.04238387938547131]
	TIME [epoch: 6.5 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05013488943126602		[learning rate: 0.0012114]
	Learning Rate: 0.00121138
	LOSS [training: 0.05013488943126602 | validation: 0.03551302202240909]
	TIME [epoch: 6.51 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0515919986256156		[learning rate: 0.0012085]
	Learning Rate: 0.00120853
	LOSS [training: 0.0515919986256156 | validation: 0.031202468289651515]
	TIME [epoch: 6.53 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05537392487066103		[learning rate: 0.0012057]
	Learning Rate: 0.00120568
	LOSS [training: 0.05537392487066103 | validation: 0.02997943461124882]
	TIME [epoch: 6.51 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06718019453879784		[learning rate: 0.0012028]
	Learning Rate: 0.00120283
	LOSS [training: 0.06718019453879784 | validation: 0.06015271431585982]
	TIME [epoch: 6.51 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06587005866836795		[learning rate: 0.0012]
	Learning Rate: 0.0012
	LOSS [training: 0.06587005866836795 | validation: 0.0417823534319791]
	TIME [epoch: 6.51 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06404851815858738		[learning rate: 0.0011972]
	Learning Rate: 0.00119716
	LOSS [training: 0.06404851815858738 | validation: 0.038395436509123436]
	TIME [epoch: 6.5 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05826207135031382		[learning rate: 0.0011943]
	Learning Rate: 0.00119434
	LOSS [training: 0.05826207135031382 | validation: 0.0541708146729792]
	TIME [epoch: 6.51 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06999977576114051		[learning rate: 0.0011915]
	Learning Rate: 0.00119152
	LOSS [training: 0.06999977576114051 | validation: 0.04935176086326035]
	TIME [epoch: 6.53 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050828603147343256		[learning rate: 0.0011887]
	Learning Rate: 0.00118871
	LOSS [training: 0.050828603147343256 | validation: 0.03501093329859469]
	TIME [epoch: 6.5 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04535869176630095		[learning rate: 0.0011859]
	Learning Rate: 0.00118591
	LOSS [training: 0.04535869176630095 | validation: 0.03592889955910608]
	TIME [epoch: 6.51 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.051737511006230044		[learning rate: 0.0011831]
	Learning Rate: 0.00118311
	LOSS [training: 0.051737511006230044 | validation: 0.0785060050619761]
	TIME [epoch: 6.5 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17898504435603785		[learning rate: 0.0011803]
	Learning Rate: 0.00118032
	LOSS [training: 0.17898504435603785 | validation: 0.16007437478623598]
	TIME [epoch: 6.51 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12624351489100993		[learning rate: 0.0011775]
	Learning Rate: 0.00117754
	LOSS [training: 0.12624351489100993 | validation: 0.07515170481237994]
	TIME [epoch: 6.55 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07606378032776015		[learning rate: 0.0011748]
	Learning Rate: 0.00117476
	LOSS [training: 0.07606378032776015 | validation: 0.062122071303435514]
	TIME [epoch: 6.52 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0705415770478949		[learning rate: 0.001172]
	Learning Rate: 0.00117199
	LOSS [training: 0.0705415770478949 | validation: 0.055662659879689436]
	TIME [epoch: 6.5 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06527433489209031		[learning rate: 0.0011692]
	Learning Rate: 0.00116922
	LOSS [training: 0.06527433489209031 | validation: 0.06333941172942523]
	TIME [epoch: 6.5 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0693881233683453		[learning rate: 0.0011665]
	Learning Rate: 0.00116646
	LOSS [training: 0.0693881233683453 | validation: 0.08086561353733743]
	TIME [epoch: 6.5 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17384982335928126		[learning rate: 0.0011637]
	Learning Rate: 0.00116371
	LOSS [training: 0.17384982335928126 | validation: 0.08606865748471758]
	TIME [epoch: 6.5 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20653310297376973		[learning rate: 0.001161]
	Learning Rate: 0.00116097
	LOSS [training: 0.20653310297376973 | validation: 0.0651428442015263]
	TIME [epoch: 6.57 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10393347521072145		[learning rate: 0.0011582]
	Learning Rate: 0.00115823
	LOSS [training: 0.10393347521072145 | validation: 0.04610237701173184]
	TIME [epoch: 6.51 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09010894309797735		[learning rate: 0.0011555]
	Learning Rate: 0.0011555
	LOSS [training: 0.09010894309797735 | validation: 0.06942676960695897]
	TIME [epoch: 6.5 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06408047085753868		[learning rate: 0.0011528]
	Learning Rate: 0.00115277
	LOSS [training: 0.06408047085753868 | validation: 0.047343494509278966]
	TIME [epoch: 6.5 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.056223805541012285		[learning rate: 0.0011501]
	Learning Rate: 0.00115005
	LOSS [training: 0.056223805541012285 | validation: 0.04722593918765848]
	TIME [epoch: 6.52 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05794123589770021		[learning rate: 0.0011473]
	Learning Rate: 0.00114734
	LOSS [training: 0.05794123589770021 | validation: 0.05230534529446651]
	TIME [epoch: 6.51 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05592149043433285		[learning rate: 0.0011446]
	Learning Rate: 0.00114463
	LOSS [training: 0.05592149043433285 | validation: 0.04660430999071097]
	TIME [epoch: 6.54 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05234800345671133		[learning rate: 0.0011419]
	Learning Rate: 0.00114193
	LOSS [training: 0.05234800345671133 | validation: 0.03384161992149372]
	TIME [epoch: 6.52 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04635912101220661		[learning rate: 0.0011392]
	Learning Rate: 0.00113924
	LOSS [training: 0.04635912101220661 | validation: 0.03471575173358274]
	TIME [epoch: 6.5 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055744229915296796		[learning rate: 0.0011366]
	Learning Rate: 0.00113655
	LOSS [training: 0.055744229915296796 | validation: 0.037319319058636086]
	TIME [epoch: 6.51 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039910631988788386		[learning rate: 0.0011339]
	Learning Rate: 0.00113387
	LOSS [training: 0.039910631988788386 | validation: 0.034357258483579574]
	TIME [epoch: 6.51 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0420563933669292		[learning rate: 0.0011312]
	Learning Rate: 0.0011312
	LOSS [training: 0.0420563933669292 | validation: 0.044191178457601996]
	TIME [epoch: 6.54 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04735376394260642		[learning rate: 0.0011285]
	Learning Rate: 0.00112853
	LOSS [training: 0.04735376394260642 | validation: 0.05386043547151893]
	TIME [epoch: 6.52 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057614048333619675		[learning rate: 0.0011259]
	Learning Rate: 0.00112587
	LOSS [training: 0.057614048333619675 | validation: 0.026653063997235906]
	TIME [epoch: 6.49 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04657432010281028		[learning rate: 0.0011232]
	Learning Rate: 0.00112321
	LOSS [training: 0.04657432010281028 | validation: 0.03227402204364222]
	TIME [epoch: 6.52 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04688950203742691		[learning rate: 0.0011206]
	Learning Rate: 0.00112056
	LOSS [training: 0.04688950203742691 | validation: 0.04171563537064014]
	TIME [epoch: 6.53 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05661684710381		[learning rate: 0.0011179]
	Learning Rate: 0.00111792
	LOSS [training: 0.05661684710381 | validation: 0.028139742718945118]
	TIME [epoch: 6.5 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0382577210730089		[learning rate: 0.0011153]
	Learning Rate: 0.00111528
	LOSS [training: 0.0382577210730089 | validation: 0.026273292066086914]
	TIME [epoch: 6.54 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07933410917645566		[learning rate: 0.0011127]
	Learning Rate: 0.00111265
	LOSS [training: 0.07933410917645566 | validation: 0.09558264585209744]
	TIME [epoch: 6.52 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12240950923696811		[learning rate: 0.00111]
	Learning Rate: 0.00111003
	LOSS [training: 0.12240950923696811 | validation: 0.03401312155112397]
	TIME [epoch: 6.5 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3516583172129975		[learning rate: 0.0011074]
	Learning Rate: 0.00110741
	LOSS [training: 0.3516583172129975 | validation: 0.3353548854584024]
	TIME [epoch: 6.51 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20606184823220067		[learning rate: 0.0011048]
	Learning Rate: 0.0011048
	LOSS [training: 0.20606184823220067 | validation: 0.019270655705083118]
	TIME [epoch: 6.5 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033009011181684964		[learning rate: 0.0011022]
	Learning Rate: 0.00110219
	LOSS [training: 0.033009011181684964 | validation: 0.026586383402320363]
	TIME [epoch: 6.51 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04277026954473472		[learning rate: 0.0010996]
	Learning Rate: 0.00109959
	LOSS [training: 0.04277026954473472 | validation: 0.031586096332689675]
	TIME [epoch: 6.55 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.044449743773286955		[learning rate: 0.001097]
	Learning Rate: 0.001097
	LOSS [training: 0.044449743773286955 | validation: 0.03442715215293231]
	TIME [epoch: 6.5 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058738862923881904		[learning rate: 0.0010944]
	Learning Rate: 0.00109441
	LOSS [training: 0.058738862923881904 | validation: 0.051583743120164095]
	TIME [epoch: 6.49 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04883539390311674		[learning rate: 0.0010918]
	Learning Rate: 0.00109183
	LOSS [training: 0.04883539390311674 | validation: 0.03866008254578066]
	TIME [epoch: 6.52 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04623697723339267		[learning rate: 0.0010893]
	Learning Rate: 0.00108925
	LOSS [training: 0.04623697723339267 | validation: 0.03099251636775221]
	TIME [epoch: 6.5 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.046892363080122526		[learning rate: 0.0010867]
	Learning Rate: 0.00108668
	LOSS [training: 0.046892363080122526 | validation: 0.03147394149152802]
	TIME [epoch: 6.52 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03964658872293366		[learning rate: 0.0010841]
	Learning Rate: 0.00108412
	LOSS [training: 0.03964658872293366 | validation: 0.04305604771598533]
	TIME [epoch: 6.55 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03998210706373172		[learning rate: 0.0010816]
	Learning Rate: 0.00108156
	LOSS [training: 0.03998210706373172 | validation: 0.02125064152750346]
	TIME [epoch: 6.53 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04447327179108944		[learning rate: 0.001079]
	Learning Rate: 0.00107901
	LOSS [training: 0.04447327179108944 | validation: 0.032926247124628105]
	TIME [epoch: 6.5 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050963234443690685		[learning rate: 0.0010765]
	Learning Rate: 0.00107647
	LOSS [training: 0.050963234443690685 | validation: 0.023348771043576962]
	TIME [epoch: 6.52 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.043488132152951206		[learning rate: 0.0010739]
	Learning Rate: 0.00107393
	LOSS [training: 0.043488132152951206 | validation: 0.03637689916079909]
	TIME [epoch: 6.5 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04287558376943832		[learning rate: 0.0010714]
	Learning Rate: 0.00107139
	LOSS [training: 0.04287558376943832 | validation: 0.03155501008597528]
	TIME [epoch: 6.54 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.047054283514372575		[learning rate: 0.0010689]
	Learning Rate: 0.00106887
	LOSS [training: 0.047054283514372575 | validation: 0.062040160393087906]
	TIME [epoch: 6.51 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0455847600222091		[learning rate: 0.0010663]
	Learning Rate: 0.00106634
	LOSS [training: 0.0455847600222091 | validation: 0.03728321009974614]
	TIME [epoch: 6.49 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050878818372078305		[learning rate: 0.0010638]
	Learning Rate: 0.00106383
	LOSS [training: 0.050878818372078305 | validation: 0.03109898661126092]
	TIME [epoch: 6.49 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03588740678158098		[learning rate: 0.0010613]
	Learning Rate: 0.00106132
	LOSS [training: 0.03588740678158098 | validation: 0.02581219200929344]
	TIME [epoch: 6.49 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03912790729756955		[learning rate: 0.0010588]
	Learning Rate: 0.00105882
	LOSS [training: 0.03912790729756955 | validation: 0.03312318115757503]
	TIME [epoch: 6.5 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04830765536118527		[learning rate: 0.0010563]
	Learning Rate: 0.00105632
	LOSS [training: 0.04830765536118527 | validation: 0.0212473452386044]
	TIME [epoch: 6.56 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039742100701119165		[learning rate: 0.0010538]
	Learning Rate: 0.00105383
	LOSS [training: 0.039742100701119165 | validation: 0.01225857553556078]
	TIME [epoch: 6.5 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025987811227339442		[learning rate: 0.0010513]
	Learning Rate: 0.00105134
	LOSS [training: 0.025987811227339442 | validation: 0.030133794773109582]
	TIME [epoch: 6.52 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03562224311177202		[learning rate: 0.0010489]
	Learning Rate: 0.00104886
	LOSS [training: 0.03562224311177202 | validation: 0.023522363530816263]
	TIME [epoch: 6.5 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.049086484587363574		[learning rate: 0.0010464]
	Learning Rate: 0.00104639
	LOSS [training: 0.049086484587363574 | validation: 0.026083741181565975]
	TIME [epoch: 6.53 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0474065336242805		[learning rate: 0.0010439]
	Learning Rate: 0.00104392
	LOSS [training: 0.0474065336242805 | validation: 0.036030949113140864]
	TIME [epoch: 6.53 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05516548912887191		[learning rate: 0.0010415]
	Learning Rate: 0.00104146
	LOSS [training: 0.05516548912887191 | validation: 0.03201161104652438]
	TIME [epoch: 6.52 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.045330858716865825		[learning rate: 0.001039]
	Learning Rate: 0.001039
	LOSS [training: 0.045330858716865825 | validation: 0.030406271796178427]
	TIME [epoch: 6.5 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0486952826467293		[learning rate: 0.0010365]
	Learning Rate: 0.00103655
	LOSS [training: 0.0486952826467293 | validation: 0.0386876412571544]
	TIME [epoch: 6.5 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04563142981998274		[learning rate: 0.0010341]
	Learning Rate: 0.0010341
	LOSS [training: 0.04563142981998274 | validation: 0.02399369692569106]
	TIME [epoch: 6.53 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04318459342571612		[learning rate: 0.0010317]
	Learning Rate: 0.00103166
	LOSS [training: 0.04318459342571612 | validation: 0.029680299111619315]
	TIME [epoch: 6.49 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039844454089148794		[learning rate: 0.0010292]
	Learning Rate: 0.00102923
	LOSS [training: 0.039844454089148794 | validation: 0.03843362554529681]
	TIME [epoch: 6.52 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.056329632421175904		[learning rate: 0.0010268]
	Learning Rate: 0.0010268
	LOSS [training: 0.056329632421175904 | validation: 0.0296916463573414]
	TIME [epoch: 6.54 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.048392128061673215		[learning rate: 0.0010244]
	Learning Rate: 0.00102438
	LOSS [training: 0.048392128061673215 | validation: 0.055908359073392734]
	TIME [epoch: 6.52 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05593396148894651		[learning rate: 0.001022]
	Learning Rate: 0.00102196
	LOSS [training: 0.05593396148894651 | validation: 0.03551304080709857]
	TIME [epoch: 6.49 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06396763702344839		[learning rate: 0.0010196]
	Learning Rate: 0.00101955
	LOSS [training: 0.06396763702344839 | validation: 0.04162888344983809]
	TIME [epoch: 6.51 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04869089519362468		[learning rate: 0.0010171]
	Learning Rate: 0.00101715
	LOSS [training: 0.04869089519362468 | validation: 0.0312354564085543]
	TIME [epoch: 6.5 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04676634099168847		[learning rate: 0.0010147]
	Learning Rate: 0.00101475
	LOSS [training: 0.04676634099168847 | validation: 0.03132511879411749]
	TIME [epoch: 6.55 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038061748875339085		[learning rate: 0.0010124]
	Learning Rate: 0.00101236
	LOSS [training: 0.038061748875339085 | validation: 0.028336688362629783]
	TIME [epoch: 6.51 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04396062931891466		[learning rate: 0.00101]
	Learning Rate: 0.00100997
	LOSS [training: 0.04396062931891466 | validation: 0.03815030208740079]
	TIME [epoch: 6.51 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05960603605073402		[learning rate: 0.0010076]
	Learning Rate: 0.00100759
	LOSS [training: 0.05960603605073402 | validation: 0.03088226218500323]
	TIME [epoch: 6.51 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04432684913501438		[learning rate: 0.0010052]
	Learning Rate: 0.00100521
	LOSS [training: 0.04432684913501438 | validation: 0.03738597534980146]
	TIME [epoch: 6.52 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04664334763809318		[learning rate: 0.0010028]
	Learning Rate: 0.00100284
	LOSS [training: 0.04664334763809318 | validation: 0.027458841542750474]
	TIME [epoch: 6.51 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0458352928298252		[learning rate: 0.0010005]
	Learning Rate: 0.00100047
	LOSS [training: 0.0458352928298252 | validation: 0.03264874094377643]
	TIME [epoch: 6.55 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057185532162018084		[learning rate: 0.00099811]
	Learning Rate: 0.000998112
	LOSS [training: 0.057185532162018084 | validation: 0.0419962599579326]
	TIME [epoch: 6.49 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04750740391986823		[learning rate: 0.00099576]
	Learning Rate: 0.000995758
	LOSS [training: 0.04750740391986823 | validation: 0.03871726123499961]
	TIME [epoch: 6.5 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06529099561128246		[learning rate: 0.00099341]
	Learning Rate: 0.000993409
	LOSS [training: 0.06529099561128246 | validation: 0.026545016700643374]
	TIME [epoch: 6.5 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09009206195187014		[learning rate: 0.00099107]
	Learning Rate: 0.000991066
	LOSS [training: 0.09009206195187014 | validation: 0.06355632733222606]
	TIME [epoch: 6.52 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09205707047472289		[learning rate: 0.00098873]
	Learning Rate: 0.000988728
	LOSS [training: 0.09205707047472289 | validation: 0.021040223729186756]
	TIME [epoch: 6.51 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036128484412927556		[learning rate: 0.0009864]
	Learning Rate: 0.000986396
	LOSS [training: 0.036128484412927556 | validation: 0.029075268065332907]
	TIME [epoch: 6.55 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.048593380301513237		[learning rate: 0.00098407]
	Learning Rate: 0.000984069
	LOSS [training: 0.048593380301513237 | validation: 0.036788206587979023]
	TIME [epoch: 6.5 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04392060481540094		[learning rate: 0.00098175]
	Learning Rate: 0.000981748
	LOSS [training: 0.04392060481540094 | validation: 0.03695805106994557]
	TIME [epoch: 6.51 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04242016684421039		[learning rate: 0.00097943]
	Learning Rate: 0.000979432
	LOSS [training: 0.04242016684421039 | validation: 0.031212816417719592]
	TIME [epoch: 6.49 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03932464015456554		[learning rate: 0.00097712]
	Learning Rate: 0.000977122
	LOSS [training: 0.03932464015456554 | validation: 0.033191749139974226]
	TIME [epoch: 6.5 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04387093709948757		[learning rate: 0.00097482]
	Learning Rate: 0.000974817
	LOSS [training: 0.04387093709948757 | validation: 0.031686438138918666]
	TIME [epoch: 6.54 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039860785188361746		[learning rate: 0.00097252]
	Learning Rate: 0.000972517
	LOSS [training: 0.039860785188361746 | validation: 0.048074806259113576]
	TIME [epoch: 6.53 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.048278657239823906		[learning rate: 0.00097022]
	Learning Rate: 0.000970224
	LOSS [training: 0.048278657239823906 | validation: 0.03749137789383418]
	TIME [epoch: 6.49 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04725464205065534		[learning rate: 0.00096793]
	Learning Rate: 0.000967935
	LOSS [training: 0.04725464205065534 | validation: 0.0787661575905056]
	TIME [epoch: 6.49 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09755965966014543		[learning rate: 0.00096565]
	Learning Rate: 0.000965652
	LOSS [training: 0.09755965966014543 | validation: 0.06379879448419049]
	TIME [epoch: 6.51 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06709889362735166		[learning rate: 0.00096337]
	Learning Rate: 0.000963374
	LOSS [training: 0.06709889362735166 | validation: 0.05983032458987233]
	TIME [epoch: 6.49 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04960538873823014		[learning rate: 0.0009611]
	Learning Rate: 0.000961101
	LOSS [training: 0.04960538873823014 | validation: 0.03398665187381298]
	TIME [epoch: 6.53 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035924944785845646		[learning rate: 0.00095883]
	Learning Rate: 0.000958834
	LOSS [training: 0.035924944785845646 | validation: 0.027370560384447355]
	TIME [epoch: 6.52 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05561367038195577		[learning rate: 0.00095657]
	Learning Rate: 0.000956572
	LOSS [training: 0.05561367038195577 | validation: 0.03961018886735153]
	TIME [epoch: 6.52 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04875790199405138		[learning rate: 0.00095432]
	Learning Rate: 0.000954316
	LOSS [training: 0.04875790199405138 | validation: 0.033623683635744125]
	TIME [epoch: 6.5 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04843789623847051		[learning rate: 0.00095207]
	Learning Rate: 0.000952065
	LOSS [training: 0.04843789623847051 | validation: 0.03118978815438271]
	TIME [epoch: 6.52 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04035039473129713		[learning rate: 0.00094982]
	Learning Rate: 0.000949819
	LOSS [training: 0.04035039473129713 | validation: 0.024727566569957404]
	TIME [epoch: 6.56 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040410621675759574		[learning rate: 0.00094758]
	Learning Rate: 0.000947579
	LOSS [training: 0.040410621675759574 | validation: 0.045693434637018214]
	TIME [epoch: 6.54 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07131967538274717		[learning rate: 0.00094534]
	Learning Rate: 0.000945344
	LOSS [training: 0.07131967538274717 | validation: 0.044476388671056744]
	TIME [epoch: 6.51 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.056912040331393764		[learning rate: 0.00094311]
	Learning Rate: 0.000943114
	LOSS [training: 0.056912040331393764 | validation: 0.03686543617497792]
	TIME [epoch: 6.52 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05188471391070837		[learning rate: 0.00094089]
	Learning Rate: 0.000940889
	LOSS [training: 0.05188471391070837 | validation: 0.049165763629971604]
	TIME [epoch: 6.5 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.049300166256970215		[learning rate: 0.00093867]
	Learning Rate: 0.00093867
	LOSS [training: 0.049300166256970215 | validation: 0.038067438836015405]
	TIME [epoch: 6.52 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06099659223206544		[learning rate: 0.00093646]
	Learning Rate: 0.000936456
	LOSS [training: 0.06099659223206544 | validation: 0.030469854683190918]
	TIME [epoch: 6.54 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042508203909125464		[learning rate: 0.00093425]
	Learning Rate: 0.000934246
	LOSS [training: 0.042508203909125464 | validation: 0.040713792546553364]
	TIME [epoch: 6.54 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04917656372498552		[learning rate: 0.00093204]
	Learning Rate: 0.000932043
	LOSS [training: 0.04917656372498552 | validation: 0.02982425009776387]
	TIME [epoch: 6.52 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04690683630613961		[learning rate: 0.00092984]
	Learning Rate: 0.000929844
	LOSS [training: 0.04690683630613961 | validation: 0.03699396165736608]
	TIME [epoch: 6.52 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05187713994818394		[learning rate: 0.00092765]
	Learning Rate: 0.000927651
	LOSS [training: 0.05187713994818394 | validation: 0.06636368789667783]
	TIME [epoch: 6.52 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47699231350616006		[learning rate: 0.00092546]
	Learning Rate: 0.000925463
	LOSS [training: 0.47699231350616006 | validation: 0.380666106164478]
	TIME [epoch: 6.51 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.601900903064878		[learning rate: 0.00092328]
	Learning Rate: 0.00092328
	LOSS [training: 0.601900903064878 | validation: 0.39539116890690795]
	TIME [epoch: 6.55 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6163117618617597		[learning rate: 0.0009211]
	Learning Rate: 0.000921102
	LOSS [training: 0.6163117618617597 | validation: 0.34835354195625845]
	TIME [epoch: 6.53 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3353539076803044		[learning rate: 0.00091893]
	Learning Rate: 0.000918929
	LOSS [training: 0.3353539076803044 | validation: 0.026856358724925533]
	TIME [epoch: 6.52 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035622913409575095		[learning rate: 0.00091676]
	Learning Rate: 0.000916762
	LOSS [training: 0.035622913409575095 | validation: 0.020098781215858365]
	TIME [epoch: 6.5 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04029522221183601		[learning rate: 0.0009146]
	Learning Rate: 0.000914599
	LOSS [training: 0.04029522221183601 | validation: 0.023693896941161727]
	TIME [epoch: 6.52 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03395502611586852		[learning rate: 0.00091244]
	Learning Rate: 0.000912442
	LOSS [training: 0.03395502611586852 | validation: 0.024057118811072205]
	TIME [epoch: 6.51 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03400626560489936		[learning rate: 0.00091029]
	Learning Rate: 0.000910289
	LOSS [training: 0.03400626560489936 | validation: 0.019319268398046104]
	TIME [epoch: 6.54 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041711728161066886		[learning rate: 0.00090814]
	Learning Rate: 0.000908142
	LOSS [training: 0.041711728161066886 | validation: 0.031017862092488795]
	TIME [epoch: 6.5 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036162373005509806		[learning rate: 0.000906]
	Learning Rate: 0.000906
	LOSS [training: 0.036162373005509806 | validation: 0.0135727196444211]
	TIME [epoch: 6.51 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02665610919073787		[learning rate: 0.00090386]
	Learning Rate: 0.000903863
	LOSS [training: 0.02665610919073787 | validation: 0.010249665660353253]
	TIME [epoch: 6.5 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_1068.pth
	Model improved!!!
EPOCH 1069/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03233508441464046		[learning rate: 0.00090173]
	Learning Rate: 0.000901731
	LOSS [training: 0.03233508441464046 | validation: 0.007621141266085448]
	TIME [epoch: 6.52 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_1069.pth
	Model improved!!!
EPOCH 1070/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024013882599955128		[learning rate: 0.0008996]
	Learning Rate: 0.000899604
	LOSS [training: 0.024013882599955128 | validation: 0.004913192754367196]
	TIME [epoch: 6.58 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_1070.pth
	Model improved!!!
EPOCH 1071/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031164025827254645		[learning rate: 0.00089748]
	Learning Rate: 0.000897482
	LOSS [training: 0.031164025827254645 | validation: 0.03688356544940996]
	TIME [epoch: 6.58 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04313111326455936		[learning rate: 0.00089536]
	Learning Rate: 0.000895365
	LOSS [training: 0.04313111326455936 | validation: 0.025801053295900413]
	TIME [epoch: 6.56 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04769398735278963		[learning rate: 0.00089325]
	Learning Rate: 0.000893253
	LOSS [training: 0.04769398735278963 | validation: 0.026310362650355197]
	TIME [epoch: 6.56 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04729188589641638		[learning rate: 0.00089115]
	Learning Rate: 0.000891146
	LOSS [training: 0.04729188589641638 | validation: 0.06455367403271645]
	TIME [epoch: 6.56 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.052959225991339995		[learning rate: 0.00088904]
	Learning Rate: 0.000889044
	LOSS [training: 0.052959225991339995 | validation: 0.025764904638607214]
	TIME [epoch: 6.56 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04089443605861357		[learning rate: 0.00088695]
	Learning Rate: 0.000886946
	LOSS [training: 0.04089443605861357 | validation: 0.04710340356049322]
	TIME [epoch: 6.6 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2018659414037161		[learning rate: 0.00088485]
	Learning Rate: 0.000884854
	LOSS [training: 0.2018659414037161 | validation: 0.07295473124970259]
	TIME [epoch: 6.56 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07620785710528685		[learning rate: 0.00088277]
	Learning Rate: 0.000882767
	LOSS [training: 0.07620785710528685 | validation: 0.027067305003168434]
	TIME [epoch: 6.56 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03157750429555404		[learning rate: 0.00088068]
	Learning Rate: 0.000880685
	LOSS [training: 0.03157750429555404 | validation: 0.013553294742559868]
	TIME [epoch: 6.56 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04047044032879497		[learning rate: 0.00087861]
	Learning Rate: 0.000878607
	LOSS [training: 0.04047044032879497 | validation: 0.02538924381062422]
	TIME [epoch: 6.56 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03229558644096102		[learning rate: 0.00087653]
	Learning Rate: 0.000876535
	LOSS [training: 0.03229558644096102 | validation: 0.018874696931259406]
	TIME [epoch: 6.56 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037150149485711145		[learning rate: 0.00087447]
	Learning Rate: 0.000874467
	LOSS [training: 0.037150149485711145 | validation: 0.020925893270455465]
	TIME [epoch: 6.6 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030857068827626198		[learning rate: 0.0008724]
	Learning Rate: 0.000872405
	LOSS [training: 0.030857068827626198 | validation: 0.019525083428647602]
	TIME [epoch: 6.56 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03711873539432698		[learning rate: 0.00087035]
	Learning Rate: 0.000870346
	LOSS [training: 0.03711873539432698 | validation: 0.019917531659250427]
	TIME [epoch: 6.56 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03353665231487212		[learning rate: 0.00086829]
	Learning Rate: 0.000868294
	LOSS [training: 0.03353665231487212 | validation: 0.0182165076303185]
	TIME [epoch: 6.56 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032998131705551645		[learning rate: 0.00086625]
	Learning Rate: 0.000866246
	LOSS [training: 0.032998131705551645 | validation: 0.0263422308837084]
	TIME [epoch: 6.56 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03529116629802966		[learning rate: 0.0008642]
	Learning Rate: 0.000864202
	LOSS [training: 0.03529116629802966 | validation: 0.022577123275518675]
	TIME [epoch: 6.57 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03575320581889565		[learning rate: 0.00086216]
	Learning Rate: 0.000862164
	LOSS [training: 0.03575320581889565 | validation: 0.011536006862561479]
	TIME [epoch: 6.59 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041866318719240694		[learning rate: 0.00086013]
	Learning Rate: 0.00086013
	LOSS [training: 0.041866318719240694 | validation: 0.030689048632956666]
	TIME [epoch: 6.56 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04395121301344313		[learning rate: 0.0008581]
	Learning Rate: 0.000858101
	LOSS [training: 0.04395121301344313 | validation: 0.027336612621679413]
	TIME [epoch: 6.55 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0396990087915617		[learning rate: 0.00085608]
	Learning Rate: 0.000856077
	LOSS [training: 0.0396990087915617 | validation: 0.025193557484741648]
	TIME [epoch: 6.56 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05416047521909456		[learning rate: 0.00085406]
	Learning Rate: 0.000854058
	LOSS [training: 0.05416047521909456 | validation: 0.02658526994743281]
	TIME [epoch: 6.56 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04444533428430231		[learning rate: 0.00085204]
	Learning Rate: 0.000852043
	LOSS [training: 0.04444533428430231 | validation: 0.02896995802585595]
	TIME [epoch: 6.59 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04387402853375694		[learning rate: 0.00085003]
	Learning Rate: 0.000850033
	LOSS [training: 0.04387402853375694 | validation: 0.04197919811750014]
	TIME [epoch: 6.58 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07501960009321326		[learning rate: 0.00084803]
	Learning Rate: 0.000848028
	LOSS [training: 0.07501960009321326 | validation: 0.0646632111404264]
	TIME [epoch: 6.55 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.051203172885158334		[learning rate: 0.00084603]
	Learning Rate: 0.000846028
	LOSS [training: 0.051203172885158334 | validation: 0.01913098657168883]
	TIME [epoch: 6.52 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034625099602911755		[learning rate: 0.00084403]
	Learning Rate: 0.000844032
	LOSS [training: 0.034625099602911755 | validation: 0.029773349340688773]
	TIME [epoch: 6.54 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04395367296772697		[learning rate: 0.00084204]
	Learning Rate: 0.000842041
	LOSS [training: 0.04395367296772697 | validation: 0.03331860153823799]
	TIME [epoch: 6.55 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04396672748866236		[learning rate: 0.00084005]
	Learning Rate: 0.000840055
	LOSS [training: 0.04396672748866236 | validation: 0.030741761341413903]
	TIME [epoch: 6.6 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04168276692414132		[learning rate: 0.00083807]
	Learning Rate: 0.000838073
	LOSS [training: 0.04168276692414132 | validation: 0.05550878413633531]
	TIME [epoch: 6.56 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061486857457609324		[learning rate: 0.0008361]
	Learning Rate: 0.000836096
	LOSS [training: 0.061486857457609324 | validation: 0.0426366772999139]
	TIME [epoch: 6.55 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07728785236291255		[learning rate: 0.00083412]
	Learning Rate: 0.000834124
	LOSS [training: 0.07728785236291255 | validation: 0.07343163485701382]
	TIME [epoch: 6.55 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06482523028238218		[learning rate: 0.00083216]
	Learning Rate: 0.000832157
	LOSS [training: 0.06482523028238218 | validation: 0.05301002190003791]
	TIME [epoch: 6.55 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0535425411348198		[learning rate: 0.00083019]
	Learning Rate: 0.000830194
	LOSS [training: 0.0535425411348198 | validation: 0.036028166998769956]
	TIME [epoch: 6.56 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038409689211847634		[learning rate: 0.00082824]
	Learning Rate: 0.000828236
	LOSS [training: 0.038409689211847634 | validation: 0.02475631460035473]
	TIME [epoch: 6.58 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034812966941614745		[learning rate: 0.00082628]
	Learning Rate: 0.000826282
	LOSS [training: 0.034812966941614745 | validation: 0.037350604900282296]
	TIME [epoch: 6.55 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24535235358512947		[learning rate: 0.00082433]
	Learning Rate: 0.000824333
	LOSS [training: 0.24535235358512947 | validation: 0.250186504440376]
	TIME [epoch: 6.55 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21173356102239485		[learning rate: 0.00082239]
	Learning Rate: 0.000822388
	LOSS [training: 0.21173356102239485 | validation: 0.06754630966114429]
	TIME [epoch: 6.56 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06980355203533381		[learning rate: 0.00082045]
	Learning Rate: 0.000820448
	LOSS [training: 0.06980355203533381 | validation: 0.001073378555252972]
	TIME [epoch: 6.56 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_1109.pth
	Model improved!!!
EPOCH 1110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029281326662816215		[learning rate: 0.00081851]
	Learning Rate: 0.000818513
	LOSS [training: 0.029281326662816215 | validation: 0.022023778843038178]
	TIME [epoch: 6.58 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03266642305559998		[learning rate: 0.00081658]
	Learning Rate: 0.000816582
	LOSS [training: 0.03266642305559998 | validation: 0.025314449607690706]
	TIME [epoch: 6.57 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023609284364664758		[learning rate: 0.00081466]
	Learning Rate: 0.000814656
	LOSS [training: 0.023609284364664758 | validation: -0.003818065161298293]
	TIME [epoch: 6.55 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_1112.pth
	Model improved!!!
EPOCH 1113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02340887801582274		[learning rate: 0.00081273]
	Learning Rate: 0.000812734
	LOSS [training: 0.02340887801582274 | validation: 0.01719748209282986]
	TIME [epoch: 6.53 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1010553011462145		[learning rate: 0.00081082]
	Learning Rate: 0.000810817
	LOSS [training: 0.1010553011462145 | validation: 0.031563797476624876]
	TIME [epoch: 6.53 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0245370991555597		[learning rate: 0.0008089]
	Learning Rate: 0.000808905
	LOSS [training: 0.0245370991555597 | validation: 0.02278001420365674]
	TIME [epoch: 6.53 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.047649789290256664		[learning rate: 0.000807]
	Learning Rate: 0.000806997
	LOSS [training: 0.047649789290256664 | validation: 0.032517388853473744]
	TIME [epoch: 6.56 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03537367530996309		[learning rate: 0.00080509]
	Learning Rate: 0.000805093
	LOSS [training: 0.03537367530996309 | validation: 0.01899124575380739]
	TIME [epoch: 6.53 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035687894873030625		[learning rate: 0.00080319]
	Learning Rate: 0.000803194
	LOSS [training: 0.035687894873030625 | validation: 0.020653805226353492]
	TIME [epoch: 6.52 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03711975439975509		[learning rate: 0.0008013]
	Learning Rate: 0.000801299
	LOSS [training: 0.03711975439975509 | validation: 0.015879520781731833]
	TIME [epoch: 6.52 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04529249739818862		[learning rate: 0.00079941]
	Learning Rate: 0.000799409
	LOSS [training: 0.04529249739818862 | validation: 0.028794484512891537]
	TIME [epoch: 6.52 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.048092492060473155		[learning rate: 0.00079752]
	Learning Rate: 0.000797524
	LOSS [training: 0.048092492060473155 | validation: 0.03129635240780644]
	TIME [epoch: 6.52 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.046358009040132875		[learning rate: 0.00079564]
	Learning Rate: 0.000795642
	LOSS [training: 0.046358009040132875 | validation: 0.04518117951799358]
	TIME [epoch: 6.57 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05687706708533322		[learning rate: 0.00079377]
	Learning Rate: 0.000793766
	LOSS [training: 0.05687706708533322 | validation: 0.03194365982818475]
	TIME [epoch: 6.52 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.045886250285795536		[learning rate: 0.00079189]
	Learning Rate: 0.000791893
	LOSS [training: 0.045886250285795536 | validation: 0.035310715218860145]
	TIME [epoch: 6.52 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05057730018157021		[learning rate: 0.00079003]
	Learning Rate: 0.000790025
	LOSS [training: 0.05057730018157021 | validation: 0.03908384775009557]
	TIME [epoch: 6.52 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041102057049893545		[learning rate: 0.00078816]
	Learning Rate: 0.000788162
	LOSS [training: 0.041102057049893545 | validation: 0.026603853450345064]
	TIME [epoch: 6.52 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03900131912951658		[learning rate: 0.0007863]
	Learning Rate: 0.000786302
	LOSS [training: 0.03900131912951658 | validation: 0.024812295172185295]
	TIME [epoch: 6.52 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030525307434185515		[learning rate: 0.00078445]
	Learning Rate: 0.000784448
	LOSS [training: 0.030525307434185515 | validation: 0.0386446888295152]
	TIME [epoch: 6.56 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054221873654280495		[learning rate: 0.0007826]
	Learning Rate: 0.000782598
	LOSS [training: 0.054221873654280495 | validation: 0.0131941624154261]
	TIME [epoch: 6.53 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037692682370903355		[learning rate: 0.00078075]
	Learning Rate: 0.000780751
	LOSS [training: 0.037692682370903355 | validation: 0.022409380627867473]
	TIME [epoch: 6.53 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0335846965750249		[learning rate: 0.00077891]
	Learning Rate: 0.00077891
	LOSS [training: 0.0335846965750249 | validation: 0.01810489017754942]
	TIME [epoch: 6.52 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03277760083245114		[learning rate: 0.00077707]
	Learning Rate: 0.000777073
	LOSS [training: 0.03277760083245114 | validation: 0.010275164969341248]
	TIME [epoch: 6.52 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04783798504146476		[learning rate: 0.00077524]
	Learning Rate: 0.000775239
	LOSS [training: 0.04783798504146476 | validation: 0.07357952105860296]
	TIME [epoch: 6.53 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1123032412511886		[learning rate: 0.00077341]
	Learning Rate: 0.000773411
	LOSS [training: 0.1123032412511886 | validation: 0.025638491393013527]
	TIME [epoch: 6.56 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030184317439766028		[learning rate: 0.00077159]
	Learning Rate: 0.000771586
	LOSS [training: 0.030184317439766028 | validation: 0.023230788472769142]
	TIME [epoch: 6.53 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026887527088713708		[learning rate: 0.00076977]
	Learning Rate: 0.000769766
	LOSS [training: 0.026887527088713708 | validation: 0.012851936697441701]
	TIME [epoch: 6.52 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035831101314025116		[learning rate: 0.00076795]
	Learning Rate: 0.000767951
	LOSS [training: 0.035831101314025116 | validation: 0.030300857369655813]
	TIME [epoch: 6.52 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040166224162089856		[learning rate: 0.00076614]
	Learning Rate: 0.000766139
	LOSS [training: 0.040166224162089856 | validation: 0.04047608123967968]
	TIME [epoch: 6.52 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04239422447966528		[learning rate: 0.00076433]
	Learning Rate: 0.000764332
	LOSS [training: 0.04239422447966528 | validation: 0.02140869308399005]
	TIME [epoch: 6.54 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03256814786306971		[learning rate: 0.00076253]
	Learning Rate: 0.000762529
	LOSS [training: 0.03256814786306971 | validation: 0.02006029341806991]
	TIME [epoch: 6.56 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037525905915092174		[learning rate: 0.00076073]
	Learning Rate: 0.00076073
	LOSS [training: 0.037525905915092174 | validation: 0.018735968998400035]
	TIME [epoch: 6.52 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03694653110089552		[learning rate: 0.00075894]
	Learning Rate: 0.000758936
	LOSS [training: 0.03694653110089552 | validation: 0.019521585432106168]
	TIME [epoch: 6.52 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0338440872797965		[learning rate: 0.00075715]
	Learning Rate: 0.000757146
	LOSS [training: 0.0338440872797965 | validation: 0.011679016271224203]
	TIME [epoch: 6.52 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034337407574735294		[learning rate: 0.00075536]
	Learning Rate: 0.00075536
	LOSS [training: 0.034337407574735294 | validation: 0.03966968496304423]
	TIME [epoch: 6.52 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04224172862297158		[learning rate: 0.00075358]
	Learning Rate: 0.000753578
	LOSS [training: 0.04224172862297158 | validation: 0.04311128458979485]
	TIME [epoch: 6.56 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04382310981765534		[learning rate: 0.0007518]
	Learning Rate: 0.0007518
	LOSS [training: 0.04382310981765534 | validation: 0.03321442845553813]
	TIME [epoch: 6.53 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04126803433811257		[learning rate: 0.00075003]
	Learning Rate: 0.000750027
	LOSS [training: 0.04126803433811257 | validation: 0.027956063692977325]
	TIME [epoch: 6.52 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0444730703072982		[learning rate: 0.00074826]
	Learning Rate: 0.000748258
	LOSS [training: 0.0444730703072982 | validation: 0.0327170431756619]
	TIME [epoch: 6.52 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04164663718317513		[learning rate: 0.00074649]
	Learning Rate: 0.000746493
	LOSS [training: 0.04164663718317513 | validation: 0.03586266031741452]
	TIME [epoch: 6.52 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.048219082279781486		[learning rate: 0.00074473]
	Learning Rate: 0.000744732
	LOSS [training: 0.048219082279781486 | validation: 0.03078770231789766]
	TIME [epoch: 6.52 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04587721134590882		[learning rate: 0.00074298]
	Learning Rate: 0.000742975
	LOSS [training: 0.04587721134590882 | validation: 0.04760184595188957]
	TIME [epoch: 6.55 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.048874374918901384		[learning rate: 0.00074122]
	Learning Rate: 0.000741223
	LOSS [training: 0.048874374918901384 | validation: 0.032350777834905725]
	TIME [epoch: 6.52 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04329814714709274		[learning rate: 0.00073947]
	Learning Rate: 0.000739474
	LOSS [training: 0.04329814714709274 | validation: 0.02417789104883066]
	TIME [epoch: 6.52 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03612014015894218		[learning rate: 0.00073773]
	Learning Rate: 0.00073773
	LOSS [training: 0.03612014015894218 | validation: 0.03348317234241212]
	TIME [epoch: 6.52 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04562434884398646		[learning rate: 0.00073599]
	Learning Rate: 0.00073599
	LOSS [training: 0.04562434884398646 | validation: 0.02354493411706549]
	TIME [epoch: 6.52 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04392800551260515		[learning rate: 0.00073425]
	Learning Rate: 0.000734254
	LOSS [training: 0.04392800551260515 | validation: 0.03527268363501428]
	TIME [epoch: 6.53 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05100175972474762		[learning rate: 0.00073252]
	Learning Rate: 0.000732522
	LOSS [training: 0.05100175972474762 | validation: 0.03407237357027866]
	TIME [epoch: 6.55 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04149753283726932		[learning rate: 0.00073079]
	Learning Rate: 0.000730794
	LOSS [training: 0.04149753283726932 | validation: 0.01467543005719566]
	TIME [epoch: 6.52 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040812296914223486		[learning rate: 0.00072907]
	Learning Rate: 0.00072907
	LOSS [training: 0.040812296914223486 | validation: 0.021931513855826937]
	TIME [epoch: 6.52 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042113452956006006		[learning rate: 0.00072735]
	Learning Rate: 0.00072735
	LOSS [training: 0.042113452956006006 | validation: 0.02424580965373061]
	TIME [epoch: 6.52 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04346442431675753		[learning rate: 0.00072563]
	Learning Rate: 0.000725634
	LOSS [training: 0.04346442431675753 | validation: 0.03597431840827033]
	TIME [epoch: 6.53 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06742612400965241		[learning rate: 0.00072392]
	Learning Rate: 0.000723923
	LOSS [training: 0.06742612400965241 | validation: 0.07058008179846129]
	TIME [epoch: 6.55 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07868113174170657		[learning rate: 0.00072222]
	Learning Rate: 0.000722215
	LOSS [training: 0.07868113174170657 | validation: 0.038622531441086225]
	TIME [epoch: 6.55 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057714071348538266		[learning rate: 0.00072051]
	Learning Rate: 0.000720512
	LOSS [training: 0.057714071348538266 | validation: 0.04137018844244608]
	TIME [epoch: 6.53 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05629142819071979		[learning rate: 0.00071881]
	Learning Rate: 0.000718812
	LOSS [training: 0.05629142819071979 | validation: 0.041934186406827764]
	TIME [epoch: 6.53 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04563727442884465		[learning rate: 0.00071712]
	Learning Rate: 0.000717117
	LOSS [training: 0.04563727442884465 | validation: 0.03036130118825551]
	TIME [epoch: 6.52 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04737498025003965		[learning rate: 0.00071542]
	Learning Rate: 0.000715425
	LOSS [training: 0.04737498025003965 | validation: 0.042487239974542776]
	TIME [epoch: 6.54 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04930773921378751		[learning rate: 0.00071374]
	Learning Rate: 0.000713738
	LOSS [training: 0.04930773921378751 | validation: 0.037165605720834036]
	TIME [epoch: 6.57 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04464657232099607		[learning rate: 0.00071205]
	Learning Rate: 0.000712054
	LOSS [training: 0.04464657232099607 | validation: 0.0344927042387069]
	TIME [epoch: 6.55 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04825361399478835		[learning rate: 0.00071037]
	Learning Rate: 0.000710374
	LOSS [training: 0.04825361399478835 | validation: 0.0229803182176956]
	TIME [epoch: 6.53 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03891267859400697		[learning rate: 0.0007087]
	Learning Rate: 0.000708698
	LOSS [training: 0.03891267859400697 | validation: 0.02318516549728166]
	TIME [epoch: 6.53 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04221660922343179		[learning rate: 0.00070703]
	Learning Rate: 0.000707027
	LOSS [training: 0.04221660922343179 | validation: 0.03766237799843126]
	TIME [epoch: 6.53 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04337746018206149		[learning rate: 0.00070536]
	Learning Rate: 0.000705359
	LOSS [training: 0.04337746018206149 | validation: 0.032246477317101105]
	TIME [epoch: 6.54 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.043213234582671255		[learning rate: 0.0007037]
	Learning Rate: 0.000703695
	LOSS [training: 0.043213234582671255 | validation: 0.02964055743792779]
	TIME [epoch: 6.58 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.045755766779322575		[learning rate: 0.00070204]
	Learning Rate: 0.000702035
	LOSS [training: 0.045755766779322575 | validation: 0.023916757560332753]
	TIME [epoch: 6.54 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042511540340084815		[learning rate: 0.00070038]
	Learning Rate: 0.000700379
	LOSS [training: 0.042511540340084815 | validation: 0.0335464841362668]
	TIME [epoch: 6.54 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06592119370608554		[learning rate: 0.00069873]
	Learning Rate: 0.000698727
	LOSS [training: 0.06592119370608554 | validation: 0.0555754953027047]
	TIME [epoch: 6.54 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06344984343585906		[learning rate: 0.00069708]
	Learning Rate: 0.000697079
	LOSS [training: 0.06344984343585906 | validation: 0.037872818557297135]
	TIME [epoch: 6.53 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04544308800014071		[learning rate: 0.00069543]
	Learning Rate: 0.000695435
	LOSS [training: 0.04544308800014071 | validation: 0.03515733717310067]
	TIME [epoch: 6.57 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061502428754097505		[learning rate: 0.00069379]
	Learning Rate: 0.000693794
	LOSS [training: 0.061502428754097505 | validation: 0.06536820536922745]
	TIME [epoch: 6.57 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0580072952611322		[learning rate: 0.00069216]
	Learning Rate: 0.000692158
	LOSS [training: 0.0580072952611322 | validation: 0.040474705097526514]
	TIME [epoch: 6.55 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05414969246509317		[learning rate: 0.00069053]
	Learning Rate: 0.000690525
	LOSS [training: 0.05414969246509317 | validation: 0.035803021239070504]
	TIME [epoch: 6.55 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05167309888374775		[learning rate: 0.0006889]
	Learning Rate: 0.000688896
	LOSS [training: 0.05167309888374775 | validation: 0.03006326792042135]
	TIME [epoch: 6.54 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04507455003627824		[learning rate: 0.00068727]
	Learning Rate: 0.000687271
	LOSS [training: 0.04507455003627824 | validation: 0.0335627757270379]
	TIME [epoch: 6.55 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.047699145891717684		[learning rate: 0.00068565]
	Learning Rate: 0.00068565
	LOSS [training: 0.047699145891717684 | validation: 0.03176602204742126]
	TIME [epoch: 6.59 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05333523356844901		[learning rate: 0.00068403]
	Learning Rate: 0.000684033
	LOSS [training: 0.05333523356844901 | validation: 0.04057480994666489]
	TIME [epoch: 6.55 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050712944266763774		[learning rate: 0.00068242]
	Learning Rate: 0.000682419
	LOSS [training: 0.050712944266763774 | validation: 0.023927557993103327]
	TIME [epoch: 6.54 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04184281039158634		[learning rate: 0.00068081]
	Learning Rate: 0.00068081
	LOSS [training: 0.04184281039158634 | validation: 0.0418985674552987]
	TIME [epoch: 6.54 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04334194833356222		[learning rate: 0.0006792]
	Learning Rate: 0.000679204
	LOSS [training: 0.04334194833356222 | validation: 0.02450264104197103]
	TIME [epoch: 6.54 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04173552701830614		[learning rate: 0.0006776]
	Learning Rate: 0.000677601
	LOSS [training: 0.04173552701830614 | validation: 0.028870318473991945]
	TIME [epoch: 6.55 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040082206345113155		[learning rate: 0.000676]
	Learning Rate: 0.000676003
	LOSS [training: 0.040082206345113155 | validation: 0.02292119558140906]
	TIME [epoch: 6.58 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033508081492564824		[learning rate: 0.00067441]
	Learning Rate: 0.000674409
	LOSS [training: 0.033508081492564824 | validation: 0.01841007693225013]
	TIME [epoch: 6.53 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04058971925872308		[learning rate: 0.00067282]
	Learning Rate: 0.000672818
	LOSS [training: 0.04058971925872308 | validation: 0.025738564479167867]
	TIME [epoch: 6.53 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04452128648760959		[learning rate: 0.00067123]
	Learning Rate: 0.000671231
	LOSS [training: 0.04452128648760959 | validation: 0.03963247835783755]
	TIME [epoch: 6.53 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04710475885007624		[learning rate: 0.00066965]
	Learning Rate: 0.000669647
	LOSS [training: 0.04710475885007624 | validation: 0.023719742981589062]
	TIME [epoch: 6.53 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04137302865856753		[learning rate: 0.00066807]
	Learning Rate: 0.000668068
	LOSS [training: 0.04137302865856753 | validation: 0.024568213503237474]
	TIME [epoch: 6.56 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0358098783926794		[learning rate: 0.00066649]
	Learning Rate: 0.000666492
	LOSS [training: 0.0358098783926794 | validation: 0.025359934826093212]
	TIME [epoch: 6.56 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03952540259148053		[learning rate: 0.00066492]
	Learning Rate: 0.00066492
	LOSS [training: 0.03952540259148053 | validation: 0.02723500504818298]
	TIME [epoch: 6.53 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.045282673271820124		[learning rate: 0.00066335]
	Learning Rate: 0.000663351
	LOSS [training: 0.045282673271820124 | validation: 0.03688850139740189]
	TIME [epoch: 6.54 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039326120361868604		[learning rate: 0.00066179]
	Learning Rate: 0.000661786
	LOSS [training: 0.039326120361868604 | validation: 0.02355516685091587]
	TIME [epoch: 6.54 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040457992354872796		[learning rate: 0.00066023]
	Learning Rate: 0.000660225
	LOSS [training: 0.040457992354872796 | validation: 0.04987737399702004]
	TIME [epoch: 6.53 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05351602320615377		[learning rate: 0.00065867]
	Learning Rate: 0.000658668
	LOSS [training: 0.05351602320615377 | validation: 0.035168296103897594]
	TIME [epoch: 6.57 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0379750631569046		[learning rate: 0.00065711]
	Learning Rate: 0.000657114
	LOSS [training: 0.0379750631569046 | validation: 0.038450091328549305]
	TIME [epoch: 6.53 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03704782580806519		[learning rate: 0.00065556]
	Learning Rate: 0.000655564
	LOSS [training: 0.03704782580806519 | validation: 0.0166824325624361]
	TIME [epoch: 6.53 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04354784961240245		[learning rate: 0.00065402]
	Learning Rate: 0.000654018
	LOSS [training: 0.04354784961240245 | validation: 0.0213184498135707]
	TIME [epoch: 6.51 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040024254482147456		[learning rate: 0.00065248]
	Learning Rate: 0.000652475
	LOSS [training: 0.040024254482147456 | validation: 0.021632232771798023]
	TIME [epoch: 6.52 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0408502580581173		[learning rate: 0.00065094]
	Learning Rate: 0.000650936
	LOSS [training: 0.0408502580581173 | validation: 0.03257223615330247]
	TIME [epoch: 6.53 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03787541694160032		[learning rate: 0.0006494]
	Learning Rate: 0.000649401
	LOSS [training: 0.03787541694160032 | validation: 0.0339003735877965]
	TIME [epoch: 6.56 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04433920074264424		[learning rate: 0.00064787]
	Learning Rate: 0.000647869
	LOSS [training: 0.04433920074264424 | validation: 0.037211021617864166]
	TIME [epoch: 6.54 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04483151404566354		[learning rate: 0.00064634]
	Learning Rate: 0.000646341
	LOSS [training: 0.04483151404566354 | validation: 0.024557438723172065]
	TIME [epoch: 6.52 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04153238102014849		[learning rate: 0.00064482]
	Learning Rate: 0.000644816
	LOSS [training: 0.04153238102014849 | validation: 0.02267691277007106]
	TIME [epoch: 6.53 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04114450435280716		[learning rate: 0.0006433]
	Learning Rate: 0.000643295
	LOSS [training: 0.04114450435280716 | validation: 0.022371444225116634]
	TIME [epoch: 6.53 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04176227446568174		[learning rate: 0.00064178]
	Learning Rate: 0.000641778
	LOSS [training: 0.04176227446568174 | validation: 0.029752232839986476]
	TIME [epoch: 6.54 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04092796387862687		[learning rate: 0.00064026]
	Learning Rate: 0.000640264
	LOSS [training: 0.04092796387862687 | validation: 0.032234486839861895]
	TIME [epoch: 6.57 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040642805913551884		[learning rate: 0.00063875]
	Learning Rate: 0.000638754
	LOSS [training: 0.040642805913551884 | validation: 0.025979802672845845]
	TIME [epoch: 6.53 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04414074464632994		[learning rate: 0.00063725]
	Learning Rate: 0.000637247
	LOSS [training: 0.04414074464632994 | validation: 0.02704955570967478]
	TIME [epoch: 6.53 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.044598588371145366		[learning rate: 0.00063574]
	Learning Rate: 0.000635744
	LOSS [training: 0.044598588371145366 | validation: 0.021378685764879096]
	TIME [epoch: 6.53 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04648124113261304		[learning rate: 0.00063424]
	Learning Rate: 0.000634244
	LOSS [training: 0.04648124113261304 | validation: 0.03962950339056201]
	TIME [epoch: 6.53 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04031510085463943		[learning rate: 0.00063275]
	Learning Rate: 0.000632748
	LOSS [training: 0.04031510085463943 | validation: 0.022619498613638107]
	TIME [epoch: 6.57 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03764277178039587		[learning rate: 0.00063126]
	Learning Rate: 0.000631255
	LOSS [training: 0.03764277178039587 | validation: 0.017781747330168594]
	TIME [epoch: 6.54 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036811892774694155		[learning rate: 0.00062977]
	Learning Rate: 0.000629766
	LOSS [training: 0.036811892774694155 | validation: 0.02642185722471735]
	TIME [epoch: 6.53 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028752139631173724		[learning rate: 0.00062828]
	Learning Rate: 0.000628281
	LOSS [training: 0.028752139631173724 | validation: 0.025375377853571586]
	TIME [epoch: 6.52 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04203785742077821		[learning rate: 0.0006268]
	Learning Rate: 0.000626799
	LOSS [training: 0.04203785742077821 | validation: 0.03543993876753518]
	TIME [epoch: 6.53 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04108290505375074		[learning rate: 0.00062532]
	Learning Rate: 0.00062532
	LOSS [training: 0.04108290505375074 | validation: 0.03498736715368154]
	TIME [epoch: 6.54 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04362241985658496		[learning rate: 0.00062385]
	Learning Rate: 0.000623845
	LOSS [training: 0.04362241985658496 | validation: 0.029509397153823478]
	TIME [epoch: 6.57 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038743891685572344		[learning rate: 0.00062237]
	Learning Rate: 0.000622374
	LOSS [training: 0.038743891685572344 | validation: 0.03301512352901073]
	TIME [epoch: 6.53 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04202306665927118		[learning rate: 0.00062091]
	Learning Rate: 0.000620906
	LOSS [training: 0.04202306665927118 | validation: 0.03720292831095369]
	TIME [epoch: 6.54 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03979530011322382		[learning rate: 0.00061944]
	Learning Rate: 0.000619441
	LOSS [training: 0.03979530011322382 | validation: 0.026901245846419578]
	TIME [epoch: 6.54 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0416139988693064		[learning rate: 0.00061798]
	Learning Rate: 0.00061798
	LOSS [training: 0.0416139988693064 | validation: 0.023185294161128796]
	TIME [epoch: 6.54 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03692967484996621		[learning rate: 0.00061652]
	Learning Rate: 0.000616522
	LOSS [training: 0.03692967484996621 | validation: 0.03009388615811909]
	TIME [epoch: 6.54 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.048638076292861335		[learning rate: 0.00061507]
	Learning Rate: 0.000615068
	LOSS [training: 0.048638076292861335 | validation: 0.03358173460104427]
	TIME [epoch: 6.57 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.045169301663262065		[learning rate: 0.00061362]
	Learning Rate: 0.000613617
	LOSS [training: 0.045169301663262065 | validation: 0.02862501285636035]
	TIME [epoch: 6.53 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03425597391776013		[learning rate: 0.00061217]
	Learning Rate: 0.00061217
	LOSS [training: 0.03425597391776013 | validation: 0.028443733362112963]
	TIME [epoch: 6.53 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0432364632296772		[learning rate: 0.00061073]
	Learning Rate: 0.000610726
	LOSS [training: 0.0432364632296772 | validation: 0.03169438256693627]
	TIME [epoch: 6.54 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04106261823025416		[learning rate: 0.00060929]
	Learning Rate: 0.000609285
	LOSS [training: 0.04106261823025416 | validation: 0.034521687100972406]
	TIME [epoch: 6.54 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04241784976999478		[learning rate: 0.00060785]
	Learning Rate: 0.000607848
	LOSS [training: 0.04241784976999478 | validation: 0.02489915974394331]
	TIME [epoch: 6.57 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041047758066636186		[learning rate: 0.00060641]
	Learning Rate: 0.000606414
	LOSS [training: 0.041047758066636186 | validation: 0.02012560929793902]
	TIME [epoch: 6.55 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0403485098564658		[learning rate: 0.00060498]
	Learning Rate: 0.000604983
	LOSS [training: 0.0403485098564658 | validation: 0.018649356631654977]
	TIME [epoch: 6.54 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04238792335437168		[learning rate: 0.00060356]
	Learning Rate: 0.000603557
	LOSS [training: 0.04238792335437168 | validation: 0.01964209023747869]
	TIME [epoch: 6.53 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04106288531610548		[learning rate: 0.00060213]
	Learning Rate: 0.000602133
	LOSS [training: 0.04106288531610548 | validation: 0.02845369527810622]
	TIME [epoch: 6.55 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036279877977346976		[learning rate: 0.00060071]
	Learning Rate: 0.000600712
	LOSS [training: 0.036279877977346976 | validation: 0.017301356957557502]
	TIME [epoch: 6.54 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03793958020544204		[learning rate: 0.0005993]
	Learning Rate: 0.000599296
	LOSS [training: 0.03793958020544204 | validation: 0.026616136938256096]
	TIME [epoch: 6.58 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028386792323774897		[learning rate: 0.00059788]
	Learning Rate: 0.000597882
	LOSS [training: 0.028386792323774897 | validation: 0.01733555895075569]
	TIME [epoch: 6.54 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03674297546767434		[learning rate: 0.00059647]
	Learning Rate: 0.000596471
	LOSS [training: 0.03674297546767434 | validation: 0.023879863895405484]
	TIME [epoch: 6.53 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03116525722468149		[learning rate: 0.00059506]
	Learning Rate: 0.000595065
	LOSS [training: 0.03116525722468149 | validation: 0.019849043697595437]
	TIME [epoch: 6.53 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03726383524670694		[learning rate: 0.00059366]
	Learning Rate: 0.000593661
	LOSS [training: 0.03726383524670694 | validation: 0.02562301718698891]
	TIME [epoch: 6.53 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03889778370960004		[learning rate: 0.00059226]
	Learning Rate: 0.000592261
	LOSS [training: 0.03889778370960004 | validation: 0.03275505619880838]
	TIME [epoch: 6.54 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.046302776164768404		[learning rate: 0.00059086]
	Learning Rate: 0.000590863
	LOSS [training: 0.046302776164768404 | validation: 0.04349816045992703]
	TIME [epoch: 6.57 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.044278824577820834		[learning rate: 0.00058947]
	Learning Rate: 0.00058947
	LOSS [training: 0.044278824577820834 | validation: 0.019829288775692195]
	TIME [epoch: 6.53 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03202096848151727		[learning rate: 0.00058808]
	Learning Rate: 0.000588079
	LOSS [training: 0.03202096848151727 | validation: 0.01071009947731642]
	TIME [epoch: 6.54 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04335767092592154		[learning rate: 0.00058669]
	Learning Rate: 0.000586692
	LOSS [training: 0.04335767092592154 | validation: 0.03341033120037405]
	TIME [epoch: 6.53 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04264837153394796		[learning rate: 0.00058531]
	Learning Rate: 0.000585308
	LOSS [training: 0.04264837153394796 | validation: 0.025416924962816258]
	TIME [epoch: 6.54 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0327185324610374		[learning rate: 0.00058393]
	Learning Rate: 0.000583927
	LOSS [training: 0.0327185324610374 | validation: 0.02615284334581828]
	TIME [epoch: 6.57 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03714689266311606		[learning rate: 0.00058255]
	Learning Rate: 0.00058255
	LOSS [training: 0.03714689266311606 | validation: 0.030220549143627505]
	TIME [epoch: 6.56 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03658552782468211		[learning rate: 0.00058118]
	Learning Rate: 0.000581176
	LOSS [training: 0.03658552782468211 | validation: 0.023571237502436136]
	TIME [epoch: 6.53 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040193006959817604		[learning rate: 0.00057981]
	Learning Rate: 0.000579805
	LOSS [training: 0.040193006959817604 | validation: 0.03623481403232574]
	TIME [epoch: 6.53 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.044704921918642594		[learning rate: 0.00057844]
	Learning Rate: 0.000578437
	LOSS [training: 0.044704921918642594 | validation: 0.031367200039903856]
	TIME [epoch: 6.53 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03901187072236861		[learning rate: 0.00057707]
	Learning Rate: 0.000577073
	LOSS [training: 0.03901187072236861 | validation: 0.0205943249200824]
	TIME [epoch: 6.53 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035813669336852524		[learning rate: 0.00057571]
	Learning Rate: 0.000575712
	LOSS [training: 0.035813669336852524 | validation: 0.02108426335775071]
	TIME [epoch: 6.57 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041213777565153896		[learning rate: 0.00057435]
	Learning Rate: 0.000574354
	LOSS [training: 0.041213777565153896 | validation: 0.030901543358897644]
	TIME [epoch: 6.52 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04289117226938148		[learning rate: 0.000573]
	Learning Rate: 0.000572999
	LOSS [training: 0.04289117226938148 | validation: 0.02979159265537822]
	TIME [epoch: 6.51 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038973975116742735		[learning rate: 0.00057165]
	Learning Rate: 0.000571647
	LOSS [training: 0.038973975116742735 | validation: 0.02073460646288512]
	TIME [epoch: 6.53 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042181372124850264		[learning rate: 0.0005703]
	Learning Rate: 0.000570299
	LOSS [training: 0.042181372124850264 | validation: 0.024658830052515516]
	TIME [epoch: 6.53 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034981085045171105		[learning rate: 0.00056895]
	Learning Rate: 0.000568954
	LOSS [training: 0.034981085045171105 | validation: 0.02514704526935727]
	TIME [epoch: 6.55 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031108884850224987		[learning rate: 0.00056761]
	Learning Rate: 0.000567612
	LOSS [training: 0.031108884850224987 | validation: 0.01537881941440544]
	TIME [epoch: 6.56 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03316607457094799		[learning rate: 0.00056627]
	Learning Rate: 0.000566273
	LOSS [training: 0.03316607457094799 | validation: 0.024660458645425157]
	TIME [epoch: 6.54 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050751268027253646		[learning rate: 0.00056494]
	Learning Rate: 0.000564937
	LOSS [training: 0.050751268027253646 | validation: 0.05724305136891378]
	TIME [epoch: 6.53 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0527858736826358		[learning rate: 0.0005636]
	Learning Rate: 0.000563604
	LOSS [training: 0.0527858736826358 | validation: 0.033577522324092]
	TIME [epoch: 6.53 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04166581764023917		[learning rate: 0.00056227]
	Learning Rate: 0.000562275
	LOSS [training: 0.04166581764023917 | validation: 0.03392505121908064]
	TIME [epoch: 6.53 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0420303234416834		[learning rate: 0.00056095]
	Learning Rate: 0.000560949
	LOSS [training: 0.0420303234416834 | validation: 0.024549332777254157]
	TIME [epoch: 6.55 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035660311986987235		[learning rate: 0.00055963]
	Learning Rate: 0.000559625
	LOSS [training: 0.035660311986987235 | validation: 0.01857265184260733]
	TIME [epoch: 6.53 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03489648446981063		[learning rate: 0.00055831]
	Learning Rate: 0.000558305
	LOSS [training: 0.03489648446981063 | validation: 0.027123307400387636]
	TIME [epoch: 6.53 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04036024339858487		[learning rate: 0.00055699]
	Learning Rate: 0.000556988
	LOSS [training: 0.04036024339858487 | validation: 0.034639338572843764]
	TIME [epoch: 6.53 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03721975062460815		[learning rate: 0.00055567]
	Learning Rate: 0.000555674
	LOSS [training: 0.03721975062460815 | validation: 0.034049058770986365]
	TIME [epoch: 6.53 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04266661536578726		[learning rate: 0.00055436]
	Learning Rate: 0.000554364
	LOSS [training: 0.04266661536578726 | validation: 0.037380596884987606]
	TIME [epoch: 6.52 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0425486876981434		[learning rate: 0.00055306]
	Learning Rate: 0.000553056
	LOSS [training: 0.0425486876981434 | validation: 0.021784285581181433]
	TIME [epoch: 6.56 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0468920835239985		[learning rate: 0.00055175]
	Learning Rate: 0.000551752
	LOSS [training: 0.0468920835239985 | validation: 0.029838061848896008]
	TIME [epoch: 6.54 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04547381350763508		[learning rate: 0.00055045]
	Learning Rate: 0.00055045
	LOSS [training: 0.04547381350763508 | validation: 0.03824437335846507]
	TIME [epoch: 6.53 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041811559205845755		[learning rate: 0.00054915]
	Learning Rate: 0.000549152
	LOSS [training: 0.041811559205845755 | validation: 0.036589771538257654]
	TIME [epoch: 6.53 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.049206860301714686		[learning rate: 0.00054786]
	Learning Rate: 0.000547856
	LOSS [training: 0.049206860301714686 | validation: 0.0372161082606589]
	TIME [epoch: 6.52 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04788294774363607		[learning rate: 0.00054656]
	Learning Rate: 0.000546564
	LOSS [training: 0.04788294774363607 | validation: 0.03225687431886271]
	TIME [epoch: 6.53 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04491731540244613		[learning rate: 0.00054527]
	Learning Rate: 0.000545275
	LOSS [training: 0.04491731540244613 | validation: 0.03841817682392183]
	TIME [epoch: 6.57 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04287345419622675		[learning rate: 0.00054399]
	Learning Rate: 0.000543988
	LOSS [training: 0.04287345419622675 | validation: 0.037861380964835295]
	TIME [epoch: 6.53 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04562949488397637		[learning rate: 0.00054271]
	Learning Rate: 0.000542705
	LOSS [training: 0.04562949488397637 | validation: 0.027461547559731778]
	TIME [epoch: 6.52 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040833797451122575		[learning rate: 0.00054143]
	Learning Rate: 0.000541425
	LOSS [training: 0.040833797451122575 | validation: 0.02019513501732148]
	TIME [epoch: 6.52 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04193522309804635		[learning rate: 0.00054015]
	Learning Rate: 0.000540148
	LOSS [training: 0.04193522309804635 | validation: 0.023151803633924176]
	TIME [epoch: 6.52 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03627089227512284		[learning rate: 0.00053887]
	Learning Rate: 0.000538874
	LOSS [training: 0.03627089227512284 | validation: 0.031160818968570855]
	TIME [epoch: 6.55 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03794415357090505		[learning rate: 0.0005376]
	Learning Rate: 0.000537603
	LOSS [training: 0.03794415357090505 | validation: 0.02756097602911897]
	TIME [epoch: 6.55 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041955996732895726		[learning rate: 0.00053633]
	Learning Rate: 0.000536335
	LOSS [training: 0.041955996732895726 | validation: 0.04059899621347117]
	TIME [epoch: 6.52 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04578176266872843		[learning rate: 0.00053507]
	Learning Rate: 0.00053507
	LOSS [training: 0.04578176266872843 | validation: 0.03998583156912308]
	TIME [epoch: 6.53 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04419625988237673		[learning rate: 0.00053381]
	Learning Rate: 0.000533807
	LOSS [training: 0.04419625988237673 | validation: 0.026932667209672266]
	TIME [epoch: 6.52 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.051093503172286225		[learning rate: 0.00053255]
	Learning Rate: 0.000532548
	LOSS [training: 0.051093503172286225 | validation: 0.024476561118420937]
	TIME [epoch: 6.53 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.043905647216625765		[learning rate: 0.00053129]
	Learning Rate: 0.000531292
	LOSS [training: 0.043905647216625765 | validation: 0.030070746226529953]
	TIME [epoch: 6.56 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04176847853813917		[learning rate: 0.00053004]
	Learning Rate: 0.000530039
	LOSS [training: 0.04176847853813917 | validation: 0.03518819160355781]
	TIME [epoch: 6.53 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03849347052379133		[learning rate: 0.00052879]
	Learning Rate: 0.000528789
	LOSS [training: 0.03849347052379133 | validation: 0.02291391637160788]
	TIME [epoch: 6.52 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0374076107066086		[learning rate: 0.00052754]
	Learning Rate: 0.000527541
	LOSS [training: 0.0374076107066086 | validation: 0.015077451373470665]
	TIME [epoch: 6.52 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035226758094120916		[learning rate: 0.0005263]
	Learning Rate: 0.000526297
	LOSS [training: 0.035226758094120916 | validation: 0.029935847637422224]
	TIME [epoch: 6.53 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04122067129310475		[learning rate: 0.00052506]
	Learning Rate: 0.000525055
	LOSS [training: 0.04122067129310475 | validation: 0.030972770197835335]
	TIME [epoch: 6.53 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0439970206164396		[learning rate: 0.00052382]
	Learning Rate: 0.000523817
	LOSS [training: 0.0439970206164396 | validation: 0.03107784862032103]
	TIME [epoch: 6.57 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04707497271983918		[learning rate: 0.00052258]
	Learning Rate: 0.000522581
	LOSS [training: 0.04707497271983918 | validation: 0.0303374570820999]
	TIME [epoch: 6.53 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.043422627587852605		[learning rate: 0.00052135]
	Learning Rate: 0.000521348
	LOSS [training: 0.043422627587852605 | validation: 0.0382573054957343]
	TIME [epoch: 6.53 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0443048628396369		[learning rate: 0.00052012]
	Learning Rate: 0.000520119
	LOSS [training: 0.0443048628396369 | validation: 0.030280782226070835]
	TIME [epoch: 6.53 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04397002586600537		[learning rate: 0.00051889]
	Learning Rate: 0.000518892
	LOSS [training: 0.04397002586600537 | validation: 0.026941295567916874]
	TIME [epoch: 6.52 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042493892913694396		[learning rate: 0.00051767]
	Learning Rate: 0.000517668
	LOSS [training: 0.042493892913694396 | validation: 0.029537926312810665]
	TIME [epoch: 6.54 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042237049831138664		[learning rate: 0.00051645]
	Learning Rate: 0.000516447
	LOSS [training: 0.042237049831138664 | validation: 0.026537764819433842]
	TIME [epoch: 6.55 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04094506971721275		[learning rate: 0.00051523]
	Learning Rate: 0.000515229
	LOSS [training: 0.04094506971721275 | validation: 0.028243035611715508]
	TIME [epoch: 6.52 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04118196134121376		[learning rate: 0.00051401]
	Learning Rate: 0.000514013
	LOSS [training: 0.04118196134121376 | validation: 0.03971056187692017]
	TIME [epoch: 6.52 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05052873763290426		[learning rate: 0.0005128]
	Learning Rate: 0.000512801
	LOSS [training: 0.05052873763290426 | validation: 0.0492068837462008]
	TIME [epoch: 6.52 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04583626626008463		[learning rate: 0.00051159]
	Learning Rate: 0.000511591
	LOSS [training: 0.04583626626008463 | validation: 0.02878290190262397]
	TIME [epoch: 6.52 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042126825679475205		[learning rate: 0.00051038]
	Learning Rate: 0.000510384
	LOSS [training: 0.042126825679475205 | validation: 0.02168124726146628]
	TIME [epoch: 6.57 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03297401043965748		[learning rate: 0.00050918]
	Learning Rate: 0.00050918
	LOSS [training: 0.03297401043965748 | validation: 0.020870716758101336]
	TIME [epoch: 6.54 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03689625012269813		[learning rate: 0.00050798]
	Learning Rate: 0.000507979
	LOSS [training: 0.03689625012269813 | validation: 0.01750110339539598]
	TIME [epoch: 6.5 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03943973285457469		[learning rate: 0.00050678]
	Learning Rate: 0.000506781
	LOSS [training: 0.03943973285457469 | validation: 0.024905120256296005]
	TIME [epoch: 6.52 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041368775304114515		[learning rate: 0.00050559]
	Learning Rate: 0.000505586
	LOSS [training: 0.041368775304114515 | validation: 0.027646474555322216]
	TIME [epoch: 6.53 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04025675696099738		[learning rate: 0.00050439]
	Learning Rate: 0.000504393
	LOSS [training: 0.04025675696099738 | validation: 0.032232895373354865]
	TIME [epoch: 6.52 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03572919340571934		[learning rate: 0.0005032]
	Learning Rate: 0.000503203
	LOSS [training: 0.03572919340571934 | validation: 0.020650284601601038]
	TIME [epoch: 6.55 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032394191944664245		[learning rate: 0.00050202]
	Learning Rate: 0.000502016
	LOSS [training: 0.032394191944664245 | validation: 0.026568304285942423]
	TIME [epoch: 6.54 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033307712195489586		[learning rate: 0.00050083]
	Learning Rate: 0.000500832
	LOSS [training: 0.033307712195489586 | validation: 0.02871596075150025]
	TIME [epoch: 6.52 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03641123253178478		[learning rate: 0.00049965]
	Learning Rate: 0.000499651
	LOSS [training: 0.03641123253178478 | validation: 0.026381990603007402]
	TIME [epoch: 6.53 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03965500257739934		[learning rate: 0.00049847]
	Learning Rate: 0.000498472
	LOSS [training: 0.03965500257739934 | validation: 0.024859850510177785]
	TIME [epoch: 6.52 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03977760085873151		[learning rate: 0.0004973]
	Learning Rate: 0.000497296
	LOSS [training: 0.03977760085873151 | validation: 0.03399003676411175]
	TIME [epoch: 6.54 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.046848007452663896		[learning rate: 0.00049612]
	Learning Rate: 0.000496123
	LOSS [training: 0.046848007452663896 | validation: 0.030052191979155343]
	TIME [epoch: 6.56 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038994638477843804		[learning rate: 0.00049495]
	Learning Rate: 0.000494953
	LOSS [training: 0.038994638477843804 | validation: 0.031112584231095017]
	TIME [epoch: 6.52 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034019741908265386		[learning rate: 0.00049379]
	Learning Rate: 0.000493786
	LOSS [training: 0.034019741908265386 | validation: 0.019182358445424944]
	TIME [epoch: 6.53 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03296886861580343		[learning rate: 0.00049262]
	Learning Rate: 0.000492621
	LOSS [training: 0.03296886861580343 | validation: 0.014062276284787519]
	TIME [epoch: 6.53 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033485462444422416		[learning rate: 0.00049146]
	Learning Rate: 0.000491459
	LOSS [training: 0.033485462444422416 | validation: 0.017534255042981322]
	TIME [epoch: 6.53 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030684254253159387		[learning rate: 0.0004903]
	Learning Rate: 0.0004903
	LOSS [training: 0.030684254253159387 | validation: 0.02598234518803569]
	TIME [epoch: 6.55 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032283629970867346		[learning rate: 0.00048914]
	Learning Rate: 0.000489143
	LOSS [training: 0.032283629970867346 | validation: 0.022424002509541546]
	TIME [epoch: 6.55 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03157591220973663		[learning rate: 0.00048799]
	Learning Rate: 0.000487989
	LOSS [training: 0.03157591220973663 | validation: 0.020868481406828333]
	TIME [epoch: 6.53 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0388629441077585		[learning rate: 0.00048684]
	Learning Rate: 0.000486838
	LOSS [training: 0.0388629441077585 | validation: 0.022588347146758055]
	TIME [epoch: 6.53 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0386677745129064		[learning rate: 0.00048569]
	Learning Rate: 0.00048569
	LOSS [training: 0.0386677745129064 | validation: 0.02655885501810034]
	TIME [epoch: 6.53 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041306901972499754		[learning rate: 0.00048454]
	Learning Rate: 0.000484544
	LOSS [training: 0.041306901972499754 | validation: 0.05314218890032196]
	TIME [epoch: 6.53 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.045596613004202605		[learning rate: 0.0004834]
	Learning Rate: 0.000483401
	LOSS [training: 0.045596613004202605 | validation: 0.03489993610571512]
	TIME [epoch: 6.57 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0418478166939703		[learning rate: 0.00048226]
	Learning Rate: 0.000482261
	LOSS [training: 0.0418478166939703 | validation: 0.04924189126364361]
	TIME [epoch: 6.54 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05029164306112138		[learning rate: 0.00048112]
	Learning Rate: 0.000481123
	LOSS [training: 0.05029164306112138 | validation: 0.030271285396995008]
	TIME [epoch: 6.53 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04606877757489295		[learning rate: 0.00047999]
	Learning Rate: 0.000479988
	LOSS [training: 0.04606877757489295 | validation: 0.041371931062840234]
	TIME [epoch: 6.53 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04140782758894487		[learning rate: 0.00047886]
	Learning Rate: 0.000478856
	LOSS [training: 0.04140782758894487 | validation: 0.03035598203062101]
	TIME [epoch: 6.53 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03550876595786155		[learning rate: 0.00047773]
	Learning Rate: 0.000477727
	LOSS [training: 0.03550876595786155 | validation: 0.01782899639156071]
	TIME [epoch: 6.55 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03088464764469003		[learning rate: 0.0004766]
	Learning Rate: 0.0004766
	LOSS [training: 0.03088464764469003 | validation: 0.025592657978725692]
	TIME [epoch: 6.56 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036528140079206114		[learning rate: 0.00047548]
	Learning Rate: 0.000475476
	LOSS [training: 0.036528140079206114 | validation: 0.025836112961955045]
	TIME [epoch: 6.53 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038304757647380276		[learning rate: 0.00047435]
	Learning Rate: 0.000474354
	LOSS [training: 0.038304757647380276 | validation: 0.027093560915856654]
	TIME [epoch: 6.53 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04154240691245285		[learning rate: 0.00047324]
	Learning Rate: 0.000473235
	LOSS [training: 0.04154240691245285 | validation: 0.028059527249854624]
	TIME [epoch: 6.54 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03659254382732778		[learning rate: 0.00047212]
	Learning Rate: 0.000472119
	LOSS [training: 0.03659254382732778 | validation: 0.023349413293804203]
	TIME [epoch: 6.53 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040246153478276175		[learning rate: 0.00047101]
	Learning Rate: 0.000471005
	LOSS [training: 0.040246153478276175 | validation: 0.02786749445779618]
	TIME [epoch: 6.56 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03436802698742089		[learning rate: 0.00046989]
	Learning Rate: 0.000469894
	LOSS [training: 0.03436802698742089 | validation: 0.03346673560501938]
	TIME [epoch: 6.55 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04025142475322826		[learning rate: 0.00046879]
	Learning Rate: 0.000468786
	LOSS [training: 0.04025142475322826 | validation: 0.024065302025906676]
	TIME [epoch: 6.53 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03550789491365749		[learning rate: 0.00046768]
	Learning Rate: 0.00046768
	LOSS [training: 0.03550789491365749 | validation: 0.02531351709341749]
	TIME [epoch: 6.52 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03817643556198497		[learning rate: 0.00046658]
	Learning Rate: 0.000466577
	LOSS [training: 0.03817643556198497 | validation: 0.0253599912874078]
	TIME [epoch: 6.53 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041664278941688226		[learning rate: 0.00046548]
	Learning Rate: 0.000465476
	LOSS [training: 0.041664278941688226 | validation: 0.01897038060166672]
	TIME [epoch: 6.53 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057693121272485916		[learning rate: 0.00046438]
	Learning Rate: 0.000464378
	LOSS [training: 0.057693121272485916 | validation: 0.09244637473659283]
	TIME [epoch: 6.57 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1198375555183592		[learning rate: 0.00046328]
	Learning Rate: 0.000463283
	LOSS [training: 0.1198375555183592 | validation: 0.03957617818538655]
	TIME [epoch: 6.53 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04834780879889544		[learning rate: 0.00046219]
	Learning Rate: 0.00046219
	LOSS [training: 0.04834780879889544 | validation: 0.031835578163828045]
	TIME [epoch: 6.52 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035544708182701494		[learning rate: 0.0004611]
	Learning Rate: 0.0004611
	LOSS [training: 0.035544708182701494 | validation: 0.011270856984546867]
	TIME [epoch: 6.53 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030537524404791228		[learning rate: 0.00046001]
	Learning Rate: 0.000460012
	LOSS [training: 0.030537524404791228 | validation: 0.01641134358933115]
	TIME [epoch: 6.53 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024336585773448993		[learning rate: 0.00045893]
	Learning Rate: 0.000458927
	LOSS [training: 0.024336585773448993 | validation: 0.010979170964998133]
	TIME [epoch: 6.54 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.045361092720076726		[learning rate: 0.00045784]
	Learning Rate: 0.000457844
	LOSS [training: 0.045361092720076726 | validation: 0.08386644160148454]
	TIME [epoch: 6.56 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09904451663125532		[learning rate: 0.00045676]
	Learning Rate: 0.000456764
	LOSS [training: 0.09904451663125532 | validation: 0.01983183365502823]
	TIME [epoch: 6.53 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02770073463680034		[learning rate: 0.00045569]
	Learning Rate: 0.000455687
	LOSS [training: 0.02770073463680034 | validation: 0.008948678561893224]
	TIME [epoch: 6.53 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03501494609341894		[learning rate: 0.00045461]
	Learning Rate: 0.000454612
	LOSS [training: 0.03501494609341894 | validation: 0.03688537664678004]
	TIME [epoch: 6.53 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04009694893073003		[learning rate: 0.00045354]
	Learning Rate: 0.00045354
	LOSS [training: 0.04009694893073003 | validation: 0.025730424847739287]
	TIME [epoch: 6.53 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031200469820905557		[learning rate: 0.00045247]
	Learning Rate: 0.00045247
	LOSS [training: 0.031200469820905557 | validation: 0.020409782249958812]
	TIME [epoch: 6.56 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03009076184800504		[learning rate: 0.0004514]
	Learning Rate: 0.000451403
	LOSS [training: 0.03009076184800504 | validation: 0.021358879764532913]
	TIME [epoch: 6.54 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028016086528317368		[learning rate: 0.00045034]
	Learning Rate: 0.000450338
	LOSS [training: 0.028016086528317368 | validation: 0.011921526097251582]
	TIME [epoch: 6.53 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029723671668271574		[learning rate: 0.00044928]
	Learning Rate: 0.000449276
	LOSS [training: 0.029723671668271574 | validation: 0.024654737208732503]
	TIME [epoch: 6.53 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04043906232570767		[learning rate: 0.00044822]
	Learning Rate: 0.000448216
	LOSS [training: 0.04043906232570767 | validation: 0.030078532184998744]
	TIME [epoch: 6.53 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04024173517095255		[learning rate: 0.00044716]
	Learning Rate: 0.000447159
	LOSS [training: 0.04024173517095255 | validation: 0.034839241087309035]
	TIME [epoch: 6.53 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04050654373661276		[learning rate: 0.0004461]
	Learning Rate: 0.000446104
	LOSS [training: 0.04050654373661276 | validation: 0.030606624864532247]
	TIME [epoch: 6.56 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04221871222723435		[learning rate: 0.00044505]
	Learning Rate: 0.000445051
	LOSS [training: 0.04221871222723435 | validation: 0.02557137649862165]
	TIME [epoch: 6.54 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.044032047369837554		[learning rate: 0.000444]
	Learning Rate: 0.000444002
	LOSS [training: 0.044032047369837554 | validation: 0.02623994345084316]
	TIME [epoch: 6.53 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040936092049230294		[learning rate: 0.00044295]
	Learning Rate: 0.000442954
	LOSS [training: 0.040936092049230294 | validation: 0.03386477121605336]
	TIME [epoch: 6.52 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04034774023674227		[learning rate: 0.00044191]
	Learning Rate: 0.000441909
	LOSS [training: 0.04034774023674227 | validation: 0.045663760145490534]
	TIME [epoch: 6.52 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0405988651186661		[learning rate: 0.00044087]
	Learning Rate: 0.000440867
	LOSS [training: 0.0405988651186661 | validation: 0.03279574866554798]
	TIME [epoch: 6.54 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041973443014799786		[learning rate: 0.00043983]
	Learning Rate: 0.000439827
	LOSS [training: 0.041973443014799786 | validation: 0.02921836618174185]
	TIME [epoch: 6.57 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0379188922976409		[learning rate: 0.00043879]
	Learning Rate: 0.00043879
	LOSS [training: 0.0379188922976409 | validation: 0.029672194744679563]
	TIME [epoch: 6.53 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04026005815760321		[learning rate: 0.00043775]
	Learning Rate: 0.000437755
	LOSS [training: 0.04026005815760321 | validation: 0.033184678515920024]
	TIME [epoch: 6.53 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036073324455021975		[learning rate: 0.00043672]
	Learning Rate: 0.000436722
	LOSS [training: 0.036073324455021975 | validation: 0.02593562055667055]
	TIME [epoch: 6.53 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03854541255480834		[learning rate: 0.00043569]
	Learning Rate: 0.000435692
	LOSS [training: 0.03854541255480834 | validation: 0.029570818565349273]
	TIME [epoch: 6.54 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04069881149386538		[learning rate: 0.00043466]
	Learning Rate: 0.000434664
	LOSS [training: 0.04069881149386538 | validation: 0.030699823680687122]
	TIME [epoch: 6.53 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03787429870573318		[learning rate: 0.00043364]
	Learning Rate: 0.000433639
	LOSS [training: 0.03787429870573318 | validation: 0.036426262136721364]
	TIME [epoch: 6.57 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.047848216600350324		[learning rate: 0.00043262]
	Learning Rate: 0.000432616
	LOSS [training: 0.047848216600350324 | validation: 0.039966288099343446]
	TIME [epoch: 6.54 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.047496496722730056		[learning rate: 0.0004316]
	Learning Rate: 0.000431595
	LOSS [training: 0.047496496722730056 | validation: 0.028936539916396165]
	TIME [epoch: 6.52 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03933377891928204		[learning rate: 0.00043058]
	Learning Rate: 0.000430577
	LOSS [training: 0.03933377891928204 | validation: 0.026851743793039246]
	TIME [epoch: 6.53 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03530294775300848		[learning rate: 0.00042956]
	Learning Rate: 0.000429562
	LOSS [training: 0.03530294775300848 | validation: 0.023531481018964816]
	TIME [epoch: 6.54 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036323537660294614		[learning rate: 0.00042855]
	Learning Rate: 0.000428548
	LOSS [training: 0.036323537660294614 | validation: 0.019124889680946888]
	TIME [epoch: 6.58 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033831933099655695		[learning rate: 0.00042754]
	Learning Rate: 0.000427538
	LOSS [training: 0.033831933099655695 | validation: 0.022985761032816694]
	TIME [epoch: 6.55 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03919725154472175		[learning rate: 0.00042653]
	Learning Rate: 0.000426529
	LOSS [training: 0.03919725154472175 | validation: 0.015558699651099258]
	TIME [epoch: 6.51 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03453166570660921		[learning rate: 0.00042552]
	Learning Rate: 0.000425523
	LOSS [training: 0.03453166570660921 | validation: 0.022758811153060915]
	TIME [epoch: 6.53 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03854898508213841		[learning rate: 0.00042452]
	Learning Rate: 0.000424519
	LOSS [training: 0.03854898508213841 | validation: 0.016865814659054713]
	TIME [epoch: 6.53 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035255105018379654		[learning rate: 0.00042352]
	Learning Rate: 0.000423518
	LOSS [training: 0.035255105018379654 | validation: 0.025217528369807323]
	TIME [epoch: 6.55 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03548062643259968		[learning rate: 0.00042252]
	Learning Rate: 0.000422519
	LOSS [training: 0.03548062643259968 | validation: 0.024776146301062636]
	TIME [epoch: 6.57 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03852406288845014		[learning rate: 0.00042152]
	Learning Rate: 0.000421522
	LOSS [training: 0.03852406288845014 | validation: 0.028371831948528187]
	TIME [epoch: 6.53 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034979768780977485		[learning rate: 0.00042053]
	Learning Rate: 0.000420528
	LOSS [training: 0.034979768780977485 | validation: 0.017704272398968948]
	TIME [epoch: 6.54 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03176691354114021		[learning rate: 0.00041954]
	Learning Rate: 0.000419536
	LOSS [training: 0.03176691354114021 | validation: 0.031703304481421786]
	TIME [epoch: 6.53 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03460601019631444		[learning rate: 0.00041855]
	Learning Rate: 0.000418546
	LOSS [training: 0.03460601019631444 | validation: 0.01886641639580081]
	TIME [epoch: 6.54 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03429138788241835		[learning rate: 0.00041756]
	Learning Rate: 0.000417559
	LOSS [training: 0.03429138788241835 | validation: 0.022482420122497532]
	TIME [epoch: 6.55 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032614864118539935		[learning rate: 0.00041657]
	Learning Rate: 0.000416574
	LOSS [training: 0.032614864118539935 | validation: 0.017635386552691357]
	TIME [epoch: 6.57 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02680759592999086		[learning rate: 0.00041559]
	Learning Rate: 0.000415591
	LOSS [training: 0.02680759592999086 | validation: 0.018417705249652146]
	TIME [epoch: 6.53 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0347083588568191		[learning rate: 0.00041461]
	Learning Rate: 0.000414611
	LOSS [training: 0.0347083588568191 | validation: 0.019012756638555398]
	TIME [epoch: 6.53 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031700133251213417		[learning rate: 0.00041363]
	Learning Rate: 0.000413633
	LOSS [training: 0.031700133251213417 | validation: 0.03273877874249523]
	TIME [epoch: 6.53 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03590394390102379		[learning rate: 0.00041266]
	Learning Rate: 0.000412657
	LOSS [training: 0.03590394390102379 | validation: 0.024459369928650873]
	TIME [epoch: 6.53 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037525181169908446		[learning rate: 0.00041168]
	Learning Rate: 0.000411684
	LOSS [training: 0.037525181169908446 | validation: 0.021449919016684017]
	TIME [epoch: 6.57 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039927647815608557		[learning rate: 0.00041071]
	Learning Rate: 0.000410713
	LOSS [training: 0.039927647815608557 | validation: 0.02780365263021618]
	TIME [epoch: 6.54 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03423627030157686		[learning rate: 0.00040974]
	Learning Rate: 0.000409744
	LOSS [training: 0.03423627030157686 | validation: 0.017724764978917076]
	TIME [epoch: 6.54 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03993597687564816		[learning rate: 0.00040878]
	Learning Rate: 0.000408778
	LOSS [training: 0.03993597687564816 | validation: 0.021166309163006193]
	TIME [epoch: 6.53 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03261887846858101		[learning rate: 0.00040781]
	Learning Rate: 0.000407813
	LOSS [training: 0.03261887846858101 | validation: 0.020644303179484156]
	TIME [epoch: 6.53 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035839436527404046		[learning rate: 0.00040685]
	Learning Rate: 0.000406851
	LOSS [training: 0.035839436527404046 | validation: 0.02434177415535664]
	TIME [epoch: 6.54 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03690372326731646		[learning rate: 0.00040589]
	Learning Rate: 0.000405892
	LOSS [training: 0.03690372326731646 | validation: 0.03596906874650866]
	TIME [epoch: 6.56 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04599783319305759		[learning rate: 0.00040493]
	Learning Rate: 0.000404934
	LOSS [training: 0.04599783319305759 | validation: 0.047366340813012546]
	TIME [epoch: 6.54 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04624398230838912		[learning rate: 0.00040398]
	Learning Rate: 0.000403979
	LOSS [training: 0.04624398230838912 | validation: 0.03391179845219889]
	TIME [epoch: 6.53 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04227990186281911		[learning rate: 0.00040303]
	Learning Rate: 0.000403026
	LOSS [training: 0.04227990186281911 | validation: 0.03001006641023404]
	TIME [epoch: 6.53 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036775069455268636		[learning rate: 0.00040208]
	Learning Rate: 0.000402076
	LOSS [training: 0.036775069455268636 | validation: 0.020520652784011287]
	TIME [epoch: 6.53 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03453986929934327		[learning rate: 0.00040113]
	Learning Rate: 0.000401127
	LOSS [training: 0.03453986929934327 | validation: 0.02791280551227098]
	TIME [epoch: 6.56 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03821786024471814		[learning rate: 0.00040018]
	Learning Rate: 0.000400181
	LOSS [training: 0.03821786024471814 | validation: 0.02728428430083652]
	TIME [epoch: 6.58 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03347636978795521		[learning rate: 0.00039924]
	Learning Rate: 0.000399237
	LOSS [training: 0.03347636978795521 | validation: 0.018477832319952165]
	TIME [epoch: 6.55 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026482104079137602		[learning rate: 0.0003983]
	Learning Rate: 0.000398295
	LOSS [training: 0.026482104079137602 | validation: 0.01656543055732615]
	TIME [epoch: 6.53 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0272533653864577		[learning rate: 0.00039736]
	Learning Rate: 0.000397356
	LOSS [training: 0.0272533653864577 | validation: 0.021072164842750533]
	TIME [epoch: 6.54 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032480349827405865		[learning rate: 0.00039642]
	Learning Rate: 0.000396418
	LOSS [training: 0.032480349827405865 | validation: 0.018311536189083374]
	TIME [epoch: 6.54 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030124600497632575		[learning rate: 0.00039548]
	Learning Rate: 0.000395483
	LOSS [training: 0.030124600497632575 | validation: 0.013673675047970601]
	TIME [epoch: 6.57 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026014736835425566		[learning rate: 0.00039455]
	Learning Rate: 0.00039455
	LOSS [training: 0.026014736835425566 | validation: 0.02037983092431002]
	TIME [epoch: 6.55 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03471613371952868		[learning rate: 0.00039362]
	Learning Rate: 0.00039362
	LOSS [training: 0.03471613371952868 | validation: 0.020848608742766978]
	TIME [epoch: 6.53 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030461930561699		[learning rate: 0.00039269]
	Learning Rate: 0.000392691
	LOSS [training: 0.030461930561699 | validation: 0.017661990708076305]
	TIME [epoch: 6.53 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0317165573935904		[learning rate: 0.00039177]
	Learning Rate: 0.000391765
	LOSS [training: 0.0317165573935904 | validation: 0.015507188207096073]
	TIME [epoch: 6.54 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030454441216142915		[learning rate: 0.00039084]
	Learning Rate: 0.000390841
	LOSS [training: 0.030454441216142915 | validation: 0.027594282139259716]
	TIME [epoch: 6.55 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034795827495370316		[learning rate: 0.00038992]
	Learning Rate: 0.000389919
	LOSS [training: 0.034795827495370316 | validation: 0.025198752274084454]
	TIME [epoch: 6.58 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03850589126437646		[learning rate: 0.000389]
	Learning Rate: 0.000388999
	LOSS [training: 0.03850589126437646 | validation: 0.02674275147125031]
	TIME [epoch: 6.53 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03461136757439877		[learning rate: 0.00038808]
	Learning Rate: 0.000388082
	LOSS [training: 0.03461136757439877 | validation: 0.02699319798482088]
	TIME [epoch: 6.52 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03370508033756429		[learning rate: 0.00038717]
	Learning Rate: 0.000387166
	LOSS [training: 0.03370508033756429 | validation: 0.02231039395083328]
	TIME [epoch: 6.53 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034729606751026224		[learning rate: 0.00038625]
	Learning Rate: 0.000386253
	LOSS [training: 0.034729606751026224 | validation: 0.01601296599693493]
	TIME [epoch: 6.54 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03390913882207099		[learning rate: 0.00038534]
	Learning Rate: 0.000385342
	LOSS [training: 0.03390913882207099 | validation: 0.014240446304953304]
	TIME [epoch: 6.56 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030801788018853547		[learning rate: 0.00038443]
	Learning Rate: 0.000384433
	LOSS [training: 0.030801788018853547 | validation: 0.03387807928730344]
	TIME [epoch: 6.57 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04988723592473794		[learning rate: 0.00038353]
	Learning Rate: 0.000383526
	LOSS [training: 0.04988723592473794 | validation: 0.03707675875458394]
	TIME [epoch: 6.54 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041019346998375464		[learning rate: 0.00038262]
	Learning Rate: 0.000382621
	LOSS [training: 0.041019346998375464 | validation: 0.02680944577246113]
	TIME [epoch: 6.53 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030104920583526186		[learning rate: 0.00038172]
	Learning Rate: 0.000381719
	LOSS [training: 0.030104920583526186 | validation: 0.02835065216330178]
	TIME [epoch: 6.54 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0306662920608678		[learning rate: 0.00038082]
	Learning Rate: 0.000380818
	LOSS [training: 0.0306662920608678 | validation: 0.0191056805993135]
	TIME [epoch: 6.54 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034394358858763005		[learning rate: 0.00037992]
	Learning Rate: 0.00037992
	LOSS [training: 0.034394358858763005 | validation: 0.010783605223530706]
	TIME [epoch: 6.57 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026739095279278608		[learning rate: 0.00037902]
	Learning Rate: 0.000379024
	LOSS [training: 0.026739095279278608 | validation: 0.02377418666462886]
	TIME [epoch: 6.56 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03696245206383518		[learning rate: 0.00037813]
	Learning Rate: 0.00037813
	LOSS [training: 0.03696245206383518 | validation: 0.025596258290813367]
	TIME [epoch: 6.54 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03591635163113735		[learning rate: 0.00037724]
	Learning Rate: 0.000377238
	LOSS [training: 0.03591635163113735 | validation: 0.032728403193262874]
	TIME [epoch: 6.54 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03669522295883652		[learning rate: 0.00037635]
	Learning Rate: 0.000376348
	LOSS [training: 0.03669522295883652 | validation: 0.03628009324265432]
	TIME [epoch: 6.54 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04068463251705091		[learning rate: 0.00037546]
	Learning Rate: 0.00037546
	LOSS [training: 0.04068463251705091 | validation: 0.03597606446229517]
	TIME [epoch: 6.54 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038266800692566535		[learning rate: 0.00037457]
	Learning Rate: 0.000374575
	LOSS [training: 0.038266800692566535 | validation: 0.025733778324021087]
	TIME [epoch: 6.59 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04107346793825451		[learning rate: 0.00037369]
	Learning Rate: 0.000373691
	LOSS [training: 0.04107346793825451 | validation: 0.02046600585211034]
	TIME [epoch: 6.55 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03845319787631973		[learning rate: 0.00037281]
	Learning Rate: 0.00037281
	LOSS [training: 0.03845319787631973 | validation: 0.02432425983306873]
	TIME [epoch: 6.54 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0341476183666421		[learning rate: 0.00037193]
	Learning Rate: 0.00037193
	LOSS [training: 0.0341476183666421 | validation: 0.0313075264482481]
	TIME [epoch: 6.53 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034722296347780374		[learning rate: 0.00037105]
	Learning Rate: 0.000371053
	LOSS [training: 0.034722296347780374 | validation: 0.02920329835937885]
	TIME [epoch: 6.53 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03769812093787387		[learning rate: 0.00037018]
	Learning Rate: 0.000370178
	LOSS [training: 0.03769812093787387 | validation: 0.027303421789928783]
	TIME [epoch: 6.55 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039506588782783715		[learning rate: 0.0003693]
	Learning Rate: 0.000369305
	LOSS [training: 0.039506588782783715 | validation: 0.019292262421472643]
	TIME [epoch: 6.57 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03683797002421565		[learning rate: 0.00036843]
	Learning Rate: 0.000368433
	LOSS [training: 0.03683797002421565 | validation: 0.026295747079103003]
	TIME [epoch: 6.51 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03921003778127261		[learning rate: 0.00036756]
	Learning Rate: 0.000367564
	LOSS [training: 0.03921003778127261 | validation: 0.022382563913041973]
	TIME [epoch: 6.52 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03613848722042261		[learning rate: 0.0003667]
	Learning Rate: 0.000366697
	LOSS [training: 0.03613848722042261 | validation: 0.025964600931309013]
	TIME [epoch: 6.53 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04203624060694472		[learning rate: 0.00036583]
	Learning Rate: 0.000365832
	LOSS [training: 0.04203624060694472 | validation: 0.03303706539896417]
	TIME [epoch: 6.54 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03443859231657367		[learning rate: 0.00036497]
	Learning Rate: 0.000364969
	LOSS [training: 0.03443859231657367 | validation: 0.024463033907390876]
	TIME [epoch: 6.56 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03519999587222086		[learning rate: 0.00036411]
	Learning Rate: 0.000364108
	LOSS [training: 0.03519999587222086 | validation: 0.013413578791260823]
	TIME [epoch: 6.55 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03827180238181545		[learning rate: 0.00036325]
	Learning Rate: 0.00036325
	LOSS [training: 0.03827180238181545 | validation: 0.020482591402978527]
	TIME [epoch: 6.53 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035050069628963024		[learning rate: 0.00036239]
	Learning Rate: 0.000362393
	LOSS [training: 0.035050069628963024 | validation: 0.020590865605615925]
	TIME [epoch: 6.53 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033416264206441344		[learning rate: 0.00036154]
	Learning Rate: 0.000361538
	LOSS [training: 0.033416264206441344 | validation: 0.020787907209697375]
	TIME [epoch: 6.53 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03382713303972521		[learning rate: 0.00036069]
	Learning Rate: 0.000360685
	LOSS [training: 0.03382713303972521 | validation: 0.01968250765819706]
	TIME [epoch: 6.54 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03486706204149109		[learning rate: 0.00035983]
	Learning Rate: 0.000359834
	LOSS [training: 0.03486706204149109 | validation: 0.017396682871037482]
	TIME [epoch: 6.58 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03951293552995851		[learning rate: 0.00035899]
	Learning Rate: 0.000358986
	LOSS [training: 0.03951293552995851 | validation: 0.02974532695430743]
	TIME [epoch: 6.53 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034131930676090695		[learning rate: 0.00035814]
	Learning Rate: 0.000358139
	LOSS [training: 0.034131930676090695 | validation: 0.01651620374854063]
	TIME [epoch: 6.53 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032997269753538026		[learning rate: 0.00035729]
	Learning Rate: 0.000357294
	LOSS [training: 0.032997269753538026 | validation: 0.027753813568223592]
	TIME [epoch: 6.53 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03502913213243712		[learning rate: 0.00035645]
	Learning Rate: 0.000356451
	LOSS [training: 0.03502913213243712 | validation: 0.02691591024415808]
	TIME [epoch: 6.53 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030740744890110673		[learning rate: 0.00035561]
	Learning Rate: 0.00035561
	LOSS [training: 0.030740744890110673 | validation: 0.016060648903320547]
	TIME [epoch: 6.55 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03669222099570232		[learning rate: 0.00035477]
	Learning Rate: 0.000354771
	LOSS [training: 0.03669222099570232 | validation: 0.021798583570563527]
	TIME [epoch: 6.56 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035499694388877664		[learning rate: 0.00035393]
	Learning Rate: 0.000353935
	LOSS [training: 0.035499694388877664 | validation: 0.025782248050613764]
	TIME [epoch: 6.53 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03651024945853808		[learning rate: 0.0003531]
	Learning Rate: 0.0003531
	LOSS [training: 0.03651024945853808 | validation: 0.018110932764609195]
	TIME [epoch: 6.53 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03623439438272516		[learning rate: 0.00035227]
	Learning Rate: 0.000352267
	LOSS [training: 0.03623439438272516 | validation: 0.029026297637316577]
	TIME [epoch: 6.54 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034459269963844234		[learning rate: 0.00035144]
	Learning Rate: 0.000351436
	LOSS [training: 0.034459269963844234 | validation: 0.029231123247534966]
	TIME [epoch: 6.54 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02709788168399292		[learning rate: 0.00035061]
	Learning Rate: 0.000350607
	LOSS [training: 0.02709788168399292 | validation: 0.024432376096437107]
	TIME [epoch: 6.55 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028029252183148744		[learning rate: 0.00034978]
	Learning Rate: 0.00034978
	LOSS [training: 0.028029252183148744 | validation: 0.009858331646586643]
	TIME [epoch: 6.56 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01720616139260312		[learning rate: 0.00034895]
	Learning Rate: 0.000348955
	LOSS [training: 0.01720616139260312 | validation: 0.00716186069005686]
	TIME [epoch: 6.53 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01553320034473471		[learning rate: 0.00034813]
	Learning Rate: 0.000348132
	LOSS [training: 0.01553320034473471 | validation: 0.008143728434197023]
	TIME [epoch: 6.53 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018291316372480295		[learning rate: 0.00034731]
	Learning Rate: 0.000347311
	LOSS [training: 0.018291316372480295 | validation: 0.018629078304247964]
	TIME [epoch: 6.54 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027641821604315487		[learning rate: 0.00034649]
	Learning Rate: 0.000346491
	LOSS [training: 0.027641821604315487 | validation: 0.022571576655127948]
	TIME [epoch: 6.54 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027071539670185878		[learning rate: 0.00034567]
	Learning Rate: 0.000345674
	LOSS [training: 0.027071539670185878 | validation: 0.016288896116242697]
	TIME [epoch: 6.57 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032412219795569464		[learning rate: 0.00034486]
	Learning Rate: 0.000344859
	LOSS [training: 0.032412219795569464 | validation: 0.02531052888840564]
	TIME [epoch: 6.54 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0282636504679963		[learning rate: 0.00034405]
	Learning Rate: 0.000344045
	LOSS [training: 0.0282636504679963 | validation: 0.005605202660868989]
	TIME [epoch: 6.53 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026499290152937116		[learning rate: 0.00034323]
	Learning Rate: 0.000343233
	LOSS [training: 0.026499290152937116 | validation: 0.002115945794571545]
	TIME [epoch: 6.54 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023831026560937496		[learning rate: 0.00034242]
	Learning Rate: 0.000342424
	LOSS [training: 0.023831026560937496 | validation: 0.013717862594149874]
	TIME [epoch: 6.53 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029933246455809148		[learning rate: 0.00034162]
	Learning Rate: 0.000341616
	LOSS [training: 0.029933246455809148 | validation: 0.025798825395825117]
	TIME [epoch: 6.53 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034128100096580925		[learning rate: 0.00034081]
	Learning Rate: 0.00034081
	LOSS [training: 0.034128100096580925 | validation: 0.017469412006742385]
	TIME [epoch: 6.56 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032600006605452245		[learning rate: 0.00034001]
	Learning Rate: 0.000340006
	LOSS [training: 0.032600006605452245 | validation: 0.0230591673935453]
	TIME [epoch: 6.54 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02804071743715663		[learning rate: 0.0003392]
	Learning Rate: 0.000339204
	LOSS [training: 0.02804071743715663 | validation: 0.015282541958785192]
	TIME [epoch: 6.54 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021627443047722857		[learning rate: 0.0003384]
	Learning Rate: 0.000338404
	LOSS [training: 0.021627443047722857 | validation: 0.004001938150643314]
	TIME [epoch: 6.53 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018937487980043223		[learning rate: 0.00033761]
	Learning Rate: 0.000337606
	LOSS [training: 0.018937487980043223 | validation: 0.002657285692682273]
	TIME [epoch: 6.55 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014807187974596158		[learning rate: 0.00033681]
	Learning Rate: 0.00033681
	LOSS [training: 0.014807187974596158 | validation: 0.0028090179651439444]
	TIME [epoch: 6.56 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02402149311405568		[learning rate: 0.00033602]
	Learning Rate: 0.000336015
	LOSS [training: 0.02402149311405568 | validation: 0.01083950902687367]
	TIME [epoch: 6.53 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02207915661624554		[learning rate: 0.00033522]
	Learning Rate: 0.000335223
	LOSS [training: 0.02207915661624554 | validation: 0.003260101880691764]
	TIME [epoch: 6.53 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019398113247440625		[learning rate: 0.00033443]
	Learning Rate: 0.000334432
	LOSS [training: 0.019398113247440625 | validation: 0.0052420877637287654]
	TIME [epoch: 6.5 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018353859636011986		[learning rate: 0.00033364]
	Learning Rate: 0.000333643
	LOSS [training: 0.018353859636011986 | validation: 0.015208768140812729]
	TIME [epoch: 6.51 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01606057811829311		[learning rate: 0.00033286]
	Learning Rate: 0.000332856
	LOSS [training: 0.01606057811829311 | validation: 0.016137156479698867]
	TIME [epoch: 6.51 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01918369485145874		[learning rate: 0.00033207]
	Learning Rate: 0.000332071
	LOSS [training: 0.01918369485145874 | validation: -0.001326050628912171]
	TIME [epoch: 6.56 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01426246483117699		[learning rate: 0.00033129]
	Learning Rate: 0.000331288
	LOSS [training: 0.01426246483117699 | validation: 0.007275607533088241]
	TIME [epoch: 6.52 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02685883373644764		[learning rate: 0.00033051]
	Learning Rate: 0.000330506
	LOSS [training: 0.02685883373644764 | validation: 0.006615755802191086]
	TIME [epoch: 6.51 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030558609290762546		[learning rate: 0.00032973]
	Learning Rate: 0.000329726
	LOSS [training: 0.030558609290762546 | validation: 0.024889428880074897]
	TIME [epoch: 6.5 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03886588285309984		[learning rate: 0.00032895]
	Learning Rate: 0.000328949
	LOSS [training: 0.03886588285309984 | validation: 0.022927010724720424]
	TIME [epoch: 6.51 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03920301631252807		[learning rate: 0.00032817]
	Learning Rate: 0.000328173
	LOSS [training: 0.03920301631252807 | validation: 0.021229397898378122]
	TIME [epoch: 6.52 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03697316788278375		[learning rate: 0.0003274]
	Learning Rate: 0.000327399
	LOSS [training: 0.03697316788278375 | validation: 0.017605999986198818]
	TIME [epoch: 6.57 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03669991977237843		[learning rate: 0.00032663]
	Learning Rate: 0.000326626
	LOSS [training: 0.03669991977237843 | validation: 0.024485498861641867]
	TIME [epoch: 6.51 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03359623339156052		[learning rate: 0.00032586]
	Learning Rate: 0.000325856
	LOSS [training: 0.03359623339156052 | validation: 0.005199135319336671]
	TIME [epoch: 6.5 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022220418923575746		[learning rate: 0.00032509]
	Learning Rate: 0.000325087
	LOSS [training: 0.022220418923575746 | validation: 0.0027691704765281768]
	TIME [epoch: 6.5 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022038552114149873		[learning rate: 0.00032432]
	Learning Rate: 0.00032432
	LOSS [training: 0.022038552114149873 | validation: 0.010726227162742762]
	TIME [epoch: 6.51 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016388206765301793		[learning rate: 0.00032356]
	Learning Rate: 0.000323555
	LOSS [training: 0.016388206765301793 | validation: 0.007287771197897556]
	TIME [epoch: 6.53 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019111107138645618		[learning rate: 0.00032279]
	Learning Rate: 0.000322792
	LOSS [training: 0.019111107138645618 | validation: 0.010141686539474174]
	TIME [epoch: 6.53 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0277253380951962		[learning rate: 0.00032203]
	Learning Rate: 0.000322031
	LOSS [training: 0.0277253380951962 | validation: 0.019881158665908664]
	TIME [epoch: 6.5 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032741672403834285		[learning rate: 0.00032127]
	Learning Rate: 0.000321271
	LOSS [training: 0.032741672403834285 | validation: 0.02383739352036337]
	TIME [epoch: 6.51 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021345379935998787		[learning rate: 0.00032051]
	Learning Rate: 0.000320513
	LOSS [training: 0.021345379935998787 | validation: 0.005280311334896948]
	TIME [epoch: 6.5 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014032936858450062		[learning rate: 0.00031976]
	Learning Rate: 0.000319757
	LOSS [training: 0.014032936858450062 | validation: 0.0033576544861485752]
	TIME [epoch: 6.5 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01657050880337073		[learning rate: 0.000319]
	Learning Rate: 0.000319003
	LOSS [training: 0.01657050880337073 | validation: 0.0033490362755122065]
	TIME [epoch: 6.54 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019716882201276063		[learning rate: 0.00031825]
	Learning Rate: 0.000318251
	LOSS [training: 0.019716882201276063 | validation: 0.0078770881826599]
	TIME [epoch: 6.52 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015750412762970362		[learning rate: 0.0003175]
	Learning Rate: 0.0003175
	LOSS [training: 0.015750412762970362 | validation: 0.003632458257392981]
	TIME [epoch: 6.52 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021201168657056523		[learning rate: 0.00031675]
	Learning Rate: 0.000316751
	LOSS [training: 0.021201168657056523 | validation: 0.017089562244132054]
	TIME [epoch: 6.52 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027265149996615713		[learning rate: 0.000316]
	Learning Rate: 0.000316004
	LOSS [training: 0.027265149996615713 | validation: 0.010489467994266956]
	TIME [epoch: 6.52 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025759006946266		[learning rate: 0.00031526]
	Learning Rate: 0.000315258
	LOSS [training: 0.025759006946266 | validation: 0.011488981086642692]
	TIME [epoch: 6.53 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02651916820011017		[learning rate: 0.00031451]
	Learning Rate: 0.000314515
	LOSS [training: 0.02651916820011017 | validation: 0.01739368818415302]
	TIME [epoch: 6.56 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02359344987682016		[learning rate: 0.00031377]
	Learning Rate: 0.000313773
	LOSS [training: 0.02359344987682016 | validation: 0.011249313283829597]
	TIME [epoch: 6.51 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02202546440016655		[learning rate: 0.00031303]
	Learning Rate: 0.000313033
	LOSS [training: 0.02202546440016655 | validation: 0.005407624428902657]
	TIME [epoch: 6.51 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029835645842384427		[learning rate: 0.00031229]
	Learning Rate: 0.000312294
	LOSS [training: 0.029835645842384427 | validation: 0.028310071530840322]
	TIME [epoch: 6.53 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031902290363548066		[learning rate: 0.00031156]
	Learning Rate: 0.000311558
	LOSS [training: 0.031902290363548066 | validation: 0.03148531287115128]
	TIME [epoch: 6.51 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031974780833462425		[learning rate: 0.00031082]
	Learning Rate: 0.000310823
	LOSS [training: 0.031974780833462425 | validation: 0.011363654161896417]
	TIME [epoch: 6.53 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02444852025187263		[learning rate: 0.00031009]
	Learning Rate: 0.00031009
	LOSS [training: 0.02444852025187263 | validation: 0.012721604523131645]
	TIME [epoch: 6.57 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019175122450983816		[learning rate: 0.00030936]
	Learning Rate: 0.000309358
	LOSS [training: 0.019175122450983816 | validation: 0.003935698283034919]
	TIME [epoch: 6.53 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02029729837658659		[learning rate: 0.00030863]
	Learning Rate: 0.000308628
	LOSS [training: 0.02029729837658659 | validation: 0.012385091987278902]
	TIME [epoch: 6.51 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024003079759993724		[learning rate: 0.0003079]
	Learning Rate: 0.0003079
	LOSS [training: 0.024003079759993724 | validation: 0.01053389891892866]
	TIME [epoch: 6.53 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021447676269093316		[learning rate: 0.00030717]
	Learning Rate: 0.000307174
	LOSS [training: 0.021447676269093316 | validation: 0.0071845374185177035]
	TIME [epoch: 6.51 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03239186867034061		[learning rate: 0.00030645]
	Learning Rate: 0.00030645
	LOSS [training: 0.03239186867034061 | validation: 0.01647386897601784]
	TIME [epoch: 6.57 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028363714942523256		[learning rate: 0.00030573]
	Learning Rate: 0.000305727
	LOSS [training: 0.028363714942523256 | validation: 0.014472329430170457]
	TIME [epoch: 6.52 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02640288407330859		[learning rate: 0.00030501]
	Learning Rate: 0.000305005
	LOSS [training: 0.02640288407330859 | validation: 0.01689079784317934]
	TIME [epoch: 6.52 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0255055525638452		[learning rate: 0.00030429]
	Learning Rate: 0.000304286
	LOSS [training: 0.0255055525638452 | validation: 0.00692743653363518]
	TIME [epoch: 6.51 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02399559581174971		[learning rate: 0.00030357]
	Learning Rate: 0.000303568
	LOSS [training: 0.02399559581174971 | validation: 0.006764268062327689]
	TIME [epoch: 6.53 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01848378696877158		[learning rate: 0.00030285]
	Learning Rate: 0.000302852
	LOSS [training: 0.01848378696877158 | validation: 0.004349340744377835]
	TIME [epoch: 6.51 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.020110632895082883		[learning rate: 0.00030214]
	Learning Rate: 0.000302138
	LOSS [training: 0.020110632895082883 | validation: 0.0038799326251452012]
	TIME [epoch: 6.56 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017459053603925946		[learning rate: 0.00030143]
	Learning Rate: 0.000301425
	LOSS [training: 0.017459053603925946 | validation: 0.008190188059657686]
	TIME [epoch: 6.52 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019369205227745923		[learning rate: 0.00030071]
	Learning Rate: 0.000300714
	LOSS [training: 0.019369205227745923 | validation: 3.925035254697187e-05]
	TIME [epoch: 6.51 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016830997697389185		[learning rate: 0.0003]
	Learning Rate: 0.000300005
	LOSS [training: 0.016830997697389185 | validation: 0.00709644647492978]
	TIME [epoch: 6.51 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022335554868810364		[learning rate: 0.0002993]
	Learning Rate: 0.000299297
	LOSS [training: 0.022335554868810364 | validation: 0.000819905747431046]
	TIME [epoch: 6.51 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018972404406342628		[learning rate: 0.00029859]
	Learning Rate: 0.000298591
	LOSS [training: 0.018972404406342628 | validation: 0.010565928426702394]
	TIME [epoch: 6.54 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.020632475740270443		[learning rate: 0.00029789]
	Learning Rate: 0.000297887
	LOSS [training: 0.020632475740270443 | validation: 0.013097919650275828]
	TIME [epoch: 6.56 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022006862638788816		[learning rate: 0.00029718]
	Learning Rate: 0.000297184
	LOSS [training: 0.022006862638788816 | validation: 0.007818885447840717]
	TIME [epoch: 6.53 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019329765881683725		[learning rate: 0.00029648]
	Learning Rate: 0.000296483
	LOSS [training: 0.019329765881683725 | validation: 0.009813158589839112]
	TIME [epoch: 6.51 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026292083058523104		[learning rate: 0.00029578]
	Learning Rate: 0.000295784
	LOSS [training: 0.026292083058523104 | validation: 0.02582114700064659]
	TIME [epoch: 6.53 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032208000993616724		[learning rate: 0.00029509]
	Learning Rate: 0.000295086
	LOSS [training: 0.032208000993616724 | validation: 0.021141598703461578]
	TIME [epoch: 6.52 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03153178576035457		[learning rate: 0.00029439]
	Learning Rate: 0.00029439
	LOSS [training: 0.03153178576035457 | validation: 0.017857439580972988]
	TIME [epoch: 6.54 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028123943792359985		[learning rate: 0.0002937]
	Learning Rate: 0.000293696
	LOSS [training: 0.028123943792359985 | validation: 0.007080889622679135]
	TIME [epoch: 6.55 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024214856234848134		[learning rate: 0.000293]
	Learning Rate: 0.000293003
	LOSS [training: 0.024214856234848134 | validation: 0.014366616140282487]
	TIME [epoch: 6.52 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021204667772850648		[learning rate: 0.00029231]
	Learning Rate: 0.000292312
	LOSS [training: 0.021204667772850648 | validation: 0.014725316139079035]
	TIME [epoch: 6.5 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027641012978154016		[learning rate: 0.00029162]
	Learning Rate: 0.000291622
	LOSS [training: 0.027641012978154016 | validation: 0.01033841786616382]
	TIME [epoch: 6.51 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017740231293948555		[learning rate: 0.00029093]
	Learning Rate: 0.000290934
	LOSS [training: 0.017740231293948555 | validation: 0.0009340229047139579]
	TIME [epoch: 6.51 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02614125946152367		[learning rate: 0.00029025]
	Learning Rate: 0.000290248
	LOSS [training: 0.02614125946152367 | validation: 0.03680107899046592]
	TIME [epoch: 6.57 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10268835590469112		[learning rate: 0.00028956]
	Learning Rate: 0.000289563
	LOSS [training: 0.10268835590469112 | validation: 0.08051283853142516]
	TIME [epoch: 6.52 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10630357431097796		[learning rate: 0.00028888]
	Learning Rate: 0.00028888
	LOSS [training: 0.10630357431097796 | validation: 0.05604183870700562]
	TIME [epoch: 6.53 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061467328511433814		[learning rate: 0.0002882]
	Learning Rate: 0.000288199
	LOSS [training: 0.061467328511433814 | validation: 0.01917087947951794]
	TIME [epoch: 6.52 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03391770436990187		[learning rate: 0.00028752]
	Learning Rate: 0.000287519
	LOSS [training: 0.03391770436990187 | validation: 0.006718524020517218]
	TIME [epoch: 6.52 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016286841937996666		[learning rate: 0.00028684]
	Learning Rate: 0.000286841
	LOSS [training: 0.016286841937996666 | validation: 0.004735430681374428]
	TIME [epoch: 6.53 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023853545853104917		[learning rate: 0.00028616]
	Learning Rate: 0.000286164
	LOSS [training: 0.023853545853104917 | validation: 0.00833794117920994]
	TIME [epoch: 6.56 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015884633001050513		[learning rate: 0.00028549]
	Learning Rate: 0.000285489
	LOSS [training: 0.015884633001050513 | validation: -0.0003456342119179147]
	TIME [epoch: 6.54 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021652866817058358		[learning rate: 0.00028482]
	Learning Rate: 0.000284816
	LOSS [training: 0.021652866817058358 | validation: 0.004989908699931208]
	TIME [epoch: 6.53 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015592465477115874		[learning rate: 0.00028414]
	Learning Rate: 0.000284144
	LOSS [training: 0.015592465477115874 | validation: -0.004051106934465157]
	TIME [epoch: 6.52 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_1558.pth
	Model improved!!!
EPOCH 1559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013212868944331897		[learning rate: 0.00028347]
	Learning Rate: 0.000283474
	LOSS [training: 0.013212868944331897 | validation: 0.002804362833065392]
	TIME [epoch: 6.53 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013891166585107995		[learning rate: 0.00028281]
	Learning Rate: 0.000282805
	LOSS [training: 0.013891166585107995 | validation: 0.003106900499125353]
	TIME [epoch: 6.52 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01119538440144073		[learning rate: 0.00028214]
	Learning Rate: 0.000282138
	LOSS [training: 0.01119538440144073 | validation: -0.0008596098137502754]
	TIME [epoch: 6.52 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018416867040031086		[learning rate: 0.00028147]
	Learning Rate: 0.000281472
	LOSS [training: 0.018416867040031086 | validation: 0.015076055898638821]
	TIME [epoch: 6.5 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02889695079156916		[learning rate: 0.00028081]
	Learning Rate: 0.000280808
	LOSS [training: 0.02889695079156916 | validation: 0.012901520420685778]
	TIME [epoch: 6.52 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02475786235489552		[learning rate: 0.00028015]
	Learning Rate: 0.000280146
	LOSS [training: 0.02475786235489552 | validation: -0.0005073804870013585]
	TIME [epoch: 6.52 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015081395006519319		[learning rate: 0.00027949]
	Learning Rate: 0.000279485
	LOSS [training: 0.015081395006519319 | validation: 0.002892770996320993]
	TIME [epoch: 6.52 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01044069282178232		[learning rate: 0.00027883]
	Learning Rate: 0.000278826
	LOSS [training: 0.01044069282178232 | validation: 0.0008631280606677012]
	TIME [epoch: 6.56 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015337086158834426		[learning rate: 0.00027817]
	Learning Rate: 0.000278168
	LOSS [training: 0.015337086158834426 | validation: -0.005380145737464951]
	TIME [epoch: 6.52 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_1567.pth
	Model improved!!!
EPOCH 1568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01240506526604603		[learning rate: 0.00027751]
	Learning Rate: 0.000277512
	LOSS [training: 0.01240506526604603 | validation: -0.0005149167622499583]
	TIME [epoch: 6.53 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009682902434311252		[learning rate: 0.00027686]
	Learning Rate: 0.000276858
	LOSS [training: 0.009682902434311252 | validation: 0.0022850736225055015]
	TIME [epoch: 6.52 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015333125051116636		[learning rate: 0.0002762]
	Learning Rate: 0.000276204
	LOSS [training: 0.015333125051116636 | validation: 0.0021994982957955845]
	TIME [epoch: 6.5 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0187197574635926		[learning rate: 0.00027555]
	Learning Rate: 0.000275553
	LOSS [training: 0.0187197574635926 | validation: 0.0060153892996434415]
	TIME [epoch: 6.5 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023041090259064374		[learning rate: 0.0002749]
	Learning Rate: 0.000274903
	LOSS [training: 0.023041090259064374 | validation: 0.01957532235913172]
	TIME [epoch: 6.54 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024180373990227218		[learning rate: 0.00027425]
	Learning Rate: 0.000274255
	LOSS [training: 0.024180373990227218 | validation: 0.011147425465338376]
	TIME [epoch: 6.5 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03182070645010987		[learning rate: 0.00027361]
	Learning Rate: 0.000273608
	LOSS [training: 0.03182070645010987 | validation: 0.01752731920283652]
	TIME [epoch: 6.5 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032721329926790055		[learning rate: 0.00027296]
	Learning Rate: 0.000272962
	LOSS [training: 0.032721329926790055 | validation: 0.025456268587846397]
	TIME [epoch: 6.51 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03648840327687741		[learning rate: 0.00027232]
	Learning Rate: 0.000272318
	LOSS [training: 0.03648840327687741 | validation: 0.024952096555893852]
	TIME [epoch: 6.5 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03686295583960037		[learning rate: 0.00027168]
	Learning Rate: 0.000271676
	LOSS [training: 0.03686295583960037 | validation: 0.021106012075403167]
	TIME [epoch: 6.52 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03814603060998274		[learning rate: 0.00027104]
	Learning Rate: 0.000271035
	LOSS [training: 0.03814603060998274 | validation: 0.027094110535660177]
	TIME [epoch: 6.56 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03475199039690844		[learning rate: 0.0002704]
	Learning Rate: 0.000270396
	LOSS [training: 0.03475199039690844 | validation: 0.023164897130471967]
	TIME [epoch: 6.52 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0379455544630132		[learning rate: 0.00026976]
	Learning Rate: 0.000269758
	LOSS [training: 0.0379455544630132 | validation: 0.02616011365006975]
	TIME [epoch: 6.53 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035749257204639055		[learning rate: 0.00026912]
	Learning Rate: 0.000269122
	LOSS [training: 0.035749257204639055 | validation: 0.01544954565258753]
	TIME [epoch: 6.5 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03348055770095786		[learning rate: 0.00026849]
	Learning Rate: 0.000268487
	LOSS [training: 0.03348055770095786 | validation: 0.028267610693159043]
	TIME [epoch: 6.5 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03684256878420595		[learning rate: 0.00026785]
	Learning Rate: 0.000267854
	LOSS [training: 0.03684256878420595 | validation: 0.02928744229049079]
	TIME [epoch: 6.5 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04024090822871139		[learning rate: 0.00026722]
	Learning Rate: 0.000267222
	LOSS [training: 0.04024090822871139 | validation: 0.02264863662616715]
	TIME [epoch: 6.55 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04113692240067751		[learning rate: 0.00026659]
	Learning Rate: 0.000266591
	LOSS [training: 0.04113692240067751 | validation: 0.02384459229969084]
	TIME [epoch: 6.53 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039199857401587435		[learning rate: 0.00026596]
	Learning Rate: 0.000265963
	LOSS [training: 0.039199857401587435 | validation: 0.03027089606497872]
	TIME [epoch: 6.52 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04223553430311426		[learning rate: 0.00026534]
	Learning Rate: 0.000265335
	LOSS [training: 0.04223553430311426 | validation: 0.030191201900543085]
	TIME [epoch: 6.52 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04038694320122075		[learning rate: 0.00026471]
	Learning Rate: 0.000264709
	LOSS [training: 0.04038694320122075 | validation: 0.030636628106210977]
	TIME [epoch: 6.57 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03579562210297034		[learning rate: 0.00026408]
	Learning Rate: 0.000264085
	LOSS [training: 0.03579562210297034 | validation: 0.023366334726430894]
	TIME [epoch: 6.53 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035212548087246456		[learning rate: 0.00026346]
	Learning Rate: 0.000263462
	LOSS [training: 0.035212548087246456 | validation: 0.019922837421036947]
	TIME [epoch: 6.54 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03594897747230912		[learning rate: 0.00026284]
	Learning Rate: 0.00026284
	LOSS [training: 0.03594897747230912 | validation: 0.030430005067429076]
	TIME [epoch: 6.52 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03949067190670484		[learning rate: 0.00026222]
	Learning Rate: 0.00026222
	LOSS [training: 0.03949067190670484 | validation: 0.03306214578802481]
	TIME [epoch: 6.5 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04034183924558661		[learning rate: 0.0002616]
	Learning Rate: 0.000261602
	LOSS [training: 0.04034183924558661 | validation: 0.022354819663388703]
	TIME [epoch: 6.49 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03375297543395768		[learning rate: 0.00026098]
	Learning Rate: 0.000260985
	LOSS [training: 0.03375297543395768 | validation: 0.026020707347884083]
	TIME [epoch: 6.5 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03677895434590989		[learning rate: 0.00026037]
	Learning Rate: 0.000260369
	LOSS [training: 0.03677895434590989 | validation: 0.015272263599604598]
	TIME [epoch: 6.53 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028563543524696013		[learning rate: 0.00025976]
	Learning Rate: 0.000259755
	LOSS [training: 0.028563543524696013 | validation: 0.021821906490724456]
	TIME [epoch: 6.54 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02684787140774002		[learning rate: 0.00025914]
	Learning Rate: 0.000259142
	LOSS [training: 0.02684787140774002 | validation: 0.01566771538258711]
	TIME [epoch: 6.5 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029827393538940296		[learning rate: 0.00025853]
	Learning Rate: 0.000258531
	LOSS [training: 0.029827393538940296 | validation: 0.02146112301359847]
	TIME [epoch: 6.5 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034133330214965917		[learning rate: 0.00025792]
	Learning Rate: 0.000257921
	LOSS [training: 0.034133330214965917 | validation: 0.01846560387755696]
	TIME [epoch: 6.5 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03396211826756214		[learning rate: 0.00025731]
	Learning Rate: 0.000257313
	LOSS [training: 0.03396211826756214 | validation: 0.008321261315262687]
	TIME [epoch: 6.5 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038666067542407624		[learning rate: 0.00025671]
	Learning Rate: 0.000256706
	LOSS [training: 0.038666067542407624 | validation: 0.024576752753647266]
	TIME [epoch: 6.57 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03461779309104136		[learning rate: 0.0002561]
	Learning Rate: 0.0002561
	LOSS [training: 0.03461779309104136 | validation: 0.02857838089516271]
	TIME [epoch: 6.5 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04274866749284131		[learning rate: 0.0002555]
	Learning Rate: 0.000255496
	LOSS [training: 0.04274866749284131 | validation: 0.01793381260241802]
	TIME [epoch: 6.5 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036805624201554164		[learning rate: 0.00025489]
	Learning Rate: 0.000254894
	LOSS [training: 0.036805624201554164 | validation: 0.021297050450657926]
	TIME [epoch: 6.5 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03613666176613806		[learning rate: 0.00025429]
	Learning Rate: 0.000254292
	LOSS [training: 0.03613666176613806 | validation: 0.019525402650800897]
	TIME [epoch: 6.5 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035015132154497905		[learning rate: 0.00025369]
	Learning Rate: 0.000253693
	LOSS [training: 0.035015132154497905 | validation: 0.026078754438048177]
	TIME [epoch: 6.52 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.043386374322957236		[learning rate: 0.00025309]
	Learning Rate: 0.000253094
	LOSS [training: 0.043386374322957236 | validation: 0.021323142752384838]
	TIME [epoch: 6.53 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04017453248805112		[learning rate: 0.0002525]
	Learning Rate: 0.000252497
	LOSS [training: 0.04017453248805112 | validation: 0.02149231876283665]
	TIME [epoch: 6.5 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032981487477611385		[learning rate: 0.0002519]
	Learning Rate: 0.000251902
	LOSS [training: 0.032981487477611385 | validation: 0.021473198592648506]
	TIME [epoch: 6.52 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03137698213974497		[learning rate: 0.00025131]
	Learning Rate: 0.000251307
	LOSS [training: 0.03137698213974497 | validation: 0.016287785109253924]
	TIME [epoch: 6.5 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03303472259778644		[learning rate: 0.00025071]
	Learning Rate: 0.000250714
	LOSS [training: 0.03303472259778644 | validation: 0.020540802366757385]
	TIME [epoch: 6.5 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03306924996062775		[learning rate: 0.00025012]
	Learning Rate: 0.000250123
	LOSS [training: 0.03306924996062775 | validation: 0.02008759293621595]
	TIME [epoch: 6.53 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03771608578434789		[learning rate: 0.00024953]
	Learning Rate: 0.000249533
	LOSS [training: 0.03771608578434789 | validation: 0.02173201940239939]
	TIME [epoch: 6.54 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03649738302282479		[learning rate: 0.00024894]
	Learning Rate: 0.000248945
	LOSS [training: 0.03649738302282479 | validation: 0.01914728880996628]
	TIME [epoch: 6.5 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036966540916172214		[learning rate: 0.00024836]
	Learning Rate: 0.000248357
	LOSS [training: 0.036966540916172214 | validation: 0.019340676848175288]
	TIME [epoch: 6.5 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02722634734770333		[learning rate: 0.00024777]
	Learning Rate: 0.000247771
	LOSS [training: 0.02722634734770333 | validation: 0.009188120927562424]
	TIME [epoch: 6.5 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02272958213464919		[learning rate: 0.00024719]
	Learning Rate: 0.000247187
	LOSS [training: 0.02272958213464919 | validation: 0.012577896372220653]
	TIME [epoch: 6.5 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029900533666882435		[learning rate: 0.0002466]
	Learning Rate: 0.000246604
	LOSS [training: 0.029900533666882435 | validation: 0.023719199063595174]
	TIME [epoch: 6.53 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032113558408133		[learning rate: 0.00024602]
	Learning Rate: 0.000246022
	LOSS [training: 0.032113558408133 | validation: 0.007067659084679797]
	TIME [epoch: 6.51 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026578873477464144		[learning rate: 0.00024544]
	Learning Rate: 0.000245442
	LOSS [training: 0.026578873477464144 | validation: 0.016519376412987237]
	TIME [epoch: 6.52 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026545375826827578		[learning rate: 0.00024486]
	Learning Rate: 0.000244863
	LOSS [training: 0.026545375826827578 | validation: 0.015882831712895486]
	TIME [epoch: 6.5 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021478076602202852		[learning rate: 0.00024429]
	Learning Rate: 0.000244285
	LOSS [training: 0.021478076602202852 | validation: 0.013558456782503399]
	TIME [epoch: 6.5 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027963349342215855		[learning rate: 0.00024371]
	Learning Rate: 0.000243709
	LOSS [training: 0.027963349342215855 | validation: 0.016793676587743743]
	TIME [epoch: 6.51 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0320604511578539		[learning rate: 0.00024313]
	Learning Rate: 0.000243134
	LOSS [training: 0.0320604511578539 | validation: 0.009991354597903386]
	TIME [epoch: 6.54 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037154771748986265		[learning rate: 0.00024256]
	Learning Rate: 0.000242561
	LOSS [training: 0.037154771748986265 | validation: 0.019358977223707136]
	TIME [epoch: 6.53 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033875526749051844		[learning rate: 0.00024199]
	Learning Rate: 0.000241989
	LOSS [training: 0.033875526749051844 | validation: 0.023455851731101332]
	TIME [epoch: 6.52 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033927132734868096		[learning rate: 0.00024142]
	Learning Rate: 0.000241418
	LOSS [training: 0.033927132734868096 | validation: 0.02206118272038534]
	TIME [epoch: 6.5 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03317988346254978		[learning rate: 0.00024085]
	Learning Rate: 0.000240848
	LOSS [training: 0.03317988346254978 | validation: 0.015048209617045312]
	TIME [epoch: 6.52 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031271704937391474		[learning rate: 0.00024028]
	Learning Rate: 0.00024028
	LOSS [training: 0.031271704937391474 | validation: 0.021576038959623452]
	TIME [epoch: 6.52 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03184332455878073		[learning rate: 0.00023971]
	Learning Rate: 0.000239713
	LOSS [training: 0.03184332455878073 | validation: 0.01830235054634458]
	TIME [epoch: 6.55 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03303860901137963		[learning rate: 0.00023915]
	Learning Rate: 0.000239148
	LOSS [training: 0.03303860901137963 | validation: 0.01813006664854749]
	TIME [epoch: 6.52 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03149633769836856		[learning rate: 0.00023858]
	Learning Rate: 0.000238584
	LOSS [training: 0.03149633769836856 | validation: 0.01862057371117875]
	TIME [epoch: 6.5 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03293732270226681		[learning rate: 0.00023802]
	Learning Rate: 0.000238021
	LOSS [training: 0.03293732270226681 | validation: 0.022439084918828865]
	TIME [epoch: 6.5 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030136552779199743		[learning rate: 0.00023746]
	Learning Rate: 0.00023746
	LOSS [training: 0.030136552779199743 | validation: 0.02571858944275104]
	TIME [epoch: 6.5 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03481805165994878		[learning rate: 0.0002369]
	Learning Rate: 0.000236899
	LOSS [training: 0.03481805165994878 | validation: 0.021125529763489477]
	TIME [epoch: 6.54 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03430377419873536		[learning rate: 0.00023634]
	Learning Rate: 0.000236341
	LOSS [training: 0.03430377419873536 | validation: 0.017165728780198435]
	TIME [epoch: 6.54 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04155059993881849		[learning rate: 0.00023578]
	Learning Rate: 0.000235783
	LOSS [training: 0.04155059993881849 | validation: 0.0248774600568441]
	TIME [epoch: 6.5 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03511897892379044		[learning rate: 0.00023523]
	Learning Rate: 0.000235227
	LOSS [training: 0.03511897892379044 | validation: 0.018808961074297817]
	TIME [epoch: 6.52 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02975935705950587		[learning rate: 0.00023467]
	Learning Rate: 0.000234672
	LOSS [training: 0.02975935705950587 | validation: 0.02492398254150153]
	TIME [epoch: 6.5 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0318922447884254		[learning rate: 0.00023412]
	Learning Rate: 0.000234119
	LOSS [training: 0.0318922447884254 | validation: 0.025041984681054077]
	TIME [epoch: 6.5 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03349762719752343		[learning rate: 0.00023357]
	Learning Rate: 0.000233566
	LOSS [training: 0.03349762719752343 | validation: 0.01918517023677097]
	TIME [epoch: 6.53 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030812664047591427		[learning rate: 0.00023302]
	Learning Rate: 0.000233015
	LOSS [training: 0.030812664047591427 | validation: 0.02499302897194761]
	TIME [epoch: 6.5 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031935772370942396		[learning rate: 0.00023247]
	Learning Rate: 0.000232466
	LOSS [training: 0.031935772370942396 | validation: 0.018319268033374216]
	TIME [epoch: 6.5 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036000706836587654		[learning rate: 0.00023192]
	Learning Rate: 0.000231917
	LOSS [training: 0.036000706836587654 | validation: 0.025120100183951524]
	TIME [epoch: 6.49 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03132986016576536		[learning rate: 0.00023137]
	Learning Rate: 0.00023137
	LOSS [training: 0.03132986016576536 | validation: 0.012756531523827034]
	TIME [epoch: 6.49 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030550831295299685		[learning rate: 0.00023082]
	Learning Rate: 0.000230825
	LOSS [training: 0.030550831295299685 | validation: 0.018203643050913116]
	TIME [epoch: 6.5 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021094841853115182		[learning rate: 0.00023028]
	Learning Rate: 0.00023028
	LOSS [training: 0.021094841853115182 | validation: 0.007343434051974102]
	TIME [epoch: 6.53 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021605448649082804		[learning rate: 0.00022974]
	Learning Rate: 0.000229737
	LOSS [training: 0.021605448649082804 | validation: 0.0037288883815951206]
	TIME [epoch: 6.51 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023976727979741826		[learning rate: 0.00022919]
	Learning Rate: 0.000229195
	LOSS [training: 0.023976727979741826 | validation: 0.015660555170519688]
	TIME [epoch: 6.49 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026993309577602664		[learning rate: 0.00022865]
	Learning Rate: 0.000228654
	LOSS [training: 0.026993309577602664 | validation: 0.02345854330350931]
	TIME [epoch: 6.51 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030202843139992313		[learning rate: 0.00022811]
	Learning Rate: 0.000228115
	LOSS [training: 0.030202843139992313 | validation: 0.016447205448631895]
	TIME [epoch: 6.5 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02404454541472376		[learning rate: 0.00022758]
	Learning Rate: 0.000227577
	LOSS [training: 0.02404454541472376 | validation: 0.010665205460569694]
	TIME [epoch: 6.52 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0207404952679145		[learning rate: 0.00022704]
	Learning Rate: 0.00022704
	LOSS [training: 0.0207404952679145 | validation: 0.014757753637842978]
	TIME [epoch: 6.53 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022673088659370847		[learning rate: 0.0002265]
	Learning Rate: 0.000226505
	LOSS [training: 0.022673088659370847 | validation: 0.01991540669056193]
	TIME [epoch: 6.5 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02877490016730545		[learning rate: 0.00022597]
	Learning Rate: 0.00022597
	LOSS [training: 0.02877490016730545 | validation: 0.01847947799292252]
	TIME [epoch: 6.5 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022996814725555377		[learning rate: 0.00022544]
	Learning Rate: 0.000225437
	LOSS [training: 0.022996814725555377 | validation: 0.01100231321990039]
	TIME [epoch: 6.5 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023532724929542247		[learning rate: 0.00022491]
	Learning Rate: 0.000224905
	LOSS [training: 0.023532724929542247 | validation: 0.005336776942115588]
	TIME [epoch: 6.53 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.020174282074662046		[learning rate: 0.00022437]
	Learning Rate: 0.000224375
	LOSS [training: 0.020174282074662046 | validation: 0.0015569982089296674]
	TIME [epoch: 6.55 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.020718885610025568		[learning rate: 0.00022385]
	Learning Rate: 0.000223846
	LOSS [training: 0.020718885610025568 | validation: 0.007378858589807865]
	TIME [epoch: 6.5 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017374446428657257		[learning rate: 0.00022332]
	Learning Rate: 0.000223318
	LOSS [training: 0.017374446428657257 | validation: 0.002193949251134468]
	TIME [epoch: 6.51 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013374765518871772		[learning rate: 0.00022279]
	Learning Rate: 0.000222791
	LOSS [training: 0.013374765518871772 | validation: 0.002302170588339104]
	TIME [epoch: 6.5 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018408702687544964		[learning rate: 0.00022227]
	Learning Rate: 0.000222265
	LOSS [training: 0.018408702687544964 | validation: 0.005626545831286451]
	TIME [epoch: 6.51 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019864634264265955		[learning rate: 0.00022174]
	Learning Rate: 0.000221741
	LOSS [training: 0.019864634264265955 | validation: 0.005217174753638862]
	TIME [epoch: 6.53 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024843855234685464		[learning rate: 0.00022122]
	Learning Rate: 0.000221218
	LOSS [training: 0.024843855234685464 | validation: 0.010584511102601375]
	TIME [epoch: 6.54 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02179844218317904		[learning rate: 0.0002207]
	Learning Rate: 0.000220696
	LOSS [training: 0.02179844218317904 | validation: 0.00018666460155395553]
	TIME [epoch: 6.52 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014492992498081465		[learning rate: 0.00022018]
	Learning Rate: 0.000220176
	LOSS [training: 0.014492992498081465 | validation: 0.008028937619741447]
	TIME [epoch: 6.49 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02367390588608905		[learning rate: 0.00021966]
	Learning Rate: 0.000219656
	LOSS [training: 0.02367390588608905 | validation: 0.013091767045836866]
	TIME [epoch: 6.5 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024344657942873143		[learning rate: 0.00021914]
	Learning Rate: 0.000219138
	LOSS [training: 0.024344657942873143 | validation: 0.006782637644320754]
	TIME [epoch: 6.51 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015269801595433516		[learning rate: 0.00021862]
	Learning Rate: 0.000218621
	LOSS [training: 0.015269801595433516 | validation: -0.0011075946690882422]
	TIME [epoch: 6.53 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011602486722798344		[learning rate: 0.00021811]
	Learning Rate: 0.000218106
	LOSS [training: 0.011602486722798344 | validation: 0.004252728462913231]
	TIME [epoch: 6.51 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010471010397076085		[learning rate: 0.00021759]
	Learning Rate: 0.000217591
	LOSS [training: 0.010471010397076085 | validation: 0.005666143787043363]
	TIME [epoch: 6.51 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01269031890134344		[learning rate: 0.00021708]
	Learning Rate: 0.000217078
	LOSS [training: 0.01269031890134344 | validation: -0.0005012884709248034]
	TIME [epoch: 6.51 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012648284705484663		[learning rate: 0.00021657]
	Learning Rate: 0.000216566
	LOSS [training: 0.012648284705484663 | validation: -0.006254873780638849]
	TIME [epoch: 6.51 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_1673.pth
	Model improved!!!
EPOCH 1674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.008710224400848714		[learning rate: 0.00021605]
	Learning Rate: 0.000216055
	LOSS [training: 0.008710224400848714 | validation: 0.00036848579256540913]
	TIME [epoch: 6.53 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009938354745570062		[learning rate: 0.00021555]
	Learning Rate: 0.000215545
	LOSS [training: 0.009938354745570062 | validation: -0.0006504435362332684]
	TIME [epoch: 6.56 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013851612174017525		[learning rate: 0.00021504]
	Learning Rate: 0.000215037
	LOSS [training: 0.013851612174017525 | validation: 0.004367230574775876]
	TIME [epoch: 6.5 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.020381341896955733		[learning rate: 0.00021453]
	Learning Rate: 0.00021453
	LOSS [training: 0.020381341896955733 | validation: 0.007284410274452553]
	TIME [epoch: 6.5 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01984021129236903		[learning rate: 0.00021402]
	Learning Rate: 0.000214024
	LOSS [training: 0.01984021129236903 | validation: 0.008355675121156026]
	TIME [epoch: 6.49 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024143346047953946		[learning rate: 0.00021352]
	Learning Rate: 0.000213519
	LOSS [training: 0.024143346047953946 | validation: 0.013996130742168723]
	TIME [epoch: 6.49 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026463720738348896		[learning rate: 0.00021302]
	Learning Rate: 0.000213015
	LOSS [training: 0.026463720738348896 | validation: 0.017572059909624297]
	TIME [epoch: 6.5 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026763325686834833		[learning rate: 0.00021251]
	Learning Rate: 0.000212513
	LOSS [training: 0.026763325686834833 | validation: 0.018424161361524992]
	TIME [epoch: 6.53 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029499439858313353		[learning rate: 0.00021201]
	Learning Rate: 0.000212011
	LOSS [training: 0.029499439858313353 | validation: 0.022063839467422693]
	TIME [epoch: 6.49 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037780608636296176		[learning rate: 0.00021151]
	Learning Rate: 0.000211511
	LOSS [training: 0.037780608636296176 | validation: 0.024240247136717893]
	TIME [epoch: 6.49 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03908551421223229		[learning rate: 0.00021101]
	Learning Rate: 0.000211012
	LOSS [training: 0.03908551421223229 | validation: 0.025105669648981706]
	TIME [epoch: 6.49 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03986639607331981		[learning rate: 0.00021051]
	Learning Rate: 0.000210514
	LOSS [training: 0.03986639607331981 | validation: 0.020899560757804258]
	TIME [epoch: 6.5 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03682547095882792		[learning rate: 0.00021002]
	Learning Rate: 0.000210018
	LOSS [training: 0.03682547095882792 | validation: 0.027195593878634253]
	TIME [epoch: 6.53 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03283319720658602		[learning rate: 0.00020952]
	Learning Rate: 0.000209523
	LOSS [training: 0.03283319720658602 | validation: 0.012078837712151342]
	TIME [epoch: 6.56 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030163868230367197		[learning rate: 0.00020903]
	Learning Rate: 0.000209028
	LOSS [training: 0.030163868230367197 | validation: 0.029948365462979853]
	TIME [epoch: 6.49 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0439655224268499		[learning rate: 0.00020854]
	Learning Rate: 0.000208535
	LOSS [training: 0.0439655224268499 | validation: 0.034380995317629844]
	TIME [epoch: 6.52 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036113696580553925		[learning rate: 0.00020804]
	Learning Rate: 0.000208043
	LOSS [training: 0.036113696580553925 | validation: 0.036093958130268076]
	TIME [epoch: 6.51 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04674864697434693		[learning rate: 0.00020755]
	Learning Rate: 0.000207553
	LOSS [training: 0.04674864697434693 | validation: 0.03391711017468443]
	TIME [epoch: 6.52 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04014451364797543		[learning rate: 0.00020706]
	Learning Rate: 0.000207063
	LOSS [training: 0.04014451364797543 | validation: 0.032466658989705396]
	TIME [epoch: 6.53 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038372166151436383		[learning rate: 0.00020657]
	Learning Rate: 0.000206575
	LOSS [training: 0.038372166151436383 | validation: 0.02708244357159579]
	TIME [epoch: 6.55 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03361382719989424		[learning rate: 0.00020609]
	Learning Rate: 0.000206087
	LOSS [training: 0.03361382719989424 | validation: 0.018325993660079067]
	TIME [epoch: 6.52 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02973839087196572		[learning rate: 0.0002056]
	Learning Rate: 0.000205601
	LOSS [training: 0.02973839087196572 | validation: 0.015795494953626116]
	TIME [epoch: 6.52 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026723428234871872		[learning rate: 0.00020512]
	Learning Rate: 0.000205116
	LOSS [training: 0.026723428234871872 | validation: 0.007222847235673731]
	TIME [epoch: 6.52 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027934899807715408		[learning rate: 0.00020463]
	Learning Rate: 0.000204632
	LOSS [training: 0.027934899807715408 | validation: 0.02609485939476733]
	TIME [epoch: 6.52 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03651170065134925		[learning rate: 0.00020415]
	Learning Rate: 0.00020415
	LOSS [training: 0.03651170065134925 | validation: 0.02196732753472104]
	TIME [epoch: 6.55 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04188928190299335		[learning rate: 0.00020367]
	Learning Rate: 0.000203668
	LOSS [training: 0.04188928190299335 | validation: 0.03602354351432716]
	TIME [epoch: 6.53 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03961841416607261		[learning rate: 0.00020319]
	Learning Rate: 0.000203188
	LOSS [training: 0.03961841416607261 | validation: 0.027603521647580762]
	TIME [epoch: 6.51 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039110251571716215		[learning rate: 0.00020271]
	Learning Rate: 0.000202708
	LOSS [training: 0.039110251571716215 | validation: 0.029345333621394888]
	TIME [epoch: 6.49 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03901993643945102		[learning rate: 0.00020223]
	Learning Rate: 0.00020223
	LOSS [training: 0.03901993643945102 | validation: 0.031192907258563128]
	TIME [epoch: 6.51 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0378054228602587		[learning rate: 0.00020175]
	Learning Rate: 0.000201753
	LOSS [training: 0.0378054228602587 | validation: 0.021542454991442105]
	TIME [epoch: 6.52 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032361946769089475		[learning rate: 0.00020128]
	Learning Rate: 0.000201277
	LOSS [training: 0.032361946769089475 | validation: 0.022593725220528778]
	TIME [epoch: 6.55 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03262927857658957		[learning rate: 0.0002008]
	Learning Rate: 0.000200803
	LOSS [training: 0.03262927857658957 | validation: 0.02163311917167799]
	TIME [epoch: 6.52 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033911360402452836		[learning rate: 0.00020033]
	Learning Rate: 0.000200329
	LOSS [training: 0.033911360402452836 | validation: 0.02011781586101084]
	TIME [epoch: 6.52 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03745109188831856		[learning rate: 0.00019986]
	Learning Rate: 0.000199856
	LOSS [training: 0.03745109188831856 | validation: 0.017394611838323644]
	TIME [epoch: 6.5 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03883469688469197		[learning rate: 0.00019938]
	Learning Rate: 0.000199385
	LOSS [training: 0.03883469688469197 | validation: 0.02413048981927896]
	TIME [epoch: 6.52 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036124333636820306		[learning rate: 0.00019891]
	Learning Rate: 0.000198915
	LOSS [training: 0.036124333636820306 | validation: 0.020851097846310358]
	TIME [epoch: 6.53 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0302531367438455		[learning rate: 0.00019845]
	Learning Rate: 0.000198445
	LOSS [training: 0.0302531367438455 | validation: 0.020808864873194523]
	TIME [epoch: 6.55 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031820208640093536		[learning rate: 0.00019798]
	Learning Rate: 0.000197977
	LOSS [training: 0.031820208640093536 | validation: 0.028673201744180775]
	TIME [epoch: 6.51 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03654413275140004		[learning rate: 0.00019751]
	Learning Rate: 0.00019751
	LOSS [training: 0.03654413275140004 | validation: 0.023283739328173094]
	TIME [epoch: 6.52 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029954094397055663		[learning rate: 0.00019704]
	Learning Rate: 0.000197044
	LOSS [training: 0.029954094397055663 | validation: 0.019549304773661725]
	TIME [epoch: 6.52 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03260725045754167		[learning rate: 0.00019658]
	Learning Rate: 0.00019658
	LOSS [training: 0.03260725045754167 | validation: 0.02693969957735094]
	TIME [epoch: 6.51 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03252941134720042		[learning rate: 0.00019612]
	Learning Rate: 0.000196116
	LOSS [training: 0.03252941134720042 | validation: 0.022341603046639052]
	TIME [epoch: 6.54 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030419825375214243		[learning rate: 0.00019565]
	Learning Rate: 0.000195653
	LOSS [training: 0.030419825375214243 | validation: 0.026825731999608214]
	TIME [epoch: 6.53 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02787293826024586		[learning rate: 0.00019519]
	Learning Rate: 0.000195192
	LOSS [training: 0.02787293826024586 | validation: 0.00803523150139056]
	TIME [epoch: 6.52 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023246168207852524		[learning rate: 0.00019473]
	Learning Rate: 0.000194731
	LOSS [training: 0.023246168207852524 | validation: 0.015146113084258804]
	TIME [epoch: 6.51 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02107327733186353		[learning rate: 0.00019427]
	Learning Rate: 0.000194272
	LOSS [training: 0.02107327733186353 | validation: 0.013056351414326726]
	TIME [epoch: 6.52 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02186007954840963		[learning rate: 0.00019381]
	Learning Rate: 0.000193814
	LOSS [training: 0.02186007954840963 | validation: 0.011305027877228003]
	TIME [epoch: 6.5 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02127038397294925		[learning rate: 0.00019336]
	Learning Rate: 0.000193357
	LOSS [training: 0.02127038397294925 | validation: 0.0075523909658025135]
	TIME [epoch: 6.56 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01952214111639398		[learning rate: 0.0001929]
	Learning Rate: 0.0001929
	LOSS [training: 0.01952214111639398 | validation: 0.006198216025962794]
	TIME [epoch: 6.52 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012474264049711263		[learning rate: 0.00019245]
	Learning Rate: 0.000192445
	LOSS [training: 0.012474264049711263 | validation: 0.0053770237694593]
	TIME [epoch: 6.53 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022559834042842924		[learning rate: 0.00019199]
	Learning Rate: 0.000191992
	LOSS [training: 0.022559834042842924 | validation: 0.008856025782914402]
	TIME [epoch: 6.52 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01672893947909884		[learning rate: 0.00019154]
	Learning Rate: 0.000191539
	LOSS [training: 0.01672893947909884 | validation: 0.002554062840953401]
	TIME [epoch: 6.5 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012504420663231796		[learning rate: 0.00019109]
	Learning Rate: 0.000191087
	LOSS [training: 0.012504420663231796 | validation: 0.002932780237847271]
	TIME [epoch: 6.52 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019326508662260797		[learning rate: 0.00019064]
	Learning Rate: 0.000190636
	LOSS [training: 0.019326508662260797 | validation: 0.013845151234545649]
	TIME [epoch: 6.54 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02128018513997046		[learning rate: 0.00019019]
	Learning Rate: 0.000190186
	LOSS [training: 0.02128018513997046 | validation: 0.013143053085924974]
	TIME [epoch: 6.51 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026748490565034887		[learning rate: 0.00018974]
	Learning Rate: 0.000189738
	LOSS [training: 0.026748490565034887 | validation: 0.013338623283336837]
	TIME [epoch: 6.5 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025281956413677913		[learning rate: 0.00018929]
	Learning Rate: 0.00018929
	LOSS [training: 0.025281956413677913 | validation: 0.018885091079991253]
	TIME [epoch: 6.5 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027697225849080048		[learning rate: 0.00018884]
	Learning Rate: 0.000188844
	LOSS [training: 0.027697225849080048 | validation: 0.01961555883473654]
	TIME [epoch: 6.52 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02617311972964214		[learning rate: 0.0001884]
	Learning Rate: 0.000188398
	LOSS [training: 0.02617311972964214 | validation: 0.009713846090840876]
	TIME [epoch: 6.53 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02652993908776873		[learning rate: 0.00018795]
	Learning Rate: 0.000187954
	LOSS [training: 0.02652993908776873 | validation: 0.008206583445599418]
	TIME [epoch: 6.54 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01879197125361113		[learning rate: 0.00018751]
	Learning Rate: 0.000187511
	LOSS [training: 0.01879197125361113 | validation: 0.00026565826237203664]
	TIME [epoch: 6.5 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012815254245275385		[learning rate: 0.00018707]
	Learning Rate: 0.000187068
	LOSS [training: 0.012815254245275385 | validation: 0.002665455131082295]
	TIME [epoch: 6.51 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01543259849826983		[learning rate: 0.00018663]
	Learning Rate: 0.000186627
	LOSS [training: 0.01543259849826983 | validation: 0.00342076285658395]
	TIME [epoch: 6.51 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02170994722329369		[learning rate: 0.00018619]
	Learning Rate: 0.000186187
	LOSS [training: 0.02170994722329369 | validation: 0.00898444910405169]
	TIME [epoch: 6.5 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01728667595329175		[learning rate: 0.00018575]
	Learning Rate: 0.000185748
	LOSS [training: 0.01728667595329175 | validation: 0.0010963095246315007]
	TIME [epoch: 6.54 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019189902686588527		[learning rate: 0.00018531]
	Learning Rate: 0.000185309
	LOSS [training: 0.019189902686588527 | validation: 0.00429973328585642]
	TIME [epoch: 6.54 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014526949636418363		[learning rate: 0.00018487]
	Learning Rate: 0.000184872
	LOSS [training: 0.014526949636418363 | validation: -0.0019732431977594707]
	TIME [epoch: 6.5 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013687607015526381		[learning rate: 0.00018444]
	Learning Rate: 0.000184436
	LOSS [training: 0.013687607015526381 | validation: 0.0033266872426152075]
	TIME [epoch: 6.5 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01018737132566806		[learning rate: 0.000184]
	Learning Rate: 0.000184001
	LOSS [training: 0.01018737132566806 | validation: -0.0006483150433600465]
	TIME [epoch: 6.5 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012141883527522266		[learning rate: 0.00018357]
	Learning Rate: 0.000183567
	LOSS [training: 0.012141883527522266 | validation: -0.0019597747208176582]
	TIME [epoch: 6.53 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015044107010605967		[learning rate: 0.00018313]
	Learning Rate: 0.000183134
	LOSS [training: 0.015044107010605967 | validation: -0.0018356552127717172]
	TIME [epoch: 6.54 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009530533430886752		[learning rate: 0.0001827]
	Learning Rate: 0.000182702
	LOSS [training: 0.009530533430886752 | validation: -0.0020757175955250177]
	TIME [epoch: 6.51 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.006607665727813222		[learning rate: 0.00018227]
	Learning Rate: 0.000182271
	LOSS [training: 0.006607665727813222 | validation: 0.00349680135842157]
	TIME [epoch: 6.52 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011271906631031055		[learning rate: 0.00018184]
	Learning Rate: 0.000181841
	LOSS [training: 0.011271906631031055 | validation: 0.0018939092020381614]
	TIME [epoch: 6.52 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009028813096556928		[learning rate: 0.00018141]
	Learning Rate: 0.000181412
	LOSS [training: 0.009028813096556928 | validation: -0.0016576370458398354]
	TIME [epoch: 6.52 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011757977210364649		[learning rate: 0.00018098]
	Learning Rate: 0.000180984
	LOSS [training: 0.011757977210364649 | validation: -0.0016214576506745704]
	TIME [epoch: 6.54 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013939536968788696		[learning rate: 0.00018056]
	Learning Rate: 0.000180557
	LOSS [training: 0.013939536968788696 | validation: -0.003451052212376236]
	TIME [epoch: 6.54 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015697983914528247		[learning rate: 0.00018013]
	Learning Rate: 0.000180132
	LOSS [training: 0.015697983914528247 | validation: 0.006959040094955846]
	TIME [epoch: 6.52 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01774813505114609		[learning rate: 0.00017971]
	Learning Rate: 0.000179707
	LOSS [training: 0.01774813505114609 | validation: -0.00030516970750450907]
	TIME [epoch: 6.52 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012683016874802893		[learning rate: 0.00017928]
	Learning Rate: 0.000179283
	LOSS [training: 0.012683016874802893 | validation: 0.005991371900729063]
	TIME [epoch: 6.52 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012358467277190631		[learning rate: 0.00017886]
	Learning Rate: 0.00017886
	LOSS [training: 0.012358467277190631 | validation: 0.009069246354330696]
	TIME [epoch: 6.5 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014698913031182962		[learning rate: 0.00017844]
	Learning Rate: 0.000178438
	LOSS [training: 0.014698913031182962 | validation: 0.009774792117278917]
	TIME [epoch: 6.53 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019000784954415678		[learning rate: 0.00017802]
	Learning Rate: 0.000178017
	LOSS [training: 0.019000784954415678 | validation: 0.0147796626371892]
	TIME [epoch: 6.52 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025114405317447457		[learning rate: 0.0001776]
	Learning Rate: 0.000177597
	LOSS [training: 0.025114405317447457 | validation: 0.009293170554732241]
	TIME [epoch: 6.53 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028140306730789988		[learning rate: 0.00017718]
	Learning Rate: 0.000177178
	LOSS [training: 0.028140306730789988 | validation: 0.011141590129991732]
	TIME [epoch: 6.52 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02957307701827392		[learning rate: 0.00017676]
	Learning Rate: 0.00017676
	LOSS [training: 0.02957307701827392 | validation: 0.02577120854792859]
	TIME [epoch: 6.52 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027623680503105756		[learning rate: 0.00017634]
	Learning Rate: 0.000176343
	LOSS [training: 0.027623680503105756 | validation: 0.02121825332520436]
	TIME [epoch: 6.51 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02903634172630141		[learning rate: 0.00017593]
	Learning Rate: 0.000175927
	LOSS [training: 0.02903634172630141 | validation: 0.016484568243672483]
	TIME [epoch: 6.54 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025565061654914522		[learning rate: 0.00017551]
	Learning Rate: 0.000175512
	LOSS [training: 0.025565061654914522 | validation: 0.00909456977455546]
	TIME [epoch: 6.51 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023579548770651028		[learning rate: 0.0001751]
	Learning Rate: 0.000175098
	LOSS [training: 0.023579548770651028 | validation: 0.003669488226719633]
	TIME [epoch: 6.51 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017823757037728528		[learning rate: 0.00017469]
	Learning Rate: 0.000174685
	LOSS [training: 0.017823757037728528 | validation: 0.006001083030438054]
	TIME [epoch: 6.52 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019891596692828882		[learning rate: 0.00017427]
	Learning Rate: 0.000174273
	LOSS [training: 0.019891596692828882 | validation: 0.00042713617199570484]
	TIME [epoch: 6.5 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02237235894715873		[learning rate: 0.00017386]
	Learning Rate: 0.000173862
	LOSS [training: 0.02237235894715873 | validation: 0.0041425904903394945]
	TIME [epoch: 6.53 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.020545194977236603		[learning rate: 0.00017345]
	Learning Rate: 0.000173452
	LOSS [training: 0.020545194977236603 | validation: 0.000770299287857561]
	TIME [epoch: 6.53 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02239336206877894		[learning rate: 0.00017304]
	Learning Rate: 0.000173043
	LOSS [training: 0.02239336206877894 | validation: 0.011271394627226898]
	TIME [epoch: 6.51 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02070756650583417		[learning rate: 0.00017263]
	Learning Rate: 0.000172635
	LOSS [training: 0.02070756650583417 | validation: 0.005848364313342159]
	TIME [epoch: 6.52 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0183485770736599		[learning rate: 0.00017223]
	Learning Rate: 0.000172228
	LOSS [training: 0.0183485770736599 | validation: 0.002672173054706642]
	TIME [epoch: 6.51 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016360536465492913		[learning rate: 0.00017182]
	Learning Rate: 0.000171821
	LOSS [training: 0.016360536465492913 | validation: 0.010722723395780396]
	TIME [epoch: 6.49 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017744359570840154		[learning rate: 0.00017142]
	Learning Rate: 0.000171416
	LOSS [training: 0.017744359570840154 | validation: 0.008809404038905658]
	TIME [epoch: 6.54 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019757601387314656		[learning rate: 0.00017101]
	Learning Rate: 0.000171012
	LOSS [training: 0.019757601387314656 | validation: 0.010615480616614293]
	TIME [epoch: 6.5 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021999020762646142		[learning rate: 0.00017061]
	Learning Rate: 0.000170608
	LOSS [training: 0.021999020762646142 | validation: 0.006414730002753056]
	TIME [epoch: 6.52 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019835377438149726		[learning rate: 0.00017021]
	Learning Rate: 0.000170206
	LOSS [training: 0.019835377438149726 | validation: 0.013561825525458395]
	TIME [epoch: 6.51 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021787021113060946		[learning rate: 0.0001698]
	Learning Rate: 0.000169804
	LOSS [training: 0.021787021113060946 | validation: 0.009453124630048765]
	TIME [epoch: 6.51 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022177458287684755		[learning rate: 0.0001694]
	Learning Rate: 0.000169404
	LOSS [training: 0.022177458287684755 | validation: 0.01188959170475066]
	TIME [epoch: 6.51 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025074765503135133		[learning rate: 0.000169]
	Learning Rate: 0.000169004
	LOSS [training: 0.025074765503135133 | validation: 0.010684878824608359]
	TIME [epoch: 6.55 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021084257172759555		[learning rate: 0.00016861]
	Learning Rate: 0.000168606
	LOSS [training: 0.021084257172759555 | validation: 0.009614244201911138]
	TIME [epoch: 6.5 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019778195330683368		[learning rate: 0.00016821]
	Learning Rate: 0.000168208
	LOSS [training: 0.019778195330683368 | validation: -0.001299379469022489]
	TIME [epoch: 6.52 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013482533206317909		[learning rate: 0.00016781]
	Learning Rate: 0.000167811
	LOSS [training: 0.013482533206317909 | validation: 0.006702698269996079]
	TIME [epoch: 6.5 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016156667118661018		[learning rate: 0.00016742]
	Learning Rate: 0.000167415
	LOSS [training: 0.016156667118661018 | validation: -3.322059033223669e-05]
	TIME [epoch: 6.49 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017216510755723436		[learning rate: 0.00016702]
	Learning Rate: 0.00016702
	LOSS [training: 0.017216510755723436 | validation: 0.008040752887388024]
	TIME [epoch: 6.53 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023281398629047104		[learning rate: 0.00016663]
	Learning Rate: 0.000166626
	LOSS [training: 0.023281398629047104 | validation: 0.005256129835890515]
	TIME [epoch: 6.55 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018886013235299294		[learning rate: 0.00016623]
	Learning Rate: 0.000166233
	LOSS [training: 0.018886013235299294 | validation: 0.008980950380704424]
	TIME [epoch: 6.52 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015130034646203227		[learning rate: 0.00016584]
	Learning Rate: 0.000165841
	LOSS [training: 0.015130034646203227 | validation: 0.002215864009903715]
	TIME [epoch: 6.5 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012152813560271172		[learning rate: 0.00016545]
	Learning Rate: 0.00016545
	LOSS [training: 0.012152813560271172 | validation: -0.003575574936416569]
	TIME [epoch: 6.51 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.008883830605195459		[learning rate: 0.00016506]
	Learning Rate: 0.00016506
	LOSS [training: 0.008883830605195459 | validation: 0.004709659079928578]
	TIME [epoch: 6.49 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024043861275446336		[learning rate: 0.00016467]
	Learning Rate: 0.00016467
	LOSS [training: 0.024043861275446336 | validation: 0.005027763233918118]
	TIME [epoch: 6.52 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035003151689931206		[learning rate: 0.00016428]
	Learning Rate: 0.000164282
	LOSS [training: 0.035003151689931206 | validation: 0.009408718253058966]
	TIME [epoch: 6.53 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03998031083649613		[learning rate: 0.00016389]
	Learning Rate: 0.000163894
	LOSS [training: 0.03998031083649613 | validation: 0.005458761867361764]
	TIME [epoch: 6.5 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026342130458009268		[learning rate: 0.00016351]
	Learning Rate: 0.000163508
	LOSS [training: 0.026342130458009268 | validation: 0.006846486421203513]
	TIME [epoch: 6.52 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021690941705170302		[learning rate: 0.00016312]
	Learning Rate: 0.000163122
	LOSS [training: 0.021690941705170302 | validation: 0.004128362034939621]
	TIME [epoch: 6.51 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017799474901598222		[learning rate: 0.00016274]
	Learning Rate: 0.000162737
	LOSS [training: 0.017799474901598222 | validation: 0.009388395289132502]
	TIME [epoch: 6.5 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01098816619775351		[learning rate: 0.00016235]
	Learning Rate: 0.000162353
	LOSS [training: 0.01098816619775351 | validation: -0.005007194307121018]
	TIME [epoch: 6.54 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.008746993898841243		[learning rate: 0.00016197]
	Learning Rate: 0.00016197
	LOSS [training: 0.008746993898841243 | validation: 0.002292543117171338]
	TIME [epoch: 6.51 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013634506502473142		[learning rate: 0.00016159]
	Learning Rate: 0.000161588
	LOSS [training: 0.013634506502473142 | validation: 0.0024750560927019423]
	TIME [epoch: 6.51 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016825759092961207		[learning rate: 0.00016121]
	Learning Rate: 0.000161207
	LOSS [training: 0.016825759092961207 | validation: 0.001048393775467762]
	TIME [epoch: 6.5 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028183815378619703		[learning rate: 0.00016083]
	Learning Rate: 0.000160827
	LOSS [training: 0.028183815378619703 | validation: 0.006820844077094315]
	TIME [epoch: 6.5 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023782424065837193		[learning rate: 0.00016045]
	Learning Rate: 0.000160448
	LOSS [training: 0.023782424065837193 | validation: 0.0010307149438878675]
	TIME [epoch: 6.51 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014972801517837262		[learning rate: 0.00016007]
	Learning Rate: 0.000160069
	LOSS [training: 0.014972801517837262 | validation: 0.003853895874335272]
	TIME [epoch: 6.55 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011757460833495723		[learning rate: 0.00015969]
	Learning Rate: 0.000159692
	LOSS [training: 0.011757460833495723 | validation: -0.007601841902199705]
	TIME [epoch: 6.52 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_1802.pth
	Model improved!!!
EPOCH 1803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.007814099956666473		[learning rate: 0.00015931]
	Learning Rate: 0.000159315
	LOSS [training: 0.007814099956666473 | validation: -0.009838429805432902]
	TIME [epoch: 6.53 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_1803.pth
	Model improved!!!
EPOCH 1804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.00971657335517781		[learning rate: 0.00015894]
	Learning Rate: 0.000158939
	LOSS [training: 0.00971657335517781 | validation: -0.0038154676100910926]
	TIME [epoch: 6.53 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.004617113551183973		[learning rate: 0.00015856]
	Learning Rate: 0.000158564
	LOSS [training: 0.004617113551183973 | validation: -0.005314714759356283]
	TIME [epoch: 6.5 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011131389999893196		[learning rate: 0.00015819]
	Learning Rate: 0.00015819
	LOSS [training: 0.011131389999893196 | validation: -0.008592779253029826]
	TIME [epoch: 6.54 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011981695538948439		[learning rate: 0.00015782]
	Learning Rate: 0.000157817
	LOSS [training: 0.011981695538948439 | validation: 0.0027514214456872983]
	TIME [epoch: 6.53 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.008100493348600133		[learning rate: 0.00015744]
	Learning Rate: 0.000157445
	LOSS [training: 0.008100493348600133 | validation: -0.011813139064160564]
	TIME [epoch: 6.52 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_1808.pth
	Model improved!!!
EPOCH 1809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.008122645564517915		[learning rate: 0.00015707]
	Learning Rate: 0.000157073
	LOSS [training: 0.008122645564517915 | validation: -0.00420961145352641]
	TIME [epoch: 6.51 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.007999971242264496		[learning rate: 0.0001567]
	Learning Rate: 0.000156703
	LOSS [training: 0.007999971242264496 | validation: -0.0010572774581231563]
	TIME [epoch: 6.51 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01419537581404447		[learning rate: 0.00015633]
	Learning Rate: 0.000156333
	LOSS [training: 0.01419537581404447 | validation: -0.003245406069381648]
	TIME [epoch: 6.53 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.006333081608367144		[learning rate: 0.00015596]
	Learning Rate: 0.000155964
	LOSS [training: 0.006333081608367144 | validation: -0.011242183035156622]
	TIME [epoch: 6.55 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.004684764555010628		[learning rate: 0.0001556]
	Learning Rate: 0.000155597
	LOSS [training: 0.004684764555010628 | validation: 0.0024759567038882017]
	TIME [epoch: 6.51 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010962595953226476		[learning rate: 0.00015523]
	Learning Rate: 0.00015523
	LOSS [training: 0.010962595953226476 | validation: 0.003482736933463853]
	TIME [epoch: 6.5 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009832724827713583		[learning rate: 0.00015486]
	Learning Rate: 0.000154863
	LOSS [training: 0.009832724827713583 | validation: -0.0022026430359827825]
	TIME [epoch: 6.5 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.004826985604521533		[learning rate: 0.0001545]
	Learning Rate: 0.000154498
	LOSS [training: 0.004826985604521533 | validation: -0.006255762955850697]
	TIME [epoch: 6.52 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.006743797499692862		[learning rate: 0.00015413]
	Learning Rate: 0.000154134
	LOSS [training: 0.006743797499692862 | validation: -0.001824424932892631]
	TIME [epoch: 6.53 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.008534740338640937		[learning rate: 0.00015377]
	Learning Rate: 0.00015377
	LOSS [training: 0.008534740338640937 | validation: -0.0008504513170390286]
	TIME [epoch: 6.53 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.007165670947928822		[learning rate: 0.00015341]
	Learning Rate: 0.000153407
	LOSS [training: 0.007165670947928822 | validation: -0.006819225438515807]
	TIME [epoch: 6.5 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.007614108613294266		[learning rate: 0.00015305]
	Learning Rate: 0.000153045
	LOSS [training: 0.007614108613294266 | validation: 0.004745182390014743]
	TIME [epoch: 6.5 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012594690698303426		[learning rate: 0.00015268]
	Learning Rate: 0.000152684
	LOSS [training: 0.012594690698303426 | validation: 0.008721574825952483]
	TIME [epoch: 6.51 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.00983668691888002		[learning rate: 0.00015232]
	Learning Rate: 0.000152324
	LOSS [training: 0.00983668691888002 | validation: -0.0016409205284673937]
	TIME [epoch: 6.5 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.007075868960121086		[learning rate: 0.00015196]
	Learning Rate: 0.000151965
	LOSS [training: 0.007075868960121086 | validation: -0.006412595384725878]
	TIME [epoch: 6.49 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.004262650772935607		[learning rate: 0.00015161]
	Learning Rate: 0.000151607
	LOSS [training: 0.004262650772935607 | validation: -0.004580756177758448]
	TIME [epoch: 6.52 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.006469876704758076		[learning rate: 0.00015125]
	Learning Rate: 0.000151249
	LOSS [training: 0.006469876704758076 | validation: -0.00405095553697585]
	TIME [epoch: 6.49 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0071965470242681875		[learning rate: 0.00015089]
	Learning Rate: 0.000150892
	LOSS [training: 0.0071965470242681875 | validation: -0.006947635583590201]
	TIME [epoch: 6.49 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.004142592762204354		[learning rate: 0.00015054]
	Learning Rate: 0.000150536
	LOSS [training: 0.004142592762204354 | validation: -0.004073898925875534]
	TIME [epoch: 6.51 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.005325088080056366		[learning rate: 0.00015018]
	Learning Rate: 0.000150181
	LOSS [training: 0.005325088080056366 | validation: -0.005528879724064889]
	TIME [epoch: 6.52 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.005666346245528188		[learning rate: 0.00014983]
	Learning Rate: 0.000149827
	LOSS [training: 0.005666346245528188 | validation: -0.004182317775184181]
	TIME [epoch: 6.51 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.008119572879967032		[learning rate: 0.00014947]
	Learning Rate: 0.000149473
	LOSS [training: 0.008119572879967032 | validation: -0.007071134531272027]
	TIME [epoch: 6.56 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009566290995332957		[learning rate: 0.00014912]
	Learning Rate: 0.000149121
	LOSS [training: 0.009566290995332957 | validation: -0.002341957741911701]
	TIME [epoch: 6.5 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01153387510247788		[learning rate: 0.00014877]
	Learning Rate: 0.000148769
	LOSS [training: 0.01153387510247788 | validation: -0.00877037968356414]
	TIME [epoch: 6.52 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017736323140956627		[learning rate: 0.00014842]
	Learning Rate: 0.000148418
	LOSS [training: 0.017736323140956627 | validation: -0.0008196826604054738]
	TIME [epoch: 6.5 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0276580449815367		[learning rate: 0.00014807]
	Learning Rate: 0.000148068
	LOSS [training: 0.0276580449815367 | validation: 0.027022813380871986]
	TIME [epoch: 6.5 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061033957234612336		[learning rate: 0.00014772]
	Learning Rate: 0.000147719
	LOSS [training: 0.061033957234612336 | validation: 0.01642506191572828]
	TIME [epoch: 6.52 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03788178997794114		[learning rate: 0.00014737]
	Learning Rate: 0.00014737
	LOSS [training: 0.03788178997794114 | validation: 0.004949586102393569]
	TIME [epoch: 6.52 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012986133839358576		[learning rate: 0.00014702]
	Learning Rate: 0.000147023
	LOSS [training: 0.012986133839358576 | validation: -0.004171564844427034]
	TIME [epoch: 6.5 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017011541432073236		[learning rate: 0.00014668]
	Learning Rate: 0.000146676
	LOSS [training: 0.017011541432073236 | validation: -0.00373993294481345]
	TIME [epoch: 6.52 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.006324842332100124		[learning rate: 0.00014633]
	Learning Rate: 0.00014633
	LOSS [training: 0.006324842332100124 | validation: -0.0005152737571423663]
	TIME [epoch: 6.5 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.004262920710215351		[learning rate: 0.00014598]
	Learning Rate: 0.000145985
	LOSS [training: 0.004262920710215351 | validation: -0.005872597956000565]
	TIME [epoch: 6.5 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.006131871534659193		[learning rate: 0.00014564]
	Learning Rate: 0.00014564
	LOSS [training: 0.006131871534659193 | validation: -0.00448411037409209]
	TIME [epoch: 6.54 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0058832955002060885		[learning rate: 0.0001453]
	Learning Rate: 0.000145297
	LOSS [training: 0.0058832955002060885 | validation: -0.002955809222861783]
	TIME [epoch: 6.51 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0075758933354529365		[learning rate: 0.00014495]
	Learning Rate: 0.000144954
	LOSS [training: 0.0075758933354529365 | validation: -0.004814304729108302]
	TIME [epoch: 6.5 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.007080196096941582		[learning rate: 0.00014461]
	Learning Rate: 0.000144612
	LOSS [training: 0.007080196096941582 | validation: -0.004949147714975429]
	TIME [epoch: 6.5 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.006200319123869851		[learning rate: 0.00014427]
	Learning Rate: 0.000144271
	LOSS [training: 0.006200319123869851 | validation: -0.003971056256602563]
	TIME [epoch: 6.51 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.007770572942926976		[learning rate: 0.00014393]
	Learning Rate: 0.000143931
	LOSS [training: 0.007770572942926976 | validation: -0.015026752095071776]
	TIME [epoch: 6.53 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_1846.pth
	Model improved!!!
EPOCH 1847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010386007855711527		[learning rate: 0.00014359]
	Learning Rate: 0.000143591
	LOSS [training: 0.010386007855711527 | validation: -0.004704881697638487]
	TIME [epoch: 6.58 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015775594057454184		[learning rate: 0.00014325]
	Learning Rate: 0.000143253
	LOSS [training: 0.015775594057454184 | validation: 0.002704086262712009]
	TIME [epoch: 6.53 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029103111979079506		[learning rate: 0.00014291]
	Learning Rate: 0.000142915
	LOSS [training: 0.029103111979079506 | validation: 0.007952966202242527]
	TIME [epoch: 6.53 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022726420229241297		[learning rate: 0.00014258]
	Learning Rate: 0.000142578
	LOSS [training: 0.022726420229241297 | validation: -0.0002801278639916159]
	TIME [epoch: 6.53 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013863611185298932		[learning rate: 0.00014224]
	Learning Rate: 0.000142241
	LOSS [training: 0.013863611185298932 | validation: 0.0013035673527917648]
	TIME [epoch: 6.53 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010113408855651363		[learning rate: 0.00014191]
	Learning Rate: 0.000141906
	LOSS [training: 0.010113408855651363 | validation: 0.004296910211753929]
	TIME [epoch: 6.55 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01262124561038111		[learning rate: 0.00014157]
	Learning Rate: 0.000141571
	LOSS [training: 0.01262124561038111 | validation: -0.002825552106023083]
	TIME [epoch: 6.55 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009291818479335653		[learning rate: 0.00014124]
	Learning Rate: 0.000141237
	LOSS [training: 0.009291818479335653 | validation: -0.005067294136186389]
	TIME [epoch: 6.53 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0054171272773565204		[learning rate: 0.0001409]
	Learning Rate: 0.000140904
	LOSS [training: 0.0054171272773565204 | validation: -0.0074101575420074724]
	TIME [epoch: 6.53 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011102229823863644		[learning rate: 0.00014057]
	Learning Rate: 0.000140572
	LOSS [training: 0.011102229823863644 | validation: 0.0011454281009819827]
	TIME [epoch: 6.55 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.003936581711182678		[learning rate: 0.00014024]
	Learning Rate: 0.00014024
	LOSS [training: 0.003936581711182678 | validation: -0.002216237513468435]
	TIME [epoch: 6.53 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016997714084743563		[learning rate: 0.00013991]
	Learning Rate: 0.000139909
	LOSS [training: 0.016997714084743563 | validation: -0.0006622940131201186]
	TIME [epoch: 6.54 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018518780285921514		[learning rate: 0.00013958]
	Learning Rate: 0.000139579
	LOSS [training: 0.018518780285921514 | validation: -0.0032777217536291885]
	TIME [epoch: 6.56 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025417531936146202		[learning rate: 0.00013925]
	Learning Rate: 0.00013925
	LOSS [training: 0.025417531936146202 | validation: 0.02226694021679186]
	TIME [epoch: 6.53 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0509897603640689		[learning rate: 0.00013892]
	Learning Rate: 0.000138921
	LOSS [training: 0.0509897603640689 | validation: 0.02620676642730168]
	TIME [epoch: 6.53 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05012271592084509		[learning rate: 0.00013859]
	Learning Rate: 0.000138594
	LOSS [training: 0.05012271592084509 | validation: 0.000771765693096985]
	TIME [epoch: 6.53 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014252627844949798		[learning rate: 0.00013827]
	Learning Rate: 0.000138267
	LOSS [training: 0.014252627844949798 | validation: 0.0013548024207325968]
	TIME [epoch: 6.52 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.006805781194155353		[learning rate: 0.00013794]
	Learning Rate: 0.000137941
	LOSS [training: 0.006805781194155353 | validation: -0.000441970783742111]
	TIME [epoch: 6.55 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.006626575116306242		[learning rate: 0.00013762]
	Learning Rate: 0.000137615
	LOSS [training: 0.006626575116306242 | validation: -0.006141190085305754]
	TIME [epoch: 6.52 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.005774295464115992		[learning rate: 0.00013729]
	Learning Rate: 0.000137291
	LOSS [training: 0.005774295464115992 | validation: -0.008133453486071536]
	TIME [epoch: 6.53 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.005006281497502764		[learning rate: 0.00013697]
	Learning Rate: 0.000136967
	LOSS [training: 0.005006281497502764 | validation: -0.0077886373394158975]
	TIME [epoch: 6.53 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0050275797159335025		[learning rate: 0.00013664]
	Learning Rate: 0.000136644
	LOSS [training: 0.0050275797159335025 | validation: -0.001465770887998717]
	TIME [epoch: 6.53 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02235255821452118		[learning rate: 0.00013632]
	Learning Rate: 0.000136321
	LOSS [training: 0.02235255821452118 | validation: 0.01073205533807509]
	TIME [epoch: 6.53 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029044849844136533		[learning rate: 0.000136]
	Learning Rate: 0.000136
	LOSS [training: 0.029044849844136533 | validation: 0.0032654403853068434]
	TIME [epoch: 6.57 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01784772478783936		[learning rate: 0.00013568]
	Learning Rate: 0.000135679
	LOSS [training: 0.01784772478783936 | validation: 0.006004736696854134]
	TIME [epoch: 6.53 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025598208288886017		[learning rate: 0.00013536]
	Learning Rate: 0.000135359
	LOSS [training: 0.025598208288886017 | validation: 0.0068796147725560305]
	TIME [epoch: 6.53 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015184895445285807		[learning rate: 0.00013504]
	Learning Rate: 0.00013504
	LOSS [training: 0.015184895445285807 | validation: -0.006632157561563431]
	TIME [epoch: 6.52 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011547686268993159		[learning rate: 0.00013472]
	Learning Rate: 0.000134721
	LOSS [training: 0.011547686268993159 | validation: 0.00610300999224324]
	TIME [epoch: 6.52 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010157651474929422		[learning rate: 0.0001344]
	Learning Rate: 0.000134403
	LOSS [training: 0.010157651474929422 | validation: 0.002756583463851557]
	TIME [epoch: 6.54 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.008736377487010349		[learning rate: 0.00013409]
	Learning Rate: 0.000134086
	LOSS [training: 0.008736377487010349 | validation: -0.005176685567708797]
	TIME [epoch: 6.56 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.006215243522083027		[learning rate: 0.00013377]
	Learning Rate: 0.00013377
	LOSS [training: 0.006215243522083027 | validation: -0.017054732712355768]
	TIME [epoch: 6.52 sec]
	Saving model to: out/model_training/model_phi2_1a_v2_20240226_171542/states/model_phi2_1a_v2_1877.pth
	Model improved!!!
EPOCH 1878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0033330811997653214		[learning rate: 0.00013345]
	Learning Rate: 0.000133455
	LOSS [training: 0.0033330811997653214 | validation: -0.004753805097025009]
	TIME [epoch: 6.53 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.008047947097315294		[learning rate: 0.00013314]
	Learning Rate: 0.00013314
	LOSS [training: 0.008047947097315294 | validation: -0.010536039776012002]
	TIME [epoch: 6.52 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009403055135391738		[learning rate: 0.00013283]
	Learning Rate: 0.000132826
	LOSS [training: 0.009403055135391738 | validation: 0.0003518797621966628]
	TIME [epoch: 6.53 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.00983943895358479		[learning rate: 0.00013251]
	Learning Rate: 0.000132512
	LOSS [training: 0.00983943895358479 | validation: -0.0022189556661426366]
	TIME [epoch: 6.56 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010100134560132177		[learning rate: 0.0001322]
	Learning Rate: 0.0001322
	LOSS [training: 0.010100134560132177 | validation: 0.0022146258532239876]
	TIME [epoch: 6.54 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01225635282226		[learning rate: 0.00013189]
	Learning Rate: 0.000131888
	LOSS [training: 0.01225635282226 | validation: -0.000439168658787085]
	TIME [epoch: 6.52 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.007602221907327322		[learning rate: 0.00013158]
	Learning Rate: 0.000131577
	LOSS [training: 0.007602221907327322 | validation: -0.006798002950985269]
	TIME [epoch: 6.52 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.007204953086024668		[learning rate: 0.00013127]
	Learning Rate: 0.000131266
	LOSS [training: 0.007204953086024668 | validation: -0.00902946872945088]
	TIME [epoch: 6.53 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.00479908230484883		[learning rate: 0.00013096]
	Learning Rate: 0.000130957
	LOSS [training: 0.00479908230484883 | validation: -0.000668201016356419]
	TIME [epoch: 6.54 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010900698110626167		[learning rate: 0.00013065]
	Learning Rate: 0.000130648
	LOSS [training: 0.010900698110626167 | validation: -0.004397843987537533]
	TIME [epoch: 6.57 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.006534102740833013		[learning rate: 0.00013034]
	Learning Rate: 0.00013034
	LOSS [training: 0.006534102740833013 | validation: 0.008655152198980292]
	TIME [epoch: 6.53 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01138605815504834		[learning rate: 0.00013003]
	Learning Rate: 0.000130032
	LOSS [training: 0.01138605815504834 | validation: 0.0040494368006655295]
	TIME [epoch: 6.52 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01307350525971678		[learning rate: 0.00012973]
	Learning Rate: 0.000129726
	LOSS [training: 0.01307350525971678 | validation: 0.005177767714976448]
	TIME [epoch: 6.53 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010855771324670303		[learning rate: 0.00012942]
	Learning Rate: 0.00012942
	LOSS [training: 0.010855771324670303 | validation: 0.006086452776782096]
	TIME [epoch: 6.52 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013727295511908216		[learning rate: 0.00012911]
	Learning Rate: 0.000129114
	LOSS [training: 0.013727295511908216 | validation: -0.002680656649100793]
	TIME [epoch: 6.53 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015964655719096783		[learning rate: 0.00012881]
	Learning Rate: 0.00012881
	LOSS [training: 0.015964655719096783 | validation: -0.0021504588105320573]
	TIME [epoch: 6.56 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009264597780202036		[learning rate: 0.00012851]
	Learning Rate: 0.000128506
	LOSS [training: 0.009264597780202036 | validation: 0.004990692404961781]
	TIME [epoch: 6.53 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013122149178528303		[learning rate: 0.0001282]
	Learning Rate: 0.000128203
	LOSS [training: 0.013122149178528303 | validation: 0.0015222867217283874]
	TIME [epoch: 6.52 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011101990860697658		[learning rate: 0.0001279]
	Learning Rate: 0.0001279
	LOSS [training: 0.011101990860697658 | validation: -0.004212105566819809]
	TIME [epoch: 6.52 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009221027588989352		[learning rate: 0.0001276]
	Learning Rate: 0.000127599
	LOSS [training: 0.009221027588989352 | validation: 0.0007651778607948986]
	TIME [epoch: 6.52 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011638144837589038		[learning rate: 0.0001273]
	Learning Rate: 0.000127298
	LOSS [training: 0.011638144837589038 | validation: 0.006566998644134088]
	TIME [epoch: 6.54 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014823156127132633		[learning rate: 0.000127]
	Learning Rate: 0.000126997
	LOSS [training: 0.014823156127132633 | validation: 0.0016135423227658105]
	TIME [epoch: 6.56 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012807707922792885		[learning rate: 0.0001267]
	Learning Rate: 0.000126698
	LOSS [training: 0.012807707922792885 | validation: 0.007485151722997588]
	TIME [epoch: 6.52 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01811484407900022		[learning rate: 0.0001264]
	Learning Rate: 0.000126399
	LOSS [training: 0.01811484407900022 | validation: 0.0049424408314067995]
	TIME [epoch: 6.52 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014455655970046116		[learning rate: 0.0001261]
	Learning Rate: 0.000126101
	LOSS [training: 0.014455655970046116 | validation: 0.0050235380029003355]
	TIME [epoch: 6.52 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01477916145945391		[learning rate: 0.0001258]
	Learning Rate: 0.000125803
	LOSS [training: 0.01477916145945391 | validation: 0.006235806831864879]
	TIME [epoch: 6.52 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017201037442537877		[learning rate: 0.00012551]
	Learning Rate: 0.000125507
	LOSS [training: 0.017201037442537877 | validation: 0.001708978057654938]
	TIME [epoch: 6.55 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017995290536548775		[learning rate: 0.00012521]
	Learning Rate: 0.000125211
	LOSS [training: 0.017995290536548775 | validation: 0.0024371507453298177]
	TIME [epoch: 6.54 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019743517193061035		[learning rate: 0.00012492]
	Learning Rate: 0.000124915
	LOSS [training: 0.019743517193061035 | validation: 0.005967742932711308]
	TIME [epoch: 6.52 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.020385193195217137		[learning rate: 0.00012462]
	Learning Rate: 0.000124621
	LOSS [training: 0.020385193195217137 | validation: 0.006664321970610535]
	TIME [epoch: 6.52 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01830025835129017		[learning rate: 0.00012433]
	Learning Rate: 0.000124327
	LOSS [training: 0.01830025835129017 | validation: 0.018351119555287308]
	TIME [epoch: 6.52 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.020661478498835435		[learning rate: 0.00012403]
	Learning Rate: 0.000124033
	LOSS [training: 0.020661478498835435 | validation: 0.005596525942371832]
	TIME [epoch: 6.52 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019112410614348978		[learning rate: 0.00012374]
	Learning Rate: 0.000123741
	LOSS [training: 0.019112410614348978 | validation: 0.010851959421508567]
	TIME [epoch: 6.56 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015503709128094765		[learning rate: 0.00012345]
	Learning Rate: 0.000123449
	LOSS [training: 0.015503709128094765 | validation: 0.0063542130757276525]
	TIME [epoch: 6.52 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017444123810884317		[learning rate: 0.00012316]
	Learning Rate: 0.000123158
	LOSS [training: 0.017444123810884317 | validation: 0.008539001566239064]
	TIME [epoch: 6.52 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01758964056702041		[learning rate: 0.00012287]
	Learning Rate: 0.000122867
	LOSS [training: 0.01758964056702041 | validation: 0.006104243398482641]
	TIME [epoch: 6.52 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017175384121126687		[learning rate: 0.00012258]
	Learning Rate: 0.000122577
	LOSS [training: 0.017175384121126687 | validation: 0.00944082568796334]
	TIME [epoch: 6.52 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021538378111984134		[learning rate: 0.00012229]
	Learning Rate: 0.000122288
	LOSS [training: 0.021538378111984134 | validation: 0.011076879534458102]
	TIME [epoch: 6.53 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02733951229644882		[learning rate: 0.000122]
	Learning Rate: 0.000122
	LOSS [training: 0.02733951229644882 | validation: 0.007228470627010819]
	TIME [epoch: 6.56 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0265416020527809		[learning rate: 0.00012171]
	Learning Rate: 0.000121712
	LOSS [training: 0.0265416020527809 | validation: 0.004079643958393557]
	TIME [epoch: 6.52 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016722742899930303		[learning rate: 0.00012142]
	Learning Rate: 0.000121425
	LOSS [training: 0.016722742899930303 | validation: 0.007355547917154036]
	TIME [epoch: 6.51 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018594304995228544		[learning rate: 0.00012114]
	Learning Rate: 0.000121138
	LOSS [training: 0.018594304995228544 | validation: 0.005171334856655633]
	TIME [epoch: 6.5 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018678279618685623		[learning rate: 0.00012085]
	Learning Rate: 0.000120853
	LOSS [training: 0.018678279618685623 | validation: 0.006346605971251075]
	TIME [epoch: 6.52 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02020716090479164		[learning rate: 0.00012057]
	Learning Rate: 0.000120568
	LOSS [training: 0.02020716090479164 | validation: 0.003911311269953791]
	TIME [epoch: 6.55 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02202959725160047		[learning rate: 0.00012028]
	Learning Rate: 0.000120283
	LOSS [training: 0.02202959725160047 | validation: 0.011943110527557777]
	TIME [epoch: 6.54 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027217159301666422		[learning rate: 0.00012]
	Learning Rate: 0.00012
	LOSS [training: 0.027217159301666422 | validation: 0.01872786381106431]
	TIME [epoch: 6.52 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023213117261130796		[learning rate: 0.00011972]
	Learning Rate: 0.000119716
	LOSS [training: 0.023213117261130796 | validation: 0.00889387612317956]
	TIME [epoch: 6.52 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02198072851063261		[learning rate: 0.00011943]
	Learning Rate: 0.000119434
	LOSS [training: 0.02198072851063261 | validation: 0.005018559040543739]
	TIME [epoch: 6.52 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019875425288099262		[learning rate: 0.00011915]
	Learning Rate: 0.000119152
	LOSS [training: 0.019875425288099262 | validation: 0.003984696383578615]
	TIME [epoch: 6.52 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015804713990475984		[learning rate: 0.00011887]
	Learning Rate: 0.000118871
	LOSS [training: 0.015804713990475984 | validation: 0.00018571506788273105]
	TIME [epoch: 6.57 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01812380280453695		[learning rate: 0.00011859]
	Learning Rate: 0.000118591
	LOSS [training: 0.01812380280453695 | validation: 0.006588787989623687]
	TIME [epoch: 6.53 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018926791367315073		[learning rate: 0.00011831]
	Learning Rate: 0.000118311
	LOSS [training: 0.018926791367315073 | validation: 0.005952668562064147]
	TIME [epoch: 6.52 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015156847173888627		[learning rate: 0.00011803]
	Learning Rate: 0.000118032
	LOSS [training: 0.015156847173888627 | validation: 0.00795598533458859]
	TIME [epoch: 6.52 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015191834965014753		[learning rate: 0.00011775]
	Learning Rate: 0.000117754
	LOSS [training: 0.015191834965014753 | validation: 0.006986745313607313]
	TIME [epoch: 6.52 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019704862825143204		[learning rate: 0.00011748]
	Learning Rate: 0.000117476
	LOSS [training: 0.019704862825143204 | validation: 0.009012799209840286]
	TIME [epoch: 6.53 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026591383276576668		[learning rate: 0.0001172]
	Learning Rate: 0.000117199
	LOSS [training: 0.026591383276576668 | validation: 0.006960514084979695]
	TIME [epoch: 6.55 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02423062981030192		[learning rate: 0.00011692]
	Learning Rate: 0.000116922
	LOSS [training: 0.02423062981030192 | validation: 0.008668105646092777]
	TIME [epoch: 6.53 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024951594513064244		[learning rate: 0.00011665]
	Learning Rate: 0.000116647
	LOSS [training: 0.024951594513064244 | validation: 0.016422043546686815]
	TIME [epoch: 6.52 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027504693348114496		[learning rate: 0.00011637]
	Learning Rate: 0.000116371
	LOSS [training: 0.027504693348114496 | validation: 0.018582195132550584]
	TIME [epoch: 6.52 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022395543042336236		[learning rate: 0.0001161]
	Learning Rate: 0.000116097
	LOSS [training: 0.022395543042336236 | validation: 0.0042664435904724955]
	TIME [epoch: 6.52 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015626831020852123		[learning rate: 0.00011582]
	Learning Rate: 0.000115823
	LOSS [training: 0.015626831020852123 | validation: 0.008719374301322568]
	TIME [epoch: 6.55 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016101488416833398		[learning rate: 0.00011555]
	Learning Rate: 0.00011555
	LOSS [training: 0.016101488416833398 | validation: 0.00336979785535232]
	TIME [epoch: 6.54 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.019490732796441777		[learning rate: 0.00011528]
	Learning Rate: 0.000115277
	LOSS [training: 0.019490732796441777 | validation: 0.010301413356799596]
	TIME [epoch: 6.52 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017200413497872564		[learning rate: 0.00011501]
	Learning Rate: 0.000115005
	LOSS [training: 0.017200413497872564 | validation: 0.002722598597377478]
	TIME [epoch: 6.52 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.011108474748896487		[learning rate: 0.00011473]
	Learning Rate: 0.000114734
	LOSS [training: 0.011108474748896487 | validation: -0.0005435057673256857]
	TIME [epoch: 6.52 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009112779563614549		[learning rate: 0.00011446]
	Learning Rate: 0.000114463
	LOSS [training: 0.009112779563614549 | validation: 0.0014987581457609278]
	TIME [epoch: 6.52 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.008719463039210309		[learning rate: 0.00011419]
	Learning Rate: 0.000114193
	LOSS [training: 0.008719463039210309 | validation: -0.00898609497871489]
	TIME [epoch: 6.56 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0075931110418096985		[learning rate: 0.00011392]
	Learning Rate: 0.000113924
	LOSS [training: 0.0075931110418096985 | validation: 0.001019083626166488]
	TIME [epoch: 6.52 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.008132056834377975		[learning rate: 0.00011366]
	Learning Rate: 0.000113655
	LOSS [training: 0.008132056834377975 | validation: -0.00038794038077289046]
	TIME [epoch: 6.52 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.005728053763337675		[learning rate: 0.00011339]
	Learning Rate: 0.000113387
	LOSS [training: 0.005728053763337675 | validation: -0.008341565779252411]
	TIME [epoch: 6.52 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.004674902084148372		[learning rate: 0.00011312]
	Learning Rate: 0.00011312
	LOSS [training: 0.004674902084148372 | validation: -0.004743822912509576]
	TIME [epoch: 6.52 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.007437093023611774		[learning rate: 0.00011285]
	Learning Rate: 0.000112853
	LOSS [training: 0.007437093023611774 | validation: -0.004016004541235678]
	TIME [epoch: 6.53 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01047373165073135		[learning rate: 0.00011259]
	Learning Rate: 0.000112587
	LOSS [training: 0.01047373165073135 | validation: -0.006637074052262066]
	TIME [epoch: 6.56 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.008283664959363788		[learning rate: 0.00011232]
	Learning Rate: 0.000112321
	LOSS [training: 0.008283664959363788 | validation: -0.006209795681749398]
	TIME [epoch: 6.53 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.00957399464022254		[learning rate: 0.00011206]
	Learning Rate: 0.000112056
	LOSS [training: 0.00957399464022254 | validation: -0.004247870417900677]
	TIME [epoch: 6.52 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.00840306494592651		[learning rate: 0.00011179]
	Learning Rate: 0.000111792
	LOSS [training: 0.00840306494592651 | validation: 0.001273458885787701]
	TIME [epoch: 6.52 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009719244980712432		[learning rate: 0.00011153]
	Learning Rate: 0.000111528
	LOSS [training: 0.009719244980712432 | validation: 0.0026112359456791565]
	TIME [epoch: 6.52 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0076087595599440335		[learning rate: 0.00011127]
	Learning Rate: 0.000111265
	LOSS [training: 0.0076087595599440335 | validation: -0.003708801714432307]
	TIME [epoch: 6.55 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.007564733251274144		[learning rate: 0.000111]
	Learning Rate: 0.000111003
	LOSS [training: 0.007564733251274144 | validation: -0.011672204192543629]
	TIME [epoch: 6.54 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0032205922430613224		[learning rate: 0.00011074]
	Learning Rate: 0.000110741
	LOSS [training: 0.0032205922430613224 | validation: -0.009037613223166202]
	TIME [epoch: 6.52 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0029162075524592082		[learning rate: 0.00011048]
	Learning Rate: 0.00011048
	LOSS [training: 0.0029162075524592082 | validation: -0.013647380751217271]
	TIME [epoch: 6.53 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0069694312340856475		[learning rate: 0.00011022]
	Learning Rate: 0.000110219
	LOSS [training: 0.0069694312340856475 | validation: -0.0039948733791930315]
	TIME [epoch: 6.52 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.003296861150133653		[learning rate: 0.00010996]
	Learning Rate: 0.000109959
	LOSS [training: 0.003296861150133653 | validation: -0.006632639089874408]
	TIME [epoch: 6.53 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0047170028649015485		[learning rate: 0.0001097]
	Learning Rate: 0.0001097
	LOSS [training: 0.0047170028649015485 | validation: -0.012162532076182358]
	TIME [epoch: 6.56 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0023793404918996835		[learning rate: 0.00010944]
	Learning Rate: 0.000109441
	LOSS [training: 0.0023793404918996835 | validation: -0.01172868669179209]
	TIME [epoch: 6.53 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.00597076665677579		[learning rate: 0.00010918]
	Learning Rate: 0.000109183
	LOSS [training: 0.00597076665677579 | validation: -0.011226136402317413]
	TIME [epoch: 6.53 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.009529337032207538		[learning rate: 0.00010893]
	Learning Rate: 0.000108925
	LOSS [training: 0.009529337032207538 | validation: -0.0030762447642228396]
	TIME [epoch: 6.53 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012562167210498182		[learning rate: 0.00010867]
	Learning Rate: 0.000108668
	LOSS [training: 0.012562167210498182 | validation: 0.008160861558925913]
	TIME [epoch: 6.53 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02701871869817085		[learning rate: 0.00010841]
	Learning Rate: 0.000108412
	LOSS [training: 0.02701871869817085 | validation: 0.010664679324527521]
	TIME [epoch: 6.54 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028421937505128846		[learning rate: 0.00010816]
	Learning Rate: 0.000108156
	LOSS [training: 0.028421937505128846 | validation: 0.008041774967169398]
	TIME [epoch: 6.56 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024417816594935724		[learning rate: 0.0001079]
	Learning Rate: 0.000107901
	LOSS [training: 0.024417816594935724 | validation: 0.009542809120982324]
	TIME [epoch: 6.53 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02248724506290275		[learning rate: 0.00010765]
	Learning Rate: 0.000107647
	LOSS [training: 0.02248724506290275 | validation: -0.0035639982299491097]
	TIME [epoch: 6.53 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.008627669981136734		[learning rate: 0.00010739]
	Learning Rate: 0.000107393
	LOSS [training: 0.008627669981136734 | validation: 0.0007953132149241459]
	TIME [epoch: 6.53 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.004311208855481971		[learning rate: 0.00010714]
	Learning Rate: 0.000107139
	LOSS [training: 0.004311208855481971 | validation: -0.004844513661470285]
	TIME [epoch: 6.52 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.004597600408941111		[learning rate: 0.00010689]
	Learning Rate: 0.000106887
	LOSS [training: 0.004597600408941111 | validation: -0.003777142640973927]
	TIME [epoch: 6.55 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.005361526223943861		[learning rate: 0.00010663]
	Learning Rate: 0.000106634
	LOSS [training: 0.005361526223943861 | validation: -0.013905824511833675]
	TIME [epoch: 6.52 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0030768643044797976		[learning rate: 0.00010638]
	Learning Rate: 0.000106383
	LOSS [training: 0.0030768643044797976 | validation: -0.014408114728478241]
	TIME [epoch: 6.51 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.003667192307635136		[learning rate: 0.00010613]
	Learning Rate: 0.000106132
	LOSS [training: 0.003667192307635136 | validation: -0.006155906187994663]
	TIME [epoch: 6.52 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.004410467862442202		[learning rate: 0.00010588]
	Learning Rate: 0.000105882
	LOSS [training: 0.004410467862442202 | validation: -0.005691702134791688]
	TIME [epoch: 6.52 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.001742510746504671		[learning rate: 0.00010563]
	Learning Rate: 0.000105632
	LOSS [training: 0.001742510746504671 | validation: -0.013890565415720958]
	TIME [epoch: 6.52 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.005266422780504048		[learning rate: 0.00010538]
	Learning Rate: 0.000105383
	LOSS [training: 0.005266422780504048 | validation: -0.0039902569833980385]
	TIME [epoch: 6.56 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0012696314149603558		[learning rate: 0.00010513]
	Learning Rate: 0.000105134
	LOSS [training: 0.0012696314149603558 | validation: -0.01116331097843004]
	TIME [epoch: 6.54 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0026655233703036458		[learning rate: 0.00010489]
	Learning Rate: 0.000104886
	LOSS [training: 0.0026655233703036458 | validation: -0.0004618202324485326]
	TIME [epoch: 6.53 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.002734214178067963		[learning rate: 0.00010464]
	Learning Rate: 0.000104639
	LOSS [training: 0.002734214178067963 | validation: -0.004086361958880756]
	TIME [epoch: 6.52 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.004652679460656946		[learning rate: 0.00010439]
	Learning Rate: 0.000104392
	LOSS [training: 0.004652679460656946 | validation: -0.0007878683818324708]
	TIME [epoch: 6.53 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.007341658742730875		[learning rate: 0.00010415]
	Learning Rate: 0.000104146
	LOSS [training: 0.007341658742730875 | validation: 0.006072484250919814]
	TIME [epoch: 6.53 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.006756180933859095		[learning rate: 0.0001039]
	Learning Rate: 0.0001039
	LOSS [training: 0.006756180933859095 | validation: -0.00442655308429329]
	TIME [epoch: 6.57 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.004036659810970868		[learning rate: 0.00010365]
	Learning Rate: 0.000103655
	LOSS [training: 0.004036659810970868 | validation: -0.0017433574106543248]
	TIME [epoch: 6.53 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0045759161290864		[learning rate: 0.00010341]
	Learning Rate: 0.00010341
	LOSS [training: 0.0045759161290864 | validation: -0.0032958373223768898]
	TIME [epoch: 6.53 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.00455187800332921		[learning rate: 0.00010317]
	Learning Rate: 0.000103166
	LOSS [training: 0.00455187800332921 | validation: -0.006465321878435761]
	TIME [epoch: 6.52 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.007158321593681183		[learning rate: 0.00010292]
	Learning Rate: 0.000102923
	LOSS [training: 0.007158321593681183 | validation: -0.00419532180267534]
	TIME [epoch: 6.52 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01042115251691158		[learning rate: 0.00010268]
	Learning Rate: 0.00010268
	LOSS [training: 0.01042115251691158 | validation: -0.00839163530847796]
	TIME [epoch: 6.54 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.008512993302271274		[learning rate: 0.00010244]
	Learning Rate: 0.000102438
	LOSS [training: 0.008512993302271274 | validation: -0.004104017349260365]
	TIME [epoch: 6.55 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010433952435826057		[learning rate: 0.0001022]
	Learning Rate: 0.000102196
	LOSS [training: 0.010433952435826057 | validation: -0.001517913538807156]
	TIME [epoch: 6.52 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.008586958974221098		[learning rate: 0.00010196]
	Learning Rate: 0.000101955
	LOSS [training: 0.008586958974221098 | validation: 0.003955851849535371]
	TIME [epoch: 6.52 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012006916845907042		[learning rate: 0.00010171]
	Learning Rate: 0.000101715
	LOSS [training: 0.012006916845907042 | validation: -0.0019327655749964128]
	TIME [epoch: 6.52 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.012743315573407927		[learning rate: 0.00010147]
	Learning Rate: 0.000101475
	LOSS [training: 0.012743315573407927 | validation: -0.00014021263708721698]
	TIME [epoch: 6.53 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013202764404838774		[learning rate: 0.00010124]
	Learning Rate: 0.000101236
	LOSS [training: 0.013202764404838774 | validation: 0.0022382526316534392]
	TIME [epoch: 6.56 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01662154268103281		[learning rate: 0.000101]
	Learning Rate: 0.000100997
	LOSS [training: 0.01662154268103281 | validation: 0.005423497727250697]
	TIME [epoch: 6.53 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014854295702068606		[learning rate: 0.00010076]
	Learning Rate: 0.000100759
	LOSS [training: 0.014854295702068606 | validation: 0.003313422221565546]
	TIME [epoch: 6.52 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.010390822387146923		[learning rate: 0.00010052]
	Learning Rate: 0.000100521
	LOSS [training: 0.010390822387146923 | validation: 0.0021500769088372606]
	TIME [epoch: 6.52 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.015370352870090443		[learning rate: 0.00010028]
	Learning Rate: 0.000100284
	LOSS [training: 0.015370352870090443 | validation: 0.0019916051053200544]
	TIME [epoch: 6.52 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.016726865266862498		[learning rate: 0.00010005]
	Learning Rate: 0.000100047
	LOSS [training: 0.016726865266862498 | validation: 0.008147215026319564]
	TIME [epoch: 6.54 sec]
Finished training in 13346.368 seconds.
