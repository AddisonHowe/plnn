Args:
Namespace(name='model_facs_dec1b_2dnmf_v1', outdir='out/model_training/model_facs_dec1b_2dnmf_v1', training_data='data/training_data/facs/nmf/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs/nmf/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=5, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.001, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2370712493

Training model...

Saving initial model state to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.6704424534615145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6704424534615145 | validation: 1.4424199246731355]
	TIME [epoch: 60.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.6244015337069662		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6244015337069662 | validation: 1.3177484644635782]
	TIME [epoch: 35.3 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0332583253932635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0332583253932635 | validation: 1.1639826212249085]
	TIME [epoch: 35.3 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9949268635986763		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9949268635986763 | validation: 0.7500658144396862]
	TIME [epoch: 35.3 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7445508424323352		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7445508424323352 | validation: 0.6075941949097279]
	TIME [epoch: 35.4 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6042712051210782		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6042712051210782 | validation: 0.5755894323801245]
	TIME [epoch: 35.4 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43117458028120953		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43117458028120953 | validation: 0.5840538272802774]
	TIME [epoch: 35.4 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3180345850284678		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3180345850284678 | validation: 0.6852036979837691]
	TIME [epoch: 35.4 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26535675607503045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26535675607503045 | validation: 0.19604084878943648]
	TIME [epoch: 35.4 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16956121635256735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16956121635256735 | validation: 0.2043488079866635]
	TIME [epoch: 35.4 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13466834252825163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13466834252825163 | validation: 0.09698878568163631]
	TIME [epoch: 35.4 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.07614013156725688		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07614013156725688 | validation: 0.048318128230841126]
	TIME [epoch: 35.3 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.04060975391173221		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04060975391173221 | validation: 0.030855375688028257]
	TIME [epoch: 35.3 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.027038983270648777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.027038983270648777 | validation: 0.02004973823140014]
	TIME [epoch: 35.4 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01978347197631336		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.01978347197631336 | validation: 0.02124404873558735]
	TIME [epoch: 35.3 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.019590168457176524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.019590168457176524 | validation: 0.012436233772319115]
	TIME [epoch: 35.3 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.019585870240544954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.019585870240544954 | validation: 0.012398998805735957]
	TIME [epoch: 35.3 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.016486636099096123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.016486636099096123 | validation: 0.01735995071608865]
	TIME [epoch: 35.3 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012244805001183403		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.012244805001183403 | validation: 0.01783612960183078]
	TIME [epoch: 35.3 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012571632076431903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.012571632076431903 | validation: 0.02002922704332122]
	TIME [epoch: 35.3 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012005366782538203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.012005366782538203 | validation: 0.01012094430166271]
	TIME [epoch: 35.4 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012213584200480628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.012213584200480628 | validation: 0.009293937089506717]
	TIME [epoch: 35.4 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01582965049895064		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.01582965049895064 | validation: 0.025570786488424625]
	TIME [epoch: 35.4 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01640271797134692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.01640271797134692 | validation: 0.015062374524230588]
	TIME [epoch: 35.4 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.015818343284213596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.015818343284213596 | validation: 0.010701071994477106]
	TIME [epoch: 35.3 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.014350022745152877		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.014350022745152877 | validation: 0.009440722800272026]
	TIME [epoch: 35.4 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012977829908936148		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.012977829908936148 | validation: 0.018989931762946697]
	TIME [epoch: 35.3 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012426552825942972		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.012426552825942972 | validation: 0.012712894751858874]
	TIME [epoch: 35.4 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.014035433129085272		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.014035433129085272 | validation: 0.010823898198116964]
	TIME [epoch: 35.3 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013338947134082514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.013338947134082514 | validation: 0.009806640824928535]
	TIME [epoch: 35.4 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012827962008542665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.012827962008542665 | validation: 0.02993844289762047]
	TIME [epoch: 35.3 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.017507775417092926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.017507775417092926 | validation: 0.015898940163155788]
	TIME [epoch: 35.3 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0149799054964344		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0149799054964344 | validation: 0.013363443938708355]
	TIME [epoch: 35.3 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011285434057517217		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.011285434057517217 | validation: 0.02438403694733063]
	TIME [epoch: 35.3 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.014644165779732852		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.014644165779732852 | validation: 0.017731816998922754]
	TIME [epoch: 35.3 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013949475405357363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.013949475405357363 | validation: 0.011348952455058983]
	TIME [epoch: 35.3 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013759715955821037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.013759715955821037 | validation: 0.012833195623195685]
	TIME [epoch: 35.3 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011543039633238043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.011543039633238043 | validation: 0.013688177435979072]
	TIME [epoch: 35.3 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.014342026519845496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.014342026519845496 | validation: 0.011228324796856875]
	TIME [epoch: 35.3 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012928009383293314		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.012928009383293314 | validation: 0.012137334623510122]
	TIME [epoch: 35.3 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012757535933093901		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.012757535933093901 | validation: 0.013020945655911598]
	TIME [epoch: 35.3 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.019630233482712797		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.019630233482712797 | validation: 0.01654751561324311]
	TIME [epoch: 35.3 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.015579793791579116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.015579793791579116 | validation: 0.011287869349756893]
	TIME [epoch: 35.3 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013729821365512158		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.013729821365512158 | validation: 0.020660030033411863]
	TIME [epoch: 35.3 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.015046711831374578		[learning rate: 0.0099823]
	Learning Rate: 0.0099823
	LOSS [training: 0.015046711831374578 | validation: 0.013176235759892619]
	TIME [epoch: 35.3 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012311893008003946		[learning rate: 0.0099426]
	Learning Rate: 0.0099426
	LOSS [training: 0.012311893008003946 | validation: 0.028355852001031183]
	TIME [epoch: 35.3 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.014884804861941584		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.014884804861941584 | validation: 0.016876508008163517]
	TIME [epoch: 35.3 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013268193656498072		[learning rate: 0.0098637]
	Learning Rate: 0.00986367
	LOSS [training: 0.013268193656498072 | validation: 0.010281906296270536]
	TIME [epoch: 35.3 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012979524198613144		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 0.012979524198613144 | validation: 0.019565879799970775]
	TIME [epoch: 35.3 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013948698249169805		[learning rate: 0.0097854]
	Learning Rate: 0.00978536
	LOSS [training: 0.013948698249169805 | validation: 0.013064315618319125]
	TIME [epoch: 35.3 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012455387915522358		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.012455387915522358 | validation: 0.01125585035843058]
	TIME [epoch: 35.3 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.015476311784839316		[learning rate: 0.0097077]
	Learning Rate: 0.00970768
	LOSS [training: 0.015476311784839316 | validation: 0.009680157663216168]
	TIME [epoch: 35.4 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012897840777931614		[learning rate: 0.0096691]
	Learning Rate: 0.00966907
	LOSS [training: 0.012897840777931614 | validation: 0.024723665453594605]
	TIME [epoch: 35.3 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013210718241229834		[learning rate: 0.0096306]
	Learning Rate: 0.00963061
	LOSS [training: 0.013210718241229834 | validation: 0.011306130424418153]
	TIME [epoch: 35.4 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011896531048566222		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.011896531048566222 | validation: 0.01612760477843121]
	TIME [epoch: 35.3 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01403842929392095		[learning rate: 0.0095542]
	Learning Rate: 0.00955415
	LOSS [training: 0.01403842929392095 | validation: 0.012671700454360607]
	TIME [epoch: 35.4 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010487828405439362		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 0.010487828405439362 | validation: 0.016771016558335634]
	TIME [epoch: 35.3 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013587157532603616		[learning rate: 0.0094783]
	Learning Rate: 0.00947831
	LOSS [training: 0.013587157532603616 | validation: 0.01325747002592301]
	TIME [epoch: 35.3 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012660200997620505		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.012660200997620505 | validation: 0.018658418191509707]
	TIME [epoch: 35.3 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013154565945776596		[learning rate: 0.0094031]
	Learning Rate: 0.00940306
	LOSS [training: 0.013154565945776596 | validation: 0.013448205457362295]
	TIME [epoch: 35.4 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01687837679361551		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.01687837679361551 | validation: 0.010831793910094851]
	TIME [epoch: 35.3 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.014824371473408862		[learning rate: 0.0093284]
	Learning Rate: 0.00932841
	LOSS [training: 0.014824371473408862 | validation: 0.024279822154595912]
	TIME [epoch: 35.4 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.018032516689183327		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.018032516689183327 | validation: 0.01324198274487896]
	TIME [epoch: 35.3 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01206814757822303		[learning rate: 0.0092544]
	Learning Rate: 0.00925435
	LOSS [training: 0.01206814757822303 | validation: 0.012649925876100403]
	TIME [epoch: 35.3 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012363265899727837		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.012363265899727837 | validation: 0.013145872331172004]
	TIME [epoch: 35.3 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013805224288871376		[learning rate: 0.0091809]
	Learning Rate: 0.00918089
	LOSS [training: 0.013805224288871376 | validation: 0.015162487151664317]
	TIME [epoch: 35.3 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.015092934321413861		[learning rate: 0.0091444]
	Learning Rate: 0.00914437
	LOSS [training: 0.015092934321413861 | validation: 0.009430810212689919]
	TIME [epoch: 35.4 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01185962641929607		[learning rate: 0.009108]
	Learning Rate: 0.009108
	LOSS [training: 0.01185962641929607 | validation: 0.015762797287855738]
	TIME [epoch: 35.3 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013542560877770145		[learning rate: 0.0090718]
	Learning Rate: 0.00907178
	LOSS [training: 0.013542560877770145 | validation: 0.022523391200850958]
	TIME [epoch: 35.4 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013021039219018772		[learning rate: 0.0090357]
	Learning Rate: 0.00903569
	LOSS [training: 0.013021039219018772 | validation: 0.010890379834498703]
	TIME [epoch: 35.3 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01566188986896187		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.01566188986896187 | validation: 0.01607099685302302]
	TIME [epoch: 35.3 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.015474789210829858		[learning rate: 0.008964]
	Learning Rate: 0.00896396
	LOSS [training: 0.015474789210829858 | validation: 0.020123149341928128]
	TIME [epoch: 35.3 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01483825145981204		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 0.01483825145981204 | validation: 0.01183627552916442]
	TIME [epoch: 35.3 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013772605923788747		[learning rate: 0.0088928]
	Learning Rate: 0.0088928
	LOSS [training: 0.013772605923788747 | validation: 0.012339505962918478]
	TIME [epoch: 35.4 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.014183921966252264		[learning rate: 0.0088574]
	Learning Rate: 0.00885743
	LOSS [training: 0.014183921966252264 | validation: 0.021380639779075783]
	TIME [epoch: 35.3 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.015246172549446666		[learning rate: 0.0088222]
	Learning Rate: 0.0088222
	LOSS [training: 0.015246172549446666 | validation: 0.012929416188831758]
	TIME [epoch: 35.4 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012949928695655465		[learning rate: 0.0087871]
	Learning Rate: 0.00878711
	LOSS [training: 0.012949928695655465 | validation: 0.010054134641412572]
	TIME [epoch: 35.4 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01430760227025435		[learning rate: 0.0087522]
	Learning Rate: 0.00875216
	LOSS [training: 0.01430760227025435 | validation: 0.01372380976854562]
	TIME [epoch: 35.4 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012204308364090193		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.012204308364090193 | validation: 0.010394659358220792]
	TIME [epoch: 35.4 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013014329730805107		[learning rate: 0.0086827]
	Learning Rate: 0.00868268
	LOSS [training: 0.013014329730805107 | validation: 0.018578141937389596]
	TIME [epoch: 35.4 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012072757122800174		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.012072757122800174 | validation: 0.0153105334688063]
	TIME [epoch: 35.3 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01227861416289177		[learning rate: 0.0086138]
	Learning Rate: 0.00861375
	LOSS [training: 0.01227861416289177 | validation: 0.010369434855492595]
	TIME [epoch: 35.4 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013556526456897193		[learning rate: 0.0085795]
	Learning Rate: 0.00857949
	LOSS [training: 0.013556526456897193 | validation: 0.009752598550410241]
	TIME [epoch: 35.3 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010944282532378778		[learning rate: 0.0085454]
	Learning Rate: 0.00854537
	LOSS [training: 0.010944282532378778 | validation: 0.010701174666610224]
	TIME [epoch: 35.4 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013114191580376335		[learning rate: 0.0085114]
	Learning Rate: 0.00851138
	LOSS [training: 0.013114191580376335 | validation: 0.01213056190659548]
	TIME [epoch: 35.3 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.015187646871062712		[learning rate: 0.0084775]
	Learning Rate: 0.00847753
	LOSS [training: 0.015187646871062712 | validation: 0.012870406469442031]
	TIME [epoch: 35.4 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01336752232524479		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.01336752232524479 | validation: 0.0100399323861732]
	TIME [epoch: 35.4 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01095466244630464		[learning rate: 0.0084102]
	Learning Rate: 0.00841023
	LOSS [training: 0.01095466244630464 | validation: 0.014250483088989246]
	TIME [epoch: 35.4 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011291548711911823		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 0.011291548711911823 | validation: 0.008150371119898052]
	TIME [epoch: 35.4 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013645711998952533		[learning rate: 0.0083435]
	Learning Rate: 0.00834346
	LOSS [training: 0.013645711998952533 | validation: 0.008143347085557306]
	TIME [epoch: 35.3 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012612214352619125		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.012612214352619125 | validation: 0.010736837150353758]
	TIME [epoch: 35.3 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010043221272581483		[learning rate: 0.0082772]
	Learning Rate: 0.00827722
	LOSS [training: 0.010043221272581483 | validation: 0.011693830880831485]
	TIME [epoch: 35.3 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011977315145211383		[learning rate: 0.0082443]
	Learning Rate: 0.0082443
	LOSS [training: 0.011977315145211383 | validation: 0.011206665662841342]
	TIME [epoch: 35.3 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01319894506404238		[learning rate: 0.0082115]
	Learning Rate: 0.00821151
	LOSS [training: 0.01319894506404238 | validation: 0.01254180579105825]
	TIME [epoch: 35.3 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0117635036540568		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.0117635036540568 | validation: 0.017683420291617704]
	TIME [epoch: 35.3 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013134608952015557		[learning rate: 0.0081463]
	Learning Rate: 0.00814632
	LOSS [training: 0.013134608952015557 | validation: 0.013992341496279603]
	TIME [epoch: 35.3 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012349007668427624		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.012349007668427624 | validation: 0.016817641532912864]
	TIME [epoch: 35.3 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012280177579148295		[learning rate: 0.0080816]
	Learning Rate: 0.00808165
	LOSS [training: 0.012280177579148295 | validation: 0.009219336574868533]
	TIME [epoch: 35.3 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009376601135136891		[learning rate: 0.0080495]
	Learning Rate: 0.00804951
	LOSS [training: 0.009376601135136891 | validation: 0.021694573524930264]
	TIME [epoch: 35.3 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.015320312900472801		[learning rate: 0.0080175]
	Learning Rate: 0.00801749
	LOSS [training: 0.015320312900472801 | validation: 0.010649919062711932]
	TIME [epoch: 35.3 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00983136288269963		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.00983136288269963 | validation: 0.01115581985602181]
	TIME [epoch: 35.4 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012163939360339033		[learning rate: 0.0079538]
	Learning Rate: 0.00795384
	LOSS [training: 0.012163939360339033 | validation: 0.011686066850173775]
	TIME [epoch: 35.3 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011822313015643805		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.011822313015643805 | validation: 0.011957340270284856]
	TIME [epoch: 35.4 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012069480052298283		[learning rate: 0.0078907]
	Learning Rate: 0.0078907
	LOSS [training: 0.012069480052298283 | validation: 0.019983832459801627]
	TIME [epoch: 35.3 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012237894932957606		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 0.012237894932957606 | validation: 0.009272489771918486]
	TIME [epoch: 35.4 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010318111579270638		[learning rate: 0.0078281]
	Learning Rate: 0.00782805
	LOSS [training: 0.010318111579270638 | validation: 0.015633120441224606]
	TIME [epoch: 35.3 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011521868235534492		[learning rate: 0.0077969]
	Learning Rate: 0.00779692
	LOSS [training: 0.011521868235534492 | validation: 0.010589315009435598]
	TIME [epoch: 35.4 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012984947086727955		[learning rate: 0.0077659]
	Learning Rate: 0.00776591
	LOSS [training: 0.012984947086727955 | validation: 0.008079947816722553]
	TIME [epoch: 35.3 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010318380600087268		[learning rate: 0.007735]
	Learning Rate: 0.00773502
	LOSS [training: 0.010318380600087268 | validation: 0.008193101644676907]
	TIME [epoch: 35.4 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01278395123972216		[learning rate: 0.0077043]
	Learning Rate: 0.00770426
	LOSS [training: 0.01278395123972216 | validation: 0.010765557453209219]
	TIME [epoch: 35.3 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011797413089367895		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.011797413089367895 | validation: 0.009902750295309999]
	TIME [epoch: 35.4 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010477702241992425		[learning rate: 0.0076431]
	Learning Rate: 0.00764309
	LOSS [training: 0.010477702241992425 | validation: 0.011139027631735719]
	TIME [epoch: 35.3 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01074104520204736		[learning rate: 0.0076127]
	Learning Rate: 0.00761269
	LOSS [training: 0.01074104520204736 | validation: 0.013763361861490409]
	TIME [epoch: 35.4 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013238425936783774		[learning rate: 0.0075824]
	Learning Rate: 0.00758242
	LOSS [training: 0.013238425936783774 | validation: 0.013238953559989858]
	TIME [epoch: 35.3 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010196800709670604		[learning rate: 0.0075523]
	Learning Rate: 0.00755226
	LOSS [training: 0.010196800709670604 | validation: 0.019637704473260787]
	TIME [epoch: 35.4 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012206360851077614		[learning rate: 0.0075222]
	Learning Rate: 0.00752222
	LOSS [training: 0.012206360851077614 | validation: 0.012574837327316507]
	TIME [epoch: 35.2 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0134698587950358		[learning rate: 0.0074923]
	Learning Rate: 0.0074923
	LOSS [training: 0.0134698587950358 | validation: 0.010105088908490312]
	TIME [epoch: 35.4 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01131099850078642		[learning rate: 0.0074625]
	Learning Rate: 0.0074625
	LOSS [training: 0.01131099850078642 | validation: 0.00980643988114227]
	TIME [epoch: 35.3 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012155871441009002		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.012155871441009002 | validation: 0.007694464067091169]
	TIME [epoch: 35.3 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_119.pth
	Model improved!!!
EPOCH 120/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010039894704029247		[learning rate: 0.0074033]
	Learning Rate: 0.00740326
	LOSS [training: 0.010039894704029247 | validation: 0.01805429479448038]
	TIME [epoch: 35.3 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010672342771510806		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.010672342771510806 | validation: 0.007540002879234229]
	TIME [epoch: 35.3 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011559491626741572		[learning rate: 0.0073445]
	Learning Rate: 0.00734449
	LOSS [training: 0.011559491626741572 | validation: 0.01328831297167759]
	TIME [epoch: 35.4 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01276527952995763		[learning rate: 0.0073153]
	Learning Rate: 0.00731528
	LOSS [training: 0.01276527952995763 | validation: 0.009850715757630723]
	TIME [epoch: 35.3 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011282872728208394		[learning rate: 0.0072862]
	Learning Rate: 0.00728618
	LOSS [training: 0.011282872728208394 | validation: 0.01389361656194672]
	TIME [epoch: 35.4 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.015679640473729533		[learning rate: 0.0072572]
	Learning Rate: 0.0072572
	LOSS [training: 0.015679640473729533 | validation: 0.009011566620209655]
	TIME [epoch: 35.3 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012435958517801568		[learning rate: 0.0072283]
	Learning Rate: 0.00722834
	LOSS [training: 0.012435958517801568 | validation: 0.013542789973055396]
	TIME [epoch: 35.3 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013167092547342775		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.013167092547342775 | validation: 0.011819119156954267]
	TIME [epoch: 35.3 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010548392080464252		[learning rate: 0.007171]
	Learning Rate: 0.00717095
	LOSS [training: 0.010548392080464252 | validation: 0.010480422733045317]
	TIME [epoch: 35.3 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010445231578517894		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.010445231578517894 | validation: 0.00740522802574887]
	TIME [epoch: 35.3 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_129.pth
	Model improved!!!
EPOCH 130/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010121073209036414		[learning rate: 0.007114]
	Learning Rate: 0.00711403
	LOSS [training: 0.010121073209036414 | validation: 0.008442679645885312]
	TIME [epoch: 35.3 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.015327030011884325		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.015327030011884325 | validation: 0.011174120593924038]
	TIME [epoch: 35.3 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011835168542979169		[learning rate: 0.0070575]
	Learning Rate: 0.00705755
	LOSS [training: 0.011835168542979169 | validation: 0.01261931850933867]
	TIME [epoch: 35.3 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010661790403088988		[learning rate: 0.0070295]
	Learning Rate: 0.00702948
	LOSS [training: 0.010661790403088988 | validation: 0.00855242558734954]
	TIME [epoch: 35.3 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009595509113558054		[learning rate: 0.0070015]
	Learning Rate: 0.00700152
	LOSS [training: 0.009595509113558054 | validation: 0.008920162415620877]
	TIME [epoch: 35.3 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011087239875681991		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.011087239875681991 | validation: 0.009595765199378303]
	TIME [epoch: 35.3 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012455300066802592		[learning rate: 0.0069459]
	Learning Rate: 0.00694594
	LOSS [training: 0.012455300066802592 | validation: 0.01034859473060951]
	TIME [epoch: 35.3 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009343443219560701		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 0.009343443219560701 | validation: 0.008874458089909557]
	TIME [epoch: 35.3 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01095279710224948		[learning rate: 0.0068908]
	Learning Rate: 0.00689079
	LOSS [training: 0.01095279710224948 | validation: 0.010465465806014974]
	TIME [epoch: 35.3 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011028572291073655		[learning rate: 0.0068634]
	Learning Rate: 0.00686339
	LOSS [training: 0.011028572291073655 | validation: 0.009229911523116141]
	TIME [epoch: 35.3 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012244143431430305		[learning rate: 0.0068361]
	Learning Rate: 0.00683609
	LOSS [training: 0.012244143431430305 | validation: 0.009360795102686722]
	TIME [epoch: 35.4 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011124258096113426		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.011124258096113426 | validation: 0.010452908732275504]
	TIME [epoch: 35.3 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009424961372532051		[learning rate: 0.0067818]
	Learning Rate: 0.00678182
	LOSS [training: 0.009424961372532051 | validation: 0.008708892422456439]
	TIME [epoch: 35.4 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011060728061455012		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.011060728061455012 | validation: 0.008798844332670832]
	TIME [epoch: 35.4 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011928649395735229		[learning rate: 0.006728]
	Learning Rate: 0.00672798
	LOSS [training: 0.011928649395735229 | validation: 0.008149010694614853]
	TIME [epoch: 35.3 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010429686848619427		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 0.010429686848619427 | validation: 0.012291191952959813]
	TIME [epoch: 35.2 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013052524155084403		[learning rate: 0.0066746]
	Learning Rate: 0.00667457
	LOSS [training: 0.013052524155084403 | validation: 0.010263139872591887]
	TIME [epoch: 35.3 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011443298728833779		[learning rate: 0.006648]
	Learning Rate: 0.00664802
	LOSS [training: 0.011443298728833779 | validation: 0.009742079437226258]
	TIME [epoch: 35.3 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.014267861329551799		[learning rate: 0.0066216]
	Learning Rate: 0.00662158
	LOSS [training: 0.014267861329551799 | validation: 0.009018764307251976]
	TIME [epoch: 35.3 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011889974748089917		[learning rate: 0.0065952]
	Learning Rate: 0.00659524
	LOSS [training: 0.011889974748089917 | validation: 0.01626711619449685]
	TIME [epoch: 35.3 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01106304028104768		[learning rate: 0.006569]
	Learning Rate: 0.00656901
	LOSS [training: 0.01106304028104768 | validation: 0.007888485837810074]
	TIME [epoch: 35.2 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010585219155292069		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.010585219155292069 | validation: 0.009974870349241004]
	TIME [epoch: 35.2 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01212775209426308		[learning rate: 0.0065169]
	Learning Rate: 0.00651686
	LOSS [training: 0.01212775209426308 | validation: 0.013958646412636463]
	TIME [epoch: 35.2 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009743370982678754		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 0.009743370982678754 | validation: 0.014098088154763874]
	TIME [epoch: 35.3 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011015627139296552		[learning rate: 0.0064651]
	Learning Rate: 0.00646512
	LOSS [training: 0.011015627139296552 | validation: 0.01540691278933035]
	TIME [epoch: 35.2 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011565667520736712		[learning rate: 0.0064394]
	Learning Rate: 0.00643941
	LOSS [training: 0.011565667520736712 | validation: 0.013105654096855077]
	TIME [epoch: 35.2 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012457785996991363		[learning rate: 0.0064138]
	Learning Rate: 0.0064138
	LOSS [training: 0.012457785996991363 | validation: 0.013595961852614063]
	TIME [epoch: 35.2 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013013689088632865		[learning rate: 0.0063883]
	Learning Rate: 0.00638829
	LOSS [training: 0.013013689088632865 | validation: 0.00813847186941335]
	TIME [epoch: 35.3 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01171685915658002		[learning rate: 0.0063629]
	Learning Rate: 0.00636288
	LOSS [training: 0.01171685915658002 | validation: 0.019537634836248746]
	TIME [epoch: 35.3 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012352847329489373		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.012352847329489373 | validation: 0.01270703703567544]
	TIME [epoch: 35.2 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011149855790987203		[learning rate: 0.0063124]
	Learning Rate: 0.00631237
	LOSS [training: 0.011149855790987203 | validation: 0.013234292995327645]
	TIME [epoch: 35.3 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011225849183248928		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.011225849183248928 | validation: 0.014655643321049197]
	TIME [epoch: 35.3 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010104168153122001		[learning rate: 0.0062623]
	Learning Rate: 0.00626226
	LOSS [training: 0.010104168153122001 | validation: 0.015130973791303303]
	TIME [epoch: 35.3 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011050186509600357		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.011050186509600357 | validation: 0.00945780791867842]
	TIME [epoch: 35.3 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011732644219970187		[learning rate: 0.0062125]
	Learning Rate: 0.00621254
	LOSS [training: 0.011732644219970187 | validation: 0.010241987923253246]
	TIME [epoch: 35.3 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011232886409023502		[learning rate: 0.0061878]
	Learning Rate: 0.00618783
	LOSS [training: 0.011232886409023502 | validation: 0.01006570767254809]
	TIME [epoch: 35.3 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01229103023288644		[learning rate: 0.0061632]
	Learning Rate: 0.00616322
	LOSS [training: 0.01229103023288644 | validation: 0.009246898668708311]
	TIME [epoch: 35.3 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011208109872292616		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.011208109872292616 | validation: 0.01836583261902686]
	TIME [epoch: 35.3 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012198815557091945		[learning rate: 0.0061143]
	Learning Rate: 0.00611429
	LOSS [training: 0.012198815557091945 | validation: 0.011517613965023137]
	TIME [epoch: 35.3 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009801835575198828		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 0.009801835575198828 | validation: 0.010799903497054345]
	TIME [epoch: 35.3 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009222138873337124		[learning rate: 0.0060658]
	Learning Rate: 0.00606575
	LOSS [training: 0.009222138873337124 | validation: 0.008084613194188468]
	TIME [epoch: 35.3 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01310696960630674		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.01310696960630674 | validation: 0.00728439931522813]
	TIME [epoch: 35.3 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_171.pth
	Model improved!!!
EPOCH 172/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011721350330244643		[learning rate: 0.0060176]
	Learning Rate: 0.0060176
	LOSS [training: 0.011721350330244643 | validation: 0.00904415562701733]
	TIME [epoch: 35.3 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010889981431772928		[learning rate: 0.0059937]
	Learning Rate: 0.00599366
	LOSS [training: 0.010889981431772928 | validation: 0.008907903211317684]
	TIME [epoch: 35.3 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010056458218097744		[learning rate: 0.0059698]
	Learning Rate: 0.00596982
	LOSS [training: 0.010056458218097744 | validation: 0.00740632871161504]
	TIME [epoch: 35.2 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010916330856794701		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.010916330856794701 | validation: 0.009491515611663691]
	TIME [epoch: 35.3 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011133205417511623		[learning rate: 0.0059224]
	Learning Rate: 0.00592243
	LOSS [training: 0.011133205417511623 | validation: 0.01477330954365117]
	TIME [epoch: 35.2 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01337736380490312		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 0.01337736380490312 | validation: 0.010091009070694068]
	TIME [epoch: 35.2 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010223466042894293		[learning rate: 0.0058754]
	Learning Rate: 0.00587541
	LOSS [training: 0.010223466042894293 | validation: 0.011026215593990196]
	TIME [epoch: 35.3 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011910316581558073		[learning rate: 0.005852]
	Learning Rate: 0.00585205
	LOSS [training: 0.011910316581558073 | validation: 0.007676127221464282]
	TIME [epoch: 35.2 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01027452154094675		[learning rate: 0.0058288]
	Learning Rate: 0.00582877
	LOSS [training: 0.01027452154094675 | validation: 0.010210477382228179]
	TIME [epoch: 35.3 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011386896755439453		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.011386896755439453 | validation: 0.00782749754547142]
	TIME [epoch: 35.2 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009452906919479523		[learning rate: 0.0057825]
	Learning Rate: 0.0057825
	LOSS [training: 0.009452906919479523 | validation: 0.010696075332097325]
	TIME [epoch: 35.3 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009584049996809159		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.009584049996809159 | validation: 0.009304337980973139]
	TIME [epoch: 35.2 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011559643880249278		[learning rate: 0.0057366]
	Learning Rate: 0.00573659
	LOSS [training: 0.011559643880249278 | validation: 0.011163749499944687]
	TIME [epoch: 35.2 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011902359394328807		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 0.011902359394328807 | validation: 0.011888315782449307]
	TIME [epoch: 35.3 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010968658830703706		[learning rate: 0.005691]
	Learning Rate: 0.00569105
	LOSS [training: 0.010968658830703706 | validation: 0.014790564245112488]
	TIME [epoch: 35.2 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012165587367944696		[learning rate: 0.0056684]
	Learning Rate: 0.00566841
	LOSS [training: 0.012165587367944696 | validation: 0.010354617996204185]
	TIME [epoch: 35.3 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010267903979071112		[learning rate: 0.0056459]
	Learning Rate: 0.00564587
	LOSS [training: 0.010267903979071112 | validation: 0.014817868736391775]
	TIME [epoch: 35.2 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011667154760354088		[learning rate: 0.0056234]
	Learning Rate: 0.00562341
	LOSS [training: 0.011667154760354088 | validation: 0.008725657946931085]
	TIME [epoch: 35.4 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009834952212282614		[learning rate: 0.005601]
	Learning Rate: 0.00560105
	LOSS [training: 0.009834952212282614 | validation: 0.009532298258582992]
	TIME [epoch: 35.3 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011530227070435993		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.011530227070435993 | validation: 0.008933476472917277]
	TIME [epoch: 35.3 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010116444025263814		[learning rate: 0.0055566]
	Learning Rate: 0.00555658
	LOSS [training: 0.010116444025263814 | validation: 0.008954240971215235]
	TIME [epoch: 35.3 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01252470472565444		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.01252470472565444 | validation: 0.012511069938566544]
	TIME [epoch: 35.3 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011523867478501738		[learning rate: 0.0055125]
	Learning Rate: 0.00551247
	LOSS [training: 0.011523867478501738 | validation: 0.013470258727363122]
	TIME [epoch: 35.2 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.016454301024523426		[learning rate: 0.0054905]
	Learning Rate: 0.00549054
	LOSS [training: 0.016454301024523426 | validation: 0.007629596159212113]
	TIME [epoch: 35.2 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01285255534611588		[learning rate: 0.0054687]
	Learning Rate: 0.00546871
	LOSS [training: 0.01285255534611588 | validation: 0.007594920653711307]
	TIME [epoch: 35.2 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00909028818115666		[learning rate: 0.005447]
	Learning Rate: 0.00544696
	LOSS [training: 0.00909028818115666 | validation: 0.008684371905768495]
	TIME [epoch: 35.2 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010388827049202999		[learning rate: 0.0054253]
	Learning Rate: 0.00542529
	LOSS [training: 0.010388827049202999 | validation: 0.009789266809765329]
	TIME [epoch: 35.2 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010230133966883426		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.010230133966883426 | validation: 0.011692828019932149]
	TIME [epoch: 35.2 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010305321759197371		[learning rate: 0.0053822]
	Learning Rate: 0.00538222
	LOSS [training: 0.010305321759197371 | validation: 0.008741504167082765]
	TIME [epoch: 35.2 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010311242749637788		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.010311242749637788 | validation: 0.007752690291650587]
	TIME [epoch: 35.2 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010476734910432125		[learning rate: 0.0053395]
	Learning Rate: 0.00533949
	LOSS [training: 0.010476734910432125 | validation: 0.01237925979256441]
	TIME [epoch: 35.2 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010880466861304457		[learning rate: 0.0053183]
	Learning Rate: 0.00531826
	LOSS [training: 0.010880466861304457 | validation: 0.010119296483569396]
	TIME [epoch: 35.3 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010078948141060343		[learning rate: 0.0052971]
	Learning Rate: 0.0052971
	LOSS [training: 0.010078948141060343 | validation: 0.016315329420165208]
	TIME [epoch: 35.2 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01489860281210625		[learning rate: 0.005276]
	Learning Rate: 0.00527604
	LOSS [training: 0.01489860281210625 | validation: 0.01026960329549842]
	TIME [epoch: 35.3 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008601137560390167		[learning rate: 0.0052551]
	Learning Rate: 0.00525505
	LOSS [training: 0.008601137560390167 | validation: 0.010983900676671696]
	TIME [epoch: 35.2 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011882117557803164		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.011882117557803164 | validation: 0.010485120857526673]
	TIME [epoch: 35.3 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009752835672701292		[learning rate: 0.0052133]
	Learning Rate: 0.00521333
	LOSS [training: 0.009752835672701292 | validation: 0.01789061056260455]
	TIME [epoch: 35.2 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011041922547163241		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 0.011041922547163241 | validation: 0.013470818708884882]
	TIME [epoch: 35.2 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010595189491631744		[learning rate: 0.0051719]
	Learning Rate: 0.00517194
	LOSS [training: 0.010595189491631744 | validation: 0.006980997641034157]
	TIME [epoch: 35.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_210.pth
	Model improved!!!
EPOCH 211/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009705927881456584		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.009705927881456584 | validation: 0.008390808603267597]
	TIME [epoch: 35.2 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008775035369881659		[learning rate: 0.0051309]
	Learning Rate: 0.00513089
	LOSS [training: 0.008775035369881659 | validation: 0.010713997094513586]
	TIME [epoch: 35.4 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011207318136586783		[learning rate: 0.0051105]
	Learning Rate: 0.00511048
	LOSS [training: 0.011207318136586783 | validation: 0.008898668495485982]
	TIME [epoch: 35.5 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010132444588503896		[learning rate: 0.0050902]
	Learning Rate: 0.00509015
	LOSS [training: 0.010132444588503896 | validation: 0.00795688697386931]
	TIME [epoch: 35.4 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013197399046288872		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.013197399046288872 | validation: 0.0068795661450349824]
	TIME [epoch: 35.5 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_215.pth
	Model improved!!!
EPOCH 216/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009600603937888554		[learning rate: 0.0050497]
	Learning Rate: 0.00504974
	LOSS [training: 0.009600603937888554 | validation: 0.00973750632390007]
	TIME [epoch: 35.4 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011688877924528482		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 0.011688877924528482 | validation: 0.022349054376552657]
	TIME [epoch: 35.5 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013052550626381533		[learning rate: 0.0050097]
	Learning Rate: 0.00500965
	LOSS [training: 0.013052550626381533 | validation: 0.012818545278112842]
	TIME [epoch: 35.4 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010963415558273551		[learning rate: 0.0049897]
	Learning Rate: 0.00498973
	LOSS [training: 0.010963415558273551 | validation: 0.007890369953630216]
	TIME [epoch: 35.4 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008420234167669285		[learning rate: 0.0049699]
	Learning Rate: 0.00496988
	LOSS [training: 0.008420234167669285 | validation: 0.012098045022529886]
	TIME [epoch: 35.4 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011734857636493932		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.011734857636493932 | validation: 0.007756737210397438]
	TIME [epoch: 35.4 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010201122145461157		[learning rate: 0.0049304]
	Learning Rate: 0.00493043
	LOSS [training: 0.010201122145461157 | validation: 0.007970627950766196]
	TIME [epoch: 35.3 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009380128949531363		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.009380128949531363 | validation: 0.009319582284027201]
	TIME [epoch: 35.5 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01086568725777265		[learning rate: 0.0048913]
	Learning Rate: 0.00489129
	LOSS [training: 0.01086568725777265 | validation: 0.009255543192816301]
	TIME [epoch: 35.3 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010248888543878159		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.010248888543878159 | validation: 0.008502535958607766]
	TIME [epoch: 35.4 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010153475122941277		[learning rate: 0.0048525]
	Learning Rate: 0.00485245
	LOSS [training: 0.010153475122941277 | validation: 0.009662336774699689]
	TIME [epoch: 35.5 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010633358082978593		[learning rate: 0.0048332]
	Learning Rate: 0.00483316
	LOSS [training: 0.010633358082978593 | validation: 0.008970864080985233]
	TIME [epoch: 35.5 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010199286265865018		[learning rate: 0.0048139]
	Learning Rate: 0.00481393
	LOSS [training: 0.010199286265865018 | validation: 0.011876364857563928]
	TIME [epoch: 35.5 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010296421523981336		[learning rate: 0.0047948]
	Learning Rate: 0.00479479
	LOSS [training: 0.010296421523981336 | validation: 0.009900715374789825]
	TIME [epoch: 35.4 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010539374224992099		[learning rate: 0.0047757]
	Learning Rate: 0.00477572
	LOSS [training: 0.010539374224992099 | validation: 0.008831356176798347]
	TIME [epoch: 35.4 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01000197254975187		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.01000197254975187 | validation: 0.013040944527436751]
	TIME [epoch: 35.5 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011577086961623378		[learning rate: 0.0047378]
	Learning Rate: 0.0047378
	LOSS [training: 0.011577086961623378 | validation: 0.007542983501090802]
	TIME [epoch: 35.5 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012893575700903308		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 0.012893575700903308 | validation: 0.008339786412425032]
	TIME [epoch: 35.6 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00966789936224833		[learning rate: 0.0047002]
	Learning Rate: 0.00470019
	LOSS [training: 0.00966789936224833 | validation: 0.009071501811094045]
	TIME [epoch: 35.4 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010666286153006372		[learning rate: 0.0046815]
	Learning Rate: 0.0046815
	LOSS [training: 0.010666286153006372 | validation: 0.012772735593064197]
	TIME [epoch: 35.4 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011292405089150402		[learning rate: 0.0046629]
	Learning Rate: 0.00466288
	LOSS [training: 0.011292405089150402 | validation: 0.00983951098961748]
	TIME [epoch: 35.4 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011244755085844474		[learning rate: 0.0046443]
	Learning Rate: 0.00464433
	LOSS [training: 0.011244755085844474 | validation: 0.009537976091560374]
	TIME [epoch: 35.5 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010297918994513412		[learning rate: 0.0046259]
	Learning Rate: 0.00462586
	LOSS [training: 0.010297918994513412 | validation: 0.010985894153172224]
	TIME [epoch: 35.4 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010164411021442573		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.010164411021442573 | validation: 0.008131213217536267]
	TIME [epoch: 35.5 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011053407350599512		[learning rate: 0.0045891]
	Learning Rate: 0.00458913
	LOSS [training: 0.011053407350599512 | validation: 0.00871711355250529]
	TIME [epoch: 35.3 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012040034527469913		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.012040034527469913 | validation: 0.009741560174876405]
	TIME [epoch: 35.5 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00963242481565282		[learning rate: 0.0045527]
	Learning Rate: 0.0045527
	LOSS [training: 0.00963242481565282 | validation: 0.009327893991965866]
	TIME [epoch: 35.5 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009594572937859593		[learning rate: 0.0045346]
	Learning Rate: 0.00453459
	LOSS [training: 0.009594572937859593 | validation: 0.008808406956949821]
	TIME [epoch: 35.4 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013035373541414982		[learning rate: 0.0045166]
	Learning Rate: 0.00451656
	LOSS [training: 0.013035373541414982 | validation: 0.013367405349629097]
	TIME [epoch: 35.4 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010822357374277097		[learning rate: 0.0044986]
	Learning Rate: 0.0044986
	LOSS [training: 0.010822357374277097 | validation: 0.007625586669027916]
	TIME [epoch: 35.3 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01380819145699972		[learning rate: 0.0044807]
	Learning Rate: 0.0044807
	LOSS [training: 0.01380819145699972 | validation: 0.008048500527051267]
	TIME [epoch: 35.4 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011274560457974665		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.011274560457974665 | validation: 0.006859047429223763]
	TIME [epoch: 35.5 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_247.pth
	Model improved!!!
EPOCH 248/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009548393764747622		[learning rate: 0.0044451]
	Learning Rate: 0.00444513
	LOSS [training: 0.009548393764747622 | validation: 0.009363533161665032]
	TIME [epoch: 35.4 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010751176621186229		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 0.010751176621186229 | validation: 0.008444722148962015]
	TIME [epoch: 35.4 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009773838369335769		[learning rate: 0.0044098]
	Learning Rate: 0.00440984
	LOSS [training: 0.009773838369335769 | validation: 0.007266785731916414]
	TIME [epoch: 35.3 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008822804089708376		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.008822804089708376 | validation: 0.007614763694182206]
	TIME [epoch: 35.4 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010003883287081964		[learning rate: 0.0043748]
	Learning Rate: 0.00437483
	LOSS [training: 0.010003883287081964 | validation: 0.007963599764876839]
	TIME [epoch: 35.4 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01062732844264943		[learning rate: 0.0043574]
	Learning Rate: 0.00435743
	LOSS [training: 0.01062732844264943 | validation: 0.007034192315034068]
	TIME [epoch: 35.4 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00958072297812184		[learning rate: 0.0043401]
	Learning Rate: 0.0043401
	LOSS [training: 0.00958072297812184 | validation: 0.011622792050949737]
	TIME [epoch: 35.3 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01131091865147473		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.01131091865147473 | validation: 0.013072365235728195]
	TIME [epoch: 35.4 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01154776206719869		[learning rate: 0.0043056]
	Learning Rate: 0.00430565
	LOSS [training: 0.01154776206719869 | validation: 0.00985610006388555]
	TIME [epoch: 35.3 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009960158139578314		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.009960158139578314 | validation: 0.007659845399559365]
	TIME [epoch: 35.3 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009604740757802835		[learning rate: 0.0042715]
	Learning Rate: 0.00427147
	LOSS [training: 0.009604740757802835 | validation: 0.008503029398513513]
	TIME [epoch: 35.3 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010387442637064684		[learning rate: 0.0042545]
	Learning Rate: 0.00425448
	LOSS [training: 0.010387442637064684 | validation: 0.008040417997789855]
	TIME [epoch: 35.4 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010164135006913573		[learning rate: 0.0042376]
	Learning Rate: 0.00423756
	LOSS [training: 0.010164135006913573 | validation: 0.007373886591526468]
	TIME [epoch: 35.3 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010751374753172173		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.010751374753172173 | validation: 0.007433260227924015]
	TIME [epoch: 35.3 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00902156083426568		[learning rate: 0.0042039]
	Learning Rate: 0.00420391
	LOSS [training: 0.00902156083426568 | validation: 0.009077834231136768]
	TIME [epoch: 35.3 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00968366263528603		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.00968366263528603 | validation: 0.008853074370107994]
	TIME [epoch: 35.4 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009555560665315281		[learning rate: 0.0041705]
	Learning Rate: 0.00417054
	LOSS [training: 0.009555560665315281 | validation: 0.007356145677022084]
	TIME [epoch: 35.3 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00810407890101516		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 0.00810407890101516 | validation: 0.010545198383736024]
	TIME [epoch: 35.3 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01183776543333277		[learning rate: 0.0041374]
	Learning Rate: 0.00413743
	LOSS [training: 0.01183776543333277 | validation: 0.008952402485777139]
	TIME [epoch: 35.3 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010126237413829085		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.010126237413829085 | validation: 0.009847828340704575]
	TIME [epoch: 35.3 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011188784985466564		[learning rate: 0.0041046]
	Learning Rate: 0.00410458
	LOSS [training: 0.011188784985466564 | validation: 0.010105888060822207]
	TIME [epoch: 35.4 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009120691484341553		[learning rate: 0.0040883]
	Learning Rate: 0.00408826
	LOSS [training: 0.009120691484341553 | validation: 0.007383134612604034]
	TIME [epoch: 35.3 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010165229748279115		[learning rate: 0.004072]
	Learning Rate: 0.004072
	LOSS [training: 0.010165229748279115 | validation: 0.008261099164340617]
	TIME [epoch: 35.3 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010126005958745247		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.010126005958745247 | validation: 0.012478731159196722]
	TIME [epoch: 35.4 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011868253229390167		[learning rate: 0.0040397]
	Learning Rate: 0.00403967
	LOSS [training: 0.011868253229390167 | validation: 0.00951746437043166]
	TIME [epoch: 35.3 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009355728255838504		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 0.009355728255838504 | validation: 0.011430145985289332]
	TIME [epoch: 35.4 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010694428968253896		[learning rate: 0.0040076]
	Learning Rate: 0.0040076
	LOSS [training: 0.010694428968253896 | validation: 0.013020993968189598]
	TIME [epoch: 35.4 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013191568710332453		[learning rate: 0.0039917]
	Learning Rate: 0.00399166
	LOSS [training: 0.013191568710332453 | validation: 0.007381562620362292]
	TIME [epoch: 35.3 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009281467485698771		[learning rate: 0.0039758]
	Learning Rate: 0.00397579
	LOSS [training: 0.009281467485698771 | validation: 0.008656616148046371]
	TIME [epoch: 35.3 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010085477278039663		[learning rate: 0.00396]
	Learning Rate: 0.00395997
	LOSS [training: 0.010085477278039663 | validation: 0.010037857068718573]
	TIME [epoch: 35.4 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01198009671816251		[learning rate: 0.0039442]
	Learning Rate: 0.00394422
	LOSS [training: 0.01198009671816251 | validation: 0.008105456569766623]
	TIME [epoch: 35.3 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010252556022059583		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.010252556022059583 | validation: 0.00880746509893208]
	TIME [epoch: 35.4 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010195559362389518		[learning rate: 0.0039129]
	Learning Rate: 0.00391291
	LOSS [training: 0.010195559362389518 | validation: 0.009640267244496284]
	TIME [epoch: 35.3 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009150363340540615		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.009150363340540615 | validation: 0.008554760149702974]
	TIME [epoch: 35.4 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009316105389278488		[learning rate: 0.0038818]
	Learning Rate: 0.00388185
	LOSS [training: 0.009316105389278488 | validation: 0.009604495594466852]
	TIME [epoch: 35.3 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010171912397564197		[learning rate: 0.0038664]
	Learning Rate: 0.00386641
	LOSS [training: 0.010171912397564197 | validation: 0.009668514101236212]
	TIME [epoch: 35.4 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.014073351815846643		[learning rate: 0.003851]
	Learning Rate: 0.00385103
	LOSS [training: 0.014073351815846643 | validation: 0.01002231890242483]
	TIME [epoch: 35.3 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010615692350011478		[learning rate: 0.0038357]
	Learning Rate: 0.00383571
	LOSS [training: 0.010615692350011478 | validation: 0.0077730305172685294]
	TIME [epoch: 35.4 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008726002856346593		[learning rate: 0.0038205]
	Learning Rate: 0.00382046
	LOSS [training: 0.008726002856346593 | validation: 0.009166454517115877]
	TIME [epoch: 35.3 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010981835964195209		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.010981835964195209 | validation: 0.012252574288415353]
	TIME [epoch: 35.4 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009778550837051696		[learning rate: 0.0037901]
	Learning Rate: 0.00379013
	LOSS [training: 0.009778550837051696 | validation: 0.008443853154858742]
	TIME [epoch: 35.3 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01075682170928574		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.01075682170928574 | validation: 0.006943596955191311]
	TIME [epoch: 35.4 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00972939047388181		[learning rate: 0.00376]
	Learning Rate: 0.00376004
	LOSS [training: 0.00972939047388181 | validation: 0.012722058500314395]
	TIME [epoch: 35.3 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0109356065625458		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.0109356065625458 | validation: 0.009819660975348712]
	TIME [epoch: 35.5 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010332662917760353		[learning rate: 0.0037302]
	Learning Rate: 0.00373019
	LOSS [training: 0.010332662917760353 | validation: 0.009665249792321223]
	TIME [epoch: 35.3 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010007829018209215		[learning rate: 0.0037154]
	Learning Rate: 0.00371535
	LOSS [training: 0.010007829018209215 | validation: 0.010393221979867797]
	TIME [epoch: 35.4 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009403702959599816		[learning rate: 0.0037006]
	Learning Rate: 0.00370058
	LOSS [training: 0.009403702959599816 | validation: 0.009334778140200698]
	TIME [epoch: 35.3 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01336631997628862		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.01336631997628862 | validation: 0.008850209739742328]
	TIME [epoch: 35.4 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011689287666346245		[learning rate: 0.0036712]
	Learning Rate: 0.0036712
	LOSS [training: 0.011689287666346245 | validation: 0.012551092699169208]
	TIME [epoch: 35.3 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01038595629750368		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 0.01038595629750368 | validation: 0.010009801289356197]
	TIME [epoch: 35.4 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011227344718831904		[learning rate: 0.0036421]
	Learning Rate: 0.00364205
	LOSS [training: 0.011227344718831904 | validation: 0.007669011264471473]
	TIME [epoch: 35.3 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009060557187833837		[learning rate: 0.0036276]
	Learning Rate: 0.00362757
	LOSS [training: 0.009060557187833837 | validation: 0.007685522063282031]
	TIME [epoch: 35.4 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008753461019342481		[learning rate: 0.0036131]
	Learning Rate: 0.00361314
	LOSS [training: 0.008753461019342481 | validation: 0.007402740872749489]
	TIME [epoch: 35.3 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009535933108044221		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.009535933108044221 | validation: 0.008332288224760807]
	TIME [epoch: 35.5 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01126501987787964		[learning rate: 0.0035845]
	Learning Rate: 0.00358445
	LOSS [training: 0.01126501987787964 | validation: 0.007940897468026828]
	TIME [epoch: 35.4 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009116013763351714		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.009116013763351714 | validation: 0.009711474962763682]
	TIME [epoch: 35.4 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010466875643882531		[learning rate: 0.003556]
	Learning Rate: 0.003556
	LOSS [training: 0.010466875643882531 | validation: 0.007907812940912081]
	TIME [epoch: 35.4 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00944603854630034		[learning rate: 0.0035419]
	Learning Rate: 0.00354185
	LOSS [training: 0.00944603854630034 | validation: 0.00826403319020071]
	TIME [epoch: 35.4 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011635399311826165		[learning rate: 0.0035278]
	Learning Rate: 0.00352777
	LOSS [training: 0.011635399311826165 | validation: 0.012589774749855388]
	TIME [epoch: 35.4 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011473454248203731		[learning rate: 0.0035137]
	Learning Rate: 0.00351374
	LOSS [training: 0.011473454248203731 | validation: 0.009686700547299663]
	TIME [epoch: 35.5 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010862359585286191		[learning rate: 0.0034998]
	Learning Rate: 0.00349976
	LOSS [training: 0.010862359585286191 | validation: 0.009793163250499786]
	TIME [epoch: 35.4 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010062098988592642		[learning rate: 0.0034858]
	Learning Rate: 0.00348584
	LOSS [training: 0.010062098988592642 | validation: 0.008392010925668032]
	TIME [epoch: 35.4 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010437379005106993		[learning rate: 0.003472]
	Learning Rate: 0.00347198
	LOSS [training: 0.010437379005106993 | validation: 0.008877178063212497]
	TIME [epoch: 35.4 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01109878400469278		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.01109878400469278 | validation: 0.0102188525479258]
	TIME [epoch: 35.4 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010461687374553075		[learning rate: 0.0034444]
	Learning Rate: 0.00344441
	LOSS [training: 0.010461687374553075 | validation: 0.007627155017861785]
	TIME [epoch: 35.4 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008907916898008218		[learning rate: 0.0034307]
	Learning Rate: 0.00343071
	LOSS [training: 0.008907916898008218 | validation: 0.009520460793226933]
	TIME [epoch: 35.4 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00936384084521174		[learning rate: 0.0034171]
	Learning Rate: 0.00341707
	LOSS [training: 0.00936384084521174 | validation: 0.009306984754316723]
	TIME [epoch: 35.4 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010617118630161812		[learning rate: 0.0034035]
	Learning Rate: 0.00340348
	LOSS [training: 0.010617118630161812 | validation: 0.00755432833508126]
	TIME [epoch: 35.4 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009129447544716878		[learning rate: 0.0033899]
	Learning Rate: 0.00338994
	LOSS [training: 0.009129447544716878 | validation: 0.009547945807740894]
	TIME [epoch: 35.4 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012120270777864005		[learning rate: 0.0033765]
	Learning Rate: 0.00337646
	LOSS [training: 0.012120270777864005 | validation: 0.0074203656876841665]
	TIME [epoch: 35.4 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009087826160308133		[learning rate: 0.003363]
	Learning Rate: 0.00336303
	LOSS [training: 0.009087826160308133 | validation: 0.007381447343268297]
	TIME [epoch: 35.4 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00897777951495034		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.00897777951495034 | validation: 0.008042257812513855]
	TIME [epoch: 35.4 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01018158502978483		[learning rate: 0.0033363]
	Learning Rate: 0.00333633
	LOSS [training: 0.01018158502978483 | validation: 0.008035469434494655]
	TIME [epoch: 35.4 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010036818891184266		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.010036818891184266 | validation: 0.009094235510203528]
	TIME [epoch: 35.4 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009447701449955966		[learning rate: 0.0033098]
	Learning Rate: 0.00330985
	LOSS [training: 0.009447701449955966 | validation: 0.009653129641673433]
	TIME [epoch: 35.4 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009820625207954316		[learning rate: 0.0032967]
	Learning Rate: 0.00329668
	LOSS [training: 0.009820625207954316 | validation: 0.009294500575048536]
	TIME [epoch: 35.4 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009562445956315863		[learning rate: 0.0032836]
	Learning Rate: 0.00328357
	LOSS [training: 0.009562445956315863 | validation: 0.00858536795303097]
	TIME [epoch: 35.4 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009384072099146233		[learning rate: 0.0032705]
	Learning Rate: 0.00327051
	LOSS [training: 0.009384072099146233 | validation: 0.007207201480404426]
	TIME [epoch: 35.4 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010720240258353794		[learning rate: 0.0032575]
	Learning Rate: 0.0032575
	LOSS [training: 0.010720240258353794 | validation: 0.008243193109938573]
	TIME [epoch: 35.5 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009110069801941971		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.009110069801941971 | validation: 0.011067004062644787]
	TIME [epoch: 35.4 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011032615422147727		[learning rate: 0.0032316]
	Learning Rate: 0.00323164
	LOSS [training: 0.011032615422147727 | validation: 0.007562301238850706]
	TIME [epoch: 35.4 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009476563462646572		[learning rate: 0.0032188]
	Learning Rate: 0.00321879
	LOSS [training: 0.009476563462646572 | validation: 0.012256770655999793]
	TIME [epoch: 35.4 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009380877875005385		[learning rate: 0.003206]
	Learning Rate: 0.00320599
	LOSS [training: 0.009380877875005385 | validation: 0.007876214631638607]
	TIME [epoch: 35.4 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009406309047606		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.009406309047606 | validation: 0.008813333488485698]
	TIME [epoch: 35.4 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009928865812175468		[learning rate: 0.0031805]
	Learning Rate: 0.00318053
	LOSS [training: 0.009928865812175468 | validation: 0.008553880230446108]
	TIME [epoch: 35.4 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012339748527672055		[learning rate: 0.0031679]
	Learning Rate: 0.00316788
	LOSS [training: 0.012339748527672055 | validation: 0.007615394889247132]
	TIME [epoch: 35.4 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00874039232629719		[learning rate: 0.0031553]
	Learning Rate: 0.00315528
	LOSS [training: 0.00874039232629719 | validation: 0.008415558230134278]
	TIME [epoch: 35.4 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010382214382907191		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.010382214382907191 | validation: 0.009467549780059295]
	TIME [epoch: 35.4 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009511198489691362		[learning rate: 0.0031302]
	Learning Rate: 0.00313023
	LOSS [training: 0.009511198489691362 | validation: 0.008043414348037485]
	TIME [epoch: 35.4 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013148200368927962		[learning rate: 0.0031178]
	Learning Rate: 0.00311779
	LOSS [training: 0.013148200368927962 | validation: 0.008186399083726129]
	TIME [epoch: 35.5 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009369775124644618		[learning rate: 0.0031054]
	Learning Rate: 0.00310538
	LOSS [training: 0.009369775124644618 | validation: 0.007050828722756064]
	TIME [epoch: 35.4 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009686577231630583		[learning rate: 0.003093]
	Learning Rate: 0.00309303
	LOSS [training: 0.009686577231630583 | validation: 0.008111302760146906]
	TIME [epoch: 35.4 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008846560274464862		[learning rate: 0.0030807]
	Learning Rate: 0.00308073
	LOSS [training: 0.008846560274464862 | validation: 0.007841252078993133]
	TIME [epoch: 35.4 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009775350041301607		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.009775350041301607 | validation: 0.0072895353014970216]
	TIME [epoch: 35.4 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00887087319933635		[learning rate: 0.0030563]
	Learning Rate: 0.00305627
	LOSS [training: 0.00887087319933635 | validation: 0.007520299795831789]
	TIME [epoch: 35.4 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009096460980098527		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.009096460980098527 | validation: 0.008370658560303777]
	TIME [epoch: 35.4 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011442677843045729		[learning rate: 0.003032]
	Learning Rate: 0.00303201
	LOSS [training: 0.011442677843045729 | validation: 0.0085457594969441]
	TIME [epoch: 35.4 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01072111984900328		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.01072111984900328 | validation: 0.0070126362362647795]
	TIME [epoch: 35.4 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008571931049288765		[learning rate: 0.0030079]
	Learning Rate: 0.00300794
	LOSS [training: 0.008571931049288765 | validation: 0.0070342366988999944]
	TIME [epoch: 35.4 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009265588385335897		[learning rate: 0.002996]
	Learning Rate: 0.00299598
	LOSS [training: 0.009265588385335897 | validation: 0.008827178925247177]
	TIME [epoch: 35.4 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008878524184909259		[learning rate: 0.0029841]
	Learning Rate: 0.00298406
	LOSS [training: 0.008878524184909259 | validation: 0.010667414026277822]
	TIME [epoch: 35.4 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011377922383935554		[learning rate: 0.0029722]
	Learning Rate: 0.00297219
	LOSS [training: 0.011377922383935554 | validation: 0.008244395036202742]
	TIME [epoch: 35.4 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008886830892738265		[learning rate: 0.0029604]
	Learning Rate: 0.00296037
	LOSS [training: 0.008886830892738265 | validation: 0.007468040779992978]
	TIME [epoch: 35.4 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009001560937051758		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.009001560937051758 | validation: 0.008603451510749403]
	TIME [epoch: 35.4 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009145785248801636		[learning rate: 0.0029369]
	Learning Rate: 0.00293687
	LOSS [training: 0.009145785248801636 | validation: 0.007590277246093608]
	TIME [epoch: 35.4 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009140110218536945		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.009140110218536945 | validation: 0.008446118552109786]
	TIME [epoch: 35.4 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010109545735621069		[learning rate: 0.0029136]
	Learning Rate: 0.00291355
	LOSS [training: 0.010109545735621069 | validation: 0.012973635103127688]
	TIME [epoch: 35.4 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010885840063285867		[learning rate: 0.002902]
	Learning Rate: 0.00290197
	LOSS [training: 0.010885840063285867 | validation: 0.008340831400724325]
	TIME [epoch: 35.3 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010204034808888936		[learning rate: 0.0028904]
	Learning Rate: 0.00289042
	LOSS [training: 0.010204034808888936 | validation: 0.008743351489956783]
	TIME [epoch: 35.4 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008789506659243551		[learning rate: 0.0028789]
	Learning Rate: 0.00287893
	LOSS [training: 0.008789506659243551 | validation: 0.006807180730664958]
	TIME [epoch: 35.4 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_357.pth
	Model improved!!!
EPOCH 358/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008715703883346273		[learning rate: 0.0028675]
	Learning Rate: 0.00286748
	LOSS [training: 0.008715703883346273 | validation: 0.00788547520963427]
	TIME [epoch: 35.5 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009387743246409706		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.009387743246409706 | validation: 0.008316190272888865]
	TIME [epoch: 35.4 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01052762619952361		[learning rate: 0.0028447]
	Learning Rate: 0.00284471
	LOSS [training: 0.01052762619952361 | validation: 0.008654992584702193]
	TIME [epoch: 35.4 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009744146317164568		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.009744146317164568 | validation: 0.007525804583726456]
	TIME [epoch: 35.3 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010415885426915622		[learning rate: 0.0028221]
	Learning Rate: 0.00282213
	LOSS [training: 0.010415885426915622 | validation: 0.01063589651958111]
	TIME [epoch: 35.3 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010424142201909679		[learning rate: 0.0028109]
	Learning Rate: 0.00281091
	LOSS [training: 0.010424142201909679 | validation: 0.008305194799250706]
	TIME [epoch: 35.3 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009875886250306628		[learning rate: 0.0027997]
	Learning Rate: 0.00279973
	LOSS [training: 0.009875886250306628 | validation: 0.008399411327411895]
	TIME [epoch: 35.4 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010130341715110862		[learning rate: 0.0027886]
	Learning Rate: 0.00278859
	LOSS [training: 0.010130341715110862 | validation: 0.008149017177546711]
	TIME [epoch: 35.4 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009434772754139247		[learning rate: 0.0027775]
	Learning Rate: 0.0027775
	LOSS [training: 0.009434772754139247 | validation: 0.0077428952789199675]
	TIME [epoch: 35.4 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009664084696165424		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.009664084696165424 | validation: 0.008439109574871746]
	TIME [epoch: 35.4 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008724236711344618		[learning rate: 0.0027554]
	Learning Rate: 0.00275545
	LOSS [training: 0.008724236711344618 | validation: 0.008534843006642983]
	TIME [epoch: 35.4 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009656667665184552		[learning rate: 0.0027445]
	Learning Rate: 0.00274449
	LOSS [training: 0.009656667665184552 | validation: 0.006690649201203064]
	TIME [epoch: 35.4 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_369.pth
	Model improved!!!
EPOCH 370/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009632892434603059		[learning rate: 0.0027336]
	Learning Rate: 0.00273357
	LOSS [training: 0.009632892434603059 | validation: 0.009092464234223946]
	TIME [epoch: 35.5 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01033135402077292		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.01033135402077292 | validation: 0.007888162207480037]
	TIME [epoch: 35.3 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009717679607119155		[learning rate: 0.0027119]
	Learning Rate: 0.00271187
	LOSS [training: 0.009717679607119155 | validation: 0.007763379267474231]
	TIME [epoch: 35.4 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008331331175680119		[learning rate: 0.0027011]
	Learning Rate: 0.00270109
	LOSS [training: 0.008331331175680119 | validation: 0.007809550615685485]
	TIME [epoch: 35.4 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01049172141529515		[learning rate: 0.0026903]
	Learning Rate: 0.00269034
	LOSS [training: 0.01049172141529515 | validation: 0.010835681822194246]
	TIME [epoch: 35.5 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009779065374518281		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.009779065374518281 | validation: 0.008270162355111648]
	TIME [epoch: 35.3 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009835536743650584		[learning rate: 0.002669]
	Learning Rate: 0.00266899
	LOSS [training: 0.009835536743650584 | validation: 0.007886668517849338]
	TIME [epoch: 35.4 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01013205737602639		[learning rate: 0.0026584]
	Learning Rate: 0.00265837
	LOSS [training: 0.01013205737602639 | validation: 0.007525852550030248]
	TIME [epoch: 35.4 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010297561041175374		[learning rate: 0.0026478]
	Learning Rate: 0.0026478
	LOSS [training: 0.010297561041175374 | validation: 0.00883767518637368]
	TIME [epoch: 35.4 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010924866090383973		[learning rate: 0.0026373]
	Learning Rate: 0.00263727
	LOSS [training: 0.010924866090383973 | validation: 0.007589773357544449]
	TIME [epoch: 35.3 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009258834582851424		[learning rate: 0.0026268]
	Learning Rate: 0.00262678
	LOSS [training: 0.009258834582851424 | validation: 0.010452351371658874]
	TIME [epoch: 35.4 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009685697783876663		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.009685697783876663 | validation: 0.010661410890725254]
	TIME [epoch: 35.4 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009878895954226004		[learning rate: 0.0026059]
	Learning Rate: 0.00260592
	LOSS [training: 0.009878895954226004 | validation: 0.007465685518115982]
	TIME [epoch: 35.4 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009568710621607433		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.009568710621607433 | validation: 0.0075754589340506105]
	TIME [epoch: 35.4 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009757128093640278		[learning rate: 0.0025852]
	Learning Rate: 0.00258523
	LOSS [training: 0.009757128093640278 | validation: 0.009043812121383854]
	TIME [epoch: 35.4 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008734674736198933		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.008734674736198933 | validation: 0.0103814379786142]
	TIME [epoch: 35.3 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00982877417157749		[learning rate: 0.0025647]
	Learning Rate: 0.00256471
	LOSS [training: 0.00982877417157749 | validation: 0.008797102292329075]
	TIME [epoch: 35.4 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00952392271588284		[learning rate: 0.0025545]
	Learning Rate: 0.00255451
	LOSS [training: 0.00952392271588284 | validation: 0.0084997558005854]
	TIME [epoch: 35.3 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012311940830555356		[learning rate: 0.0025444]
	Learning Rate: 0.00254435
	LOSS [training: 0.012311940830555356 | validation: 0.006952721075959012]
	TIME [epoch: 35.3 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009327729537697409		[learning rate: 0.0025342]
	Learning Rate: 0.00253423
	LOSS [training: 0.009327729537697409 | validation: 0.00927498473815434]
	TIME [epoch: 35.3 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008668718416049995		[learning rate: 0.0025242]
	Learning Rate: 0.00252415
	LOSS [training: 0.008668718416049995 | validation: 0.008331487486741706]
	TIME [epoch: 35.3 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009511188981515437		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.009511188981515437 | validation: 0.008190063545708736]
	TIME [epoch: 35.4 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008609792730579477		[learning rate: 0.0025041]
	Learning Rate: 0.00250411
	LOSS [training: 0.008609792730579477 | validation: 0.009085824334730517]
	TIME [epoch: 35.3 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008846735525973893		[learning rate: 0.0024942]
	Learning Rate: 0.00249415
	LOSS [training: 0.008846735525973893 | validation: 0.011437037817410681]
	TIME [epoch: 35.4 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011175652709262289		[learning rate: 0.0024842]
	Learning Rate: 0.00248423
	LOSS [training: 0.011175652709262289 | validation: 0.007164219637056948]
	TIME [epoch: 35.3 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00950973444233333		[learning rate: 0.0024744]
	Learning Rate: 0.00247435
	LOSS [training: 0.00950973444233333 | validation: 0.008998878773792183]
	TIME [epoch: 35.3 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01120406392700534		[learning rate: 0.0024645]
	Learning Rate: 0.00246451
	LOSS [training: 0.01120406392700534 | validation: 0.007416328516280256]
	TIME [epoch: 35.3 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00840012719977261		[learning rate: 0.0024547]
	Learning Rate: 0.00245471
	LOSS [training: 0.00840012719977261 | validation: 0.008533607818618167]
	TIME [epoch: 35.3 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008785415775639384		[learning rate: 0.0024449]
	Learning Rate: 0.00244495
	LOSS [training: 0.008785415775639384 | validation: 0.009140631797992457]
	TIME [epoch: 35.4 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010749451480347672		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.010749451480347672 | validation: 0.007589687132056558]
	TIME [epoch: 35.3 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009421129676248929		[learning rate: 0.0024255]
	Learning Rate: 0.00242554
	LOSS [training: 0.009421129676248929 | validation: 0.00714585354570633]
	TIME [epoch: 35.3 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00884008923285124		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.00884008923285124 | validation: 0.007657231501333644]
	TIME [epoch: 35.5 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009201379660041972		[learning rate: 0.0024063]
	Learning Rate: 0.00240628
	LOSS [training: 0.009201379660041972 | validation: 0.008238818829294926]
	TIME [epoch: 35.4 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008730799790494582		[learning rate: 0.0023967]
	Learning Rate: 0.00239671
	LOSS [training: 0.008730799790494582 | validation: 0.006935411991255941]
	TIME [epoch: 35.4 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009913197570583654		[learning rate: 0.0023872]
	Learning Rate: 0.00238718
	LOSS [training: 0.009913197570583654 | validation: 0.007131576976884664]
	TIME [epoch: 35.3 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008915133930914497		[learning rate: 0.0023777]
	Learning Rate: 0.00237768
	LOSS [training: 0.008915133930914497 | validation: 0.007788399057531192]
	TIME [epoch: 35.4 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00924073178737776		[learning rate: 0.0023682]
	Learning Rate: 0.00236823
	LOSS [training: 0.00924073178737776 | validation: 0.007115485586149291]
	TIME [epoch: 35.3 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009390464229270283		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.009390464229270283 | validation: 0.007213984675139566]
	TIME [epoch: 35.4 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009627319199969599		[learning rate: 0.0023494]
	Learning Rate: 0.00234942
	LOSS [training: 0.009627319199969599 | validation: 0.01223971849606825]
	TIME [epoch: 35.3 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010240748486371763		[learning rate: 0.0023401]
	Learning Rate: 0.00234008
	LOSS [training: 0.010240748486371763 | validation: 0.0071987711433752115]
	TIME [epoch: 35.4 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008838401187136993		[learning rate: 0.0023308]
	Learning Rate: 0.00233077
	LOSS [training: 0.008838401187136993 | validation: 0.008627871055620868]
	TIME [epoch: 35.3 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009768983700861189		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.009768983700861189 | validation: 0.007010130747101351]
	TIME [epoch: 35.4 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009027349053389847		[learning rate: 0.0023123]
	Learning Rate: 0.00231227
	LOSS [training: 0.009027349053389847 | validation: 0.00767017027866373]
	TIME [epoch: 35.2 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008820534836414977		[learning rate: 0.0023031]
	Learning Rate: 0.00230307
	LOSS [training: 0.008820534836414977 | validation: 0.008203752744157513]
	TIME [epoch: 35.4 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010203998783020855		[learning rate: 0.0022939]
	Learning Rate: 0.00229391
	LOSS [training: 0.010203998783020855 | validation: 0.00886628638089316]
	TIME [epoch: 35.3 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010223008344792185		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.010223008344792185 | validation: 0.0073617558672914914]
	TIME [epoch: 35.3 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009982086973328325		[learning rate: 0.0022757]
	Learning Rate: 0.0022757
	LOSS [training: 0.009982086973328325 | validation: 0.008021399364583312]
	TIME [epoch: 35.4 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010764691481442422		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.010764691481442422 | validation: 0.007707896410338093]
	TIME [epoch: 35.5 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008752930388233018		[learning rate: 0.0022576]
	Learning Rate: 0.00225764
	LOSS [training: 0.008752930388233018 | validation: 0.009103485813929392]
	TIME [epoch: 35.3 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009594966503366505		[learning rate: 0.0022487]
	Learning Rate: 0.00224866
	LOSS [training: 0.009594966503366505 | validation: 0.006945480140061284]
	TIME [epoch: 35.4 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008725179073553965		[learning rate: 0.0022397]
	Learning Rate: 0.00223971
	LOSS [training: 0.008725179073553965 | validation: 0.008797380681513133]
	TIME [epoch: 35.3 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008323890071914496		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.008323890071914496 | validation: 0.007375741372999958]
	TIME [epoch: 35.4 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008734581583275459		[learning rate: 0.0022219]
	Learning Rate: 0.00222193
	LOSS [training: 0.008734581583275459 | validation: 0.007882103174392757]
	TIME [epoch: 35.4 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009747500368682195		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.009747500368682195 | validation: 0.007562481688246888]
	TIME [epoch: 35.6 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008738769532901989		[learning rate: 0.0022043]
	Learning Rate: 0.00220429
	LOSS [training: 0.008738769532901989 | validation: 0.007837688528004061]
	TIME [epoch: 35.5 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008707964082169312		[learning rate: 0.0021955]
	Learning Rate: 0.00219553
	LOSS [training: 0.008707964082169312 | validation: 0.008518917826569265]
	TIME [epoch: 35.5 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00998877292643388		[learning rate: 0.0021868]
	Learning Rate: 0.00218679
	LOSS [training: 0.00998877292643388 | validation: 0.007830042380580738]
	TIME [epoch: 35.3 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009607510609829886		[learning rate: 0.0021781]
	Learning Rate: 0.0021781
	LOSS [training: 0.009607510609829886 | validation: 0.008590531741648864]
	TIME [epoch: 35.4 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01002836353953575		[learning rate: 0.0021694]
	Learning Rate: 0.00216943
	LOSS [training: 0.01002836353953575 | validation: 0.007417132243885033]
	TIME [epoch: 35.3 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009258612545326948		[learning rate: 0.0021608]
	Learning Rate: 0.0021608
	LOSS [training: 0.009258612545326948 | validation: 0.00725664335678184]
	TIME [epoch: 35.4 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009265629047745388		[learning rate: 0.0021522]
	Learning Rate: 0.00215221
	LOSS [training: 0.009265629047745388 | validation: 0.007324527318489632]
	TIME [epoch: 35.3 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009048349897638567		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.009048349897638567 | validation: 0.008338270063420992]
	TIME [epoch: 35.4 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008748379770890003		[learning rate: 0.0021351]
	Learning Rate: 0.00213512
	LOSS [training: 0.008748379770890003 | validation: 0.007433841505501611]
	TIME [epoch: 35.3 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008592365607240715		[learning rate: 0.0021266]
	Learning Rate: 0.00212663
	LOSS [training: 0.008592365607240715 | validation: 0.00764162093436529]
	TIME [epoch: 35.3 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00906862058932554		[learning rate: 0.0021182]
	Learning Rate: 0.00211817
	LOSS [training: 0.00906862058932554 | validation: 0.007273995508245297]
	TIME [epoch: 35.3 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010359827621669185		[learning rate: 0.0021097]
	Learning Rate: 0.00210975
	LOSS [training: 0.010359827621669185 | validation: 0.007470060485342098]
	TIME [epoch: 35.4 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009573937167048666		[learning rate: 0.0021014]
	Learning Rate: 0.00210136
	LOSS [training: 0.009573937167048666 | validation: 0.009123660716533913]
	TIME [epoch: 36.1 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010043494809261831		[learning rate: 0.002093]
	Learning Rate: 0.002093
	LOSS [training: 0.010043494809261831 | validation: 0.007440398719442834]
	TIME [epoch: 36 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008172984310757553		[learning rate: 0.0020847]
	Learning Rate: 0.00208468
	LOSS [training: 0.008172984310757553 | validation: 0.0090664906195141]
	TIME [epoch: 36 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009157168075871353		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.009157168075871353 | validation: 0.009589584871573496]
	TIME [epoch: 36.1 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012709186287431814		[learning rate: 0.0020681]
	Learning Rate: 0.00206813
	LOSS [training: 0.012709186287431814 | validation: 0.00829931316381269]
	TIME [epoch: 36.1 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009258278277966225		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.009258278277966225 | validation: 0.00838621763921302]
	TIME [epoch: 36.1 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008905569807026718		[learning rate: 0.0020517]
	Learning Rate: 0.00205171
	LOSS [training: 0.008905569807026718 | validation: 0.007677652550903616]
	TIME [epoch: 36.1 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010087363925737922		[learning rate: 0.0020435]
	Learning Rate: 0.00204355
	LOSS [training: 0.010087363925737922 | validation: 0.007361798148236018]
	TIME [epoch: 36.1 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00936827925276905		[learning rate: 0.0020354]
	Learning Rate: 0.00203542
	LOSS [training: 0.00936827925276905 | validation: 0.008009813798802737]
	TIME [epoch: 36 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011616184988454443		[learning rate: 0.0020273]
	Learning Rate: 0.00202732
	LOSS [training: 0.011616184988454443 | validation: 0.006967809961245899]
	TIME [epoch: 35.8 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008387485043695665		[learning rate: 0.0020193]
	Learning Rate: 0.00201926
	LOSS [training: 0.008387485043695665 | validation: 0.007353236454369879]
	TIME [epoch: 35.5 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008934493314191352		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.008934493314191352 | validation: 0.006995019287898074]
	TIME [epoch: 35.5 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010482362272354405		[learning rate: 0.0020032]
	Learning Rate: 0.00200323
	LOSS [training: 0.010482362272354405 | validation: 0.007457170868923968]
	TIME [epoch: 35.3 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010375489161677735		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.010375489161677735 | validation: 0.007592933242786248]
	TIME [epoch: 35.3 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009302968526589442		[learning rate: 0.0019873]
	Learning Rate: 0.00198733
	LOSS [training: 0.009302968526589442 | validation: 0.007527752091860562]
	TIME [epoch: 35.2 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009526701369018861		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.009526701369018861 | validation: 0.007919843238793889]
	TIME [epoch: 35.3 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009715065571294534		[learning rate: 0.0019715]
	Learning Rate: 0.00197155
	LOSS [training: 0.009715065571294534 | validation: 0.008010763445213818]
	TIME [epoch: 35.2 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009600650738263529		[learning rate: 0.0019637]
	Learning Rate: 0.00196371
	LOSS [training: 0.009600650738263529 | validation: 0.007345638698596666]
	TIME [epoch: 35.3 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008775700477709448		[learning rate: 0.0019559]
	Learning Rate: 0.0019559
	LOSS [training: 0.008775700477709448 | validation: 0.007725768506063231]
	TIME [epoch: 35.3 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00879921531035155		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.00879921531035155 | validation: 0.008165424801931947]
	TIME [epoch: 36.1 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01217953651693033		[learning rate: 0.0019404]
	Learning Rate: 0.00194037
	LOSS [training: 0.01217953651693033 | validation: 0.006834663732423088]
	TIME [epoch: 36 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010027721860629897		[learning rate: 0.0019327]
	Learning Rate: 0.00193265
	LOSS [training: 0.010027721860629897 | validation: 0.007517472122687896]
	TIME [epoch: 36 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008490260556487375		[learning rate: 0.001925]
	Learning Rate: 0.00192497
	LOSS [training: 0.008490260556487375 | validation: 0.007566027688880102]
	TIME [epoch: 36.1 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008560484282989573		[learning rate: 0.0019173]
	Learning Rate: 0.00191731
	LOSS [training: 0.008560484282989573 | validation: 0.006756087745395556]
	TIME [epoch: 36.2 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00835468083940427		[learning rate: 0.0019097]
	Learning Rate: 0.00190968
	LOSS [training: 0.00835468083940427 | validation: 0.0071830546085904735]
	TIME [epoch: 36.1 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009727478716277806		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.009727478716277806 | validation: 0.0080931669096592]
	TIME [epoch: 36 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009683333186468135		[learning rate: 0.0018945]
	Learning Rate: 0.00189452
	LOSS [training: 0.009683333186468135 | validation: 0.006993831380639595]
	TIME [epoch: 36 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010190437745951112		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.010190437745951112 | validation: 0.006771495824591205]
	TIME [epoch: 35.9 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008690129378184405		[learning rate: 0.0018795]
	Learning Rate: 0.00187948
	LOSS [training: 0.008690129378184405 | validation: 0.0076492935121072764]
	TIME [epoch: 35.8 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009903358639431406		[learning rate: 0.001872]
	Learning Rate: 0.00187201
	LOSS [training: 0.009903358639431406 | validation: 0.007994991633406806]
	TIME [epoch: 35.6 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00877798705111507		[learning rate: 0.0018646]
	Learning Rate: 0.00186456
	LOSS [training: 0.00877798705111507 | validation: 0.007493855437701848]
	TIME [epoch: 35.5 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00857465533958724		[learning rate: 0.0018571]
	Learning Rate: 0.00185715
	LOSS [training: 0.00857465533958724 | validation: 0.007033234060516355]
	TIME [epoch: 35.4 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009900342757789476		[learning rate: 0.0018498]
	Learning Rate: 0.00184976
	LOSS [training: 0.009900342757789476 | validation: 0.007815509809470132]
	TIME [epoch: 35.2 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009825428483586748		[learning rate: 0.0018424]
	Learning Rate: 0.0018424
	LOSS [training: 0.009825428483586748 | validation: 0.007665909528621931]
	TIME [epoch: 35.2 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010957718967891071		[learning rate: 0.0018351]
	Learning Rate: 0.00183508
	LOSS [training: 0.010957718967891071 | validation: 0.007167759296075405]
	TIME [epoch: 35.2 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008803707350703101		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.008803707350703101 | validation: 0.00799006034298103]
	TIME [epoch: 35.2 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008858046176099208		[learning rate: 0.0018205]
	Learning Rate: 0.00182051
	LOSS [training: 0.008858046176099208 | validation: 0.00702108099966082]
	TIME [epoch: 35.2 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009885104151883213		[learning rate: 0.0018133]
	Learning Rate: 0.00181327
	LOSS [training: 0.009885104151883213 | validation: 0.007380409114224431]
	TIME [epoch: 35.7 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00829232386243811		[learning rate: 0.0018061]
	Learning Rate: 0.00180605
	LOSS [training: 0.00829232386243811 | validation: 0.008130160453958065]
	TIME [epoch: 36 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011456919285611844		[learning rate: 0.0017989]
	Learning Rate: 0.00179887
	LOSS [training: 0.011456919285611844 | validation: 0.008679073054559689]
	TIME [epoch: 36 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010419582549506784		[learning rate: 0.0017917]
	Learning Rate: 0.00179172
	LOSS [training: 0.010419582549506784 | validation: 0.007140729961488223]
	TIME [epoch: 36.1 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008789513410327816		[learning rate: 0.0017846]
	Learning Rate: 0.00178459
	LOSS [training: 0.008789513410327816 | validation: 0.00685259057762103]
	TIME [epoch: 36.1 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009074459185178041		[learning rate: 0.0017775]
	Learning Rate: 0.00177749
	LOSS [training: 0.009074459185178041 | validation: 0.007424292558279406]
	TIME [epoch: 36.1 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00973875604584284		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.00973875604584284 | validation: 0.007963135613597853]
	TIME [epoch: 36.1 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008484177527283235		[learning rate: 0.0017634]
	Learning Rate: 0.00176338
	LOSS [training: 0.008484177527283235 | validation: 0.008004770254228043]
	TIME [epoch: 36 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010637014049383848		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.010637014049383848 | validation: 0.007664400835297421]
	TIME [epoch: 36.1 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01014856986200599		[learning rate: 0.0017494]
	Learning Rate: 0.00174938
	LOSS [training: 0.01014856986200599 | validation: 0.006810196132482916]
	TIME [epoch: 36.1 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008539766259178608		[learning rate: 0.0017424]
	Learning Rate: 0.00174242
	LOSS [training: 0.008539766259178608 | validation: 0.0080276731088696]
	TIME [epoch: 35.5 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008668111159512482		[learning rate: 0.0017355]
	Learning Rate: 0.00173549
	LOSS [training: 0.008668111159512482 | validation: 0.008060347931020537]
	TIME [epoch: 35.6 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008855513013205352		[learning rate: 0.0017286]
	Learning Rate: 0.00172859
	LOSS [training: 0.008855513013205352 | validation: 0.007150023802647421]
	TIME [epoch: 35.3 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009530060172037634		[learning rate: 0.0017217]
	Learning Rate: 0.00172172
	LOSS [training: 0.009530060172037634 | validation: 0.007181098506766173]
	TIME [epoch: 35.2 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008161114347799196		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.008161114347799196 | validation: 0.00819459623377405]
	TIME [epoch: 35.2 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009590381880801814		[learning rate: 0.001708]
	Learning Rate: 0.00170805
	LOSS [training: 0.009590381880801814 | validation: 0.007722801795257479]
	TIME [epoch: 35.2 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009187193724816085		[learning rate: 0.0017013]
	Learning Rate: 0.00170125
	LOSS [training: 0.009187193724816085 | validation: 0.007787805992269492]
	TIME [epoch: 35.2 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009076699356399444		[learning rate: 0.0016945]
	Learning Rate: 0.00169449
	LOSS [training: 0.009076699356399444 | validation: 0.0071205979025521825]
	TIME [epoch: 35.2 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009151566389665326		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.009151566389665326 | validation: 0.008368634727123871]
	TIME [epoch: 35.7 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009861227458989992		[learning rate: 0.001681]
	Learning Rate: 0.00168104
	LOSS [training: 0.009861227458989992 | validation: 0.0071619627148542]
	TIME [epoch: 35.7 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008494298736824411		[learning rate: 0.0016743]
	Learning Rate: 0.00167435
	LOSS [training: 0.008494298736824411 | validation: 0.008547432685873494]
	TIME [epoch: 36 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008917526215145792		[learning rate: 0.0016677]
	Learning Rate: 0.00166769
	LOSS [training: 0.008917526215145792 | validation: 0.007407263257744909]
	TIME [epoch: 36 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008065813916362612		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.008065813916362612 | validation: 0.0071249001520793]
	TIME [epoch: 36.1 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009101157010648326		[learning rate: 0.0016545]
	Learning Rate: 0.00165445
	LOSS [training: 0.009101157010648326 | validation: 0.009469909987379498]
	TIME [epoch: 36.1 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008778245684527515		[learning rate: 0.0016479]
	Learning Rate: 0.00164787
	LOSS [training: 0.008778245684527515 | validation: 0.007235001786372361]
	TIME [epoch: 36.1 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00873284895673783		[learning rate: 0.0016413]
	Learning Rate: 0.00164132
	LOSS [training: 0.00873284895673783 | validation: 0.008433386685622388]
	TIME [epoch: 36.1 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008362148603651143		[learning rate: 0.0016348]
	Learning Rate: 0.00163479
	LOSS [training: 0.008362148603651143 | validation: 0.0072382418113853845]
	TIME [epoch: 36.1 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008575351051927665		[learning rate: 0.0016283]
	Learning Rate: 0.00162829
	LOSS [training: 0.008575351051927665 | validation: 0.007408044033039447]
	TIME [epoch: 36.1 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008252578224509631		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.008252578224509631 | validation: 0.007403392455144644]
	TIME [epoch: 35.4 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008542509631231687		[learning rate: 0.0016154]
	Learning Rate: 0.00161536
	LOSS [training: 0.008542509631231687 | validation: 0.007530728875333988]
	TIME [epoch: 35.2 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008423807548662197		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.008423807548662197 | validation: 0.007341438649693899]
	TIME [epoch: 35.3 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008379805347769996		[learning rate: 0.0016025]
	Learning Rate: 0.00160254
	LOSS [training: 0.008379805347769996 | validation: 0.0075855800233068]
	TIME [epoch: 35.3 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009307037504672513		[learning rate: 0.0015962]
	Learning Rate: 0.00159616
	LOSS [training: 0.009307037504672513 | validation: 0.0073428190694104735]
	TIME [epoch: 35.3 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010159544814347124		[learning rate: 0.0015898]
	Learning Rate: 0.00158981
	LOSS [training: 0.010159544814347124 | validation: 0.007329880017497592]
	TIME [epoch: 35.2 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008738618410112595		[learning rate: 0.0015835]
	Learning Rate: 0.00158349
	LOSS [training: 0.008738618410112595 | validation: 0.007469380081880304]
	TIME [epoch: 35.3 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00877921446514765		[learning rate: 0.0015772]
	Learning Rate: 0.00157719
	LOSS [training: 0.00877921446514765 | validation: 0.00739293264531081]
	TIME [epoch: 35.5 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009681633788641276		[learning rate: 0.0015709]
	Learning Rate: 0.00157092
	LOSS [training: 0.009681633788641276 | validation: 0.007163792287074618]
	TIME [epoch: 36.1 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008169164985135202		[learning rate: 0.0015647]
	Learning Rate: 0.00156467
	LOSS [training: 0.008169164985135202 | validation: 0.0077853503299170875]
	TIME [epoch: 36 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010408887712564003		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.010408887712564003 | validation: 0.007585743663930611]
	TIME [epoch: 36.1 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008675509021878748		[learning rate: 0.0015522]
	Learning Rate: 0.00155225
	LOSS [training: 0.008675509021878748 | validation: 0.007712136541009997]
	TIME [epoch: 36 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008287347241379929		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.008287347241379929 | validation: 0.007067943587686147]
	TIME [epoch: 36.1 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007704618921449032		[learning rate: 0.0015399]
	Learning Rate: 0.00153993
	LOSS [training: 0.007704618921449032 | validation: 0.009190340745739841]
	TIME [epoch: 36 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008957957889602798		[learning rate: 0.0015338]
	Learning Rate: 0.0015338
	LOSS [training: 0.008957957889602798 | validation: 0.007548450222158856]
	TIME [epoch: 36 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009702645857331701		[learning rate: 0.0015277]
	Learning Rate: 0.0015277
	LOSS [training: 0.009702645857331701 | validation: 0.007097250526844863]
	TIME [epoch: 36 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009599638108832912		[learning rate: 0.0015216]
	Learning Rate: 0.00152163
	LOSS [training: 0.009599638108832912 | validation: 0.007259307065019055]
	TIME [epoch: 35.7 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00848926463511016		[learning rate: 0.0015156]
	Learning Rate: 0.00151557
	LOSS [training: 0.00848926463511016 | validation: 0.008378762873689341]
	TIME [epoch: 35.5 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008952001028121818		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.008952001028121818 | validation: 0.007214937294060783]
	TIME [epoch: 35.5 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008618603331140175		[learning rate: 0.0015035]
	Learning Rate: 0.00150354
	LOSS [training: 0.008618603331140175 | validation: 0.00786633919296155]
	TIME [epoch: 35.3 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008610173803191654		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.008610173803191654 | validation: 0.009262104478286673]
	TIME [epoch: 35.3 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009137092054894708		[learning rate: 0.0014916]
	Learning Rate: 0.00149161
	LOSS [training: 0.009137092054894708 | validation: 0.007233961978926255]
	TIME [epoch: 35.3 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01016215943745397		[learning rate: 0.0014857]
	Learning Rate: 0.00148567
	LOSS [training: 0.01016215943745397 | validation: 0.007055787789806797]
	TIME [epoch: 35.3 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00974505461362928		[learning rate: 0.0014798]
	Learning Rate: 0.00147976
	LOSS [training: 0.00974505461362928 | validation: 0.006777512907732311]
	TIME [epoch: 35.3 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008584301084372609		[learning rate: 0.0014739]
	Learning Rate: 0.00147388
	LOSS [training: 0.008584301084372609 | validation: 0.009824600328271557]
	TIME [epoch: 35.3 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011376813333258051		[learning rate: 0.001468]
	Learning Rate: 0.00146802
	LOSS [training: 0.011376813333258051 | validation: 0.006769939405817421]
	TIME [epoch: 35.2 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00831163932443194		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.00831163932443194 | validation: 0.008592728839509373]
	TIME [epoch: 36 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009816282646275336		[learning rate: 0.0014564]
	Learning Rate: 0.00145636
	LOSS [training: 0.009816282646275336 | validation: 0.0076046688265486535]
	TIME [epoch: 36.1 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008259955801758556		[learning rate: 0.0014506]
	Learning Rate: 0.00145057
	LOSS [training: 0.008259955801758556 | validation: 0.006963555000542266]
	TIME [epoch: 36 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008608785303790957		[learning rate: 0.0014448]
	Learning Rate: 0.0014448
	LOSS [training: 0.008608785303790957 | validation: 0.00734279819986147]
	TIME [epoch: 36.1 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009646610381246618		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.009646610381246618 | validation: 0.007038823219441902]
	TIME [epoch: 36.2 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01045649158346926		[learning rate: 0.0014333]
	Learning Rate: 0.00143333
	LOSS [training: 0.01045649158346926 | validation: 0.008674819635176459]
	TIME [epoch: 36.1 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009583033951575509		[learning rate: 0.0014276]
	Learning Rate: 0.00142763
	LOSS [training: 0.009583033951575509 | validation: 0.007280074718939394]
	TIME [epoch: 36.2 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009342767702740081		[learning rate: 0.001422]
	Learning Rate: 0.00142195
	LOSS [training: 0.009342767702740081 | validation: 0.007464245968700212]
	TIME [epoch: 36.1 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009159830013839292		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.009159830013839292 | validation: 0.008092014557108557]
	TIME [epoch: 36 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009669407097265367		[learning rate: 0.0014107]
	Learning Rate: 0.00141066
	LOSS [training: 0.009669407097265367 | validation: 0.0073018572983865855]
	TIME [epoch: 36.2 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008435944841520722		[learning rate: 0.0014051]
	Learning Rate: 0.00140505
	LOSS [training: 0.008435944841520722 | validation: 0.008414405104897335]
	TIME [epoch: 36.1 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008839796988449203		[learning rate: 0.0013995]
	Learning Rate: 0.00139946
	LOSS [training: 0.008839796988449203 | validation: 0.008346277068607976]
	TIME [epoch: 35.6 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009375877601994632		[learning rate: 0.0013939]
	Learning Rate: 0.0013939
	LOSS [training: 0.009375877601994632 | validation: 0.007144535907174063]
	TIME [epoch: 35.6 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007996154003574146		[learning rate: 0.0013884]
	Learning Rate: 0.00138835
	LOSS [training: 0.007996154003574146 | validation: 0.006660087338685642]
	TIME [epoch: 35.3 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_540.pth
	Model improved!!!
EPOCH 541/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011349300179576468		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.011349300179576468 | validation: 0.008216326990358533]
	TIME [epoch: 35.4 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009574036873193532		[learning rate: 0.0013773]
	Learning Rate: 0.00137733
	LOSS [training: 0.009574036873193532 | validation: 0.006731913226031168]
	TIME [epoch: 35.2 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008604680771984214		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.008604680771984214 | validation: 0.006796568340432185]
	TIME [epoch: 35.2 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008691653794157577		[learning rate: 0.0013664]
	Learning Rate: 0.0013664
	LOSS [training: 0.008691653794157577 | validation: 0.00844822992091109]
	TIME [epoch: 35.2 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009723787320184096		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.009723787320184096 | validation: 0.007420856781911872]
	TIME [epoch: 35.3 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008270083549606578		[learning rate: 0.0013555]
	Learning Rate: 0.00135555
	LOSS [training: 0.008270083549606578 | validation: 0.007615157692826609]
	TIME [epoch: 35.2 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008815988810118683		[learning rate: 0.0013502]
	Learning Rate: 0.00135016
	LOSS [training: 0.008815988810118683 | validation: 0.0074876161203218635]
	TIME [epoch: 35.3 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008373257678015576		[learning rate: 0.0013448]
	Learning Rate: 0.00134479
	LOSS [training: 0.008373257678015576 | validation: 0.007110165214463433]
	TIME [epoch: 35.3 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007956083647684638		[learning rate: 0.0013394]
	Learning Rate: 0.00133944
	LOSS [training: 0.007956083647684638 | validation: 0.006905940390045986]
	TIME [epoch: 35.3 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00841750093923403		[learning rate: 0.0013341]
	Learning Rate: 0.00133411
	LOSS [training: 0.00841750093923403 | validation: 0.007269419458996712]
	TIME [epoch: 35.2 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009307779319210837		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.009307779319210837 | validation: 0.0075955023512685755]
	TIME [epoch: 35.3 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010099842938658066		[learning rate: 0.0013235]
	Learning Rate: 0.00132352
	LOSS [training: 0.010099842938658066 | validation: 0.009093945500493056]
	TIME [epoch: 35.2 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00876618141765433		[learning rate: 0.0013183]
	Learning Rate: 0.00131826
	LOSS [training: 0.00876618141765433 | validation: 0.00788913621006134]
	TIME [epoch: 35.3 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008551033191091998		[learning rate: 0.001313]
	Learning Rate: 0.00131301
	LOSS [training: 0.008551033191091998 | validation: 0.007307656337748175]
	TIME [epoch: 35.2 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009146426837460982		[learning rate: 0.0013078]
	Learning Rate: 0.00130779
	LOSS [training: 0.009146426837460982 | validation: 0.007237246015457083]
	TIME [epoch: 35.3 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008817719920869691		[learning rate: 0.0013026]
	Learning Rate: 0.00130259
	LOSS [training: 0.008817719920869691 | validation: 0.0072929581414233665]
	TIME [epoch: 35.2 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00925786122664791		[learning rate: 0.0012974]
	Learning Rate: 0.00129741
	LOSS [training: 0.00925786122664791 | validation: 0.006860928317534887]
	TIME [epoch: 35.3 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008090993070822504		[learning rate: 0.0012922]
	Learning Rate: 0.00129225
	LOSS [training: 0.008090993070822504 | validation: 0.006870465447851211]
	TIME [epoch: 35.2 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009265378533774453		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.009265378533774453 | validation: 0.0067206604538864595]
	TIME [epoch: 35.3 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00926681581175297		[learning rate: 0.001282]
	Learning Rate: 0.00128199
	LOSS [training: 0.00926681581175297 | validation: 0.00773226443004313]
	TIME [epoch: 35.2 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00906919060604295		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.00906919060604295 | validation: 0.00685230102497548]
	TIME [epoch: 35.3 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009014141991746149		[learning rate: 0.0012718]
	Learning Rate: 0.00127181
	LOSS [training: 0.009014141991746149 | validation: 0.006788001743225465]
	TIME [epoch: 35.3 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008221076963913514		[learning rate: 0.0012668]
	Learning Rate: 0.00126675
	LOSS [training: 0.008221076963913514 | validation: 0.008653052731846458]
	TIME [epoch: 35.3 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007669172154440135		[learning rate: 0.0012617]
	Learning Rate: 0.00126172
	LOSS [training: 0.007669172154440135 | validation: 0.007289979815147479]
	TIME [epoch: 35.3 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009418640656438385		[learning rate: 0.0012567]
	Learning Rate: 0.0012567
	LOSS [training: 0.009418640656438385 | validation: 0.006856449394294599]
	TIME [epoch: 35.3 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008962036296353029		[learning rate: 0.0012517]
	Learning Rate: 0.0012517
	LOSS [training: 0.008962036296353029 | validation: 0.007938614531812363]
	TIME [epoch: 35.2 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008195174232551422		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.008195174232551422 | validation: 0.007465228547469814]
	TIME [epoch: 35.2 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00838953887171756		[learning rate: 0.0012418]
	Learning Rate: 0.00124176
	LOSS [training: 0.00838953887171756 | validation: 0.009709643445274469]
	TIME [epoch: 35.2 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008227501756290693		[learning rate: 0.0012368]
	Learning Rate: 0.00123682
	LOSS [training: 0.008227501756290693 | validation: 0.007113925693090018]
	TIME [epoch: 35.2 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008191540764764983		[learning rate: 0.0012319]
	Learning Rate: 0.0012319
	LOSS [training: 0.008191540764764983 | validation: 0.006824039324883543]
	TIME [epoch: 35.2 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012044774641754396		[learning rate: 0.001227]
	Learning Rate: 0.001227
	LOSS [training: 0.012044774641754396 | validation: 0.007397523860854296]
	TIME [epoch: 35.3 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008574127662258308		[learning rate: 0.0012221]
	Learning Rate: 0.00122212
	LOSS [training: 0.008574127662258308 | validation: 0.006585103127784683]
	TIME [epoch: 35.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_572.pth
	Model improved!!!
EPOCH 573/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008128625197876601		[learning rate: 0.0012173]
	Learning Rate: 0.00121726
	LOSS [training: 0.008128625197876601 | validation: 0.008405254661782498]
	TIME [epoch: 35.4 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00893514104788616		[learning rate: 0.0012124]
	Learning Rate: 0.00121242
	LOSS [training: 0.00893514104788616 | validation: 0.006712250420275167]
	TIME [epoch: 35.8 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008990082042634129		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.008990082042634129 | validation: 0.007472379351699776]
	TIME [epoch: 35.4 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008748766569676084		[learning rate: 0.0012028]
	Learning Rate: 0.0012028
	LOSS [training: 0.008748766569676084 | validation: 0.007341919666874525]
	TIME [epoch: 35.3 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0084083319502131		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.0084083319502131 | validation: 0.007258094932867172]
	TIME [epoch: 35.3 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00950320103221982		[learning rate: 0.0011932]
	Learning Rate: 0.00119325
	LOSS [training: 0.00950320103221982 | validation: 0.006817872413506408]
	TIME [epoch: 35.3 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008120143849711135		[learning rate: 0.0011885]
	Learning Rate: 0.0011885
	LOSS [training: 0.008120143849711135 | validation: 0.006976217080701766]
	TIME [epoch: 35.3 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008709153467763325		[learning rate: 0.0011838]
	Learning Rate: 0.00118378
	LOSS [training: 0.008709153467763325 | validation: 0.007995214287157167]
	TIME [epoch: 35.3 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010169644242420207		[learning rate: 0.0011791]
	Learning Rate: 0.00117907
	LOSS [training: 0.010169644242420207 | validation: 0.007613357948635083]
	TIME [epoch: 35.3 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009282527390167496		[learning rate: 0.0011744]
	Learning Rate: 0.00117438
	LOSS [training: 0.009282527390167496 | validation: 0.006895293665672613]
	TIME [epoch: 35.3 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008044071848890175		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.008044071848890175 | validation: 0.0075280543956317645]
	TIME [epoch: 35.3 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00909215030117374		[learning rate: 0.0011651]
	Learning Rate: 0.00116505
	LOSS [training: 0.00909215030117374 | validation: 0.007836689974678063]
	TIME [epoch: 35.3 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00944152550646344		[learning rate: 0.0011604]
	Learning Rate: 0.00116042
	LOSS [training: 0.00944152550646344 | validation: 0.006652276376721411]
	TIME [epoch: 35.3 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0086859154330407		[learning rate: 0.0011558]
	Learning Rate: 0.00115581
	LOSS [training: 0.0086859154330407 | validation: 0.006195307784813622]
	TIME [epoch: 35.3 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_586.pth
	Model improved!!!
EPOCH 587/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009176574270206864		[learning rate: 0.0011512]
	Learning Rate: 0.00115121
	LOSS [training: 0.009176574270206864 | validation: 0.006905450142577321]
	TIME [epoch: 35.4 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008164320877784794		[learning rate: 0.0011466]
	Learning Rate: 0.00114663
	LOSS [training: 0.008164320877784794 | validation: 0.007628937832109993]
	TIME [epoch: 35.3 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010007476768443054		[learning rate: 0.0011421]
	Learning Rate: 0.00114207
	LOSS [training: 0.010007476768443054 | validation: 0.0065425583577794905]
	TIME [epoch: 35.3 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011404100336580751		[learning rate: 0.0011375]
	Learning Rate: 0.00113753
	LOSS [training: 0.011404100336580751 | validation: 0.007030229833804929]
	TIME [epoch: 35.3 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008649361859781941		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.008649361859781941 | validation: 0.007533520013750317]
	TIME [epoch: 35.3 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009414828418740435		[learning rate: 0.0011285]
	Learning Rate: 0.0011285
	LOSS [training: 0.009414828418740435 | validation: 0.00702447371436159]
	TIME [epoch: 35.3 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00818013744257444		[learning rate: 0.001124]
	Learning Rate: 0.00112401
	LOSS [training: 0.00818013744257444 | validation: 0.007301046899789712]
	TIME [epoch: 35.3 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00896810570047748		[learning rate: 0.0011195]
	Learning Rate: 0.00111954
	LOSS [training: 0.00896810570047748 | validation: 0.006735722779871227]
	TIME [epoch: 35.4 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008268397540795192		[learning rate: 0.0011151]
	Learning Rate: 0.00111508
	LOSS [training: 0.008268397540795192 | validation: 0.006642137505396403]
	TIME [epoch: 35.3 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009122534638415317		[learning rate: 0.0011106]
	Learning Rate: 0.00111065
	LOSS [training: 0.009122534638415317 | validation: 0.0072449565674827954]
	TIME [epoch: 35.3 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007909444488218882		[learning rate: 0.0011062]
	Learning Rate: 0.00110623
	LOSS [training: 0.007909444488218882 | validation: 0.006966940799057714]
	TIME [epoch: 35.3 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00847721974533912		[learning rate: 0.0011018]
	Learning Rate: 0.00110183
	LOSS [training: 0.00847721974533912 | validation: 0.007315538175000552]
	TIME [epoch: 35.3 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008153439823869686		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.008153439823869686 | validation: 0.006846225528999139]
	TIME [epoch: 35.3 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008031613406160357		[learning rate: 0.0010931]
	Learning Rate: 0.00109309
	LOSS [training: 0.008031613406160357 | validation: 0.006877788370609488]
	TIME [epoch: 35.2 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00894101024389168		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.00894101024389168 | validation: 0.006992382201808436]
	TIME [epoch: 35.5 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008891515413091739		[learning rate: 0.0010844]
	Learning Rate: 0.00108441
	LOSS [training: 0.008891515413091739 | validation: 0.007646860309029698]
	TIME [epoch: 35.3 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009188578257805002		[learning rate: 0.0010801]
	Learning Rate: 0.00108009
	LOSS [training: 0.009188578257805002 | validation: 0.0069993967486123064]
	TIME [epoch: 35.3 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010266308847297432		[learning rate: 0.0010758]
	Learning Rate: 0.0010758
	LOSS [training: 0.010266308847297432 | validation: 0.0086767957103315]
	TIME [epoch: 35.3 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00765965180003881		[learning rate: 0.0010715]
	Learning Rate: 0.00107152
	LOSS [training: 0.00765965180003881 | validation: 0.0077694797575589645]
	TIME [epoch: 35.3 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008133757990517495		[learning rate: 0.0010673]
	Learning Rate: 0.00106726
	LOSS [training: 0.008133757990517495 | validation: 0.006920929839967456]
	TIME [epoch: 35.3 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009290323424809937		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.009290323424809937 | validation: 0.00680991906976137]
	TIME [epoch: 35.3 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008309589345369817		[learning rate: 0.0010588]
	Learning Rate: 0.00105878
	LOSS [training: 0.008309589345369817 | validation: 0.007182889867521065]
	TIME [epoch: 35.3 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008838312712035019		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.008838312712035019 | validation: 0.007630141033307632]
	TIME [epoch: 35.3 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007913890493517681		[learning rate: 0.0010504]
	Learning Rate: 0.00105038
	LOSS [training: 0.007913890493517681 | validation: 0.008459025026301466]
	TIME [epoch: 35.3 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00918373224601041		[learning rate: 0.0010462]
	Learning Rate: 0.0010462
	LOSS [training: 0.00918373224601041 | validation: 0.0074036638829210995]
	TIME [epoch: 35.3 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008124418198449484		[learning rate: 0.001042]
	Learning Rate: 0.00104204
	LOSS [training: 0.008124418198449484 | validation: 0.007292365446934288]
	TIME [epoch: 35.3 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008660857613137167		[learning rate: 0.0010379]
	Learning Rate: 0.0010379
	LOSS [training: 0.008660857613137167 | validation: 0.006964175017139041]
	TIME [epoch: 35.3 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009929006245008632		[learning rate: 0.0010338]
	Learning Rate: 0.00103377
	LOSS [training: 0.009929006245008632 | validation: 0.007297103023462088]
	TIME [epoch: 35.3 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008407935108861874		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.008407935108861874 | validation: 0.007925409165213807]
	TIME [epoch: 35.3 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008508517155842115		[learning rate: 0.0010256]
	Learning Rate: 0.00102556
	LOSS [training: 0.008508517155842115 | validation: 0.0069469512455030994]
	TIME [epoch: 35.3 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010788368789977874		[learning rate: 0.0010215]
	Learning Rate: 0.00102148
	LOSS [training: 0.010788368789977874 | validation: 0.007259985031909197]
	TIME [epoch: 35.3 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008976957287350833		[learning rate: 0.0010174]
	Learning Rate: 0.00101742
	LOSS [training: 0.008976957287350833 | validation: 0.006947569680450086]
	TIME [epoch: 35.3 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008462833014479998		[learning rate: 0.0010134]
	Learning Rate: 0.00101337
	LOSS [training: 0.008462833014479998 | validation: 0.007946499011338643]
	TIME [epoch: 35.3 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008895459222763672		[learning rate: 0.0010093]
	Learning Rate: 0.00100934
	LOSS [training: 0.008895459222763672 | validation: 0.00788982344369325]
	TIME [epoch: 35.3 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00824755921446524		[learning rate: 0.0010053]
	Learning Rate: 0.00100533
	LOSS [training: 0.00824755921446524 | validation: 0.00721632011698081]
	TIME [epoch: 35.6 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008712686091246329		[learning rate: 0.0010013]
	Learning Rate: 0.00100133
	LOSS [training: 0.008712686091246329 | validation: 0.006999909953276981]
	TIME [epoch: 35.3 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009256583992873095		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.009256583992873095 | validation: 0.007816247535825683]
	TIME [epoch: 35.3 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011705601287011591		[learning rate: 0.00099338]
	Learning Rate: 0.00099338
	LOSS [training: 0.011705601287011591 | validation: 0.007074536774160185]
	TIME [epoch: 35.3 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009028045034654757		[learning rate: 0.00098943]
	Learning Rate: 0.000989429
	LOSS [training: 0.009028045034654757 | validation: 0.0069256831837552334]
	TIME [epoch: 35.3 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00887939062588803		[learning rate: 0.00098549]
	Learning Rate: 0.000985494
	LOSS [training: 0.00887939062588803 | validation: 0.0071234058928188754]
	TIME [epoch: 35.3 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008147887064726954		[learning rate: 0.00098157]
	Learning Rate: 0.000981574
	LOSS [training: 0.008147887064726954 | validation: 0.0065718702891147535]
	TIME [epoch: 35.3 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008184467690041814		[learning rate: 0.00097767]
	Learning Rate: 0.00097767
	LOSS [training: 0.008184467690041814 | validation: 0.006767395262295778]
	TIME [epoch: 35.3 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008876666200284985		[learning rate: 0.00097378]
	Learning Rate: 0.000973782
	LOSS [training: 0.008876666200284985 | validation: 0.007147336210681594]
	TIME [epoch: 35.3 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008781443827414852		[learning rate: 0.00096991]
	Learning Rate: 0.000969909
	LOSS [training: 0.008781443827414852 | validation: 0.006923971836307316]
	TIME [epoch: 35.3 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008588160399585688		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.008588160399585688 | validation: 0.007352927732157651]
	TIME [epoch: 35.3 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009159935765707712		[learning rate: 0.00096221]
	Learning Rate: 0.000962209
	LOSS [training: 0.009159935765707712 | validation: 0.006796641203979212]
	TIME [epoch: 35.3 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00820004148229852		[learning rate: 0.00095838]
	Learning Rate: 0.000958382
	LOSS [training: 0.00820004148229852 | validation: 0.007212833484320646]
	TIME [epoch: 35.3 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007874274718572044		[learning rate: 0.00095457]
	Learning Rate: 0.00095457
	LOSS [training: 0.007874274718572044 | validation: 0.00675050296305933]
	TIME [epoch: 35.2 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008765324619326378		[learning rate: 0.00095077]
	Learning Rate: 0.000950773
	LOSS [training: 0.008765324619326378 | validation: 0.007800896081007142]
	TIME [epoch: 35.3 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009073359990734437		[learning rate: 0.00094699]
	Learning Rate: 0.000946992
	LOSS [training: 0.009073359990734437 | validation: 0.006981361446423277]
	TIME [epoch: 35.3 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008675456203349537		[learning rate: 0.00094323]
	Learning Rate: 0.000943225
	LOSS [training: 0.008675456203349537 | validation: 0.007200629561944015]
	TIME [epoch: 35.3 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009009335600406768		[learning rate: 0.00093947]
	Learning Rate: 0.000939474
	LOSS [training: 0.009009335600406768 | validation: 0.006398497005782861]
	TIME [epoch: 35.3 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008052535400622887		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.008052535400622887 | validation: 0.007182997006364178]
	TIME [epoch: 35.3 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007888771912686924		[learning rate: 0.00093202]
	Learning Rate: 0.000932015
	LOSS [training: 0.007888771912686924 | validation: 0.007072500687999828]
	TIME [epoch: 35.3 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008777693929087145		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.008777693929087145 | validation: 0.006717109317089359]
	TIME [epoch: 35.4 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008952612483398646		[learning rate: 0.00092462]
	Learning Rate: 0.000924616
	LOSS [training: 0.008952612483398646 | validation: 0.006733228405724989]
	TIME [epoch: 35.3 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009345036966402176		[learning rate: 0.00092094]
	Learning Rate: 0.000920939
	LOSS [training: 0.009345036966402176 | validation: 0.007053709741254616]
	TIME [epoch: 35.3 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008727401251428022		[learning rate: 0.00091728]
	Learning Rate: 0.000917276
	LOSS [training: 0.008727401251428022 | validation: 0.007316891153671121]
	TIME [epoch: 35.3 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009138613086669814		[learning rate: 0.00091363]
	Learning Rate: 0.000913628
	LOSS [training: 0.009138613086669814 | validation: 0.006636017879404763]
	TIME [epoch: 35.4 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011515549179951378		[learning rate: 0.00090999]
	Learning Rate: 0.000909994
	LOSS [training: 0.011515549179951378 | validation: 0.006461680661785008]
	TIME [epoch: 35.2 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008473077504783232		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.008473077504783232 | validation: 0.007103242484237668]
	TIME [epoch: 35.3 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008462818808491262		[learning rate: 0.00090277]
	Learning Rate: 0.00090277
	LOSS [training: 0.008462818808491262 | validation: 0.006031487724470827]
	TIME [epoch: 35.3 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_648.pth
	Model improved!!!
EPOCH 649/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008478768254137467		[learning rate: 0.00089918]
	Learning Rate: 0.000899179
	LOSS [training: 0.008478768254137467 | validation: 0.007382207500967057]
	TIME [epoch: 35.4 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009200975170696311		[learning rate: 0.0008956]
	Learning Rate: 0.000895603
	LOSS [training: 0.009200975170696311 | validation: 0.006541461479210131]
	TIME [epoch: 35.2 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009120835821105396		[learning rate: 0.00089204]
	Learning Rate: 0.000892041
	LOSS [training: 0.009120835821105396 | validation: 0.006411330658834409]
	TIME [epoch: 35.3 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008409309057434537		[learning rate: 0.00088849]
	Learning Rate: 0.000888493
	LOSS [training: 0.008409309057434537 | validation: 0.0069981293263987]
	TIME [epoch: 35.2 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008884754900789237		[learning rate: 0.00088496]
	Learning Rate: 0.000884959
	LOSS [training: 0.008884754900789237 | validation: 0.006613210137774455]
	TIME [epoch: 35.2 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007966762840544454		[learning rate: 0.00088144]
	Learning Rate: 0.000881439
	LOSS [training: 0.007966762840544454 | validation: 0.007381227480333643]
	TIME [epoch: 35.2 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007791196824650267		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.007791196824650267 | validation: 0.0070010935282289214]
	TIME [epoch: 35.3 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008441458419641439		[learning rate: 0.00087444]
	Learning Rate: 0.000874441
	LOSS [training: 0.008441458419641439 | validation: 0.00747952381011264]
	TIME [epoch: 35.3 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008481841980190863		[learning rate: 0.00087096]
	Learning Rate: 0.000870964
	LOSS [training: 0.008481841980190863 | validation: 0.006656158326097619]
	TIME [epoch: 35.2 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008196346739851862		[learning rate: 0.0008675]
	Learning Rate: 0.0008675
	LOSS [training: 0.008196346739851862 | validation: 0.007077673754155876]
	TIME [epoch: 35.2 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007811200110466723		[learning rate: 0.00086405]
	Learning Rate: 0.000864049
	LOSS [training: 0.007811200110466723 | validation: 0.007786625787798851]
	TIME [epoch: 35.2 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008269390206010592		[learning rate: 0.00086061]
	Learning Rate: 0.000860613
	LOSS [training: 0.008269390206010592 | validation: 0.007177312070506129]
	TIME [epoch: 35.3 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009314268986373199		[learning rate: 0.00085719]
	Learning Rate: 0.00085719
	LOSS [training: 0.009314268986373199 | validation: 0.007646766064368133]
	TIME [epoch: 35.2 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008178525094692428		[learning rate: 0.00085378]
	Learning Rate: 0.00085378
	LOSS [training: 0.008178525094692428 | validation: 0.0064569059289281095]
	TIME [epoch: 35.2 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008557347047692654		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.008557347047692654 | validation: 0.007485106629568747]
	TIME [epoch: 35.3 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008433215290638322		[learning rate: 0.000847]
	Learning Rate: 0.000847002
	LOSS [training: 0.008433215290638322 | validation: 0.007723367448749676]
	TIME [epoch: 35.2 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007657278462004113		[learning rate: 0.00084363]
	Learning Rate: 0.000843634
	LOSS [training: 0.007657278462004113 | validation: 0.00718694769789463]
	TIME [epoch: 35.2 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008679724961667246		[learning rate: 0.00084028]
	Learning Rate: 0.000840278
	LOSS [training: 0.008679724961667246 | validation: 0.007089990323552139]
	TIME [epoch: 35.2 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008440682198133107		[learning rate: 0.00083694]
	Learning Rate: 0.000836936
	LOSS [training: 0.008440682198133107 | validation: 0.006554340843070099]
	TIME [epoch: 35.2 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008177789861398038		[learning rate: 0.00083361]
	Learning Rate: 0.000833608
	LOSS [training: 0.008177789861398038 | validation: 0.006725423478628825]
	TIME [epoch: 35.2 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0075615169802320005		[learning rate: 0.00083029]
	Learning Rate: 0.000830292
	LOSS [training: 0.0075615169802320005 | validation: 0.007524975925585387]
	TIME [epoch: 35.2 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008591331775007373		[learning rate: 0.00082699]
	Learning Rate: 0.00082699
	LOSS [training: 0.008591331775007373 | validation: 0.007080631596301683]
	TIME [epoch: 35.2 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009440349929658797		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.009440349929658797 | validation: 0.007042142256096414]
	TIME [epoch: 35.2 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008018737151068		[learning rate: 0.00082042]
	Learning Rate: 0.000820424
	LOSS [training: 0.008018737151068 | validation: 0.007294867136863373]
	TIME [epoch: 35.3 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007887024361814321		[learning rate: 0.00081716]
	Learning Rate: 0.000817161
	LOSS [training: 0.007887024361814321 | validation: 0.006815096467097775]
	TIME [epoch: 35.2 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008393736472101055		[learning rate: 0.00081391]
	Learning Rate: 0.000813911
	LOSS [training: 0.008393736472101055 | validation: 0.006361627919440252]
	TIME [epoch: 35.3 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007972799331072509		[learning rate: 0.00081067]
	Learning Rate: 0.000810674
	LOSS [training: 0.007972799331072509 | validation: 0.006846159205637759]
	TIME [epoch: 35.3 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008597458338028656		[learning rate: 0.00080745]
	Learning Rate: 0.00080745
	LOSS [training: 0.008597458338028656 | validation: 0.005982977912404359]
	TIME [epoch: 35.3 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_676.pth
	Model improved!!!
EPOCH 677/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008655511695577125		[learning rate: 0.00080424]
	Learning Rate: 0.000804238
	LOSS [training: 0.008655511695577125 | validation: 0.007253776819489724]
	TIME [epoch: 35.3 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008816518692727144		[learning rate: 0.00080104]
	Learning Rate: 0.000801039
	LOSS [training: 0.008816518692727144 | validation: 0.006183636195277695]
	TIME [epoch: 35.2 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00826708769396723		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.00826708769396723 | validation: 0.006825019494770951]
	TIME [epoch: 35.4 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008322639475182022		[learning rate: 0.00079468]
	Learning Rate: 0.00079468
	LOSS [training: 0.008322639475182022 | validation: 0.006523441985333452]
	TIME [epoch: 35.2 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00812517569394954		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.00812517569394954 | validation: 0.0071568085916447225]
	TIME [epoch: 35.3 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007803787077197787		[learning rate: 0.00078837]
	Learning Rate: 0.000788371
	LOSS [training: 0.007803787077197787 | validation: 0.007021045135088883]
	TIME [epoch: 35.2 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0078110197221207345		[learning rate: 0.00078524]
	Learning Rate: 0.000785236
	LOSS [training: 0.0078110197221207345 | validation: 0.006673480065592932]
	TIME [epoch: 35.3 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0078380378629423		[learning rate: 0.00078211]
	Learning Rate: 0.000782113
	LOSS [training: 0.0078380378629423 | validation: 0.006575929480668341]
	TIME [epoch: 35.2 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008247797425315466		[learning rate: 0.000779]
	Learning Rate: 0.000779002
	LOSS [training: 0.008247797425315466 | validation: 0.00784516248955144]
	TIME [epoch: 35.4 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0105492533954134		[learning rate: 0.0007759]
	Learning Rate: 0.000775904
	LOSS [training: 0.0105492533954134 | validation: 0.006893754929581952]
	TIME [epoch: 35.3 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007990317955579102		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.007990317955579102 | validation: 0.006892747900513081]
	TIME [epoch: 35.3 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008381444799541664		[learning rate: 0.00076974]
	Learning Rate: 0.000769744
	LOSS [training: 0.008381444799541664 | validation: 0.006107259737955287]
	TIME [epoch: 35.2 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007770986112840397		[learning rate: 0.00076668]
	Learning Rate: 0.000766682
	LOSS [training: 0.007770986112840397 | validation: 0.006171732247718036]
	TIME [epoch: 35.3 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007439944014626586		[learning rate: 0.00076363]
	Learning Rate: 0.000763633
	LOSS [training: 0.007439944014626586 | validation: 0.00663522178710878]
	TIME [epoch: 35.2 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008906808439194168		[learning rate: 0.0007606]
	Learning Rate: 0.000760596
	LOSS [training: 0.008906808439194168 | validation: 0.006999616050341713]
	TIME [epoch: 35.2 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010863574002150897		[learning rate: 0.00075757]
	Learning Rate: 0.000757571
	LOSS [training: 0.010863574002150897 | validation: 0.006535157035618151]
	TIME [epoch: 35.2 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008079811344516645		[learning rate: 0.00075456]
	Learning Rate: 0.000754557
	LOSS [training: 0.008079811344516645 | validation: 0.006603419678242517]
	TIME [epoch: 35.3 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007713535813501763		[learning rate: 0.00075156]
	Learning Rate: 0.000751556
	LOSS [training: 0.007713535813501763 | validation: 0.006232161965155724]
	TIME [epoch: 35.4 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00774132906936985		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.00774132906936985 | validation: 0.007032540508410503]
	TIME [epoch: 35.3 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008332876499156447		[learning rate: 0.00074559]
	Learning Rate: 0.00074559
	LOSS [training: 0.008332876499156447 | validation: 0.0071697317237232345]
	TIME [epoch: 35.3 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008687953370677494		[learning rate: 0.00074262]
	Learning Rate: 0.000742624
	LOSS [training: 0.008687953370677494 | validation: 0.007359846969110735]
	TIME [epoch: 35.2 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008297426436181364		[learning rate: 0.00073967]
	Learning Rate: 0.000739671
	LOSS [training: 0.008297426436181364 | validation: 0.006554848030079654]
	TIME [epoch: 35.2 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007804228342111518		[learning rate: 0.00073673]
	Learning Rate: 0.000736729
	LOSS [training: 0.007804228342111518 | validation: 0.007235463810917793]
	TIME [epoch: 35.2 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010818932411446401		[learning rate: 0.0007338]
	Learning Rate: 0.000733799
	LOSS [training: 0.010818932411446401 | validation: 0.006995968853600929]
	TIME [epoch: 35.2 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007605722038747669		[learning rate: 0.00073088]
	Learning Rate: 0.00073088
	LOSS [training: 0.007605722038747669 | validation: 0.0065503027613369414]
	TIME [epoch: 35.4 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008211584746891612		[learning rate: 0.00072797]
	Learning Rate: 0.000727973
	LOSS [training: 0.008211584746891612 | validation: 0.006857434599562328]
	TIME [epoch: 35.2 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008536986640641874		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.008536986640641874 | validation: 0.006729896517985284]
	TIME [epoch: 35.3 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008156615717067868		[learning rate: 0.00072219]
	Learning Rate: 0.000722194
	LOSS [training: 0.008156615717067868 | validation: 0.006189694269750583]
	TIME [epoch: 35.2 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00814523400819412		[learning rate: 0.00071932]
	Learning Rate: 0.000719322
	LOSS [training: 0.00814523400819412 | validation: 0.0067570755099900254]
	TIME [epoch: 35.3 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011539505854407463		[learning rate: 0.00071646]
	Learning Rate: 0.000716461
	LOSS [training: 0.011539505854407463 | validation: 0.006673902714209512]
	TIME [epoch: 35.2 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008747932473711303		[learning rate: 0.00071361]
	Learning Rate: 0.000713611
	LOSS [training: 0.008747932473711303 | validation: 0.006426118658042862]
	TIME [epoch: 35.3 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00814343273190206		[learning rate: 0.00071077]
	Learning Rate: 0.000710773
	LOSS [training: 0.00814343273190206 | validation: 0.007551725418180398]
	TIME [epoch: 35.2 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007827889763127857		[learning rate: 0.00070795]
	Learning Rate: 0.000707946
	LOSS [training: 0.007827889763127857 | validation: 0.0065989836833921485]
	TIME [epoch: 35.2 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007840910362194578		[learning rate: 0.00070513]
	Learning Rate: 0.00070513
	LOSS [training: 0.007840910362194578 | validation: 0.0073410172590112985]
	TIME [epoch: 35.2 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008949312747638338		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.008949312747638338 | validation: 0.006328148398547731]
	TIME [epoch: 35.3 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007661926028073949		[learning rate: 0.00069953]
	Learning Rate: 0.000699532
	LOSS [training: 0.007661926028073949 | validation: 0.0064544069809131825]
	TIME [epoch: 35.2 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0075447764983879095		[learning rate: 0.00069675]
	Learning Rate: 0.00069675
	LOSS [training: 0.0075447764983879095 | validation: 0.006223598045612224]
	TIME [epoch: 35.3 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007582786257043228		[learning rate: 0.00069398]
	Learning Rate: 0.000693979
	LOSS [training: 0.007582786257043228 | validation: 0.007322267469260332]
	TIME [epoch: 35.2 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007696188632170174		[learning rate: 0.00069122]
	Learning Rate: 0.000691219
	LOSS [training: 0.007696188632170174 | validation: 0.005966475172991212]
	TIME [epoch: 35.3 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_715.pth
	Model improved!!!
EPOCH 716/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008126207536449413		[learning rate: 0.00068847]
	Learning Rate: 0.000688469
	LOSS [training: 0.008126207536449413 | validation: 0.006452824078213732]
	TIME [epoch: 35.3 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007602038987050724		[learning rate: 0.00068573]
	Learning Rate: 0.000685731
	LOSS [training: 0.007602038987050724 | validation: 0.006844290848540014]
	TIME [epoch: 35.3 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007314963400553346		[learning rate: 0.000683]
	Learning Rate: 0.000683004
	LOSS [training: 0.007314963400553346 | validation: 0.00639604936675914]
	TIME [epoch: 35.2 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00828053922918944		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.00828053922918944 | validation: 0.006128331423438982]
	TIME [epoch: 35.2 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007568598128536063		[learning rate: 0.00067758]
	Learning Rate: 0.000677582
	LOSS [training: 0.007568598128536063 | validation: 0.006218268766743594]
	TIME [epoch: 35.2 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007873928086927749		[learning rate: 0.00067489]
	Learning Rate: 0.000674887
	LOSS [training: 0.007873928086927749 | validation: 0.005919517673997845]
	TIME [epoch: 35.4 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_721.pth
	Model improved!!!
EPOCH 722/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007984316605426015		[learning rate: 0.0006722]
	Learning Rate: 0.000672202
	LOSS [training: 0.007984316605426015 | validation: 0.0066624266562385955]
	TIME [epoch: 35.4 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007402077310324228		[learning rate: 0.00066953]
	Learning Rate: 0.000669529
	LOSS [training: 0.007402077310324228 | validation: 0.006814743512463997]
	TIME [epoch: 35.4 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007995635035841412		[learning rate: 0.00066687]
	Learning Rate: 0.000666866
	LOSS [training: 0.007995635035841412 | validation: 0.006929548460736684]
	TIME [epoch: 35.3 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008951047163016817		[learning rate: 0.00066421]
	Learning Rate: 0.000664213
	LOSS [training: 0.008951047163016817 | validation: 0.0065988182360995715]
	TIME [epoch: 35.3 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008688002137541031		[learning rate: 0.00066157]
	Learning Rate: 0.000661572
	LOSS [training: 0.008688002137541031 | validation: 0.00801099077838317]
	TIME [epoch: 35.3 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009139168047287587		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.009139168047287587 | validation: 0.006180771391448672]
	TIME [epoch: 35.3 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008994139312093226		[learning rate: 0.00065632]
	Learning Rate: 0.00065632
	LOSS [training: 0.008994139312093226 | validation: 0.006898727120163968]
	TIME [epoch: 35.3 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007780805849424964		[learning rate: 0.00065371]
	Learning Rate: 0.000653709
	LOSS [training: 0.007780805849424964 | validation: 0.006975800691903703]
	TIME [epoch: 35.3 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009043054514552794		[learning rate: 0.00065111]
	Learning Rate: 0.000651109
	LOSS [training: 0.009043054514552794 | validation: 0.006385567823924005]
	TIME [epoch: 35.3 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007592846953918036		[learning rate: 0.00064852]
	Learning Rate: 0.00064852
	LOSS [training: 0.007592846953918036 | validation: 0.006831695620456543]
	TIME [epoch: 35.3 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008567576139497058		[learning rate: 0.00064594]
	Learning Rate: 0.00064594
	LOSS [training: 0.008567576139497058 | validation: 0.006679055933025167]
	TIME [epoch: 35.3 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008350504150244718		[learning rate: 0.00064337]
	Learning Rate: 0.000643371
	LOSS [training: 0.008350504150244718 | validation: 0.00774868738066835]
	TIME [epoch: 35.3 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00839743171169076		[learning rate: 0.00064081]
	Learning Rate: 0.000640812
	LOSS [training: 0.00839743171169076 | validation: 0.006127222984101835]
	TIME [epoch: 35.3 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0075170998297593794		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.0075170998297593794 | validation: 0.0062781900164710705]
	TIME [epoch: 35.3 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007857525777348646		[learning rate: 0.00063572]
	Learning Rate: 0.000635725
	LOSS [training: 0.007857525777348646 | validation: 0.0060842095697897]
	TIME [epoch: 35.3 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007240910424247323		[learning rate: 0.0006332]
	Learning Rate: 0.000633196
	LOSS [training: 0.007240910424247323 | validation: 0.00742072313037771]
	TIME [epoch: 35.3 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008282339233663106		[learning rate: 0.00063068]
	Learning Rate: 0.000630678
	LOSS [training: 0.008282339233663106 | validation: 0.0074659323853624475]
	TIME [epoch: 35.3 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010979556694532683		[learning rate: 0.00062817]
	Learning Rate: 0.00062817
	LOSS [training: 0.010979556694532683 | validation: 0.008415862727029865]
	TIME [epoch: 35.3 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008467256505690383		[learning rate: 0.00062567]
	Learning Rate: 0.000625671
	LOSS [training: 0.008467256505690383 | validation: 0.006775849609908358]
	TIME [epoch: 35.3 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00816900229908654		[learning rate: 0.00062318]
	Learning Rate: 0.000623183
	LOSS [training: 0.00816900229908654 | validation: 0.006614810472236372]
	TIME [epoch: 35.3 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008014570746089014		[learning rate: 0.0006207]
	Learning Rate: 0.000620704
	LOSS [training: 0.008014570746089014 | validation: 0.006369535551026581]
	TIME [epoch: 35.3 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007943022560376574		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.007943022560376574 | validation: 0.006436089646239309]
	TIME [epoch: 35.3 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00811125489783331		[learning rate: 0.00061578]
	Learning Rate: 0.000615777
	LOSS [training: 0.00811125489783331 | validation: 0.0061649763771436565]
	TIME [epoch: 35.3 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007887904502447782		[learning rate: 0.00061333]
	Learning Rate: 0.000613327
	LOSS [training: 0.007887904502447782 | validation: 0.008028096220760443]
	TIME [epoch: 35.3 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00803955173036664		[learning rate: 0.00061089]
	Learning Rate: 0.000610888
	LOSS [training: 0.00803955173036664 | validation: 0.006025147009457834]
	TIME [epoch: 35.3 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007392564476349486		[learning rate: 0.00060846]
	Learning Rate: 0.000608458
	LOSS [training: 0.007392564476349486 | validation: 0.0057975494627057565]
	TIME [epoch: 35.3 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_747.pth
	Model improved!!!
EPOCH 748/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00806018200129189		[learning rate: 0.00060604]
	Learning Rate: 0.000606038
	LOSS [training: 0.00806018200129189 | validation: 0.006570763429468857]
	TIME [epoch: 35.4 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007410759776577668		[learning rate: 0.00060363]
	Learning Rate: 0.000603628
	LOSS [training: 0.007410759776577668 | validation: 0.005925615151400057]
	TIME [epoch: 35.3 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007468265472149607		[learning rate: 0.00060123]
	Learning Rate: 0.000601227
	LOSS [training: 0.007468265472149607 | validation: 0.007161006443361156]
	TIME [epoch: 35.2 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008211880727502629		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.008211880727502629 | validation: 0.005650913686585076]
	TIME [epoch: 35.3 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_751.pth
	Model improved!!!
EPOCH 752/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008701935720567036		[learning rate: 0.00059645]
	Learning Rate: 0.000596454
	LOSS [training: 0.008701935720567036 | validation: 0.006253046565286321]
	TIME [epoch: 35.4 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007347869494423053		[learning rate: 0.00059408]
	Learning Rate: 0.000594082
	LOSS [training: 0.007347869494423053 | validation: 0.006110680401544358]
	TIME [epoch: 35.3 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008269341939316957		[learning rate: 0.00059172]
	Learning Rate: 0.000591719
	LOSS [training: 0.008269341939316957 | validation: 0.006232837267044827]
	TIME [epoch: 35.2 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007462147895204356		[learning rate: 0.00058937]
	Learning Rate: 0.000589365
	LOSS [training: 0.007462147895204356 | validation: 0.007134089376788296]
	TIME [epoch: 35.3 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008474188811741135		[learning rate: 0.00058702]
	Learning Rate: 0.000587021
	LOSS [training: 0.008474188811741135 | validation: 0.00599633438202134]
	TIME [epoch: 35.2 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007410943364690721		[learning rate: 0.00058469]
	Learning Rate: 0.000584687
	LOSS [training: 0.007410943364690721 | validation: 0.006203078773937052]
	TIME [epoch: 35.3 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008545992004984364		[learning rate: 0.00058236]
	Learning Rate: 0.000582361
	LOSS [training: 0.008545992004984364 | validation: 0.0061751867203590745]
	TIME [epoch: 35.2 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008074542331123683		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.008074542331123683 | validation: 0.006040632455406425]
	TIME [epoch: 35.3 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007591199042469493		[learning rate: 0.00057774]
	Learning Rate: 0.000577738
	LOSS [training: 0.007591199042469493 | validation: 0.007005702148053472]
	TIME [epoch: 35.2 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0079967157012447		[learning rate: 0.00057544]
	Learning Rate: 0.00057544
	LOSS [training: 0.0079967157012447 | validation: 0.006182979230669443]
	TIME [epoch: 35.2 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0070184001102594805		[learning rate: 0.00057315]
	Learning Rate: 0.000573151
	LOSS [training: 0.0070184001102594805 | validation: 0.0064241126774195936]
	TIME [epoch: 35.2 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008036557966165333		[learning rate: 0.00057087]
	Learning Rate: 0.000570872
	LOSS [training: 0.008036557966165333 | validation: 0.006507661376030875]
	TIME [epoch: 35.3 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007562557284133161		[learning rate: 0.0005686]
	Learning Rate: 0.000568601
	LOSS [training: 0.007562557284133161 | validation: 0.006630058288518309]
	TIME [epoch: 35.2 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007126841480875602		[learning rate: 0.00056634]
	Learning Rate: 0.00056634
	LOSS [training: 0.007126841480875602 | validation: 0.006680011272734349]
	TIME [epoch: 35.2 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008115207244226423		[learning rate: 0.00056409]
	Learning Rate: 0.000564087
	LOSS [training: 0.008115207244226423 | validation: 0.00657276833347165]
	TIME [epoch: 35.2 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00757939603966471		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.00757939603966471 | validation: 0.007353143983320214]
	TIME [epoch: 35.2 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008497833082627172		[learning rate: 0.00055961]
	Learning Rate: 0.000559609
	LOSS [training: 0.008497833082627172 | validation: 0.006260335820555918]
	TIME [epoch: 35.2 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007338729501757134		[learning rate: 0.00055738]
	Learning Rate: 0.000557383
	LOSS [training: 0.007338729501757134 | validation: 0.006385859497202784]
	TIME [epoch: 35.4 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007815740327062186		[learning rate: 0.00055517]
	Learning Rate: 0.000555166
	LOSS [training: 0.007815740327062186 | validation: 0.006142986892003539]
	TIME [epoch: 35.4 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00900055556727161		[learning rate: 0.00055296]
	Learning Rate: 0.000552958
	LOSS [training: 0.00900055556727161 | validation: 0.006904485268015882]
	TIME [epoch: 35.3 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007502022838324265		[learning rate: 0.00055076]
	Learning Rate: 0.000550759
	LOSS [training: 0.007502022838324265 | validation: 0.005915357103030693]
	TIME [epoch: 35.2 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0073041759581958425		[learning rate: 0.00054857]
	Learning Rate: 0.000548568
	LOSS [training: 0.0073041759581958425 | validation: 0.006553599231492524]
	TIME [epoch: 35.3 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008523943128922752		[learning rate: 0.00054639]
	Learning Rate: 0.000546387
	LOSS [training: 0.008523943128922752 | validation: 0.0054911829809516505]
	TIME [epoch: 35.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_774.pth
	Model improved!!!
EPOCH 775/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007995167087301394		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.007995167087301394 | validation: 0.006056572503807015]
	TIME [epoch: 35.3 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0076082065581103		[learning rate: 0.00054205]
	Learning Rate: 0.000542049
	LOSS [training: 0.0076082065581103 | validation: 0.0059256422214442415]
	TIME [epoch: 35.2 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007325764009583357		[learning rate: 0.00053989]
	Learning Rate: 0.000539893
	LOSS [training: 0.007325764009583357 | validation: 0.006492470183194726]
	TIME [epoch: 35.2 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008071208860859765		[learning rate: 0.00053775]
	Learning Rate: 0.000537746
	LOSS [training: 0.008071208860859765 | validation: 0.006504900445138917]
	TIME [epoch: 35.2 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007847035851248683		[learning rate: 0.00053561]
	Learning Rate: 0.000535607
	LOSS [training: 0.007847035851248683 | validation: 0.0070733984504386446]
	TIME [epoch: 35.2 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007921357467609297		[learning rate: 0.00053348]
	Learning Rate: 0.000533477
	LOSS [training: 0.007921357467609297 | validation: 0.005922136740826418]
	TIME [epoch: 35.2 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007387549993391071		[learning rate: 0.00053135]
	Learning Rate: 0.000531355
	LOSS [training: 0.007387549993391071 | validation: 0.006714486837764873]
	TIME [epoch: 35.2 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008544602734242407		[learning rate: 0.00052924]
	Learning Rate: 0.000529241
	LOSS [training: 0.008544602734242407 | validation: 0.00582512718550578]
	TIME [epoch: 35.2 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007267206965057253		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.007267206965057253 | validation: 0.005979187901718075]
	TIME [epoch: 35.2 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008053063835111961		[learning rate: 0.00052504]
	Learning Rate: 0.00052504
	LOSS [training: 0.008053063835111961 | validation: 0.006295412721878621]
	TIME [epoch: 35.2 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007258629919308905		[learning rate: 0.00052295]
	Learning Rate: 0.000522952
	LOSS [training: 0.007258629919308905 | validation: 0.006667430950931305]
	TIME [epoch: 35.2 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007919672385245224		[learning rate: 0.00052087]
	Learning Rate: 0.000520872
	LOSS [training: 0.007919672385245224 | validation: 0.006153883533861207]
	TIME [epoch: 35.2 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00763412393511183		[learning rate: 0.0005188]
	Learning Rate: 0.0005188
	LOSS [training: 0.00763412393511183 | validation: 0.005928508426974402]
	TIME [epoch: 35.2 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007380694269938278		[learning rate: 0.00051674]
	Learning Rate: 0.000516737
	LOSS [training: 0.007380694269938278 | validation: 0.00743994463459607]
	TIME [epoch: 35.2 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00832609516169985		[learning rate: 0.00051468]
	Learning Rate: 0.000514681
	LOSS [training: 0.00832609516169985 | validation: 0.006212403578412298]
	TIME [epoch: 35.2 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007779584064066109		[learning rate: 0.00051263]
	Learning Rate: 0.000512634
	LOSS [training: 0.007779584064066109 | validation: 0.005462657467536705]
	TIME [epoch: 35.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_790.pth
	Model improved!!!
EPOCH 791/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0075443602431233825		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.0075443602431233825 | validation: 0.006045622248099387]
	TIME [epoch: 35.3 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009357565501485171		[learning rate: 0.00050856]
	Learning Rate: 0.000508565
	LOSS [training: 0.009357565501485171 | validation: 0.007591379978684448]
	TIME [epoch: 35.2 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007791745247954217		[learning rate: 0.00050654]
	Learning Rate: 0.000506542
	LOSS [training: 0.007791745247954217 | validation: 0.006051757040933464]
	TIME [epoch: 35.2 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007581357745742427		[learning rate: 0.00050453]
	Learning Rate: 0.000504527
	LOSS [training: 0.007581357745742427 | validation: 0.006411451786608016]
	TIME [epoch: 35.3 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007403814909923782		[learning rate: 0.00050252]
	Learning Rate: 0.000502521
	LOSS [training: 0.007403814909923782 | validation: 0.005884362384442783]
	TIME [epoch: 35.2 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00692892995811643		[learning rate: 0.00050052]
	Learning Rate: 0.000500522
	LOSS [training: 0.00692892995811643 | validation: 0.006437754072457125]
	TIME [epoch: 35.2 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007864150823481462		[learning rate: 0.00049853]
	Learning Rate: 0.000498531
	LOSS [training: 0.007864150823481462 | validation: 0.00593472539464178]
	TIME [epoch: 35.3 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007785891015957185		[learning rate: 0.00049655]
	Learning Rate: 0.000496548
	LOSS [training: 0.007785891015957185 | validation: 0.00547978948405619]
	TIME [epoch: 35.3 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006989260936356458		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.006989260936356458 | validation: 0.00578495253448867]
	TIME [epoch: 35.2 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007939425260510724		[learning rate: 0.00049261]
	Learning Rate: 0.000492606
	LOSS [training: 0.007939425260510724 | validation: 0.006622635109209312]
	TIME [epoch: 35.3 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008036492130667454		[learning rate: 0.00049065]
	Learning Rate: 0.000490647
	LOSS [training: 0.008036492130667454 | validation: 0.006387524215210818]
	TIME [epoch: 35.3 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008569374861050423		[learning rate: 0.0004887]
	Learning Rate: 0.000488696
	LOSS [training: 0.008569374861050423 | validation: 0.005996275591610884]
	TIME [epoch: 35.2 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007023793098541564		[learning rate: 0.00048675]
	Learning Rate: 0.000486752
	LOSS [training: 0.007023793098541564 | validation: 0.006507623327211812]
	TIME [epoch: 35.4 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008414250463418059		[learning rate: 0.00048482]
	Learning Rate: 0.000484816
	LOSS [training: 0.008414250463418059 | validation: 0.006351962214423984]
	TIME [epoch: 35.3 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007917884057747591		[learning rate: 0.00048289]
	Learning Rate: 0.000482888
	LOSS [training: 0.007917884057747591 | validation: 0.006537102110141193]
	TIME [epoch: 35.3 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007501466081460902		[learning rate: 0.00048097]
	Learning Rate: 0.000480967
	LOSS [training: 0.007501466081460902 | validation: 0.006218013854348832]
	TIME [epoch: 35.3 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008210648577305517		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.008210648577305517 | validation: 0.005963835235256614]
	TIME [epoch: 35.3 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009634139437845047		[learning rate: 0.00047715]
	Learning Rate: 0.000477149
	LOSS [training: 0.009634139437845047 | validation: 0.0059840678080406344]
	TIME [epoch: 35.2 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008164190928554508		[learning rate: 0.00047525]
	Learning Rate: 0.000475251
	LOSS [training: 0.008164190928554508 | validation: 0.006016708889136031]
	TIME [epoch: 35.3 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007148664230820092		[learning rate: 0.00047336]
	Learning Rate: 0.000473361
	LOSS [training: 0.007148664230820092 | validation: 0.005678208193262649]
	TIME [epoch: 35.3 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006510067795860093		[learning rate: 0.00047148]
	Learning Rate: 0.000471478
	LOSS [training: 0.006510067795860093 | validation: 0.006251186693945377]
	TIME [epoch: 35.3 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008339140770659394		[learning rate: 0.0004696]
	Learning Rate: 0.000469603
	LOSS [training: 0.008339140770659394 | validation: 0.005858846589300515]
	TIME [epoch: 35.3 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007229855465147178		[learning rate: 0.00046774]
	Learning Rate: 0.000467735
	LOSS [training: 0.007229855465147178 | validation: 0.006034751706637431]
	TIME [epoch: 35.3 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007029988565927544		[learning rate: 0.00046587]
	Learning Rate: 0.000465875
	LOSS [training: 0.007029988565927544 | validation: 0.006038864203710581]
	TIME [epoch: 35.3 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0078746882766572		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.0078746882766572 | validation: 0.006019444293431953]
	TIME [epoch: 35.3 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006696901760855839		[learning rate: 0.00046218]
	Learning Rate: 0.000462176
	LOSS [training: 0.006696901760855839 | validation: 0.005748088246704053]
	TIME [epoch: 35.2 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007366173235804401		[learning rate: 0.00046034]
	Learning Rate: 0.000460338
	LOSS [training: 0.007366173235804401 | validation: 0.00753034019076428]
	TIME [epoch: 35.3 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007662595570638651		[learning rate: 0.00045851]
	Learning Rate: 0.000458507
	LOSS [training: 0.007662595570638651 | validation: 0.006272227334347055]
	TIME [epoch: 35.3 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008226885387658926		[learning rate: 0.00045668]
	Learning Rate: 0.000456684
	LOSS [training: 0.008226885387658926 | validation: 0.005899219515578165]
	TIME [epoch: 35.3 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0070288598606506915		[learning rate: 0.00045487]
	Learning Rate: 0.000454867
	LOSS [training: 0.0070288598606506915 | validation: 0.005770444051608146]
	TIME [epoch: 35.3 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007646959289246959		[learning rate: 0.00045306]
	Learning Rate: 0.000453058
	LOSS [training: 0.007646959289246959 | validation: 0.0061806303859663556]
	TIME [epoch: 35.3 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007473481879501882		[learning rate: 0.00045126]
	Learning Rate: 0.000451256
	LOSS [training: 0.007473481879501882 | validation: 0.005673658239327111]
	TIME [epoch: 35.3 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007298822286850159		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.007298822286850159 | validation: 0.006045102725921807]
	TIME [epoch: 35.3 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00781775916251476		[learning rate: 0.00044767]
	Learning Rate: 0.000447674
	LOSS [training: 0.00781775916251476 | validation: 0.005471022130562009]
	TIME [epoch: 35.3 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007226512011605277		[learning rate: 0.00044589]
	Learning Rate: 0.000445893
	LOSS [training: 0.007226512011605277 | validation: 0.0056028974803459435]
	TIME [epoch: 35.3 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007382155392729652		[learning rate: 0.00044412]
	Learning Rate: 0.00044412
	LOSS [training: 0.007382155392729652 | validation: 0.006018117788026234]
	TIME [epoch: 35.3 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007913569891175252		[learning rate: 0.00044235]
	Learning Rate: 0.000442353
	LOSS [training: 0.007913569891175252 | validation: 0.0067469266750685404]
	TIME [epoch: 35.3 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00761934516814995		[learning rate: 0.00044059]
	Learning Rate: 0.000440594
	LOSS [training: 0.00761934516814995 | validation: 0.005748454077646681]
	TIME [epoch: 35.3 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007873193102338657		[learning rate: 0.00043884]
	Learning Rate: 0.000438842
	LOSS [training: 0.007873193102338657 | validation: 0.005718087558612286]
	TIME [epoch: 35.4 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007893240861690791		[learning rate: 0.0004371]
	Learning Rate: 0.000437096
	LOSS [training: 0.007893240861690791 | validation: 0.006241028491285903]
	TIME [epoch: 35.2 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00786233473142884		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.00786233473142884 | validation: 0.00606351236155283]
	TIME [epoch: 35.3 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0077275220558393936		[learning rate: 0.00043363]
	Learning Rate: 0.000433626
	LOSS [training: 0.0077275220558393936 | validation: 0.0056858736747403965]
	TIME [epoch: 35.2 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0077857952284834785		[learning rate: 0.0004319]
	Learning Rate: 0.000431901
	LOSS [training: 0.0077857952284834785 | validation: 0.006201586955190663]
	TIME [epoch: 35.3 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00709113358766743		[learning rate: 0.00043018]
	Learning Rate: 0.000430184
	LOSS [training: 0.00709113358766743 | validation: 0.005346982551451256]
	TIME [epoch: 35.3 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_834.pth
	Model improved!!!
EPOCH 835/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0075145508867650295		[learning rate: 0.00042847]
	Learning Rate: 0.000428473
	LOSS [training: 0.0075145508867650295 | validation: 0.005757700879813764]
	TIME [epoch: 35.4 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007627671344798831		[learning rate: 0.00042677]
	Learning Rate: 0.000426768
	LOSS [training: 0.007627671344798831 | validation: 0.005732420123371731]
	TIME [epoch: 35.3 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0070837594868061		[learning rate: 0.00042507]
	Learning Rate: 0.000425071
	LOSS [training: 0.0070837594868061 | validation: 0.006171334950776437]
	TIME [epoch: 35.3 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007260550390688986		[learning rate: 0.00042338]
	Learning Rate: 0.00042338
	LOSS [training: 0.007260550390688986 | validation: 0.007455487905604405]
	TIME [epoch: 35.3 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007685487311131232		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.007685487311131232 | validation: 0.00509933402363119]
	TIME [epoch: 35.3 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_839.pth
	Model improved!!!
EPOCH 840/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007037150193983605		[learning rate: 0.00042002]
	Learning Rate: 0.000420019
	LOSS [training: 0.007037150193983605 | validation: 0.005767142216417081]
	TIME [epoch: 35.4 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006623269293072509		[learning rate: 0.00041835]
	Learning Rate: 0.000418349
	LOSS [training: 0.006623269293072509 | validation: 0.007717694185199311]
	TIME [epoch: 35.3 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008323349879458505		[learning rate: 0.00041668]
	Learning Rate: 0.000416685
	LOSS [training: 0.008323349879458505 | validation: 0.00627694056790431]
	TIME [epoch: 35.3 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006820390070397903		[learning rate: 0.00041503]
	Learning Rate: 0.000415028
	LOSS [training: 0.006820390070397903 | validation: 0.006192883024373219]
	TIME [epoch: 35.3 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007106101167072766		[learning rate: 0.00041338]
	Learning Rate: 0.000413377
	LOSS [training: 0.007106101167072766 | validation: 0.0063206273490157465]
	TIME [epoch: 35.4 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006897906186364278		[learning rate: 0.00041173]
	Learning Rate: 0.000411733
	LOSS [training: 0.006897906186364278 | validation: 0.0055126047220004975]
	TIME [epoch: 35.3 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007177412459835904		[learning rate: 0.0004101]
	Learning Rate: 0.000410095
	LOSS [training: 0.007177412459835904 | validation: 0.006458251809776305]
	TIME [epoch: 35.4 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008748220926550282		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.008748220926550282 | validation: 0.0064114941140601175]
	TIME [epoch: 35.3 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007072680490656541		[learning rate: 0.00040684]
	Learning Rate: 0.00040684
	LOSS [training: 0.007072680490656541 | validation: 0.005713591283492319]
	TIME [epoch: 35.3 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006970389701307644		[learning rate: 0.00040522]
	Learning Rate: 0.000405221
	LOSS [training: 0.006970389701307644 | validation: 0.005614980784051147]
	TIME [epoch: 35.3 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007366792481083812		[learning rate: 0.00040361]
	Learning Rate: 0.00040361
	LOSS [training: 0.007366792481083812 | validation: 0.005384932970174697]
	TIME [epoch: 35.3 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007483963321407679		[learning rate: 0.000402]
	Learning Rate: 0.000402004
	LOSS [training: 0.007483963321407679 | validation: 0.005816902527161063]
	TIME [epoch: 35.3 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007889561714833739		[learning rate: 0.00040041]
	Learning Rate: 0.000400406
	LOSS [training: 0.007889561714833739 | validation: 0.005750377231649702]
	TIME [epoch: 35.3 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0073863359623822416		[learning rate: 0.00039881]
	Learning Rate: 0.000398813
	LOSS [training: 0.0073863359623822416 | validation: 0.005148975729703222]
	TIME [epoch: 35.3 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007889531464314661		[learning rate: 0.00039723]
	Learning Rate: 0.000397227
	LOSS [training: 0.007889531464314661 | validation: 0.00557616575753833]
	TIME [epoch: 35.3 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007089526781588069		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.007089526781588069 | validation: 0.005012104272222882]
	TIME [epoch: 35.3 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_855.pth
	Model improved!!!
EPOCH 856/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007377065819995998		[learning rate: 0.00039407]
	Learning Rate: 0.000394073
	LOSS [training: 0.007377065819995998 | validation: 0.006216513380385753]
	TIME [epoch: 35.5 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009109247756954326		[learning rate: 0.00039251]
	Learning Rate: 0.000392506
	LOSS [training: 0.009109247756954326 | validation: 0.006205360695499022]
	TIME [epoch: 35.3 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007669446926885915		[learning rate: 0.00039094]
	Learning Rate: 0.000390945
	LOSS [training: 0.007669446926885915 | validation: 0.005378923761867526]
	TIME [epoch: 35.3 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006997260319925605		[learning rate: 0.00038939]
	Learning Rate: 0.00038939
	LOSS [training: 0.006997260319925605 | validation: 0.006214914588087806]
	TIME [epoch: 35.3 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006841246851637627		[learning rate: 0.00038784]
	Learning Rate: 0.000387841
	LOSS [training: 0.006841246851637627 | validation: 0.005885108564854957]
	TIME [epoch: 35.4 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007262563117724612		[learning rate: 0.0003863]
	Learning Rate: 0.000386299
	LOSS [training: 0.007262563117724612 | validation: 0.005642026937290737]
	TIME [epoch: 35.3 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008034823033686904		[learning rate: 0.00038476]
	Learning Rate: 0.000384762
	LOSS [training: 0.008034823033686904 | validation: 0.005915700504377841]
	TIME [epoch: 35.3 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0070991833335102995		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.0070991833335102995 | validation: 0.005869853948592825]
	TIME [epoch: 35.3 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006906105892477187		[learning rate: 0.00038171]
	Learning Rate: 0.000381708
	LOSS [training: 0.006906105892477187 | validation: 0.005668170888271412]
	TIME [epoch: 35.3 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006653342442260637		[learning rate: 0.00038019]
	Learning Rate: 0.000380189
	LOSS [training: 0.006653342442260637 | validation: 0.005567627621578626]
	TIME [epoch: 35.3 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00981411265645533		[learning rate: 0.00037868]
	Learning Rate: 0.000378677
	LOSS [training: 0.00981411265645533 | validation: 0.006371383701488808]
	TIME [epoch: 35.3 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007249170099132416		[learning rate: 0.00037717]
	Learning Rate: 0.000377171
	LOSS [training: 0.007249170099132416 | validation: 0.005243389439982029]
	TIME [epoch: 35.6 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007256787152828562		[learning rate: 0.00037567]
	Learning Rate: 0.000375671
	LOSS [training: 0.007256787152828562 | validation: 0.005261813728880802]
	TIME [epoch: 35.3 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006034539526809626		[learning rate: 0.00037418]
	Learning Rate: 0.000374177
	LOSS [training: 0.006034539526809626 | validation: 0.0051131860620476305]
	TIME [epoch: 35.3 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008164264258164838		[learning rate: 0.00037269]
	Learning Rate: 0.000372689
	LOSS [training: 0.008164264258164838 | validation: 0.006044915470205079]
	TIME [epoch: 35.3 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007886504210656797		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.007886504210656797 | validation: 0.005339007987942549]
	TIME [epoch: 35.3 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007245457403164852		[learning rate: 0.00036973]
	Learning Rate: 0.00036973
	LOSS [training: 0.007245457403164852 | validation: 0.00588125704891731]
	TIME [epoch: 35.3 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0074280722209157084		[learning rate: 0.00036826]
	Learning Rate: 0.000368259
	LOSS [training: 0.0074280722209157084 | validation: 0.006175231663084717]
	TIME [epoch: 35.3 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007409497196711727		[learning rate: 0.00036679]
	Learning Rate: 0.000366795
	LOSS [training: 0.007409497196711727 | validation: 0.005588176572973707]
	TIME [epoch: 35.3 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007511404274827025		[learning rate: 0.00036534]
	Learning Rate: 0.000365336
	LOSS [training: 0.007511404274827025 | validation: 0.005911602955627315]
	TIME [epoch: 35.4 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006878677302619692		[learning rate: 0.00036388]
	Learning Rate: 0.000363883
	LOSS [training: 0.006878677302619692 | validation: 0.007068554840756724]
	TIME [epoch: 35.5 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010200772815152841		[learning rate: 0.00036244]
	Learning Rate: 0.000362436
	LOSS [training: 0.010200772815152841 | validation: 0.005262211552130327]
	TIME [epoch: 35.4 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0067888737738933495		[learning rate: 0.00036099]
	Learning Rate: 0.000360994
	LOSS [training: 0.0067888737738933495 | validation: 0.006410544522427944]
	TIME [epoch: 35.4 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0072253315870548195		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.0072253315870548195 | validation: 0.005762977056772632]
	TIME [epoch: 35.3 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00713446095868873		[learning rate: 0.00035813]
	Learning Rate: 0.000358128
	LOSS [training: 0.00713446095868873 | validation: 0.005243574411071439]
	TIME [epoch: 35.4 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006689767152706017		[learning rate: 0.0003567]
	Learning Rate: 0.000356704
	LOSS [training: 0.006689767152706017 | validation: 0.006197691733534483]
	TIME [epoch: 35.3 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0068184659693014075		[learning rate: 0.00035529]
	Learning Rate: 0.000355285
	LOSS [training: 0.0068184659693014075 | validation: 0.005432571461287408]
	TIME [epoch: 35.3 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009268701598112956		[learning rate: 0.00035387]
	Learning Rate: 0.000353872
	LOSS [training: 0.009268701598112956 | validation: 0.006831478301312872]
	TIME [epoch: 35.3 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00675287183138525		[learning rate: 0.00035246]
	Learning Rate: 0.000352465
	LOSS [training: 0.00675287183138525 | validation: 0.00517325743279474]
	TIME [epoch: 35.3 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006964485024893907		[learning rate: 0.00035106]
	Learning Rate: 0.000351063
	LOSS [training: 0.006964485024893907 | validation: 0.0056882342308744215]
	TIME [epoch: 35.3 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007453773897589549		[learning rate: 0.00034967]
	Learning Rate: 0.000349666
	LOSS [training: 0.007453773897589549 | validation: 0.005757438605846517]
	TIME [epoch: 35.3 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008595388621724709		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.008595388621724709 | validation: 0.006334859784775393]
	TIME [epoch: 35.3 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006947892730815441		[learning rate: 0.00034689]
	Learning Rate: 0.000346891
	LOSS [training: 0.006947892730815441 | validation: 0.005737127152321149]
	TIME [epoch: 35.4 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00694713127153633		[learning rate: 0.00034551]
	Learning Rate: 0.000345511
	LOSS [training: 0.00694713127153633 | validation: 0.005543882778441565]
	TIME [epoch: 35.3 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0067725444816308135		[learning rate: 0.00034414]
	Learning Rate: 0.000344137
	LOSS [training: 0.0067725444816308135 | validation: 0.006159080451185739]
	TIME [epoch: 35.3 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006960597467506949		[learning rate: 0.00034277]
	Learning Rate: 0.000342768
	LOSS [training: 0.006960597467506949 | validation: 0.005699186356151413]
	TIME [epoch: 35.4 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007805878084029143		[learning rate: 0.0003414]
	Learning Rate: 0.000341405
	LOSS [training: 0.007805878084029143 | validation: 0.005236339359379448]
	TIME [epoch: 35.4 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007045813716516354		[learning rate: 0.00034005]
	Learning Rate: 0.000340047
	LOSS [training: 0.007045813716516354 | validation: 0.005828801183514308]
	TIME [epoch: 35.3 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007205406257456199		[learning rate: 0.00033869]
	Learning Rate: 0.000338694
	LOSS [training: 0.007205406257456199 | validation: 0.005549389683224444]
	TIME [epoch: 35.3 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007415126026190405		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.007415126026190405 | validation: 0.006002257947691386]
	TIME [epoch: 35.3 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007926176827393534		[learning rate: 0.00033601]
	Learning Rate: 0.000336005
	LOSS [training: 0.007926176827393534 | validation: 0.005450550292250144]
	TIME [epoch: 35.4 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006995585074208071		[learning rate: 0.00033467]
	Learning Rate: 0.000334669
	LOSS [training: 0.006995585074208071 | validation: 0.005762829097771811]
	TIME [epoch: 35.3 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007557810561787761		[learning rate: 0.00033334]
	Learning Rate: 0.000333338
	LOSS [training: 0.007557810561787761 | validation: 0.0050840393267096926]
	TIME [epoch: 35.4 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0068195752411073784		[learning rate: 0.00033201]
	Learning Rate: 0.000332012
	LOSS [training: 0.0068195752411073784 | validation: 0.0055909050791448645]
	TIME [epoch: 35.4 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007110411420090484		[learning rate: 0.00033069]
	Learning Rate: 0.000330692
	LOSS [training: 0.007110411420090484 | validation: 0.005455241651613401]
	TIME [epoch: 35.3 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006661553592925717		[learning rate: 0.00032938]
	Learning Rate: 0.000329376
	LOSS [training: 0.006661553592925717 | validation: 0.005672190727447779]
	TIME [epoch: 35.5 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00709943521966548		[learning rate: 0.00032807]
	Learning Rate: 0.000328066
	LOSS [training: 0.00709943521966548 | validation: 0.005628946578880729]
	TIME [epoch: 35.4 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007083309418007805		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.007083309418007805 | validation: 0.005747666724337513]
	TIME [epoch: 35.3 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007564110939593071		[learning rate: 0.00032546]
	Learning Rate: 0.000325462
	LOSS [training: 0.007564110939593071 | validation: 0.005391778949290887]
	TIME [epoch: 35.4 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007025266618711751		[learning rate: 0.00032417]
	Learning Rate: 0.000324167
	LOSS [training: 0.007025266618711751 | validation: 0.005749474201123005]
	TIME [epoch: 35.3 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007098571125968712		[learning rate: 0.00032288]
	Learning Rate: 0.000322878
	LOSS [training: 0.007098571125968712 | validation: 0.0051371718033184745]
	TIME [epoch: 35.4 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0066109005016572455		[learning rate: 0.00032159]
	Learning Rate: 0.000321594
	LOSS [training: 0.0066109005016572455 | validation: 0.005494853681620336]
	TIME [epoch: 35.3 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006942660916869636		[learning rate: 0.00032031]
	Learning Rate: 0.000320315
	LOSS [training: 0.006942660916869636 | validation: 0.005142697803635633]
	TIME [epoch: 35.3 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007723372593808171		[learning rate: 0.00031904]
	Learning Rate: 0.000319041
	LOSS [training: 0.007723372593808171 | validation: 0.004995460112550237]
	TIME [epoch: 35.4 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_909.pth
	Model improved!!!
EPOCH 910/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007028990537452188		[learning rate: 0.00031777]
	Learning Rate: 0.000317772
	LOSS [training: 0.007028990537452188 | validation: 0.005520046124121554]
	TIME [epoch: 35.5 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007080791066482784		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.007080791066482784 | validation: 0.005947602508577413]
	TIME [epoch: 35.4 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006787785660402513		[learning rate: 0.00031525]
	Learning Rate: 0.000315249
	LOSS [training: 0.006787785660402513 | validation: 0.005173295679744019]
	TIME [epoch: 35.5 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007383421569981844		[learning rate: 0.000314]
	Learning Rate: 0.000313995
	LOSS [training: 0.007383421569981844 | validation: 0.005801876385219784]
	TIME [epoch: 35.4 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0072122381414380776		[learning rate: 0.00031275]
	Learning Rate: 0.000312746
	LOSS [training: 0.0072122381414380776 | validation: 0.005850578463873437]
	TIME [epoch: 35.4 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0071882629322587615		[learning rate: 0.0003115]
	Learning Rate: 0.000311503
	LOSS [training: 0.0071882629322587615 | validation: 0.005323179976063556]
	TIME [epoch: 35.5 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006948194753214038		[learning rate: 0.00031026]
	Learning Rate: 0.000310264
	LOSS [training: 0.006948194753214038 | validation: 0.00566284490756555]
	TIME [epoch: 35.4 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007419894709833603		[learning rate: 0.00030903]
	Learning Rate: 0.00030903
	LOSS [training: 0.007419894709833603 | validation: 0.0054879401980844605]
	TIME [epoch: 35.3 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006626994094164109		[learning rate: 0.0003078]
	Learning Rate: 0.0003078
	LOSS [training: 0.006626994094164109 | validation: 0.005029769055185271]
	TIME [epoch: 35.4 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006632253731749612		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.006632253731749612 | validation: 0.005972058888214891]
	TIME [epoch: 35.4 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007269374609211591		[learning rate: 0.00030536]
	Learning Rate: 0.000305357
	LOSS [training: 0.007269374609211591 | validation: 0.005387304803747264]
	TIME [epoch: 35.4 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0075623224777077325		[learning rate: 0.00030414]
	Learning Rate: 0.000304142
	LOSS [training: 0.0075623224777077325 | validation: 0.005735239052860797]
	TIME [epoch: 35.4 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007752691443356922		[learning rate: 0.00030293]
	Learning Rate: 0.000302933
	LOSS [training: 0.007752691443356922 | validation: 0.005374425190443453]
	TIME [epoch: 35.4 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006917170015157601		[learning rate: 0.00030173]
	Learning Rate: 0.000301728
	LOSS [training: 0.006917170015157601 | validation: 0.0063278794910676785]
	TIME [epoch: 35.4 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006580581945576746		[learning rate: 0.00030053]
	Learning Rate: 0.000300528
	LOSS [training: 0.006580581945576746 | validation: 0.0059593093044101415]
	TIME [epoch: 35.4 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0065303207198040515		[learning rate: 0.00029933]
	Learning Rate: 0.000299333
	LOSS [training: 0.0065303207198040515 | validation: 0.005342579520538267]
	TIME [epoch: 35.4 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007302479034089886		[learning rate: 0.00029814]
	Learning Rate: 0.000298142
	LOSS [training: 0.007302479034089886 | validation: 0.0052859708661049925]
	TIME [epoch: 35.4 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0067423571706331205		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.0067423571706331205 | validation: 0.0054936716082029284]
	TIME [epoch: 35.4 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0070158802352452854		[learning rate: 0.00029578]
	Learning Rate: 0.000295775
	LOSS [training: 0.0070158802352452854 | validation: 0.005717537492084933]
	TIME [epoch: 35.4 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007680362541658599		[learning rate: 0.0002946]
	Learning Rate: 0.000294599
	LOSS [training: 0.007680362541658599 | validation: 0.005348626893975745]
	TIME [epoch: 35.4 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0070148113284945485		[learning rate: 0.00029343]
	Learning Rate: 0.000293427
	LOSS [training: 0.0070148113284945485 | validation: 0.0051064837162840245]
	TIME [epoch: 35.4 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006981079721258576		[learning rate: 0.00029226]
	Learning Rate: 0.00029226
	LOSS [training: 0.006981079721258576 | validation: 0.005851842042408949]
	TIME [epoch: 35.4 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006338388439945156		[learning rate: 0.0002911]
	Learning Rate: 0.000291098
	LOSS [training: 0.006338388439945156 | validation: 0.005362370878298309]
	TIME [epoch: 35.4 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007212109164665377		[learning rate: 0.00028994]
	Learning Rate: 0.00028994
	LOSS [training: 0.007212109164665377 | validation: 0.0052837091514309495]
	TIME [epoch: 35.3 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00778383341222735		[learning rate: 0.00028879]
	Learning Rate: 0.000288786
	LOSS [training: 0.00778383341222735 | validation: 0.005997137989041047]
	TIME [epoch: 35.4 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011486068021770685		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.011486068021770685 | validation: 0.005788001786007918]
	TIME [epoch: 35.4 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0076179328065648306		[learning rate: 0.00028649]
	Learning Rate: 0.000286494
	LOSS [training: 0.0076179328065648306 | validation: 0.005352287700980072]
	TIME [epoch: 35.4 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007014949693978349		[learning rate: 0.00028535]
	Learning Rate: 0.000285354
	LOSS [training: 0.007014949693978349 | validation: 0.005118262337962194]
	TIME [epoch: 35.3 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006968753699287126		[learning rate: 0.00028422]
	Learning Rate: 0.00028422
	LOSS [training: 0.006968753699287126 | validation: 0.005283571494294629]
	TIME [epoch: 35.4 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007291485581965507		[learning rate: 0.00028309]
	Learning Rate: 0.000283089
	LOSS [training: 0.007291485581965507 | validation: 0.005293201725504755]
	TIME [epoch: 35.4 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007190255095956533		[learning rate: 0.00028196]
	Learning Rate: 0.000281963
	LOSS [training: 0.007190255095956533 | validation: 0.00580846260446947]
	TIME [epoch: 35.4 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006661493918946674		[learning rate: 0.00028084]
	Learning Rate: 0.000280842
	LOSS [training: 0.006661493918946674 | validation: 0.005792350069717252]
	TIME [epoch: 35.4 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006447149054752632		[learning rate: 0.00027972]
	Learning Rate: 0.000279725
	LOSS [training: 0.006447149054752632 | validation: 0.005464957718655153]
	TIME [epoch: 35.3 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006627247229680672		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.006627247229680672 | validation: 0.006414604417008066]
	TIME [epoch: 35.3 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0064872005965247136		[learning rate: 0.0002775]
	Learning Rate: 0.000277504
	LOSS [training: 0.0064872005965247136 | validation: 0.0049490752215632355]
	TIME [epoch: 35.3 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_944.pth
	Model improved!!!
EPOCH 945/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007149588873323603		[learning rate: 0.0002764]
	Learning Rate: 0.0002764
	LOSS [training: 0.007149588873323603 | validation: 0.00530772729342385]
	TIME [epoch: 35.5 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006367875647375903		[learning rate: 0.0002753]
	Learning Rate: 0.000275301
	LOSS [training: 0.006367875647375903 | validation: 0.005407138335391921]
	TIME [epoch: 35.3 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009664510112869134		[learning rate: 0.00027421]
	Learning Rate: 0.000274206
	LOSS [training: 0.009664510112869134 | validation: 0.00571175605407198]
	TIME [epoch: 35.3 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007053767011591007		[learning rate: 0.00027312]
	Learning Rate: 0.000273115
	LOSS [training: 0.007053767011591007 | validation: 0.005668239088706657]
	TIME [epoch: 35.3 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007189530683253518		[learning rate: 0.00027203]
	Learning Rate: 0.000272029
	LOSS [training: 0.007189530683253518 | validation: 0.005267208130716435]
	TIME [epoch: 35.4 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007064799996295011		[learning rate: 0.00027095]
	Learning Rate: 0.000270947
	LOSS [training: 0.007064799996295011 | validation: 0.005013106192548498]
	TIME [epoch: 35.3 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007003646960436772		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.007003646960436772 | validation: 0.005291547250265332]
	TIME [epoch: 35.3 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006459213999136394		[learning rate: 0.0002688]
	Learning Rate: 0.000268796
	LOSS [training: 0.006459213999136394 | validation: 0.005296639389960487]
	TIME [epoch: 35.3 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006913074381160482		[learning rate: 0.00026773]
	Learning Rate: 0.000267727
	LOSS [training: 0.006913074381160482 | validation: 0.0050495530766460385]
	TIME [epoch: 35.3 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0071156385374054314		[learning rate: 0.00026666]
	Learning Rate: 0.000266662
	LOSS [training: 0.0071156385374054314 | validation: 0.005552691451871152]
	TIME [epoch: 35.3 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006954105483425385		[learning rate: 0.0002656]
	Learning Rate: 0.000265602
	LOSS [training: 0.006954105483425385 | validation: 0.005285980260431776]
	TIME [epoch: 35.3 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006933509109304132		[learning rate: 0.00026455]
	Learning Rate: 0.000264545
	LOSS [training: 0.006933509109304132 | validation: 0.005614024247492662]
	TIME [epoch: 35.3 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006283934750765961		[learning rate: 0.00026349]
	Learning Rate: 0.000263493
	LOSS [training: 0.006283934750765961 | validation: 0.005575862724058149]
	TIME [epoch: 35.3 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006373845150630315		[learning rate: 0.00026245]
	Learning Rate: 0.000262445
	LOSS [training: 0.006373845150630315 | validation: 0.0064900188594139594]
	TIME [epoch: 35.4 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008313241375399485		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.008313241375399485 | validation: 0.00493535447384752]
	TIME [epoch: 35.3 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_959.pth
	Model improved!!!
EPOCH 960/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007243446894742009		[learning rate: 0.00026036]
	Learning Rate: 0.000260362
	LOSS [training: 0.007243446894742009 | validation: 0.0054744625808451144]
	TIME [epoch: 35.4 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006654990332112413		[learning rate: 0.00025933]
	Learning Rate: 0.000259326
	LOSS [training: 0.006654990332112413 | validation: 0.005036610950403824]
	TIME [epoch: 35.3 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006596076688545003		[learning rate: 0.00025829]
	Learning Rate: 0.000258295
	LOSS [training: 0.006596076688545003 | validation: 0.005330762489049371]
	TIME [epoch: 35.4 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006419836861064991		[learning rate: 0.00025727]
	Learning Rate: 0.000257267
	LOSS [training: 0.006419836861064991 | validation: 0.005117245028222616]
	TIME [epoch: 35.4 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0064585037882765		[learning rate: 0.00025624]
	Learning Rate: 0.000256244
	LOSS [training: 0.0064585037882765 | validation: 0.005693250000648962]
	TIME [epoch: 35.4 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007150393340202784		[learning rate: 0.00025522]
	Learning Rate: 0.000255225
	LOSS [training: 0.007150393340202784 | validation: 0.005741132054596957]
	TIME [epoch: 35.3 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00670799482578965		[learning rate: 0.00025421]
	Learning Rate: 0.00025421
	LOSS [training: 0.00670799482578965 | validation: 0.0050165511706954736]
	TIME [epoch: 35.4 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006484541041748533		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.006484541041748533 | validation: 0.007132200538827305]
	TIME [epoch: 35.4 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007279870220935452		[learning rate: 0.00025219]
	Learning Rate: 0.000252192
	LOSS [training: 0.007279870220935452 | validation: 0.005522171744499631]
	TIME [epoch: 35.4 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007008098621779891		[learning rate: 0.00025119]
	Learning Rate: 0.000251189
	LOSS [training: 0.007008098621779891 | validation: 0.00569893528304525]
	TIME [epoch: 35.3 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007084524090870368		[learning rate: 0.00025019]
	Learning Rate: 0.00025019
	LOSS [training: 0.007084524090870368 | validation: 0.005196136528159992]
	TIME [epoch: 35.4 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0068910361705261		[learning rate: 0.00024919]
	Learning Rate: 0.000249195
	LOSS [training: 0.0068910361705261 | validation: 0.005170489749086067]
	TIME [epoch: 35.3 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007306201431750555		[learning rate: 0.0002482]
	Learning Rate: 0.000248203
	LOSS [training: 0.007306201431750555 | validation: 0.005171237810842095]
	TIME [epoch: 35.4 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007043687949624067		[learning rate: 0.00024722]
	Learning Rate: 0.000247216
	LOSS [training: 0.007043687949624067 | validation: 0.0051158127631448875]
	TIME [epoch: 35.3 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007565383184248726		[learning rate: 0.00024623]
	Learning Rate: 0.000246233
	LOSS [training: 0.007565383184248726 | validation: 0.005086436987012691]
	TIME [epoch: 35.4 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0060432541473299075		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.0060432541473299075 | validation: 0.005464125512304285]
	TIME [epoch: 35.4 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006741663766640817		[learning rate: 0.00024428]
	Learning Rate: 0.000244278
	LOSS [training: 0.006741663766640817 | validation: 0.005355480803640211]
	TIME [epoch: 35.4 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006715936273931158		[learning rate: 0.00024331]
	Learning Rate: 0.000243307
	LOSS [training: 0.006715936273931158 | validation: 0.005645853166834946]
	TIME [epoch: 35.4 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009105462908041234		[learning rate: 0.00024234]
	Learning Rate: 0.000242339
	LOSS [training: 0.009105462908041234 | validation: 0.0059467365846896806]
	TIME [epoch: 35.4 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006900116366318118		[learning rate: 0.00024138]
	Learning Rate: 0.000241375
	LOSS [training: 0.006900116366318118 | validation: 0.004995191794832002]
	TIME [epoch: 35.3 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0065505947748248005		[learning rate: 0.00024042]
	Learning Rate: 0.000240415
	LOSS [training: 0.0065505947748248005 | validation: 0.005415809201361706]
	TIME [epoch: 35.4 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007083626276142081		[learning rate: 0.00023946]
	Learning Rate: 0.000239459
	LOSS [training: 0.007083626276142081 | validation: 0.005209395138067877]
	TIME [epoch: 35.4 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007018442935867336		[learning rate: 0.00023851]
	Learning Rate: 0.000238506
	LOSS [training: 0.007018442935867336 | validation: 0.005047765143514411]
	TIME [epoch: 35.4 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006752786877806037		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.006752786877806037 | validation: 0.005348534812212891]
	TIME [epoch: 35.3 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006402544810597692		[learning rate: 0.00023661]
	Learning Rate: 0.000236613
	LOSS [training: 0.006402544810597692 | validation: 0.005912215539612107]
	TIME [epoch: 35.4 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006920793085180795		[learning rate: 0.00023567]
	Learning Rate: 0.000235672
	LOSS [training: 0.006920793085180795 | validation: 0.0051792688412399725]
	TIME [epoch: 35.4 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006259817252010042		[learning rate: 0.00023473]
	Learning Rate: 0.000234735
	LOSS [training: 0.006259817252010042 | validation: 0.005397445337590701]
	TIME [epoch: 35.4 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007181768255395617		[learning rate: 0.0002338]
	Learning Rate: 0.000233801
	LOSS [training: 0.007181768255395617 | validation: 0.005162451943264425]
	TIME [epoch: 35.4 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006696634556359838		[learning rate: 0.00023287]
	Learning Rate: 0.000232871
	LOSS [training: 0.006696634556359838 | validation: 0.005229148886596624]
	TIME [epoch: 35.4 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007235116798033934		[learning rate: 0.00023194]
	Learning Rate: 0.000231945
	LOSS [training: 0.007235116798033934 | validation: 0.005337693643050825]
	TIME [epoch: 35.4 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007159134913068969		[learning rate: 0.00023102]
	Learning Rate: 0.000231022
	LOSS [training: 0.007159134913068969 | validation: 0.005267036684580893]
	TIME [epoch: 35.4 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006989072943074613		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.006989072943074613 | validation: 0.00543798545047585]
	TIME [epoch: 35.4 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0065642636278995985		[learning rate: 0.00022919]
	Learning Rate: 0.000229188
	LOSS [training: 0.0065642636278995985 | validation: 0.005862894067419333]
	TIME [epoch: 35.4 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006794201793061496		[learning rate: 0.00022828]
	Learning Rate: 0.000228277
	LOSS [training: 0.006794201793061496 | validation: 0.005525910657073592]
	TIME [epoch: 35.4 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007109978025973145		[learning rate: 0.00022737]
	Learning Rate: 0.000227369
	LOSS [training: 0.007109978025973145 | validation: 0.004905177684143794]
	TIME [epoch: 35.4 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_994.pth
	Model improved!!!
EPOCH 995/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006866236346777852		[learning rate: 0.00022646]
	Learning Rate: 0.000226464
	LOSS [training: 0.006866236346777852 | validation: 0.00538775910008316]
	TIME [epoch: 35.4 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007795315963552336		[learning rate: 0.00022556]
	Learning Rate: 0.000225564
	LOSS [training: 0.007795315963552336 | validation: 0.005379025020685102]
	TIME [epoch: 35.3 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006586734618683925		[learning rate: 0.00022467]
	Learning Rate: 0.000224667
	LOSS [training: 0.006586734618683925 | validation: 0.004958316568778]
	TIME [epoch: 35.3 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006502919848455156		[learning rate: 0.00022377]
	Learning Rate: 0.000223773
	LOSS [training: 0.006502919848455156 | validation: 0.005504150755080053]
	TIME [epoch: 35.4 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006842093211898782		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.006842093211898782 | validation: 0.005287673829448579]
	TIME [epoch: 35.4 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007005837868726146		[learning rate: 0.000222]
	Learning Rate: 0.000221997
	LOSS [training: 0.007005837868726146 | validation: 0.004948741399884096]
	TIME [epoch: 35.3 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006504158595921202		[learning rate: 0.00022111]
	Learning Rate: 0.000221114
	LOSS [training: 0.006504158595921202 | validation: 0.005180967239304972]
	TIME [epoch: 35.4 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006445521760427225		[learning rate: 0.00022023]
	Learning Rate: 0.000220234
	LOSS [training: 0.006445521760427225 | validation: 0.005866792530239686]
	TIME [epoch: 35.5 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0064376313687953225		[learning rate: 0.00021936]
	Learning Rate: 0.000219358
	LOSS [training: 0.0064376313687953225 | validation: 0.004846678519232324]
	TIME [epoch: 35.4 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_1003.pth
	Model improved!!!
EPOCH 1004/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006845355185294559		[learning rate: 0.00021849]
	Learning Rate: 0.000218486
	LOSS [training: 0.006845355185294559 | validation: 0.005343604731978893]
	TIME [epoch: 35.4 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007127223346877652		[learning rate: 0.00021762]
	Learning Rate: 0.000217617
	LOSS [training: 0.007127223346877652 | validation: 0.004765956293229579]
	TIME [epoch: 35.4 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_1005.pth
	Model improved!!!
EPOCH 1006/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006775218914220214		[learning rate: 0.00021675]
	Learning Rate: 0.000216751
	LOSS [training: 0.006775218914220214 | validation: 0.00501233998470962]
	TIME [epoch: 35.4 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006910347337640933		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.006910347337640933 | validation: 0.0050810666041246535]
	TIME [epoch: 35.3 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006877549442307047		[learning rate: 0.00021503]
	Learning Rate: 0.00021503
	LOSS [training: 0.006877549442307047 | validation: 0.005392924269997339]
	TIME [epoch: 35.3 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007204738228357904		[learning rate: 0.00021418]
	Learning Rate: 0.000214175
	LOSS [training: 0.007204738228357904 | validation: 0.0047374878935597]
	TIME [epoch: 35.3 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_1009.pth
	Model improved!!!
EPOCH 1010/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006848935689330787		[learning rate: 0.00021332]
	Learning Rate: 0.000213323
	LOSS [training: 0.006848935689330787 | validation: 0.005201310593500854]
	TIME [epoch: 35.3 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006654038164485377		[learning rate: 0.00021247]
	Learning Rate: 0.000212475
	LOSS [training: 0.006654038164485377 | validation: 0.005796337751275331]
	TIME [epoch: 35.3 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006644414643321768		[learning rate: 0.00021163]
	Learning Rate: 0.00021163
	LOSS [training: 0.006644414643321768 | validation: 0.004622519823608582]
	TIME [epoch: 35.3 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_1012.pth
	Model improved!!!
EPOCH 1013/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006925155775377491		[learning rate: 0.00021079]
	Learning Rate: 0.000210788
	LOSS [training: 0.006925155775377491 | validation: 0.0049290113503463445]
	TIME [epoch: 35.4 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007541309208892382		[learning rate: 0.00020995]
	Learning Rate: 0.00020995
	LOSS [training: 0.007541309208892382 | validation: 0.005200450981697134]
	TIME [epoch: 35.3 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00924280388716281		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.00924280388716281 | validation: 0.005375583869477759]
	TIME [epoch: 35.3 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00653509566677781		[learning rate: 0.00020828]
	Learning Rate: 0.000208283
	LOSS [training: 0.00653509566677781 | validation: 0.005592547413373623]
	TIME [epoch: 35.4 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010440100214098587		[learning rate: 0.00020745]
	Learning Rate: 0.000207455
	LOSS [training: 0.010440100214098587 | validation: 0.005232613321935232]
	TIME [epoch: 35.4 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007415324443385135		[learning rate: 0.00020663]
	Learning Rate: 0.00020663
	LOSS [training: 0.007415324443385135 | validation: 0.00516543384113847]
	TIME [epoch: 35.4 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0067506205340929		[learning rate: 0.00020581]
	Learning Rate: 0.000205808
	LOSS [training: 0.0067506205340929 | validation: 0.004817670927939628]
	TIME [epoch: 35.4 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006840890821756767		[learning rate: 0.00020499]
	Learning Rate: 0.000204989
	LOSS [training: 0.006840890821756767 | validation: 0.004815162633004846]
	TIME [epoch: 35.3 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006792493681638279		[learning rate: 0.00020417]
	Learning Rate: 0.000204174
	LOSS [training: 0.006792493681638279 | validation: 0.005090315752196038]
	TIME [epoch: 35.3 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007456132553631815		[learning rate: 0.00020336]
	Learning Rate: 0.000203362
	LOSS [training: 0.007456132553631815 | validation: 0.004863278565455373]
	TIME [epoch: 35.4 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007143757666830227		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.007143757666830227 | validation: 0.005196935263094935]
	TIME [epoch: 35.3 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00912394681908759		[learning rate: 0.00020175]
	Learning Rate: 0.000201747
	LOSS [training: 0.00912394681908759 | validation: 0.005295770398907931]
	TIME [epoch: 35.4 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006744970151909593		[learning rate: 0.00020094]
	Learning Rate: 0.000200945
	LOSS [training: 0.006744970151909593 | validation: 0.0048524894817747865]
	TIME [epoch: 35.4 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006413608655349067		[learning rate: 0.00020015]
	Learning Rate: 0.000200146
	LOSS [training: 0.006413608655349067 | validation: 0.005165568643955183]
	TIME [epoch: 35.3 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006356369391793064		[learning rate: 0.00019935]
	Learning Rate: 0.00019935
	LOSS [training: 0.006356369391793064 | validation: 0.005295199605753354]
	TIME [epoch: 35.3 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0068338451192907525		[learning rate: 0.00019856]
	Learning Rate: 0.000198557
	LOSS [training: 0.0068338451192907525 | validation: 0.004986973564255624]
	TIME [epoch: 35.3 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007644072036308745		[learning rate: 0.00019777]
	Learning Rate: 0.000197767
	LOSS [training: 0.007644072036308745 | validation: 0.0050695396134898905]
	TIME [epoch: 35.3 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006261834420452767		[learning rate: 0.00019698]
	Learning Rate: 0.00019698
	LOSS [training: 0.006261834420452767 | validation: 0.004491384104476261]
	TIME [epoch: 35.3 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_1030.pth
	Model improved!!!
EPOCH 1031/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006938584575449556		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.006938584575449556 | validation: 0.005357788157262004]
	TIME [epoch: 35.3 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006567041383553202		[learning rate: 0.00019542]
	Learning Rate: 0.000195417
	LOSS [training: 0.006567041383553202 | validation: 0.005023404645652825]
	TIME [epoch: 35.4 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006278808605817244		[learning rate: 0.00019464]
	Learning Rate: 0.000194639
	LOSS [training: 0.006278808605817244 | validation: 0.005092734718089847]
	TIME [epoch: 35.3 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00648020857549917		[learning rate: 0.00019387]
	Learning Rate: 0.000193865
	LOSS [training: 0.00648020857549917 | validation: 0.004887504610105786]
	TIME [epoch: 35.4 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006819092494295875		[learning rate: 0.00019309]
	Learning Rate: 0.000193094
	LOSS [training: 0.006819092494295875 | validation: 0.004886165109446764]
	TIME [epoch: 35.3 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00919543018458095		[learning rate: 0.00019233]
	Learning Rate: 0.000192326
	LOSS [training: 0.00919543018458095 | validation: 0.0053365620460631025]
	TIME [epoch: 35.4 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006987759923519543		[learning rate: 0.00019156]
	Learning Rate: 0.000191561
	LOSS [training: 0.006987759923519543 | validation: 0.004861356260862628]
	TIME [epoch: 35.3 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006833529688916141		[learning rate: 0.0001908]
	Learning Rate: 0.000190799
	LOSS [training: 0.006833529688916141 | validation: 0.004649957470130857]
	TIME [epoch: 35.4 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006989124549551118		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.006989124549551118 | validation: 0.0051274199808639545]
	TIME [epoch: 35.4 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006388816854138262		[learning rate: 0.00018928]
	Learning Rate: 0.000189285
	LOSS [training: 0.006388816854138262 | validation: 0.0048591704855794945]
	TIME [epoch: 35.3 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006846383693232462		[learning rate: 0.00018853]
	Learning Rate: 0.000188532
	LOSS [training: 0.006846383693232462 | validation: 0.005253866609529548]
	TIME [epoch: 35.4 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006168986537677556		[learning rate: 0.00018778]
	Learning Rate: 0.000187782
	LOSS [training: 0.006168986537677556 | validation: 0.004981326125471433]
	TIME [epoch: 35.3 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007452008919532303		[learning rate: 0.00018704]
	Learning Rate: 0.000187035
	LOSS [training: 0.007452008919532303 | validation: 0.005440775364993594]
	TIME [epoch: 35.4 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006362626601321322		[learning rate: 0.00018629]
	Learning Rate: 0.000186291
	LOSS [training: 0.006362626601321322 | validation: 0.005092518744681516]
	TIME [epoch: 35.4 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007081829337850944		[learning rate: 0.00018555]
	Learning Rate: 0.00018555
	LOSS [training: 0.007081829337850944 | validation: 0.00494122360470032]
	TIME [epoch: 35.3 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006422241492479068		[learning rate: 0.00018481]
	Learning Rate: 0.000184812
	LOSS [training: 0.006422241492479068 | validation: 0.005040693896405206]
	TIME [epoch: 35.3 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006819855450057539		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.006819855450057539 | validation: 0.005088695449591932]
	TIME [epoch: 35.3 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0068800121214366875		[learning rate: 0.00018335]
	Learning Rate: 0.000183345
	LOSS [training: 0.0068800121214366875 | validation: 0.005328729915412836]
	TIME [epoch: 35.3 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006708138522478723		[learning rate: 0.00018262]
	Learning Rate: 0.000182616
	LOSS [training: 0.006708138522478723 | validation: 0.005206004054783726]
	TIME [epoch: 35.3 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006784264867367495		[learning rate: 0.00018189]
	Learning Rate: 0.00018189
	LOSS [training: 0.006784264867367495 | validation: 0.005757730716120762]
	TIME [epoch: 35.3 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006433754829610146		[learning rate: 0.00018117]
	Learning Rate: 0.000181166
	LOSS [training: 0.006433754829610146 | validation: 0.004994011853017227]
	TIME [epoch: 35.4 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006474812217813502		[learning rate: 0.00018045]
	Learning Rate: 0.000180446
	LOSS [training: 0.006474812217813502 | validation: 0.005548036030201234]
	TIME [epoch: 35.3 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006708951288681216		[learning rate: 0.00017973]
	Learning Rate: 0.000179728
	LOSS [training: 0.006708951288681216 | validation: 0.004894591026999833]
	TIME [epoch: 35.3 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006784204734634772		[learning rate: 0.00017901]
	Learning Rate: 0.000179013
	LOSS [training: 0.006784204734634772 | validation: 0.004543159763451836]
	TIME [epoch: 35.3 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00650162690169474		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.00650162690169474 | validation: 0.005205078569572219]
	TIME [epoch: 35.3 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006549684965962015		[learning rate: 0.00017759]
	Learning Rate: 0.000177592
	LOSS [training: 0.006549684965962015 | validation: 0.004786704031067216]
	TIME [epoch: 35.4 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007143652002401185		[learning rate: 0.00017689]
	Learning Rate: 0.000176886
	LOSS [training: 0.007143652002401185 | validation: 0.004745297468881483]
	TIME [epoch: 35.4 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006908988208018973		[learning rate: 0.00017618]
	Learning Rate: 0.000176182
	LOSS [training: 0.006908988208018973 | validation: 0.005464294929574805]
	TIME [epoch: 35.3 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006936638833045821		[learning rate: 0.00017548]
	Learning Rate: 0.000175481
	LOSS [training: 0.006936638833045821 | validation: 0.0055381946571893]
	TIME [epoch: 35.4 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006122710250019436		[learning rate: 0.00017478]
	Learning Rate: 0.000174783
	LOSS [training: 0.006122710250019436 | validation: 0.004967354974950693]
	TIME [epoch: 35.3 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006609909484114122		[learning rate: 0.00017409]
	Learning Rate: 0.000174088
	LOSS [training: 0.006609909484114122 | validation: 0.005199601548140423]
	TIME [epoch: 35.4 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009818016221276146		[learning rate: 0.0001734]
	Learning Rate: 0.000173396
	LOSS [training: 0.009818016221276146 | validation: 0.0051271580408009144]
	TIME [epoch: 35.3 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006857511239779221		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.006857511239779221 | validation: 0.005458773250626452]
	TIME [epoch: 35.5 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006251573379962277		[learning rate: 0.00017202]
	Learning Rate: 0.000172019
	LOSS [training: 0.006251573379962277 | validation: 0.004871007585587291]
	TIME [epoch: 35.3 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006656875166825518		[learning rate: 0.00017134]
	Learning Rate: 0.000171335
	LOSS [training: 0.006656875166825518 | validation: 0.004785874456318844]
	TIME [epoch: 35.3 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006634349092103269		[learning rate: 0.00017065]
	Learning Rate: 0.000170654
	LOSS [training: 0.006634349092103269 | validation: 0.004859238339188635]
	TIME [epoch: 35.3 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0066449815618732835		[learning rate: 0.00016997]
	Learning Rate: 0.000169975
	LOSS [training: 0.0066449815618732835 | validation: 0.00546085125087851]
	TIME [epoch: 35.4 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006647185415906965		[learning rate: 0.0001693]
	Learning Rate: 0.000169299
	LOSS [training: 0.006647185415906965 | validation: 0.004865075471833573]
	TIME [epoch: 35.3 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006491715438092746		[learning rate: 0.00016863]
	Learning Rate: 0.000168625
	LOSS [training: 0.006491715438092746 | validation: 0.004781032555572269]
	TIME [epoch: 35.4 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006324159138244372		[learning rate: 0.00016795]
	Learning Rate: 0.000167955
	LOSS [training: 0.006324159138244372 | validation: 0.005178588305497814]
	TIME [epoch: 35.3 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0063250990992257915		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.0063250990992257915 | validation: 0.004971190215142919]
	TIME [epoch: 35.3 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006743628935007505		[learning rate: 0.00016662]
	Learning Rate: 0.000166621
	LOSS [training: 0.006743628935007505 | validation: 0.004914683166661842]
	TIME [epoch: 35.4 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006160829263611876		[learning rate: 0.00016596]
	Learning Rate: 0.000165959
	LOSS [training: 0.006160829263611876 | validation: 0.005369295974070392]
	TIME [epoch: 35.4 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006331587767212726		[learning rate: 0.0001653]
	Learning Rate: 0.000165299
	LOSS [training: 0.006331587767212726 | validation: 0.004563206462093636]
	TIME [epoch: 35.3 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006581123035599007		[learning rate: 0.00016464]
	Learning Rate: 0.000164641
	LOSS [training: 0.006581123035599007 | validation: 0.004740707830737674]
	TIME [epoch: 35.4 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006416187761168308		[learning rate: 0.00016399]
	Learning Rate: 0.000163986
	LOSS [training: 0.006416187761168308 | validation: 0.005206268071401766]
	TIME [epoch: 35.3 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007033589926487015		[learning rate: 0.00016333]
	Learning Rate: 0.000163334
	LOSS [training: 0.007033589926487015 | validation: 0.005134983553032391]
	TIME [epoch: 35.3 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006310916560175311		[learning rate: 0.00016268]
	Learning Rate: 0.000162685
	LOSS [training: 0.006310916560175311 | validation: 0.004925557446578029]
	TIME [epoch: 35.3 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0064204980068807245		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.0064204980068807245 | validation: 0.004569374189758451]
	TIME [epoch: 35.3 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0061920668239693905		[learning rate: 0.00016139]
	Learning Rate: 0.000161393
	LOSS [training: 0.0061920668239693905 | validation: 0.004690278698678668]
	TIME [epoch: 35.3 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006935679101584194		[learning rate: 0.00016075]
	Learning Rate: 0.000160751
	LOSS [training: 0.006935679101584194 | validation: 0.005134354402244328]
	TIME [epoch: 35.3 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00619145190599754		[learning rate: 0.00016011]
	Learning Rate: 0.000160112
	LOSS [training: 0.00619145190599754 | validation: 0.004390575454133816]
	TIME [epoch: 35.3 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_1082.pth
	Model improved!!!
EPOCH 1083/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006687916031722176		[learning rate: 0.00015947]
	Learning Rate: 0.000159475
	LOSS [training: 0.006687916031722176 | validation: 0.005048158928944994]
	TIME [epoch: 35.3 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006415352053545024		[learning rate: 0.00015884]
	Learning Rate: 0.000158841
	LOSS [training: 0.006415352053545024 | validation: 0.0054934360142579975]
	TIME [epoch: 35.3 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006328477395574418		[learning rate: 0.00015821]
	Learning Rate: 0.000158209
	LOSS [training: 0.006328477395574418 | validation: 0.005267309336183344]
	TIME [epoch: 35.3 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006189017670144415		[learning rate: 0.00015758]
	Learning Rate: 0.00015758
	LOSS [training: 0.006189017670144415 | validation: 0.004644300999539404]
	TIME [epoch: 35.3 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0069411291370027085		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.0069411291370027085 | validation: 0.004434970543614446]
	TIME [epoch: 35.3 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006391751434594969		[learning rate: 0.00015633]
	Learning Rate: 0.000156329
	LOSS [training: 0.006391751434594969 | validation: 0.005523652623766894]
	TIME [epoch: 35.4 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006437956877136056		[learning rate: 0.00015571]
	Learning Rate: 0.000155707
	LOSS [training: 0.006437956877136056 | validation: 0.00527226267224354]
	TIME [epoch: 35.4 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006325217130900797		[learning rate: 0.00015509]
	Learning Rate: 0.000155088
	LOSS [training: 0.006325217130900797 | validation: 0.004938797650349361]
	TIME [epoch: 35.4 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006910723973643487		[learning rate: 0.00015447]
	Learning Rate: 0.000154471
	LOSS [training: 0.006910723973643487 | validation: 0.0050409992429121695]
	TIME [epoch: 35.4 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009668441067883362		[learning rate: 0.00015386]
	Learning Rate: 0.000153856
	LOSS [training: 0.009668441067883362 | validation: 0.005607330786497196]
	TIME [epoch: 35.4 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006618477944192434		[learning rate: 0.00015324]
	Learning Rate: 0.000153244
	LOSS [training: 0.006618477944192434 | validation: 0.004750546845993556]
	TIME [epoch: 35.4 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00967525549794175		[learning rate: 0.00015263]
	Learning Rate: 0.000152635
	LOSS [training: 0.00967525549794175 | validation: 0.004843382218375961]
	TIME [epoch: 35.4 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005917232779697587		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.005917232779697587 | validation: 0.005085856436567716]
	TIME [epoch: 35.4 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006616328515917096		[learning rate: 0.00015142]
	Learning Rate: 0.000151423
	LOSS [training: 0.006616328515917096 | validation: 0.004905549218782693]
	TIME [epoch: 35.4 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006384196833830583		[learning rate: 0.00015082]
	Learning Rate: 0.000150821
	LOSS [training: 0.006384196833830583 | validation: 0.005270639895496445]
	TIME [epoch: 35.4 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006883597916813012		[learning rate: 0.00015022]
	Learning Rate: 0.000150221
	LOSS [training: 0.006883597916813012 | validation: 0.005492409133243825]
	TIME [epoch: 35.4 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00685155148635001		[learning rate: 0.00014962]
	Learning Rate: 0.000149624
	LOSS [training: 0.00685155148635001 | validation: 0.004983662983056641]
	TIME [epoch: 35.4 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007377980860716669		[learning rate: 0.00014903]
	Learning Rate: 0.000149028
	LOSS [training: 0.007377980860716669 | validation: 0.005123538459343955]
	TIME [epoch: 35.5 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007430512814016874		[learning rate: 0.00014844]
	Learning Rate: 0.000148436
	LOSS [training: 0.007430512814016874 | validation: 0.004404135106771792]
	TIME [epoch: 35.3 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0068857576968239355		[learning rate: 0.00014785]
	Learning Rate: 0.000147845
	LOSS [training: 0.0068857576968239355 | validation: 0.00503220690666188]
	TIME [epoch: 35.4 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00660446355721802		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.00660446355721802 | validation: 0.0048799476737166145]
	TIME [epoch: 35.4 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007093712427685315		[learning rate: 0.00014667]
	Learning Rate: 0.000146672
	LOSS [training: 0.007093712427685315 | validation: 0.005020632241026189]
	TIME [epoch: 35.4 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006439321976303727		[learning rate: 0.00014609]
	Learning Rate: 0.000146088
	LOSS [training: 0.006439321976303727 | validation: 0.005432068799122205]
	TIME [epoch: 35.4 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0064339163276091885		[learning rate: 0.00014551]
	Learning Rate: 0.000145507
	LOSS [training: 0.0064339163276091885 | validation: 0.004724279377137726]
	TIME [epoch: 35.4 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0062436703347718185		[learning rate: 0.00014493]
	Learning Rate: 0.000144929
	LOSS [training: 0.0062436703347718185 | validation: 0.005179282079057162]
	TIME [epoch: 35.4 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006552642296777868		[learning rate: 0.00014435]
	Learning Rate: 0.000144352
	LOSS [training: 0.006552642296777868 | validation: 0.005014779658042935]
	TIME [epoch: 35.3 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006935407567725755		[learning rate: 0.00014378]
	Learning Rate: 0.000143778
	LOSS [training: 0.006935407567725755 | validation: 0.004805829532727542]
	TIME [epoch: 35.3 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007028624629301221		[learning rate: 0.00014321]
	Learning Rate: 0.000143206
	LOSS [training: 0.007028624629301221 | validation: 0.0048553045153674115]
	TIME [epoch: 35.4 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006856686552527914		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.006856686552527914 | validation: 0.004959336185952257]
	TIME [epoch: 35.4 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0065780323956606945		[learning rate: 0.00014207]
	Learning Rate: 0.000142069
	LOSS [training: 0.0065780323956606945 | validation: 0.004701258446134213]
	TIME [epoch: 35.4 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006575366075249238		[learning rate: 0.0001415]
	Learning Rate: 0.000141504
	LOSS [training: 0.006575366075249238 | validation: 0.0051047484107835574]
	TIME [epoch: 35.3 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006552649494532087		[learning rate: 0.00014094]
	Learning Rate: 0.000140941
	LOSS [training: 0.006552649494532087 | validation: 0.0047825573915528845]
	TIME [epoch: 35.4 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00687270201345626		[learning rate: 0.00014038]
	Learning Rate: 0.000140381
	LOSS [training: 0.00687270201345626 | validation: 0.005140107558300771]
	TIME [epoch: 35.4 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006504340833054279		[learning rate: 0.00013982]
	Learning Rate: 0.000139822
	LOSS [training: 0.006504340833054279 | validation: 0.005030657167262045]
	TIME [epoch: 35.4 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006550903635775172		[learning rate: 0.00013927]
	Learning Rate: 0.000139266
	LOSS [training: 0.006550903635775172 | validation: 0.004914454762279421]
	TIME [epoch: 35.4 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006433707760588414		[learning rate: 0.00013871]
	Learning Rate: 0.000138712
	LOSS [training: 0.006433707760588414 | validation: 0.004806277379749253]
	TIME [epoch: 35.4 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00713198228159005		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.00713198228159005 | validation: 0.004726319267974581]
	TIME [epoch: 35.3 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006204810231828562		[learning rate: 0.00013761]
	Learning Rate: 0.000137611
	LOSS [training: 0.006204810231828562 | validation: 0.005034453622246549]
	TIME [epoch: 35.4 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006301527646906122		[learning rate: 0.00013706]
	Learning Rate: 0.000137064
	LOSS [training: 0.006301527646906122 | validation: 0.004701013886831023]
	TIME [epoch: 35.4 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006194210035320082		[learning rate: 0.00013652]
	Learning Rate: 0.000136519
	LOSS [training: 0.006194210035320082 | validation: 0.004877871766832076]
	TIME [epoch: 35.4 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006522297704990556		[learning rate: 0.00013598]
	Learning Rate: 0.000135976
	LOSS [training: 0.006522297704990556 | validation: 0.004847936599426427]
	TIME [epoch: 35.4 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006560146773237443		[learning rate: 0.00013543]
	Learning Rate: 0.000135435
	LOSS [training: 0.006560146773237443 | validation: 0.00492796765003269]
	TIME [epoch: 35.4 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006733131361644621		[learning rate: 0.0001349]
	Learning Rate: 0.000134896
	LOSS [training: 0.006733131361644621 | validation: 0.0049985050427778345]
	TIME [epoch: 35.4 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0068241492744524936		[learning rate: 0.00013436]
	Learning Rate: 0.00013436
	LOSS [training: 0.0068241492744524936 | validation: 0.0046510929848281365]
	TIME [epoch: 35.4 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0069395821255277814		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.0069395821255277814 | validation: 0.005005552283226815]
	TIME [epoch: 35.4 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006614170480546057		[learning rate: 0.00013329]
	Learning Rate: 0.000133293
	LOSS [training: 0.006614170480546057 | validation: 0.005083366246544228]
	TIME [epoch: 35.3 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006688339523869826		[learning rate: 0.00013276]
	Learning Rate: 0.000132763
	LOSS [training: 0.006688339523869826 | validation: 0.0054642612135088475]
	TIME [epoch: 35.4 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006591018274778321		[learning rate: 0.00013223]
	Learning Rate: 0.000132235
	LOSS [training: 0.006591018274778321 | validation: 0.004718434082331938]
	TIME [epoch: 35.4 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006337760319817735		[learning rate: 0.00013171]
	Learning Rate: 0.000131709
	LOSS [training: 0.006337760319817735 | validation: 0.005258305424978941]
	TIME [epoch: 35.4 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006389452867248366		[learning rate: 0.00013119]
	Learning Rate: 0.000131185
	LOSS [training: 0.006389452867248366 | validation: 0.0046053349901700276]
	TIME [epoch: 35.4 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0067316569192893885		[learning rate: 0.00013066]
	Learning Rate: 0.000130663
	LOSS [training: 0.0067316569192893885 | validation: 0.005177196511996982]
	TIME [epoch: 35.4 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006414723771366133		[learning rate: 0.00013014]
	Learning Rate: 0.000130144
	LOSS [training: 0.006414723771366133 | validation: 0.004965255996235415]
	TIME [epoch: 35.4 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00646326356101289		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.00646326356101289 | validation: 0.004864624123166777]
	TIME [epoch: 35.4 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00656655771212156		[learning rate: 0.00012911]
	Learning Rate: 0.000129111
	LOSS [training: 0.00656655771212156 | validation: 0.004651426402186818]
	TIME [epoch: 35.4 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007514274068656605		[learning rate: 0.0001286]
	Learning Rate: 0.000128597
	LOSS [training: 0.007514274068656605 | validation: 0.004969214916218423]
	TIME [epoch: 35.4 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006983889081880958		[learning rate: 0.00012809]
	Learning Rate: 0.000128086
	LOSS [training: 0.006983889081880958 | validation: 0.004854996019232437]
	TIME [epoch: 35.4 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006102630075093845		[learning rate: 0.00012758]
	Learning Rate: 0.000127576
	LOSS [training: 0.006102630075093845 | validation: 0.004731784090432316]
	TIME [epoch: 35.4 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00675760139336572		[learning rate: 0.00012707]
	Learning Rate: 0.000127069
	LOSS [training: 0.00675760139336572 | validation: 0.005010061636167329]
	TIME [epoch: 35.4 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006561230508641108		[learning rate: 0.00012656]
	Learning Rate: 0.000126563
	LOSS [training: 0.006561230508641108 | validation: 0.004319888045318976]
	TIME [epoch: 35.4 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dnmf_v1_20240624_135122/states/model_facs_dec1b_2dnmf_v1_1141.pth
	Model improved!!!
EPOCH 1142/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0064628645417952385		[learning rate: 0.00012606]
	Learning Rate: 0.00012606
	LOSS [training: 0.0064628645417952385 | validation: 0.004660278918976264]
	TIME [epoch: 35.4 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006384237905198934		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.006384237905198934 | validation: 0.004506605937155098]
	TIME [epoch: 35.3 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0072696783123784685		[learning rate: 0.00012506]
	Learning Rate: 0.000125059
	LOSS [training: 0.0072696783123784685 | validation: 0.004926751672231258]
	TIME [epoch: 35.3 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007062837850900166		[learning rate: 0.00012456]
	Learning Rate: 0.000124562
	LOSS [training: 0.007062837850900166 | validation: 0.0046098369827397125]
	TIME [epoch: 35.3 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006712558369544801		[learning rate: 0.00012407]
	Learning Rate: 0.000124066
	LOSS [training: 0.006712558369544801 | validation: 0.004955818167479418]
	TIME [epoch: 35.3 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006363079778162842		[learning rate: 0.00012357]
	Learning Rate: 0.000123573
	LOSS [training: 0.006363079778162842 | validation: 0.005191100602086047]
	TIME [epoch: 35.3 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006576471857056583		[learning rate: 0.00012308]
	Learning Rate: 0.000123081
	LOSS [training: 0.006576471857056583 | validation: 0.005167205210849697]
	TIME [epoch: 35.3 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009126687769971322		[learning rate: 0.00012259]
	Learning Rate: 0.000122592
	LOSS [training: 0.009126687769971322 | validation: 0.0052306395554868245]
	TIME [epoch: 35.3 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007143014724794291		[learning rate: 0.0001221]
	Learning Rate: 0.000122104
	LOSS [training: 0.007143014724794291 | validation: 0.0050641420072639765]
	TIME [epoch: 35.3 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0069866688747589984		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.0069866688747589984 | validation: 0.00481814892958567]
	TIME [epoch: 35.4 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006484002715141216		[learning rate: 0.00012113]
	Learning Rate: 0.000121135
	LOSS [training: 0.006484002715141216 | validation: 0.0056019302278600995]
	TIME [epoch: 35.3 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006675362861304344		[learning rate: 0.00012065]
	Learning Rate: 0.000120653
	LOSS [training: 0.006675362861304344 | validation: 0.0048509881730341145]
	TIME [epoch: 35.3 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007144531110466441		[learning rate: 0.00012017]
	Learning Rate: 0.000120173
	LOSS [training: 0.007144531110466441 | validation: 0.005203564915986747]
	TIME [epoch: 35.3 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006692623120436968		[learning rate: 0.0001197]
	Learning Rate: 0.000119695
	LOSS [training: 0.006692623120436968 | validation: 0.005439872918015585]
	TIME [epoch: 35.3 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00982947662427531		[learning rate: 0.00011922]
	Learning Rate: 0.000119219
	LOSS [training: 0.00982947662427531 | validation: 0.004651579283514772]
	TIME [epoch: 35.4 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006423633118596298		[learning rate: 0.00011875]
	Learning Rate: 0.000118745
	LOSS [training: 0.006423633118596298 | validation: 0.004601047945082178]
	TIME [epoch: 35.3 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007207840371032176		[learning rate: 0.00011827]
	Learning Rate: 0.000118273
	LOSS [training: 0.007207840371032176 | validation: 0.00503526433613108]
	TIME [epoch: 35.3 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0068086753254790085		[learning rate: 0.0001178]
