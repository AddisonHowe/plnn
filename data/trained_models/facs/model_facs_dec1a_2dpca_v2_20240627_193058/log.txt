Args:
Namespace(name='model_facs_dec1a_2dpca_v2', outdir='out/model_training/model_facs_dec1a_2dpca_v2', training_data='data/training_data/facs/pca/dec1/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs/pca/dec1/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=2000, ncells_sample=2000, model_do_sample=False, dt=0.001, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 928898895

Training model...

Saving initial model state to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6408656297760073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6408656297760073 | validation: 0.5714140537937227]
	TIME [epoch: 172 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6128102830575772		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6128102830575772 | validation: 0.5361928178127344]
	TIME [epoch: 144 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.557773881780771		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.557773881780771 | validation: 0.5216282059219394]
	TIME [epoch: 144 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5551659213842037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5551659213842037 | validation: 0.5032961489242995]
	TIME [epoch: 144 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5198316536913187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5198316536913187 | validation: 0.48418777255799855]
	TIME [epoch: 144 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.49478800659131		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49478800659131 | validation: 0.4452084432767672]
	TIME [epoch: 144 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4758747107814383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4758747107814383 | validation: 0.44168283462709174]
	TIME [epoch: 144 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.45590454239394684		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45590454239394684 | validation: 0.40974865469362054]
	TIME [epoch: 145 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3958003755093833		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3958003755093833 | validation: 0.392563937283863]
	TIME [epoch: 145 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3106370287267408		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3106370287267408 | validation: 0.277368144921009]
	TIME [epoch: 144 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3102160624398057		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3102160624398057 | validation: 0.26380554129333]
	TIME [epoch: 144 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24525885119662247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24525885119662247 | validation: 0.21966135938118683]
	TIME [epoch: 144 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22128589645171715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22128589645171715 | validation: 0.1952065819328668]
	TIME [epoch: 144 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.20616513193747027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20616513193747027 | validation: 0.20340058092280922]
	TIME [epoch: 144 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1966082712949987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1966082712949987 | validation: 0.2578473588904928]
	TIME [epoch: 144 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.20066197792173623		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20066197792173623 | validation: 0.17312264386381881]
	TIME [epoch: 144 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1961274803567742		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1961274803567742 | validation: 0.1640788034656923]
	TIME [epoch: 144 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17261327282230707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17261327282230707 | validation: 0.15105869338463912]
	TIME [epoch: 144 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15667573240110635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15667573240110635 | validation: 0.14362680169533634]
	TIME [epoch: 145 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15488612315450434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15488612315450434 | validation: 0.1440286800543622]
	TIME [epoch: 145 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16043268905673697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16043268905673697 | validation: 0.13613272046465447]
	TIME [epoch: 145 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15389413866028745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15389413866028745 | validation: 0.15970949644260554]
	TIME [epoch: 144 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14963894556504986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14963894556504986 | validation: 0.14167964998817842]
	TIME [epoch: 145 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15074182039758785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15074182039758785 | validation: 0.12383785066686621]
	TIME [epoch: 145 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1428959915271091		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1428959915271091 | validation: 0.13649110645736795]
	TIME [epoch: 144 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14588571347715512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14588571347715512 | validation: 0.13917822219540316]
	TIME [epoch: 144 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14384819713285352		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14384819713285352 | validation: 0.1278545639011601]
	TIME [epoch: 144 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14178796562397467		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14178796562397467 | validation: 0.12255050626819255]
	TIME [epoch: 145 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13872135995229012		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13872135995229012 | validation: 0.12979047559586132]
	TIME [epoch: 144 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14031748453633408		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14031748453633408 | validation: 0.18450081661187714]
	TIME [epoch: 144 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.143706626765618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.143706626765618 | validation: 0.1472036519115878]
	TIME [epoch: 144 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13578612857235667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13578612857235667 | validation: 0.12255097347324032]
	TIME [epoch: 144 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13791952635067978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13791952635067978 | validation: 0.12648997970635764]
	TIME [epoch: 145 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12843701515766826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12843701515766826 | validation: 0.11550796955661542]
	TIME [epoch: 145 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13501231104977343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13501231104977343 | validation: 0.14500114017056098]
	TIME [epoch: 144 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13534344383038752		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13534344383038752 | validation: 0.12135923716466357]
	TIME [epoch: 144 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13046366172271875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13046366172271875 | validation: 0.11342809395478817]
	TIME [epoch: 144 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12866328978810695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12866328978810695 | validation: 0.12819742157123415]
	TIME [epoch: 144 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13020416248618955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13020416248618955 | validation: 0.12667576172578143]
	TIME [epoch: 144 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1277659425269705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1277659425269705 | validation: 0.10845555654225354]
	TIME [epoch: 144 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12632967520409227		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12632967520409227 | validation: 0.10700916883167369]
	TIME [epoch: 144 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12422044245258114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12422044245258114 | validation: 0.108328766936497]
	TIME [epoch: 145 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13214929833811562		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13214929833811562 | validation: 0.11038300644787813]
	TIME [epoch: 145 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12419245395929239		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12419245395929239 | validation: 0.11440642426106096]
	TIME [epoch: 145 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1246810550963699		[learning rate: 0.0099823]
	Learning Rate: 0.0099823
	LOSS [training: 0.1246810550963699 | validation: 0.12153845732073146]
	TIME [epoch: 145 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12400054757876562		[learning rate: 0.0099426]
	Learning Rate: 0.0099426
	LOSS [training: 0.12400054757876562 | validation: 0.11330733705810034]
	TIME [epoch: 145 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12888236726556224		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.12888236726556224 | validation: 0.12405523121668978]
	TIME [epoch: 145 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1264320948047484		[learning rate: 0.0098637]
	Learning Rate: 0.00986367
	LOSS [training: 0.1264320948047484 | validation: 0.10088233947697112]
	TIME [epoch: 145 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12115164961988922		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 0.12115164961988922 | validation: 0.10250676905729221]
	TIME [epoch: 145 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12982447888096385		[learning rate: 0.0097854]
	Learning Rate: 0.00978536
	LOSS [training: 0.12982447888096385 | validation: 0.10722726145634691]
	TIME [epoch: 145 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13189344301907768		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.13189344301907768 | validation: 0.10539448918107527]
	TIME [epoch: 145 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12253618063077999		[learning rate: 0.0097077]
	Learning Rate: 0.00970768
	LOSS [training: 0.12253618063077999 | validation: 0.10087550057144731]
	TIME [epoch: 145 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11952678847791158		[learning rate: 0.0096691]
	Learning Rate: 0.00966907
	LOSS [training: 0.11952678847791158 | validation: 0.10391502659858756]
	TIME [epoch: 145 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1267639826102204		[learning rate: 0.0096306]
	Learning Rate: 0.00963061
	LOSS [training: 0.1267639826102204 | validation: 0.11752825788582513]
	TIME [epoch: 144 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12035616778369031		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.12035616778369031 | validation: 0.11126051027574002]
	TIME [epoch: 144 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12418377828273869		[learning rate: 0.0095542]
	Learning Rate: 0.00955415
	LOSS [training: 0.12418377828273869 | validation: 0.0996742332384603]
	TIME [epoch: 144 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11928252995955482		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 0.11928252995955482 | validation: 0.11961146451574389]
	TIME [epoch: 144 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12560492835149836		[learning rate: 0.0094783]
	Learning Rate: 0.00947831
	LOSS [training: 0.12560492835149836 | validation: 0.11458136435905546]
	TIME [epoch: 144 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12026395506297366		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.12026395506297366 | validation: 0.10003189336762383]
	TIME [epoch: 144 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11790118108189657		[learning rate: 0.0094031]
	Learning Rate: 0.00940306
	LOSS [training: 0.11790118108189657 | validation: 0.10739422295729613]
	TIME [epoch: 144 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11909844347194048		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.11909844347194048 | validation: 0.10923660515909761]
	TIME [epoch: 144 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12038057680637565		[learning rate: 0.0093284]
	Learning Rate: 0.00932841
	LOSS [training: 0.12038057680637565 | validation: 0.10949338541944617]
	TIME [epoch: 144 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12196386449572717		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.12196386449572717 | validation: 0.1104572144914131]
	TIME [epoch: 144 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12086108072763604		[learning rate: 0.0092544]
	Learning Rate: 0.00925435
	LOSS [training: 0.12086108072763604 | validation: 0.10039747350884617]
	TIME [epoch: 144 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1179190386432148		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.1179190386432148 | validation: 0.09853764657128616]
	TIME [epoch: 144 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11927694334505182		[learning rate: 0.0091809]
	Learning Rate: 0.00918089
	LOSS [training: 0.11927694334505182 | validation: 0.11095048326689061]
	TIME [epoch: 144 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13664542208944205		[learning rate: 0.0091444]
	Learning Rate: 0.00914437
	LOSS [training: 0.13664542208944205 | validation: 0.10190787584992371]
	TIME [epoch: 144 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12174825256639717		[learning rate: 0.009108]
	Learning Rate: 0.009108
	LOSS [training: 0.12174825256639717 | validation: 0.10279437864901668]
	TIME [epoch: 144 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11776970166958137		[learning rate: 0.0090718]
	Learning Rate: 0.00907178
	LOSS [training: 0.11776970166958137 | validation: 0.09558510426311109]
	TIME [epoch: 144 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12151777026059195		[learning rate: 0.0090357]
	Learning Rate: 0.00903569
	LOSS [training: 0.12151777026059195 | validation: 0.10144032335651902]
	TIME [epoch: 144 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12420385460694407		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.12420385460694407 | validation: 0.1151633681242]
	TIME [epoch: 144 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12024375109096913		[learning rate: 0.008964]
	Learning Rate: 0.00896396
	LOSS [training: 0.12024375109096913 | validation: 0.10099929825039886]
	TIME [epoch: 144 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11483679371429184		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 0.11483679371429184 | validation: 0.10189741606236646]
	TIME [epoch: 144 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11528208523239337		[learning rate: 0.0088928]
	Learning Rate: 0.0088928
	LOSS [training: 0.11528208523239337 | validation: 0.10504193776868927]
	TIME [epoch: 144 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11843009568165644		[learning rate: 0.0088574]
	Learning Rate: 0.00885743
	LOSS [training: 0.11843009568165644 | validation: 0.10858395599562487]
	TIME [epoch: 144 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11668475492792924		[learning rate: 0.0088222]
	Learning Rate: 0.0088222
	LOSS [training: 0.11668475492792924 | validation: 0.11460358860953612]
	TIME [epoch: 144 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12128917096652485		[learning rate: 0.0087871]
	Learning Rate: 0.00878711
	LOSS [training: 0.12128917096652485 | validation: 0.09769981543231519]
	TIME [epoch: 144 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11429348110599287		[learning rate: 0.0087522]
	Learning Rate: 0.00875216
	LOSS [training: 0.11429348110599287 | validation: 0.09733306391161581]
	TIME [epoch: 144 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1200998416260999		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.1200998416260999 | validation: 0.1017907522446408]
	TIME [epoch: 144 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1185040312506646		[learning rate: 0.0086827]
	Learning Rate: 0.00868268
	LOSS [training: 0.1185040312506646 | validation: 0.11380507134538323]
	TIME [epoch: 144 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12070280290770946		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.12070280290770946 | validation: 0.10332412914256424]
	TIME [epoch: 144 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11611697112462276		[learning rate: 0.0086138]
	Learning Rate: 0.00861375
	LOSS [training: 0.11611697112462276 | validation: 0.09504851949845534]
	TIME [epoch: 144 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12192204963984893		[learning rate: 0.0085795]
	Learning Rate: 0.00857949
	LOSS [training: 0.12192204963984893 | validation: 0.09942570010870547]
	TIME [epoch: 144 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11606980596133679		[learning rate: 0.0085454]
	Learning Rate: 0.00854537
	LOSS [training: 0.11606980596133679 | validation: 0.1012205089659319]
	TIME [epoch: 144 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1193271252640968		[learning rate: 0.0085114]
	Learning Rate: 0.00851138
	LOSS [training: 0.1193271252640968 | validation: 0.12076250949516867]
	TIME [epoch: 144 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11854514742489625		[learning rate: 0.0084775]
	Learning Rate: 0.00847753
	LOSS [training: 0.11854514742489625 | validation: 0.09791046985709735]
	TIME [epoch: 144 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1144323894096989		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.1144323894096989 | validation: 0.09758250549811517]
	TIME [epoch: 144 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11510143151926772		[learning rate: 0.0084102]
	Learning Rate: 0.00841023
	LOSS [training: 0.11510143151926772 | validation: 0.10352212016734832]
	TIME [epoch: 144 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11569754429044583		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 0.11569754429044583 | validation: 0.10360165537906212]
	TIME [epoch: 144 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11623820908809177		[learning rate: 0.0083435]
	Learning Rate: 0.00834346
	LOSS [training: 0.11623820908809177 | validation: 0.10116372757555422]
	TIME [epoch: 144 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11523203449343843		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.11523203449343843 | validation: 0.09735147766693046]
	TIME [epoch: 144 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11988386750500626		[learning rate: 0.0082772]
	Learning Rate: 0.00827722
	LOSS [training: 0.11988386750500626 | validation: 0.09772661177184072]
	TIME [epoch: 144 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1195539597247319		[learning rate: 0.0082443]
	Learning Rate: 0.0082443
	LOSS [training: 0.1195539597247319 | validation: 0.0967343010426539]
	TIME [epoch: 144 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1181378009180993		[learning rate: 0.0082115]
	Learning Rate: 0.00821151
	LOSS [training: 0.1181378009180993 | validation: 0.09727229500535678]
	TIME [epoch: 144 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11482772643220057		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.11482772643220057 | validation: 0.10473320090271157]
	TIME [epoch: 144 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1145892612781038		[learning rate: 0.0081463]
	Learning Rate: 0.00814632
	LOSS [training: 0.1145892612781038 | validation: 0.100535132263699]
	TIME [epoch: 144 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11578200515159949		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.11578200515159949 | validation: 0.10207248033632524]
	TIME [epoch: 144 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12309352499517298		[learning rate: 0.0080816]
	Learning Rate: 0.00808165
	LOSS [training: 0.12309352499517298 | validation: 0.09712232905748998]
	TIME [epoch: 144 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11468837384849023		[learning rate: 0.0080495]
	Learning Rate: 0.00804951
	LOSS [training: 0.11468837384849023 | validation: 0.09541353617173766]
	TIME [epoch: 144 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11473256178365736		[learning rate: 0.0080175]
	Learning Rate: 0.00801749
	LOSS [training: 0.11473256178365736 | validation: 0.1053297214335233]
	TIME [epoch: 144 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11245499462662872		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.11245499462662872 | validation: 0.1017322057070632]
	TIME [epoch: 144 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11678277493927183		[learning rate: 0.0079538]
	Learning Rate: 0.00795384
	LOSS [training: 0.11678277493927183 | validation: 0.09722931481637408]
	TIME [epoch: 144 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11705899669467976		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.11705899669467976 | validation: 0.09443288321113372]
	TIME [epoch: 144 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11395238270105162		[learning rate: 0.0078907]
	Learning Rate: 0.0078907
	LOSS [training: 0.11395238270105162 | validation: 0.10311298726729916]
	TIME [epoch: 144 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1144008760656575		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 0.1144008760656575 | validation: 0.09961803835643185]
	TIME [epoch: 144 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11865549329480757		[learning rate: 0.0078281]
	Learning Rate: 0.00782805
	LOSS [training: 0.11865549329480757 | validation: 0.09600453698301888]
	TIME [epoch: 144 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11081545655141462		[learning rate: 0.0077969]
	Learning Rate: 0.00779692
	LOSS [training: 0.11081545655141462 | validation: 0.10411628567055176]
	TIME [epoch: 144 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12285713774163545		[learning rate: 0.0077659]
	Learning Rate: 0.00776591
	LOSS [training: 0.12285713774163545 | validation: 0.09613186913234313]
	TIME [epoch: 144 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11545116444784889		[learning rate: 0.007735]
	Learning Rate: 0.00773502
	LOSS [training: 0.11545116444784889 | validation: 0.09785952985753572]
	TIME [epoch: 144 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11307770115026278		[learning rate: 0.0077043]
	Learning Rate: 0.00770426
	LOSS [training: 0.11307770115026278 | validation: 0.10021674383002488]
	TIME [epoch: 144 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11247448118224915		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.11247448118224915 | validation: 0.09667077210701491]
	TIME [epoch: 144 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11411220436079904		[learning rate: 0.0076431]
	Learning Rate: 0.00764309
	LOSS [training: 0.11411220436079904 | validation: 0.09785284752494325]
	TIME [epoch: 144 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11424084402693507		[learning rate: 0.0076127]
	Learning Rate: 0.00761269
	LOSS [training: 0.11424084402693507 | validation: 0.09903754039441456]
	TIME [epoch: 144 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11111077398971442		[learning rate: 0.0075824]
	Learning Rate: 0.00758242
	LOSS [training: 0.11111077398971442 | validation: 0.09595961533889562]
	TIME [epoch: 144 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11634825038722843		[learning rate: 0.0075523]
	Learning Rate: 0.00755226
	LOSS [training: 0.11634825038722843 | validation: 0.10461736727462234]
	TIME [epoch: 144 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11431712837339097		[learning rate: 0.0075222]
	Learning Rate: 0.00752222
	LOSS [training: 0.11431712837339097 | validation: 0.10381139796153907]
	TIME [epoch: 144 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11502869575262192		[learning rate: 0.0074923]
	Learning Rate: 0.0074923
	LOSS [training: 0.11502869575262192 | validation: 0.09834951820760467]
	TIME [epoch: 144 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11522913427681367		[learning rate: 0.0074625]
	Learning Rate: 0.0074625
	LOSS [training: 0.11522913427681367 | validation: 0.09336465410275305]
	TIME [epoch: 144 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_118.pth
	Model improved!!!
EPOCH 119/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.112894074465809		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.112894074465809 | validation: 0.10201431403700933]
	TIME [epoch: 144 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12013317347082636		[learning rate: 0.0074033]
	Learning Rate: 0.00740326
	LOSS [training: 0.12013317347082636 | validation: 0.09904537410724859]
	TIME [epoch: 144 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11349685674722508		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.11349685674722508 | validation: 0.10617566177852233]
	TIME [epoch: 144 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11505623558204808		[learning rate: 0.0073445]
	Learning Rate: 0.00734449
	LOSS [training: 0.11505623558204808 | validation: 0.09684136354509768]
	TIME [epoch: 144 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11429150234880872		[learning rate: 0.0073153]
	Learning Rate: 0.00731528
	LOSS [training: 0.11429150234880872 | validation: 0.10891907107822978]
	TIME [epoch: 144 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11528820768489838		[learning rate: 0.0072862]
	Learning Rate: 0.00728618
	LOSS [training: 0.11528820768489838 | validation: 0.09641353203784693]
	TIME [epoch: 144 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1147128455579013		[learning rate: 0.0072572]
	Learning Rate: 0.0072572
	LOSS [training: 0.1147128455579013 | validation: 0.09900226701892793]
	TIME [epoch: 144 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11406326324990496		[learning rate: 0.0072283]
	Learning Rate: 0.00722834
	LOSS [training: 0.11406326324990496 | validation: 0.0979974252576861]
	TIME [epoch: 144 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11395335136534329		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.11395335136534329 | validation: 0.09906425807301955]
	TIME [epoch: 144 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11306548313602643		[learning rate: 0.007171]
	Learning Rate: 0.00717095
	LOSS [training: 0.11306548313602643 | validation: 0.09865766292916159]
	TIME [epoch: 144 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10975295923087049		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.10975295923087049 | validation: 0.09677219278003565]
	TIME [epoch: 144 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11277103141254946		[learning rate: 0.007114]
	Learning Rate: 0.00711403
	LOSS [training: 0.11277103141254946 | validation: 0.0994651944432244]
	TIME [epoch: 144 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11389030033584276		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.11389030033584276 | validation: 0.09931388287536207]
	TIME [epoch: 144 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11755248389538703		[learning rate: 0.0070575]
	Learning Rate: 0.00705755
	LOSS [training: 0.11755248389538703 | validation: 0.09847010605535493]
	TIME [epoch: 144 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11311640469187115		[learning rate: 0.0070295]
	Learning Rate: 0.00702948
	LOSS [training: 0.11311640469187115 | validation: 0.09820865313134078]
	TIME [epoch: 144 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11186555866387679		[learning rate: 0.0070015]
	Learning Rate: 0.00700152
	LOSS [training: 0.11186555866387679 | validation: 0.09465598801449582]
	TIME [epoch: 144 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11385760048062214		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.11385760048062214 | validation: 0.09590782684279062]
	TIME [epoch: 144 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11179764327744308		[learning rate: 0.0069459]
	Learning Rate: 0.00694594
	LOSS [training: 0.11179764327744308 | validation: 0.11589125141132675]
	TIME [epoch: 144 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1188266923147254		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 0.1188266923147254 | validation: 0.10514115174759102]
	TIME [epoch: 144 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11894426223129487		[learning rate: 0.0068908]
	Learning Rate: 0.00689079
	LOSS [training: 0.11894426223129487 | validation: 0.09817591903618612]
	TIME [epoch: 144 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11121648258741741		[learning rate: 0.0068634]
	Learning Rate: 0.00686339
	LOSS [training: 0.11121648258741741 | validation: 0.09732118388764059]
	TIME [epoch: 144 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11208759280992779		[learning rate: 0.0068361]
	Learning Rate: 0.00683609
	LOSS [training: 0.11208759280992779 | validation: 0.09266090548599915]
	TIME [epoch: 144 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_140.pth
	Model improved!!!
EPOCH 141/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11179934530427826		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.11179934530427826 | validation: 0.09535146036883449]
	TIME [epoch: 144 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11162064600718148		[learning rate: 0.0067818]
	Learning Rate: 0.00678182
	LOSS [training: 0.11162064600718148 | validation: 0.09811157134238487]
	TIME [epoch: 144 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11190195032063989		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.11190195032063989 | validation: 0.09421834425929566]
	TIME [epoch: 144 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10987938655214163		[learning rate: 0.006728]
	Learning Rate: 0.00672798
	LOSS [training: 0.10987938655214163 | validation: 0.09832625349500199]
	TIME [epoch: 144 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11325560311751103		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 0.11325560311751103 | validation: 0.09673922626873376]
	TIME [epoch: 144 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11159290300882486		[learning rate: 0.0066746]
	Learning Rate: 0.00667457
	LOSS [training: 0.11159290300882486 | validation: 0.09405294873169016]
	TIME [epoch: 144 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11298529072748585		[learning rate: 0.006648]
	Learning Rate: 0.00664802
	LOSS [training: 0.11298529072748585 | validation: 0.09219147433206097]
	TIME [epoch: 144 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_147.pth
	Model improved!!!
EPOCH 148/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1128153566727412		[learning rate: 0.0066216]
	Learning Rate: 0.00662158
	LOSS [training: 0.1128153566727412 | validation: 0.09475664172188321]
	TIME [epoch: 144 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1121521455882229		[learning rate: 0.0065952]
	Learning Rate: 0.00659524
	LOSS [training: 0.1121521455882229 | validation: 0.10556251585563622]
	TIME [epoch: 144 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11724503100738375		[learning rate: 0.006569]
	Learning Rate: 0.00656901
	LOSS [training: 0.11724503100738375 | validation: 0.1027785698507921]
	TIME [epoch: 144 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11485812623175236		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.11485812623175236 | validation: 0.09404020799851902]
	TIME [epoch: 144 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11002458734024717		[learning rate: 0.0065169]
	Learning Rate: 0.00651686
	LOSS [training: 0.11002458734024717 | validation: 0.09274812887848691]
	TIME [epoch: 144 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11019514232037365		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 0.11019514232037365 | validation: 0.09999072550657506]
	TIME [epoch: 144 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11202930496120087		[learning rate: 0.0064651]
	Learning Rate: 0.00646512
	LOSS [training: 0.11202930496120087 | validation: 0.09597753547062447]
	TIME [epoch: 144 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11204308136024986		[learning rate: 0.0064394]
	Learning Rate: 0.00643941
	LOSS [training: 0.11204308136024986 | validation: 0.09763435482336283]
	TIME [epoch: 144 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11294997330015866		[learning rate: 0.0064138]
	Learning Rate: 0.0064138
	LOSS [training: 0.11294997330015866 | validation: 0.11152751104858001]
	TIME [epoch: 144 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11622491710174192		[learning rate: 0.0063883]
	Learning Rate: 0.00638829
	LOSS [training: 0.11622491710174192 | validation: 0.10018197310591923]
	TIME [epoch: 144 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11122186777334868		[learning rate: 0.0063629]
	Learning Rate: 0.00636288
	LOSS [training: 0.11122186777334868 | validation: 0.10078465745317289]
	TIME [epoch: 144 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1147164068731356		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.1147164068731356 | validation: 0.09419138900202453]
	TIME [epoch: 144 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10890074453021815		[learning rate: 0.0063124]
	Learning Rate: 0.00631237
	LOSS [training: 0.10890074453021815 | validation: 0.09828137391942161]
	TIME [epoch: 144 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11290775263184585		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.11290775263184585 | validation: 0.10534961921961299]
	TIME [epoch: 144 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1163654556859792		[learning rate: 0.0062623]
	Learning Rate: 0.00626226
	LOSS [training: 0.1163654556859792 | validation: 0.09530644363414588]
	TIME [epoch: 144 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10905279169310172		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.10905279169310172 | validation: 0.09465662840748919]
	TIME [epoch: 144 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11242947894369307		[learning rate: 0.0062125]
	Learning Rate: 0.00621254
	LOSS [training: 0.11242947894369307 | validation: 0.09362523423385177]
	TIME [epoch: 144 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11765038403263045		[learning rate: 0.0061878]
	Learning Rate: 0.00618783
	LOSS [training: 0.11765038403263045 | validation: 0.0958583882998287]
	TIME [epoch: 144 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1165961551550078		[learning rate: 0.0061632]
	Learning Rate: 0.00616322
	LOSS [training: 0.1165961551550078 | validation: 0.09416366481444514]
	TIME [epoch: 144 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.113476877099214		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.113476877099214 | validation: 0.0939920861552253]
	TIME [epoch: 144 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1130255728867377		[learning rate: 0.0061143]
	Learning Rate: 0.00611429
	LOSS [training: 0.1130255728867377 | validation: 0.10042211438801107]
	TIME [epoch: 144 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11687075023272733		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 0.11687075023272733 | validation: 0.09383734236403667]
	TIME [epoch: 144 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11225074975943618		[learning rate: 0.0060658]
	Learning Rate: 0.00606575
	LOSS [training: 0.11225074975943618 | validation: 0.09357924594548975]
	TIME [epoch: 144 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11066463997206134		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.11066463997206134 | validation: 0.09844866305224456]
	TIME [epoch: 144 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11545961713321622		[learning rate: 0.0060176]
	Learning Rate: 0.0060176
	LOSS [training: 0.11545961713321622 | validation: 0.0931558044429984]
	TIME [epoch: 144 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10730420926397292		[learning rate: 0.0059937]
	Learning Rate: 0.00599366
	LOSS [training: 0.10730420926397292 | validation: 0.09528320037942414]
	TIME [epoch: 144 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11247697731604675		[learning rate: 0.0059698]
	Learning Rate: 0.00596982
	LOSS [training: 0.11247697731604675 | validation: 0.09655719895883726]
	TIME [epoch: 144 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11091891376780172		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.11091891376780172 | validation: 0.09562243566563985]
	TIME [epoch: 144 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10910472731065675		[learning rate: 0.0059224]
	Learning Rate: 0.00592243
	LOSS [training: 0.10910472731065675 | validation: 0.09319989053752335]
	TIME [epoch: 144 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11286630648068069		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 0.11286630648068069 | validation: 0.09402402351221222]
	TIME [epoch: 144 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1099334180953219		[learning rate: 0.0058754]
	Learning Rate: 0.00587541
	LOSS [training: 0.1099334180953219 | validation: 0.09301353659255222]
	TIME [epoch: 144 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11223496577123078		[learning rate: 0.005852]
	Learning Rate: 0.00585205
	LOSS [training: 0.11223496577123078 | validation: 0.09671023378334007]
	TIME [epoch: 144 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11321535486560405		[learning rate: 0.0058288]
	Learning Rate: 0.00582877
	LOSS [training: 0.11321535486560405 | validation: 0.09976623478493636]
	TIME [epoch: 144 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11357724209724397		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.11357724209724397 | validation: 0.09269244407868002]
	TIME [epoch: 144 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11113983872015853		[learning rate: 0.0057825]
	Learning Rate: 0.0057825
	LOSS [training: 0.11113983872015853 | validation: 0.09277621752066453]
	TIME [epoch: 144 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11584125553928137		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.11584125553928137 | validation: 0.09406749728011826]
	TIME [epoch: 144 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10813097083035414		[learning rate: 0.0057366]
	Learning Rate: 0.00573659
	LOSS [training: 0.10813097083035414 | validation: 0.09384317183174512]
	TIME [epoch: 144 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10995897649296912		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 0.10995897649296912 | validation: 0.09713968702343263]
	TIME [epoch: 144 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11333605069448632		[learning rate: 0.005691]
	Learning Rate: 0.00569105
	LOSS [training: 0.11333605069448632 | validation: 0.09205502286282852]
	TIME [epoch: 144 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_186.pth
	Model improved!!!
EPOCH 187/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10784019709225734		[learning rate: 0.0056684]
	Learning Rate: 0.00566841
	LOSS [training: 0.10784019709225734 | validation: 0.09286828750813146]
	TIME [epoch: 144 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11174258806429399		[learning rate: 0.0056459]
	Learning Rate: 0.00564587
	LOSS [training: 0.11174258806429399 | validation: 0.09251863961326538]
	TIME [epoch: 144 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11052286601736457		[learning rate: 0.0056234]
	Learning Rate: 0.00562341
	LOSS [training: 0.11052286601736457 | validation: 0.10393450907127418]
	TIME [epoch: 144 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11526888783114411		[learning rate: 0.005601]
	Learning Rate: 0.00560105
	LOSS [training: 0.11526888783114411 | validation: 0.09890857663517981]
	TIME [epoch: 144 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11305019459104855		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.11305019459104855 | validation: 0.0918221581329653]
	TIME [epoch: 144 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_191.pth
	Model improved!!!
EPOCH 192/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11447963031078039		[learning rate: 0.0055566]
	Learning Rate: 0.00555658
	LOSS [training: 0.11447963031078039 | validation: 0.10490539512529373]
	TIME [epoch: 144 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11336812685449657		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.11336812685449657 | validation: 0.09612994820616247]
	TIME [epoch: 144 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11163688130416803		[learning rate: 0.0055125]
	Learning Rate: 0.00551247
	LOSS [training: 0.11163688130416803 | validation: 0.09116214553226863]
	TIME [epoch: 144 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_194.pth
	Model improved!!!
EPOCH 195/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10686480963137152		[learning rate: 0.0054905]
	Learning Rate: 0.00549054
	LOSS [training: 0.10686480963137152 | validation: 0.0940986137035992]
	TIME [epoch: 144 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1141579279814513		[learning rate: 0.0054687]
	Learning Rate: 0.00546871
	LOSS [training: 0.1141579279814513 | validation: 0.09378490752252902]
	TIME [epoch: 144 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11046658231308645		[learning rate: 0.005447]
	Learning Rate: 0.00544696
	LOSS [training: 0.11046658231308645 | validation: 0.09783422750190425]
	TIME [epoch: 145 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11355322291410122		[learning rate: 0.0054253]
	Learning Rate: 0.00542529
	LOSS [training: 0.11355322291410122 | validation: 0.09897821477150762]
	TIME [epoch: 144 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11021975357474563		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.11021975357474563 | validation: 0.10275758861769675]
	TIME [epoch: 144 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11010481264699334		[learning rate: 0.0053822]
	Learning Rate: 0.00538222
	LOSS [training: 0.11010481264699334 | validation: 0.091770522715231]
	TIME [epoch: 144 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11399808407779911		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.11399808407779911 | validation: 0.0928982494784826]
	TIME [epoch: 144 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11215683185713053		[learning rate: 0.0053395]
	Learning Rate: 0.00533949
	LOSS [training: 0.11215683185713053 | validation: 0.09913140220201283]
	TIME [epoch: 144 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1131518171620874		[learning rate: 0.0053183]
	Learning Rate: 0.00531826
	LOSS [training: 0.1131518171620874 | validation: 0.09598200468293812]
	TIME [epoch: 144 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10950130568399476		[learning rate: 0.0052971]
	Learning Rate: 0.0052971
	LOSS [training: 0.10950130568399476 | validation: 0.0941376680757245]
	TIME [epoch: 144 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1085295889430749		[learning rate: 0.005276]
	Learning Rate: 0.00527604
	LOSS [training: 0.1085295889430749 | validation: 0.09388839033528801]
	TIME [epoch: 144 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1094312119203707		[learning rate: 0.0052551]
	Learning Rate: 0.00525505
	LOSS [training: 0.1094312119203707 | validation: 0.09935002344188154]
	TIME [epoch: 144 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10938996822091882		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.10938996822091882 | validation: 0.0954681197044761]
	TIME [epoch: 144 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11177331080649479		[learning rate: 0.0052133]
	Learning Rate: 0.00521333
	LOSS [training: 0.11177331080649479 | validation: 0.10113866565793313]
	TIME [epoch: 144 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11361853331888004		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 0.11361853331888004 | validation: 0.09564403950624609]
	TIME [epoch: 144 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11209480512191036		[learning rate: 0.0051719]
	Learning Rate: 0.00517194
	LOSS [training: 0.11209480512191036 | validation: 0.09530251052243591]
	TIME [epoch: 144 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11114374172685583		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.11114374172685583 | validation: 0.09397453371231124]
	TIME [epoch: 144 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11132141573314105		[learning rate: 0.0051309]
	Learning Rate: 0.00513089
	LOSS [training: 0.11132141573314105 | validation: 0.09130430786410895]
	TIME [epoch: 144 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10914572220398477		[learning rate: 0.0051105]
	Learning Rate: 0.00511048
	LOSS [training: 0.10914572220398477 | validation: 0.09473243452970061]
	TIME [epoch: 144 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10818953098293911		[learning rate: 0.0050902]
	Learning Rate: 0.00509015
	LOSS [training: 0.10818953098293911 | validation: 0.09974732967278611]
	TIME [epoch: 144 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11586753174521819		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.11586753174521819 | validation: 0.0939968859230943]
	TIME [epoch: 144 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11152595267763672		[learning rate: 0.0050497]
	Learning Rate: 0.00504974
	LOSS [training: 0.11152595267763672 | validation: 0.09348403194888626]
	TIME [epoch: 144 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11002675855743521		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 0.11002675855743521 | validation: 0.09170729788848858]
	TIME [epoch: 144 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11016003990277763		[learning rate: 0.0050097]
	Learning Rate: 0.00500965
	LOSS [training: 0.11016003990277763 | validation: 0.09491011737609432]
	TIME [epoch: 144 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1082017410406277		[learning rate: 0.0049897]
	Learning Rate: 0.00498973
	LOSS [training: 0.1082017410406277 | validation: 0.0941688191749241]
	TIME [epoch: 144 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10875150970538684		[learning rate: 0.0049699]
	Learning Rate: 0.00496988
	LOSS [training: 0.10875150970538684 | validation: 0.0949155158696562]
	TIME [epoch: 144 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11314179593953028		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.11314179593953028 | validation: 0.09657905037731754]
	TIME [epoch: 144 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11364470528915765		[learning rate: 0.0049304]
	Learning Rate: 0.00493043
	LOSS [training: 0.11364470528915765 | validation: 0.09722590891581592]
	TIME [epoch: 144 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11501453021654531		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.11501453021654531 | validation: 0.09370020319213096]
	TIME [epoch: 144 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10829284700776601		[learning rate: 0.0048913]
	Learning Rate: 0.00489129
	LOSS [training: 0.10829284700776601 | validation: 0.09319626029504893]
	TIME [epoch: 144 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10996571012998671		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.10996571012998671 | validation: 0.09301251649434411]
	TIME [epoch: 144 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.109931198622361		[learning rate: 0.0048525]
	Learning Rate: 0.00485245
	LOSS [training: 0.109931198622361 | validation: 0.09336742674008218]
	TIME [epoch: 144 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10809723672879697		[learning rate: 0.0048332]
	Learning Rate: 0.00483316
	LOSS [training: 0.10809723672879697 | validation: 0.0957195222052051]
	TIME [epoch: 144 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11206413652229062		[learning rate: 0.0048139]
	Learning Rate: 0.00481393
	LOSS [training: 0.11206413652229062 | validation: 0.09300020134207951]
	TIME [epoch: 144 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11170286305072612		[learning rate: 0.0047948]
	Learning Rate: 0.00479479
	LOSS [training: 0.11170286305072612 | validation: 0.09514743117871838]
	TIME [epoch: 144 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10774213689525342		[learning rate: 0.0047757]
	Learning Rate: 0.00477572
	LOSS [training: 0.10774213689525342 | validation: 0.09299697281457744]
	TIME [epoch: 144 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10867137435991775		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.10867137435991775 | validation: 0.09845549386771485]
	TIME [epoch: 144 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11085042318869635		[learning rate: 0.0047378]
	Learning Rate: 0.0047378
	LOSS [training: 0.11085042318869635 | validation: 0.09316653892278395]
	TIME [epoch: 144 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10949710070419466		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 0.10949710070419466 | validation: 0.09561983075850784]
	TIME [epoch: 144 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11029663218344027		[learning rate: 0.0047002]
	Learning Rate: 0.00470019
	LOSS [training: 0.11029663218344027 | validation: 0.0934764245250729]
	TIME [epoch: 144 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10927082318775505		[learning rate: 0.0046815]
	Learning Rate: 0.0046815
	LOSS [training: 0.10927082318775505 | validation: 0.09350715561737144]
	TIME [epoch: 144 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1066335216790833		[learning rate: 0.0046629]
	Learning Rate: 0.00466288
	LOSS [training: 0.1066335216790833 | validation: 0.09792658132595615]
	TIME [epoch: 144 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11259965701124248		[learning rate: 0.0046443]
	Learning Rate: 0.00464433
	LOSS [training: 0.11259965701124248 | validation: 0.09582235216553195]
	TIME [epoch: 144 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10823662705344961		[learning rate: 0.0046259]
	Learning Rate: 0.00462586
	LOSS [training: 0.10823662705344961 | validation: 0.09628064664486909]
	TIME [epoch: 144 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10725186235988607		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.10725186235988607 | validation: 0.0939131539101158]
	TIME [epoch: 144 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10981231655204689		[learning rate: 0.0045891]
	Learning Rate: 0.00458913
	LOSS [training: 0.10981231655204689 | validation: 0.0936118975307628]
	TIME [epoch: 144 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10719641146217988		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.10719641146217988 | validation: 0.09236363679318411]
	TIME [epoch: 144 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10901239072032115		[learning rate: 0.0045527]
	Learning Rate: 0.0045527
	LOSS [training: 0.10901239072032115 | validation: 0.09467463312309507]
	TIME [epoch: 144 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.110168268148658		[learning rate: 0.0045346]
	Learning Rate: 0.00453459
	LOSS [training: 0.110168268148658 | validation: 0.09294079223142834]
	TIME [epoch: 144 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10941934360513034		[learning rate: 0.0045166]
	Learning Rate: 0.00451656
	LOSS [training: 0.10941934360513034 | validation: 0.09150640886167186]
	TIME [epoch: 144 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10754843962125385		[learning rate: 0.0044986]
	Learning Rate: 0.0044986
	LOSS [training: 0.10754843962125385 | validation: 0.09515917432448061]
	TIME [epoch: 144 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10971373938649884		[learning rate: 0.0044807]
	Learning Rate: 0.0044807
	LOSS [training: 0.10971373938649884 | validation: 0.09254324029356122]
	TIME [epoch: 144 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10878395591000047		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.10878395591000047 | validation: 0.09302414684535901]
	TIME [epoch: 144 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10837710708842069		[learning rate: 0.0044451]
	Learning Rate: 0.00444513
	LOSS [training: 0.10837710708842069 | validation: 0.0944368516443505]
	TIME [epoch: 144 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10866796107136525		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 0.10866796107136525 | validation: 0.09420450206297841]
	TIME [epoch: 144 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10960188393035238		[learning rate: 0.0044098]
	Learning Rate: 0.00440984
	LOSS [training: 0.10960188393035238 | validation: 0.09288550944591403]
	TIME [epoch: 144 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10804120975312224		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.10804120975312224 | validation: 0.09846593087607937]
	TIME [epoch: 144 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11036570828591236		[learning rate: 0.0043748]
	Learning Rate: 0.00437483
	LOSS [training: 0.11036570828591236 | validation: 0.09233862492492109]
	TIME [epoch: 144 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1087394706092134		[learning rate: 0.0043574]
	Learning Rate: 0.00435743
	LOSS [training: 0.1087394706092134 | validation: 0.0930066811128865]
	TIME [epoch: 144 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11138459844011422		[learning rate: 0.0043401]
	Learning Rate: 0.0043401
	LOSS [training: 0.11138459844011422 | validation: 0.09191261537759153]
	TIME [epoch: 144 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11118040668619011		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.11118040668619011 | validation: 0.09353952205744051]
	TIME [epoch: 144 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10996681120059677		[learning rate: 0.0043056]
	Learning Rate: 0.00430565
	LOSS [training: 0.10996681120059677 | validation: 0.09537711520376439]
	TIME [epoch: 144 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11119418915268382		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.11119418915268382 | validation: 0.09403513320330702]
	TIME [epoch: 144 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10639874346213746		[learning rate: 0.0042715]
	Learning Rate: 0.00427147
	LOSS [training: 0.10639874346213746 | validation: 0.09116712949157292]
	TIME [epoch: 144 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10859978203173883		[learning rate: 0.0042545]
	Learning Rate: 0.00425448
	LOSS [training: 0.10859978203173883 | validation: 0.09277745805045631]
	TIME [epoch: 144 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10793429809381191		[learning rate: 0.0042376]
	Learning Rate: 0.00423756
	LOSS [training: 0.10793429809381191 | validation: 0.09475573122573781]
	TIME [epoch: 144 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11024210263894468		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.11024210263894468 | validation: 0.09283873510977601]
	TIME [epoch: 144 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10619553475938812		[learning rate: 0.0042039]
	Learning Rate: 0.00420391
	LOSS [training: 0.10619553475938812 | validation: 0.09193473076455454]
	TIME [epoch: 144 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1069974482482508		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.1069974482482508 | validation: 0.09358127917632669]
	TIME [epoch: 144 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10894326353350453		[learning rate: 0.0041705]
	Learning Rate: 0.00417054
	LOSS [training: 0.10894326353350453 | validation: 0.0942202452547805]
	TIME [epoch: 144 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10907823824159708		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 0.10907823824159708 | validation: 0.0919508166518775]
	TIME [epoch: 144 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10922759269142876		[learning rate: 0.0041374]
	Learning Rate: 0.00413743
	LOSS [training: 0.10922759269142876 | validation: 0.0980307845009894]
	TIME [epoch: 144 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11122901045418684		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.11122901045418684 | validation: 0.09380082749672647]
	TIME [epoch: 144 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11124578610231012		[learning rate: 0.0041046]
	Learning Rate: 0.00410458
	LOSS [training: 0.11124578610231012 | validation: 0.09556944464260915]
	TIME [epoch: 144 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1119184413981872		[learning rate: 0.0040883]
	Learning Rate: 0.00408826
	LOSS [training: 0.1119184413981872 | validation: 0.09837338623118749]
	TIME [epoch: 144 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11010443369896822		[learning rate: 0.004072]
	Learning Rate: 0.004072
	LOSS [training: 0.11010443369896822 | validation: 0.091453012276982]
	TIME [epoch: 144 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1077263430593484		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.1077263430593484 | validation: 0.09254868434553971]
	TIME [epoch: 144 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10650286852135281		[learning rate: 0.0040397]
	Learning Rate: 0.00403967
	LOSS [training: 0.10650286852135281 | validation: 0.09547358971646894]
	TIME [epoch: 144 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1127876211871545		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 0.1127876211871545 | validation: 0.09159418476017725]
	TIME [epoch: 144 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10862039880393665		[learning rate: 0.0040076]
	Learning Rate: 0.0040076
	LOSS [training: 0.10862039880393665 | validation: 0.09103235369485982]
	TIME [epoch: 144 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v2_20240627_193058/states/model_facs_dec1a_2dpca_v2_274.pth
	Model improved!!!
EPOCH 275/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.106567154346495		[learning rate: 0.0039917]
	Learning Rate: 0.00399166
	LOSS [training: 0.106567154346495 | validation: 0.09283023723835045]
	TIME [epoch: 144 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1077901528648382		[learning rate: 0.0039758]
	Learning Rate: 0.00397579
	LOSS [training: 0.1077901528648382 | validation: 0.09208396467521843]
	TIME [epoch: 144 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10678997050242468		[learning rate: 0.00396]
	Learning Rate: 0.00395997
	LOSS [training: 0.10678997050242468 | validation: 0.09478757067273608]
	TIME [epoch: 144 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1066164621115147		[learning rate: 0.0039442]
	Learning Rate: 0.00394422
	LOSS [training: 0.1066164621115147 | validation: 0.09557222152205183]
	TIME [epoch: 144 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11137087538641971		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.11137087538641971 | validation: 0.0933042034376796]
	TIME [epoch: 144 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10859104085790099		[learning rate: 0.0039129]
	Learning Rate: 0.00391291
	LOSS [training: 0.10859104085790099 | validation: 0.09235847799977526]
	TIME [epoch: 144 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10985400195207165		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.10985400195207165 | validation: 0.09430762544930302]
	TIME [epoch: 144 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10810164697034484		[learning rate: 0.0038818]
	Learning Rate: 0.00388185
	LOSS [training: 0.10810164697034484 | validation: 0.09317366568542382]
	TIME [epoch: 144 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10793473327874986		[learning rate: 0.0038664]
	Learning Rate: 0.00386641
	LOSS [training: 0.10793473327874986 | validation: 0.09292858208532871]
	TIME [epoch: 144 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10689683272609385		[learning rate: 0.003851]
	Learning Rate: 0.00385103
	LOSS [training: 0.10689683272609385 | validation: 0.09346879700833878]
	TIME [epoch: 144 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10747516062617829		[learning rate: 0.0038357]
	Learning Rate: 0.00383571
	LOSS [training: 0.10747516062617829 | validation: 0.09318063585963374]
	TIME [epoch: 144 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10865605310746285		[learning rate: 0.0038205]
	Learning Rate: 0.00382046
	LOSS [training: 0.10865605310746285 | validation: 0.09174346127707995]
	TIME [epoch: 144 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11039305018898028		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.11039305018898028 | validation: 0.09325446283572279]
	TIME [epoch: 144 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10680800122797833		[learning rate: 0.0037901]
	Learning Rate: 0.00379013
	LOSS [training: 0.10680800122797833 | validation: 0.09335840959262995]
	TIME [epoch: 144 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10598073382684783		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.10598073382684783 | validation: 0.09961433659088774]
	TIME [epoch: 144 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1147157220112616		[learning rate: 0.00376]
	Learning Rate: 0.00376004
	LOSS [training: 0.1147157220112616 | validation: 0.09393612889873001]
	TIME [epoch: 144 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10858631433475811		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.10858631433475811 | validation: 0.0910823065648407]
	TIME [epoch: 144 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10844746023814254		[learning rate: 0.0037302]
	Learning Rate: 0.00373019
	LOSS [training: 0.10844746023814254 | validation: 0.0918892619336019]
	TIME [epoch: 144 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10630785921441285		[learning rate: 0.0037154]
	Learning Rate: 0.00371535
	LOSS [training: 0.10630785921441285 | validation: 0.093395636828136]
	TIME [epoch: 144 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1067475052120925		[learning rate: 0.0037006]
	Learning Rate: 0.00370058
	LOSS [training: 0.1067475052120925 | validation: 0.09216118738632148]
	TIME [epoch: 144 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10808823916079585		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.10808823916079585 | validation: 0.0969202304602039]
	TIME [epoch: 144 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10963519570924346		[learning rate: 0.0036712]
	Learning Rate: 0.0036712
	LOSS [training: 0.10963519570924346 | validation: 0.09438420523258481]
	TIME [epoch: 144 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1076853639629146		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 0.1076853639629146 | validation: 0.09616917768105211]
	TIME [epoch: 144 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10912352430569151		[learning rate: 0.0036421]
	Learning Rate: 0.00364205
	LOSS [training: 0.10912352430569151 | validation: 0.09210940401921655]
	TIME [epoch: 144 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11043267850360479		[learning rate: 0.0036276]
	Learning Rate: 0.00362757
	LOSS [training: 0.11043267850360479 | validation: 0.09214008439094047]
	TIME [epoch: 144 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11009016005331224		[learning rate: 0.0036131]
	Learning Rate: 0.00361314
	LOSS [training: 0.11009016005331224 | validation: 0.09265010737624098]
	TIME [epoch: 144 sec]
EPOCH 301/2000:
	Training over batches...
