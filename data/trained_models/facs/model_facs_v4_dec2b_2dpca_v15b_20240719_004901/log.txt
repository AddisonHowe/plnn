Args:
Namespace(name='model_facs_v4_dec2b_2dpca_v15b', outdir='out/model_training/model_facs_v4_dec2b_2dpca_v15b', training_data='data/training_data/facs_v4/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v4/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=100, ncells_sample=100, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 200, 300], dt_schedule_scales=[0.5, 0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 605221827

Training model...

Saving initial model state to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240719_004901/states/model_facs_v4_dec2b_2dpca_v15b_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9216966733081817		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9216966733081817 | validation: 1.021112191126581]
	TIME [epoch: 25.7 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240719_004901/states/model_facs_v4_dec2b_2dpca_v15b_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6818178503600231		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6818178503600231 | validation: 0.9478569409260961]
	TIME [epoch: 3.6 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240719_004901/states/model_facs_v4_dec2b_2dpca_v15b_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7074670879387185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7074670879387185 | validation: 0.7761789983181783]
	TIME [epoch: 3.79 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240719_004901/states/model_facs_v4_dec2b_2dpca_v15b_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6082116571125763		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6082116571125763 | validation: 0.7851410352273073]
	TIME [epoch: 3.57 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5739203599312365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5739203599312365 | validation: 0.6800334808887296]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240719_004901/states/model_facs_v4_dec2b_2dpca_v15b_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5066137377747302		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5066137377747302 | validation: 0.7171919384458324]
	TIME [epoch: 3.57 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6304928628796115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6304928628796115 | validation: 0.648750461812147]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240719_004901/states/model_facs_v4_dec2b_2dpca_v15b_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48810324169649366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48810324169649366 | validation: 0.719782775332676]
	TIME [epoch: 3.59 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4913075802188365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4913075802188365 | validation: 0.6256353575670237]
	TIME [epoch: 3.58 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240719_004901/states/model_facs_v4_dec2b_2dpca_v15b_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4378613473027019		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4378613473027019 | validation: 0.6323464663959055]
	TIME [epoch: 3.57 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4487528586762711		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4487528586762711 | validation: 0.6775880980369345]
	TIME [epoch: 3.57 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4903422428507918		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4903422428507918 | validation: 0.5682476897756377]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240719_004901/states/model_facs_v4_dec2b_2dpca_v15b_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40523456698727006		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40523456698727006 | validation: 0.5039116742792475]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240719_004901/states/model_facs_v4_dec2b_2dpca_v15b_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3591269899070341		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3591269899070341 | validation: 0.5307542595164655]
	TIME [epoch: 3.58 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3404076975620596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3404076975620596 | validation: 0.5190370302197179]
	TIME [epoch: 3.57 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39645822906347594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39645822906347594 | validation: 0.7998179367466033]
	TIME [epoch: 3.59 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42785407667836944		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42785407667836944 | validation: 0.4504304101930739]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240719_004901/states/model_facs_v4_dec2b_2dpca_v15b_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.308565772673359		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.308565772673359 | validation: 0.44192932880161795]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240719_004901/states/model_facs_v4_dec2b_2dpca_v15b_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3508216156225298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3508216156225298 | validation: 0.648749607589592]
	TIME [epoch: 3.57 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34963025141555093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34963025141555093 | validation: 0.47339194212910674]
	TIME [epoch: 3.59 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2819247343375831		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2819247343375831 | validation: 0.41668628860867846]
	TIME [epoch: 3.59 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240719_004901/states/model_facs_v4_dec2b_2dpca_v15b_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28968599175104176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28968599175104176 | validation: 0.4850181642450779]
	TIME [epoch: 3.57 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2711637008311705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2711637008311705 | validation: 0.39670384244609996]
	TIME [epoch: 3.55 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240719_004901/states/model_facs_v4_dec2b_2dpca_v15b_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30268409806251595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30268409806251595 | validation: 0.5805403463845958]
	TIME [epoch: 3.57 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2915552553696167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2915552553696167 | validation: 0.3989248838605617]
	TIME [epoch: 3.58 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25310207285892644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25310207285892644 | validation: 0.479490720005873]
	TIME [epoch: 3.55 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3134296037075569		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3134296037075569 | validation: 0.3932824206910067]
	TIME [epoch: 3.56 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240719_004901/states/model_facs_v4_dec2b_2dpca_v15b_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22619559169185044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22619559169185044 | validation: 0.4280523536140326]
	TIME [epoch: 3.56 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27173932238328014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27173932238328014 | validation: 0.43193290479266594]
	TIME [epoch: 3.57 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2498696566287099		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2498696566287099 | validation: 0.3884986949050057]
	TIME [epoch: 3.55 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240719_004901/states/model_facs_v4_dec2b_2dpca_v15b_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2104521457003265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2104521457003265 | validation: 0.394057355104213]
	TIME [epoch: 3.57 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22881944139926197		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22881944139926197 | validation: 0.3661238852424255]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240719_004901/states/model_facs_v4_dec2b_2dpca_v15b_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2585669611580137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2585669611580137 | validation: 0.38338751295527307]
	TIME [epoch: 3.55 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2538797046617821		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2538797046617821 | validation: 0.45529098779353594]
	TIME [epoch: 3.55 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30626505097186485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30626505097186485 | validation: 0.40950147222073324]
	TIME [epoch: 3.55 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24002500518298986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24002500518298986 | validation: 0.4103899018744961]
	TIME [epoch: 3.55 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2601356593649406		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2601356593649406 | validation: 0.43547314536114384]
	TIME [epoch: 3.54 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2739096421403293		[learning rate: 0.0099882]
	Learning Rate: 0.0099882
	LOSS [training: 0.2739096421403293 | validation: 0.35136960981555204]
	TIME [epoch: 3.55 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240719_004901/states/model_facs_v4_dec2b_2dpca_v15b_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21440602672032746		[learning rate: 0.0099411]
	Learning Rate: 0.00994113
	LOSS [training: 0.21440602672032746 | validation: 0.4003733494435251]
	TIME [epoch: 3.55 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2430007019135219		[learning rate: 0.0098943]
	Learning Rate: 0.00989429
	LOSS [training: 0.2430007019135219 | validation: 0.5292745756115247]
	TIME [epoch: 3.6 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2611740298809194		[learning rate: 0.0098477]
	Learning Rate: 0.00984767
	LOSS [training: 0.2611740298809194 | validation: 0.3848576037638841]
	TIME [epoch: 3.57 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20838718401528206		[learning rate: 0.0098013]
	Learning Rate: 0.00980126
	LOSS [training: 0.20838718401528206 | validation: 0.348916124613819]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240719_004901/states/model_facs_v4_dec2b_2dpca_v15b_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2319658392338072		[learning rate: 0.0097551]
	Learning Rate: 0.00975508
	LOSS [training: 0.2319658392338072 | validation: 0.45945745688552]
	TIME [epoch: 3.57 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25743957456998434		[learning rate: 0.0097091]
	Learning Rate: 0.00970911
	LOSS [training: 0.25743957456998434 | validation: 0.4085702904514344]
	TIME [epoch: 3.57 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21065011808130868		[learning rate: 0.0096634]
	Learning Rate: 0.00966336
	LOSS [training: 0.21065011808130868 | validation: 0.35819797692598393]
	TIME [epoch: 3.57 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2601874083441131		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.2601874083441131 | validation: 0.3998218998144819]
	TIME [epoch: 3.56 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1872175020116323		[learning rate: 0.0095725]
	Learning Rate: 0.00957251
	LOSS [training: 0.1872175020116323 | validation: 0.36869599781574475]
	TIME [epoch: 3.57 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21509554940318232		[learning rate: 0.0095274]
	Learning Rate: 0.0095274
	LOSS [training: 0.21509554940318232 | validation: 0.3483544333009651]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240719_004901/states/model_facs_v4_dec2b_2dpca_v15b_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21880630206057672		[learning rate: 0.0094825]
	Learning Rate: 0.0094825
	LOSS [training: 0.21880630206057672 | validation: 0.46962039132281613]
	TIME [epoch: 3.56 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22594141935377218		[learning rate: 0.0094378]
	Learning Rate: 0.00943782
	LOSS [training: 0.22594141935377218 | validation: 0.3837848056760272]
	TIME [epoch: 3.56 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19652406870724737		[learning rate: 0.0093933]
	Learning Rate: 0.00939335
	LOSS [training: 0.19652406870724737 | validation: 0.37117636964741213]
	TIME [epoch: 27 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.270471078861352		[learning rate: 0.0093491]
	Learning Rate: 0.00934909
	LOSS [training: 0.270471078861352 | validation: 0.3629290684915258]
	TIME [epoch: 6.82 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2174634242060783		[learning rate: 0.009305]
	Learning Rate: 0.00930503
	LOSS [training: 0.2174634242060783 | validation: 0.3869201179277597]
	TIME [epoch: 6.81 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22032502522576067		[learning rate: 0.0092612]
	Learning Rate: 0.00926119
	LOSS [training: 0.22032502522576067 | validation: 0.3904448090868292]
	TIME [epoch: 6.84 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18833878003090965		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.18833878003090965 | validation: 0.36060687844742545]
	TIME [epoch: 6.84 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23259921411320925		[learning rate: 0.0091741]
	Learning Rate: 0.00917411
	LOSS [training: 0.23259921411320925 | validation: 0.42729201951626977]
	TIME [epoch: 6.83 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2188414404771481		[learning rate: 0.0091309]
	Learning Rate: 0.00913088
	LOSS [training: 0.2188414404771481 | validation: 0.32361027109028906]
	TIME [epoch: 6.82 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240719_004901/states/model_facs_v4_dec2b_2dpca_v15b_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19956794105667885		[learning rate: 0.0090879]
	Learning Rate: 0.00908786
	LOSS [training: 0.19956794105667885 | validation: 0.3518872231156225]
	TIME [epoch: 6.84 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22937206422197948		[learning rate: 0.009045]
	Learning Rate: 0.00904503
	LOSS [training: 0.22937206422197948 | validation: 0.38163667143678903]
	TIME [epoch: 6.83 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17981926203996568		[learning rate: 0.0090024]
	Learning Rate: 0.00900241
	LOSS [training: 0.17981926203996568 | validation: 0.3160003011742412]
	TIME [epoch: 6.83 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240719_004901/states/model_facs_v4_dec2b_2dpca_v15b_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.190777590524419		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.190777590524419 | validation: 0.3809092095404637]
	TIME [epoch: 6.82 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22311515125713527		[learning rate: 0.0089178]
	Learning Rate: 0.00891777
	LOSS [training: 0.22311515125713527 | validation: 0.45096593513928335]
	TIME [epoch: 6.84 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20974260607130724		[learning rate: 0.0088758]
	Learning Rate: 0.00887575
	LOSS [training: 0.20974260607130724 | validation: 0.3757709747660149]
	TIME [epoch: 6.85 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2033585185899507		[learning rate: 0.0088339]
	Learning Rate: 0.00883393
	LOSS [training: 0.2033585185899507 | validation: 0.3271739746232232]
	TIME [epoch: 6.82 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1930790541837406		[learning rate: 0.0087923]
	Learning Rate: 0.0087923
	LOSS [training: 0.1930790541837406 | validation: 0.4530608715512833]
	TIME [epoch: 6.81 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.200222334347542		[learning rate: 0.0087509]
	Learning Rate: 0.00875087
	LOSS [training: 0.200222334347542 | validation: 0.442442547009023]
	TIME [epoch: 6.85 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23894146118240972		[learning rate: 0.0087096]
	Learning Rate: 0.00870964
	LOSS [training: 0.23894146118240972 | validation: 0.3955329574637368]
	TIME [epoch: 6.82 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22581520524136803		[learning rate: 0.0086686]
	Learning Rate: 0.00866859
	LOSS [training: 0.22581520524136803 | validation: 0.3765263913870556]
	TIME [epoch: 6.83 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19059335428928598		[learning rate: 0.0086277]
	Learning Rate: 0.00862775
	LOSS [training: 0.19059335428928598 | validation: 0.36208305718629996]
	TIME [epoch: 6.84 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18350558505305087		[learning rate: 0.0085871]
	Learning Rate: 0.00858709
	LOSS [training: 0.18350558505305087 | validation: 0.4481734596693515]
	TIME [epoch: 6.83 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1783061727002941		[learning rate: 0.0085466]
	Learning Rate: 0.00854663
	LOSS [training: 0.1783061727002941 | validation: 0.39718376618368745]
	TIME [epoch: 6.83 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1930598945305273		[learning rate: 0.0085064]
	Learning Rate: 0.00850636
	LOSS [training: 0.1930598945305273 | validation: 0.49002307368075837]
	TIME [epoch: 6.82 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21051833969876138		[learning rate: 0.0084663]
	Learning Rate: 0.00846627
	LOSS [training: 0.21051833969876138 | validation: 0.35367369483476846]
	TIME [epoch: 6.83 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16394645756317838		[learning rate: 0.0084264]
	Learning Rate: 0.00842638
	LOSS [training: 0.16394645756317838 | validation: 0.3195496821855141]
	TIME [epoch: 6.83 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1774364136613304		[learning rate: 0.0083867]
	Learning Rate: 0.00838667
	LOSS [training: 0.1774364136613304 | validation: 0.3080665181963886]
	TIME [epoch: 6.83 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240719_004901/states/model_facs_v4_dec2b_2dpca_v15b_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.156864620889327		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.156864620889327 | validation: 0.4730407421182868]
	TIME [epoch: 6.84 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21843082821007095		[learning rate: 0.0083078]
	Learning Rate: 0.00830782
	LOSS [training: 0.21843082821007095 | validation: 0.3454636072094446]
	TIME [epoch: 6.83 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18205530940487455		[learning rate: 0.0082687]
	Learning Rate: 0.00826867
	LOSS [training: 0.18205530940487455 | validation: 0.41232929877998026]
	TIME [epoch: 6.82 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20399780767949935		[learning rate: 0.0082297]
	Learning Rate: 0.00822971
	LOSS [training: 0.20399780767949935 | validation: 0.38627803125138993]
	TIME [epoch: 6.83 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17128213967254152		[learning rate: 0.0081909]
	Learning Rate: 0.00819093
	LOSS [training: 0.17128213967254152 | validation: 0.3882259536370531]
	TIME [epoch: 6.82 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25967520759105484		[learning rate: 0.0081523]
	Learning Rate: 0.00815233
	LOSS [training: 0.25967520759105484 | validation: 0.37826621610762057]
	TIME [epoch: 6.83 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22220375606117698		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.22220375606117698 | validation: 0.3324456593735736]
	TIME [epoch: 6.83 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18623057202078974		[learning rate: 0.0080757]
	Learning Rate: 0.00807569
	LOSS [training: 0.18623057202078974 | validation: 0.3738088043932927]
	TIME [epoch: 6.85 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1846503018375098		[learning rate: 0.0080376]
	Learning Rate: 0.00803763
	LOSS [training: 0.1846503018375098 | validation: 0.34243079165466117]
	TIME [epoch: 6.83 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1959925802661865		[learning rate: 0.0079998]
	Learning Rate: 0.00799976
	LOSS [training: 0.1959925802661865 | validation: 0.3362487796571029]
	TIME [epoch: 6.82 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18993457849727563		[learning rate: 0.0079621]
	Learning Rate: 0.00796206
	LOSS [training: 0.18993457849727563 | validation: 0.3833220751602366]
	TIME [epoch: 6.83 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.168797993367251		[learning rate: 0.0079245]
	Learning Rate: 0.00792455
	LOSS [training: 0.168797993367251 | validation: 0.31423329404010614]
	TIME [epoch: 6.84 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20487229481385		[learning rate: 0.0078872]
	Learning Rate: 0.0078872
	LOSS [training: 0.20487229481385 | validation: 0.5450200364400961]
	TIME [epoch: 6.83 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1840636506026817		[learning rate: 0.00785]
	Learning Rate: 0.00785004
	LOSS [training: 0.1840636506026817 | validation: 0.36832154207507917]
	TIME [epoch: 6.85 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18071422179622648		[learning rate: 0.007813]
	Learning Rate: 0.00781305
	LOSS [training: 0.18071422179622648 | validation: 0.3447022585745896]
	TIME [epoch: 6.83 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18912963676228786		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.18912963676228786 | validation: 0.3616062178943943]
	TIME [epoch: 6.83 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17181831377171985		[learning rate: 0.0077396]
	Learning Rate: 0.00773959
	LOSS [training: 0.17181831377171985 | validation: 0.4008048232276224]
	TIME [epoch: 6.85 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16643219843289386		[learning rate: 0.0077031]
	Learning Rate: 0.00770312
	LOSS [training: 0.16643219843289386 | validation: 0.2985682755642804]
	TIME [epoch: 6.83 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240719_004901/states/model_facs_v4_dec2b_2dpca_v15b_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15084126397022649		[learning rate: 0.0076668]
	Learning Rate: 0.00766682
	LOSS [training: 0.15084126397022649 | validation: 0.3804855259889542]
	TIME [epoch: 6.83 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.217872268547378		[learning rate: 0.0076307]
	Learning Rate: 0.0076307
	LOSS [training: 0.217872268547378 | validation: 0.3622753317554744]
	TIME [epoch: 6.84 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1829522875893889		[learning rate: 0.0075947]
	Learning Rate: 0.00759474
	LOSS [training: 0.1829522875893889 | validation: 0.29637257130577177]
	TIME [epoch: 6.82 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240719_004901/states/model_facs_v4_dec2b_2dpca_v15b_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14943281775269823		[learning rate: 0.007559]
	Learning Rate: 0.00755895
	LOSS [training: 0.14943281775269823 | validation: 0.33058459961562253]
	TIME [epoch: 6.83 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19338963437500115		[learning rate: 0.0075233]
	Learning Rate: 0.00752333
	LOSS [training: 0.19338963437500115 | validation: 0.41596940467563126]
	TIME [epoch: 6.8 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21951350562039917		[learning rate: 0.0074879]
	Learning Rate: 0.00748788
	LOSS [training: 0.21951350562039917 | validation: 0.3982806895273543]
	TIME [epoch: 6.81 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22379877528632544		[learning rate: 0.0074526]
	Learning Rate: 0.0074526
	LOSS [training: 0.22379877528632544 | validation: 0.3159591580583546]
	TIME [epoch: 6.81 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1744769777801978		[learning rate: 0.0074175]
	Learning Rate: 0.00741748
	LOSS [training: 0.1744769777801978 | validation: 0.3442274947894578]
	TIME [epoch: 35.2 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.144612822873031		[learning rate: 0.0073825]
	Learning Rate: 0.00738253
	LOSS [training: 0.144612822873031 | validation: 0.36472189514651937]
	TIME [epoch: 14.8 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17906814645210622		[learning rate: 0.0073477]
	Learning Rate: 0.00734774
	LOSS [training: 0.17906814645210622 | validation: 0.39488149124002386]
	TIME [epoch: 14.8 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18577956958686198		[learning rate: 0.0073131]
	Learning Rate: 0.00731312
	LOSS [training: 0.18577956958686198 | validation: 0.3890731479502414]
	TIME [epoch: 14.8 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17631570156084414		[learning rate: 0.0072787]
	Learning Rate: 0.00727866
	LOSS [training: 0.17631570156084414 | validation: 0.3455001950087786]
	TIME [epoch: 14.8 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18456746044966105		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.18456746044966105 | validation: 0.3721217487924079]
	TIME [epoch: 14.8 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14522199644057046		[learning rate: 0.0072102]
	Learning Rate: 0.00721022
	LOSS [training: 0.14522199644057046 | validation: 0.33790602791339863]
	TIME [epoch: 14.8 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19773786496837245		[learning rate: 0.0071762]
	Learning Rate: 0.00717625
	LOSS [training: 0.19773786496837245 | validation: 0.3436582785433667]
	TIME [epoch: 14.8 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15536013050633168		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.15536013050633168 | validation: 0.3181912771349707]
	TIME [epoch: 14.8 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1520135614959893		[learning rate: 0.0071088]
	Learning Rate: 0.00710878
	LOSS [training: 0.1520135614959893 | validation: 0.3816574238760577]
	TIME [epoch: 14.8 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15708527717037732		[learning rate: 0.0070753]
	Learning Rate: 0.00707528
	LOSS [training: 0.15708527717037732 | validation: 0.3680980281163137]
	TIME [epoch: 14.8 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17133157639063343		[learning rate: 0.0070419]
	Learning Rate: 0.00704194
	LOSS [training: 0.17133157639063343 | validation: 0.3602507224345639]
	TIME [epoch: 14.8 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1782565681221584		[learning rate: 0.0070088]
	Learning Rate: 0.00700876
	LOSS [training: 0.1782565681221584 | validation: 0.4178821584812977]
	TIME [epoch: 14.8 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15405303956613797		[learning rate: 0.0069757]
	Learning Rate: 0.00697573
	LOSS [training: 0.15405303956613797 | validation: 0.35555543237717546]
	TIME [epoch: 14.8 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17710525641085179		[learning rate: 0.0069429]
	Learning Rate: 0.00694286
	LOSS [training: 0.17710525641085179 | validation: 0.35798226794765775]
	TIME [epoch: 14.8 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17548446504442566		[learning rate: 0.0069101]
	Learning Rate: 0.00691014
	LOSS [training: 0.17548446504442566 | validation: 0.3662135318048545]
	TIME [epoch: 14.8 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1965094736292557		[learning rate: 0.0068776]
	Learning Rate: 0.00687758
	LOSS [training: 0.1965094736292557 | validation: 0.3848148455643781]
	TIME [epoch: 14.8 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15272204459784214		[learning rate: 0.0068452]
	Learning Rate: 0.00684518
	LOSS [training: 0.15272204459784214 | validation: 0.3359935117507884]
	TIME [epoch: 14.8 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15498455511889309		[learning rate: 0.0068129]
	Learning Rate: 0.00681292
	LOSS [training: 0.15498455511889309 | validation: 0.32172189447269905]
	TIME [epoch: 14.8 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16046925484611888		[learning rate: 0.0067808]
	Learning Rate: 0.00678082
	LOSS [training: 0.16046925484611888 | validation: 0.325802233989673]
	TIME [epoch: 14.8 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14721570451144708		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.14721570451144708 | validation: 0.3219502925916742]
	TIME [epoch: 14.8 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14344938748887662		[learning rate: 0.0067171]
	Learning Rate: 0.00671706
	LOSS [training: 0.14344938748887662 | validation: 0.3434485144409971]
	TIME [epoch: 14.8 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18427284495845558		[learning rate: 0.0066854]
	Learning Rate: 0.00668541
	LOSS [training: 0.18427284495845558 | validation: 0.33690075019472476]
	TIME [epoch: 14.8 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14820943639679693		[learning rate: 0.0066539]
	Learning Rate: 0.00665391
	LOSS [training: 0.14820943639679693 | validation: 0.3773946182048482]
	TIME [epoch: 14.8 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16073506024996267		[learning rate: 0.0066226]
	Learning Rate: 0.00662256
	LOSS [training: 0.16073506024996267 | validation: 0.38482438393125706]
	TIME [epoch: 14.8 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18419831598322087		[learning rate: 0.0065913]
	Learning Rate: 0.00659135
	LOSS [training: 0.18419831598322087 | validation: 0.3049031085560562]
	TIME [epoch: 14.8 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16661002963202295		[learning rate: 0.0065603]
	Learning Rate: 0.00656029
	LOSS [training: 0.16661002963202295 | validation: 0.3256485948189071]
	TIME [epoch: 14.8 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18229725043854142		[learning rate: 0.0065294]
	Learning Rate: 0.00652938
	LOSS [training: 0.18229725043854142 | validation: 0.39932934283178184]
	TIME [epoch: 14.9 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19951097783389188		[learning rate: 0.0064986]
	Learning Rate: 0.00649861
	LOSS [training: 0.19951097783389188 | validation: 0.3583982679056551]
	TIME [epoch: 14.8 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18258114611521728		[learning rate: 0.006468]
	Learning Rate: 0.00646799
	LOSS [training: 0.18258114611521728 | validation: 0.3162496640542091]
	TIME [epoch: 14.9 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1505078803530133		[learning rate: 0.0064375]
	Learning Rate: 0.00643751
	LOSS [training: 0.1505078803530133 | validation: 0.31076631423712203]
	TIME [epoch: 14.9 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12678949302604792		[learning rate: 0.0064072]
	Learning Rate: 0.00640718
	LOSS [training: 0.12678949302604792 | validation: 0.431672327538449]
	TIME [epoch: 14.8 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21611216177097553		[learning rate: 0.006377]
	Learning Rate: 0.00637698
	LOSS [training: 0.21611216177097553 | validation: 0.34441920257256553]
	TIME [epoch: 14.8 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1650654595466883		[learning rate: 0.0063469]
	Learning Rate: 0.00634694
	LOSS [training: 0.1650654595466883 | validation: 0.3127414686591768]
	TIME [epoch: 14.9 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15320570405692063		[learning rate: 0.006317]
	Learning Rate: 0.00631703
	LOSS [training: 0.15320570405692063 | validation: 0.4731295951909249]
	TIME [epoch: 14.8 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15691586602011595		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.15691586602011595 | validation: 0.34027112137777676]
	TIME [epoch: 14.8 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1660260032645957		[learning rate: 0.0062576]
	Learning Rate: 0.00625764
	LOSS [training: 0.1660260032645957 | validation: 0.33423893946733]
	TIME [epoch: 14.8 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1476458192442679		[learning rate: 0.0062281]
	Learning Rate: 0.00622815
	LOSS [training: 0.1476458192442679 | validation: 0.3706760714941012]
	TIME [epoch: 14.8 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15659236700423027		[learning rate: 0.0061988]
	Learning Rate: 0.0061988
	LOSS [training: 0.15659236700423027 | validation: 0.39123095129398644]
	TIME [epoch: 14.8 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17218378125166317		[learning rate: 0.0061696]
	Learning Rate: 0.00616959
	LOSS [training: 0.17218378125166317 | validation: 0.3082954804370183]
	TIME [epoch: 14.8 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16058502733431673		[learning rate: 0.0061405]
	Learning Rate: 0.00614052
	LOSS [training: 0.16058502733431673 | validation: 0.3867608299625905]
	TIME [epoch: 14.8 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18840870890868636		[learning rate: 0.0061116]
	Learning Rate: 0.00611158
	LOSS [training: 0.18840870890868636 | validation: 0.4086262177346013]
	TIME [epoch: 14.9 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14364456908938966		[learning rate: 0.0060828]
	Learning Rate: 0.00608279
	LOSS [training: 0.14364456908938966 | validation: 0.36360549633118816]
	TIME [epoch: 14.8 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15874825370418494		[learning rate: 0.0060541]
	Learning Rate: 0.00605412
	LOSS [training: 0.15874825370418494 | validation: 0.34899975755810136]
	TIME [epoch: 14.8 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16830597566368855		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 0.16830597566368855 | validation: 0.3496128101007514]
	TIME [epoch: 14.8 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1682312672898017		[learning rate: 0.0059972]
	Learning Rate: 0.0059972
	LOSS [training: 0.1682312672898017 | validation: 0.30915080578239434]
	TIME [epoch: 14.8 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13587387754803493		[learning rate: 0.0059689]
	Learning Rate: 0.00596894
	LOSS [training: 0.13587387754803493 | validation: 0.39582236684265004]
	TIME [epoch: 14.8 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15243903039617296		[learning rate: 0.0059408]
	Learning Rate: 0.00594082
	LOSS [training: 0.15243903039617296 | validation: 0.3288878455392749]
	TIME [epoch: 14.8 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.132396622315354		[learning rate: 0.0059128]
	Learning Rate: 0.00591282
	LOSS [training: 0.132396622315354 | validation: 0.38995374084338796]
	TIME [epoch: 14.8 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16845116294727033		[learning rate: 0.005885]
	Learning Rate: 0.00588496
	LOSS [training: 0.16845116294727033 | validation: 0.3477511460761769]
	TIME [epoch: 14.8 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17065330420915376		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.17065330420915376 | validation: 0.29476055621323055]
	TIME [epoch: 14.8 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240719_004901/states/model_facs_v4_dec2b_2dpca_v15b_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14756900836051456		[learning rate: 0.0058296]
	Learning Rate: 0.00582963
	LOSS [training: 0.14756900836051456 | validation: 0.3339092248368094]
	TIME [epoch: 14.8 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18639152106696283		[learning rate: 0.0058022]
	Learning Rate: 0.00580216
	LOSS [training: 0.18639152106696283 | validation: 0.46310943533266996]
	TIME [epoch: 14.8 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23105116398778333		[learning rate: 0.0057748]
	Learning Rate: 0.00577482
	LOSS [training: 0.23105116398778333 | validation: 0.3442973607742378]
	TIME [epoch: 14.8 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16139983041436096		[learning rate: 0.0057476]
	Learning Rate: 0.00574761
	LOSS [training: 0.16139983041436096 | validation: 0.3775436606933885]
	TIME [epoch: 14.8 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14631226607000994		[learning rate: 0.0057205]
	Learning Rate: 0.00572052
	LOSS [training: 0.14631226607000994 | validation: 0.36314293004237475]
	TIME [epoch: 14.8 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15288718005118448		[learning rate: 0.0056936]
	Learning Rate: 0.00569357
	LOSS [training: 0.15288718005118448 | validation: 0.349363984954751]
	TIME [epoch: 14.8 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17571607128152264		[learning rate: 0.0056667]
	Learning Rate: 0.00566674
	LOSS [training: 0.17571607128152264 | validation: 0.33935767684504303]
	TIME [epoch: 14.8 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.131620184280722		[learning rate: 0.00564]
	Learning Rate: 0.00564004
	LOSS [training: 0.131620184280722 | validation: 0.3404685886289105]
	TIME [epoch: 14.8 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16196434039116625		[learning rate: 0.0056135]
	Learning Rate: 0.00561346
	LOSS [training: 0.16196434039116625 | validation: 0.35570459277859473]
	TIME [epoch: 14.8 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16774727405447845		[learning rate: 0.005587]
	Learning Rate: 0.00558701
	LOSS [training: 0.16774727405447845 | validation: 0.35935887592798066]
	TIME [epoch: 14.8 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19142647648799518		[learning rate: 0.0055607]
	Learning Rate: 0.00556068
	LOSS [training: 0.19142647648799518 | validation: 0.3172571827451103]
	TIME [epoch: 14.8 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1181760974992141		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.1181760974992141 | validation: 0.3706521731777076]
	TIME [epoch: 14.8 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16014303869368923		[learning rate: 0.0055084]
	Learning Rate: 0.0055084
	LOSS [training: 0.16014303869368923 | validation: 0.4849267658088226]
	TIME [epoch: 14.8 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18215878848556585		[learning rate: 0.0054824]
	Learning Rate: 0.00548245
	LOSS [training: 0.18215878848556585 | validation: 0.5432024087821498]
	TIME [epoch: 14.8 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15943780701460214		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.15943780701460214 | validation: 0.33620288810751076]
	TIME [epoch: 14.9 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15620959964865572		[learning rate: 0.0054309]
	Learning Rate: 0.0054309
	LOSS [training: 0.15620959964865572 | validation: 0.3177181756496227]
	TIME [epoch: 14.8 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.159055326101157		[learning rate: 0.0054053]
	Learning Rate: 0.00540531
	LOSS [training: 0.159055326101157 | validation: 0.2994973451380719]
	TIME [epoch: 14.8 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12563658186600704		[learning rate: 0.0053798]
	Learning Rate: 0.00537984
	LOSS [training: 0.12563658186600704 | validation: 0.3109192268571619]
	TIME [epoch: 14.8 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14107642071722995		[learning rate: 0.0053545]
	Learning Rate: 0.00535449
	LOSS [training: 0.14107642071722995 | validation: 0.3092071216302111]
	TIME [epoch: 14.9 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16071911050505458		[learning rate: 0.0053293]
	Learning Rate: 0.00532926
	LOSS [training: 0.16071911050505458 | validation: 0.47730424568546975]
	TIME [epoch: 14.8 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14054697660447021		[learning rate: 0.0053041]
	Learning Rate: 0.00530415
	LOSS [training: 0.14054697660447021 | validation: 0.32750907822356967]
	TIME [epoch: 14.8 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14618273388425404		[learning rate: 0.0052792]
	Learning Rate: 0.00527915
	LOSS [training: 0.14618273388425404 | validation: 0.31723368091210474]
	TIME [epoch: 14.9 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13183459433057748		[learning rate: 0.0052543]
	Learning Rate: 0.00525428
	LOSS [training: 0.13183459433057748 | validation: 0.31788623072195343]
	TIME [epoch: 14.8 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16264205805629428		[learning rate: 0.0052295]
	Learning Rate: 0.00522952
	LOSS [training: 0.16264205805629428 | validation: 0.3768908229949013]
	TIME [epoch: 14.8 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17041887639136916		[learning rate: 0.0052049]
	Learning Rate: 0.00520487
	LOSS [training: 0.17041887639136916 | validation: 0.37935616583090126]
	TIME [epoch: 14.9 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14519440380507087		[learning rate: 0.0051803]
	Learning Rate: 0.00518035
	LOSS [training: 0.14519440380507087 | validation: 0.3711399554452445]
	TIME [epoch: 14.8 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14755900029253288		[learning rate: 0.0051559]
	Learning Rate: 0.00515594
	LOSS [training: 0.14755900029253288 | validation: 0.32127304660878186]
	TIME [epoch: 14.8 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13274250348074135		[learning rate: 0.0051316]
	Learning Rate: 0.00513164
	LOSS [training: 0.13274250348074135 | validation: 0.4091048032356102]
	TIME [epoch: 14.9 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12351326849474531		[learning rate: 0.0051075]
	Learning Rate: 0.00510746
	LOSS [training: 0.12351326849474531 | validation: 0.3999162005097006]
	TIME [epoch: 14.9 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15357647230254273		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.15357647230254273 | validation: 0.3457467425064926]
	TIME [epoch: 14.8 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1457195289214357		[learning rate: 0.0050594]
	Learning Rate: 0.00505944
	LOSS [training: 0.1457195289214357 | validation: 0.34358562303453993]
	TIME [epoch: 14.8 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12779947744636758		[learning rate: 0.0050356]
	Learning Rate: 0.0050356
	LOSS [training: 0.12779947744636758 | validation: 0.3221174899052294]
	TIME [epoch: 14.8 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14968882069243844		[learning rate: 0.0050119]
	Learning Rate: 0.00501187
	LOSS [training: 0.14968882069243844 | validation: 0.3659922033833917]
	TIME [epoch: 14.9 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13182189739245495		[learning rate: 0.0049883]
	Learning Rate: 0.00498826
	LOSS [training: 0.13182189739245495 | validation: 0.3080075853814265]
	TIME [epoch: 14.8 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13063003986551497		[learning rate: 0.0049648]
	Learning Rate: 0.00496475
	LOSS [training: 0.13063003986551497 | validation: 0.336969057163387]
	TIME [epoch: 14.8 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1767269766490013		[learning rate: 0.0049414]
	Learning Rate: 0.00494136
	LOSS [training: 0.1767269766490013 | validation: 0.36092907198834034]
	TIME [epoch: 14.8 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1658724158638766		[learning rate: 0.0049181]
	Learning Rate: 0.00491807
	LOSS [training: 0.1658724158638766 | validation: 0.31656574279758176]
	TIME [epoch: 14.8 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13506721389763204		[learning rate: 0.0048949]
	Learning Rate: 0.0048949
	LOSS [training: 0.13506721389763204 | validation: 0.3649125808820567]
	TIME [epoch: 14.8 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13976988540304572		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.13976988540304572 | validation: 0.32227627084115557]
	TIME [epoch: 14.8 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1363079955506915		[learning rate: 0.0048489]
	Learning Rate: 0.00484888
	LOSS [training: 0.1363079955506915 | validation: 0.3050187175169006]
	TIME [epoch: 14.8 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14291630664896768		[learning rate: 0.004826]
	Learning Rate: 0.00482603
	LOSS [training: 0.14291630664896768 | validation: 0.37237451901865404]
	TIME [epoch: 14.8 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12788575992534212		[learning rate: 0.0048033]
	Learning Rate: 0.00480329
	LOSS [training: 0.12788575992534212 | validation: 0.3728174022486516]
	TIME [epoch: 14.9 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13781735288957828		[learning rate: 0.0047807]
	Learning Rate: 0.00478065
	LOSS [training: 0.13781735288957828 | validation: 0.33421231136824925]
	TIME [epoch: 14.8 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14896940532074637		[learning rate: 0.0047581]
	Learning Rate: 0.00475813
	LOSS [training: 0.14896940532074637 | validation: 0.41813210883033225]
	TIME [epoch: 14.8 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15132272544287215		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.15132272544287215 | validation: 0.3477728914919985]
	TIME [epoch: 14.8 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1270153923187952		[learning rate: 0.0047134]
	Learning Rate: 0.00471339
	LOSS [training: 0.1270153923187952 | validation: 0.33101924708687686]
	TIME [epoch: 14.8 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14671888234106795		[learning rate: 0.0046912]
	Learning Rate: 0.00469118
	LOSS [training: 0.14671888234106795 | validation: 0.4967731580545738]
	TIME [epoch: 14.7 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15350334689567188		[learning rate: 0.0046691]
	Learning Rate: 0.00466907
	LOSS [training: 0.15350334689567188 | validation: 0.34310007059851566]
	TIME [epoch: 14.8 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13964697952396116		[learning rate: 0.0046471]
	Learning Rate: 0.00464707
	LOSS [training: 0.13964697952396116 | validation: 0.29965125894459266]
	TIME [epoch: 14.8 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11190660854442777		[learning rate: 0.0046252]
	Learning Rate: 0.00462518
	LOSS [training: 0.11190660854442777 | validation: 0.30503167752395266]
	TIME [epoch: 52.4 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13006398321599408		[learning rate: 0.0046034]
	Learning Rate: 0.00460338
	LOSS [training: 0.13006398321599408 | validation: 0.3849486836027578]
	TIME [epoch: 31.8 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14139340299319805		[learning rate: 0.0045817]
	Learning Rate: 0.00458169
	LOSS [training: 0.14139340299319805 | validation: 0.3466547792414431]
	TIME [epoch: 31.8 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13506453359772977		[learning rate: 0.0045601]
	Learning Rate: 0.0045601
	LOSS [training: 0.13506453359772977 | validation: 0.3416151317667926]
	TIME [epoch: 31.8 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14931226157711755		[learning rate: 0.0045386]
	Learning Rate: 0.00453861
	LOSS [training: 0.14931226157711755 | validation: 0.406970735538157]
	TIME [epoch: 31.9 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1635896440966909		[learning rate: 0.0045172]
	Learning Rate: 0.00451723
	LOSS [training: 0.1635896440966909 | validation: 0.360377220879877]
	TIME [epoch: 31.8 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15485725000367268		[learning rate: 0.0044959]
	Learning Rate: 0.00449594
	LOSS [training: 0.15485725000367268 | validation: 0.3314267390962677]
	TIME [epoch: 31.8 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12793606000002947		[learning rate: 0.0044748]
	Learning Rate: 0.00447475
	LOSS [training: 0.12793606000002947 | validation: 0.36499712813907514]
	TIME [epoch: 31.8 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14080606270508003		[learning rate: 0.0044537]
	Learning Rate: 0.00445367
	LOSS [training: 0.14080606270508003 | validation: 0.38423077478445733]
	TIME [epoch: 31.9 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13737901263603267		[learning rate: 0.0044327]
	Learning Rate: 0.00443268
	LOSS [training: 0.13737901263603267 | validation: 0.3302085234887426]
	TIME [epoch: 31.8 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15500070133725613		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.15500070133725613 | validation: 0.32808608905113756]
	TIME [epoch: 31.8 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14772502574490298		[learning rate: 0.004391]
	Learning Rate: 0.00439101
	LOSS [training: 0.14772502574490298 | validation: 0.3557450162087415]
	TIME [epoch: 31.9 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1509007380339615		[learning rate: 0.0043703]
	Learning Rate: 0.00437032
	LOSS [training: 0.1509007380339615 | validation: 0.3462242609428869]
	TIME [epoch: 31.9 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13744766679532255		[learning rate: 0.0043497]
	Learning Rate: 0.00434972
	LOSS [training: 0.13744766679532255 | validation: 0.36469636368739355]
	TIME [epoch: 31.8 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13331589161472332		[learning rate: 0.0043292]
	Learning Rate: 0.00432923
	LOSS [training: 0.13331589161472332 | validation: 0.33192169614164635]
	TIME [epoch: 31.8 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13538565547867779		[learning rate: 0.0043088]
	Learning Rate: 0.00430883
	LOSS [training: 0.13538565547867779 | validation: 0.46838153420569784]
	TIME [epoch: 31.9 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16466229197400528		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.16466229197400528 | validation: 0.3363785618184274]
	TIME [epoch: 31.8 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17539104343976245		[learning rate: 0.0042683]
	Learning Rate: 0.00426831
	LOSS [training: 0.17539104343976245 | validation: 0.3492032833963362]
	TIME [epoch: 31.8 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1282903339576145		[learning rate: 0.0042482]
	Learning Rate: 0.0042482
	LOSS [training: 0.1282903339576145 | validation: 0.3536684725048541]
	TIME [epoch: 31.9 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12624817380281808		[learning rate: 0.0042282]
	Learning Rate: 0.00422818
	LOSS [training: 0.12624817380281808 | validation: 0.3404614758590133]
	TIME [epoch: 31.8 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1508634224076096		[learning rate: 0.0042083]
	Learning Rate: 0.00420826
	LOSS [training: 0.1508634224076096 | validation: 0.33524569220008305]
	TIME [epoch: 31.9 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12107691253028009		[learning rate: 0.0041884]
	Learning Rate: 0.00418843
	LOSS [training: 0.12107691253028009 | validation: 0.35537337166107025]
	TIME [epoch: 31.8 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11755315962786698		[learning rate: 0.0041687]
	Learning Rate: 0.00416869
	LOSS [training: 0.11755315962786698 | validation: 0.39064559725163456]
	TIME [epoch: 31.8 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13631729279131433		[learning rate: 0.0041491]
	Learning Rate: 0.00414905
	LOSS [training: 0.13631729279131433 | validation: 0.36716773275881137]
	TIME [epoch: 31.7 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16277639241320982		[learning rate: 0.0041295]
	Learning Rate: 0.0041295
	LOSS [training: 0.16277639241320982 | validation: 0.3190747370320043]
	TIME [epoch: 31.8 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12509145237583083		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.12509145237583083 | validation: 0.4165429042255794]
	TIME [epoch: 31.8 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12207155531555368		[learning rate: 0.0040907]
	Learning Rate: 0.00409067
	LOSS [training: 0.12207155531555368 | validation: 0.3297751379786501]
	TIME [epoch: 31.9 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13790640985824848		[learning rate: 0.0040714]
	Learning Rate: 0.0040714
	LOSS [training: 0.13790640985824848 | validation: 0.37728603477316347]
	TIME [epoch: 31.9 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13897148936866396		[learning rate: 0.0040522]
	Learning Rate: 0.00405221
	LOSS [training: 0.13897148936866396 | validation: 0.3232736453947677]
	TIME [epoch: 31.8 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15632688835895647		[learning rate: 0.0040331]
	Learning Rate: 0.00403312
	LOSS [training: 0.15632688835895647 | validation: 0.4202736127605956]
	TIME [epoch: 31.8 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14939876389919932		[learning rate: 0.0040141]
	Learning Rate: 0.00401411
	LOSS [training: 0.14939876389919932 | validation: 0.3562448753593981]
	TIME [epoch: 31.9 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14146601719566143		[learning rate: 0.0039952]
	Learning Rate: 0.0039952
	LOSS [training: 0.14146601719566143 | validation: 0.31285850525092124]
	TIME [epoch: 31.9 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12669496949794445		[learning rate: 0.0039764]
	Learning Rate: 0.00397637
	LOSS [training: 0.12669496949794445 | validation: 0.3180146395095168]
	TIME [epoch: 31.9 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.138354062260984		[learning rate: 0.0039576]
	Learning Rate: 0.00395764
	LOSS [training: 0.138354062260984 | validation: 0.3456367925462097]
	TIME [epoch: 31.9 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15794153312949058		[learning rate: 0.003939]
	Learning Rate: 0.00393899
	LOSS [training: 0.15794153312949058 | validation: 0.30762261191350676]
	TIME [epoch: 31.9 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11538664110144475		[learning rate: 0.0039204]
	Learning Rate: 0.00392043
	LOSS [training: 0.11538664110144475 | validation: 0.35639714602491296]
	TIME [epoch: 31.8 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12640280134836857		[learning rate: 0.003902]
	Learning Rate: 0.00390195
	LOSS [training: 0.12640280134836857 | validation: 0.41211958403072035]
	TIME [epoch: 31.8 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13569785938289208		[learning rate: 0.0038836]
	Learning Rate: 0.00388357
	LOSS [training: 0.13569785938289208 | validation: 0.3349342706721984]
	TIME [epoch: 31.9 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12936231691750089		[learning rate: 0.0038653]
	Learning Rate: 0.00386527
	LOSS [training: 0.12936231691750089 | validation: 0.46387235545372596]
	TIME [epoch: 31.8 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14510188464871565		[learning rate: 0.0038471]
	Learning Rate: 0.00384705
	LOSS [training: 0.14510188464871565 | validation: 0.3064732757890846]
	TIME [epoch: 31.8 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13638809654195372		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.13638809654195372 | validation: 0.3240632164195572]
	TIME [epoch: 31.8 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15797171718051184		[learning rate: 0.0038109]
	Learning Rate: 0.00381088
	LOSS [training: 0.15797171718051184 | validation: 0.34422448210653755]
	TIME [epoch: 31.9 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12588655356092518		[learning rate: 0.0037929]
	Learning Rate: 0.00379293
	LOSS [training: 0.12588655356092518 | validation: 0.371082937742053]
	TIME [epoch: 31.7 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13537102346951985		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.13537102346951985 | validation: 0.29707354795196184]
	TIME [epoch: 31.9 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13054405463995422		[learning rate: 0.0037573]
	Learning Rate: 0.00375726
	LOSS [training: 0.13054405463995422 | validation: 0.3401445044144476]
	TIME [epoch: 31.9 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11377308359064339		[learning rate: 0.0037396]
	Learning Rate: 0.00373956
	LOSS [training: 0.11377308359064339 | validation: 0.30533151404590303]
	TIME [epoch: 31.9 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14008806844418192		[learning rate: 0.0037219]
	Learning Rate: 0.00372194
	LOSS [training: 0.14008806844418192 | validation: 0.33621788738579617]
	TIME [epoch: 31.8 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12973954398196863		[learning rate: 0.0037044]
	Learning Rate: 0.0037044
	LOSS [training: 0.12973954398196863 | validation: 0.32590586754800865]
	TIME [epoch: 31.9 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14730533841504162		[learning rate: 0.0036869]
	Learning Rate: 0.00368695
	LOSS [training: 0.14730533841504162 | validation: 0.3545379398539547]
	TIME [epoch: 31.9 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1127219642146877		[learning rate: 0.0036696]
	Learning Rate: 0.00366957
	LOSS [training: 0.1127219642146877 | validation: 0.3402921571694413]
	TIME [epoch: 31.8 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1431530682190779		[learning rate: 0.0036523]
	Learning Rate: 0.00365228
	LOSS [training: 0.1431530682190779 | validation: 0.34995538720551334]
	TIME [epoch: 31.8 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12569729990642886		[learning rate: 0.0036351]
	Learning Rate: 0.00363507
	LOSS [training: 0.12569729990642886 | validation: 0.31913584582939186]
	TIME [epoch: 31.8 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12495703209043704		[learning rate: 0.0036179]
	Learning Rate: 0.00361794
	LOSS [training: 0.12495703209043704 | validation: 0.3476738088978849]
	TIME [epoch: 31.8 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13413634106237976		[learning rate: 0.0036009]
	Learning Rate: 0.00360089
	LOSS [training: 0.13413634106237976 | validation: 0.34016259321890563]
	TIME [epoch: 31.9 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13534380402850865		[learning rate: 0.0035839]
	Learning Rate: 0.00358393
	LOSS [training: 0.13534380402850865 | validation: 0.30280938989957285]
	TIME [epoch: 31.8 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11910013749484266		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.11910013749484266 | validation: 0.36611120783114187]
	TIME [epoch: 31.8 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12455356040528394		[learning rate: 0.0035502]
	Learning Rate: 0.00355023
	LOSS [training: 0.12455356040528394 | validation: 0.3175903121469231]
	TIME [epoch: 31.8 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12042470249046416		[learning rate: 0.0035335]
	Learning Rate: 0.0035335
	LOSS [training: 0.12042470249046416 | validation: 0.3265543430792008]
	TIME [epoch: 31.9 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13784609014336993		[learning rate: 0.0035168]
	Learning Rate: 0.00351685
	LOSS [training: 0.13784609014336993 | validation: 0.31213316559768345]
	TIME [epoch: 31.8 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12953215765999393		[learning rate: 0.0035003]
	Learning Rate: 0.00350028
	LOSS [training: 0.12953215765999393 | validation: 0.33634317056867746]
	TIME [epoch: 31.8 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11859663181318815		[learning rate: 0.0034838]
	Learning Rate: 0.00348378
	LOSS [training: 0.11859663181318815 | validation: 0.405468731358671]
	TIME [epoch: 31.8 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13215418578022692		[learning rate: 0.0034674]
	Learning Rate: 0.00346737
	LOSS [training: 0.13215418578022692 | validation: 0.31950755558726346]
	TIME [epoch: 31.9 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1468424730881761		[learning rate: 0.003451]
	Learning Rate: 0.00345103
	LOSS [training: 0.1468424730881761 | validation: 0.3106730874842269]
	TIME [epoch: 31.8 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11762913874942618		[learning rate: 0.0034348]
	Learning Rate: 0.00343477
	LOSS [training: 0.11762913874942618 | validation: 0.30157533318209434]
	TIME [epoch: 31.8 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12539768911801358		[learning rate: 0.0034186]
	Learning Rate: 0.00341858
	LOSS [training: 0.12539768911801358 | validation: 0.35527036150239494]
	TIME [epoch: 31.8 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12556715507360522		[learning rate: 0.0034025]
	Learning Rate: 0.00340247
	LOSS [training: 0.12556715507360522 | validation: 0.31551485188341116]
	TIME [epoch: 31.8 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10393124442395053		[learning rate: 0.0033864]
	Learning Rate: 0.00338644
	LOSS [training: 0.10393124442395053 | validation: 0.3463297526790937]
	TIME [epoch: 31.8 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1370091519087558		[learning rate: 0.0033705]
	Learning Rate: 0.00337048
	LOSS [training: 0.1370091519087558 | validation: 0.29199357642253837]
	TIME [epoch: 31.9 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240719_004901/states/model_facs_v4_dec2b_2dpca_v15b_268.pth
	Model improved!!!
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11961127191814686		[learning rate: 0.0033546]
	Learning Rate: 0.0033546
	LOSS [training: 0.11961127191814686 | validation: 0.3147092498107621]
	TIME [epoch: 31.8 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.127818438338102		[learning rate: 0.0033388]
	Learning Rate: 0.00333879
	LOSS [training: 0.127818438338102 | validation: 0.33284496610817094]
	TIME [epoch: 31.9 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15230859084120613		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.15230859084120613 | validation: 0.4411023858541301]
	TIME [epoch: 31.8 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14679025715824948		[learning rate: 0.0033074]
	Learning Rate: 0.0033074
	LOSS [training: 0.14679025715824948 | validation: 0.3083831855232573]
	TIME [epoch: 31.8 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13612806352105564		[learning rate: 0.0032918]
	Learning Rate: 0.00329182
	LOSS [training: 0.13612806352105564 | validation: 0.3065878170138576]
	TIME [epoch: 31.8 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12471173339719085		[learning rate: 0.0032763]
	Learning Rate: 0.00327631
	LOSS [training: 0.12471173339719085 | validation: 0.3652408803008927]
	TIME [epoch: 31.9 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11519863481841672		[learning rate: 0.0032609]
	Learning Rate: 0.00326087
	LOSS [training: 0.11519863481841672 | validation: 0.32667457596050903]
	TIME [epoch: 31.8 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14308419648514775		[learning rate: 0.0032455]
	Learning Rate: 0.0032455
	LOSS [training: 0.14308419648514775 | validation: 0.41326186562390566]
	TIME [epoch: 31.8 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11128932337834899		[learning rate: 0.0032302]
	Learning Rate: 0.00323021
	LOSS [training: 0.11128932337834899 | validation: 0.342565306929837]
	TIME [epoch: 31.8 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10910174194947289		[learning rate: 0.003215]
	Learning Rate: 0.00321499
	LOSS [training: 0.10910174194947289 | validation: 0.3129998385729101]
	TIME [epoch: 31.9 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1335869051767284		[learning rate: 0.0031998]
	Learning Rate: 0.00319984
	LOSS [training: 0.1335869051767284 | validation: 0.3496423202406083]
	TIME [epoch: 31.8 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12593926939272237		[learning rate: 0.0031848]
	Learning Rate: 0.00318476
	LOSS [training: 0.12593926939272237 | validation: 0.3054173130224135]
	TIME [epoch: 31.8 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12312401167861596		[learning rate: 0.0031698]
	Learning Rate: 0.00316975
	LOSS [training: 0.12312401167861596 | validation: 0.30620511666404876]
	TIME [epoch: 31.8 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1197799698926406		[learning rate: 0.0031548]
	Learning Rate: 0.00315482
	LOSS [training: 0.1197799698926406 | validation: 0.37809361100836525]
	TIME [epoch: 31.9 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15478083261044617		[learning rate: 0.00314]
	Learning Rate: 0.00313995
	LOSS [training: 0.15478083261044617 | validation: 0.32835325795096376]
	TIME [epoch: 31.8 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12475258979894555		[learning rate: 0.0031252]
	Learning Rate: 0.00312516
	LOSS [training: 0.12475258979894555 | validation: 0.2949346038534582]
	TIME [epoch: 31.9 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13627467157617076		[learning rate: 0.0031104]
	Learning Rate: 0.00311043
	LOSS [training: 0.13627467157617076 | validation: 0.350085741103183]
	TIME [epoch: 31.8 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12718066076945922		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.12718066076945922 | validation: 0.33703520918770874]
	TIME [epoch: 31.9 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1225063824918681		[learning rate: 0.0030812]
	Learning Rate: 0.00308119
	LOSS [training: 0.1225063824918681 | validation: 0.3451461696090232]
	TIME [epoch: 31.8 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12930422514802453		[learning rate: 0.0030667]
	Learning Rate: 0.00306667
	LOSS [training: 0.12930422514802453 | validation: 0.3238498174724057]
	TIME [epoch: 31.8 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11243573451445332		[learning rate: 0.0030522]
	Learning Rate: 0.00305222
	LOSS [training: 0.11243573451445332 | validation: 0.29673188372117865]
	TIME [epoch: 31.8 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11751313068140044		[learning rate: 0.0030378]
	Learning Rate: 0.00303783
	LOSS [training: 0.11751313068140044 | validation: 0.3249554255644804]
	TIME [epoch: 31.9 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1639994206890365		[learning rate: 0.0030235]
	Learning Rate: 0.00302352
	LOSS [training: 0.1639994206890365 | validation: 0.2974046999299997]
	TIME [epoch: 31.8 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12083494005644246		[learning rate: 0.0030093]
	Learning Rate: 0.00300927
	LOSS [training: 0.12083494005644246 | validation: 0.3200717645733026]
	TIME [epoch: 31.8 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12219507237782286		[learning rate: 0.0029951]
	Learning Rate: 0.00299509
	LOSS [training: 0.12219507237782286 | validation: 0.3656352562671462]
	TIME [epoch: 31.8 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12644994397954282		[learning rate: 0.002981]
	Learning Rate: 0.00298098
	LOSS [training: 0.12644994397954282 | validation: 0.3571534087669974]
	TIME [epoch: 31.9 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12810810115048257		[learning rate: 0.0029669]
	Learning Rate: 0.00296693
	LOSS [training: 0.12810810115048257 | validation: 0.3326571179341606]
	TIME [epoch: 31.8 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13808526260581436		[learning rate: 0.002953]
	Learning Rate: 0.00295295
	LOSS [training: 0.13808526260581436 | validation: 0.3360539128103677]
	TIME [epoch: 31.8 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13082043982411024		[learning rate: 0.002939]
	Learning Rate: 0.00293904
	LOSS [training: 0.13082043982411024 | validation: 0.3148253249188615]
	TIME [epoch: 31.8 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11645584948870968		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.11645584948870968 | validation: 0.28132813468697226]
	TIME [epoch: 31.8 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240719_004901/states/model_facs_v4_dec2b_2dpca_v15b_298.pth
	Model improved!!!
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11656262207530985		[learning rate: 0.0029114]
	Learning Rate: 0.0029114
	LOSS [training: 0.11656262207530985 | validation: 0.37217152359698347]
	TIME [epoch: 31.7 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.128004877863993		[learning rate: 0.0028977]
	Learning Rate: 0.00289769
	LOSS [training: 0.128004877863993 | validation: 0.2829743955227848]
	TIME [epoch: 31.7 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11465924384553547		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.11465924384553547 | validation: 0.31820686206723553]
	TIME [epoch: 86 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11250363979602523		[learning rate: 0.0028704]
	Learning Rate: 0.00287044
	LOSS [training: 0.11250363979602523 | validation: 0.3412443888460692]
	TIME [epoch: 65.8 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12120172251265933		[learning rate: 0.0028569]
	Learning Rate: 0.00285692
	LOSS [training: 0.12120172251265933 | validation: 0.32663098348938713]
	TIME [epoch: 65.7 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1521897826618135		[learning rate: 0.0028435]
	Learning Rate: 0.00284345
	LOSS [training: 0.1521897826618135 | validation: 0.3290339516334181]
	TIME [epoch: 65.7 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12116085730725373		[learning rate: 0.0028301]
	Learning Rate: 0.00283005
	LOSS [training: 0.12116085730725373 | validation: 0.306587649599809]
	TIME [epoch: 65.8 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1256586867216063		[learning rate: 0.0028167]
	Learning Rate: 0.00281672
	LOSS [training: 0.1256586867216063 | validation: 0.2856919055710224]
	TIME [epoch: 65.7 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11977582764387228		[learning rate: 0.0028034]
	Learning Rate: 0.00280345
	LOSS [training: 0.11977582764387228 | validation: 0.3643532226265223]
	TIME [epoch: 65.7 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14438435566813995		[learning rate: 0.0027902]
	Learning Rate: 0.00279024
	LOSS [training: 0.14438435566813995 | validation: 0.3564675080738277]
	TIME [epoch: 65.7 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11456563254465174		[learning rate: 0.0027771]
	Learning Rate: 0.00277709
	LOSS [training: 0.11456563254465174 | validation: 0.3089019956659431]
	TIME [epoch: 65.5 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11839828746004298		[learning rate: 0.002764]
	Learning Rate: 0.002764
	LOSS [training: 0.11839828746004298 | validation: 0.36039858867613933]
	TIME [epoch: 65.7 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1486082565882823		[learning rate: 0.002751]
	Learning Rate: 0.00275098
	LOSS [training: 0.1486082565882823 | validation: 0.29362911552737214]
	TIME [epoch: 65.7 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12970837943877406		[learning rate: 0.002738]
	Learning Rate: 0.00273802
	LOSS [training: 0.12970837943877406 | validation: 0.3239753096994736]
	TIME [epoch: 65.8 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1212888975849972		[learning rate: 0.0027251]
	Learning Rate: 0.00272511
	LOSS [training: 0.1212888975849972 | validation: 0.3291025747083231]
	TIME [epoch: 65.7 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13556608596994957		[learning rate: 0.0027123]
	Learning Rate: 0.00271227
	LOSS [training: 0.13556608596994957 | validation: 0.369388707273165]
	TIME [epoch: 65.8 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14740143550595766		[learning rate: 0.0026995]
	Learning Rate: 0.00269949
	LOSS [training: 0.14740143550595766 | validation: 0.32684560208701374]
	TIME [epoch: 65.8 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13377992177460718		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.13377992177460718 | validation: 0.3275389931957486]
	TIME [epoch: 65.8 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11758026137169783		[learning rate: 0.0026741]
	Learning Rate: 0.00267411
	LOSS [training: 0.11758026137169783 | validation: 0.3283173109305726]
	TIME [epoch: 65.7 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13559926480887677		[learning rate: 0.0026615]
	Learning Rate: 0.00266151
	LOSS [training: 0.13559926480887677 | validation: 0.3257736102334615]
	TIME [epoch: 65.7 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12065594611036756		[learning rate: 0.002649]
	Learning Rate: 0.00264897
	LOSS [training: 0.12065594611036756 | validation: 0.32178515069683866]
	TIME [epoch: 65.8 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1170351073550308		[learning rate: 0.0026365]
	Learning Rate: 0.00263649
	LOSS [training: 0.1170351073550308 | validation: 0.3280918495189689]
	TIME [epoch: 65.8 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1421014136284598		[learning rate: 0.0026241]
	Learning Rate: 0.00262406
	LOSS [training: 0.1421014136284598 | validation: 0.33778858721075633]
	TIME [epoch: 65.7 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11926779207241225		[learning rate: 0.0026117]
	Learning Rate: 0.0026117
	LOSS [training: 0.11926779207241225 | validation: 0.3023469304116515]
	TIME [epoch: 65.8 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11298132875575476		[learning rate: 0.0025994]
	Learning Rate: 0.00259939
	LOSS [training: 0.11298132875575476 | validation: 0.3272568092851931]
	TIME [epoch: 65.8 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12148269908248757		[learning rate: 0.0025871]
	Learning Rate: 0.00258714
	LOSS [training: 0.12148269908248757 | validation: 0.3256245323988488]
	TIME [epoch: 65.8 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12722106449097123		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.12722106449097123 | validation: 0.3319434327477331]
	TIME [epoch: 65.8 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12139600942731903		[learning rate: 0.0025628]
	Learning Rate: 0.00256282
	LOSS [training: 0.12139600942731903 | validation: 0.30534183770203377]
	TIME [epoch: 65.8 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11430631729915605		[learning rate: 0.0025507]
	Learning Rate: 0.00255074
	LOSS [training: 0.11430631729915605 | validation: 0.3485596987346193]
	TIME [epoch: 65.8 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12470662495127874		[learning rate: 0.0025387]
	Learning Rate: 0.00253872
	LOSS [training: 0.12470662495127874 | validation: 0.33086859246227734]
	TIME [epoch: 65.8 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12717321499456818		[learning rate: 0.0025268]
	Learning Rate: 0.00252676
	LOSS [training: 0.12717321499456818 | validation: 0.2903350039595109]
	TIME [epoch: 65.8 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13286715776869576		[learning rate: 0.0025149]
	Learning Rate: 0.00251485
	LOSS [training: 0.13286715776869576 | validation: 0.3327821119537515]
	TIME [epoch: 65.7 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12611954599208894		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.12611954599208894 | validation: 0.31207199109788847]
	TIME [epoch: 65.7 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12841386535577073		[learning rate: 0.0024912]
	Learning Rate: 0.00249121
	LOSS [training: 0.12841386535577073 | validation: 0.34063216412115455]
	TIME [epoch: 65.9 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10641452332379155		[learning rate: 0.0024795]
	Learning Rate: 0.00247947
	LOSS [training: 0.10641452332379155 | validation: 0.29580870414280586]
	TIME [epoch: 65.8 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10913635686201033		[learning rate: 0.0024678]
	Learning Rate: 0.00246779
	LOSS [training: 0.10913635686201033 | validation: 0.3159755622839962]
	TIME [epoch: 65.8 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12833172065681842		[learning rate: 0.0024562]
	Learning Rate: 0.00245616
	LOSS [training: 0.12833172065681842 | validation: 0.28677537963461064]
	TIME [epoch: 65.7 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.121752210705762		[learning rate: 0.0024446]
	Learning Rate: 0.00244458
	LOSS [training: 0.121752210705762 | validation: 0.4058454243299204]
	TIME [epoch: 65.7 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13060795551519738		[learning rate: 0.0024331]
	Learning Rate: 0.00243307
	LOSS [training: 0.13060795551519738 | validation: 0.2933268485859978]
	TIME [epoch: 65.7 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12508174312515977		[learning rate: 0.0024216]
	Learning Rate: 0.0024216
	LOSS [training: 0.12508174312515977 | validation: 0.3386016410845539]
	TIME [epoch: 65.7 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12704756770643755		[learning rate: 0.0024102]
	Learning Rate: 0.00241019
	LOSS [training: 0.12704756770643755 | validation: 0.3217401316159897]
	TIME [epoch: 65.7 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14196436417974162		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.14196436417974162 | validation: 0.3020965003373671]
	TIME [epoch: 65.8 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12363873860550655		[learning rate: 0.0023875]
	Learning Rate: 0.00238753
	LOSS [training: 0.12363873860550655 | validation: 0.30936642825860505]
	TIME [epoch: 65.8 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.133244678135657		[learning rate: 0.0023763]
	Learning Rate: 0.00237628
	LOSS [training: 0.133244678135657 | validation: 0.32016386454834644]
	TIME [epoch: 65.8 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11812267947530514		[learning rate: 0.0023651]
	Learning Rate: 0.00236508
	LOSS [training: 0.11812267947530514 | validation: 0.32530805939216656]
	TIME [epoch: 65.7 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10891314530646815		[learning rate: 0.0023539]
	Learning Rate: 0.00235394
	LOSS [training: 0.10891314530646815 | validation: 0.3379709020939093]
	TIME [epoch: 65.8 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11194807576751704		[learning rate: 0.0023428]
	Learning Rate: 0.00234285
	LOSS [training: 0.11194807576751704 | validation: 0.31496090406922356]
	TIME [epoch: 65.8 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11333317112824483		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.11333317112824483 | validation: 0.34894445833716525]
	TIME [epoch: 65.8 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12169464492933996		[learning rate: 0.0023208]
	Learning Rate: 0.00232082
	LOSS [training: 0.12169464492933996 | validation: 0.32171748024446467]
	TIME [epoch: 65.8 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1370726607167428		[learning rate: 0.0023099]
	Learning Rate: 0.00230988
	LOSS [training: 0.1370726607167428 | validation: 0.3350999897243554]
	TIME [epoch: 65.8 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1271079233415755		[learning rate: 0.002299]
	Learning Rate: 0.002299
	LOSS [training: 0.1271079233415755 | validation: 0.36811729198506427]
	TIME [epoch: 65.7 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10228520735341405		[learning rate: 0.0022882]
	Learning Rate: 0.00228816
	LOSS [training: 0.10228520735341405 | validation: 0.3062870949449208]
	TIME [epoch: 65.8 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1383611603079154		[learning rate: 0.0022774]
	Learning Rate: 0.00227738
	LOSS [training: 0.1383611603079154 | validation: 0.3312592431916906]
	TIME [epoch: 65.7 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1233357291442085		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.1233357291442085 | validation: 0.3272471188047977]
	TIME [epoch: 65.8 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14126520335220127		[learning rate: 0.002256]
	Learning Rate: 0.00225597
	LOSS [training: 0.14126520335220127 | validation: 0.3260968477056119]
	TIME [epoch: 65.7 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11927546776845048		[learning rate: 0.0022453]
	Learning Rate: 0.00224534
	LOSS [training: 0.11927546776845048 | validation: 0.32347883732221927]
	TIME [epoch: 65.8 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11115499777315482		[learning rate: 0.0022348]
	Learning Rate: 0.00223476
	LOSS [training: 0.11115499777315482 | validation: 0.31981932852674433]
	TIME [epoch: 65.8 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1162406081502447		[learning rate: 0.0022242]
	Learning Rate: 0.00222423
	LOSS [training: 0.1162406081502447 | validation: 0.33863635172268]
	TIME [epoch: 65.6 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11731952908720608		[learning rate: 0.0022137]
	Learning Rate: 0.00221375
	LOSS [training: 0.11731952908720608 | validation: 0.2970845012965324]
	TIME [epoch: 65.7 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1567797837730907		[learning rate: 0.0022033]
	Learning Rate: 0.00220332
	LOSS [training: 0.1567797837730907 | validation: 0.3441055519054217]
	TIME [epoch: 65.7 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12492407081987542		[learning rate: 0.0021929]
	Learning Rate: 0.00219293
	LOSS [training: 0.12492407081987542 | validation: 0.3096838948975039]
	TIME [epoch: 65.8 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1539906084225132		[learning rate: 0.0021826]
	Learning Rate: 0.0021826
	LOSS [training: 0.1539906084225132 | validation: 0.2995153115995634]
	TIME [epoch: 65.7 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12436751008559326		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.12436751008559326 | validation: 0.3524946650860778]
	TIME [epoch: 65.7 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12444062339140027		[learning rate: 0.0021621]
	Learning Rate: 0.00216208
	LOSS [training: 0.12444062339140027 | validation: 0.34310876158389214]
	TIME [epoch: 65.7 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10825625843990637		[learning rate: 0.0021519]
	Learning Rate: 0.00215189
	LOSS [training: 0.10825625843990637 | validation: 0.35915948430065664]
	TIME [epoch: 65.8 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09889711540313784		[learning rate: 0.0021418]
	Learning Rate: 0.00214175
	LOSS [training: 0.09889711540313784 | validation: 0.3110082533403404]
	TIME [epoch: 65.8 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12353268117951637		[learning rate: 0.0021317]
	Learning Rate: 0.00213166
	LOSS [training: 0.12353268117951637 | validation: 0.31766300038630185]
	TIME [epoch: 65.7 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11433386605749826		[learning rate: 0.0021216]
	Learning Rate: 0.00212162
	LOSS [training: 0.11433386605749826 | validation: 0.4403034552519169]
	TIME [epoch: 65.7 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13509723284023012		[learning rate: 0.0021116]
	Learning Rate: 0.00211162
	LOSS [training: 0.13509723284023012 | validation: 0.3093557864437094]
	TIME [epoch: 65.9 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13058112175745873		[learning rate: 0.0021017]
	Learning Rate: 0.00210167
	LOSS [training: 0.13058112175745873 | validation: 0.33016052457454653]
	TIME [epoch: 65.8 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12738667127460465		[learning rate: 0.0020918]
	Learning Rate: 0.00209176
	LOSS [training: 0.12738667127460465 | validation: 0.4293955222936802]
	TIME [epoch: 65.8 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14486231514967518		[learning rate: 0.0020819]
	Learning Rate: 0.00208191
	LOSS [training: 0.14486231514967518 | validation: 0.32938765363578354]
	TIME [epoch: 65.8 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1419051148681944		[learning rate: 0.0020721]
	Learning Rate: 0.0020721
	LOSS [training: 0.1419051148681944 | validation: 0.3300650187520638]
	TIME [epoch: 65.8 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11148635046344793		[learning rate: 0.0020623]
	Learning Rate: 0.00206233
	LOSS [training: 0.11148635046344793 | validation: 0.3185433425163944]
	TIME [epoch: 65.6 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12738319550793922		[learning rate: 0.0020526]
	Learning Rate: 0.00205262
	LOSS [training: 0.12738319550793922 | validation: 0.3241964805452368]
	TIME [epoch: 65.7 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.137529079034687		[learning rate: 0.0020429]
	Learning Rate: 0.00204294
	LOSS [training: 0.137529079034687 | validation: 0.3278315805775712]
	TIME [epoch: 65.5 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12114826490561506		[learning rate: 0.0020333]
	Learning Rate: 0.00203332
	LOSS [training: 0.12114826490561506 | validation: 0.34425837036757045]
	TIME [epoch: 65.8 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14380569173747434		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.14380569173747434 | validation: 0.3711941265126759]
	TIME [epoch: 65.8 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12389031435876699		[learning rate: 0.0020142]
	Learning Rate: 0.0020142
	LOSS [training: 0.12389031435876699 | validation: 0.3449838327661926]
	TIME [epoch: 65.8 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11232094737487575		[learning rate: 0.0020047]
	Learning Rate: 0.00200471
	LOSS [training: 0.11232094737487575 | validation: 0.3385892946220416]
	TIME [epoch: 65.8 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12523509588222057		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.12523509588222057 | validation: 0.3136543492236714]
	TIME [epoch: 65.8 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12444277755804314		[learning rate: 0.0019859]
	Learning Rate: 0.00198586
	LOSS [training: 0.12444277755804314 | validation: 0.323753867475066]
	TIME [epoch: 65.9 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11628933685160082		[learning rate: 0.0019765]
	Learning Rate: 0.0019765
	LOSS [training: 0.11628933685160082 | validation: 0.29184042137601884]
	TIME [epoch: 65.8 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12793868862487182		[learning rate: 0.0019672]
	Learning Rate: 0.00196719
	LOSS [training: 0.12793868862487182 | validation: 0.3147609820485611]
	TIME [epoch: 65.8 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1333328329897226		[learning rate: 0.0019579]
	Learning Rate: 0.00195792
	LOSS [training: 0.1333328329897226 | validation: 0.29617945904331844]
	TIME [epoch: 65.7 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14180401727761943		[learning rate: 0.0019487]
	Learning Rate: 0.00194869
	LOSS [training: 0.14180401727761943 | validation: 0.3091999431678063]
	TIME [epoch: 65.7 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1278213996257078		[learning rate: 0.0019395]
	Learning Rate: 0.00193951
	LOSS [training: 0.1278213996257078 | validation: 0.35858966742254733]
	TIME [epoch: 65.9 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11980929486999492		[learning rate: 0.0019304]
	Learning Rate: 0.00193037
	LOSS [training: 0.11980929486999492 | validation: 0.285544588894275]
	TIME [epoch: 65.8 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11194034527507325		[learning rate: 0.0019213]
	Learning Rate: 0.00192128
	LOSS [training: 0.11194034527507325 | validation: 0.3306491564332177]
	TIME [epoch: 65.8 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13786423826602925		[learning rate: 0.0019122]
	Learning Rate: 0.00191222
	LOSS [training: 0.13786423826602925 | validation: 0.3197809085222603]
	TIME [epoch: 65.8 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14346642743795815		[learning rate: 0.0019032]
	Learning Rate: 0.00190321
	LOSS [training: 0.14346642743795815 | validation: 0.3419170270294347]
	TIME [epoch: 65.8 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11703431734594179		[learning rate: 0.0018942]
	Learning Rate: 0.00189424
	LOSS [training: 0.11703431734594179 | validation: 0.30027779328553206]
	TIME [epoch: 65.7 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12342489807094359		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.12342489807094359 | validation: 0.2927272218496363]
	TIME [epoch: 65.9 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12149846285371697		[learning rate: 0.0018764]
	Learning Rate: 0.00187643
	LOSS [training: 0.12149846285371697 | validation: 0.32450012718355425]
	TIME [epoch: 65.9 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1147644195456301		[learning rate: 0.0018676]
	Learning Rate: 0.00186759
	LOSS [training: 0.1147644195456301 | validation: 0.29896444086088303]
	TIME [epoch: 65.9 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1099152843272781		[learning rate: 0.0018588]
	Learning Rate: 0.00185879
	LOSS [training: 0.1099152843272781 | validation: 0.32253877669791453]
	TIME [epoch: 65.9 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12730378489245933		[learning rate: 0.00185]
	Learning Rate: 0.00185003
	LOSS [training: 0.12730378489245933 | validation: 0.3249924003738279]
	TIME [epoch: 65.8 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13746511279347776		[learning rate: 0.0018413]
	Learning Rate: 0.00184132
	LOSS [training: 0.13746511279347776 | validation: 0.31790602752524255]
	TIME [epoch: 65.7 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1344298648090424		[learning rate: 0.0018326]
	Learning Rate: 0.00183264
	LOSS [training: 0.1344298648090424 | validation: 0.3012547051507427]
	TIME [epoch: 65.8 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11878684578558306		[learning rate: 0.001824]
	Learning Rate: 0.001824
	LOSS [training: 0.11878684578558306 | validation: 0.29995259102447125]
	TIME [epoch: 65.9 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12699697061052106		[learning rate: 0.0018154]
	Learning Rate: 0.00181541
	LOSS [training: 0.12699697061052106 | validation: 0.31375661906631236]
	TIME [epoch: 65.9 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12936210191553787		[learning rate: 0.0018069]
	Learning Rate: 0.00180685
	LOSS [training: 0.12936210191553787 | validation: 0.2960527996220072]
	TIME [epoch: 65.9 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11335056738522481		[learning rate: 0.0017983]
	Learning Rate: 0.00179834
	LOSS [training: 0.11335056738522481 | validation: 0.3174156949692071]
	TIME [epoch: 65.7 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12941492920149716		[learning rate: 0.0017899]
	Learning Rate: 0.00178987
	LOSS [training: 0.12941492920149716 | validation: 0.3111574225045535]
	TIME [epoch: 65.7 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11556118140458765		[learning rate: 0.0017814]
	Learning Rate: 0.00178143
	LOSS [training: 0.11556118140458765 | validation: 0.2975845198366763]
	TIME [epoch: 65.7 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10159004465660684		[learning rate: 0.001773]
	Learning Rate: 0.00177304
	LOSS [training: 0.10159004465660684 | validation: 0.3215588262583774]
	TIME [epoch: 65.7 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15756439785368573		[learning rate: 0.0017647]
	Learning Rate: 0.00176468
	LOSS [training: 0.15756439785368573 | validation: 0.3384332403383793]
	TIME [epoch: 65.8 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1072051346495879		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.1072051346495879 | validation: 0.3264616371413056]
	TIME [epoch: 65.7 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12883819221076623		[learning rate: 0.0017481]
	Learning Rate: 0.00174809
	LOSS [training: 0.12883819221076623 | validation: 0.3128147323614508]
	TIME [epoch: 65.7 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10940931517514661		[learning rate: 0.0017399]
	Learning Rate: 0.00173985
	LOSS [training: 0.10940931517514661 | validation: 0.31935771327856716]
	TIME [epoch: 65.7 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11011878654144117		[learning rate: 0.0017317]
	Learning Rate: 0.00173166
	LOSS [training: 0.11011878654144117 | validation: 0.34794535852658504]
	TIME [epoch: 65.6 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12169954429041346		[learning rate: 0.0017235]
	Learning Rate: 0.0017235
	LOSS [training: 0.12169954429041346 | validation: 0.3207609669007987]
	TIME [epoch: 65.8 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11977408026822942		[learning rate: 0.0017154]
	Learning Rate: 0.00171537
	LOSS [training: 0.11977408026822942 | validation: 0.295572498863401]
	TIME [epoch: 65.9 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11730388084797583		[learning rate: 0.0017073]
	Learning Rate: 0.00170729
	LOSS [training: 0.11730388084797583 | validation: 0.3575012549671932]
	TIME [epoch: 65.8 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12606030733967277		[learning rate: 0.0016992]
	Learning Rate: 0.00169925
	LOSS [training: 0.12606030733967277 | validation: 0.3150280203397839]
	TIME [epoch: 65.9 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11936264590942433		[learning rate: 0.0016912]
	Learning Rate: 0.00169124
	LOSS [training: 0.11936264590942433 | validation: 0.33033070680092674]
	TIME [epoch: 65.9 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13052386137692878		[learning rate: 0.0016833]
	Learning Rate: 0.00168327
	LOSS [training: 0.13052386137692878 | validation: 0.2879420596764397]
	TIME [epoch: 65.8 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12853869058990303		[learning rate: 0.0016753]
	Learning Rate: 0.00167534
	LOSS [training: 0.12853869058990303 | validation: 0.33428298981118204]
	TIME [epoch: 65.8 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.133407656566353		[learning rate: 0.0016674]
	Learning Rate: 0.00166744
	LOSS [training: 0.133407656566353 | validation: 0.32748100770522637]
	TIME [epoch: 65.9 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11509259041668343		[learning rate: 0.0016596]
	Learning Rate: 0.00165959
	LOSS [training: 0.11509259041668343 | validation: 0.319847161313054]
	TIME [epoch: 65.9 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10738633685631853		[learning rate: 0.0016518]
	Learning Rate: 0.00165177
	LOSS [training: 0.10738633685631853 | validation: 0.3331303966558727]
	TIME [epoch: 65.9 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13614391151381053		[learning rate: 0.001644]
	Learning Rate: 0.00164398
	LOSS [training: 0.13614391151381053 | validation: 0.304031879816586]
	TIME [epoch: 65.9 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11856634111403964		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.11856634111403964 | validation: 0.34604488539908856]
	TIME [epoch: 65.9 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1173657360270313		[learning rate: 0.0016285]
	Learning Rate: 0.00162853
	LOSS [training: 0.1173657360270313 | validation: 0.29483408356493057]
	TIME [epoch: 65.8 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11048950032951294		[learning rate: 0.0016209]
	Learning Rate: 0.00162085
	LOSS [training: 0.11048950032951294 | validation: 0.3208559641627273]
	TIME [epoch: 65.7 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12551827280692107		[learning rate: 0.0016132]
	Learning Rate: 0.00161322
	LOSS [training: 0.12551827280692107 | validation: 0.31947419084703216]
	TIME [epoch: 65.8 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12588248332445645		[learning rate: 0.0016056]
	Learning Rate: 0.00160561
	LOSS [training: 0.12588248332445645 | validation: 0.2904335824451617]
	TIME [epoch: 65.8 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11615597922729166		[learning rate: 0.001598]
	Learning Rate: 0.00159805
	LOSS [training: 0.11615597922729166 | validation: 0.31112572959637863]
	TIME [epoch: 65.9 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1599206449740333		[learning rate: 0.0015905]
	Learning Rate: 0.00159052
	LOSS [training: 0.1599206449740333 | validation: 0.29771258202163814]
	TIME [epoch: 65.7 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10371064380513642		[learning rate: 0.001583]
	Learning Rate: 0.00158302
	LOSS [training: 0.10371064380513642 | validation: 0.3221287798330947]
	TIME [epoch: 65.8 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1209851800767225		[learning rate: 0.0015756]
	Learning Rate: 0.00157556
	LOSS [training: 0.1209851800767225 | validation: 0.33051883503483953]
	TIME [epoch: 65.8 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10913205882352223		[learning rate: 0.0015681]
	Learning Rate: 0.00156814
	LOSS [training: 0.10913205882352223 | validation: 0.3373592913131722]
	TIME [epoch: 65.7 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1391072441333778		[learning rate: 0.0015607]
	Learning Rate: 0.00156075
	LOSS [training: 0.1391072441333778 | validation: 0.33435630198045246]
	TIME [epoch: 65.7 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11947530988820679		[learning rate: 0.0015534]
	Learning Rate: 0.0015534
	LOSS [training: 0.11947530988820679 | validation: 0.29451611762470464]
	TIME [epoch: 65.7 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1104414431289809		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.1104414431289809 | validation: 0.32766513896872174]
	TIME [epoch: 65.7 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11285605797928719		[learning rate: 0.0015388]
	Learning Rate: 0.00153879
	LOSS [training: 0.11285605797928719 | validation: 0.3230619470178338]
	TIME [epoch: 65.8 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12624048383944206		[learning rate: 0.0015315]
	Learning Rate: 0.00153154
	LOSS [training: 0.12624048383944206 | validation: 0.3013812058131005]
	TIME [epoch: 65.7 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11978605981239909		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.11978605981239909 | validation: 0.33197262574495645]
	TIME [epoch: 65.8 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10537501397322646		[learning rate: 0.0015171]
	Learning Rate: 0.00151714
	LOSS [training: 0.10537501397322646 | validation: 0.32158013178512024]
	TIME [epoch: 65.7 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1238849910407144		[learning rate: 0.00151]
	Learning Rate: 0.00150999
	LOSS [training: 0.1238849910407144 | validation: 0.3594756935251757]
	TIME [epoch: 65.8 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11960378586080803		[learning rate: 0.0015029]
	Learning Rate: 0.00150288
	LOSS [training: 0.11960378586080803 | validation: 0.3513952110407266]
	TIME [epoch: 65.8 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1421569498507661		[learning rate: 0.0014958]
	Learning Rate: 0.00149579
	LOSS [training: 0.1421569498507661 | validation: 0.31237525729858234]
	TIME [epoch: 65.9 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13496145285981948		[learning rate: 0.0014887]
	Learning Rate: 0.00148875
	LOSS [training: 0.13496145285981948 | validation: 0.31353416333943396]
	TIME [epoch: 65.7 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11584301852757181		[learning rate: 0.0014817]
	Learning Rate: 0.00148173
	LOSS [training: 0.11584301852757181 | validation: 0.3066762437948756]
	TIME [epoch: 65.9 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11169928383973378		[learning rate: 0.0014747]
	Learning Rate: 0.00147475
	LOSS [training: 0.11169928383973378 | validation: 0.32336863434160407]
	TIME [epoch: 65.6 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10961818082898604		[learning rate: 0.0014678]
	Learning Rate: 0.0014678
	LOSS [training: 0.10961818082898604 | validation: 0.3280483977063528]
	TIME [epoch: 65.8 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13347951356497095		[learning rate: 0.0014609]
	Learning Rate: 0.00146088
	LOSS [training: 0.13347951356497095 | validation: 0.2911763977858179]
	TIME [epoch: 65.6 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1151861627749942		[learning rate: 0.001454]
	Learning Rate: 0.001454
	LOSS [training: 0.1151861627749942 | validation: 0.33106555169345214]
	TIME [epoch: 65.7 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11857912067217592		[learning rate: 0.0014471]
	Learning Rate: 0.00144715
	LOSS [training: 0.11857912067217592 | validation: 0.3166260884182962]
	TIME [epoch: 65.7 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10881673510383844		[learning rate: 0.0014403]
	Learning Rate: 0.00144033
	LOSS [training: 0.10881673510383844 | validation: 0.3415850816672259]
	TIME [epoch: 65.9 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10482556207787906		[learning rate: 0.0014335]
	Learning Rate: 0.00143354
	LOSS [training: 0.10482556207787906 | validation: 0.31856237660254666]
	TIME [epoch: 65.7 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13635943194430505		[learning rate: 0.0014268]
	Learning Rate: 0.00142679
	LOSS [training: 0.13635943194430505 | validation: 0.34202300088602366]
	TIME [epoch: 65.8 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1254996938417114		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.1254996938417114 | validation: 0.3581048398317748]
	TIME [epoch: 65.8 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11164701902660798		[learning rate: 0.0014134]
	Learning Rate: 0.00141337
	LOSS [training: 0.11164701902660798 | validation: 0.3063648019568481]
	TIME [epoch: 65.9 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1219618826632409		[learning rate: 0.0014067]
	Learning Rate: 0.00140671
	LOSS [training: 0.1219618826632409 | validation: 0.3268536530863505]
	TIME [epoch: 65.8 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13135856966588685		[learning rate: 0.0014001]
	Learning Rate: 0.00140008
	LOSS [training: 0.13135856966588685 | validation: 0.34457064141637905]
	TIME [epoch: 65.8 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10934790161482572		[learning rate: 0.0013935]
	Learning Rate: 0.00139349
	LOSS [training: 0.10934790161482572 | validation: 0.3238871185458981]
	TIME [epoch: 65.8 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.131833036597772		[learning rate: 0.0013869]
	Learning Rate: 0.00138692
	LOSS [training: 0.131833036597772 | validation: 0.2886643770042214]
	TIME [epoch: 65.7 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12783408045867178		[learning rate: 0.0013804]
	Learning Rate: 0.00138038
	LOSS [training: 0.12783408045867178 | validation: 0.31648859909914534]
	TIME [epoch: 65.8 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13256203543931286		[learning rate: 0.0013739]
	Learning Rate: 0.00137388
	LOSS [training: 0.13256203543931286 | validation: 0.34235154011044866]
	TIME [epoch: 65.9 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12625569732906775		[learning rate: 0.0013674]
	Learning Rate: 0.00136741
	LOSS [training: 0.12625569732906775 | validation: 0.30025912710719443]
	TIME [epoch: 65.8 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09933984621739914		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.09933984621739914 | validation: 0.31214824118808576]
	TIME [epoch: 65.7 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13245876365756498		[learning rate: 0.0013545]
	Learning Rate: 0.00135455
	LOSS [training: 0.13245876365756498 | validation: 0.3296643697615522]
	TIME [epoch: 65.8 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14233747734751084		[learning rate: 0.0013482]
	Learning Rate: 0.00134817
	LOSS [training: 0.14233747734751084 | validation: 0.3130218494813697]
	TIME [epoch: 65.9 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11158831731211136		[learning rate: 0.0013418]
	Learning Rate: 0.00134181
	LOSS [training: 0.11158831731211136 | validation: 0.3147714391577009]
	TIME [epoch: 65.9 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1089347585990129		[learning rate: 0.0013355]
	Learning Rate: 0.00133549
	LOSS [training: 0.1089347585990129 | validation: 0.3128163246234653]
	TIME [epoch: 65.9 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12864396364190833		[learning rate: 0.0013292]
	Learning Rate: 0.0013292
	LOSS [training: 0.12864396364190833 | validation: 0.31481854178392965]
	TIME [epoch: 65.9 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11629272228334152		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.11629272228334152 | validation: 0.30326502811647205]
	TIME [epoch: 65.9 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1314503833898931		[learning rate: 0.0013167]
	Learning Rate: 0.0013167
	LOSS [training: 0.1314503833898931 | validation: 0.33299757526035273]
	TIME [epoch: 65.8 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10904277279548916		[learning rate: 0.0013105]
	Learning Rate: 0.0013105
	LOSS [training: 0.10904277279548916 | validation: 0.28721557704483985]
	TIME [epoch: 65.8 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1071891863425993		[learning rate: 0.0013043]
	Learning Rate: 0.00130432
	LOSS [training: 0.1071891863425993 | validation: 0.3416101451764068]
	TIME [epoch: 65.8 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10503230439915567		[learning rate: 0.0012982]
	Learning Rate: 0.00129818
	LOSS [training: 0.10503230439915567 | validation: 0.3367956267052602]
	TIME [epoch: 65.8 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12850578917382957		[learning rate: 0.0012921]
	Learning Rate: 0.00129206
	LOSS [training: 0.12850578917382957 | validation: 0.3198122356125576]
	TIME [epoch: 65.9 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1278527715128755		[learning rate: 0.001286]
	Learning Rate: 0.00128597
	LOSS [training: 0.1278527715128755 | validation: 0.34107501282768604]
	TIME [epoch: 65.8 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11475109342381544		[learning rate: 0.0012799]
	Learning Rate: 0.00127991
	LOSS [training: 0.11475109342381544 | validation: 0.2920667466441138]
	TIME [epoch: 65.8 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12278618596611225		[learning rate: 0.0012739]
	Learning Rate: 0.00127388
	LOSS [training: 0.12278618596611225 | validation: 0.3171951382758166]
	TIME [epoch: 65.7 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1093486303065634		[learning rate: 0.0012679]
	Learning Rate: 0.00126788
	LOSS [training: 0.1093486303065634 | validation: 0.31011346111422955]
	TIME [epoch: 65.8 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12587898542627887		[learning rate: 0.0012619]
	Learning Rate: 0.0012619
	LOSS [training: 0.12587898542627887 | validation: 0.3291511065172079]
	TIME [epoch: 65.7 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14104638274598924		[learning rate: 0.001256]
	Learning Rate: 0.00125596
	LOSS [training: 0.14104638274598924 | validation: 0.33056521826597385]
	TIME [epoch: 65.8 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11990827781862305		[learning rate: 0.00125]
	Learning Rate: 0.00125004
	LOSS [training: 0.11990827781862305 | validation: 0.31056333121257834]
	TIME [epoch: 65.8 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11192621813389994		[learning rate: 0.0012441]
	Learning Rate: 0.00124415
	LOSS [training: 0.11192621813389994 | validation: 0.31889969698748305]
	TIME [epoch: 65.8 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11968752893837173		[learning rate: 0.0012383]
	Learning Rate: 0.00123828
	LOSS [training: 0.11968752893837173 | validation: 0.31147956600652704]
	TIME [epoch: 65.8 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12221000139325632		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.12221000139325632 | validation: 0.32045951516184357]
	TIME [epoch: 65.9 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13282451488040048		[learning rate: 0.0012266]
	Learning Rate: 0.00122664
	LOSS [training: 0.13282451488040048 | validation: 0.3170360245287459]
	TIME [epoch: 65.9 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12870271987686038		[learning rate: 0.0012209]
	Learning Rate: 0.00122086
	LOSS [training: 0.12870271987686038 | validation: 0.3218385426632281]
	TIME [epoch: 65.8 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13351625381611698		[learning rate: 0.0012151]
	Learning Rate: 0.00121511
	LOSS [training: 0.13351625381611698 | validation: 0.33228168112216694]
	TIME [epoch: 65.8 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12587861230319455		[learning rate: 0.0012094]
	Learning Rate: 0.00120938
	LOSS [training: 0.12587861230319455 | validation: 0.3302330045428607]
	TIME [epoch: 65.7 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10755811713955155		[learning rate: 0.0012037]
	Learning Rate: 0.00120368
	LOSS [training: 0.10755811713955155 | validation: 0.3119151941026218]
	TIME [epoch: 65.7 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11038758382564694		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.11038758382564694 | validation: 0.2958556439048353]
	TIME [epoch: 65.8 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11911679069242627		[learning rate: 0.0011924]
	Learning Rate: 0.00119237
	LOSS [training: 0.11911679069242627 | validation: 0.3398139935887633]
	TIME [epoch: 65.7 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12663259856105585		[learning rate: 0.0011867]
	Learning Rate: 0.00118675
	LOSS [training: 0.12663259856105585 | validation: 0.31965056269693937]
	TIME [epoch: 65.8 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10798872875530699		[learning rate: 0.0011812]
	Learning Rate: 0.00118116
	LOSS [training: 0.10798872875530699 | validation: 0.34159220461341605]
	TIME [epoch: 65.9 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1374296933996495		[learning rate: 0.0011756]
	Learning Rate: 0.00117559
	LOSS [training: 0.1374296933996495 | validation: 0.3302301451539617]
	TIME [epoch: 65.9 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09713604463848187		[learning rate: 0.0011701]
	Learning Rate: 0.00117005
	LOSS [training: 0.09713604463848187 | validation: 0.3186716967494271]
	TIME [epoch: 65.8 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11888813572587167		[learning rate: 0.0011645]
	Learning Rate: 0.00116454
	LOSS [training: 0.11888813572587167 | validation: 0.2998678901798342]
	TIME [epoch: 65.7 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1205384238102002		[learning rate: 0.0011591]
	Learning Rate: 0.00115905
	LOSS [training: 0.1205384238102002 | validation: 0.3237427906682861]
	TIME [epoch: 66 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10490358054131521		[learning rate: 0.0011536]
	Learning Rate: 0.00115359
	LOSS [training: 0.10490358054131521 | validation: 0.34689741731078705]
	TIME [epoch: 65.9 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11612081621261683		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.11612081621261683 | validation: 0.27916690728129645]
	TIME [epoch: 65.9 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240719_004901/states/model_facs_v4_dec2b_2dpca_v15b_496.pth
	Model improved!!!
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11469266502076118		[learning rate: 0.0011427]
	Learning Rate: 0.00114274
	LOSS [training: 0.11469266502076118 | validation: 0.33132426781481533]
	TIME [epoch: 65.9 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10621069599155698		[learning rate: 0.0011374]
	Learning Rate: 0.00113736
	LOSS [training: 0.10621069599155698 | validation: 0.310132305701823]
	TIME [epoch: 65.9 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11692073044804369		[learning rate: 0.001132]
	Learning Rate: 0.001132
	LOSS [training: 0.11692073044804369 | validation: 0.31059774721068034]
	TIME [epoch: 66 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12466827094226525		[learning rate: 0.0011267]
	Learning Rate: 0.00112667
	LOSS [training: 0.12466827094226525 | validation: 0.30705973972265826]
	TIME [epoch: 65.8 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12231932270022279		[learning rate: 0.0011214]
	Learning Rate: 0.00112136
	LOSS [training: 0.12231932270022279 | validation: 0.3285261707952865]
	TIME [epoch: 65.9 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11214409070786036		[learning rate: 0.0011161]
	Learning Rate: 0.00111607
	LOSS [training: 0.11214409070786036 | validation: 0.3299903061326786]
	TIME [epoch: 65.8 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.113820767094944		[learning rate: 0.0011108]
	Learning Rate: 0.00111081
	LOSS [training: 0.113820767094944 | validation: 0.3154413655268834]
	TIME [epoch: 65.8 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11266675366865124		[learning rate: 0.0011056]
	Learning Rate: 0.00110558
	LOSS [training: 0.11266675366865124 | validation: 0.32521928679754336]
	TIME [epoch: 65.8 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12436041219609617		[learning rate: 0.0011004]
	Learning Rate: 0.00110037
	LOSS [training: 0.12436041219609617 | validation: 0.3445862152811743]
	TIME [epoch: 65.6 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12620837260381074		[learning rate: 0.0010952]
	Learning Rate: 0.00109518
	LOSS [training: 0.12620837260381074 | validation: 0.3012721562475618]
	TIME [epoch: 65.8 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1362499608175537		[learning rate: 0.00109]
	Learning Rate: 0.00109002
	LOSS [training: 0.1362499608175537 | validation: 0.30960352918368206]
	TIME [epoch: 65.9 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10833775852663384		[learning rate: 0.0010849]
	Learning Rate: 0.00108489
	LOSS [training: 0.10833775852663384 | validation: 0.3389368099459072]
	TIME [epoch: 65.7 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12203258025559013		[learning rate: 0.0010798]
	Learning Rate: 0.00107978
	LOSS [training: 0.12203258025559013 | validation: 0.3026848196674639]
	TIME [epoch: 65.8 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10477265250817354		[learning rate: 0.0010747]
	Learning Rate: 0.00107469
	LOSS [training: 0.10477265250817354 | validation: 0.3048222882919767]
	TIME [epoch: 65.8 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1180243422109901		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.1180243422109901 | validation: 0.3330759297860356]
	TIME [epoch: 65.8 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1002369776708488		[learning rate: 0.0010646]
	Learning Rate: 0.00106458
	LOSS [training: 0.1002369776708488 | validation: 0.2912165887065932]
	TIME [epoch: 65.9 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11111937385189966		[learning rate: 0.0010596]
	Learning Rate: 0.00105957
	LOSS [training: 0.11111937385189966 | validation: 0.3341115993288306]
	TIME [epoch: 65.9 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10067420610917013		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.10067420610917013 | validation: 0.3163046199702954]
	TIME [epoch: 65.9 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12340710945600292		[learning rate: 0.0010496]
	Learning Rate: 0.0010496
	LOSS [training: 0.12340710945600292 | validation: 0.31352173076355944]
	TIME [epoch: 65.9 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1479239763159816		[learning rate: 0.0010447]
	Learning Rate: 0.00104466
	LOSS [training: 0.1479239763159816 | validation: 0.38742839958159725]
	TIME [epoch: 65.7 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11873849117391945		[learning rate: 0.0010397]
	Learning Rate: 0.00103974
	LOSS [training: 0.11873849117391945 | validation: 0.29468042381178966]
	TIME [epoch: 65.9 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10730981109334187		[learning rate: 0.0010348]
	Learning Rate: 0.00103484
	LOSS [training: 0.10730981109334187 | validation: 0.3083910854568922]
	TIME [epoch: 65.9 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1021880091756347		[learning rate: 0.00103]
	Learning Rate: 0.00102996
	LOSS [training: 0.1021880091756347 | validation: 0.33492218085086717]
	TIME [epoch: 65.8 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12694568426846392		[learning rate: 0.0010251]
	Learning Rate: 0.00102511
	LOSS [training: 0.12694568426846392 | validation: 0.30549774727579626]
	TIME [epoch: 65.8 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1310657769711975		[learning rate: 0.0010203]
	Learning Rate: 0.00102028
	LOSS [training: 0.1310657769711975 | validation: 0.298533602141959]
	TIME [epoch: 65.8 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12723550556639665		[learning rate: 0.0010155]
	Learning Rate: 0.00101547
	LOSS [training: 0.12723550556639665 | validation: 0.32499161716366626]
	TIME [epoch: 65.9 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12064657763488146		[learning rate: 0.0010107]
	Learning Rate: 0.00101068
	LOSS [training: 0.12064657763488146 | validation: 0.3541894823003841]
	TIME [epoch: 65.8 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13287753395790117		[learning rate: 0.0010059]
	Learning Rate: 0.00100592
	LOSS [training: 0.13287753395790117 | validation: 0.29189447371498306]
	TIME [epoch: 65.9 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1107416233889181		[learning rate: 0.0010012]
	Learning Rate: 0.00100118
	LOSS [training: 0.1107416233889181 | validation: 0.3064100043885926]
	TIME [epoch: 65.7 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12024707226206038		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.12024707226206038 | validation: 0.3354732739334763]
	TIME [epoch: 66.3 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13010689684032598		[learning rate: 0.00099177]
	Learning Rate: 0.000991768
	LOSS [training: 0.13010689684032598 | validation: 0.3139839816770412]
	TIME [epoch: 65.8 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12496752346955133		[learning rate: 0.0009871]
	Learning Rate: 0.000987095
	LOSS [training: 0.12496752346955133 | validation: 0.30302210752018344]
	TIME [epoch: 65.8 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11342499292079766		[learning rate: 0.00098244]
	Learning Rate: 0.000982444
	LOSS [training: 0.11342499292079766 | validation: 0.29347748245386884]
	TIME [epoch: 65.8 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13242376392761782		[learning rate: 0.00097781]
	Learning Rate: 0.000977814
	LOSS [training: 0.13242376392761782 | validation: 0.29824963853448877]
	TIME [epoch: 65.7 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11234684920843375		[learning rate: 0.00097321]
	Learning Rate: 0.000973207
	LOSS [training: 0.11234684920843375 | validation: 0.31300693798649737]
	TIME [epoch: 65.8 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12253655661559043		[learning rate: 0.00096862]
	Learning Rate: 0.000968621
	LOSS [training: 0.12253655661559043 | validation: 0.3067723537211774]
	TIME [epoch: 65.7 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11869358843200994		[learning rate: 0.00096406]
	Learning Rate: 0.000964057
	LOSS [training: 0.11869358843200994 | validation: 0.32771039991257644]
	TIME [epoch: 65.8 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11546910168961824		[learning rate: 0.00095951]
	Learning Rate: 0.000959514
	LOSS [training: 0.11546910168961824 | validation: 0.3071638099901331]
	TIME [epoch: 65.7 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10794045469041641		[learning rate: 0.00095499]
	Learning Rate: 0.000954993
	LOSS [training: 0.10794045469041641 | validation: 0.3067291599165657]
	TIME [epoch: 65.8 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10914910842339122		[learning rate: 0.00095049]
	Learning Rate: 0.000950493
	LOSS [training: 0.10914910842339122 | validation: 0.31374440164017664]
	TIME [epoch: 65.8 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11142593244690571		[learning rate: 0.00094601]
	Learning Rate: 0.000946014
	LOSS [training: 0.11142593244690571 | validation: 0.29610977886279516]
	TIME [epoch: 65.8 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09354445170606852		[learning rate: 0.00094156]
	Learning Rate: 0.000941556
	LOSS [training: 0.09354445170606852 | validation: 0.3130335094647548]
	TIME [epoch: 65.8 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10450127742816412		[learning rate: 0.00093712]
	Learning Rate: 0.000937119
	LOSS [training: 0.10450127742816412 | validation: 0.3335096311726922]
	TIME [epoch: 65.8 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1009084461295969		[learning rate: 0.0009327]
	Learning Rate: 0.000932703
	LOSS [training: 0.1009084461295969 | validation: 0.33947631419945606]
	TIME [epoch: 65.8 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1272477522404952		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.1272477522404952 | validation: 0.3078934125335083]
	TIME [epoch: 65.8 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13386627910983706		[learning rate: 0.00092393]
	Learning Rate: 0.000923934
	LOSS [training: 0.13386627910983706 | validation: 0.3386785940015478]
	TIME [epoch: 65.7 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11801597526936226		[learning rate: 0.00091958]
	Learning Rate: 0.000919581
	LOSS [training: 0.11801597526936226 | validation: 0.316140180517385]
	TIME [epoch: 65.8 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12160488937743871		[learning rate: 0.00091525]
	Learning Rate: 0.000915247
	LOSS [training: 0.12160488937743871 | validation: 0.32114817877275187]
	TIME [epoch: 65.8 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1141307261463318		[learning rate: 0.00091093]
	Learning Rate: 0.000910934
	LOSS [training: 0.1141307261463318 | validation: 0.32383305508998833]
	TIME [epoch: 65.9 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12048121594678926		[learning rate: 0.00090664]
	Learning Rate: 0.000906642
	LOSS [training: 0.12048121594678926 | validation: 0.28155206398793686]
	TIME [epoch: 65.8 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1275281474057275		[learning rate: 0.00090237]
	Learning Rate: 0.00090237
	LOSS [training: 0.1275281474057275 | validation: 0.32008929518802515]
	TIME [epoch: 65.8 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12482222873837538		[learning rate: 0.00089812]
	Learning Rate: 0.000898118
	LOSS [training: 0.12482222873837538 | validation: 0.327917205567322]
	TIME [epoch: 65.8 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12800677302907715		[learning rate: 0.00089389]
	Learning Rate: 0.000893886
	LOSS [training: 0.12800677302907715 | validation: 0.3139990493558261]
	TIME [epoch: 65.9 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12622309658833958		[learning rate: 0.00088967]
	Learning Rate: 0.000889674
	LOSS [training: 0.12622309658833958 | validation: 0.30058064368015347]
	TIME [epoch: 65.8 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13241287183797124		[learning rate: 0.00088548]
	Learning Rate: 0.000885481
	LOSS [training: 0.13241287183797124 | validation: 0.33004745095200955]
	TIME [epoch: 65.9 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11556202079999583		[learning rate: 0.00088131]
	Learning Rate: 0.000881309
	LOSS [training: 0.11556202079999583 | validation: 0.3311565761096675]
	TIME [epoch: 65.9 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10835801867054609		[learning rate: 0.00087716]
	Learning Rate: 0.000877156
	LOSS [training: 0.10835801867054609 | validation: 0.3076904296565463]
	TIME [epoch: 65.9 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1253589914537097		[learning rate: 0.00087302]
	Learning Rate: 0.000873023
	LOSS [training: 0.1253589914537097 | validation: 0.300822607990676]
	TIME [epoch: 65.8 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10928110286668455		[learning rate: 0.00086891]
	Learning Rate: 0.000868909
	LOSS [training: 0.10928110286668455 | validation: 0.31674400354880017]
	TIME [epoch: 65.9 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12076311966540912		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.12076311966540912 | validation: 0.303953643908023]
	TIME [epoch: 65.8 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14318153333215797		[learning rate: 0.00086074]
	Learning Rate: 0.00086074
	LOSS [training: 0.14318153333215797 | validation: 0.29637466427692233]
	TIME [epoch: 65.9 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1134335944198123		[learning rate: 0.00085668]
	Learning Rate: 0.000856684
	LOSS [training: 0.1134335944198123 | validation: 0.3089035398439114]
	TIME [epoch: 65.9 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11106352485379214		[learning rate: 0.00085265]
	Learning Rate: 0.000852647
	LOSS [training: 0.11106352485379214 | validation: 0.30706908975392094]
	TIME [epoch: 65.9 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1268230458888415		[learning rate: 0.00084863]
	Learning Rate: 0.000848629
	LOSS [training: 0.1268230458888415 | validation: 0.30493260751641926]
	TIME [epoch: 65.8 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1176966494644632		[learning rate: 0.00084463]
	Learning Rate: 0.00084463
	LOSS [training: 0.1176966494644632 | validation: 0.35564374109946967]
	TIME [epoch: 65.9 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11113529574090984		[learning rate: 0.00084065]
	Learning Rate: 0.00084065
	LOSS [training: 0.11113529574090984 | validation: 0.30583809345085716]
	TIME [epoch: 65.9 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1193289229253246		[learning rate: 0.00083669]
	Learning Rate: 0.000836689
	LOSS [training: 0.1193289229253246 | validation: 0.3272662991026122]
	TIME [epoch: 65.9 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10687845238232392		[learning rate: 0.00083275]
	Learning Rate: 0.000832746
	LOSS [training: 0.10687845238232392 | validation: 0.341215754261911]
	TIME [epoch: 65.8 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12581970398472567		[learning rate: 0.00082882]
	Learning Rate: 0.000828822
	LOSS [training: 0.12581970398472567 | validation: 0.3142150907120954]
	TIME [epoch: 65.8 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1201232039680402		[learning rate: 0.00082492]
	Learning Rate: 0.000824917
	LOSS [training: 0.1201232039680402 | validation: 0.31706792763870506]
	TIME [epoch: 65.9 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12398560559766295		[learning rate: 0.00082103]
	Learning Rate: 0.00082103
	LOSS [training: 0.12398560559766295 | validation: 0.29059432251034295]
	TIME [epoch: 65.9 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12707099955997975		[learning rate: 0.00081716]
	Learning Rate: 0.000817161
	LOSS [training: 0.12707099955997975 | validation: 0.3267901088871894]
	TIME [epoch: 65.9 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09976244376888573		[learning rate: 0.00081331]
	Learning Rate: 0.000813311
	LOSS [training: 0.09976244376888573 | validation: 0.29533168289620854]
	TIME [epoch: 65.8 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14843501263985182		[learning rate: 0.00080948]
	Learning Rate: 0.000809478
	LOSS [training: 0.14843501263985182 | validation: 0.29947414660893]
	TIME [epoch: 66 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1325126820389887		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.1325126820389887 | validation: 0.33808026168651095]
	TIME [epoch: 65.9 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12235015103661631		[learning rate: 0.00080187]
	Learning Rate: 0.000801868
	LOSS [training: 0.12235015103661631 | validation: 0.3113884960762656]
	TIME [epoch: 65.9 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10949610588799795		[learning rate: 0.00079809]
	Learning Rate: 0.000798089
	LOSS [training: 0.10949610588799795 | validation: 0.2879438984197635]
	TIME [epoch: 65.9 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12551252216777528		[learning rate: 0.00079433]
	Learning Rate: 0.000794328
	LOSS [training: 0.12551252216777528 | validation: 0.3150451991357729]
	TIME [epoch: 65.8 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10663832348039147		[learning rate: 0.00079059]
	Learning Rate: 0.000790585
	LOSS [training: 0.10663832348039147 | validation: 0.3138706140057086]
	TIME [epoch: 65.9 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12592562653069697		[learning rate: 0.00078686]
	Learning Rate: 0.00078686
	LOSS [training: 0.12592562653069697 | validation: 0.3220880484457137]
	TIME [epoch: 65.9 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11287309399378534		[learning rate: 0.00078315]
	Learning Rate: 0.000783152
	LOSS [training: 0.11287309399378534 | validation: 0.3088900236925005]
	TIME [epoch: 65.8 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11229503047387183		[learning rate: 0.00077946]
	Learning Rate: 0.000779462
	LOSS [training: 0.11229503047387183 | validation: 0.31949204120757263]
	TIME [epoch: 65.8 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11773008069171434		[learning rate: 0.00077579]
	Learning Rate: 0.000775789
	LOSS [training: 0.11773008069171434 | validation: 0.32190915373269785]
	TIME [epoch: 65.8 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12156133608603495		[learning rate: 0.00077213]
	Learning Rate: 0.000772133
	LOSS [training: 0.12156133608603495 | validation: 0.32557652927612374]
	TIME [epoch: 65.8 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1214806132519385		[learning rate: 0.00076849]
	Learning Rate: 0.000768495
	LOSS [training: 0.1214806132519385 | validation: 0.30235938192186673]
	TIME [epoch: 65.8 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1060670070274839		[learning rate: 0.00076487]
	Learning Rate: 0.000764874
	LOSS [training: 0.1060670070274839 | validation: 0.33255271120229335]
	TIME [epoch: 65.8 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12916469018765148		[learning rate: 0.00076127]
	Learning Rate: 0.00076127
	LOSS [training: 0.12916469018765148 | validation: 0.30084536696807046]
	TIME [epoch: 65.8 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11865290480193684		[learning rate: 0.00075768]
	Learning Rate: 0.000757682
	LOSS [training: 0.11865290480193684 | validation: 0.322840680454207]
	TIME [epoch: 65.8 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1145806773297294		[learning rate: 0.00075411]
	Learning Rate: 0.000754112
	LOSS [training: 0.1145806773297294 | validation: 0.32924893358549695]
	TIME [epoch: 65.8 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1271835743935187		[learning rate: 0.00075056]
	Learning Rate: 0.000750559
	LOSS [training: 0.1271835743935187 | validation: 0.3183260849907926]
	TIME [epoch: 65.7 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11554638140106249		[learning rate: 0.00074702]
	Learning Rate: 0.000747022
	LOSS [training: 0.11554638140106249 | validation: 0.3213916191470375]
	TIME [epoch: 65.8 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11845047305995635		[learning rate: 0.0007435]
	Learning Rate: 0.000743502
	LOSS [training: 0.11845047305995635 | validation: 0.3022002801037412]
	TIME [epoch: 65.7 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10172855594323052		[learning rate: 0.00074]
	Learning Rate: 0.000739998
	LOSS [training: 0.10172855594323052 | validation: 0.3255001844090335]
	TIME [epoch: 65.8 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10344426911417912		[learning rate: 0.00073651]
	Learning Rate: 0.000736511
	LOSS [training: 0.10344426911417912 | validation: 0.3241901482940695]
	TIME [epoch: 65.8 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10940102703668764		[learning rate: 0.00073304]
	Learning Rate: 0.000733041
	LOSS [training: 0.10940102703668764 | validation: 0.31157720569795]
	TIME [epoch: 65.8 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1048503201127572		[learning rate: 0.00072959]
	Learning Rate: 0.000729587
	LOSS [training: 0.1048503201127572 | validation: 0.3087395305673251]
	TIME [epoch: 65.8 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11580129932160202		[learning rate: 0.00072615]
	Learning Rate: 0.000726149
	LOSS [training: 0.11580129932160202 | validation: 0.3218332350208132]
	TIME [epoch: 65.7 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11500811181221082		[learning rate: 0.00072273]
	Learning Rate: 0.000722727
	LOSS [training: 0.11500811181221082 | validation: 0.30010390095370887]
	TIME [epoch: 65.8 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11446714418727617		[learning rate: 0.00071932]
	Learning Rate: 0.000719321
	LOSS [training: 0.11446714418727617 | validation: 0.3217883867894686]
	TIME [epoch: 65.8 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1252772548585948		[learning rate: 0.00071593]
	Learning Rate: 0.000715932
	LOSS [training: 0.1252772548585948 | validation: 0.30823655937402344]
	TIME [epoch: 65.8 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12652186737241958		[learning rate: 0.00071256]
	Learning Rate: 0.000712558
	LOSS [training: 0.12652186737241958 | validation: 0.31558754387761123]
	TIME [epoch: 65.9 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1013104651835957		[learning rate: 0.0007092]
	Learning Rate: 0.000709201
	LOSS [training: 0.1013104651835957 | validation: 0.30052935514065765]
	TIME [epoch: 65.8 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12820761741053294		[learning rate: 0.00070586]
	Learning Rate: 0.000705859
	LOSS [training: 0.12820761741053294 | validation: 0.3091840741991685]
	TIME [epoch: 65.8 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11129620005171312		[learning rate: 0.00070253]
	Learning Rate: 0.000702533
	LOSS [training: 0.11129620005171312 | validation: 0.2983162600667798]
	TIME [epoch: 65.7 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1254913038200603		[learning rate: 0.00069922]
	Learning Rate: 0.000699222
	LOSS [training: 0.1254913038200603 | validation: 0.29811938312629443]
	TIME [epoch: 65.8 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11339402886937336		[learning rate: 0.00069593]
	Learning Rate: 0.000695928
	LOSS [training: 0.11339402886937336 | validation: 0.310921739461266]
	TIME [epoch: 65.8 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10841886143212914		[learning rate: 0.00069265]
	Learning Rate: 0.000692648
	LOSS [training: 0.10841886143212914 | validation: 0.3153480135598367]
	TIME [epoch: 65.7 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10722116806805294		[learning rate: 0.00068938]
	Learning Rate: 0.000689385
	LOSS [training: 0.10722116806805294 | validation: 0.3053329790594227]
	TIME [epoch: 65.8 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1076510678463639		[learning rate: 0.00068614]
	Learning Rate: 0.000686136
	LOSS [training: 0.1076510678463639 | validation: 0.32094780445448906]
	TIME [epoch: 65.9 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10787448128368854		[learning rate: 0.0006829]
	Learning Rate: 0.000682903
	LOSS [training: 0.10787448128368854 | validation: 0.3073051572883899]
	TIME [epoch: 65.9 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11676254487704582		[learning rate: 0.00067969]
	Learning Rate: 0.000679685
	LOSS [training: 0.11676254487704582 | validation: 0.29250397454142146]
	TIME [epoch: 65.8 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1045315285336769		[learning rate: 0.00067648]
	Learning Rate: 0.000676482
	LOSS [training: 0.1045315285336769 | validation: 0.3403654419928148]
	TIME [epoch: 65.8 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0995244430697433		[learning rate: 0.00067329]
	Learning Rate: 0.000673295
	LOSS [training: 0.0995244430697433 | validation: 0.3210082168265479]
	TIME [epoch: 65.7 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12805744685050924		[learning rate: 0.00067012]
	Learning Rate: 0.000670122
	LOSS [training: 0.12805744685050924 | validation: 0.3107863445433652]
	TIME [epoch: 65.8 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10907157124476309		[learning rate: 0.00066696]
	Learning Rate: 0.000666964
	LOSS [training: 0.10907157124476309 | validation: 0.3041484570566457]
	TIME [epoch: 65.8 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10390914798261672		[learning rate: 0.00066382]
	Learning Rate: 0.000663821
	LOSS [training: 0.10390914798261672 | validation: 0.30469278319816334]
	TIME [epoch: 65.7 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12427811724015714		[learning rate: 0.00066069]
	Learning Rate: 0.000660694
	LOSS [training: 0.12427811724015714 | validation: 0.31865299618833237]
	TIME [epoch: 65.8 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1027428344155055		[learning rate: 0.00065758]
	Learning Rate: 0.00065758
	LOSS [training: 0.1027428344155055 | validation: 0.30373721259572445]
	TIME [epoch: 65.7 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10548642182898305		[learning rate: 0.00065448]
	Learning Rate: 0.000654482
	LOSS [training: 0.10548642182898305 | validation: 0.32760963452610764]
	TIME [epoch: 65.8 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09904800374345403		[learning rate: 0.0006514]
	Learning Rate: 0.000651398
	LOSS [training: 0.09904800374345403 | validation: 0.3306196952971968]
	TIME [epoch: 65.8 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1110455087028683		[learning rate: 0.00064833]
	Learning Rate: 0.000648328
	LOSS [training: 0.1110455087028683 | validation: 0.31305833372954106]
	TIME [epoch: 65.8 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10665687544036892		[learning rate: 0.00064527]
	Learning Rate: 0.000645273
	LOSS [training: 0.10665687544036892 | validation: 0.3162082950996776]
	TIME [epoch: 65.7 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10973304912313103		[learning rate: 0.00064223]
	Learning Rate: 0.000642232
	LOSS [training: 0.10973304912313103 | validation: 0.3007729447706769]
	TIME [epoch: 65.6 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10789856314079845		[learning rate: 0.00063921]
	Learning Rate: 0.000639206
	LOSS [training: 0.10789856314079845 | validation: 0.325628414150334]
	TIME [epoch: 65.8 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09995895246479937		[learning rate: 0.00063619]
	Learning Rate: 0.000636194
	LOSS [training: 0.09995895246479937 | validation: 0.2986314682679001]
	TIME [epoch: 65.9 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11093967724546366		[learning rate: 0.0006332]
	Learning Rate: 0.000633196
	LOSS [training: 0.11093967724546366 | validation: 0.31657316923240914]
	TIME [epoch: 65.8 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1057039277888482		[learning rate: 0.00063021]
	Learning Rate: 0.000630213
	LOSS [training: 0.1057039277888482 | validation: 0.29846051194098383]
	TIME [epoch: 65.7 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11488155243777744		[learning rate: 0.00062724]
	Learning Rate: 0.000627243
	LOSS [training: 0.11488155243777744 | validation: 0.31001716990526884]
	TIME [epoch: 65.8 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11065258550422605		[learning rate: 0.00062429]
	Learning Rate: 0.000624287
	LOSS [training: 0.11065258550422605 | validation: 0.3202465299660543]
	TIME [epoch: 65.8 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10796880522964072		[learning rate: 0.00062135]
	Learning Rate: 0.000621346
	LOSS [training: 0.10796880522964072 | validation: 0.3112236540837255]
	TIME [epoch: 65.9 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12025842283650469		[learning rate: 0.00061842]
	Learning Rate: 0.000618418
	LOSS [training: 0.12025842283650469 | validation: 0.30395310925242175]
	TIME [epoch: 65.8 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12780354111630154		[learning rate: 0.0006155]
	Learning Rate: 0.000615504
	LOSS [training: 0.12780354111630154 | validation: 0.3162075099505139]
	TIME [epoch: 65.9 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15393211310081284		[learning rate: 0.0006126]
	Learning Rate: 0.000612604
	LOSS [training: 0.15393211310081284 | validation: 0.33179399900091666]
	TIME [epoch: 65.8 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1255637678150768		[learning rate: 0.00060972]
	Learning Rate: 0.000609717
	LOSS [training: 0.1255637678150768 | validation: 0.3012988228696441]
	TIME [epoch: 65.9 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1180284726935798		[learning rate: 0.00060684]
	Learning Rate: 0.000606844
	LOSS [training: 0.1180284726935798 | validation: 0.3062607213564825]
	TIME [epoch: 65.8 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12534245402798583		[learning rate: 0.00060398]
	Learning Rate: 0.000603984
	LOSS [training: 0.12534245402798583 | validation: 0.31927378647241283]
	TIME [epoch: 65.8 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12102810119715993		[learning rate: 0.00060114]
	Learning Rate: 0.000601138
	LOSS [training: 0.12102810119715993 | validation: 0.29650975537731916]
	TIME [epoch: 65.8 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1025082863927154		[learning rate: 0.00059831]
	Learning Rate: 0.000598306
	LOSS [training: 0.1025082863927154 | validation: 0.31474276107284505]
	TIME [epoch: 65.8 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1145520281147949		[learning rate: 0.00059549]
	Learning Rate: 0.000595486
	LOSS [training: 0.1145520281147949 | validation: 0.3026692094313904]
	TIME [epoch: 65.9 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12002802337774093		[learning rate: 0.00059268]
	Learning Rate: 0.00059268
	LOSS [training: 0.12002802337774093 | validation: 0.30901816244843483]
	TIME [epoch: 65.7 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11783150187803394		[learning rate: 0.00058989]
	Learning Rate: 0.000589888
	LOSS [training: 0.11783150187803394 | validation: 0.309926482976941]
	TIME [epoch: 65.8 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1173256161079651		[learning rate: 0.00058711]
	Learning Rate: 0.000587108
	LOSS [training: 0.1173256161079651 | validation: 0.3106669640502076]
	TIME [epoch: 65.8 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11333310073018005		[learning rate: 0.00058434]
	Learning Rate: 0.000584341
	LOSS [training: 0.11333310073018005 | validation: 0.323825263796869]
	TIME [epoch: 65.7 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11789977251354725		[learning rate: 0.00058159]
	Learning Rate: 0.000581588
	LOSS [training: 0.11789977251354725 | validation: 0.2901338370045514]
	TIME [epoch: 65.7 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1220721379121931		[learning rate: 0.00057885]
	Learning Rate: 0.000578847
	LOSS [training: 0.1220721379121931 | validation: 0.2988337269709991]
	TIME [epoch: 65.9 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11302019164606855		[learning rate: 0.00057612]
	Learning Rate: 0.00057612
	LOSS [training: 0.11302019164606855 | validation: 0.3180745884811177]
	TIME [epoch: 65.6 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10240464610679366		[learning rate: 0.00057341]
	Learning Rate: 0.000573405
	LOSS [training: 0.10240464610679366 | validation: 0.32282273453093585]
	TIME [epoch: 65.6 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10682650219972237		[learning rate: 0.0005707]
	Learning Rate: 0.000570703
	LOSS [training: 0.10682650219972237 | validation: 0.32734317361203563]
	TIME [epoch: 65.7 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10305471361026924		[learning rate: 0.00056801]
	Learning Rate: 0.000568014
	LOSS [training: 0.10305471361026924 | validation: 0.30145932854641766]
	TIME [epoch: 65.7 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1088552677511781		[learning rate: 0.00056534]
	Learning Rate: 0.000565337
	LOSS [training: 0.1088552677511781 | validation: 0.2907905287034196]
	TIME [epoch: 65.7 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11338444319236535		[learning rate: 0.00056267]
	Learning Rate: 0.000562673
	LOSS [training: 0.11338444319236535 | validation: 0.2902714414615998]
	TIME [epoch: 65.8 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12345802564673695		[learning rate: 0.00056002]
	Learning Rate: 0.000560022
	LOSS [training: 0.12345802564673695 | validation: 0.32811118646122317]
	TIME [epoch: 65.7 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13694802559633173		[learning rate: 0.00055738]
	Learning Rate: 0.000557383
	LOSS [training: 0.13694802559633173 | validation: 0.3122500626620202]
	TIME [epoch: 65.8 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10549420337124274		[learning rate: 0.00055476]
	Learning Rate: 0.000554757
	LOSS [training: 0.10549420337124274 | validation: 0.3283337364371911]
	TIME [epoch: 65.8 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13256575987790284		[learning rate: 0.00055214]
	Learning Rate: 0.000552143
	LOSS [training: 0.13256575987790284 | validation: 0.32238808785102996]
	TIME [epoch: 65.8 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11967026979414626		[learning rate: 0.00054954]
	Learning Rate: 0.000549541
	LOSS [training: 0.11967026979414626 | validation: 0.3031845575745492]
	TIME [epoch: 65.8 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10669961333777805		[learning rate: 0.00054695]
	Learning Rate: 0.000546951
	LOSS [training: 0.10669961333777805 | validation: 0.3429027574282055]
	TIME [epoch: 65.9 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11241417590288602		[learning rate: 0.00054437]
	Learning Rate: 0.000544374
	LOSS [training: 0.11241417590288602 | validation: 0.31060168430336393]
	TIME [epoch: 65.9 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10655807104825728		[learning rate: 0.00054181]
	Learning Rate: 0.000541809
	LOSS [training: 0.10655807104825728 | validation: 0.3235047399359007]
	TIME [epoch: 65.8 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12977944400416785		[learning rate: 0.00053926]
	Learning Rate: 0.000539256
	LOSS [training: 0.12977944400416785 | validation: 0.3203741741652689]
	TIME [epoch: 65.8 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1341629034819733		[learning rate: 0.00053671]
	Learning Rate: 0.000536715
	LOSS [training: 0.1341629034819733 | validation: 0.31409072047807396]
	TIME [epoch: 65.8 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11760240812090683		[learning rate: 0.00053419]
	Learning Rate: 0.000534186
	LOSS [training: 0.11760240812090683 | validation: 0.31107846724236354]
	TIME [epoch: 65.8 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10482890567173711		[learning rate: 0.00053167]
	Learning Rate: 0.000531669
	LOSS [training: 0.10482890567173711 | validation: 0.30102158556287617]
	TIME [epoch: 65.8 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10900872318731164		[learning rate: 0.00052916]
	Learning Rate: 0.000529163
	LOSS [training: 0.10900872318731164 | validation: 0.31926673030570446]
	TIME [epoch: 65.6 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11461185732550803		[learning rate: 0.00052667]
	Learning Rate: 0.00052667
	LOSS [training: 0.11461185732550803 | validation: 0.2926638250205248]
	TIME [epoch: 65.9 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11607338617401528		[learning rate: 0.00052419]
	Learning Rate: 0.000524188
	LOSS [training: 0.11607338617401528 | validation: 0.3100754133981019]
	TIME [epoch: 65.6 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1052178929898627		[learning rate: 0.00052172]
	Learning Rate: 0.000521718
	LOSS [training: 0.1052178929898627 | validation: 0.32603712584109434]
	TIME [epoch: 65.7 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13811267676168767		[learning rate: 0.00051926]
	Learning Rate: 0.00051926
	LOSS [training: 0.13811267676168767 | validation: 0.3462455776398194]
	TIME [epoch: 65.7 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09016717933284374		[learning rate: 0.00051681]
	Learning Rate: 0.000516813
	LOSS [training: 0.09016717933284374 | validation: 0.3149715926249677]
	TIME [epoch: 65.7 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12591084698692237		[learning rate: 0.00051438]
	Learning Rate: 0.000514378
	LOSS [training: 0.12591084698692237 | validation: 0.33192082137532997]
	TIME [epoch: 65.8 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11372027829169226		[learning rate: 0.00051195]
	Learning Rate: 0.000511954
	LOSS [training: 0.11372027829169226 | validation: 0.30116605406998953]
	TIME [epoch: 65.8 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10488749627892698		[learning rate: 0.00050954]
	Learning Rate: 0.000509541
	LOSS [training: 0.10488749627892698 | validation: 0.3051649799618213]
	TIME [epoch: 65.8 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10892114084992652		[learning rate: 0.00050714]
	Learning Rate: 0.00050714
	LOSS [training: 0.10892114084992652 | validation: 0.3061194304667607]
	TIME [epoch: 65.9 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11250267418590623		[learning rate: 0.00050475]
	Learning Rate: 0.000504751
	LOSS [training: 0.11250267418590623 | validation: 0.3302903101454326]
	TIME [epoch: 65.8 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1244266813388153		[learning rate: 0.00050237]
	Learning Rate: 0.000502372
	LOSS [training: 0.1244266813388153 | validation: 0.3085133368895669]
	TIME [epoch: 65.9 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11077235595976867		[learning rate: 0.00050001]
	Learning Rate: 0.000500005
	LOSS [training: 0.11077235595976867 | validation: 0.30311561236895446]
	TIME [epoch: 65.8 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11690483444223618		[learning rate: 0.00049765]
	Learning Rate: 0.000497649
	LOSS [training: 0.11690483444223618 | validation: 0.31090753899805706]
	TIME [epoch: 65.9 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12558071863589465		[learning rate: 0.0004953]
	Learning Rate: 0.000495304
	LOSS [training: 0.12558071863589465 | validation: 0.30788056361595717]
	TIME [epoch: 65.9 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12281905234906985		[learning rate: 0.00049297]
	Learning Rate: 0.00049297
	LOSS [training: 0.12281905234906985 | validation: 0.31480431099202383]
	TIME [epoch: 65.9 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13134528902842119		[learning rate: 0.00049065]
	Learning Rate: 0.000490647
	LOSS [training: 0.13134528902842119 | validation: 0.30634322535221853]
	TIME [epoch: 65.7 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10496880004001893		[learning rate: 0.00048834]
	Learning Rate: 0.000488335
	LOSS [training: 0.10496880004001893 | validation: 0.3017523810412259]
	TIME [epoch: 65.7 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1252940610259354		[learning rate: 0.00048603]
	Learning Rate: 0.000486034
	LOSS [training: 0.1252940610259354 | validation: 0.3213289668140896]
	TIME [epoch: 65.7 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10766751646425954		[learning rate: 0.00048374]
	Learning Rate: 0.000483744
	LOSS [training: 0.10766751646425954 | validation: 0.3206138772157081]
	TIME [epoch: 65.7 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1195170396899458		[learning rate: 0.00048146]
	Learning Rate: 0.000481464
	LOSS [training: 0.1195170396899458 | validation: 0.3036004984885815]
	TIME [epoch: 65.7 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10480316725168588		[learning rate: 0.0004792]
	Learning Rate: 0.000479196
	LOSS [training: 0.10480316725168588 | validation: 0.3363426357782256]
	TIME [epoch: 65.8 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12892370008978155		[learning rate: 0.00047694]
	Learning Rate: 0.000476938
	LOSS [training: 0.12892370008978155 | validation: 0.2981876157072248]
	TIME [epoch: 65.7 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10620944171376173		[learning rate: 0.00047469]
	Learning Rate: 0.00047469
	LOSS [training: 0.10620944171376173 | validation: 0.3124845219113588]
	TIME [epoch: 65.7 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10278346050390366		[learning rate: 0.00047245]
	Learning Rate: 0.000472453
	LOSS [training: 0.10278346050390366 | validation: 0.31252001468269197]
	TIME [epoch: 65.6 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13149856564198495		[learning rate: 0.00047023]
	Learning Rate: 0.000470227
	LOSS [training: 0.13149856564198495 | validation: 0.3163712104846543]
	TIME [epoch: 65.6 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12001395073444418		[learning rate: 0.00046801]
	Learning Rate: 0.000468011
	LOSS [training: 0.12001395073444418 | validation: 0.33546364251673333]
	TIME [epoch: 65.6 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12849384527321533		[learning rate: 0.00046581]
	Learning Rate: 0.000465806
	LOSS [training: 0.12849384527321533 | validation: 0.30529144069305025]
	TIME [epoch: 65.7 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12842339475813322		[learning rate: 0.00046361]
	Learning Rate: 0.000463611
	LOSS [training: 0.12842339475813322 | validation: 0.3188927411080229]
	TIME [epoch: 65.6 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12592688952897524		[learning rate: 0.00046143]
	Learning Rate: 0.000461426
	LOSS [training: 0.12592688952897524 | validation: 0.30411743247626705]
	TIME [epoch: 65.7 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10292550333685732		[learning rate: 0.00045925]
	Learning Rate: 0.000459252
	LOSS [training: 0.10292550333685732 | validation: 0.3070463742465491]
	TIME [epoch: 65.8 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11460972910448575		[learning rate: 0.00045709]
	Learning Rate: 0.000457088
	LOSS [training: 0.11460972910448575 | validation: 0.2982818939350913]
	TIME [epoch: 65.8 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11270392349788112		[learning rate: 0.00045493]
	Learning Rate: 0.000454934
	LOSS [training: 0.11270392349788112 | validation: 0.2980702621869136]
	TIME [epoch: 65.8 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10641157847984631		[learning rate: 0.00045279]
	Learning Rate: 0.000452791
	LOSS [training: 0.10641157847984631 | validation: 0.3237299991472111]
	TIME [epoch: 65.9 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10233720440369574		[learning rate: 0.00045066]
	Learning Rate: 0.000450657
	LOSS [training: 0.10233720440369574 | validation: 0.32931054030862217]
	TIME [epoch: 65.8 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12995712865885867		[learning rate: 0.00044853]
	Learning Rate: 0.000448533
	LOSS [training: 0.12995712865885867 | validation: 0.310370760113398]
	TIME [epoch: 65.8 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11429517662017744		[learning rate: 0.00044642]
	Learning Rate: 0.00044642
	LOSS [training: 0.11429517662017744 | validation: 0.2965832721262142]
	TIME [epoch: 65.9 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11038838535770479		[learning rate: 0.00044432]
	Learning Rate: 0.000444316
	LOSS [training: 0.11038838535770479 | validation: 0.30596472732882046]
	TIME [epoch: 65.8 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240719_004901/states/model_facs_v4_dec2b_2dpca_v15b_697.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 31478.934 seconds.
