Args:
Namespace(name='model_facs_v3_dec1b_2dpca_v7', outdir='out/model_training/model_facs_v3_dec1b_2dpca_v7', training_data='data/training_data/facs_v3/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs_v3/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=200, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[500, 1000, 1500], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.02, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3969829584

Training model...

Saving initial model state to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.5120955428794247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5120955428794247 | validation: 1.2632716159476556]
	TIME [epoch: 27.3 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.3627001813559716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3627001813559716 | validation: 1.1965789298454703]
	TIME [epoch: 5.82 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.2977501230106967		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2977501230106967 | validation: 1.1714232409179055]
	TIME [epoch: 5.82 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.2414736759225402		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2414736759225402 | validation: 1.1572958255407149]
	TIME [epoch: 5.83 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.2102633793227089		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2102633793227089 | validation: 1.1085258918564604]
	TIME [epoch: 5.84 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.189085328727476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.189085328727476 | validation: 1.1032994842091848]
	TIME [epoch: 5.83 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.156310161274818		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.156310161274818 | validation: 1.0440798304775605]
	TIME [epoch: 5.82 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.0971987309825086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0971987309825086 | validation: 0.9821325798126364]
	TIME [epoch: 5.81 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.0776469596619382		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0776469596619382 | validation: 1.0203525559977469]
	TIME [epoch: 5.83 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.0023740746196186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0023740746196186 | validation: 0.9597327072192552]
	TIME [epoch: 5.83 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.0077836519012708		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0077836519012708 | validation: 1.088792972138887]
	TIME [epoch: 5.82 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.973159790952468		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.973159790952468 | validation: 0.8945529181449366]
	TIME [epoch: 5.81 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.917252792672611		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.917252792672611 | validation: 1.0376936990843721]
	TIME [epoch: 5.83 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9341508707530245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9341508707530245 | validation: 0.8915831847135003]
	TIME [epoch: 5.82 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9320953628445744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9320953628445744 | validation: 0.9745917726403593]
	TIME [epoch: 5.82 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.88490348368813		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.88490348368813 | validation: 0.8191323131762311]
	TIME [epoch: 5.83 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7828817186708853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7828817186708853 | validation: 0.8133972546025172]
	TIME [epoch: 5.82 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9909591079664332		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9909591079664332 | validation: 0.7730414850333283]
	TIME [epoch: 5.82 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7939272397121422		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7939272397121422 | validation: 0.7054618665188501]
	TIME [epoch: 5.82 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8145786225770926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8145786225770926 | validation: 0.7092479553282696]
	TIME [epoch: 5.81 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6863085605301119		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6863085605301119 | validation: 0.6112524301733092]
	TIME [epoch: 5.81 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6529039544434806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6529039544434806 | validation: 0.5827999636512677]
	TIME [epoch: 5.81 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7589824334367515		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7589824334367515 | validation: 0.5844106255820564]
	TIME [epoch: 5.85 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.801792602648084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.801792602648084 | validation: 0.5728066348233134]
	TIME [epoch: 5.84 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6440769899366555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6440769899366555 | validation: 0.6310624186437255]
	TIME [epoch: 5.81 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6154782975611995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6154782975611995 | validation: 0.5415429719277719]
	TIME [epoch: 5.81 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.647412894056758		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.647412894056758 | validation: 0.6652372167273619]
	TIME [epoch: 5.82 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6270398328222891		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6270398328222891 | validation: 0.5617779838613234]
	TIME [epoch: 5.82 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5748238955333645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5748238955333645 | validation: 0.5691815040968355]
	TIME [epoch: 5.82 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6034998305702045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6034998305702045 | validation: 0.5278405834953632]
	TIME [epoch: 5.83 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5786920821572367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5786920821572367 | validation: 0.515750156737779]
	TIME [epoch: 5.83 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6671668713069715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6671668713069715 | validation: 0.534389042749838]
	TIME [epoch: 5.82 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5636142919218589		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5636142919218589 | validation: 0.5072163896739947]
	TIME [epoch: 5.81 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6066318812957952		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6066318812957952 | validation: 0.6038848317731492]
	TIME [epoch: 5.8 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6149342955695257		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6149342955695257 | validation: 0.5190045146236646]
	TIME [epoch: 5.81 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5403951328937668		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5403951328937668 | validation: 0.5530442539474193]
	TIME [epoch: 5.81 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5467230253409768		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5467230253409768 | validation: 0.5168559943298272]
	TIME [epoch: 5.81 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.512794323809021		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.512794323809021 | validation: 0.5717782459566059]
	TIME [epoch: 5.81 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.617595803275445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.617595803275445 | validation: 0.5015101536666198]
	TIME [epoch: 5.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6176243798549036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6176243798549036 | validation: 0.5657705379326308]
	TIME [epoch: 5.82 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5743436081704448		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5743436081704448 | validation: 0.5005862478157106]
	TIME [epoch: 5.81 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5535019670653609		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5535019670653609 | validation: 0.5234858975390833]
	TIME [epoch: 5.84 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5344433735742312		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5344433735742312 | validation: 0.48001419427066194]
	TIME [epoch: 5.83 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.529127995453251		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.529127995453251 | validation: 0.48349186020191565]
	TIME [epoch: 5.82 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.49444800680762446		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49444800680762446 | validation: 0.4408848117984136]
	TIME [epoch: 5.82 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5165705784540143		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5165705784540143 | validation: 0.5614186270680774]
	TIME [epoch: 5.81 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5190583163609005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5190583163609005 | validation: 0.45864728462984816]
	TIME [epoch: 5.82 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5132494030187313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5132494030187313 | validation: 0.6896795933538029]
	TIME [epoch: 5.81 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6412846331626146		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6412846331626146 | validation: 0.4665664270824953]
	TIME [epoch: 5.82 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5332128657864547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5332128657864547 | validation: 0.5124830044092293]
	TIME [epoch: 5.82 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.47964152301372637		[learning rate: 0.0099705]
	Learning Rate: 0.00997052
	LOSS [training: 0.47964152301372637 | validation: 0.5268996616090147]
	TIME [epoch: 5.81 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5147883248175442		[learning rate: 0.0099353]
	Learning Rate: 0.00993527
	LOSS [training: 0.5147883248175442 | validation: 0.45456516339653685]
	TIME [epoch: 5.83 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5443840514864129		[learning rate: 0.0099001]
	Learning Rate: 0.00990013
	LOSS [training: 0.5443840514864129 | validation: 0.4984425044294795]
	TIME [epoch: 5.81 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.49334971813668904		[learning rate: 0.0098651]
	Learning Rate: 0.00986512
	LOSS [training: 0.49334971813668904 | validation: 0.5749002300624552]
	TIME [epoch: 5.82 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7507101469013412		[learning rate: 0.0098302]
	Learning Rate: 0.00983024
	LOSS [training: 0.7507101469013412 | validation: 0.7797467941014871]
	TIME [epoch: 5.81 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7079130075276193		[learning rate: 0.0097955]
	Learning Rate: 0.00979548
	LOSS [training: 0.7079130075276193 | validation: 0.48932779381569985]
	TIME [epoch: 5.81 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.49409586953476836		[learning rate: 0.0097608]
	Learning Rate: 0.00976084
	LOSS [training: 0.49409586953476836 | validation: 0.5091106697077418]
	TIME [epoch: 5.81 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4987357961474655		[learning rate: 0.0097263]
	Learning Rate: 0.00972632
	LOSS [training: 0.4987357961474655 | validation: 0.4634517753454309]
	TIME [epoch: 5.82 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.46601517667856834		[learning rate: 0.0096919]
	Learning Rate: 0.00969193
	LOSS [training: 0.46601517667856834 | validation: 0.43911432283386576]
	TIME [epoch: 5.81 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5146576753697881		[learning rate: 0.0096577]
	Learning Rate: 0.00965766
	LOSS [training: 0.5146576753697881 | validation: 0.44065184809795677]
	TIME [epoch: 5.8 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4671168330361386		[learning rate: 0.0096235]
	Learning Rate: 0.00962351
	LOSS [training: 0.4671168330361386 | validation: 0.4368440679853823]
	TIME [epoch: 5.81 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4936030477243017		[learning rate: 0.0095895]
	Learning Rate: 0.00958948
	LOSS [training: 0.4936030477243017 | validation: 0.46854225173864855]
	TIME [epoch: 5.81 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.48627446699885274		[learning rate: 0.0095556]
	Learning Rate: 0.00955557
	LOSS [training: 0.48627446699885274 | validation: 0.4535684052952441]
	TIME [epoch: 5.8 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5937764448010191		[learning rate: 0.0095218]
	Learning Rate: 0.00952177
	LOSS [training: 0.5937764448010191 | validation: 0.46564384530508035]
	TIME [epoch: 5.81 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5169794169745688		[learning rate: 0.0094881]
	Learning Rate: 0.0094881
	LOSS [training: 0.5169794169745688 | validation: 0.4440274319403425]
	TIME [epoch: 5.8 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.47308150532877086		[learning rate: 0.0094546]
	Learning Rate: 0.00945455
	LOSS [training: 0.47308150532877086 | validation: 0.5211418093461206]
	TIME [epoch: 5.81 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4853175975126163		[learning rate: 0.0094211]
	Learning Rate: 0.00942112
	LOSS [training: 0.4853175975126163 | validation: 0.45717071490616706]
	TIME [epoch: 5.79 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.46275060299408605		[learning rate: 0.0093878]
	Learning Rate: 0.00938781
	LOSS [training: 0.46275060299408605 | validation: 0.4565193972033684]
	TIME [epoch: 5.82 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.46953167278413677		[learning rate: 0.0093546]
	Learning Rate: 0.00935461
	LOSS [training: 0.46953167278413677 | validation: 0.47348381211170754]
	TIME [epoch: 5.81 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5434192199981259		[learning rate: 0.0093215]
	Learning Rate: 0.00932153
	LOSS [training: 0.5434192199981259 | validation: 0.46732122051263625]
	TIME [epoch: 5.81 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.46964475285074614		[learning rate: 0.0092886]
	Learning Rate: 0.00928857
	LOSS [training: 0.46964475285074614 | validation: 0.5100484016937065]
	TIME [epoch: 5.81 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4743625161330583		[learning rate: 0.0092557]
	Learning Rate: 0.00925572
	LOSS [training: 0.4743625161330583 | validation: 0.44337987188823674]
	TIME [epoch: 5.81 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4589274019687175		[learning rate: 0.009223]
	Learning Rate: 0.00922299
	LOSS [training: 0.4589274019687175 | validation: 0.5102348720197514]
	TIME [epoch: 5.82 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.46655164503415986		[learning rate: 0.0091904]
	Learning Rate: 0.00919038
	LOSS [training: 0.46655164503415986 | validation: 0.4540346793560933]
	TIME [epoch: 5.82 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4815672734913338		[learning rate: 0.0091579]
	Learning Rate: 0.00915788
	LOSS [training: 0.4815672734913338 | validation: 0.4317489965186144]
	TIME [epoch: 5.82 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.463019505508038		[learning rate: 0.0091255]
	Learning Rate: 0.00912549
	LOSS [training: 0.463019505508038 | validation: 0.4307245114148201]
	TIME [epoch: 5.81 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4246546239395185		[learning rate: 0.0090932]
	Learning Rate: 0.00909323
	LOSS [training: 0.4246546239395185 | validation: 0.39878529217648784]
	TIME [epoch: 5.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.47818105391284565		[learning rate: 0.0090611]
	Learning Rate: 0.00906107
	LOSS [training: 0.47818105391284565 | validation: 0.5727384310066335]
	TIME [epoch: 5.82 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4647609891387461		[learning rate: 0.009029]
	Learning Rate: 0.00902903
	LOSS [training: 0.4647609891387461 | validation: 0.4737475884682292]
	TIME [epoch: 5.8 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4454025159071479		[learning rate: 0.0089971]
	Learning Rate: 0.0089971
	LOSS [training: 0.4454025159071479 | validation: 0.43190630764901394]
	TIME [epoch: 5.8 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.46057790966265144		[learning rate: 0.0089653]
	Learning Rate: 0.00896528
	LOSS [training: 0.46057790966265144 | validation: 0.4362960688169542]
	TIME [epoch: 5.8 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4373709619278722		[learning rate: 0.0089336]
	Learning Rate: 0.00893358
	LOSS [training: 0.4373709619278722 | validation: 0.43082490761047787]
	TIME [epoch: 5.8 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.44540873476136866		[learning rate: 0.008902]
	Learning Rate: 0.00890199
	LOSS [training: 0.44540873476136866 | validation: 0.5596658395327093]
	TIME [epoch: 5.82 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4579078818588844		[learning rate: 0.0088705]
	Learning Rate: 0.00887051
	LOSS [training: 0.4579078818588844 | validation: 0.39508393328203273]
	TIME [epoch: 5.81 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.43837002015108634		[learning rate: 0.0088391]
	Learning Rate: 0.00883914
	LOSS [training: 0.43837002015108634 | validation: 0.3947459390182075]
	TIME [epoch: 5.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5086898449843035		[learning rate: 0.0088079]
	Learning Rate: 0.00880789
	LOSS [training: 0.5086898449843035 | validation: 0.45725837055641316]
	TIME [epoch: 5.81 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.436610953348089		[learning rate: 0.0087767]
	Learning Rate: 0.00877674
	LOSS [training: 0.436610953348089 | validation: 0.45668331359034847]
	TIME [epoch: 5.81 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.42994578347075807		[learning rate: 0.0087457]
	Learning Rate: 0.00874571
	LOSS [training: 0.42994578347075807 | validation: 0.4295457211158628]
	TIME [epoch: 5.82 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4413398288050994		[learning rate: 0.0087148]
	Learning Rate: 0.00871478
	LOSS [training: 0.4413398288050994 | validation: 0.4184700723956702]
	TIME [epoch: 5.81 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.42852676137392115		[learning rate: 0.008684]
	Learning Rate: 0.00868396
	LOSS [training: 0.42852676137392115 | validation: 0.44108178595048175]
	TIME [epoch: 5.82 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4359997563683444		[learning rate: 0.0086533]
	Learning Rate: 0.00865326
	LOSS [training: 0.4359997563683444 | validation: 0.4296699369477913]
	TIME [epoch: 5.81 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.44046947694271693		[learning rate: 0.0086227]
	Learning Rate: 0.00862265
	LOSS [training: 0.44046947694271693 | validation: 0.44769127604176884]
	TIME [epoch: 5.82 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5058361749870989		[learning rate: 0.0085922]
	Learning Rate: 0.00859216
	LOSS [training: 0.5058361749870989 | validation: 0.4104459194717158]
	TIME [epoch: 5.83 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3946475602844017		[learning rate: 0.0085618]
	Learning Rate: 0.00856178
	LOSS [training: 0.3946475602844017 | validation: 0.39999985905121865]
	TIME [epoch: 5.82 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5077043306892953		[learning rate: 0.0085315]
	Learning Rate: 0.0085315
	LOSS [training: 0.5077043306892953 | validation: 0.47758791684033436]
	TIME [epoch: 5.82 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5007700545707304		[learning rate: 0.0085013]
	Learning Rate: 0.00850134
	LOSS [training: 0.5007700545707304 | validation: 0.4378688087346768]
	TIME [epoch: 5.82 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.43237185804547323		[learning rate: 0.0084713]
	Learning Rate: 0.00847127
	LOSS [training: 0.43237185804547323 | validation: 0.3926423168258536]
	TIME [epoch: 5.81 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4128274432572212		[learning rate: 0.0084413]
	Learning Rate: 0.00844132
	LOSS [training: 0.4128274432572212 | validation: 0.41734947975003645]
	TIME [epoch: 5.81 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.41801431416872686		[learning rate: 0.0084115]
	Learning Rate: 0.00841147
	LOSS [training: 0.41801431416872686 | validation: 0.4090944584887878]
	TIME [epoch: 5.81 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.44262562808013056		[learning rate: 0.0083817]
	Learning Rate: 0.00838172
	LOSS [training: 0.44262562808013056 | validation: 0.42225133343919624]
	TIME [epoch: 5.81 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.41175167263006446		[learning rate: 0.0083521]
	Learning Rate: 0.00835208
	LOSS [training: 0.41175167263006446 | validation: 0.41063896791464316]
	TIME [epoch: 5.81 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4120607812375148		[learning rate: 0.0083225]
	Learning Rate: 0.00832255
	LOSS [training: 0.4120607812375148 | validation: 0.3964642299951935]
	TIME [epoch: 5.84 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3841150698177274		[learning rate: 0.0082931]
	Learning Rate: 0.00829312
	LOSS [training: 0.3841150698177274 | validation: 0.41304627060906773]
	TIME [epoch: 5.83 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4401708296901927		[learning rate: 0.0082638]
	Learning Rate: 0.00826379
	LOSS [training: 0.4401708296901927 | validation: 0.4240697311478462]
	TIME [epoch: 5.81 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.43551450739883824		[learning rate: 0.0082346]
	Learning Rate: 0.00823457
	LOSS [training: 0.43551450739883824 | validation: 0.46511959594723773]
	TIME [epoch: 5.81 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4111649622019821		[learning rate: 0.0082055]
	Learning Rate: 0.00820545
	LOSS [training: 0.4111649622019821 | validation: 0.37867611383167954]
	TIME [epoch: 5.82 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.39587872629318577		[learning rate: 0.0081764]
	Learning Rate: 0.00817644
	LOSS [training: 0.39587872629318577 | validation: 0.4472483151036387]
	TIME [epoch: 5.83 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4421632424816286		[learning rate: 0.0081475]
	Learning Rate: 0.00814752
	LOSS [training: 0.4421632424816286 | validation: 0.3780077503468736]
	TIME [epoch: 5.81 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3867913209207725		[learning rate: 0.0081187]
	Learning Rate: 0.00811871
	LOSS [training: 0.3867913209207725 | validation: 0.39276372005660243]
	TIME [epoch: 5.81 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3872694276576514		[learning rate: 0.00809]
	Learning Rate: 0.00809
	LOSS [training: 0.3872694276576514 | validation: 0.429715427496988]
	TIME [epoch: 5.81 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4029462220193634		[learning rate: 0.0080614]
	Learning Rate: 0.0080614
	LOSS [training: 0.4029462220193634 | validation: 0.3918478199243489]
	TIME [epoch: 5.81 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.39838573790816706		[learning rate: 0.0080329]
	Learning Rate: 0.00803289
	LOSS [training: 0.39838573790816706 | validation: 0.3903345623072526]
	TIME [epoch: 5.81 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4096536043079888		[learning rate: 0.0080045]
	Learning Rate: 0.00800448
	LOSS [training: 0.4096536043079888 | validation: 0.39791554804704304]
	TIME [epoch: 5.82 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6023499564118143		[learning rate: 0.0079762]
	Learning Rate: 0.00797618
	LOSS [training: 0.6023499564118143 | validation: 0.44165830283671204]
	TIME [epoch: 5.81 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4549032833568687		[learning rate: 0.007948]
	Learning Rate: 0.00794797
	LOSS [training: 0.4549032833568687 | validation: 0.40397685332034394]
	TIME [epoch: 5.83 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.41257435146613636		[learning rate: 0.0079199]
	Learning Rate: 0.00791987
	LOSS [training: 0.41257435146613636 | validation: 0.40125046118978797]
	TIME [epoch: 5.81 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.40068784143707536		[learning rate: 0.0078919]
	Learning Rate: 0.00789186
	LOSS [training: 0.40068784143707536 | validation: 0.40003968224335873]
	TIME [epoch: 5.81 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4054606270311078		[learning rate: 0.007864]
	Learning Rate: 0.00786395
	LOSS [training: 0.4054606270311078 | validation: 0.3818507877740271]
	TIME [epoch: 5.81 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4122762892667937		[learning rate: 0.0078361]
	Learning Rate: 0.00783615
	LOSS [training: 0.4122762892667937 | validation: 0.4033595789100267]
	TIME [epoch: 5.81 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.394600843623844		[learning rate: 0.0078084]
	Learning Rate: 0.00780844
	LOSS [training: 0.394600843623844 | validation: 0.4058495104921812]
	TIME [epoch: 5.82 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.41761070834851927		[learning rate: 0.0077808]
	Learning Rate: 0.00778083
	LOSS [training: 0.41761070834851927 | validation: 0.38978414530017264]
	TIME [epoch: 5.81 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.39290936055179015		[learning rate: 0.0077533]
	Learning Rate: 0.00775331
	LOSS [training: 0.39290936055179015 | validation: 0.39686125477799206]
	TIME [epoch: 5.82 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.431899468001077		[learning rate: 0.0077259]
	Learning Rate: 0.00772589
	LOSS [training: 0.431899468001077 | validation: 0.3823226402004284]
	TIME [epoch: 5.84 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3905260876364796		[learning rate: 0.0076986]
	Learning Rate: 0.00769857
	LOSS [training: 0.3905260876364796 | validation: 0.3841630099831129]
	TIME [epoch: 5.81 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5360201988808037		[learning rate: 0.0076714]
	Learning Rate: 0.00767135
	LOSS [training: 0.5360201988808037 | validation: 0.466213764152229]
	TIME [epoch: 5.82 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.42975728563772225		[learning rate: 0.0076442]
	Learning Rate: 0.00764422
	LOSS [training: 0.42975728563772225 | validation: 0.3747712387217584]
	TIME [epoch: 5.81 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_126.pth
	Model improved!!!
EPOCH 127/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3744875400956238		[learning rate: 0.0076172]
	Learning Rate: 0.00761719
	LOSS [training: 0.3744875400956238 | validation: 0.3750176475755335]
	TIME [epoch: 5.83 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4033523221566204		[learning rate: 0.0075903]
	Learning Rate: 0.00759025
	LOSS [training: 0.4033523221566204 | validation: 0.41466207325830673]
	TIME [epoch: 5.81 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3844479630549266		[learning rate: 0.0075634]
	Learning Rate: 0.00756341
	LOSS [training: 0.3844479630549266 | validation: 0.39483300336568267]
	TIME [epoch: 5.83 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3910007294579161		[learning rate: 0.0075367]
	Learning Rate: 0.00753667
	LOSS [training: 0.3910007294579161 | validation: 0.38494592018222884]
	TIME [epoch: 5.81 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4133433456262736		[learning rate: 0.00751]
	Learning Rate: 0.00751002
	LOSS [training: 0.4133433456262736 | validation: 0.39530317238966306]
	TIME [epoch: 5.82 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.39137407847816147		[learning rate: 0.0074835]
	Learning Rate: 0.00748346
	LOSS [training: 0.39137407847816147 | validation: 0.3810736587774207]
	TIME [epoch: 5.81 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.41375273670348794		[learning rate: 0.007457]
	Learning Rate: 0.007457
	LOSS [training: 0.41375273670348794 | validation: 0.5880106666361272]
	TIME [epoch: 5.83 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5767528965696279		[learning rate: 0.0074306]
	Learning Rate: 0.00743063
	LOSS [training: 0.5767528965696279 | validation: 0.41441150918182296]
	TIME [epoch: 5.82 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.41507881909386324		[learning rate: 0.0074044]
	Learning Rate: 0.00740435
	LOSS [training: 0.41507881909386324 | validation: 0.3894943104642386]
	TIME [epoch: 5.83 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37975849149469926		[learning rate: 0.0073782]
	Learning Rate: 0.00737817
	LOSS [training: 0.37975849149469926 | validation: 0.36644143484130703]
	TIME [epoch: 5.83 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_136.pth
	Model improved!!!
EPOCH 137/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3791261728793935		[learning rate: 0.0073521]
	Learning Rate: 0.00735208
	LOSS [training: 0.3791261728793935 | validation: 0.3708143969525971]
	TIME [epoch: 5.81 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3921266923612399		[learning rate: 0.0073261]
	Learning Rate: 0.00732608
	LOSS [training: 0.3921266923612399 | validation: 0.4028912154713738]
	TIME [epoch: 5.81 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3899872448716908		[learning rate: 0.0073002]
	Learning Rate: 0.00730018
	LOSS [training: 0.3899872448716908 | validation: 0.4203014200352159]
	TIME [epoch: 5.81 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3828038436271226		[learning rate: 0.0072744]
	Learning Rate: 0.00727436
	LOSS [training: 0.3828038436271226 | validation: 0.3852557329907068]
	TIME [epoch: 5.81 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3713609988045185		[learning rate: 0.0072486]
	Learning Rate: 0.00724864
	LOSS [training: 0.3713609988045185 | validation: 0.4270195853357909]
	TIME [epoch: 5.82 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3893831807701718		[learning rate: 0.007223]
	Learning Rate: 0.007223
	LOSS [training: 0.3893831807701718 | validation: 0.36859171404543295]
	TIME [epoch: 5.81 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4095169303345862		[learning rate: 0.0071975]
	Learning Rate: 0.00719746
	LOSS [training: 0.4095169303345862 | validation: 0.37940330306653897]
	TIME [epoch: 5.81 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35790830734011964		[learning rate: 0.007172]
	Learning Rate: 0.00717201
	LOSS [training: 0.35790830734011964 | validation: 0.38771764503906764]
	TIME [epoch: 5.83 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3914642773912755		[learning rate: 0.0071467]
	Learning Rate: 0.00714665
	LOSS [training: 0.3914642773912755 | validation: 0.40835577017293234]
	TIME [epoch: 5.81 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3759692215305465		[learning rate: 0.0071214]
	Learning Rate: 0.00712138
	LOSS [training: 0.3759692215305465 | validation: 0.3697253618740465]
	TIME [epoch: 5.81 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37070605953214364		[learning rate: 0.0070962]
	Learning Rate: 0.0070962
	LOSS [training: 0.37070605953214364 | validation: 0.3946334365020095]
	TIME [epoch: 5.81 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4740747125516787		[learning rate: 0.0070711]
	Learning Rate: 0.0070711
	LOSS [training: 0.4740747125516787 | validation: 0.37501153965721956]
	TIME [epoch: 5.81 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3875185329470698		[learning rate: 0.0070461]
	Learning Rate: 0.0070461
	LOSS [training: 0.3875185329470698 | validation: 0.37702131392418686]
	TIME [epoch: 5.82 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3557211065856172		[learning rate: 0.0070212]
	Learning Rate: 0.00702118
	LOSS [training: 0.3557211065856172 | validation: 0.36685358811598573]
	TIME [epoch: 5.81 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35463903555212756		[learning rate: 0.0069964]
	Learning Rate: 0.00699635
	LOSS [training: 0.35463903555212756 | validation: 0.37564589695854644]
	TIME [epoch: 5.82 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37970321458778233		[learning rate: 0.0069716]
	Learning Rate: 0.00697161
	LOSS [training: 0.37970321458778233 | validation: 0.3988623715746234]
	TIME [epoch: 5.81 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4098200145883352		[learning rate: 0.006947]
	Learning Rate: 0.00694696
	LOSS [training: 0.4098200145883352 | validation: 0.3875403655148667]
	TIME [epoch: 5.81 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3622318573601855		[learning rate: 0.0069224]
	Learning Rate: 0.00692239
	LOSS [training: 0.3622318573601855 | validation: 0.3815794611302209]
	TIME [epoch: 5.82 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3747294130067913		[learning rate: 0.0068979]
	Learning Rate: 0.00689792
	LOSS [training: 0.3747294130067913 | validation: 0.44929886402852776]
	TIME [epoch: 5.81 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5665909775000557		[learning rate: 0.0068735]
	Learning Rate: 0.00687352
	LOSS [training: 0.5665909775000557 | validation: 0.40363259447900157]
	TIME [epoch: 5.83 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3896888224447916		[learning rate: 0.0068492]
	Learning Rate: 0.00684922
	LOSS [training: 0.3896888224447916 | validation: 0.35694826503556204]
	TIME [epoch: 5.81 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_157.pth
	Model improved!!!
EPOCH 158/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35345496068753673		[learning rate: 0.006825]
	Learning Rate: 0.006825
	LOSS [training: 0.35345496068753673 | validation: 0.34536439240271194]
	TIME [epoch: 5.82 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_158.pth
	Model improved!!!
EPOCH 159/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3485171184474667		[learning rate: 0.0068009]
	Learning Rate: 0.00680086
	LOSS [training: 0.3485171184474667 | validation: 0.38117977598133823]
	TIME [epoch: 5.83 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.36644607884914876		[learning rate: 0.0067768]
	Learning Rate: 0.00677681
	LOSS [training: 0.36644607884914876 | validation: 0.35537797987530156]
	TIME [epoch: 5.81 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.36391008774887146		[learning rate: 0.0067529]
	Learning Rate: 0.00675285
	LOSS [training: 0.36391008774887146 | validation: 0.34656594561742565]
	TIME [epoch: 5.83 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3660647361603568		[learning rate: 0.006729]
	Learning Rate: 0.00672897
	LOSS [training: 0.3660647361603568 | validation: 0.3864670936124879]
	TIME [epoch: 5.82 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5242421722287999		[learning rate: 0.0067052]
	Learning Rate: 0.00670518
	LOSS [training: 0.5242421722287999 | validation: 0.40369105690182205]
	TIME [epoch: 5.82 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.40733651643619434		[learning rate: 0.0066815]
	Learning Rate: 0.00668147
	LOSS [training: 0.40733651643619434 | validation: 0.39324167033320234]
	TIME [epoch: 5.84 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37638177802315936		[learning rate: 0.0066578]
	Learning Rate: 0.00665784
	LOSS [training: 0.37638177802315936 | validation: 0.40560625565526287]
	TIME [epoch: 5.82 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3788994363710076		[learning rate: 0.0066343]
	Learning Rate: 0.0066343
	LOSS [training: 0.3788994363710076 | validation: 0.3740859799866233]
	TIME [epoch: 5.93 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3593746381130553		[learning rate: 0.0066108]
	Learning Rate: 0.00661084
	LOSS [training: 0.3593746381130553 | validation: 0.37119607749759564]
	TIME [epoch: 5.83 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3691186021668537		[learning rate: 0.0065875]
	Learning Rate: 0.00658746
	LOSS [training: 0.3691186021668537 | validation: 0.36746195144700805]
	TIME [epoch: 5.82 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4691848892663379		[learning rate: 0.0065642]
	Learning Rate: 0.00656416
	LOSS [training: 0.4691848892663379 | validation: 0.4188793558911229]
	TIME [epoch: 5.83 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4087126997856397		[learning rate: 0.006541]
	Learning Rate: 0.00654095
	LOSS [training: 0.4087126997856397 | validation: 0.36873770364463504]
	TIME [epoch: 5.83 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37534972344770035		[learning rate: 0.0065178]
	Learning Rate: 0.00651782
	LOSS [training: 0.37534972344770035 | validation: 0.35186118460880594]
	TIME [epoch: 5.82 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35052944490127724		[learning rate: 0.0064948]
	Learning Rate: 0.00649477
	LOSS [training: 0.35052944490127724 | validation: 0.356155686333494]
	TIME [epoch: 5.82 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3696510326114664		[learning rate: 0.0064718]
	Learning Rate: 0.00647181
	LOSS [training: 0.3696510326114664 | validation: 0.38475831962689233]
	TIME [epoch: 5.81 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4114914358650175		[learning rate: 0.0064489]
	Learning Rate: 0.00644892
	LOSS [training: 0.4114914358650175 | validation: 0.3549806550441944]
	TIME [epoch: 5.82 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3586607627153391		[learning rate: 0.0064261]
	Learning Rate: 0.00642612
	LOSS [training: 0.3586607627153391 | validation: 0.37168247810866945]
	TIME [epoch: 5.81 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35272590036060986		[learning rate: 0.0064034]
	Learning Rate: 0.00640339
	LOSS [training: 0.35272590036060986 | validation: 0.39118457827490205]
	TIME [epoch: 5.81 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.39331695890129037		[learning rate: 0.0063808]
	Learning Rate: 0.00638075
	LOSS [training: 0.39331695890129037 | validation: 0.3509745848239852]
	TIME [epoch: 5.83 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3486820568489806		[learning rate: 0.0063582]
	Learning Rate: 0.00635819
	LOSS [training: 0.3486820568489806 | validation: 0.33967037288249735]
	TIME [epoch: 5.82 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_178.pth
	Model improved!!!
EPOCH 179/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3644884554378432		[learning rate: 0.0063357]
	Learning Rate: 0.0063357
	LOSS [training: 0.3644884554378432 | validation: 0.4603682108317365]
	TIME [epoch: 5.82 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.36179721208146204		[learning rate: 0.0063133]
	Learning Rate: 0.0063133
	LOSS [training: 0.36179721208146204 | validation: 0.35059491741646254]
	TIME [epoch: 5.81 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3589267918855396		[learning rate: 0.006291]
	Learning Rate: 0.00629097
	LOSS [training: 0.3589267918855396 | validation: 0.34880872220384285]
	TIME [epoch: 5.81 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3505118968009496		[learning rate: 0.0062687]
	Learning Rate: 0.00626873
	LOSS [training: 0.3505118968009496 | validation: 0.3593481308162133]
	TIME [epoch: 5.81 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4766117567734514		[learning rate: 0.0062466]
	Learning Rate: 0.00624656
	LOSS [training: 0.4766117567734514 | validation: 0.6041606988549135]
	TIME [epoch: 5.81 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5208855038657788		[learning rate: 0.0062245]
	Learning Rate: 0.00622447
	LOSS [training: 0.5208855038657788 | validation: 0.3791460700321171]
	TIME [epoch: 5.83 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.47931965988816766		[learning rate: 0.0062025]
	Learning Rate: 0.00620246
	LOSS [training: 0.47931965988816766 | validation: 0.36438017476923396]
	TIME [epoch: 5.83 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.435260877546875		[learning rate: 0.0061805]
	Learning Rate: 0.00618053
	LOSS [training: 0.435260877546875 | validation: 0.35667159894557354]
	TIME [epoch: 5.81 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.45100176138497217		[learning rate: 0.0061587]
	Learning Rate: 0.00615867
	LOSS [training: 0.45100176138497217 | validation: 0.3822601742657309]
	TIME [epoch: 5.81 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.40043788800702346		[learning rate: 0.0061369]
	Learning Rate: 0.00613689
	LOSS [training: 0.40043788800702346 | validation: 0.3515462596689559]
	TIME [epoch: 5.81 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3921260401279644		[learning rate: 0.0061152]
	Learning Rate: 0.00611519
	LOSS [training: 0.3921260401279644 | validation: 0.36869875526784346]
	TIME [epoch: 5.81 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3867829905634272		[learning rate: 0.0060936]
	Learning Rate: 0.00609357
	LOSS [training: 0.3867829905634272 | validation: 0.35468734691795883]
	TIME [epoch: 5.81 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3880355333465271		[learning rate: 0.006072]
	Learning Rate: 0.00607202
	LOSS [training: 0.3880355333465271 | validation: 0.35777442540886817]
	TIME [epoch: 5.82 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3861710097911111		[learning rate: 0.0060505]
	Learning Rate: 0.00605055
	LOSS [training: 0.3861710097911111 | validation: 0.38582234293725803]
	TIME [epoch: 5.82 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.36637655057854895		[learning rate: 0.0060292]
	Learning Rate: 0.00602915
	LOSS [training: 0.36637655057854895 | validation: 0.372174349431326]
	TIME [epoch: 5.82 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.39746243846639473		[learning rate: 0.0060078]
	Learning Rate: 0.00600783
	LOSS [training: 0.39746243846639473 | validation: 0.37087602041688417]
	TIME [epoch: 5.81 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4002456338397109		[learning rate: 0.0059866]
	Learning Rate: 0.00598659
	LOSS [training: 0.4002456338397109 | validation: 0.4326323873151415]
	TIME [epoch: 5.83 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4548737461442493		[learning rate: 0.0059654]
	Learning Rate: 0.00596542
	LOSS [training: 0.4548737461442493 | validation: 0.35161660471522976]
	TIME [epoch: 5.81 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3673991333014501		[learning rate: 0.0059443]
	Learning Rate: 0.00594433
	LOSS [training: 0.3673991333014501 | validation: 0.35217831101971403]
	TIME [epoch: 5.82 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37389612991426074		[learning rate: 0.0059233]
	Learning Rate: 0.0059233
	LOSS [training: 0.37389612991426074 | validation: 0.36828300637627387]
	TIME [epoch: 5.82 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3686908503396058		[learning rate: 0.0059024]
	Learning Rate: 0.00590236
	LOSS [training: 0.3686908503396058 | validation: 0.35302067845273977]
	TIME [epoch: 5.82 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35143652490876076		[learning rate: 0.0058815]
	Learning Rate: 0.00588149
	LOSS [training: 0.35143652490876076 | validation: 0.34404771239116333]
	TIME [epoch: 5.82 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35995959797544114		[learning rate: 0.0058607]
	Learning Rate: 0.00586069
	LOSS [training: 0.35995959797544114 | validation: 0.4435770389930026]
	TIME [epoch: 5.81 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.42710777820488294		[learning rate: 0.00584]
	Learning Rate: 0.00583996
	LOSS [training: 0.42710777820488294 | validation: 0.3515221812272933]
	TIME [epoch: 5.81 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3556845591496192		[learning rate: 0.0058193]
	Learning Rate: 0.00581931
	LOSS [training: 0.3556845591496192 | validation: 0.3515538481475888]
	TIME [epoch: 5.81 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3867291898563015		[learning rate: 0.0057987]
	Learning Rate: 0.00579874
	LOSS [training: 0.3867291898563015 | validation: 0.41193718117963635]
	TIME [epoch: 5.8 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3786121477440963		[learning rate: 0.0057782]
	Learning Rate: 0.00577823
	LOSS [training: 0.3786121477440963 | validation: 0.3346590072906615]
	TIME [epoch: 5.83 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_205.pth
	Model improved!!!
EPOCH 206/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3604009336911284		[learning rate: 0.0057578]
	Learning Rate: 0.0057578
	LOSS [training: 0.3604009336911284 | validation: 0.4017558590780886]
	TIME [epoch: 5.82 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.36957215783651653		[learning rate: 0.0057374]
	Learning Rate: 0.00573744
	LOSS [training: 0.36957215783651653 | validation: 0.36137840904315277]
	TIME [epoch: 5.81 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.36609679226201286		[learning rate: 0.0057171]
	Learning Rate: 0.00571715
	LOSS [training: 0.36609679226201286 | validation: 0.36181660358200624]
	TIME [epoch: 5.81 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3502571367656481		[learning rate: 0.0056969]
	Learning Rate: 0.00569693
	LOSS [training: 0.3502571367656481 | validation: 0.35644869496503684]
	TIME [epoch: 5.81 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3542389507253978		[learning rate: 0.0056768]
	Learning Rate: 0.00567679
	LOSS [training: 0.3542389507253978 | validation: 0.373927552425012]
	TIME [epoch: 5.81 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4091380742595274		[learning rate: 0.0056567]
	Learning Rate: 0.00565671
	LOSS [training: 0.4091380742595274 | validation: 0.354738828337911]
	TIME [epoch: 5.8 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3496682886527455		[learning rate: 0.0056367]
	Learning Rate: 0.00563671
	LOSS [training: 0.3496682886527455 | validation: 0.35536648586678854]
	TIME [epoch: 5.82 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3723124647033853		[learning rate: 0.0056168]
	Learning Rate: 0.00561678
	LOSS [training: 0.3723124647033853 | validation: 0.41728929237912604]
	TIME [epoch: 5.81 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3448606183830601		[learning rate: 0.0055969]
	Learning Rate: 0.00559691
	LOSS [training: 0.3448606183830601 | validation: 0.35785416928057284]
	TIME [epoch: 5.81 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33774078058837403		[learning rate: 0.0055771]
	Learning Rate: 0.00557712
	LOSS [training: 0.33774078058837403 | validation: 0.342586833650793]
	TIME [epoch: 5.82 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5863287403345708		[learning rate: 0.0055574]
	Learning Rate: 0.0055574
	LOSS [training: 0.5863287403345708 | validation: 0.3514854982433896]
	TIME [epoch: 5.81 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34959043619258207		[learning rate: 0.0055378]
	Learning Rate: 0.00553775
	LOSS [training: 0.34959043619258207 | validation: 0.34946525525162137]
	TIME [epoch: 5.82 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3412520518913973		[learning rate: 0.0055182]
	Learning Rate: 0.00551817
	LOSS [training: 0.3412520518913973 | validation: 0.36831215715508]
	TIME [epoch: 5.81 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34452620355205843		[learning rate: 0.0054987]
	Learning Rate: 0.00549865
	LOSS [training: 0.34452620355205843 | validation: 0.36232717420708493]
	TIME [epoch: 5.83 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3378645266229636		[learning rate: 0.0054792]
	Learning Rate: 0.00547921
	LOSS [training: 0.3378645266229636 | validation: 0.33683223143942687]
	TIME [epoch: 5.82 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34853294424311193		[learning rate: 0.0054598]
	Learning Rate: 0.00545983
	LOSS [training: 0.34853294424311193 | validation: 0.3752618070966163]
	TIME [epoch: 5.81 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.36727026632666976		[learning rate: 0.0054405]
	Learning Rate: 0.00544053
	LOSS [training: 0.36727026632666976 | validation: 0.40005958634898564]
	TIME [epoch: 5.81 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34959974997467014		[learning rate: 0.0054213]
	Learning Rate: 0.00542129
	LOSS [training: 0.34959974997467014 | validation: 0.3273902350820591]
	TIME [epoch: 5.81 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_223.pth
	Model improved!!!
EPOCH 224/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34569260525634343		[learning rate: 0.0054021]
	Learning Rate: 0.00540212
	LOSS [training: 0.34569260525634343 | validation: 0.33509511630190064]
	TIME [epoch: 5.82 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3470472770235613		[learning rate: 0.005383]
	Learning Rate: 0.00538302
	LOSS [training: 0.3470472770235613 | validation: 0.34476047727705794]
	TIME [epoch: 5.82 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35404943575579745		[learning rate: 0.005364]
	Learning Rate: 0.00536398
	LOSS [training: 0.35404943575579745 | validation: 0.3492180762684828]
	TIME [epoch: 5.82 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3272665142774131		[learning rate: 0.005345]
	Learning Rate: 0.00534501
	LOSS [training: 0.3272665142774131 | validation: 0.35899937694694717]
	TIME [epoch: 5.81 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.40552587348702634		[learning rate: 0.0053261]
	Learning Rate: 0.00532611
	LOSS [training: 0.40552587348702634 | validation: 0.35237242980004824]
	TIME [epoch: 5.82 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3384555928440989		[learning rate: 0.0053073]
	Learning Rate: 0.00530728
	LOSS [training: 0.3384555928440989 | validation: 0.37366510684813414]
	TIME [epoch: 5.81 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.36976675319445523		[learning rate: 0.0052885]
	Learning Rate: 0.00528851
	LOSS [training: 0.36976675319445523 | validation: 0.34667744910094017]
	TIME [epoch: 5.81 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3414248215928198		[learning rate: 0.0052698]
	Learning Rate: 0.00526981
	LOSS [training: 0.3414248215928198 | validation: 0.34698564998303894]
	TIME [epoch: 5.82 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32035928602083674		[learning rate: 0.0052512]
	Learning Rate: 0.00525117
	LOSS [training: 0.32035928602083674 | validation: 0.35144008174563623]
	TIME [epoch: 5.82 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31892278560685533		[learning rate: 0.0052326]
	Learning Rate: 0.0052326
	LOSS [training: 0.31892278560685533 | validation: 0.3427596397535879]
	TIME [epoch: 5.81 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3387816755560104		[learning rate: 0.0052141]
	Learning Rate: 0.0052141
	LOSS [training: 0.3387816755560104 | validation: 0.33673768812504934]
	TIME [epoch: 5.81 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33599756118453855		[learning rate: 0.0051957]
	Learning Rate: 0.00519566
	LOSS [training: 0.33599756118453855 | validation: 0.35960351524746675]
	TIME [epoch: 5.81 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37502701750718087		[learning rate: 0.0051773]
	Learning Rate: 0.00517729
	LOSS [training: 0.37502701750718087 | validation: 0.3266725669585358]
	TIME [epoch: 5.82 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_236.pth
	Model improved!!!
EPOCH 237/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3797068421891874		[learning rate: 0.005159]
	Learning Rate: 0.00515898
	LOSS [training: 0.3797068421891874 | validation: 0.3298431972159303]
	TIME [epoch: 5.81 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32090544512907193		[learning rate: 0.0051407]
	Learning Rate: 0.00514074
	LOSS [training: 0.32090544512907193 | validation: 0.3376286415301676]
	TIME [epoch: 5.81 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3348595770950116		[learning rate: 0.0051226]
	Learning Rate: 0.00512256
	LOSS [training: 0.3348595770950116 | validation: 0.3357831367050137]
	TIME [epoch: 5.81 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34962183697246446		[learning rate: 0.0051044]
	Learning Rate: 0.00510445
	LOSS [training: 0.34962183697246446 | validation: 0.36166588009741557]
	TIME [epoch: 5.82 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3668735728741354		[learning rate: 0.0050864]
	Learning Rate: 0.0050864
	LOSS [training: 0.3668735728741354 | validation: 0.44683545045234324]
	TIME [epoch: 5.82 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.41566008420728834		[learning rate: 0.0050684]
	Learning Rate: 0.00506841
	LOSS [training: 0.41566008420728834 | validation: 0.3219579325858478]
	TIME [epoch: 5.81 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_242.pth
	Model improved!!!
EPOCH 243/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32548083896836816		[learning rate: 0.0050505]
	Learning Rate: 0.00505049
	LOSS [training: 0.32548083896836816 | validation: 0.32714444107385326]
	TIME [epoch: 5.82 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3217555716881314		[learning rate: 0.0050326]
	Learning Rate: 0.00503263
	LOSS [training: 0.3217555716881314 | validation: 0.3253849343853405]
	TIME [epoch: 5.82 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31481906099243256		[learning rate: 0.0050148]
	Learning Rate: 0.00501483
	LOSS [training: 0.31481906099243256 | validation: 0.3577296161098111]
	TIME [epoch: 5.82 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.347537781941664		[learning rate: 0.0049971]
	Learning Rate: 0.0049971
	LOSS [training: 0.347537781941664 | validation: 0.41327246597591527]
	TIME [epoch: 5.83 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3948302730309103		[learning rate: 0.0049794]
	Learning Rate: 0.00497943
	LOSS [training: 0.3948302730309103 | validation: 0.32546229345870936]
	TIME [epoch: 5.82 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3108743811638917		[learning rate: 0.0049618]
	Learning Rate: 0.00496182
	LOSS [training: 0.3108743811638917 | validation: 0.3349096048503472]
	TIME [epoch: 5.83 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32679134080367017		[learning rate: 0.0049443]
	Learning Rate: 0.00494427
	LOSS [training: 0.32679134080367017 | validation: 0.3258606212726595]
	TIME [epoch: 5.82 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32650439945747367		[learning rate: 0.0049268]
	Learning Rate: 0.00492679
	LOSS [training: 0.32650439945747367 | validation: 0.37068956142541976]
	TIME [epoch: 5.81 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3369218601111336		[learning rate: 0.0049094]
	Learning Rate: 0.00490937
	LOSS [training: 0.3369218601111336 | validation: 0.46404582978701425]
	TIME [epoch: 5.82 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4035791955845201		[learning rate: 0.004892]
	Learning Rate: 0.00489201
	LOSS [training: 0.4035791955845201 | validation: 0.3461215832098709]
	TIME [epoch: 5.82 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3248596427549311		[learning rate: 0.0048747]
	Learning Rate: 0.00487471
	LOSS [training: 0.3248596427549311 | validation: 0.32982586528510016]
	TIME [epoch: 5.82 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3092357364904763		[learning rate: 0.0048575]
	Learning Rate: 0.00485747
	LOSS [training: 0.3092357364904763 | validation: 0.33583074595857026]
	TIME [epoch: 5.82 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32406852347737936		[learning rate: 0.0048403]
	Learning Rate: 0.00484029
	LOSS [training: 0.32406852347737936 | validation: 0.35629957740331325]
	TIME [epoch: 5.83 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3244023301710634		[learning rate: 0.0048232]
	Learning Rate: 0.00482318
	LOSS [training: 0.3244023301710634 | validation: 0.3420680196801627]
	TIME [epoch: 5.83 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3701701024477673		[learning rate: 0.0048061]
	Learning Rate: 0.00480612
	LOSS [training: 0.3701701024477673 | validation: 0.33495145773078316]
	TIME [epoch: 5.82 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3417422611902145		[learning rate: 0.0047891]
	Learning Rate: 0.00478913
	LOSS [training: 0.3417422611902145 | validation: 0.3527846618632796]
	TIME [epoch: 5.82 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3270340324485019		[learning rate: 0.0047722]
	Learning Rate: 0.00477219
	LOSS [training: 0.3270340324485019 | validation: 0.3363364288195963]
	TIME [epoch: 5.81 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32235817059956734		[learning rate: 0.0047553]
	Learning Rate: 0.00475532
	LOSS [training: 0.32235817059956734 | validation: 0.3311323689441969]
	TIME [epoch: 5.82 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33702948102249525		[learning rate: 0.0047385]
	Learning Rate: 0.0047385
	LOSS [training: 0.33702948102249525 | validation: 0.3621561529284141]
	TIME [epoch: 5.82 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32033489136844145		[learning rate: 0.0047217]
	Learning Rate: 0.00472175
	LOSS [training: 0.32033489136844145 | validation: 0.3419040729230224]
	TIME [epoch: 5.82 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3318010503296534		[learning rate: 0.004705]
	Learning Rate: 0.00470505
	LOSS [training: 0.3318010503296534 | validation: 0.35337002797047246]
	TIME [epoch: 5.82 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32317490952620037		[learning rate: 0.0046884]
	Learning Rate: 0.00468841
	LOSS [training: 0.32317490952620037 | validation: 0.3516484687798071]
	TIME [epoch: 5.82 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3189872924994581		[learning rate: 0.0046718]
	Learning Rate: 0.00467183
	LOSS [training: 0.3189872924994581 | validation: 0.37249654350913636]
	TIME [epoch: 5.81 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34318482784524473		[learning rate: 0.0046553]
	Learning Rate: 0.00465531
	LOSS [training: 0.34318482784524473 | validation: 0.3273452877903766]
	TIME [epoch: 5.82 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3328805202215775		[learning rate: 0.0046388]
	Learning Rate: 0.00463885
	LOSS [training: 0.3328805202215775 | validation: 0.33162060452376024]
	TIME [epoch: 5.81 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3207858949012515		[learning rate: 0.0046224]
	Learning Rate: 0.00462245
	LOSS [training: 0.3207858949012515 | validation: 0.3400640933257584]
	TIME [epoch: 5.82 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34758220369233245		[learning rate: 0.0046061]
	Learning Rate: 0.0046061
	LOSS [training: 0.34758220369233245 | validation: 0.34916066500855025]
	TIME [epoch: 5.82 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3161332384363322		[learning rate: 0.0045898]
	Learning Rate: 0.00458981
	LOSS [training: 0.3161332384363322 | validation: 0.3590165186698423]
	TIME [epoch: 5.82 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33894982266834744		[learning rate: 0.0045736]
	Learning Rate: 0.00457358
	LOSS [training: 0.33894982266834744 | validation: 0.32853744348421376]
	TIME [epoch: 5.82 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32303374858447403		[learning rate: 0.0045574]
	Learning Rate: 0.00455741
	LOSS [training: 0.32303374858447403 | validation: 0.33783143313626074]
	TIME [epoch: 5.82 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3327896498417772		[learning rate: 0.0045413]
	Learning Rate: 0.00454129
	LOSS [training: 0.3327896498417772 | validation: 0.34285247266647423]
	TIME [epoch: 5.82 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31291155833271106		[learning rate: 0.0045252]
	Learning Rate: 0.00452523
	LOSS [training: 0.31291155833271106 | validation: 0.34792258982044133]
	TIME [epoch: 5.82 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.330456640553145		[learning rate: 0.0045092]
	Learning Rate: 0.00450923
	LOSS [training: 0.330456640553145 | validation: 0.3218092962510226]
	TIME [epoch: 5.82 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_275.pth
	Model improved!!!
EPOCH 276/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3239061010610832		[learning rate: 0.0044933]
	Learning Rate: 0.00449329
	LOSS [training: 0.3239061010610832 | validation: 0.3280783369916396]
	TIME [epoch: 5.83 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35113863196758816		[learning rate: 0.0044774]
	Learning Rate: 0.0044774
	LOSS [training: 0.35113863196758816 | validation: 0.3546032198142434]
	TIME [epoch: 5.83 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32716768596057094		[learning rate: 0.0044616]
	Learning Rate: 0.00446156
	LOSS [training: 0.32716768596057094 | validation: 0.3346914257793896]
	TIME [epoch: 5.82 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3244379037052353		[learning rate: 0.0044458]
	Learning Rate: 0.00444579
	LOSS [training: 0.3244379037052353 | validation: 0.3324800762298154]
	TIME [epoch: 5.82 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33223569213325976		[learning rate: 0.0044301]
	Learning Rate: 0.00443007
	LOSS [training: 0.33223569213325976 | validation: 0.3459509173228191]
	TIME [epoch: 5.81 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.40162366823730705		[learning rate: 0.0044144]
	Learning Rate: 0.0044144
	LOSS [training: 0.40162366823730705 | validation: 0.35713350673533295]
	TIME [epoch: 5.81 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3408070438172717		[learning rate: 0.0043988]
	Learning Rate: 0.00439879
	LOSS [training: 0.3408070438172717 | validation: 0.34108909469033794]
	TIME [epoch: 5.81 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31042514780308		[learning rate: 0.0043832]
	Learning Rate: 0.00438324
	LOSS [training: 0.31042514780308 | validation: 0.32629387619041256]
	TIME [epoch: 5.82 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33564161791523		[learning rate: 0.0043677]
	Learning Rate: 0.00436774
	LOSS [training: 0.33564161791523 | validation: 0.35501502335847546]
	TIME [epoch: 5.82 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3195713867441772		[learning rate: 0.0043523]
	Learning Rate: 0.00435229
	LOSS [training: 0.3195713867441772 | validation: 0.332087584120567]
	TIME [epoch: 5.81 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3121288389107359		[learning rate: 0.0043369]
	Learning Rate: 0.0043369
	LOSS [training: 0.3121288389107359 | validation: 0.3236680224204848]
	TIME [epoch: 5.81 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33533600776565176		[learning rate: 0.0043216]
	Learning Rate: 0.00432156
	LOSS [training: 0.33533600776565176 | validation: 0.33811873646556434]
	TIME [epoch: 5.82 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3460418823674147		[learning rate: 0.0043063]
	Learning Rate: 0.00430628
	LOSS [training: 0.3460418823674147 | validation: 0.35509643924209106]
	TIME [epoch: 5.81 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.337327048710623		[learning rate: 0.0042911]
	Learning Rate: 0.00429106
	LOSS [training: 0.337327048710623 | validation: 0.3255905766782713]
	TIME [epoch: 5.81 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.329516257276639		[learning rate: 0.0042759]
	Learning Rate: 0.00427588
	LOSS [training: 0.329516257276639 | validation: 0.3464909532967672]
	TIME [epoch: 5.82 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32117523732401226		[learning rate: 0.0042608]
	Learning Rate: 0.00426076
	LOSS [training: 0.32117523732401226 | validation: 0.33207736119337283]
	TIME [epoch: 5.81 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3311687399009285		[learning rate: 0.0042457]
	Learning Rate: 0.00424569
	LOSS [training: 0.3311687399009285 | validation: 0.3284500091728106]
	TIME [epoch: 5.81 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31048941089553683		[learning rate: 0.0042307]
	Learning Rate: 0.00423068
	LOSS [training: 0.31048941089553683 | validation: 0.3526608035478835]
	TIME [epoch: 5.81 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31223717667838385		[learning rate: 0.0042157]
	Learning Rate: 0.00421572
	LOSS [training: 0.31223717667838385 | validation: 0.3304641212959142]
	TIME [epoch: 5.81 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3521059909192144		[learning rate: 0.0042008]
	Learning Rate: 0.00420081
	LOSS [training: 0.3521059909192144 | validation: 0.3377680715649455]
	TIME [epoch: 5.81 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3196615490181122		[learning rate: 0.004186]
	Learning Rate: 0.00418596
	LOSS [training: 0.3196615490181122 | validation: 0.32835714739317773]
	TIME [epoch: 5.81 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3156028739457236		[learning rate: 0.0041712]
	Learning Rate: 0.00417116
	LOSS [training: 0.3156028739457236 | validation: 0.35571228066235105]
	TIME [epoch: 5.83 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32832498636176904		[learning rate: 0.0041564]
	Learning Rate: 0.00415641
	LOSS [training: 0.32832498636176904 | validation: 0.3487622784571718]
	TIME [epoch: 5.82 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3182632939232931		[learning rate: 0.0041417]
	Learning Rate: 0.00414171
	LOSS [training: 0.3182632939232931 | validation: 0.3293663689835226]
	TIME [epoch: 5.82 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.36666532671442426		[learning rate: 0.0041271]
	Learning Rate: 0.00412706
	LOSS [training: 0.36666532671442426 | validation: 0.3357439403433239]
	TIME [epoch: 5.81 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3312413585542906		[learning rate: 0.0041125]
	Learning Rate: 0.00411247
	LOSS [training: 0.3312413585542906 | validation: 0.322075899144015]
	TIME [epoch: 5.8 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3251490844713187		[learning rate: 0.0040979]
	Learning Rate: 0.00409793
	LOSS [training: 0.3251490844713187 | validation: 0.32184836195508126]
	TIME [epoch: 5.8 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3197075068622404		[learning rate: 0.0040834]
	Learning Rate: 0.00408344
	LOSS [training: 0.3197075068622404 | validation: 0.32698970955229456]
	TIME [epoch: 5.8 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3100367051340549		[learning rate: 0.004069]
	Learning Rate: 0.004069
	LOSS [training: 0.3100367051340549 | validation: 0.31977607842273603]
	TIME [epoch: 5.81 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_304.pth
	Model improved!!!
EPOCH 305/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3631077445262077		[learning rate: 0.0040546]
	Learning Rate: 0.00405461
	LOSS [training: 0.3631077445262077 | validation: 0.4014427161711428]
	TIME [epoch: 5.81 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5108187825045083		[learning rate: 0.0040403]
	Learning Rate: 0.00404027
	LOSS [training: 0.5108187825045083 | validation: 0.37636233781650325]
	TIME [epoch: 5.81 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.49183522211891023		[learning rate: 0.004026]
	Learning Rate: 0.00402598
	LOSS [training: 0.49183522211891023 | validation: 0.3702398200587752]
	TIME [epoch: 5.82 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.46324306401091864		[learning rate: 0.0040117]
	Learning Rate: 0.00401175
	LOSS [training: 0.46324306401091864 | validation: 0.3629103441403957]
	TIME [epoch: 5.83 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.439522624993431		[learning rate: 0.0039976]
	Learning Rate: 0.00399756
	LOSS [training: 0.439522624993431 | validation: 0.3398177059668382]
	TIME [epoch: 5.82 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4145375457459342		[learning rate: 0.0039834]
	Learning Rate: 0.00398342
	LOSS [training: 0.4145375457459342 | validation: 0.3644462162780139]
	TIME [epoch: 5.81 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4081179570424853		[learning rate: 0.0039693]
	Learning Rate: 0.00396934
	LOSS [training: 0.4081179570424853 | validation: 0.35384342496125565]
	TIME [epoch: 5.82 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.386402534151099		[learning rate: 0.0039553]
	Learning Rate: 0.0039553
	LOSS [training: 0.386402534151099 | validation: 0.33770217839610234]
	TIME [epoch: 5.82 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4157961447672686		[learning rate: 0.0039413]
	Learning Rate: 0.00394131
	LOSS [training: 0.4157961447672686 | validation: 0.3567747102583998]
	TIME [epoch: 5.81 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.39021370257872107		[learning rate: 0.0039274]
	Learning Rate: 0.00392738
	LOSS [training: 0.39021370257872107 | validation: 0.32839616534286276]
	TIME [epoch: 5.81 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37040996449733976		[learning rate: 0.0039135]
	Learning Rate: 0.00391349
	LOSS [training: 0.37040996449733976 | validation: 0.32337144252001593]
	TIME [epoch: 5.81 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34596608724098704		[learning rate: 0.0038997]
	Learning Rate: 0.00389965
	LOSS [training: 0.34596608724098704 | validation: 0.3489987497105419]
	TIME [epoch: 5.81 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33826406755839306		[learning rate: 0.0038859]
	Learning Rate: 0.00388586
	LOSS [training: 0.33826406755839306 | validation: 0.3510748814624544]
	TIME [epoch: 5.81 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33880713592560063		[learning rate: 0.0038721]
	Learning Rate: 0.00387212
	LOSS [training: 0.33880713592560063 | validation: 0.33543340537607635]
	TIME [epoch: 5.82 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3065213206778616		[learning rate: 0.0038584]
	Learning Rate: 0.00385843
	LOSS [training: 0.3065213206778616 | validation: 0.33514658429147837]
	TIME [epoch: 5.81 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3377611000515808		[learning rate: 0.0038448]
	Learning Rate: 0.00384478
	LOSS [training: 0.3377611000515808 | validation: 0.33940867739246383]
	TIME [epoch: 5.82 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33632150431128754		[learning rate: 0.0038312]
	Learning Rate: 0.00383119
	LOSS [training: 0.33632150431128754 | validation: 0.35035522611128134]
	TIME [epoch: 5.81 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3428781000980276		[learning rate: 0.0038176]
	Learning Rate: 0.00381764
	LOSS [training: 0.3428781000980276 | validation: 0.3738212825612481]
	TIME [epoch: 5.81 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33576130055739983		[learning rate: 0.0038041]
	Learning Rate: 0.00380414
	LOSS [training: 0.33576130055739983 | validation: 0.3297153452553638]
	TIME [epoch: 5.81 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32441569580029966		[learning rate: 0.0037907]
	Learning Rate: 0.00379069
	LOSS [training: 0.32441569580029966 | validation: 0.35409806476097727]
	TIME [epoch: 5.81 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37116144708635485		[learning rate: 0.0037773]
	Learning Rate: 0.00377728
	LOSS [training: 0.37116144708635485 | validation: 0.32524606220135177]
	TIME [epoch: 5.81 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33205013537993394		[learning rate: 0.0037639]
	Learning Rate: 0.00376393
	LOSS [training: 0.33205013537993394 | validation: 0.3407459051882561]
	TIME [epoch: 5.81 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.347996411400822		[learning rate: 0.0037506]
	Learning Rate: 0.00375062
	LOSS [training: 0.347996411400822 | validation: 0.343688286436646]
	TIME [epoch: 5.82 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3386034927762355		[learning rate: 0.0037374]
	Learning Rate: 0.00373735
	LOSS [training: 0.3386034927762355 | validation: 0.33452204713119604]
	TIME [epoch: 5.82 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3785774709355521		[learning rate: 0.0037241]
	Learning Rate: 0.00372414
	LOSS [training: 0.3785774709355521 | validation: 0.417723353905911]
	TIME [epoch: 5.81 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3650771722131543		[learning rate: 0.003711]
	Learning Rate: 0.00371097
	LOSS [training: 0.3650771722131543 | validation: 0.32662331228808]
	TIME [epoch: 5.81 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3114940110793125		[learning rate: 0.0036978]
	Learning Rate: 0.00369785
	LOSS [training: 0.3114940110793125 | validation: 0.3199050215224252]
	TIME [epoch: 5.81 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31446452853841883		[learning rate: 0.0036848]
	Learning Rate: 0.00368477
	LOSS [training: 0.31446452853841883 | validation: 0.3331582198867517]
	TIME [epoch: 5.81 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3347518592260303		[learning rate: 0.0036717]
	Learning Rate: 0.00367174
	LOSS [training: 0.3347518592260303 | validation: 0.32224040107561674]
	TIME [epoch: 5.82 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33543465670275596		[learning rate: 0.0036588]
	Learning Rate: 0.00365875
	LOSS [training: 0.33543465670275596 | validation: 0.3480229214780387]
	TIME [epoch: 5.81 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.334963890453098		[learning rate: 0.0036458]
	Learning Rate: 0.00364582
	LOSS [training: 0.334963890453098 | validation: 0.34636434983883085]
	TIME [epoch: 5.82 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3301528259501146		[learning rate: 0.0036329]
	Learning Rate: 0.00363292
	LOSS [training: 0.3301528259501146 | validation: 0.34689440625397194]
	TIME [epoch: 5.81 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35147507795522265		[learning rate: 0.0036201]
	Learning Rate: 0.00362008
	LOSS [training: 0.35147507795522265 | validation: 0.6331299393238925]
	TIME [epoch: 5.81 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4201495417839392		[learning rate: 0.0036073]
	Learning Rate: 0.00360728
	LOSS [training: 0.4201495417839392 | validation: 0.3998883487235535]
	TIME [epoch: 5.81 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3324889555195234		[learning rate: 0.0035945]
	Learning Rate: 0.00359452
	LOSS [training: 0.3324889555195234 | validation: 0.3351820268533041]
	TIME [epoch: 5.82 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3178124457614539		[learning rate: 0.0035818]
	Learning Rate: 0.00358181
	LOSS [training: 0.3178124457614539 | validation: 0.34031617503936273]
	TIME [epoch: 5.82 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3218753323977815		[learning rate: 0.0035691]
	Learning Rate: 0.00356914
	LOSS [training: 0.3218753323977815 | validation: 0.33048142847470807]
	TIME [epoch: 5.82 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3254760258315188		[learning rate: 0.0035565]
	Learning Rate: 0.00355652
	LOSS [training: 0.3254760258315188 | validation: 0.396006213753848]
	TIME [epoch: 5.81 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.38725475115408714		[learning rate: 0.0035439]
	Learning Rate: 0.00354395
	LOSS [training: 0.38725475115408714 | validation: 0.32818456090996845]
	TIME [epoch: 5.81 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30217248077419184		[learning rate: 0.0035314]
	Learning Rate: 0.00353141
	LOSS [training: 0.30217248077419184 | validation: 0.3406652535346824]
	TIME [epoch: 5.81 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3218152670730635		[learning rate: 0.0035189]
	Learning Rate: 0.00351893
	LOSS [training: 0.3218152670730635 | validation: 0.32393106012081524]
	TIME [epoch: 5.81 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35419319889880224		[learning rate: 0.0035065]
	Learning Rate: 0.00350648
	LOSS [training: 0.35419319889880224 | validation: 0.33254728028433905]
	TIME [epoch: 5.81 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31184250192970603		[learning rate: 0.0034941]
	Learning Rate: 0.00349408
	LOSS [training: 0.31184250192970603 | validation: 0.33904712628276995]
	TIME [epoch: 5.83 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31630025214554025		[learning rate: 0.0034817]
	Learning Rate: 0.00348173
	LOSS [training: 0.31630025214554025 | validation: 0.32168236063682115]
	TIME [epoch: 5.83 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3127716202330075		[learning rate: 0.0034694]
	Learning Rate: 0.00346942
	LOSS [training: 0.3127716202330075 | validation: 0.3214451214339227]
	TIME [epoch: 5.81 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30992207150797674		[learning rate: 0.0034571]
	Learning Rate: 0.00345715
	LOSS [training: 0.30992207150797674 | validation: 0.34853312622258337]
	TIME [epoch: 5.8 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3110666199232281		[learning rate: 0.0034449]
	Learning Rate: 0.00344492
	LOSS [training: 0.3110666199232281 | validation: 0.3309767907085371]
	TIME [epoch: 5.81 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3119822854450128		[learning rate: 0.0034327]
	Learning Rate: 0.00343274
	LOSS [training: 0.3119822854450128 | validation: 0.3335507434634685]
	TIME [epoch: 5.81 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31690293961919264		[learning rate: 0.0034206]
	Learning Rate: 0.0034206
	LOSS [training: 0.31690293961919264 | validation: 0.35628487254491426]
	TIME [epoch: 5.81 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.367077400939809		[learning rate: 0.0034085]
	Learning Rate: 0.00340851
	LOSS [training: 0.367077400939809 | validation: 0.33148221246625686]
	TIME [epoch: 5.83 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3285602325751075		[learning rate: 0.0033965]
	Learning Rate: 0.00339645
	LOSS [training: 0.3285602325751075 | validation: 0.32799123261137486]
	TIME [epoch: 5.81 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3255844462732441		[learning rate: 0.0033844]
	Learning Rate: 0.00338444
	LOSS [training: 0.3255844462732441 | validation: 0.34917506749664623]
	TIME [epoch: 5.81 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3526789281261182		[learning rate: 0.0033725]
	Learning Rate: 0.00337247
	LOSS [training: 0.3526789281261182 | validation: 0.5296786741087256]
	TIME [epoch: 5.81 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4405510555359517		[learning rate: 0.0033605]
	Learning Rate: 0.00336055
	LOSS [training: 0.4405510555359517 | validation: 0.34647931406828414]
	TIME [epoch: 5.81 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3268068013527936		[learning rate: 0.0033487]
	Learning Rate: 0.00334867
	LOSS [training: 0.3268068013527936 | validation: 0.3346380304594605]
	TIME [epoch: 5.81 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3092527936080962		[learning rate: 0.0033368]
	Learning Rate: 0.00333682
	LOSS [training: 0.3092527936080962 | validation: 0.3104057531706159]
	TIME [epoch: 5.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_360.pth
	Model improved!!!
EPOCH 361/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3259634247457426		[learning rate: 0.003325]
	Learning Rate: 0.00332502
	LOSS [training: 0.3259634247457426 | validation: 0.32678930120872246]
	TIME [epoch: 5.82 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3163520437286042		[learning rate: 0.0033133]
	Learning Rate: 0.00331327
	LOSS [training: 0.3163520437286042 | validation: 0.33993550735177863]
	TIME [epoch: 5.81 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3174764408308837		[learning rate: 0.0033016]
	Learning Rate: 0.00330155
	LOSS [training: 0.3174764408308837 | validation: 0.32406351808328165]
	TIME [epoch: 5.81 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3167052383872737		[learning rate: 0.0032899]
	Learning Rate: 0.00328988
	LOSS [training: 0.3167052383872737 | validation: 0.3520785106246609]
	TIME [epoch: 5.8 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3088277811356373		[learning rate: 0.0032782]
	Learning Rate: 0.00327824
	LOSS [training: 0.3088277811356373 | validation: 0.3155762111055106]
	TIME [epoch: 5.81 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30764269141823314		[learning rate: 0.0032666]
	Learning Rate: 0.00326665
	LOSS [training: 0.30764269141823314 | validation: 0.32100953107514596]
	TIME [epoch: 5.81 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3563764332610872		[learning rate: 0.0032551]
	Learning Rate: 0.0032551
	LOSS [training: 0.3563764332610872 | validation: 0.32117306140653257]
	TIME [epoch: 5.8 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3253371536756207		[learning rate: 0.0032436]
	Learning Rate: 0.00324359
	LOSS [training: 0.3253371536756207 | validation: 0.3279933782591705]
	TIME [epoch: 5.82 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3358490017740603		[learning rate: 0.0032321]
	Learning Rate: 0.00323212
	LOSS [training: 0.3358490017740603 | validation: 0.3257257862428704]
	TIME [epoch: 5.82 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30946426676949707		[learning rate: 0.0032207]
	Learning Rate: 0.00322069
	LOSS [training: 0.30946426676949707 | validation: 0.329100741408633]
	TIME [epoch: 5.81 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33181570416374745		[learning rate: 0.0032093]
	Learning Rate: 0.0032093
	LOSS [training: 0.33181570416374745 | validation: 0.32385005684072654]
	TIME [epoch: 5.82 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31191078620925894		[learning rate: 0.003198]
	Learning Rate: 0.00319795
	LOSS [training: 0.31191078620925894 | validation: 0.3253765583887943]
	TIME [epoch: 5.81 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33143203852966824		[learning rate: 0.0031866]
	Learning Rate: 0.00318664
	LOSS [training: 0.33143203852966824 | validation: 0.3244069244856889]
	TIME [epoch: 5.81 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3148010480543582		[learning rate: 0.0031754]
	Learning Rate: 0.00317537
	LOSS [training: 0.3148010480543582 | validation: 0.3303728746341507]
	TIME [epoch: 5.81 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.335353381191876		[learning rate: 0.0031641]
	Learning Rate: 0.00316415
	LOSS [training: 0.335353381191876 | validation: 0.3416682096226259]
	TIME [epoch: 5.82 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32204997606548136		[learning rate: 0.003153]
	Learning Rate: 0.00315296
	LOSS [training: 0.32204997606548136 | validation: 0.3321119628946735]
	TIME [epoch: 5.82 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30334850939054175		[learning rate: 0.0031418]
	Learning Rate: 0.00314181
	LOSS [training: 0.30334850939054175 | validation: 0.3279919956377511]
	TIME [epoch: 5.81 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30340493403838725		[learning rate: 0.0031307]
	Learning Rate: 0.0031307
	LOSS [training: 0.30340493403838725 | validation: 0.31842496505722406]
	TIME [epoch: 5.81 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3230485129469602		[learning rate: 0.0031196]
	Learning Rate: 0.00311963
	LOSS [training: 0.3230485129469602 | validation: 0.3179511654124722]
	TIME [epoch: 5.83 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29247465666159367		[learning rate: 0.0031086]
	Learning Rate: 0.00310859
	LOSS [training: 0.29247465666159367 | validation: 0.3254691969098381]
	TIME [epoch: 5.81 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30029767099872445		[learning rate: 0.0030976]
	Learning Rate: 0.0030976
	LOSS [training: 0.30029767099872445 | validation: 0.3193243343635727]
	TIME [epoch: 5.89 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33882499347491285		[learning rate: 0.0030866]
	Learning Rate: 0.00308665
	LOSS [training: 0.33882499347491285 | validation: 0.3229096640846024]
	TIME [epoch: 5.82 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32742854857788817		[learning rate: 0.0030757]
	Learning Rate: 0.00307573
	LOSS [training: 0.32742854857788817 | validation: 0.32397614949656084]
	TIME [epoch: 5.81 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31558776784553394		[learning rate: 0.0030649]
	Learning Rate: 0.00306486
	LOSS [training: 0.31558776784553394 | validation: 0.3714262809965189]
	TIME [epoch: 5.81 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34948857884779055		[learning rate: 0.003054]
	Learning Rate: 0.00305402
	LOSS [training: 0.34948857884779055 | validation: 0.33450285606060287]
	TIME [epoch: 5.83 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3455588757131037		[learning rate: 0.0030432]
	Learning Rate: 0.00304322
	LOSS [training: 0.3455588757131037 | validation: 0.32005563753642774]
	TIME [epoch: 5.82 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32520329950468607		[learning rate: 0.0030325]
	Learning Rate: 0.00303246
	LOSS [training: 0.32520329950468607 | validation: 0.31683372466664833]
	TIME [epoch: 5.81 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30591894610848797		[learning rate: 0.0030217]
	Learning Rate: 0.00302174
	LOSS [training: 0.30591894610848797 | validation: 0.3167421363054655]
	TIME [epoch: 5.81 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3041767285601567		[learning rate: 0.003011]
	Learning Rate: 0.00301105
	LOSS [training: 0.3041767285601567 | validation: 0.31729653235940186]
	TIME [epoch: 5.81 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31281612753238197		[learning rate: 0.0030004]
	Learning Rate: 0.0030004
	LOSS [training: 0.31281612753238197 | validation: 0.3257163245689593]
	TIME [epoch: 5.82 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3086785788698424		[learning rate: 0.0029898]
	Learning Rate: 0.00298979
	LOSS [training: 0.3086785788698424 | validation: 0.34608641382403726]
	TIME [epoch: 5.81 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3158612285328197		[learning rate: 0.0029792]
	Learning Rate: 0.00297922
	LOSS [training: 0.3158612285328197 | validation: 0.31284800499587484]
	TIME [epoch: 5.82 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3185886094564014		[learning rate: 0.0029687]
	Learning Rate: 0.00296869
	LOSS [training: 0.3185886094564014 | validation: 0.32287084260353177]
	TIME [epoch: 5.81 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3067768469718253		[learning rate: 0.0029582]
	Learning Rate: 0.00295819
	LOSS [training: 0.3067768469718253 | validation: 0.32165766338228113]
	TIME [epoch: 5.81 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.307892044216677		[learning rate: 0.0029477]
	Learning Rate: 0.00294773
	LOSS [training: 0.307892044216677 | validation: 0.32955972322661636]
	TIME [epoch: 5.81 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3113474424337806		[learning rate: 0.0029373]
	Learning Rate: 0.0029373
	LOSS [training: 0.3113474424337806 | validation: 0.31639014518482655]
	TIME [epoch: 5.81 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3063211840518792		[learning rate: 0.0029269]
	Learning Rate: 0.00292692
	LOSS [training: 0.3063211840518792 | validation: 0.32783690927325965]
	TIME [epoch: 5.81 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34857739453747844		[learning rate: 0.0029166]
	Learning Rate: 0.00291657
	LOSS [training: 0.34857739453747844 | validation: 0.3243331774649093]
	TIME [epoch: 5.81 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3133762246243235		[learning rate: 0.0029063]
	Learning Rate: 0.00290625
	LOSS [training: 0.3133762246243235 | validation: 0.3436985169931034]
	TIME [epoch: 5.82 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32459511523304574		[learning rate: 0.002896]
	Learning Rate: 0.00289598
	LOSS [training: 0.32459511523304574 | validation: 0.31915025911971096]
	TIME [epoch: 5.82 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30662272120014156		[learning rate: 0.0028857]
	Learning Rate: 0.00288573
	LOSS [training: 0.30662272120014156 | validation: 0.3448085227835381]
	TIME [epoch: 5.81 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6139979091178559		[learning rate: 0.0028755]
	Learning Rate: 0.00287553
	LOSS [training: 0.6139979091178559 | validation: 1.283302755519959]
	TIME [epoch: 5.81 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.1898171362530228		[learning rate: 0.0028654]
	Learning Rate: 0.00286536
	LOSS [training: 1.1898171362530228 | validation: 1.0671152056475957]
	TIME [epoch: 5.8 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.0607080275859258		[learning rate: 0.0028552]
	Learning Rate: 0.00285523
	LOSS [training: 1.0607080275859258 | validation: 2.4565195531215926]
	TIME [epoch: 5.81 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 6/6] avg loss: 2.7888250712784015		[learning rate: 0.0028451]
	Learning Rate: 0.00284513
	LOSS [training: 2.7888250712784015 | validation: 2.7983809941951487]
	TIME [epoch: 5.81 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 6/6] avg loss: 2.713516448011278		[learning rate: 0.0028351]
	Learning Rate: 0.00283507
	LOSS [training: 2.713516448011278 | validation: 3.4359172094986556]
	TIME [epoch: 5.8 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 6/6] avg loss: 3.2289663769114796		[learning rate: 0.002825]
	Learning Rate: 0.00282505
	LOSS [training: 3.2289663769114796 | validation: 4.019567316546231]
	TIME [epoch: 5.8 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 6/6] avg loss: 3.6131963384449572		[learning rate: 0.0028151]
	Learning Rate: 0.00281506
	LOSS [training: 3.6131963384449572 | validation: 4.435047354413358]
	TIME [epoch: 5.8 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 6/6] avg loss: 3.7440534406812325		[learning rate: 0.0028051]
	Learning Rate: 0.0028051
	LOSS [training: 3.7440534406812325 | validation: 4.430167805342814]
	TIME [epoch: 5.8 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 6/6] avg loss: 4.7618991630391365		[learning rate: 0.0027952]
	Learning Rate: 0.00279518
	LOSS [training: 4.7618991630391365 | validation: 5.342129030191453]
	TIME [epoch: 5.81 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 6/6] avg loss: 5.3673974054277585		[learning rate: 0.0027853]
	Learning Rate: 0.0027853
	LOSS [training: 5.3673974054277585 | validation: 6.117429066103324]
	TIME [epoch: 5.81 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 6/6] avg loss: 6.125259770704916		[learning rate: 0.0027754]
	Learning Rate: 0.00277545
	LOSS [training: 6.125259770704916 | validation: 5.230072329321013]
	TIME [epoch: 5.82 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 6/6] avg loss: 4.519826271324885		[learning rate: 0.0027656]
	Learning Rate: 0.00276564
	LOSS [training: 4.519826271324885 | validation: 4.648379381852538]
	TIME [epoch: 5.8 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 6/6] avg loss: 5.202714644374419		[learning rate: 0.0027559]
	Learning Rate: 0.00275586
	LOSS [training: 5.202714644374419 | validation: 6.274391578235866]
	TIME [epoch: 5.8 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 6/6] avg loss: 5.5275111436758495		[learning rate: 0.0027461]
	Learning Rate: 0.00274611
	LOSS [training: 5.5275111436758495 | validation: 4.994955180717521]
	TIME [epoch: 5.81 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 6/6] avg loss: 4.513225557493498		[learning rate: 0.0027364]
	Learning Rate: 0.0027364
	LOSS [training: 4.513225557493498 | validation: 4.223718926201579]
	TIME [epoch: 5.79 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 6/6] avg loss: 4.153090311931902		[learning rate: 0.0027267]
	Learning Rate: 0.00272672
	LOSS [training: 4.153090311931902 | validation: 4.4931188382608145]
	TIME [epoch: 5.86 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 6/6] avg loss: 4.620807228109147		[learning rate: 0.0027171]
	Learning Rate: 0.00271708
	LOSS [training: 4.620807228109147 | validation: 4.868515834968082]
	TIME [epoch: 5.81 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 6/6] avg loss: 4.581960078527419		[learning rate: 0.0027075]
	Learning Rate: 0.00270747
	LOSS [training: 4.581960078527419 | validation: 4.891193869752184]
	TIME [epoch: 5.8 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 6/6] avg loss: 4.776075584496993		[learning rate: 0.0026979]
	Learning Rate: 0.0026979
	LOSS [training: 4.776075584496993 | validation: 5.0271609814694616]
	TIME [epoch: 5.81 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 6/6] avg loss: 4.610489867875345		[learning rate: 0.0026884]
	Learning Rate: 0.00268836
	LOSS [training: 4.610489867875345 | validation: 4.371047933449266]
	TIME [epoch: 5.8 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 6/6] avg loss: 4.5043084265882065		[learning rate: 0.0026789]
	Learning Rate: 0.00267885
	LOSS [training: 4.5043084265882065 | validation: 5.082449182399869]
	TIME [epoch: 5.81 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 6/6] avg loss: 4.861321886344567		[learning rate: 0.0026694]
	Learning Rate: 0.00266938
	LOSS [training: 4.861321886344567 | validation: 4.97410019554828]
	TIME [epoch: 5.8 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 6/6] avg loss: 4.398340016924367		[learning rate: 0.0026599]
	Learning Rate: 0.00265994
	LOSS [training: 4.398340016924367 | validation: 4.621660423844556]
	TIME [epoch: 5.8 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 6/6] avg loss: 4.49691971253166		[learning rate: 0.0026505]
	Learning Rate: 0.00265053
	LOSS [training: 4.49691971253166 | validation: 4.734178139376914]
	TIME [epoch: 5.82 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 6/6] avg loss: 4.777749190489983		[learning rate: 0.0026412]
	Learning Rate: 0.00264116
	LOSS [training: 4.777749190489983 | validation: 5.316757388174613]
	TIME [epoch: 5.8 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 6/6] avg loss: 5.372968202842162		[learning rate: 0.0026318]
	Learning Rate: 0.00263182
	LOSS [training: 5.372968202842162 | validation: 5.543828060946256]
	TIME [epoch: 5.81 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 6/6] avg loss: 5.381015161755766		[learning rate: 0.0026225]
	Learning Rate: 0.00262251
	LOSS [training: 5.381015161755766 | validation: 5.729463597154836]
	TIME [epoch: 5.81 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 6/6] avg loss: 5.686995694998593		[learning rate: 0.0026132]
	Learning Rate: 0.00261324
	LOSS [training: 5.686995694998593 | validation: 5.9571358894303]
	TIME [epoch: 5.81 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 6/6] avg loss: 5.721664762736822		[learning rate: 0.002604]
	Learning Rate: 0.002604
	LOSS [training: 5.721664762736822 | validation: 5.701300575678719]
	TIME [epoch: 5.8 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 6/6] avg loss: 5.498640200261399		[learning rate: 0.0025948]
	Learning Rate: 0.00259479
	LOSS [training: 5.498640200261399 | validation: 5.750283224093074]
	TIME [epoch: 5.81 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 6/6] avg loss: 5.426766587650573		[learning rate: 0.0025856]
	Learning Rate: 0.00258562
	LOSS [training: 5.426766587650573 | validation: 5.573524714802625]
	TIME [epoch: 5.81 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 6/6] avg loss: 5.339495275076648		[learning rate: 0.0025765]
	Learning Rate: 0.00257647
	LOSS [training: 5.339495275076648 | validation: 5.791476483059813]
	TIME [epoch: 5.81 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 6/6] avg loss: 6.1423247786589705		[learning rate: 0.0025674]
	Learning Rate: 0.00256736
	LOSS [training: 6.1423247786589705 | validation: 6.357638445291377]
	TIME [epoch: 5.8 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 6/6] avg loss: 5.895029827468714		[learning rate: 0.0025583]
	Learning Rate: 0.00255828
	LOSS [training: 5.895029827468714 | validation: 6.188452305293624]
	TIME [epoch: 5.8 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 6/6] avg loss: 5.433506244436867		[learning rate: 0.0025492]
	Learning Rate: 0.00254924
	LOSS [training: 5.433506244436867 | validation: 5.665203609537654]
	TIME [epoch: 5.92 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 6/6] avg loss: 5.4025688368330975		[learning rate: 0.0025402]
	Learning Rate: 0.00254022
	LOSS [training: 5.4025688368330975 | validation: 5.682065589204966]
	TIME [epoch: 5.81 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 6/6] avg loss: 5.299670713094991		[learning rate: 0.0025312]
	Learning Rate: 0.00253124
	LOSS [training: 5.299670713094991 | validation: 5.597872769657383]
	TIME [epoch: 5.8 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 6/6] avg loss: 5.567445975341609		[learning rate: 0.0025223]
	Learning Rate: 0.00252229
	LOSS [training: 5.567445975341609 | validation: 5.955378256996047]
	TIME [epoch: 5.82 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 6/6] avg loss: 6.1033117921171955		[learning rate: 0.0025134]
	Learning Rate: 0.00251337
	LOSS [training: 6.1033117921171955 | validation: 6.016750784987224]
	TIME [epoch: 5.81 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 6/6] avg loss: 5.644739857038261		[learning rate: 0.0025045]
	Learning Rate: 0.00250448
	LOSS [training: 5.644739857038261 | validation: 5.764459092014912]
	TIME [epoch: 5.82 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 6/6] avg loss: 5.4712155877017326		[learning rate: 0.0024956]
	Learning Rate: 0.00249563
	LOSS [training: 5.4712155877017326 | validation: 5.592859005750504]
	TIME [epoch: 5.8 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 6/6] avg loss: 5.37621825661189		[learning rate: 0.0024868]
	Learning Rate: 0.0024868
	LOSS [training: 5.37621825661189 | validation: 5.556832785426556]
	TIME [epoch: 5.81 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 6/6] avg loss: 5.282843319007859		[learning rate: 0.002478]
	Learning Rate: 0.00247801
	LOSS [training: 5.282843319007859 | validation: 5.541160475551212]
	TIME [epoch: 5.8 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 6/6] avg loss: 5.372779119468517		[learning rate: 0.0024692]
	Learning Rate: 0.00246924
	LOSS [training: 5.372779119468517 | validation: 5.741356142411209]
	TIME [epoch: 5.8 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 6/6] avg loss: 5.344239272859194		[learning rate: 0.0024605]
	Learning Rate: 0.00246051
	LOSS [training: 5.344239272859194 | validation: 5.478533075489106]
	TIME [epoch: 5.82 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 6/6] avg loss: 5.0871030875498695		[learning rate: 0.0024518]
	Learning Rate: 0.00245181
	LOSS [training: 5.0871030875498695 | validation: 5.323554467113345]
	TIME [epoch: 5.81 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 6/6] avg loss: 5.1166002309913505		[learning rate: 0.0024431]
	Learning Rate: 0.00244314
	LOSS [training: 5.1166002309913505 | validation: 5.671716284470189]
	TIME [epoch: 5.81 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 6/6] avg loss: 5.290175940602323		[learning rate: 0.0024345]
	Learning Rate: 0.0024345
	LOSS [training: 5.290175940602323 | validation: 5.204919761840469]
	TIME [epoch: 5.8 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 6/6] avg loss: 4.8270835959634		[learning rate: 0.0024259]
	Learning Rate: 0.00242589
	LOSS [training: 4.8270835959634 | validation: 6.79140370784679]
	TIME [epoch: 5.81 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 6/6] avg loss: 5.9360153752230405		[learning rate: 0.0024173]
	Learning Rate: 0.00241732
	LOSS [training: 5.9360153752230405 | validation: 5.221240818467782]
	TIME [epoch: 5.82 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 6/6] avg loss: 4.424166795531352		[learning rate: 0.0024088]
	Learning Rate: 0.00240877
	LOSS [training: 4.424166795531352 | validation: 4.035001383026192]
	TIME [epoch: 5.81 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 6/6] avg loss: 2.9928952276575633		[learning rate: 0.0024002]
	Learning Rate: 0.00240025
	LOSS [training: 2.9928952276575633 | validation: 2.3287107250858416]
	TIME [epoch: 5.81 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.5797110068159874		[learning rate: 0.0023918]
	Learning Rate: 0.00239176
	LOSS [training: 1.5797110068159874 | validation: 1.1372660773578274]
	TIME [epoch: 5.81 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9666351003835693		[learning rate: 0.0023833]
	Learning Rate: 0.0023833
	LOSS [training: 0.9666351003835693 | validation: 0.694255824641701]
	TIME [epoch: 5.81 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.696637335421597		[learning rate: 0.0023749]
	Learning Rate: 0.00237488
	LOSS [training: 0.696637335421597 | validation: 0.5905058954302453]
	TIME [epoch: 5.82 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6219643367964851		[learning rate: 0.0023665]
	Learning Rate: 0.00236648
	LOSS [training: 0.6219643367964851 | validation: 0.5498458982753324]
	TIME [epoch: 5.81 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5910160674867507		[learning rate: 0.0023581]
	Learning Rate: 0.00235811
	LOSS [training: 0.5910160674867507 | validation: 0.5085515340974629]
	TIME [epoch: 5.8 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5457442072664338		[learning rate: 0.0023498]
	Learning Rate: 0.00234977
	LOSS [training: 0.5457442072664338 | validation: 0.45701153499643177]
	TIME [epoch: 5.81 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4947622225662968		[learning rate: 0.0023415]
	Learning Rate: 0.00234146
	LOSS [training: 0.4947622225662968 | validation: 0.4054505900243692]
	TIME [epoch: 5.81 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4568136145053244		[learning rate: 0.0023332]
	Learning Rate: 0.00233318
	LOSS [training: 0.4568136145053244 | validation: 0.3896369959094561]
	TIME [epoch: 5.81 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.41810189121227687		[learning rate: 0.0023249]
	Learning Rate: 0.00232493
	LOSS [training: 0.41810189121227687 | validation: 0.39861393286506364]
	TIME [epoch: 5.82 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.39517780529267776		[learning rate: 0.0023167]
	Learning Rate: 0.00231671
	LOSS [training: 0.39517780529267776 | validation: 0.358280779490414]
	TIME [epoch: 5.81 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3743761865832563		[learning rate: 0.0023085]
	Learning Rate: 0.00230852
	LOSS [training: 0.3743761865832563 | validation: 0.3641068450192601]
	TIME [epoch: 5.81 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37175406035696157		[learning rate: 0.0023004]
	Learning Rate: 0.00230035
	LOSS [training: 0.37175406035696157 | validation: 0.35799068617289836]
	TIME [epoch: 5.8 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3912734378386147		[learning rate: 0.0022922]
	Learning Rate: 0.00229222
	LOSS [training: 0.3912734378386147 | validation: 0.37044756063311246]
	TIME [epoch: 5.8 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.38155254503989755		[learning rate: 0.0022841]
	Learning Rate: 0.00228411
	LOSS [training: 0.38155254503989755 | validation: 0.3564382737370202]
	TIME [epoch: 5.81 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.400665854199669		[learning rate: 0.002276]
	Learning Rate: 0.00227604
	LOSS [training: 0.400665854199669 | validation: 0.9672006317110847]
	TIME [epoch: 5.81 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.0506195383191979		[learning rate: 0.002268]
	Learning Rate: 0.00226799
	LOSS [training: 1.0506195383191979 | validation: 1.5543877004835391]
	TIME [epoch: 5.81 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.3993024944627084		[learning rate: 0.00226]
	Learning Rate: 0.00225997
	LOSS [training: 1.3993024944627084 | validation: 1.557869134390428]
	TIME [epoch: 5.8 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.2648532477708299		[learning rate: 0.002252]
	Learning Rate: 0.00225198
	LOSS [training: 1.2648532477708299 | validation: 1.1569544518460673]
	TIME [epoch: 5.8 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.187834511013592		[learning rate: 0.002244]
	Learning Rate: 0.00224401
	LOSS [training: 1.187834511013592 | validation: 0.956799281235123]
	TIME [epoch: 5.81 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.863829687515957		[learning rate: 0.0022361]
	Learning Rate: 0.00223608
	LOSS [training: 0.863829687515957 | validation: 1.0343080518765333]
	TIME [epoch: 5.8 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.896827816874597		[learning rate: 0.0022282]
	Learning Rate: 0.00222817
	LOSS [training: 0.896827816874597 | validation: 1.5650284737838276]
	TIME [epoch: 5.8 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.462651878292652		[learning rate: 0.0022203]
	Learning Rate: 0.00222029
	LOSS [training: 1.462651878292652 | validation: 1.885498690273182]
	TIME [epoch: 5.82 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.5554532532429637		[learning rate: 0.0022124]
	Learning Rate: 0.00221244
	LOSS [training: 1.5554532532429637 | validation: 1.4631477025155402]
	TIME [epoch: 5.81 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.6811534453463395		[learning rate: 0.0022046]
	Learning Rate: 0.00220462
	LOSS [training: 1.6811534453463395 | validation: 2.379532263359436]
	TIME [epoch: 5.81 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.954035883477226		[learning rate: 0.0021968]
	Learning Rate: 0.00219682
	LOSS [training: 1.954035883477226 | validation: 2.541783185256468]
	TIME [epoch: 5.8 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 6/6] avg loss: 2.697270594213459		[learning rate: 0.0021891]
	Learning Rate: 0.00218905
	LOSS [training: 2.697270594213459 | validation: 2.493628882232211]
	TIME [epoch: 5.82 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 6/6] avg loss: 2.2780851286981108		[learning rate: 0.0021813]
	Learning Rate: 0.00218131
	LOSS [training: 2.2780851286981108 | validation: 2.3581685697886914]
	TIME [epoch: 5.8 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 6/6] avg loss: 2.2624687991240955		[learning rate: 0.0021736]
	Learning Rate: 0.0021736
	LOSS [training: 2.2624687991240955 | validation: 2.488920224979101]
	TIME [epoch: 5.8 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 6/6] avg loss: 2.060935735726103		[learning rate: 0.0021659]
	Learning Rate: 0.00216591
	LOSS [training: 2.060935735726103 | validation: 2.195242844335581]
	TIME [epoch: 5.82 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.3554793850231912		[learning rate: 0.0021583]
	Learning Rate: 0.00215825
	LOSS [training: 1.3554793850231912 | validation: 0.6121508714545014]
	TIME [epoch: 5.82 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6890828607606392		[learning rate: 0.0021506]
	Learning Rate: 0.00215062
	LOSS [training: 0.6890828607606392 | validation: 0.5078856893582635]
	TIME [epoch: 5.81 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5474687147294247		[learning rate: 0.002143]
	Learning Rate: 0.00214302
	LOSS [training: 0.5474687147294247 | validation: 0.42798017849798226]
	TIME [epoch: 5.81 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4306525684502888		[learning rate: 0.0021354]
	Learning Rate: 0.00213544
	LOSS [training: 0.4306525684502888 | validation: 0.397945689360261]
	TIME [epoch: 5.81 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4173244224406489		[learning rate: 0.0021279]
	Learning Rate: 0.00212789
	LOSS [training: 0.4173244224406489 | validation: 0.40474136154541573]
	TIME [epoch: 5.82 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4081557754970502		[learning rate: 0.0021204]
	Learning Rate: 0.00212036
	LOSS [training: 0.4081557754970502 | validation: 0.3930166386466506]
	TIME [epoch: 5.81 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.39892852315787203		[learning rate: 0.0021129]
	Learning Rate: 0.00211287
	LOSS [training: 0.39892852315787203 | validation: 0.3973543255033023]
	TIME [epoch: 5.82 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4036061397682003		[learning rate: 0.0021054]
	Learning Rate: 0.00210539
	LOSS [training: 0.4036061397682003 | validation: 0.38573590073262065]
	TIME [epoch: 5.81 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3958792042472932		[learning rate: 0.0020979]
	Learning Rate: 0.00209795
	LOSS [training: 0.3958792042472932 | validation: 0.39706135632210454]
	TIME [epoch: 5.81 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4118886447299066		[learning rate: 0.0020905]
	Learning Rate: 0.00209053
	LOSS [training: 0.4118886447299066 | validation: 0.3845196362076809]
	TIME [epoch: 5.82 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.41026567924779617		[learning rate: 0.0020831]
	Learning Rate: 0.00208314
	LOSS [training: 0.41026567924779617 | validation: 0.3822516864420976]
	TIME [epoch: 5.82 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3948878222556636		[learning rate: 0.0020758]
	Learning Rate: 0.00207577
	LOSS [training: 0.3948878222556636 | validation: 0.37663860854889303]
	TIME [epoch: 5.81 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3862633141938616		[learning rate: 0.0020684]
	Learning Rate: 0.00206843
	LOSS [training: 0.3862633141938616 | validation: 0.3619191016686929]
	TIME [epoch: 5.81 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3839073663579951		[learning rate: 0.0020611]
	Learning Rate: 0.00206112
	LOSS [training: 0.3839073663579951 | validation: 0.3920264804709132]
	TIME [epoch: 5.82 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.38630186412683054		[learning rate: 0.0020538]
	Learning Rate: 0.00205383
	LOSS [training: 0.38630186412683054 | validation: 0.35694728469764964]
	TIME [epoch: 5.82 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3815593039579019		[learning rate: 0.0020466]
	Learning Rate: 0.00204657
	LOSS [training: 0.3815593039579019 | validation: 0.34876138377837634]
	TIME [epoch: 5.82 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.38264469801177126		[learning rate: 0.0020393]
	Learning Rate: 0.00203933
	LOSS [training: 0.38264469801177126 | validation: 0.35597680812325266]
	TIME [epoch: 5.81 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37606036676597004		[learning rate: 0.0020321]
	Learning Rate: 0.00203212
	LOSS [training: 0.37606036676597004 | validation: 0.34388355979822216]
	TIME [epoch: 5.81 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35936887488193986		[learning rate: 0.0020249]
	Learning Rate: 0.00202493
	LOSS [training: 0.35936887488193986 | validation: 0.34175266707335833]
	TIME [epoch: 24.7 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3522044596377513		[learning rate: 0.0020178]
	Learning Rate: 0.00201777
	LOSS [training: 0.3522044596377513 | validation: 0.34759232388825406]
	TIME [epoch: 11.2 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3628659009513779		[learning rate: 0.0020106]
	Learning Rate: 0.00201064
	LOSS [training: 0.3628659009513779 | validation: 0.3365528808497636]
	TIME [epoch: 11.2 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37000342019761373		[learning rate: 0.0020035]
	Learning Rate: 0.00200353
	LOSS [training: 0.37000342019761373 | validation: 0.35396463031723835]
	TIME [epoch: 11.2 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3618506657227854		[learning rate: 0.0019964]
	Learning Rate: 0.00199644
	LOSS [training: 0.3618506657227854 | validation: 0.35015874002262515]
	TIME [epoch: 11.2 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3648177872571295		[learning rate: 0.0019894]
	Learning Rate: 0.00198938
	LOSS [training: 0.3648177872571295 | validation: 0.3453794991919824]
	TIME [epoch: 11.2 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3545625556195664		[learning rate: 0.0019823]
	Learning Rate: 0.00198235
	LOSS [training: 0.3545625556195664 | validation: 0.3434445043235833]
	TIME [epoch: 11.1 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.39124032879881465		[learning rate: 0.0019753]
	Learning Rate: 0.00197534
	LOSS [training: 0.39124032879881465 | validation: 0.3439681545928039]
	TIME [epoch: 11.2 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35717465999685766		[learning rate: 0.0019684]
	Learning Rate: 0.00196835
	LOSS [training: 0.35717465999685766 | validation: 0.34073267918349776]
	TIME [epoch: 11.2 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35229630556196084		[learning rate: 0.0019614]
	Learning Rate: 0.00196139
	LOSS [training: 0.35229630556196084 | validation: 0.3279849372948804]
	TIME [epoch: 11.1 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34789496148102445		[learning rate: 0.0019545]
	Learning Rate: 0.00195445
	LOSS [training: 0.34789496148102445 | validation: 0.35073523872916207]
	TIME [epoch: 11.1 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34681173180790886		[learning rate: 0.0019475]
	Learning Rate: 0.00194754
	LOSS [training: 0.34681173180790886 | validation: 0.3362369553328971]
	TIME [epoch: 11.2 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35287320912618153		[learning rate: 0.0019407]
	Learning Rate: 0.00194066
	LOSS [training: 0.35287320912618153 | validation: 0.32882326621672947]
	TIME [epoch: 11.1 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3534045938353229		[learning rate: 0.0019338]
	Learning Rate: 0.00193379
	LOSS [training: 0.3534045938353229 | validation: 0.33881972042776576]
	TIME [epoch: 11.1 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35709664984129796		[learning rate: 0.001927]
	Learning Rate: 0.00192696
	LOSS [training: 0.35709664984129796 | validation: 0.48559593230506337]
	TIME [epoch: 11.1 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.1024554632244783		[learning rate: 0.0019201]
	Learning Rate: 0.00192014
	LOSS [training: 1.1024554632244783 | validation: 1.27748816279755]
	TIME [epoch: 11.2 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8396468424167703		[learning rate: 0.0019134]
	Learning Rate: 0.00191335
	LOSS [training: 0.8396468424167703 | validation: 0.7960156968847051]
	TIME [epoch: 11.1 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5301550114289507		[learning rate: 0.0019066]
	Learning Rate: 0.00190659
	LOSS [training: 0.5301550114289507 | validation: 0.3914633221492041]
	TIME [epoch: 11.1 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.38206524220650234		[learning rate: 0.0018998]
	Learning Rate: 0.00189984
	LOSS [training: 0.38206524220650234 | validation: 0.34430969937620687]
	TIME [epoch: 11.1 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.344554481143754		[learning rate: 0.0018931]
	Learning Rate: 0.00189313
	LOSS [training: 0.344554481143754 | validation: 0.46811927566106915]
	TIME [epoch: 11.1 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4198889688497815		[learning rate: 0.0018864]
	Learning Rate: 0.00188643
	LOSS [training: 0.4198889688497815 | validation: 0.4299543308819954]
	TIME [epoch: 11.1 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3971703879421899		[learning rate: 0.0018798]
	Learning Rate: 0.00187976
	LOSS [training: 0.3971703879421899 | validation: 0.4406506687966022]
	TIME [epoch: 11.1 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.39255088162897595		[learning rate: 0.0018731]
	Learning Rate: 0.00187311
	LOSS [training: 0.39255088162897595 | validation: 0.3803472756772]
	TIME [epoch: 11.1 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3959529945004357		[learning rate: 0.0018665]
	Learning Rate: 0.00186649
	LOSS [training: 0.3959529945004357 | validation: 0.44390640408097237]
	TIME [epoch: 11.1 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.42784213513481356		[learning rate: 0.0018599]
	Learning Rate: 0.00185989
	LOSS [training: 0.42784213513481356 | validation: 0.4932568910763666]
	TIME [epoch: 11.1 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.38079708796018547		[learning rate: 0.0018533]
	Learning Rate: 0.00185331
	LOSS [training: 0.38079708796018547 | validation: 0.36793030860796194]
	TIME [epoch: 11.1 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3667851240734146		[learning rate: 0.0018468]
	Learning Rate: 0.00184676
	LOSS [training: 0.3667851240734146 | validation: 0.3295203582414968]
	TIME [epoch: 11.2 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3395857551456094		[learning rate: 0.0018402]
	Learning Rate: 0.00184023
	LOSS [training: 0.3395857551456094 | validation: 0.33023901240273396]
	TIME [epoch: 11.1 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34098092063228785		[learning rate: 0.0018337]
	Learning Rate: 0.00183372
	LOSS [training: 0.34098092063228785 | validation: 0.32759100907362193]
	TIME [epoch: 11.1 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34210081603192344		[learning rate: 0.0018272]
	Learning Rate: 0.00182724
	LOSS [training: 0.34210081603192344 | validation: 0.36810770490356615]
	TIME [epoch: 11.1 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5609038441852507		[learning rate: 0.0018208]
	Learning Rate: 0.00182078
	LOSS [training: 0.5609038441852507 | validation: 1.2384800377640464]
	TIME [epoch: 11.1 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6786021701244013		[learning rate: 0.0018143]
	Learning Rate: 0.00181434
	LOSS [training: 0.6786021701244013 | validation: 0.4672383144994018]
	TIME [epoch: 11.1 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.40805463330659714		[learning rate: 0.0018079]
	Learning Rate: 0.00180792
	LOSS [training: 0.40805463330659714 | validation: 0.3576428420514173]
	TIME [epoch: 11.1 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.36040250882709746		[learning rate: 0.0018015]
	Learning Rate: 0.00180153
	LOSS [training: 0.36040250882709746 | validation: 0.43758960019793225]
	TIME [epoch: 11.1 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3697501110157449		[learning rate: 0.0017952]
	Learning Rate: 0.00179516
	LOSS [training: 0.3697501110157449 | validation: 0.35493259878444117]
	TIME [epoch: 11.1 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3486947009657506		[learning rate: 0.0017888]
	Learning Rate: 0.00178881
	LOSS [training: 0.3486947009657506 | validation: 0.36015637801913936]
	TIME [epoch: 11.1 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37877220348088864		[learning rate: 0.0017825]
	Learning Rate: 0.00178248
	LOSS [training: 0.37877220348088864 | validation: 0.427218394954739]
	TIME [epoch: 11.1 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3953780160083755		[learning rate: 0.0017762]
	Learning Rate: 0.00177618
	LOSS [training: 0.3953780160083755 | validation: 0.5827984782164823]
	TIME [epoch: 11.2 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4580769645301537		[learning rate: 0.0017699]
	Learning Rate: 0.0017699
	LOSS [training: 0.4580769645301537 | validation: 0.5526972952940535]
	TIME [epoch: 11.1 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.43492642757002403		[learning rate: 0.0017636]
	Learning Rate: 0.00176364
	LOSS [training: 0.43492642757002403 | validation: 0.38658703299035085]
	TIME [epoch: 11.1 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.40992269232125605		[learning rate: 0.0017574]
	Learning Rate: 0.0017574
	LOSS [training: 0.40992269232125605 | validation: 0.35083041197858844]
	TIME [epoch: 11.1 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3779528480110514		[learning rate: 0.0017512]
	Learning Rate: 0.00175119
	LOSS [training: 0.3779528480110514 | validation: 0.4061351139228521]
	TIME [epoch: 11.1 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.39296009815128263		[learning rate: 0.001745]
	Learning Rate: 0.001745
	LOSS [training: 0.39296009815128263 | validation: 0.5430111458891366]
	TIME [epoch: 11.1 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.39113872450603476		[learning rate: 0.0017388]
	Learning Rate: 0.00173883
	LOSS [training: 0.39113872450603476 | validation: 0.3482481798483318]
	TIME [epoch: 11.1 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35877134578096653		[learning rate: 0.0017327]
	Learning Rate: 0.00173268
	LOSS [training: 0.35877134578096653 | validation: 0.3554615115162437]
	TIME [epoch: 11.1 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34622835972619587		[learning rate: 0.0017266]
	Learning Rate: 0.00172655
	LOSS [training: 0.34622835972619587 | validation: 0.35575131067332016]
	TIME [epoch: 11.1 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3395712480179145		[learning rate: 0.0017204]
	Learning Rate: 0.00172045
	LOSS [training: 0.3395712480179145 | validation: 0.3532151241518153]
	TIME [epoch: 11.1 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.334245777785047		[learning rate: 0.0017144]
	Learning Rate: 0.00171436
	LOSS [training: 0.334245777785047 | validation: 0.33079971068244785]
	TIME [epoch: 11.1 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34161680787420384		[learning rate: 0.0017083]
	Learning Rate: 0.0017083
	LOSS [training: 0.34161680787420384 | validation: 0.3606953608982023]
	TIME [epoch: 11.1 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3299904266293818		[learning rate: 0.0017023]
	Learning Rate: 0.00170226
	LOSS [training: 0.3299904266293818 | validation: 0.32406896751704506]
	TIME [epoch: 11.1 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3915235640004074		[learning rate: 0.0016962]
	Learning Rate: 0.00169624
	LOSS [training: 0.3915235640004074 | validation: 0.8130952738903178]
	TIME [epoch: 11.1 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6279742372166733		[learning rate: 0.0016902]
	Learning Rate: 0.00169024
	LOSS [training: 0.6279742372166733 | validation: 0.4159488525772912]
	TIME [epoch: 11.1 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3554363943164764		[learning rate: 0.0016843]
	Learning Rate: 0.00168426
	LOSS [training: 0.3554363943164764 | validation: 0.3298587781403682]
	TIME [epoch: 11.1 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3510783122866328		[learning rate: 0.0016783]
	Learning Rate: 0.00167831
	LOSS [training: 0.3510783122866328 | validation: 0.32510219204601254]
	TIME [epoch: 11.1 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3317647374496298		[learning rate: 0.0016724]
	Learning Rate: 0.00167237
	LOSS [training: 0.3317647374496298 | validation: 0.3231013522434921]
	TIME [epoch: 11.1 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3244532341767281		[learning rate: 0.0016665]
	Learning Rate: 0.00166646
	LOSS [training: 0.3244532341767281 | validation: 0.32681555226527126]
	TIME [epoch: 11.1 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32622773599581106		[learning rate: 0.0016606]
	Learning Rate: 0.00166057
	LOSS [training: 0.32622773599581106 | validation: 0.3282595553720741]
	TIME [epoch: 11.1 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3279289285815048		[learning rate: 0.0016547]
	Learning Rate: 0.00165469
	LOSS [training: 0.3279289285815048 | validation: 0.3458599709426238]
	TIME [epoch: 11.1 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3419879614654799		[learning rate: 0.0016488]
	Learning Rate: 0.00164884
	LOSS [training: 0.3419879614654799 | validation: 0.32075412633252925]
	TIME [epoch: 11.1 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3444525804032326		[learning rate: 0.001643]
	Learning Rate: 0.00164301
	LOSS [training: 0.3444525804032326 | validation: 0.37044696384694126]
	TIME [epoch: 11.1 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3351915590520505		[learning rate: 0.0016372]
	Learning Rate: 0.0016372
	LOSS [training: 0.3351915590520505 | validation: 0.3546207099507694]
	TIME [epoch: 11.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v7_20240715_180006/states/model_facs_v3_dec1b_2dpca_v7_561.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 3671.657 seconds.
