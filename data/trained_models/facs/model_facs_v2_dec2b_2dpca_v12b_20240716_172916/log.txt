Args:
Namespace(name='model_facs_v2_dec2b_2dpca_v12b', outdir='out/model_training/model_facs_v2_dec2b_2dpca_v12b', training_data='data/training_data/facs_v2/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v2/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=800, ncells_sample=800, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 200, 300], dt_schedule_scales=[0.5, 0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3954773900

Training model...

Saving initial model state to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9064146058915531		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9064146058915531 | validation: 0.8759182645780055]
	TIME [epoch: 36.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6496230363732767		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6496230363732767 | validation: 0.7696126683438254]
	TIME [epoch: 7.94 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5774245690281171		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5774245690281171 | validation: 0.7440218272970704]
	TIME [epoch: 7.91 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5399545415045987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5399545415045987 | validation: 0.7320630314474468]
	TIME [epoch: 7.95 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5223594259393284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5223594259393284 | validation: 0.7008243475458362]
	TIME [epoch: 7.93 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5016034400188769		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5016034400188769 | validation: 0.8590269331729963]
	TIME [epoch: 7.9 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5062242474662085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5062242474662085 | validation: 0.5858060636580074]
	TIME [epoch: 7.92 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38785394707279564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38785394707279564 | validation: 0.5550579284025982]
	TIME [epoch: 7.93 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33449104268140195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33449104268140195 | validation: 0.5767383981590966]
	TIME [epoch: 7.94 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3296751275413645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3296751275413645 | validation: 0.628636496530035]
	TIME [epoch: 7.94 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39747596904533666		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39747596904533666 | validation: 0.5158831233685967]
	TIME [epoch: 7.92 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27708019373690673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27708019373690673 | validation: 0.475760412019721]
	TIME [epoch: 7.95 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29959493794104486		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29959493794104486 | validation: 0.4457713179876167]
	TIME [epoch: 7.96 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3943744308634306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3943744308634306 | validation: 0.5298270820427893]
	TIME [epoch: 7.91 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2987986529709709		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2987986529709709 | validation: 0.44167421047207295]
	TIME [epoch: 7.91 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2711771550286688		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2711771550286688 | validation: 0.4977123084133493]
	TIME [epoch: 7.91 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33358067638095046		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33358067638095046 | validation: 0.4505242642537057]
	TIME [epoch: 7.93 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24161338106377594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24161338106377594 | validation: 0.41370513619109517]
	TIME [epoch: 7.91 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3162226012798422		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3162226012798422 | validation: 0.4647749467707019]
	TIME [epoch: 7.91 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3058934838736521		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3058934838736521 | validation: 0.46943260395892666]
	TIME [epoch: 7.91 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28133447919409393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28133447919409393 | validation: 0.44083199102201004]
	TIME [epoch: 7.93 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2688197865557814		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2688197865557814 | validation: 0.4041508571120679]
	TIME [epoch: 7.91 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25174319971898806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25174319971898806 | validation: 0.4110847478000983]
	TIME [epoch: 7.93 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30445524388699446		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30445524388699446 | validation: 0.41435793774152424]
	TIME [epoch: 7.93 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2893324736359226		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2893324736359226 | validation: 0.41609407476272275]
	TIME [epoch: 7.88 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29416437815931484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29416437815931484 | validation: 0.4366814034679285]
	TIME [epoch: 7.94 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24143001532945713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24143001532945713 | validation: 0.38412554941985905]
	TIME [epoch: 7.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22298922735584775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22298922735584775 | validation: 0.4061621458657466]
	TIME [epoch: 7.94 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21400155407060134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21400155407060134 | validation: 0.37306286728055726]
	TIME [epoch: 7.94 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2523608246818406		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2523608246818406 | validation: 0.5583761861338208]
	TIME [epoch: 7.93 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33063133317644455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33063133317644455 | validation: 0.41254187009846954]
	TIME [epoch: 7.9 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22189244214238085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22189244214238085 | validation: 0.38267468366355045]
	TIME [epoch: 7.91 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26896391303681744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26896391303681744 | validation: 0.3587276753411267]
	TIME [epoch: 7.92 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2151916774861154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2151916774861154 | validation: 0.3906289666117527]
	TIME [epoch: 7.96 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28231551538041877		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28231551538041877 | validation: 0.3991305203573252]
	TIME [epoch: 7.97 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2668331042808878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2668331042808878 | validation: 0.46207638036399346]
	TIME [epoch: 7.95 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2613934252009563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2613934252009563 | validation: 0.40823586487427954]
	TIME [epoch: 7.95 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26338968162145343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26338968162145343 | validation: 0.4266944579931982]
	TIME [epoch: 7.95 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2547266156085375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2547266156085375 | validation: 0.4372264796267409]
	TIME [epoch: 7.97 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2614923449314002		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2614923449314002 | validation: 0.44792001474771936]
	TIME [epoch: 7.95 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2631599770703289		[learning rate: 0.0099646]
	Learning Rate: 0.00996464
	LOSS [training: 0.2631599770703289 | validation: 0.4209168900560813]
	TIME [epoch: 7.95 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23919365571568146		[learning rate: 0.0099206]
	Learning Rate: 0.00992061
	LOSS [training: 0.23919365571568146 | validation: 0.4446376466105097]
	TIME [epoch: 7.95 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2606799408347241		[learning rate: 0.0098768]
	Learning Rate: 0.00987678
	LOSS [training: 0.2606799408347241 | validation: 0.3611101509798658]
	TIME [epoch: 7.96 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2838556472751437		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.2838556472751437 | validation: 0.37389559749193724]
	TIME [epoch: 7.95 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23598922054198548		[learning rate: 0.0097897]
	Learning Rate: 0.0097897
	LOSS [training: 0.23598922054198548 | validation: 0.4180758858003144]
	TIME [epoch: 7.94 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24087635667283996		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.24087635667283996 | validation: 0.3775127253544476]
	TIME [epoch: 7.94 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2362662794245634		[learning rate: 0.0097034]
	Learning Rate: 0.00970338
	LOSS [training: 0.2362662794245634 | validation: 0.3703542439422931]
	TIME [epoch: 7.95 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.221819079696931		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.221819079696931 | validation: 0.3697789593576359]
	TIME [epoch: 7.97 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2607947302383034		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.2607947302383034 | validation: 0.34106076221275744]
	TIME [epoch: 7.96 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20896659038784643		[learning rate: 0.0095753]
	Learning Rate: 0.00957533
	LOSS [training: 0.20896659038784643 | validation: 0.42977364611633656]
	TIME [epoch: 7.94 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2635608785231812		[learning rate: 0.009533]
	Learning Rate: 0.00953303
	LOSS [training: 0.2635608785231812 | validation: 0.3870337057114838]
	TIME [epoch: 41 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19616650206441036		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.19616650206441036 | validation: 0.3594442285607572]
	TIME [epoch: 15.3 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2326490019803722		[learning rate: 0.009449]
	Learning Rate: 0.00944897
	LOSS [training: 0.2326490019803722 | validation: 0.3461612144945744]
	TIME [epoch: 15.3 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2143430676858534		[learning rate: 0.0094072]
	Learning Rate: 0.00940722
	LOSS [training: 0.2143430676858534 | validation: 0.4103747133203265]
	TIME [epoch: 15.3 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26244012338413353		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.26244012338413353 | validation: 0.3418756183782316]
	TIME [epoch: 15.3 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2014751320434433		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.2014751320434433 | validation: 0.3776102885455122]
	TIME [epoch: 15.3 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23712321455208257		[learning rate: 0.0092831]
	Learning Rate: 0.00928308
	LOSS [training: 0.23712321455208257 | validation: 0.41206717122125736]
	TIME [epoch: 15.3 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2009064081509285		[learning rate: 0.0092421]
	Learning Rate: 0.00924207
	LOSS [training: 0.2009064081509285 | validation: 0.37171083209817357]
	TIME [epoch: 15.3 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23121264304747058		[learning rate: 0.0092012]
	Learning Rate: 0.00920124
	LOSS [training: 0.23121264304747058 | validation: 0.454153439404809]
	TIME [epoch: 15.3 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21314715313076155		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.21314715313076155 | validation: 0.3376845508468186]
	TIME [epoch: 15.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22693238630665533		[learning rate: 0.0091201]
	Learning Rate: 0.00912011
	LOSS [training: 0.22693238630665533 | validation: 0.43266464545658523]
	TIME [epoch: 15.3 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23356062799977545		[learning rate: 0.0090798]
	Learning Rate: 0.00907981
	LOSS [training: 0.23356062799977545 | validation: 0.3766917797065488]
	TIME [epoch: 15.3 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23486916575666045		[learning rate: 0.0090397]
	Learning Rate: 0.0090397
	LOSS [training: 0.23486916575666045 | validation: 0.3551769397675553]
	TIME [epoch: 15.3 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.238888312484262		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.238888312484262 | validation: 0.33410737581516425]
	TIME [epoch: 15.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20693913214138449		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.20693913214138449 | validation: 0.41074960335239763]
	TIME [epoch: 15.3 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21454245893452448		[learning rate: 0.0089204]
	Learning Rate: 0.00892041
	LOSS [training: 0.21454245893452448 | validation: 0.4217062633436625]
	TIME [epoch: 15.3 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21740672245672674		[learning rate: 0.008881]
	Learning Rate: 0.00888099
	LOSS [training: 0.21740672245672674 | validation: 0.3311064563698676]
	TIME [epoch: 15.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2552102588649078		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.2552102588649078 | validation: 0.37236668432948283]
	TIME [epoch: 15.3 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22361599633626633		[learning rate: 0.0088027]
	Learning Rate: 0.00880269
	LOSS [training: 0.22361599633626633 | validation: 0.333604289577804]
	TIME [epoch: 15.3 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23218564137179637		[learning rate: 0.0087638]
	Learning Rate: 0.0087638
	LOSS [training: 0.23218564137179637 | validation: 0.3167370814988951]
	TIME [epoch: 15.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20226407097507654		[learning rate: 0.0087251]
	Learning Rate: 0.00872508
	LOSS [training: 0.20226407097507654 | validation: 0.3577366807347991]
	TIME [epoch: 15.3 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21607997719765396		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.21607997719765396 | validation: 0.3276250786777293]
	TIME [epoch: 15.3 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22680908689642823		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.22680908689642823 | validation: 0.3503442430884716]
	TIME [epoch: 15.3 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22783540434768712		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 0.22783540434768712 | validation: 0.34232495169750743]
	TIME [epoch: 15.3 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20604275893007795		[learning rate: 0.0085719]
	Learning Rate: 0.0085719
	LOSS [training: 0.20604275893007795 | validation: 0.3366449400381623]
	TIME [epoch: 15.3 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20931509813108873		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.20931509813108873 | validation: 0.37655727895404]
	TIME [epoch: 15.3 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21920544237142936		[learning rate: 0.0084963]
	Learning Rate: 0.00849632
	LOSS [training: 0.21920544237142936 | validation: 0.34815083033208893]
	TIME [epoch: 15.3 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20970872923776884		[learning rate: 0.0084588]
	Learning Rate: 0.00845878
	LOSS [training: 0.20970872923776884 | validation: 0.35841947633267035]
	TIME [epoch: 15.3 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21785841909049036		[learning rate: 0.0084214]
	Learning Rate: 0.00842141
	LOSS [training: 0.21785841909049036 | validation: 0.4376694294481996]
	TIME [epoch: 15.3 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20889185334272825		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.20889185334272825 | validation: 0.3574794518082014]
	TIME [epoch: 15.3 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2212391173899122		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.2212391173899122 | validation: 0.3279062790524575]
	TIME [epoch: 15.3 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21320536074457083		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.21320536074457083 | validation: 0.32987422991999094]
	TIME [epoch: 15.3 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19703226787701755		[learning rate: 0.0082736]
	Learning Rate: 0.00827356
	LOSS [training: 0.19703226787701755 | validation: 0.5904268045905995]
	TIME [epoch: 15.3 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2241382133642979		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.2241382133642979 | validation: 0.3238417102192706]
	TIME [epoch: 15.3 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19453449835171568		[learning rate: 0.0082006]
	Learning Rate: 0.00820061
	LOSS [training: 0.19453449835171568 | validation: 0.3305714856066442]
	TIME [epoch: 15.4 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1907269624291807		[learning rate: 0.0081644]
	Learning Rate: 0.00816438
	LOSS [training: 0.1907269624291807 | validation: 0.30591986869275495]
	TIME [epoch: 15.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1995972526766679		[learning rate: 0.0081283]
	Learning Rate: 0.0081283
	LOSS [training: 0.1995972526766679 | validation: 0.3352301246419766]
	TIME [epoch: 15.3 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2205099514723142		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.2205099514723142 | validation: 0.3472762671700334]
	TIME [epoch: 15.3 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1975284327792438		[learning rate: 0.0080566]
	Learning Rate: 0.00805664
	LOSS [training: 0.1975284327792438 | validation: 0.3181345595772257]
	TIME [epoch: 15.3 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20147089646630345		[learning rate: 0.008021]
	Learning Rate: 0.00802104
	LOSS [training: 0.20147089646630345 | validation: 0.3124220595344982]
	TIME [epoch: 15.3 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2027649976736389		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.2027649976736389 | validation: 0.4221046758424371]
	TIME [epoch: 15.3 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20559726059370717		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.20559726059370717 | validation: 0.38132400488495716]
	TIME [epoch: 15.3 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2177021736995131		[learning rate: 0.0079152]
	Learning Rate: 0.00791519
	LOSS [training: 0.2177021736995131 | validation: 0.33709863434590825]
	TIME [epoch: 15.3 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21542604649974004		[learning rate: 0.0078802]
	Learning Rate: 0.00788022
	LOSS [training: 0.21542604649974004 | validation: 0.31275212705338]
	TIME [epoch: 15.3 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19511819102111683		[learning rate: 0.0078454]
	Learning Rate: 0.00784541
	LOSS [training: 0.19511819102111683 | validation: 0.334650872263777]
	TIME [epoch: 15.3 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21708602212358694		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.21708602212358694 | validation: 0.32702768838439517]
	TIME [epoch: 15.3 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19144950135892774		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.19144950135892774 | validation: 0.3591900882806153]
	TIME [epoch: 15.4 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19159829475135876		[learning rate: 0.0077419]
	Learning Rate: 0.00774188
	LOSS [training: 0.19159829475135876 | validation: 0.3228847724083924]
	TIME [epoch: 15.3 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2071791596447647		[learning rate: 0.0077077]
	Learning Rate: 0.00770767
	LOSS [training: 0.2071791596447647 | validation: 0.3845124592462812]
	TIME [epoch: 15.3 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20975270487148193		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.20975270487148193 | validation: 0.39963101784343824]
	TIME [epoch: 15.3 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22626105776131786		[learning rate: 0.0076397]
	Learning Rate: 0.00763971
	LOSS [training: 0.22626105776131786 | validation: 0.32029366633732487]
	TIME [epoch: 58.7 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18213475853479202		[learning rate: 0.007606]
	Learning Rate: 0.00760596
	LOSS [training: 0.18213475853479202 | validation: 0.32935684553751]
	TIME [epoch: 32.8 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18596948072566258		[learning rate: 0.0075724]
	Learning Rate: 0.00757235
	LOSS [training: 0.18596948072566258 | validation: 0.34275452113021937]
	TIME [epoch: 32.8 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22784554395805978		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.22784554395805978 | validation: 0.3392651172240504]
	TIME [epoch: 32.8 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2165472516312618		[learning rate: 0.0075056]
	Learning Rate: 0.00750559
	LOSS [training: 0.2165472516312618 | validation: 0.4934734547961466]
	TIME [epoch: 32.8 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2189391544910877		[learning rate: 0.0074724]
	Learning Rate: 0.00747242
	LOSS [training: 0.2189391544910877 | validation: 0.3278390578046906]
	TIME [epoch: 32.8 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18514586120245635		[learning rate: 0.0074394]
	Learning Rate: 0.00743941
	LOSS [training: 0.18514586120245635 | validation: 0.3006340473138021]
	TIME [epoch: 32.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18604569360089004		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.18604569360089004 | validation: 0.33214332292946885]
	TIME [epoch: 32.7 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18991010448982554		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.18991010448982554 | validation: 0.3200246431749439]
	TIME [epoch: 32.8 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2071444373500841		[learning rate: 0.0073412]
	Learning Rate: 0.00734124
	LOSS [training: 0.2071444373500841 | validation: 0.4438838860795465]
	TIME [epoch: 32.8 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1885333391494028		[learning rate: 0.0073088]
	Learning Rate: 0.0073088
	LOSS [training: 0.1885333391494028 | validation: 0.34262144300265257]
	TIME [epoch: 32.8 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17999099349716818		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.17999099349716818 | validation: 0.3625791705815267]
	TIME [epoch: 32.8 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18497391656767692		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.18497391656767692 | validation: 0.4206065211690073]
	TIME [epoch: 32.8 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2140112952835726		[learning rate: 0.0072124]
	Learning Rate: 0.00721235
	LOSS [training: 0.2140112952835726 | validation: 0.3385391533502132]
	TIME [epoch: 32.8 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20886329540451737		[learning rate: 0.0071805]
	Learning Rate: 0.00718049
	LOSS [training: 0.20886329540451737 | validation: 0.32320466248129676]
	TIME [epoch: 32.8 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2015925288224286		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.2015925288224286 | validation: 0.32560223210730804]
	TIME [epoch: 32.8 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17649269523186845		[learning rate: 0.0071172]
	Learning Rate: 0.00711718
	LOSS [training: 0.17649269523186845 | validation: 0.3159051083121342]
	TIME [epoch: 32.8 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19179779707010974		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.19179779707010974 | validation: 0.3790318398931779]
	TIME [epoch: 32.8 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19765501394760912		[learning rate: 0.0070544]
	Learning Rate: 0.00705442
	LOSS [training: 0.19765501394760912 | validation: 0.3109123113921354]
	TIME [epoch: 32.8 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18423842948063765		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.18423842948063765 | validation: 0.31995576003354304]
	TIME [epoch: 32.8 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18828576905102457		[learning rate: 0.0069922]
	Learning Rate: 0.00699222
	LOSS [training: 0.18828576905102457 | validation: 0.34878231251440656]
	TIME [epoch: 32.8 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18727626753635618		[learning rate: 0.0069613]
	Learning Rate: 0.00696133
	LOSS [training: 0.18727626753635618 | validation: 0.2963225357335154]
	TIME [epoch: 32.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_122.pth
	Model improved!!!
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1940665655413321		[learning rate: 0.0069306]
	Learning Rate: 0.00693057
	LOSS [training: 0.1940665655413321 | validation: 0.35019001722093446]
	TIME [epoch: 32.8 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18878109395938214		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.18878109395938214 | validation: 0.3020629663999974]
	TIME [epoch: 32.8 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18592701451503665		[learning rate: 0.0068695]
	Learning Rate: 0.00686947
	LOSS [training: 0.18592701451503665 | validation: 0.3143109056606613]
	TIME [epoch: 32.8 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1933527594585454		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.1933527594585454 | validation: 0.32120122523031913]
	TIME [epoch: 32.8 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17500475895293927		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.17500475895293927 | validation: 0.3184012050463391]
	TIME [epoch: 32.8 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19680037582557489		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.19680037582557489 | validation: 0.37860171624682204]
	TIME [epoch: 32.8 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19687685280287243		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.19687685280287243 | validation: 0.32356366569389977]
	TIME [epoch: 32.8 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17660112463874847		[learning rate: 0.006719]
	Learning Rate: 0.00671905
	LOSS [training: 0.17660112463874847 | validation: 0.30756344234349653]
	TIME [epoch: 32.8 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1790554082837805		[learning rate: 0.0066894]
	Learning Rate: 0.00668936
	LOSS [training: 0.1790554082837805 | validation: 0.2993180128154194]
	TIME [epoch: 32.8 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18229444408948842		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.18229444408948842 | validation: 0.3884483738543981]
	TIME [epoch: 32.8 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1869576296277397		[learning rate: 0.0066304]
	Learning Rate: 0.00663038
	LOSS [training: 0.1869576296277397 | validation: 0.37981664798015513]
	TIME [epoch: 32.8 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18750129144814676		[learning rate: 0.0066011]
	Learning Rate: 0.00660109
	LOSS [training: 0.18750129144814676 | validation: 0.35084761969242517]
	TIME [epoch: 32.8 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18360691948640595		[learning rate: 0.0065719]
	Learning Rate: 0.00657192
	LOSS [training: 0.18360691948640595 | validation: 0.3343729561331936]
	TIME [epoch: 32.8 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19289771405439327		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.19289771405439327 | validation: 0.33064264176464603]
	TIME [epoch: 32.8 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19740924362129048		[learning rate: 0.006514]
	Learning Rate: 0.00651398
	LOSS [training: 0.19740924362129048 | validation: 0.30637222271176934]
	TIME [epoch: 32.8 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18303398730837706		[learning rate: 0.0064852]
	Learning Rate: 0.00648519
	LOSS [training: 0.18303398730837706 | validation: 0.31921883610137614]
	TIME [epoch: 32.8 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1738730008400422		[learning rate: 0.0064565]
	Learning Rate: 0.00645654
	LOSS [training: 0.1738730008400422 | validation: 0.3384010465420022]
	TIME [epoch: 32.8 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18373479945276644		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.18373479945276644 | validation: 0.370697268662177]
	TIME [epoch: 32.8 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1966004755161332		[learning rate: 0.0063996]
	Learning Rate: 0.00639961
	LOSS [training: 0.1966004755161332 | validation: 0.3356052480408602]
	TIME [epoch: 32.8 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2009152805378646		[learning rate: 0.0063713]
	Learning Rate: 0.00637134
	LOSS [training: 0.2009152805378646 | validation: 0.36225295467227214]
	TIME [epoch: 32.8 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20128719574336112		[learning rate: 0.0063432]
	Learning Rate: 0.00634319
	LOSS [training: 0.20128719574336112 | validation: 0.31060246631710675]
	TIME [epoch: 32.8 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17915161588883033		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.17915161588883033 | validation: 0.36223312906678484]
	TIME [epoch: 32.8 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19852160411379766		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.19852160411379766 | validation: 0.3727449610366685]
	TIME [epoch: 32.8 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17605479791105733		[learning rate: 0.0062595]
	Learning Rate: 0.00625948
	LOSS [training: 0.17605479791105733 | validation: 0.36908428741366944]
	TIME [epoch: 32.8 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18382151545784456		[learning rate: 0.0062318]
	Learning Rate: 0.00623183
	LOSS [training: 0.18382151545784456 | validation: 0.31395448803842413]
	TIME [epoch: 32.8 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17654612408325174		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.17654612408325174 | validation: 0.3266096970306461]
	TIME [epoch: 32.7 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17454225058782832		[learning rate: 0.0061769]
	Learning Rate: 0.00617688
	LOSS [training: 0.17454225058782832 | validation: 0.3360110235210028]
	TIME [epoch: 32.8 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19480651571090885		[learning rate: 0.0061496]
	Learning Rate: 0.00614959
	LOSS [training: 0.19480651571090885 | validation: 0.3169031019135437]
	TIME [epoch: 32.8 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19239448404351625		[learning rate: 0.0061224]
	Learning Rate: 0.00612242
	LOSS [training: 0.19239448404351625 | validation: 0.2961055096242677]
	TIME [epoch: 32.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1746482656337765		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.1746482656337765 | validation: 0.38593714243276594]
	TIME [epoch: 32.8 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18305705083039792		[learning rate: 0.0060684]
	Learning Rate: 0.00606844
	LOSS [training: 0.18305705083039792 | validation: 0.3119763551219099]
	TIME [epoch: 32.8 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18160888972216935		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.18160888972216935 | validation: 0.2960177247444552]
	TIME [epoch: 32.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_154.pth
	Model improved!!!
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1870158694874685		[learning rate: 0.0060149]
	Learning Rate: 0.00601493
	LOSS [training: 0.1870158694874685 | validation: 0.29313945245920137]
	TIME [epoch: 32.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_155.pth
	Model improved!!!
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17429904773988852		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.17429904773988852 | validation: 0.4292788235011119]
	TIME [epoch: 32.7 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.181954689889933		[learning rate: 0.0059619]
	Learning Rate: 0.0059619
	LOSS [training: 0.181954689889933 | validation: 0.28284183765633375]
	TIME [epoch: 32.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_157.pth
	Model improved!!!
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1800425043766353		[learning rate: 0.0059356]
	Learning Rate: 0.00593556
	LOSS [training: 0.1800425043766353 | validation: 0.3430845789824167]
	TIME [epoch: 32.8 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17737881225337276		[learning rate: 0.0059093]
	Learning Rate: 0.00590933
	LOSS [training: 0.17737881225337276 | validation: 0.3379848941826112]
	TIME [epoch: 32.8 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1756513013525405		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.1756513013525405 | validation: 0.3951834846090421]
	TIME [epoch: 32.8 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1849330487810783		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.1849330487810783 | validation: 0.36736646295837067]
	TIME [epoch: 32.8 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17363878442394517		[learning rate: 0.0058314]
	Learning Rate: 0.00583135
	LOSS [training: 0.17363878442394517 | validation: 0.34444634462746554]
	TIME [epoch: 32.8 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17577005585011066		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.17577005585011066 | validation: 0.32207670522139364]
	TIME [epoch: 32.8 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17818695973668577		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.17818695973668577 | validation: 0.2818502069224336]
	TIME [epoch: 32.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_164.pth
	Model improved!!!
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19198761953740093		[learning rate: 0.0057544]
	Learning Rate: 0.0057544
	LOSS [training: 0.19198761953740093 | validation: 0.2858543159217529]
	TIME [epoch: 32.7 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18411634977113053		[learning rate: 0.005729]
	Learning Rate: 0.00572897
	LOSS [training: 0.18411634977113053 | validation: 0.3137034736358157]
	TIME [epoch: 32.8 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17774759843173205		[learning rate: 0.0057037]
	Learning Rate: 0.00570366
	LOSS [training: 0.17774759843173205 | validation: 0.29948880362265856]
	TIME [epoch: 32.8 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17027882883738438		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.17027882883738438 | validation: 0.3088749164731842]
	TIME [epoch: 32.7 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1739096488654915		[learning rate: 0.0056534]
	Learning Rate: 0.00565337
	LOSS [training: 0.1739096488654915 | validation: 0.30383962188174574]
	TIME [epoch: 32.7 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17954289593501255		[learning rate: 0.0056284]
	Learning Rate: 0.0056284
	LOSS [training: 0.17954289593501255 | validation: 0.3638066703145151]
	TIME [epoch: 32.7 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1765552328751935		[learning rate: 0.0056035]
	Learning Rate: 0.00560353
	LOSS [training: 0.1765552328751935 | validation: 0.3294874392688626]
	TIME [epoch: 32.8 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17672705945451664		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.17672705945451664 | validation: 0.29339783451155615]
	TIME [epoch: 32.7 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16815382493946313		[learning rate: 0.0055541]
	Learning Rate: 0.00555412
	LOSS [training: 0.16815382493946313 | validation: 0.3401286253362115]
	TIME [epoch: 32.9 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18207695220887574		[learning rate: 0.0055296]
	Learning Rate: 0.00552958
	LOSS [training: 0.18207695220887574 | validation: 0.3215542405334083]
	TIME [epoch: 32.8 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18579356810622358		[learning rate: 0.0055052]
	Learning Rate: 0.00550515
	LOSS [training: 0.18579356810622358 | validation: 0.31007586808611276]
	TIME [epoch: 32.8 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16809776310182856		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.16809776310182856 | validation: 0.30845273248967586]
	TIME [epoch: 32.8 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1785683783298277		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.1785683783298277 | validation: 0.2927181299067438]
	TIME [epoch: 32.8 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18471711157236942		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.18471711157236942 | validation: 0.2872001707479589]
	TIME [epoch: 32.8 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17107600160237063		[learning rate: 0.0054085]
	Learning Rate: 0.0054085
	LOSS [training: 0.17107600160237063 | validation: 0.28845398094937413]
	TIME [epoch: 32.8 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19833429452621068		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.19833429452621068 | validation: 0.3265136980480109]
	TIME [epoch: 32.8 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17224013495382184		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.17224013495382184 | validation: 0.3277755908747057]
	TIME [epoch: 32.8 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17615852706389132		[learning rate: 0.0053371]
	Learning Rate: 0.00533713
	LOSS [training: 0.17615852706389132 | validation: 0.2863777676675389]
	TIME [epoch: 32.8 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16955616457574613		[learning rate: 0.0053135]
	Learning Rate: 0.00531355
	LOSS [training: 0.16955616457574613 | validation: 0.328465128165158]
	TIME [epoch: 32.8 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17053187590111557		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.17053187590111557 | validation: 0.3097748004696755]
	TIME [epoch: 32.8 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16849673030277856		[learning rate: 0.0052667]
	Learning Rate: 0.0052667
	LOSS [training: 0.16849673030277856 | validation: 0.3666363041144791]
	TIME [epoch: 32.8 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1797180481469118		[learning rate: 0.0052434]
	Learning Rate: 0.00524343
	LOSS [training: 0.1797180481469118 | validation: 0.28697255544863837]
	TIME [epoch: 32.8 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16765367148795662		[learning rate: 0.0052203]
	Learning Rate: 0.00522026
	LOSS [training: 0.16765367148795662 | validation: 0.29816419342071715]
	TIME [epoch: 32.8 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1781970047886766		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.1781970047886766 | validation: 0.283769682532295]
	TIME [epoch: 32.8 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16554222366608554		[learning rate: 0.0051742]
	Learning Rate: 0.00517423
	LOSS [training: 0.16554222366608554 | validation: 0.31019958852339]
	TIME [epoch: 32.8 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16612385570151997		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.16612385570151997 | validation: 0.335801279046571]
	TIME [epoch: 32.8 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19234676464244604		[learning rate: 0.0051286]
	Learning Rate: 0.00512861
	LOSS [training: 0.19234676464244604 | validation: 0.320728427081147]
	TIME [epoch: 32.9 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17316879458725926		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.17316879458725926 | validation: 0.32511703484022936]
	TIME [epoch: 32.8 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18118182057121954		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.18118182057121954 | validation: 0.2990634355561771]
	TIME [epoch: 32.8 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1724746056677368		[learning rate: 0.0050609]
	Learning Rate: 0.00506093
	LOSS [training: 0.1724746056677368 | validation: 0.28264408155115933]
	TIME [epoch: 32.8 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16854257124243438		[learning rate: 0.0050386]
	Learning Rate: 0.00503857
	LOSS [training: 0.16854257124243438 | validation: 0.31532120805456665]
	TIME [epoch: 32.8 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16254120702453742		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.16254120702453742 | validation: 0.2989387252906701]
	TIME [epoch: 32.8 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1713661980058096		[learning rate: 0.0049941]
	Learning Rate: 0.00499415
	LOSS [training: 0.1713661980058096 | validation: 0.31839311396470615]
	TIME [epoch: 32.7 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16089118640064023		[learning rate: 0.0049721]
	Learning Rate: 0.00497208
	LOSS [training: 0.16089118640064023 | validation: 0.31211935676485447]
	TIME [epoch: 32.8 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17257345364275173		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.17257345364275173 | validation: 0.2812153180697414]
	TIME [epoch: 32.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_199.pth
	Model improved!!!
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16865904155646994		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.16865904155646994 | validation: 0.30001363612038917]
	TIME [epoch: 32.7 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16223776924451871		[learning rate: 0.0049065]
	Learning Rate: 0.00490647
	LOSS [training: 0.16223776924451871 | validation: 0.3210383793325323]
	TIME [epoch: 95.7 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16548107526985334		[learning rate: 0.0048848]
	Learning Rate: 0.00488479
	LOSS [training: 0.16548107526985334 | validation: 0.3119934973147566]
	TIME [epoch: 69.5 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18405243358977072		[learning rate: 0.0048632]
	Learning Rate: 0.00486321
	LOSS [training: 0.18405243358977072 | validation: 0.27866832584001644]
	TIME [epoch: 69.5 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_203.pth
	Model improved!!!
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16725288293064502		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.16725288293064502 | validation: 0.3091975499150031]
	TIME [epoch: 69.1 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16328554977014126		[learning rate: 0.0048203]
	Learning Rate: 0.00482033
	LOSS [training: 0.16328554977014126 | validation: 0.32365847327899777]
	TIME [epoch: 69.2 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1744472517316025		[learning rate: 0.004799]
	Learning Rate: 0.00479903
	LOSS [training: 0.1744472517316025 | validation: 0.31143531679478476]
	TIME [epoch: 69.1 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17021464655730717		[learning rate: 0.0047778]
	Learning Rate: 0.00477783
	LOSS [training: 0.17021464655730717 | validation: 0.3379774501013137]
	TIME [epoch: 69.2 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.179783910984384		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.179783910984384 | validation: 0.30410572898143523]
	TIME [epoch: 69.2 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16642573302720393		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.16642573302720393 | validation: 0.28995862293715685]
	TIME [epoch: 69.2 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17100586049870717		[learning rate: 0.0047148]
	Learning Rate: 0.00471478
	LOSS [training: 0.17100586049870717 | validation: 0.3911285255270717]
	TIME [epoch: 69.2 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16338151516354574		[learning rate: 0.0046939]
	Learning Rate: 0.00469395
	LOSS [training: 0.16338151516354574 | validation: 0.31350426750372445]
	TIME [epoch: 69.3 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1821700506046711		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.1821700506046711 | validation: 0.2971726614063705]
	TIME [epoch: 69.2 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18126756099743843		[learning rate: 0.0046526]
	Learning Rate: 0.00465256
	LOSS [training: 0.18126756099743843 | validation: 0.30914975888183865]
	TIME [epoch: 69.2 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17459240446275764		[learning rate: 0.004632]
	Learning Rate: 0.00463201
	LOSS [training: 0.17459240446275764 | validation: 0.3402603603244009]
	TIME [epoch: 69.2 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1702094429861441		[learning rate: 0.0046115]
	Learning Rate: 0.00461154
	LOSS [training: 0.1702094429861441 | validation: 0.29555162526049517]
	TIME [epoch: 69.3 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17503863964742022		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.17503863964742022 | validation: 0.295973055500186]
	TIME [epoch: 69.1 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15843475695416592		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.15843475695416592 | validation: 0.33193910710686103]
	TIME [epoch: 69.2 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15965953769688462		[learning rate: 0.0045507]
	Learning Rate: 0.00455069
	LOSS [training: 0.15965953769688462 | validation: 0.32722301759285854]
	TIME [epoch: 69.1 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1626750150892742		[learning rate: 0.0045306]
	Learning Rate: 0.00453058
	LOSS [training: 0.1626750150892742 | validation: 0.2881176060027084]
	TIME [epoch: 69.3 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16680958309286473		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.16680958309286473 | validation: 0.28941888561357143]
	TIME [epoch: 69 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16822496474408113		[learning rate: 0.0044906]
	Learning Rate: 0.00449063
	LOSS [training: 0.16822496474408113 | validation: 0.28517563840719273]
	TIME [epoch: 69.2 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17323937759350755		[learning rate: 0.0044708]
	Learning Rate: 0.00447079
	LOSS [training: 0.17323937759350755 | validation: 0.2942284133293648]
	TIME [epoch: 69.2 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16116747259660952		[learning rate: 0.004451]
	Learning Rate: 0.00445104
	LOSS [training: 0.16116747259660952 | validation: 0.27734275100373107]
	TIME [epoch: 69.2 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_223.pth
	Model improved!!!
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15978329458573273		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.15978329458573273 | validation: 0.28469808777629757]
	TIME [epoch: 69.4 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17185510676600085		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.17185510676600085 | validation: 0.33413144544812534]
	TIME [epoch: 69.4 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18133128915814117		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.18133128915814117 | validation: 0.30471186036267994]
	TIME [epoch: 69.5 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.165606977407822		[learning rate: 0.0043729]
	Learning Rate: 0.0043729
	LOSS [training: 0.165606977407822 | validation: 0.2740031825256111]
	TIME [epoch: 69.4 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_227.pth
	Model improved!!!
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17003210446453929		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.17003210446453929 | validation: 0.27854044686545804]
	TIME [epoch: 69.3 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1622674013436417		[learning rate: 0.0043343]
	Learning Rate: 0.00433434
	LOSS [training: 0.1622674013436417 | validation: 0.29257926831003905]
	TIME [epoch: 69.3 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1657145761123969		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 0.1657145761123969 | validation: 0.2817106566754625]
	TIME [epoch: 69.4 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16740879489500418		[learning rate: 0.0042961]
	Learning Rate: 0.00429612
	LOSS [training: 0.16740879489500418 | validation: 0.3335658957476946]
	TIME [epoch: 69.3 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16729772993234		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.16729772993234 | validation: 0.30819982851378513]
	TIME [epoch: 69.2 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1657721857457442		[learning rate: 0.0042582]
	Learning Rate: 0.00425825
	LOSS [training: 0.1657721857457442 | validation: 0.27274953540243774]
	TIME [epoch: 69.4 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_233.pth
	Model improved!!!
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1714155051906044		[learning rate: 0.0042394]
	Learning Rate: 0.00423943
	LOSS [training: 0.1714155051906044 | validation: 0.2788332763451874]
	TIME [epoch: 69.4 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16356181704981482		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.16356181704981482 | validation: 0.2831348257749046]
	TIME [epoch: 69.4 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15591167702291667		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.15591167702291667 | validation: 0.2843775074708]
	TIME [epoch: 69.4 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15961358395133654		[learning rate: 0.0041835]
	Learning Rate: 0.00418349
	LOSS [training: 0.15961358395133654 | validation: 0.27687136558277453]
	TIME [epoch: 69.5 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17047477041131004		[learning rate: 0.004165]
	Learning Rate: 0.004165
	LOSS [training: 0.17047477041131004 | validation: 0.3126925197897999]
	TIME [epoch: 69.5 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17783124450555626		[learning rate: 0.0041466]
	Learning Rate: 0.0041466
	LOSS [training: 0.17783124450555626 | validation: 0.32319684755958383]
	TIME [epoch: 69.4 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16011355339194253		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.16011355339194253 | validation: 0.31735817901154767]
	TIME [epoch: 69.4 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1716731151052322		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.1716731151052322 | validation: 0.3497509712154017]
	TIME [epoch: 69.4 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.171179825712908		[learning rate: 0.0040919]
	Learning Rate: 0.00409188
	LOSS [training: 0.171179825712908 | validation: 0.27142846850270175]
	TIME [epoch: 69.5 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_242.pth
	Model improved!!!
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16007653936437974		[learning rate: 0.0040738]
	Learning Rate: 0.0040738
	LOSS [training: 0.16007653936437974 | validation: 0.29799152075821345]
	TIME [epoch: 69.2 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15724652353524868		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.15724652353524868 | validation: 0.30137057080210927]
	TIME [epoch: 69.2 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16354124733366104		[learning rate: 0.0040379]
	Learning Rate: 0.00403788
	LOSS [training: 0.16354124733366104 | validation: 0.28116507891785875]
	TIME [epoch: 69.1 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1692365803218618		[learning rate: 0.00402]
	Learning Rate: 0.00402004
	LOSS [training: 0.1692365803218618 | validation: 0.307060113471525]
	TIME [epoch: 69.1 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15880257673571263		[learning rate: 0.0040023]
	Learning Rate: 0.00400228
	LOSS [training: 0.15880257673571263 | validation: 0.30663968931658203]
	TIME [epoch: 69 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1604481638420235		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.1604481638420235 | validation: 0.2907319486121733]
	TIME [epoch: 69 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16665038443654062		[learning rate: 0.003967]
	Learning Rate: 0.00396699
	LOSS [training: 0.16665038443654062 | validation: 0.2760687487954321]
	TIME [epoch: 69.1 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1612207769762684		[learning rate: 0.0039495]
	Learning Rate: 0.00394947
	LOSS [training: 0.1612207769762684 | validation: 0.2840353809018379]
	TIME [epoch: 69.1 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16110786013676356		[learning rate: 0.003932]
	Learning Rate: 0.00393202
	LOSS [training: 0.16110786013676356 | validation: 0.274490198127201]
	TIME [epoch: 69.1 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16694160001690414		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.16694160001690414 | validation: 0.28560871866828186]
	TIME [epoch: 69 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16606858122586837		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.16606858122586837 | validation: 0.2821764548783465]
	TIME [epoch: 69 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1592364677582015		[learning rate: 0.0038801]
	Learning Rate: 0.00388013
	LOSS [training: 0.1592364677582015 | validation: 0.29912201148221457]
	TIME [epoch: 69.1 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16224804085068253		[learning rate: 0.003863]
	Learning Rate: 0.00386299
	LOSS [training: 0.16224804085068253 | validation: 0.33455311530698284]
	TIME [epoch: 69.2 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16408977240571532		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.16408977240571532 | validation: 0.29733965404494805]
	TIME [epoch: 69.2 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1639604976606734		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.1639604976606734 | validation: 0.29014505981510474]
	TIME [epoch: 69.1 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15796447085026033		[learning rate: 0.003812]
	Learning Rate: 0.00381201
	LOSS [training: 0.15796447085026033 | validation: 0.3319228567440497]
	TIME [epoch: 69.1 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1638658590711224		[learning rate: 0.0037952]
	Learning Rate: 0.00379517
	LOSS [training: 0.1638658590711224 | validation: 0.28224578964426283]
	TIME [epoch: 69.1 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16707334713346714		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.16707334713346714 | validation: 0.2944118966338352]
	TIME [epoch: 69.2 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15802890074866918		[learning rate: 0.0037617]
	Learning Rate: 0.0037617
	LOSS [training: 0.15802890074866918 | validation: 0.2766841813660942]
	TIME [epoch: 69.1 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15303765986462298		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.15303765986462298 | validation: 0.32536677396369595]
	TIME [epoch: 69.2 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16806397966206343		[learning rate: 0.0037285]
	Learning Rate: 0.00372854
	LOSS [training: 0.16806397966206343 | validation: 0.30983781987856013]
	TIME [epoch: 69.2 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16212375768036363		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.16212375768036363 | validation: 0.3111220726192199]
	TIME [epoch: 69.2 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17498882940560795		[learning rate: 0.0036957]
	Learning Rate: 0.00369566
	LOSS [training: 0.17498882940560795 | validation: 0.2844612020657456]
	TIME [epoch: 69.1 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15934633349905664		[learning rate: 0.0036793]
	Learning Rate: 0.00367933
	LOSS [training: 0.15934633349905664 | validation: 0.2904372075067535]
	TIME [epoch: 69.2 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15778932486696662		[learning rate: 0.0036631]
	Learning Rate: 0.00366308
	LOSS [training: 0.15778932486696662 | validation: 0.316960711577379]
	TIME [epoch: 69.1 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1629659153366301		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.1629659153366301 | validation: 0.28400487393294627]
	TIME [epoch: 69.1 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17279589252395572		[learning rate: 0.0036308]
	Learning Rate: 0.00363078
	LOSS [training: 0.17279589252395572 | validation: 0.285184179919823]
	TIME [epoch: 69.2 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15950002918630773		[learning rate: 0.0036147]
	Learning Rate: 0.00361474
	LOSS [training: 0.15950002918630773 | validation: 0.31420870396949657]
	TIME [epoch: 69.1 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15507748657575915		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.15507748657575915 | validation: 0.2952337164966838]
	TIME [epoch: 69.1 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15781843980184146		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.15781843980184146 | validation: 0.32575014125864976]
	TIME [epoch: 69.1 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16498536440525183		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.16498536440525183 | validation: 0.27831399627461295]
	TIME [epoch: 69.1 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1582737184832373		[learning rate: 0.0035513]
	Learning Rate: 0.00355128
	LOSS [training: 0.1582737184832373 | validation: 0.3021409480108317]
	TIME [epoch: 69 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16888656950125994		[learning rate: 0.0035356]
	Learning Rate: 0.00353559
	LOSS [training: 0.16888656950125994 | validation: 0.2993547435716241]
	TIME [epoch: 69.2 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1723459020421743		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.1723459020421743 | validation: 0.28989325821071416]
	TIME [epoch: 69.1 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17199072980870528		[learning rate: 0.0035044]
	Learning Rate: 0.00350441
	LOSS [training: 0.17199072980870528 | validation: 0.31301875679752017]
	TIME [epoch: 69.2 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.160667199961512		[learning rate: 0.0034889]
	Learning Rate: 0.00348893
	LOSS [training: 0.160667199961512 | validation: 0.30266904460471633]
	TIME [epoch: 69 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15837587627559857		[learning rate: 0.0034735]
	Learning Rate: 0.00347352
	LOSS [training: 0.15837587627559857 | validation: 0.30903838623405644]
	TIME [epoch: 69.1 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16581211816550465		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.16581211816550465 | validation: 0.3294849953191664]
	TIME [epoch: 69.2 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15783933346162474		[learning rate: 0.0034429]
	Learning Rate: 0.00344289
	LOSS [training: 0.15783933346162474 | validation: 0.3004951611466998]
	TIME [epoch: 69.2 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15988902898663246		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 0.15988902898663246 | validation: 0.3126954287900646]
	TIME [epoch: 69.1 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16753342168636778		[learning rate: 0.0034125]
	Learning Rate: 0.00341253
	LOSS [training: 0.16753342168636778 | validation: 0.318537045759422]
	TIME [epoch: 69.1 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1584748701121072		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.1584748701121072 | validation: 0.3288315392670666]
	TIME [epoch: 69 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15733783394889939		[learning rate: 0.0033824]
	Learning Rate: 0.00338245
	LOSS [training: 0.15733783394889939 | validation: 0.3131256408238748]
	TIME [epoch: 69.2 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1619097144296817		[learning rate: 0.0033675]
	Learning Rate: 0.0033675
	LOSS [training: 0.1619097144296817 | validation: 0.27273974114388033]
	TIME [epoch: 69.1 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16183974830159165		[learning rate: 0.0033526]
	Learning Rate: 0.00335262
	LOSS [training: 0.16183974830159165 | validation: 0.2943111001518707]
	TIME [epoch: 69.2 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15837003822699972		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.15837003822699972 | validation: 0.28565405457863147]
	TIME [epoch: 69.1 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15871305372472447		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.15871305372472447 | validation: 0.29177786049694937]
	TIME [epoch: 69.2 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1547007108647049		[learning rate: 0.0033084]
	Learning Rate: 0.00330838
	LOSS [training: 0.1547007108647049 | validation: 0.3042540398695834]
	TIME [epoch: 69.1 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1602359842003474		[learning rate: 0.0032938]
	Learning Rate: 0.00329376
	LOSS [training: 0.1602359842003474 | validation: 0.2953916189018348]
	TIME [epoch: 69.2 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1613573790884217		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.1613573790884217 | validation: 0.29659662977129214]
	TIME [epoch: 69.2 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15638874539463463		[learning rate: 0.0032647]
	Learning Rate: 0.00326472
	LOSS [training: 0.15638874539463463 | validation: 0.2811406166132121]
	TIME [epoch: 69.4 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15759121773754525		[learning rate: 0.0032503]
	Learning Rate: 0.0032503
	LOSS [training: 0.15759121773754525 | validation: 0.3211992882745069]
	TIME [epoch: 69 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15650737368052792		[learning rate: 0.0032359]
	Learning Rate: 0.00323594
	LOSS [training: 0.15650737368052792 | validation: 0.3051705511054111]
	TIME [epoch: 69.1 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16562739835184967		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.16562739835184967 | validation: 0.2814887977935669]
	TIME [epoch: 69 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.159885313740641		[learning rate: 0.0032074]
	Learning Rate: 0.00320741
	LOSS [training: 0.159885313740641 | validation: 0.3135882742093807]
	TIME [epoch: 69.3 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15941233852879114		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.15941233852879114 | validation: 0.30564964370118036]
	TIME [epoch: 69.1 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16589027763785485		[learning rate: 0.0031791]
	Learning Rate: 0.00317913
	LOSS [training: 0.16589027763785485 | validation: 0.3265229746743923]
	TIME [epoch: 69.2 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16019458649485677		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.16019458649485677 | validation: 0.29838596778688253]
	TIME [epoch: 69.3 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16778509403916964		[learning rate: 0.0031511]
	Learning Rate: 0.0031511
	LOSS [training: 0.16778509403916964 | validation: 0.2793656835823612]
	TIME [epoch: 168 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.163119895866677		[learning rate: 0.0031372]
	Learning Rate: 0.00313717
	LOSS [training: 0.163119895866677 | validation: 0.303912740879888]
	TIME [epoch: 143 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16058046585889146		[learning rate: 0.0031233]
	Learning Rate: 0.00312331
	LOSS [training: 0.16058046585889146 | validation: 0.2941732851300948]
	TIME [epoch: 143 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15644577559995262		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.15644577559995262 | validation: 0.2915226271764472]
	TIME [epoch: 143 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16389972308697254		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.16389972308697254 | validation: 0.2857211982001085]
	TIME [epoch: 143 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.158831958233613		[learning rate: 0.0030821]
	Learning Rate: 0.0030821
	LOSS [training: 0.158831958233613 | validation: 0.2734679616898097]
	TIME [epoch: 142 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15647707612402362		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.15647707612402362 | validation: 0.2927097749481361]
	TIME [epoch: 143 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15790227786481403		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.15790227786481403 | validation: 0.29898472928925574]
	TIME [epoch: 143 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15750160368451796		[learning rate: 0.0030414]
	Learning Rate: 0.00304142
	LOSS [training: 0.15750160368451796 | validation: 0.2835416623760202]
	TIME [epoch: 143 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1630248065313719		[learning rate: 0.003028]
	Learning Rate: 0.00302799
	LOSS [training: 0.1630248065313719 | validation: 0.2962008025493487]
	TIME [epoch: 142 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15584974822683068		[learning rate: 0.0030146]
	Learning Rate: 0.00301461
	LOSS [training: 0.15584974822683068 | validation: 0.2841291518864157]
	TIME [epoch: 143 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16003014087118464		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.16003014087118464 | validation: 0.2957475545346444]
	TIME [epoch: 143 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15633459110657363		[learning rate: 0.002988]
	Learning Rate: 0.00298803
	LOSS [training: 0.15633459110657363 | validation: 0.2995553070327977]
	TIME [epoch: 143 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15498461647263548		[learning rate: 0.0029748]
	Learning Rate: 0.00297483
	LOSS [training: 0.15498461647263548 | validation: 0.31250800684079505]
	TIME [epoch: 143 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15950618643652145		[learning rate: 0.0029617]
	Learning Rate: 0.00296168
	LOSS [training: 0.15950618643652145 | validation: 0.3152773069345547]
	TIME [epoch: 143 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15356375525778757		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.15356375525778757 | validation: 0.27378726927582087]
	TIME [epoch: 143 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15266900258611066		[learning rate: 0.0029356]
	Learning Rate: 0.00293557
	LOSS [training: 0.15266900258611066 | validation: 0.28193927941652747]
	TIME [epoch: 143 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1628433493441052		[learning rate: 0.0029226]
	Learning Rate: 0.0029226
	LOSS [training: 0.1628433493441052 | validation: 0.29397037044488367]
	TIME [epoch: 142 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15862153880259286		[learning rate: 0.0029097]
	Learning Rate: 0.00290969
	LOSS [training: 0.15862153880259286 | validation: 0.3146220133345714]
	TIME [epoch: 143 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16085905019012087		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.16085905019012087 | validation: 0.2938118238157553]
	TIME [epoch: 143 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15844304763080075		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.15844304763080075 | validation: 0.31103675618881377]
	TIME [epoch: 142 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15403631469124263		[learning rate: 0.0028713]
	Learning Rate: 0.00287129
	LOSS [training: 0.15403631469124263 | validation: 0.28869093479091296]
	TIME [epoch: 142 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1556794724258189		[learning rate: 0.0028586]
	Learning Rate: 0.0028586
	LOSS [training: 0.1556794724258189 | validation: 0.29274410315028904]
	TIME [epoch: 142 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15123483223612882		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.15123483223612882 | validation: 0.284268528487322]
	TIME [epoch: 142 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15552742374659448		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.15552742374659448 | validation: 0.28784580409016103]
	TIME [epoch: 143 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16370827577724645		[learning rate: 0.0028209]
	Learning Rate: 0.00282088
	LOSS [training: 0.16370827577724645 | validation: 0.28542660297613587]
	TIME [epoch: 143 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15974236829774147		[learning rate: 0.0028084]
	Learning Rate: 0.00280842
	LOSS [training: 0.15974236829774147 | validation: 0.26862060443993996]
	TIME [epoch: 143 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_327.pth
	Model improved!!!
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1589481707754289		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.1589481707754289 | validation: 0.2942274598990207]
	TIME [epoch: 142 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15881834869540398		[learning rate: 0.0027837]
	Learning Rate: 0.00278366
	LOSS [training: 0.15881834869540398 | validation: 0.292032155741275]
	TIME [epoch: 142 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15382069132124299		[learning rate: 0.0027714]
	Learning Rate: 0.00277136
	LOSS [training: 0.15382069132124299 | validation: 0.30390841289674875]
	TIME [epoch: 142 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15636542753835658		[learning rate: 0.0027591]
	Learning Rate: 0.00275911
	LOSS [training: 0.15636542753835658 | validation: 0.309062436838225]
	TIME [epoch: 142 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15740310577901628		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.15740310577901628 | validation: 0.3037851257893086]
	TIME [epoch: 143 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15790221818469372		[learning rate: 0.0027348]
	Learning Rate: 0.00273478
	LOSS [training: 0.15790221818469372 | validation: 0.2989844321190531]
	TIME [epoch: 142 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1592493677721491		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.1592493677721491 | validation: 0.27824940386283886]
	TIME [epoch: 142 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15556163411260765		[learning rate: 0.0027107]
	Learning Rate: 0.00271067
	LOSS [training: 0.15556163411260765 | validation: 0.28949673082001803]
	TIME [epoch: 142 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15596060271142162		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.15596060271142162 | validation: 0.2987504418396752]
	TIME [epoch: 143 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15670100890920866		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.15670100890920866 | validation: 0.29733597636643394]
	TIME [epoch: 143 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1585455257221861		[learning rate: 0.0026749]
	Learning Rate: 0.0026749
	LOSS [training: 0.1585455257221861 | validation: 0.2906725252624743]
	TIME [epoch: 143 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15271176445957854		[learning rate: 0.0026631]
	Learning Rate: 0.00266308
	LOSS [training: 0.15271176445957854 | validation: 0.31627533387924006]
	TIME [epoch: 142 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1564106574049529		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.1564106574049529 | validation: 0.29298596122202575]
	TIME [epoch: 142 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15981451182248232		[learning rate: 0.0026396]
	Learning Rate: 0.0026396
	LOSS [training: 0.15981451182248232 | validation: 0.3071260992948144]
	TIME [epoch: 142 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15942933305098933		[learning rate: 0.0026279]
	Learning Rate: 0.00262794
	LOSS [training: 0.15942933305098933 | validation: 0.2945030271965066]
	TIME [epoch: 142 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1608222599784981		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.1608222599784981 | validation: 0.2899794890571734]
	TIME [epoch: 143 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15918843813009723		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.15918843813009723 | validation: 0.28863935565709353]
	TIME [epoch: 142 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16099899084182445		[learning rate: 0.0025933]
	Learning Rate: 0.00259326
	LOSS [training: 0.16099899084182445 | validation: 0.30531287890629616]
	TIME [epoch: 142 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1532912285475166		[learning rate: 0.0025818]
	Learning Rate: 0.0025818
	LOSS [training: 0.1532912285475166 | validation: 0.2812959584306453]
	TIME [epoch: 143 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15427417659487497		[learning rate: 0.0025704]
	Learning Rate: 0.0025704
	LOSS [training: 0.15427417659487497 | validation: 0.29380392670260386]
	TIME [epoch: 143 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1606175897871789		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.1606175897871789 | validation: 0.28635822198658356]
	TIME [epoch: 142 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15127489857582493		[learning rate: 0.0025477]
	Learning Rate: 0.00254773
	LOSS [training: 0.15127489857582493 | validation: 0.28850670116042304]
	TIME [epoch: 142 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1594698290658965		[learning rate: 0.0025365]
	Learning Rate: 0.00253648
	LOSS [training: 0.1594698290658965 | validation: 0.2827460677150571]
	TIME [epoch: 143 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15507178241663994		[learning rate: 0.0025253]
	Learning Rate: 0.00252527
	LOSS [training: 0.15507178241663994 | validation: 0.3103656680432964]
	TIME [epoch: 142 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.157378729461443		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.157378729461443 | validation: 0.2974711387627087]
	TIME [epoch: 143 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15168652640839517		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.15168652640839517 | validation: 0.28652737999237077]
	TIME [epoch: 142 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15462668192917334		[learning rate: 0.0024919]
	Learning Rate: 0.00249194
	LOSS [training: 0.15462668192917334 | validation: 0.3094747781368821]
	TIME [epoch: 142 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15192081898269308		[learning rate: 0.0024809]
	Learning Rate: 0.00248093
	LOSS [training: 0.15192081898269308 | validation: 0.2845885094906391]
	TIME [epoch: 142 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15646561674503928		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.15646561674503928 | validation: 0.31810341237074286]
	TIME [epoch: 142 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15790098654926019		[learning rate: 0.0024591]
	Learning Rate: 0.00245906
	LOSS [training: 0.15790098654926019 | validation: 0.2902649390892759]
	TIME [epoch: 142 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15918530931935343		[learning rate: 0.0024482]
	Learning Rate: 0.0024482
	LOSS [training: 0.15918530931935343 | validation: 0.28772089260466344]
	TIME [epoch: 143 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1598802736298252		[learning rate: 0.0024374]
	Learning Rate: 0.00243738
	LOSS [training: 0.1598802736298252 | validation: 0.2758562932369254]
	TIME [epoch: 142 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15925533586868973		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.15925533586868973 | validation: 0.28360087200733275]
	TIME [epoch: 142 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15476069858902516		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.15476069858902516 | validation: 0.2809861684042902]
	TIME [epoch: 142 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15427463071420422		[learning rate: 0.0024052]
	Learning Rate: 0.00240521
	LOSS [training: 0.15427463071420422 | validation: 0.2958529896687238]
	TIME [epoch: 142 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15235151999944319		[learning rate: 0.0023946]
	Learning Rate: 0.00239459
	LOSS [training: 0.15235151999944319 | validation: 0.29239477705777317]
	TIME [epoch: 142 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15644003029234835		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.15644003029234835 | validation: 0.29083737223042955]
	TIME [epoch: 143 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15913514515277494		[learning rate: 0.0023735]
	Learning Rate: 0.00237347
	LOSS [training: 0.15913514515277494 | validation: 0.27727246000897]
	TIME [epoch: 142 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1548392168012623		[learning rate: 0.002363]
	Learning Rate: 0.00236299
	LOSS [training: 0.1548392168012623 | validation: 0.2798358657885036]
	TIME [epoch: 142 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15288067311189812		[learning rate: 0.0023525]
	Learning Rate: 0.00235255
	LOSS [training: 0.15288067311189812 | validation: 0.29355267648320127]
	TIME [epoch: 143 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15150497759512246		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.15150497759512246 | validation: 0.2865659903326839]
	TIME [epoch: 142 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1532710461340845		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.1532710461340845 | validation: 0.2907477568352705]
	TIME [epoch: 142 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14943918558361857		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.14943918558361857 | validation: 0.28925562071694855]
	TIME [epoch: 142 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15489120093409342		[learning rate: 0.0023112]
	Learning Rate: 0.00231125
	LOSS [training: 0.15489120093409342 | validation: 0.2752621990767121]
	TIME [epoch: 142 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15633486981389183		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.15633486981389183 | validation: 0.2904550746917713]
	TIME [epoch: 142 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15319888920770658		[learning rate: 0.0022909]
	Learning Rate: 0.00229087
	LOSS [training: 0.15319888920770658 | validation: 0.28736076799120924]
	TIME [epoch: 142 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16001371408026382		[learning rate: 0.0022807]
	Learning Rate: 0.00228075
	LOSS [training: 0.16001371408026382 | validation: 0.2897879113819595]
	TIME [epoch: 142 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14985530051210322		[learning rate: 0.0022707]
	Learning Rate: 0.00227067
	LOSS [training: 0.14985530051210322 | validation: 0.3023802752384868]
	TIME [epoch: 142 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15410127132444523		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.15410127132444523 | validation: 0.2800515888431232]
	TIME [epoch: 142 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15642650963985966		[learning rate: 0.0022506]
	Learning Rate: 0.00225065
	LOSS [training: 0.15642650963985966 | validation: 0.273261358826088]
	TIME [epoch: 142 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15295371671976077		[learning rate: 0.0022407]
	Learning Rate: 0.0022407
	LOSS [training: 0.15295371671976077 | validation: 0.2838840540205211]
	TIME [epoch: 142 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15775633495207733		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.15775633495207733 | validation: 0.3118529039160322]
	TIME [epoch: 142 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14859003584611324		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.14859003584611324 | validation: 0.2883921605704902]
	TIME [epoch: 142 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1507467142714251		[learning rate: 0.0022111]
	Learning Rate: 0.00221114
	LOSS [training: 0.1507467142714251 | validation: 0.29613418204494407]
	TIME [epoch: 142 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1512070994016955		[learning rate: 0.0022014]
	Learning Rate: 0.00220137
	LOSS [training: 0.1512070994016955 | validation: 0.3049860384883299]
	TIME [epoch: 143 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15285035771912167		[learning rate: 0.0021916]
	Learning Rate: 0.00219164
	LOSS [training: 0.15285035771912167 | validation: 0.2864391212402566]
	TIME [epoch: 143 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16158233160521074		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.16158233160521074 | validation: 0.3176721783744612]
	TIME [epoch: 142 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15808998237046681		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.15808998237046681 | validation: 0.29715353705785397]
	TIME [epoch: 143 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15267843594137817		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: 0.15267843594137817 | validation: 0.30299984307624744]
	TIME [epoch: 142 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15589459407751866		[learning rate: 0.0021532]
	Learning Rate: 0.00215316
	LOSS [training: 0.15589459407751866 | validation: 0.2870134708602207]
	TIME [epoch: 143 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15325019621506092		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.15325019621506092 | validation: 0.2844069877012096]
	TIME [epoch: 143 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15179842541775362		[learning rate: 0.0021342]
	Learning Rate: 0.00213418
	LOSS [training: 0.15179842541775362 | validation: 0.28586286592558]
	TIME [epoch: 142 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1526130095435749		[learning rate: 0.0021247]
	Learning Rate: 0.00212475
	LOSS [training: 0.1526130095435749 | validation: 0.273695040669822]
	TIME [epoch: 142 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1515384179618105		[learning rate: 0.0021154]
	Learning Rate: 0.00211536
	LOSS [training: 0.1515384179618105 | validation: 0.3071207980949525]
	TIME [epoch: 143 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15739923450751928		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.15739923450751928 | validation: 0.28707393857035934]
	TIME [epoch: 142 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15425714021317147		[learning rate: 0.0020967]
	Learning Rate: 0.00209671
	LOSS [training: 0.15425714021317147 | validation: 0.2722361135283403]
	TIME [epoch: 143 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15824113623913652		[learning rate: 0.0020874]
	Learning Rate: 0.00208745
	LOSS [training: 0.15824113623913652 | validation: 0.28056304862178494]
	TIME [epoch: 143 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15345770559901303		[learning rate: 0.0020782]
	Learning Rate: 0.00207822
	LOSS [training: 0.15345770559901303 | validation: 0.28072087232024245]
	TIME [epoch: 143 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14721177498508922		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.14721177498508922 | validation: 0.2853343435160401]
	TIME [epoch: 142 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15600536483388683		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.15600536483388683 | validation: 0.28168064667286874]
	TIME [epoch: 142 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15309454275809362		[learning rate: 0.0020508]
	Learning Rate: 0.0020508
	LOSS [training: 0.15309454275809362 | validation: 0.28155961606307706]
	TIME [epoch: 143 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1519600558065607		[learning rate: 0.0020417]
	Learning Rate: 0.00204174
	LOSS [training: 0.1519600558065607 | validation: 0.2877365423545039]
	TIME [epoch: 143 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1513149036227815		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.1513149036227815 | validation: 0.2884422633547965]
	TIME [epoch: 142 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1541127018393083		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.1541127018393083 | validation: 0.3012899924719062]
	TIME [epoch: 142 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1560339652003113		[learning rate: 0.0020148]
	Learning Rate: 0.00201479
	LOSS [training: 0.1560339652003113 | validation: 0.2942224278387447]
	TIME [epoch: 143 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1552630862083492		[learning rate: 0.0020059]
	Learning Rate: 0.00200589
	LOSS [training: 0.1552630862083492 | validation: 0.29009070760395944]
	TIME [epoch: 142 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15508949632724484		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.15508949632724484 | validation: 0.2765930488771301]
	TIME [epoch: 142 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14988118412324528		[learning rate: 0.0019882]
	Learning Rate: 0.00198821
	LOSS [training: 0.14988118412324528 | validation: 0.29830095884166036]
	TIME [epoch: 142 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14957518631002328		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.14957518631002328 | validation: 0.2924141578433383]
	TIME [epoch: 143 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1549405395225568		[learning rate: 0.0019707]
	Learning Rate: 0.00197068
	LOSS [training: 0.1549405395225568 | validation: 0.2864253315567256]
	TIME [epoch: 143 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14951997591840843		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.14951997591840843 | validation: 0.30001723243580253]
	TIME [epoch: 142 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1548074301725683		[learning rate: 0.0019533]
	Learning Rate: 0.0019533
	LOSS [training: 0.1548074301725683 | validation: 0.29829810747314667]
	TIME [epoch: 143 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15133215522252466		[learning rate: 0.0019447]
	Learning Rate: 0.00194467
	LOSS [training: 0.15133215522252466 | validation: 0.30596022239255577]
	TIME [epoch: 142 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15453508858109655		[learning rate: 0.0019361]
	Learning Rate: 0.00193608
	LOSS [training: 0.15453508858109655 | validation: 0.30379341972414564]
	TIME [epoch: 142 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1497834558368792		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.1497834558368792 | validation: 0.29663300077919497]
	TIME [epoch: 142 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15567400557081468		[learning rate: 0.001919]
	Learning Rate: 0.00191901
	LOSS [training: 0.15567400557081468 | validation: 0.28178898881948344]
	TIME [epoch: 142 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15500255815512826		[learning rate: 0.0019105]
	Learning Rate: 0.00191053
	LOSS [training: 0.15500255815512826 | validation: 0.2727372038526853]
	TIME [epoch: 142 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15477239275908009		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.15477239275908009 | validation: 0.29018733552758785]
	TIME [epoch: 142 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1552918403661105		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.1552918403661105 | validation: 0.30176819525110005]
	TIME [epoch: 142 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1548020013622865		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.1548020013622865 | validation: 0.2827101034837499]
	TIME [epoch: 142 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15143222225363295		[learning rate: 0.001877]
	Learning Rate: 0.00187699
	LOSS [training: 0.15143222225363295 | validation: 0.2913163570449107]
	TIME [epoch: 142 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15174990488768886		[learning rate: 0.0018687]
	Learning Rate: 0.0018687
	LOSS [training: 0.15174990488768886 | validation: 0.281982846546681]
	TIME [epoch: 143 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1504930977373126		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.1504930977373126 | validation: 0.28266412695092247]
	TIME [epoch: 142 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15257767632064292		[learning rate: 0.0018522]
	Learning Rate: 0.00185222
	LOSS [training: 0.15257767632064292 | validation: 0.29009656681207696]
	TIME [epoch: 142 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1564479023790761		[learning rate: 0.001844]
	Learning Rate: 0.00184404
	LOSS [training: 0.1564479023790761 | validation: 0.29079656674000315]
	TIME [epoch: 142 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15406613713286593		[learning rate: 0.0018359]
	Learning Rate: 0.00183589
	LOSS [training: 0.15406613713286593 | validation: 0.28001398137647465]
	TIME [epoch: 142 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14902750374496823		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.14902750374496823 | validation: 0.27703825392935016]
	TIME [epoch: 142 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15555500410098622		[learning rate: 0.0018197]
	Learning Rate: 0.0018197
	LOSS [training: 0.15555500410098622 | validation: 0.2707670661550825]
	TIME [epoch: 142 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15161769593979763		[learning rate: 0.0018117]
	Learning Rate: 0.00181166
	LOSS [training: 0.15161769593979763 | validation: 0.2870220999716214]
	TIME [epoch: 143 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15140782173307474		[learning rate: 0.0018037]
	Learning Rate: 0.00180366
	LOSS [training: 0.15140782173307474 | validation: 0.2830515328006412]
	TIME [epoch: 142 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15252485474820826		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.15252485474820826 | validation: 0.2957489056341574]
	TIME [epoch: 142 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15426785125858128		[learning rate: 0.0017878]
	Learning Rate: 0.00178775
	LOSS [training: 0.15426785125858128 | validation: 0.2779069761600622]
	TIME [epoch: 142 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14861639445676045		[learning rate: 0.0017799]
	Learning Rate: 0.00177985
	LOSS [training: 0.14861639445676045 | validation: 0.29601630274259577]
	TIME [epoch: 142 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15620502434564115		[learning rate: 0.001772]
	Learning Rate: 0.00177199
	LOSS [training: 0.15620502434564115 | validation: 0.28964355686790433]
	TIME [epoch: 143 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15090875756833416		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.15090875756833416 | validation: 0.2827501671611598]
	TIME [epoch: 142 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15785180868949766		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.15785180868949766 | validation: 0.2723490898381157]
	TIME [epoch: 142 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14944117109189417		[learning rate: 0.0017486]
	Learning Rate: 0.00174861
	LOSS [training: 0.14944117109189417 | validation: 0.2851936418077891]
	TIME [epoch: 142 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1569866356683097		[learning rate: 0.0017409]
	Learning Rate: 0.00174088
	LOSS [training: 0.1569866356683097 | validation: 0.28615420262523417]
	TIME [epoch: 142 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15229765101697013		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.15229765101697013 | validation: 0.2825320545027279]
	TIME [epoch: 142 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14915494584717523		[learning rate: 0.0017255]
	Learning Rate: 0.00172553
	LOSS [training: 0.14915494584717523 | validation: 0.29026325753024884]
	TIME [epoch: 142 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15079092941268116		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: 0.15079092941268116 | validation: 0.2907528974651619]
	TIME [epoch: 142 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14933793194390593		[learning rate: 0.0017103]
	Learning Rate: 0.00171032
	LOSS [training: 0.14933793194390593 | validation: 0.28857187622789937]
	TIME [epoch: 142 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1510536656636599		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.1510536656636599 | validation: 0.29143641645238094]
	TIME [epoch: 143 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15263246786145004		[learning rate: 0.0016952]
	Learning Rate: 0.00169524
	LOSS [training: 0.15263246786145004 | validation: 0.2828284355285142]
	TIME [epoch: 143 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15129762587631684		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.15129762587631684 | validation: 0.29067231940740745]
	TIME [epoch: 143 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15413835084343663		[learning rate: 0.0016803]
	Learning Rate: 0.00168029
	LOSS [training: 0.15413835084343663 | validation: 0.29090646610203486]
	TIME [epoch: 142 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15452118115573688		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.15452118115573688 | validation: 0.2892289237243391]
	TIME [epoch: 143 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15211940463265947		[learning rate: 0.0016655]
	Learning Rate: 0.00166548
	LOSS [training: 0.15211940463265947 | validation: 0.3112517380799837]
	TIME [epoch: 143 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15255272250738758		[learning rate: 0.0016581]
	Learning Rate: 0.00165812
	LOSS [training: 0.15255272250738758 | validation: 0.28408755077868153]
	TIME [epoch: 143 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15464366642182395		[learning rate: 0.0016508]
	Learning Rate: 0.00165079
	LOSS [training: 0.15464366642182395 | validation: 0.2824141655586099]
	TIME [epoch: 143 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16014118917666292		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.16014118917666292 | validation: 0.2786009287557262]
	TIME [epoch: 143 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15186295562019828		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.15186295562019828 | validation: 0.27693999506790584]
	TIME [epoch: 142 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1544791672307692		[learning rate: 0.001629]
	Learning Rate: 0.00162901
	LOSS [training: 0.1544791672307692 | validation: 0.27964759267281203]
	TIME [epoch: 142 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.150484149338426		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.150484149338426 | validation: 0.2955539213606243]
	TIME [epoch: 142 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15150268331868563		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.15150268331868563 | validation: 0.2800003889666025]
	TIME [epoch: 142 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15227508970431752		[learning rate: 0.0016075]
	Learning Rate: 0.00160751
	LOSS [training: 0.15227508970431752 | validation: 0.27600322067871746]
	TIME [epoch: 142 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14983694160489658		[learning rate: 0.0016004]
	Learning Rate: 0.00160041
	LOSS [training: 0.14983694160489658 | validation: 0.28265371302612274]
	TIME [epoch: 142 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14602941550727774		[learning rate: 0.0015933]
	Learning Rate: 0.00159334
	LOSS [training: 0.14602941550727774 | validation: 0.2967986958569107]
	TIME [epoch: 143 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15115398394484747		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.15115398394484747 | validation: 0.27767098330299556]
	TIME [epoch: 143 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14690114089683318		[learning rate: 0.0015793]
	Learning Rate: 0.00157929
	LOSS [training: 0.14690114089683318 | validation: 0.27258880837125216]
	TIME [epoch: 143 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15411195523193402		[learning rate: 0.0015723]
	Learning Rate: 0.00157231
	LOSS [training: 0.15411195523193402 | validation: 0.29240663149053125]
	TIME [epoch: 142 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15263515837255376		[learning rate: 0.0015654]
	Learning Rate: 0.00156536
	LOSS [training: 0.15263515837255376 | validation: 0.2973393260357661]
	TIME [epoch: 142 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15473870769994366		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.15473870769994366 | validation: 0.2774998342944561]
	TIME [epoch: 142 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1497588528601868		[learning rate: 0.0015516]
	Learning Rate: 0.00155156
	LOSS [training: 0.1497588528601868 | validation: 0.30720852901837026]
	TIME [epoch: 142 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1517609939061874		[learning rate: 0.0015447]
	Learning Rate: 0.00154471
	LOSS [training: 0.1517609939061874 | validation: 0.28510939397269475]
	TIME [epoch: 143 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1496057252968018		[learning rate: 0.0015379]
	Learning Rate: 0.00153788
	LOSS [training: 0.1496057252968018 | validation: 0.27930019382106813]
	TIME [epoch: 143 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1529843120429053		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.1529843120429053 | validation: 0.273967038405397]
	TIME [epoch: 142 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1466850923332831		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.1466850923332831 | validation: 0.2859521889367635]
	TIME [epoch: 142 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15100870976352793		[learning rate: 0.0015176]
	Learning Rate: 0.00151759
	LOSS [training: 0.15100870976352793 | validation: 0.2858759023780143]
	TIME [epoch: 142 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15743593782675852		[learning rate: 0.0015109]
	Learning Rate: 0.00151088
	LOSS [training: 0.15743593782675852 | validation: 0.28514096100047825]
	TIME [epoch: 142 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15562037717850563		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.15562037717850563 | validation: 0.2684084428881105]
	TIME [epoch: 142 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12b_20240716_172916/states/model_facs_v2_dec2b_2dpca_v12b_468.pth
	Model improved!!!
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15155049292837952		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.15155049292837952 | validation: 0.27516562792959093]
	TIME [epoch: 142 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14987723548706203		[learning rate: 0.0014909]
	Learning Rate: 0.00149094
	LOSS [training: 0.14987723548706203 | validation: 0.2812384008136641]
	TIME [epoch: 142 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14639472663268968		[learning rate: 0.0014844]
	Learning Rate: 0.00148436
	LOSS [training: 0.14639472663268968 | validation: 0.2803191598662942]
	TIME [epoch: 143 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15430165781721564		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.15430165781721564 | validation: 0.27898795855258496]
	TIME [epoch: 142 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15423253233883744		[learning rate: 0.0014713]
	Learning Rate: 0.00147127
	LOSS [training: 0.15423253233883744 | validation: 0.2774046688643218]
	TIME [epoch: 143 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14975668293460526		[learning rate: 0.0014648]
	Learning Rate: 0.00146477
	LOSS [training: 0.14975668293460526 | validation: 0.28277071162868844]
	TIME [epoch: 142 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15703465704210667		[learning rate: 0.0014583]
	Learning Rate: 0.0014583
	LOSS [training: 0.15703465704210667 | validation: 0.2872024912881898]
	TIME [epoch: 142 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1501855722313133		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.1501855722313133 | validation: 0.28596740953800437]
	TIME [epoch: 142 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15066672498733		[learning rate: 0.0014454]
	Learning Rate: 0.00144544
	LOSS [training: 0.15066672498733 | validation: 0.2954621349775077]
	TIME [epoch: 143 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15450805787067978		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.15450805787067978 | validation: 0.2865448902588423]
	TIME [epoch: 143 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1520927026150909		[learning rate: 0.0014327]
	Learning Rate: 0.0014327
	LOSS [training: 0.1520927026150909 | validation: 0.2825102091733625]
	TIME [epoch: 142 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15091964700312496		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.15091964700312496 | validation: 0.2900696608899211]
	TIME [epoch: 143 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14745131635238695		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.14745131635238695 | validation: 0.2815559186166238]
	TIME [epoch: 143 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14454721180995336		[learning rate: 0.0014138]
	Learning Rate: 0.00141379
	LOSS [training: 0.14454721180995336 | validation: 0.28424561125858716]
	TIME [epoch: 142 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1485673700572717		[learning rate: 0.0014075]
	Learning Rate: 0.00140754
	LOSS [training: 0.1485673700572717 | validation: 0.28445200188264924]
	TIME [epoch: 143 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14748864244637677		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.14748864244637677 | validation: 0.3003691739443203]
	TIME [epoch: 143 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1496641046724646		[learning rate: 0.0013951]
	Learning Rate: 0.00139513
	LOSS [training: 0.1496641046724646 | validation: 0.29280566274153236]
	TIME [epoch: 142 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15353221768262576		[learning rate: 0.001389]
	Learning Rate: 0.00138897
	LOSS [training: 0.15353221768262576 | validation: 0.2853245388149093]
	TIME [epoch: 143 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15463122057832188		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.15463122057832188 | validation: 0.2728718388266725]
	TIME [epoch: 143 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14393128292494187		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.14393128292494187 | validation: 0.28639823762261]
	TIME [epoch: 143 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15373123473506758		[learning rate: 0.0013706]
	Learning Rate: 0.00137064
	LOSS [training: 0.15373123473506758 | validation: 0.28925346819382286]
	TIME [epoch: 143 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14966285992069156		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: 0.14966285992069156 | validation: 0.2988335131131325]
	TIME [epoch: 142 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15263539624593295		[learning rate: 0.0013586]
	Learning Rate: 0.00135855
	LOSS [training: 0.15263539624593295 | validation: 0.2827589480242625]
	TIME [epoch: 143 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15449708657675276		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.15449708657675276 | validation: 0.27829778422002216]
	TIME [epoch: 143 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15367932863322803		[learning rate: 0.0013466]
	Learning Rate: 0.00134658
	LOSS [training: 0.15367932863322803 | validation: 0.2839527943924716]
	TIME [epoch: 143 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14929783964904045		[learning rate: 0.0013406]
	Learning Rate: 0.00134063
	LOSS [training: 0.14929783964904045 | validation: 0.28352467231779366]
	TIME [epoch: 143 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15535074662350024		[learning rate: 0.0013347]
	Learning Rate: 0.0013347
	LOSS [training: 0.15535074662350024 | validation: 0.2753741753649578]
	TIME [epoch: 143 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14593615178659525		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.14593615178659525 | validation: 0.2734359035349143]
	TIME [epoch: 143 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14691757909002895		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.14691757909002895 | validation: 0.28565224772387]
	TIME [epoch: 142 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1509605361951863		[learning rate: 0.0013171]
	Learning Rate: 0.00131709
	LOSS [training: 0.1509605361951863 | validation: 0.2792710212446385]
	TIME [epoch: 142 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1521872317800259		[learning rate: 0.0013113]
	Learning Rate: 0.00131127
	LOSS [training: 0.1521872317800259 | validation: 0.28198600927763845]
	TIME [epoch: 143 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1527685769517126		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.1527685769517126 | validation: 0.2913609165077815]
	TIME [epoch: 142 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1513312338227156		[learning rate: 0.0012997]
	Learning Rate: 0.00129971
	LOSS [training: 0.1513312338227156 | validation: 0.2821775814908765]
	TIME [epoch: 142 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14933553588021214		[learning rate: 0.001294]
	Learning Rate: 0.00129397
	LOSS [training: 0.14933553588021214 | validation: 0.27686367641365145]
	TIME [epoch: 142 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15094720184750474		[learning rate: 0.0012882]
	Learning Rate: 0.00128825
	LOSS [training: 0.15094720184750474 | validation: 0.28062004597176887]
	TIME [epoch: 143 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1511222888581656		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.1511222888581656 | validation: 0.2845416621697849]
	TIME [epoch: 143 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1523648133262142		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.1523648133262142 | validation: 0.28548465762309627]
	TIME [epoch: 143 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15537731158930781		[learning rate: 0.0012712]
	Learning Rate: 0.00127125
	LOSS [training: 0.15537731158930781 | validation: 0.27231036755586957]
	TIME [epoch: 142 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14616297748413612		[learning rate: 0.0012656]
	Learning Rate: 0.00126563
	LOSS [training: 0.14616297748413612 | validation: 0.27215435624426615]
	TIME [epoch: 142 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14798572705963448		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.14798572705963448 | validation: 0.28214931293424145]
	TIME [epoch: 142 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14613120270065064		[learning rate: 0.0012545]
	Learning Rate: 0.00125447
	LOSS [training: 0.14613120270065064 | validation: 0.3029130884890372]
	TIME [epoch: 142 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15019824641455645		[learning rate: 0.0012489]
	Learning Rate: 0.00124893
	LOSS [training: 0.15019824641455645 | validation: 0.29299494948780763]
	TIME [epoch: 142 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1516432122967937		[learning rate: 0.0012434]
	Learning Rate: 0.00124341
	LOSS [training: 0.1516432122967937 | validation: 0.2792839527972041]
	TIME [epoch: 143 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14515330065188964		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.14515330065188964 | validation: 0.2918942045561099]
	TIME [epoch: 143 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1486843825996213		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.1486843825996213 | validation: 0.28909463656256174]
	TIME [epoch: 143 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15047526191114927		[learning rate: 0.001227]
	Learning Rate: 0.001227
	LOSS [training: 0.15047526191114927 | validation: 0.28044639088410894]
	TIME [epoch: 143 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14954493962256682		[learning rate: 0.0012216]
	Learning Rate: 0.00122158
	LOSS [training: 0.14954493962256682 | validation: 0.2926633919996718]
	TIME [epoch: 142 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14976801189395206		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.14976801189395206 | validation: 0.2791500969900995]
	TIME [epoch: 143 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14834144541970873		[learning rate: 0.0012108]
	Learning Rate: 0.00121081
	LOSS [training: 0.14834144541970873 | validation: 0.27995239011093487]
	TIME [epoch: 143 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14395041703836314		[learning rate: 0.0012055]
	Learning Rate: 0.00120546
	LOSS [training: 0.14395041703836314 | validation: 0.2832444562397864]
	TIME [epoch: 143 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15292678219725692		[learning rate: 0.0012001]
	Learning Rate: 0.00120014
	LOSS [training: 0.15292678219725692 | validation: 0.3026270052527456]
	TIME [epoch: 142 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15121866841799111		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.15121866841799111 | validation: 0.28012528278535953]
	TIME [epoch: 143 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15088712787697695		[learning rate: 0.0011896]
	Learning Rate: 0.00118956
	LOSS [training: 0.15088712787697695 | validation: 0.2851829591964695]
	TIME [epoch: 143 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14831772539720148		[learning rate: 0.0011843]
	Learning Rate: 0.0011843
	LOSS [training: 0.14831772539720148 | validation: 0.2918351729178492]
	TIME [epoch: 142 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15159147326016587		[learning rate: 0.0011791]
	Learning Rate: 0.00117907
	LOSS [training: 0.15159147326016587 | validation: 0.2789204613740913]
	TIME [epoch: 142 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15211453013802378		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.15211453013802378 | validation: 0.27138421487849496]
	TIME [epoch: 143 sec]
EPOCH 525/2000:
	Training over batches...
