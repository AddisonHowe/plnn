Args:
Namespace(name='model_facs_dec2b_2dpca_v8', outdir='out/model_training/model_facs_dec2b_2dpca_v8', training_data='data/training_data/facs/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=400, ncells_sample=400, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[500, 1000, 1500], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.02, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 467948907

Training model...

Saving initial model state to: out/model_training/model_facs_dec2b_2dpca_v8_20240710_215556/states/model_facs_dec2b_2dpca_v8_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9885787234645621		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9885787234645621 | validation: 0.819260353297385]
	TIME [epoch: 41.2 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v8_20240710_215556/states/model_facs_dec2b_2dpca_v8_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.657711297497243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.657711297497243 | validation: 0.7844985641848413]
	TIME [epoch: 5.64 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v8_20240710_215556/states/model_facs_dec2b_2dpca_v8_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6237292588750031		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6237292588750031 | validation: 0.7602522021961465]
	TIME [epoch: 5.63 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v8_20240710_215556/states/model_facs_dec2b_2dpca_v8_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6115936720164377		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6115936720164377 | validation: 0.7355644918467819]
	TIME [epoch: 5.62 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v8_20240710_215556/states/model_facs_dec2b_2dpca_v8_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5983078772879281		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5983078772879281 | validation: 0.7754877837425709]
	TIME [epoch: 5.64 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5709993939574651		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5709993939574651 | validation: 0.6528456434594072]
	TIME [epoch: 5.62 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v8_20240710_215556/states/model_facs_dec2b_2dpca_v8_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5023646279103147		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5023646279103147 | validation: 0.625991739746887]
	TIME [epoch: 5.63 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v8_20240710_215556/states/model_facs_dec2b_2dpca_v8_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5320144030651075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5320144030651075 | validation: 0.625358500578933]
	TIME [epoch: 5.62 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v8_20240710_215556/states/model_facs_dec2b_2dpca_v8_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4768971796512754		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4768971796512754 | validation: 0.6360994947415046]
	TIME [epoch: 5.62 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4335566016855689		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4335566016855689 | validation: 0.6055149012399913]
	TIME [epoch: 5.63 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v8_20240710_215556/states/model_facs_dec2b_2dpca_v8_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4263387282611161		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4263387282611161 | validation: 0.6130097977492348]
	TIME [epoch: 5.63 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3930056742139407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3930056742139407 | validation: 0.6044952209394456]
	TIME [epoch: 5.62 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v8_20240710_215556/states/model_facs_dec2b_2dpca_v8_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3621199857520024		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3621199857520024 | validation: 0.5020339918636735]
	TIME [epoch: 5.62 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v8_20240710_215556/states/model_facs_dec2b_2dpca_v8_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3558394620679619		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3558394620679619 | validation: 0.4843172376119299]
	TIME [epoch: 5.63 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v8_20240710_215556/states/model_facs_dec2b_2dpca_v8_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32065840249923083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32065840249923083 | validation: 0.47969858763936674]
	TIME [epoch: 5.62 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v8_20240710_215556/states/model_facs_dec2b_2dpca_v8_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3275797573014537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3275797573014537 | validation: 0.4783060952439593]
	TIME [epoch: 5.63 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v8_20240710_215556/states/model_facs_dec2b_2dpca_v8_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32818224648005007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32818224648005007 | validation: 0.6196310945941171]
	TIME [epoch: 5.63 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35685038041137196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35685038041137196 | validation: 0.4458187996926354]
	TIME [epoch: 5.62 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v8_20240710_215556/states/model_facs_dec2b_2dpca_v8_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28766921942327606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28766921942327606 | validation: 0.4246901503493974]
	TIME [epoch: 5.63 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v8_20240710_215556/states/model_facs_dec2b_2dpca_v8_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29127969692961464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29127969692961464 | validation: 0.4293612669810992]
	TIME [epoch: 5.63 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32074269275584355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32074269275584355 | validation: 0.4445813939953827]
	TIME [epoch: 5.63 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29514773643081804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29514773643081804 | validation: 0.4665128063652912]
	TIME [epoch: 5.62 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36369773142256656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36369773142256656 | validation: 0.46579170157481015]
	TIME [epoch: 5.62 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2854762465182696		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2854762465182696 | validation: 0.48836768956015086]
	TIME [epoch: 5.62 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29641909224283286		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29641909224283286 | validation: 0.4543310463467486]
	TIME [epoch: 5.62 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3153723455705405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3153723455705405 | validation: 0.44644341945500077]
	TIME [epoch: 5.63 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2940481635425221		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2940481635425221 | validation: 0.5574570015849385]
	TIME [epoch: 5.63 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3009661899272237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3009661899272237 | validation: 0.4604461228421812]
	TIME [epoch: 5.62 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2828869155749537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2828869155749537 | validation: 0.4070344744579786]
	TIME [epoch: 5.62 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v8_20240710_215556/states/model_facs_dec2b_2dpca_v8_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27947451760626907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27947451760626907 | validation: 0.4539119588814145]
	TIME [epoch: 5.62 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2700181509141405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2700181509141405 | validation: 0.43032624110896034]
	TIME [epoch: 5.62 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2686464335783181		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2686464335783181 | validation: 0.4134692230427495]
	TIME [epoch: 5.63 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2819114986914166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2819114986914166 | validation: 0.4030140517752479]
	TIME [epoch: 5.69 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v8_20240710_215556/states/model_facs_dec2b_2dpca_v8_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2357088893884117		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2357088893884117 | validation: 0.43104913178560067]
	TIME [epoch: 5.63 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2755031778086657		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2755031778086657 | validation: 0.3946095293392131]
	TIME [epoch: 5.62 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v8_20240710_215556/states/model_facs_dec2b_2dpca_v8_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25531068713163385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25531068713163385 | validation: 0.5000547471674611]
	TIME [epoch: 5.63 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3086615315918781		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3086615315918781 | validation: 0.3826703801804862]
	TIME [epoch: 5.62 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v8_20240710_215556/states/model_facs_dec2b_2dpca_v8_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25622558135353624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25622558135353624 | validation: 0.46239441152116784]
	TIME [epoch: 5.64 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25609983873115055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25609983873115055 | validation: 0.37057801943255997]
	TIME [epoch: 5.62 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v8_20240710_215556/states/model_facs_dec2b_2dpca_v8_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2666909256374458		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2666909256374458 | validation: 0.40448449882742715]
	TIME [epoch: 5.62 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25097581651127987		[learning rate: 0.0099646]
	Learning Rate: 0.00996464
	LOSS [training: 0.25097581651127987 | validation: 0.42572470858763567]
	TIME [epoch: 5.62 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21572985059579275		[learning rate: 0.0099206]
	Learning Rate: 0.00992061
	LOSS [training: 0.21572985059579275 | validation: 0.35852834722448135]
	TIME [epoch: 5.62 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v8_20240710_215556/states/model_facs_dec2b_2dpca_v8_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2661565908456262		[learning rate: 0.0098768]
	Learning Rate: 0.00987678
	LOSS [training: 0.2661565908456262 | validation: 0.37200786375608613]
	TIME [epoch: 5.64 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27392136715585746		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.27392136715585746 | validation: 0.4537528280383838]
	TIME [epoch: 5.62 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2493909372407476		[learning rate: 0.0097897]
	Learning Rate: 0.0097897
	LOSS [training: 0.2493909372407476 | validation: 0.38272652053570083]
	TIME [epoch: 5.62 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24142254916058037		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.24142254916058037 | validation: 0.44112748065623897]
	TIME [epoch: 5.62 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2529642028299913		[learning rate: 0.0097034]
	Learning Rate: 0.00970338
	LOSS [training: 0.2529642028299913 | validation: 0.4273618926295422]
	TIME [epoch: 5.62 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31447768320696395		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.31447768320696395 | validation: 0.48205753946530927]
	TIME [epoch: 5.62 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24631988490619783		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.24631988490619783 | validation: 0.43549011725651654]
	TIME [epoch: 5.63 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26085819898378665		[learning rate: 0.0095753]
	Learning Rate: 0.00957533
	LOSS [training: 0.26085819898378665 | validation: 0.386452932450739]
	TIME [epoch: 5.62 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21664145221695746		[learning rate: 0.009533]
	Learning Rate: 0.00953303
	LOSS [training: 0.21664145221695746 | validation: 0.395347988319191]
	TIME [epoch: 5.62 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23616067992081854		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.23616067992081854 | validation: 0.3630300251971817]
	TIME [epoch: 5.62 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24256328432178736		[learning rate: 0.009449]
	Learning Rate: 0.00944897
	LOSS [training: 0.24256328432178736 | validation: 0.3711587352745912]
	TIME [epoch: 5.62 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24536778037187174		[learning rate: 0.0094072]
	Learning Rate: 0.00940722
	LOSS [training: 0.24536778037187174 | validation: 0.4830877052815572]
	TIME [epoch: 5.62 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3287516957947122		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.3287516957947122 | validation: 0.42418615770455087]
	TIME [epoch: 5.63 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.267459611847012		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.267459611847012 | validation: 0.3637715929477204]
	TIME [epoch: 5.62 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2183572026970193		[learning rate: 0.0092831]
	Learning Rate: 0.00928308
	LOSS [training: 0.2183572026970193 | validation: 0.40668291852741334]
	TIME [epoch: 5.62 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25100822584554094		[learning rate: 0.0092421]
	Learning Rate: 0.00924207
	LOSS [training: 0.25100822584554094 | validation: 0.3637046691782438]
	TIME [epoch: 5.62 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2542717712943498		[learning rate: 0.0092012]
	Learning Rate: 0.00920124
	LOSS [training: 0.2542717712943498 | validation: 0.45390886600470204]
	TIME [epoch: 5.62 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2646312649928058		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.2646312649928058 | validation: 0.3463437014089077]
	TIME [epoch: 5.62 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v8_20240710_215556/states/model_facs_dec2b_2dpca_v8_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2009074954865142		[learning rate: 0.0091201]
	Learning Rate: 0.00912011
	LOSS [training: 0.2009074954865142 | validation: 0.3685855028523588]
	TIME [epoch: 5.63 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19634721941104596		[learning rate: 0.0090798]
	Learning Rate: 0.00907981
	LOSS [training: 0.19634721941104596 | validation: 0.3398699127479578]
	TIME [epoch: 5.62 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v8_20240710_215556/states/model_facs_dec2b_2dpca_v8_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23458270938236972		[learning rate: 0.0090397]
	Learning Rate: 0.0090397
	LOSS [training: 0.23458270938236972 | validation: 0.35074729903921653]
	TIME [epoch: 5.62 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25585851667590365		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.25585851667590365 | validation: 0.40516777933902387]
	TIME [epoch: 5.62 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23318192765364376		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.23318192765364376 | validation: 0.36196665117000276]
	TIME [epoch: 5.62 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21300812444228306		[learning rate: 0.0089204]
	Learning Rate: 0.00892041
	LOSS [training: 0.21300812444228306 | validation: 0.5642349693468374]
	TIME [epoch: 5.64 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2922499541459219		[learning rate: 0.008881]
	Learning Rate: 0.00888099
	LOSS [training: 0.2922499541459219 | validation: 0.5162389023976863]
	TIME [epoch: 5.62 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31347018987567815		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.31347018987567815 | validation: 0.4349973709737782]
	TIME [epoch: 5.62 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2375421512208971		[learning rate: 0.0088027]
	Learning Rate: 0.00880269
	LOSS [training: 0.2375421512208971 | validation: 0.36077571898650396]
	TIME [epoch: 5.62 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21063467069555544		[learning rate: 0.0087638]
	Learning Rate: 0.0087638
	LOSS [training: 0.21063467069555544 | validation: 0.4001092582112265]
	TIME [epoch: 5.62 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19880091774374825		[learning rate: 0.0087251]
	Learning Rate: 0.00872508
	LOSS [training: 0.19880091774374825 | validation: 0.3395281531868717]
	TIME [epoch: 5.62 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v8_20240710_215556/states/model_facs_dec2b_2dpca_v8_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22960693765471527		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.22960693765471527 | validation: 0.3607238433894778]
	TIME [epoch: 5.64 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23442998960685407		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.23442998960685407 | validation: 0.32055244801432414]
	TIME [epoch: 5.62 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v8_20240710_215556/states/model_facs_dec2b_2dpca_v8_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20067682115101415		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 0.20067682115101415 | validation: 0.41457363633008976]
	TIME [epoch: 5.63 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20976855630397223		[learning rate: 0.0085719]
	Learning Rate: 0.0085719
	LOSS [training: 0.20976855630397223 | validation: 0.3243063051671144]
	TIME [epoch: 5.62 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19541959600379857		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.19541959600379857 | validation: 0.3214547195890355]
	TIME [epoch: 5.62 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2038836185275037		[learning rate: 0.0084963]
	Learning Rate: 0.00849632
	LOSS [training: 0.2038836185275037 | validation: 0.32778223938737494]
	TIME [epoch: 5.62 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1913101390837769		[learning rate: 0.0084588]
	Learning Rate: 0.00845878
	LOSS [training: 0.1913101390837769 | validation: 0.3247854572868819]
	TIME [epoch: 5.63 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2104234374472898		[learning rate: 0.0084214]
	Learning Rate: 0.00842141
	LOSS [training: 0.2104234374472898 | validation: 0.3249580232746326]
	TIME [epoch: 5.62 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20128075519483812		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.20128075519483812 | validation: 0.3210294055006903]
	TIME [epoch: 5.62 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.202349164533069		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.202349164533069 | validation: 0.46429906248496966]
	TIME [epoch: 5.62 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19041133632098334		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.19041133632098334 | validation: 0.40660261189754077]
	TIME [epoch: 5.62 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2177849961979162		[learning rate: 0.0082736]
	Learning Rate: 0.00827356
	LOSS [training: 0.2177849961979162 | validation: 0.3765945057476838]
	TIME [epoch: 5.63 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23726585075313		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.23726585075313 | validation: 0.4702835777024852]
	TIME [epoch: 5.62 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2817198205326544		[learning rate: 0.0082006]
	Learning Rate: 0.00820061
	LOSS [training: 0.2817198205326544 | validation: 0.3711008393784249]
	TIME [epoch: 5.62 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21160042941070883		[learning rate: 0.0081644]
	Learning Rate: 0.00816438
	LOSS [training: 0.21160042941070883 | validation: 0.34656807950315066]
	TIME [epoch: 5.62 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.205194597836154		[learning rate: 0.0081283]
	Learning Rate: 0.0081283
	LOSS [training: 0.205194597836154 | validation: 0.4330365007765261]
	TIME [epoch: 5.62 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20887061337546742		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.20887061337546742 | validation: 0.35608477780014397]
	TIME [epoch: 5.62 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2044651453257774		[learning rate: 0.0080566]
	Learning Rate: 0.00805664
	LOSS [training: 0.2044651453257774 | validation: 0.3241519575989035]
	TIME [epoch: 5.64 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19519500352123806		[learning rate: 0.008021]
	Learning Rate: 0.00802104
	LOSS [training: 0.19519500352123806 | validation: 0.4327128542038891]
	TIME [epoch: 5.62 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2976923397883599		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.2976923397883599 | validation: 0.36122929376801416]
	TIME [epoch: 5.62 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.221244112175301		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.221244112175301 | validation: 0.36167308093722556]
	TIME [epoch: 5.62 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19998303575054494		[learning rate: 0.0079152]
	Learning Rate: 0.00791519
	LOSS [training: 0.19998303575054494 | validation: 0.33647630115073923]
	TIME [epoch: 5.62 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20505410581337088		[learning rate: 0.0078802]
	Learning Rate: 0.00788022
	LOSS [training: 0.20505410581337088 | validation: 0.3305853127311515]
	TIME [epoch: 5.62 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2162374906742241		[learning rate: 0.0078454]
	Learning Rate: 0.00784541
	LOSS [training: 0.2162374906742241 | validation: 0.31774468522111327]
	TIME [epoch: 5.64 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v8_20240710_215556/states/model_facs_dec2b_2dpca_v8_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20445771578409686		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.20445771578409686 | validation: 0.3328715261820838]
	TIME [epoch: 5.62 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20591389948344005		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.20591389948344005 | validation: 0.3542975043286804]
	TIME [epoch: 5.62 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2001142344476139		[learning rate: 0.0077419]
	Learning Rate: 0.00774188
	LOSS [training: 0.2001142344476139 | validation: 0.34164940452494136]
	TIME [epoch: 5.62 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17896153305876839		[learning rate: 0.0077077]
	Learning Rate: 0.00770767
	LOSS [training: 0.17896153305876839 | validation: 0.33534901922799676]
	TIME [epoch: 5.62 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21817203314825212		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.21817203314825212 | validation: 0.33112471009565564]
	TIME [epoch: 5.63 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.191941246921267		[learning rate: 0.0076397]
	Learning Rate: 0.00763971
	LOSS [training: 0.191941246921267 | validation: 0.33643647968829066]
	TIME [epoch: 5.63 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2282977273750416		[learning rate: 0.007606]
	Learning Rate: 0.00760596
	LOSS [training: 0.2282977273750416 | validation: 0.3445902088363349]
	TIME [epoch: 5.62 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20305398366953664		[learning rate: 0.0075724]
	Learning Rate: 0.00757235
	LOSS [training: 0.20305398366953664 | validation: 0.3258425763786708]
	TIME [epoch: 5.61 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20333816272735716		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.20333816272735716 | validation: 0.37477005330557844]
	TIME [epoch: 5.62 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19367575252952224		[learning rate: 0.0075056]
	Learning Rate: 0.00750559
	LOSS [training: 0.19367575252952224 | validation: 0.33184170962637954]
	TIME [epoch: 5.62 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19568464928853285		[learning rate: 0.0074724]
	Learning Rate: 0.00747242
	LOSS [training: 0.19568464928853285 | validation: 0.3226970045262548]
	TIME [epoch: 5.63 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19933083115362524		[learning rate: 0.0074394]
	Learning Rate: 0.00743941
	LOSS [training: 0.19933083115362524 | validation: 0.34273717886066196]
	TIME [epoch: 5.61 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19892282141335116		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.19892282141335116 | validation: 0.36126832764259653]
	TIME [epoch: 5.62 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20396210407508683		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.20396210407508683 | validation: 0.3319701790133982]
	TIME [epoch: 5.61 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18756687349366247		[learning rate: 0.0073412]
	Learning Rate: 0.00734124
	LOSS [training: 0.18756687349366247 | validation: 0.36447068902484275]
	TIME [epoch: 5.61 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19159844813392835		[learning rate: 0.0073088]
	Learning Rate: 0.0073088
	LOSS [training: 0.19159844813392835 | validation: 0.4656854199601706]
	TIME [epoch: 5.61 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2154817482078483		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.2154817482078483 | validation: 0.3099898101448641]
	TIME [epoch: 5.63 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v8_20240710_215556/states/model_facs_dec2b_2dpca_v8_112.pth
	Model improved!!!
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20312147295523159		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.20312147295523159 | validation: 0.34741397408326724]
	TIME [epoch: 5.62 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20046738646140033		[learning rate: 0.0072124]
	Learning Rate: 0.00721235
	LOSS [training: 0.20046738646140033 | validation: 0.36655581819254346]
	TIME [epoch: 5.62 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21542523374439462		[learning rate: 0.0071805]
	Learning Rate: 0.00718049
	LOSS [training: 0.21542523374439462 | validation: 0.3387880001441058]
	TIME [epoch: 5.62 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20574435720700662		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.20574435720700662 | validation: 0.3629128725138866]
	TIME [epoch: 5.62 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19021754403465682		[learning rate: 0.0071172]
	Learning Rate: 0.00711718
	LOSS [training: 0.19021754403465682 | validation: 0.3507332306317803]
	TIME [epoch: 5.63 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19965199002386322		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.19965199002386322 | validation: 0.35425865729603834]
	TIME [epoch: 5.63 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1950911334748269		[learning rate: 0.0070544]
	Learning Rate: 0.00705442
	LOSS [training: 0.1950911334748269 | validation: 0.41410668486659535]
	TIME [epoch: 5.62 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19323696291895373		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.19323696291895373 | validation: 0.3662322135290032]
	TIME [epoch: 5.62 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21491885583956888		[learning rate: 0.0069922]
	Learning Rate: 0.00699222
	LOSS [training: 0.21491885583956888 | validation: 0.350240376277489]
	TIME [epoch: 5.61 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1961513715288817		[learning rate: 0.0069613]
	Learning Rate: 0.00696133
	LOSS [training: 0.1961513715288817 | validation: 0.3549190732519999]
	TIME [epoch: 5.62 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18436790607517345		[learning rate: 0.0069306]
	Learning Rate: 0.00693057
	LOSS [training: 0.18436790607517345 | validation: 0.33275622422302703]
	TIME [epoch: 5.63 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18694442412516607		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.18694442412516607 | validation: 0.3219381126998735]
	TIME [epoch: 5.63 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20054579840772896		[learning rate: 0.0068695]
	Learning Rate: 0.00686947
	LOSS [training: 0.20054579840772896 | validation: 0.3568906782404121]
	TIME [epoch: 5.62 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20156630169084266		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.20156630169084266 | validation: 0.3452277051030149]
	TIME [epoch: 5.61 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18991003705168308		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.18991003705168308 | validation: 0.34667578073092287]
	TIME [epoch: 5.61 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19530339588024861		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.19530339588024861 | validation: 0.34340706928919523]
	TIME [epoch: 5.62 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20951627368701042		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.20951627368701042 | validation: 0.37360149727148695]
	TIME [epoch: 5.63 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22488236823761992		[learning rate: 0.006719]
	Learning Rate: 0.00671905
	LOSS [training: 0.22488236823761992 | validation: 0.36344967399647976]
	TIME [epoch: 5.62 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19646501312770215		[learning rate: 0.0066894]
	Learning Rate: 0.00668936
	LOSS [training: 0.19646501312770215 | validation: 0.3648611225434347]
	TIME [epoch: 5.62 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18572196902026095		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.18572196902026095 | validation: 0.491735842185142]
	TIME [epoch: 5.62 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1954252652391862		[learning rate: 0.0066304]
	Learning Rate: 0.00663038
	LOSS [training: 0.1954252652391862 | validation: 0.3669119628965294]
	TIME [epoch: 5.61 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18671487700246894		[learning rate: 0.0066011]
	Learning Rate: 0.00660109
	LOSS [training: 0.18671487700246894 | validation: 0.345629228193883]
	TIME [epoch: 5.62 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18709823374853535		[learning rate: 0.0065719]
	Learning Rate: 0.00657192
	LOSS [training: 0.18709823374853535 | validation: 0.3524814848492123]
	TIME [epoch: 5.63 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19742172316514978		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.19742172316514978 | validation: 0.33926895298489124]
	TIME [epoch: 5.61 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19021616802506938		[learning rate: 0.006514]
	Learning Rate: 0.00651398
	LOSS [training: 0.19021616802506938 | validation: 0.312790687769442]
	TIME [epoch: 5.61 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18867286776799688		[learning rate: 0.0064852]
	Learning Rate: 0.00648519
	LOSS [training: 0.18867286776799688 | validation: 0.2940693066618103]
	TIME [epoch: 5.62 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v8_20240710_215556/states/model_facs_dec2b_2dpca_v8_138.pth
	Model improved!!!
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18200561198670337		[learning rate: 0.0064565]
	Learning Rate: 0.00645654
	LOSS [training: 0.18200561198670337 | validation: 0.3240676805719647]
	TIME [epoch: 5.62 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18262551359215373		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.18262551359215373 | validation: 0.34994797231257474]
	TIME [epoch: 5.62 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18075204297971223		[learning rate: 0.0063996]
	Learning Rate: 0.00639961
	LOSS [training: 0.18075204297971223 | validation: 0.3210040023969567]
	TIME [epoch: 5.63 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19658029193680313		[learning rate: 0.0063713]
	Learning Rate: 0.00637134
	LOSS [training: 0.19658029193680313 | validation: 0.3559445396375719]
	TIME [epoch: 5.62 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18461791852072323		[learning rate: 0.0063432]
	Learning Rate: 0.00634319
	LOSS [training: 0.18461791852072323 | validation: 0.347562601202364]
	TIME [epoch: 5.62 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2224460735400983		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.2224460735400983 | validation: 0.38713612377690804]
	TIME [epoch: 5.61 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19285450812022345		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.19285450812022345 | validation: 0.3152437256409041]
	TIME [epoch: 5.61 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1959989517570383		[learning rate: 0.0062595]
	Learning Rate: 0.00625948
	LOSS [training: 0.1959989517570383 | validation: 0.3067198748500223]
	TIME [epoch: 5.62 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1841937588029561		[learning rate: 0.0062318]
	Learning Rate: 0.00623183
	LOSS [training: 0.1841937588029561 | validation: 0.30415175628474644]
	TIME [epoch: 5.62 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18892924269115777		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.18892924269115777 | validation: 0.3174604237677414]
	TIME [epoch: 5.62 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17648719467145663		[learning rate: 0.0061769]
	Learning Rate: 0.00617688
	LOSS [training: 0.17648719467145663 | validation: 0.4248933782986958]
	TIME [epoch: 5.62 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20602593895169835		[learning rate: 0.0061496]
	Learning Rate: 0.00614959
	LOSS [training: 0.20602593895169835 | validation: 0.3272482038074749]
	TIME [epoch: 5.62 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18558678054220315		[learning rate: 0.0061224]
	Learning Rate: 0.00612242
	LOSS [training: 0.18558678054220315 | validation: 0.30521793807349307]
	TIME [epoch: 5.61 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19182117830469786		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.19182117830469786 | validation: 0.3354858680734423]
	TIME [epoch: 5.63 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19289023062686447		[learning rate: 0.0060684]
	Learning Rate: 0.00606844
	LOSS [training: 0.19289023062686447 | validation: 0.32293449789926276]
	TIME [epoch: 5.62 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1940507969504527		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.1940507969504527 | validation: 0.3370160860572331]
	TIME [epoch: 5.62 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1872862422127785		[learning rate: 0.0060149]
	Learning Rate: 0.00601493
	LOSS [training: 0.1872862422127785 | validation: 0.31888667147730626]
	TIME [epoch: 5.62 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.185613382635815		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.185613382635815 | validation: 0.3425983884714994]
	TIME [epoch: 5.62 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19113250672871734		[learning rate: 0.0059619]
	Learning Rate: 0.0059619
	LOSS [training: 0.19113250672871734 | validation: 0.349797579568458]
	TIME [epoch: 5.62 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18896451347098614		[learning rate: 0.0059356]
	Learning Rate: 0.00593556
	LOSS [training: 0.18896451347098614 | validation: 0.3043399157404061]
	TIME [epoch: 5.63 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19189486645631967		[learning rate: 0.0059093]
	Learning Rate: 0.00590933
	LOSS [training: 0.19189486645631967 | validation: 0.2984396407123529]
	TIME [epoch: 5.62 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.187133232976549		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.187133232976549 | validation: 0.31258444188437484]
	TIME [epoch: 5.62 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19373897773874485		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.19373897773874485 | validation: 0.30755176739275747]
	TIME [epoch: 5.62 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17987781112895113		[learning rate: 0.0058314]
	Learning Rate: 0.00583135
	LOSS [training: 0.17987781112895113 | validation: 0.3123958510603265]
	TIME [epoch: 5.62 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17840617393272235		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.17840617393272235 | validation: 0.3700309436899286]
	TIME [epoch: 5.62 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18059108166440718		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.18059108166440718 | validation: 0.3074350636449645]
	TIME [epoch: 5.64 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18194849505295974		[learning rate: 0.0057544]
	Learning Rate: 0.0057544
	LOSS [training: 0.18194849505295974 | validation: 0.4122085023574887]
	TIME [epoch: 5.62 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18307147044159217		[learning rate: 0.005729]
	Learning Rate: 0.00572897
	LOSS [training: 0.18307147044159217 | validation: 0.3034821145580288]
	TIME [epoch: 5.62 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17640783274179947		[learning rate: 0.0057037]
	Learning Rate: 0.00570366
	LOSS [training: 0.17640783274179947 | validation: 0.32917637998979093]
	TIME [epoch: 5.62 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19624093294548667		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.19624093294548667 | validation: 0.47078823958302357]
	TIME [epoch: 5.62 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23963666554700674		[learning rate: 0.0056534]
	Learning Rate: 0.00565337
	LOSS [training: 0.23963666554700674 | validation: 0.34694291645456843]
	TIME [epoch: 5.63 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18376226087519426		[learning rate: 0.0056284]
	Learning Rate: 0.0056284
	LOSS [training: 0.18376226087519426 | validation: 0.3242247648478156]
	TIME [epoch: 5.63 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17778775208495967		[learning rate: 0.0056035]
	Learning Rate: 0.00560353
	LOSS [training: 0.17778775208495967 | validation: 0.30816024791567276]
	TIME [epoch: 5.62 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16598325031823502		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.16598325031823502 | validation: 0.317369279378259]
	TIME [epoch: 5.62 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19418886671545948		[learning rate: 0.0055541]
	Learning Rate: 0.00555412
	LOSS [training: 0.19418886671545948 | validation: 0.38840512786590237]
	TIME [epoch: 5.62 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18469981299716925		[learning rate: 0.0055296]
	Learning Rate: 0.00552958
	LOSS [training: 0.18469981299716925 | validation: 0.32374057920413907]
	TIME [epoch: 5.62 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17359924724067052		[learning rate: 0.0055052]
	Learning Rate: 0.00550515
	LOSS [training: 0.17359924724067052 | validation: 0.3267047667584311]
	TIME [epoch: 5.64 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17383627706401064		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.17383627706401064 | validation: 0.3275540802852937]
	TIME [epoch: 5.62 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17439613133355847		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.17439613133355847 | validation: 0.3789288328649586]
	TIME [epoch: 5.62 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18567625048547226		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.18567625048547226 | validation: 0.31618993271465046]
	TIME [epoch: 5.62 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18833654091837498		[learning rate: 0.0054085]
	Learning Rate: 0.0054085
	LOSS [training: 0.18833654091837498 | validation: 0.3150481377882742]
	TIME [epoch: 5.62 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1824496361991771		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.1824496361991771 | validation: 0.31580814905191484]
	TIME [epoch: 5.62 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19316176687577577		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.19316176687577577 | validation: 0.3203827164130185]
	TIME [epoch: 5.64 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18946746981509843		[learning rate: 0.0053371]
	Learning Rate: 0.00533713
	LOSS [training: 0.18946746981509843 | validation: 0.34427173764911717]
	TIME [epoch: 5.61 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17930704634712696		[learning rate: 0.0053135]
	Learning Rate: 0.00531355
	LOSS [training: 0.17930704634712696 | validation: 0.3090622518751469]
	TIME [epoch: 5.62 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18229181633560215		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.18229181633560215 | validation: 0.31356529001195227]
	TIME [epoch: 5.62 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21442522502916903		[learning rate: 0.0052667]
	Learning Rate: 0.0052667
	LOSS [training: 0.21442522502916903 | validation: 0.34444258113379445]
	TIME [epoch: 5.61 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19862562936265954		[learning rate: 0.0052434]
	Learning Rate: 0.00524343
	LOSS [training: 0.19862562936265954 | validation: 0.30842895974038537]
	TIME [epoch: 5.61 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17782175619792748		[learning rate: 0.0052203]
	Learning Rate: 0.00522026
	LOSS [training: 0.17782175619792748 | validation: 0.3084455612787599]
	TIME [epoch: 5.63 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17353299836247116		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.17353299836247116 | validation: 0.29764343348913225]
	TIME [epoch: 5.61 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18532666196158148		[learning rate: 0.0051742]
	Learning Rate: 0.00517423
	LOSS [training: 0.18532666196158148 | validation: 0.3365601396205454]
	TIME [epoch: 5.62 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1863387518760041		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.1863387518760041 | validation: 0.2933651810580756]
	TIME [epoch: 5.61 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v8_20240710_215556/states/model_facs_dec2b_2dpca_v8_190.pth
	Model improved!!!
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1761416972205673		[learning rate: 0.0051286]
	Learning Rate: 0.00512861
	LOSS [training: 0.1761416972205673 | validation: 0.3252422525179598]
	TIME [epoch: 5.62 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1840875089727288		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.1840875089727288 | validation: 0.3170142130377791]
	TIME [epoch: 5.63 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18530754962767518		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.18530754962767518 | validation: 0.3078221288304708]
	TIME [epoch: 5.63 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1828082111035072		[learning rate: 0.0050609]
	Learning Rate: 0.00506093
	LOSS [training: 0.1828082111035072 | validation: 0.3273904392629855]
	TIME [epoch: 5.62 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19145943837146492		[learning rate: 0.0050386]
	Learning Rate: 0.00503857
	LOSS [training: 0.19145943837146492 | validation: 0.36531929123751394]
	TIME [epoch: 5.62 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1685675800620408		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.1685675800620408 | validation: 0.3240385787667042]
	TIME [epoch: 5.62 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1820904140446256		[learning rate: 0.0049941]
	Learning Rate: 0.00499415
	LOSS [training: 0.1820904140446256 | validation: 0.31694784700758855]
	TIME [epoch: 5.62 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16728325359078655		[learning rate: 0.0049721]
	Learning Rate: 0.00497208
	LOSS [training: 0.16728325359078655 | validation: 0.32422181979679554]
	TIME [epoch: 5.63 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1738757845263811		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.1738757845263811 | validation: 0.3241277596314449]
	TIME [epoch: 5.62 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16886958429598112		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.16886958429598112 | validation: 0.3600703983661344]
	TIME [epoch: 5.62 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18703008024740503		[learning rate: 0.0049065]
	Learning Rate: 0.00490647
	LOSS [training: 0.18703008024740503 | validation: 0.36505151129963975]
	TIME [epoch: 5.62 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17708325631093663		[learning rate: 0.0048848]
	Learning Rate: 0.00488479
	LOSS [training: 0.17708325631093663 | validation: 0.35654186161631496]
	TIME [epoch: 5.62 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17669575629465945		[learning rate: 0.0048632]
	Learning Rate: 0.00486321
	LOSS [training: 0.17669575629465945 | validation: 0.3066709743155362]
	TIME [epoch: 5.62 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17063381175538936		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.17063381175538936 | validation: 0.30926176508016207]
	TIME [epoch: 5.63 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17352406291304429		[learning rate: 0.0048203]
	Learning Rate: 0.00482033
	LOSS [training: 0.17352406291304429 | validation: 0.3495239865862335]
	TIME [epoch: 5.61 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18689720648624575		[learning rate: 0.004799]
	Learning Rate: 0.00479903
	LOSS [training: 0.18689720648624575 | validation: 0.3444856186614649]
	TIME [epoch: 5.61 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18112637548998856		[learning rate: 0.0047778]
	Learning Rate: 0.00477783
	LOSS [training: 0.18112637548998856 | validation: 0.2969789738659302]
	TIME [epoch: 5.62 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16502255854733197		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.16502255854733197 | validation: 0.33592262937540485]
	TIME [epoch: 5.62 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17303296512173152		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.17303296512173152 | validation: 0.3373459407545558]
	TIME [epoch: 5.62 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18305624180345056		[learning rate: 0.0047148]
	Learning Rate: 0.00471478
	LOSS [training: 0.18305624180345056 | validation: 0.34692416069506204]
	TIME [epoch: 5.63 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18095978931249318		[learning rate: 0.0046939]
	Learning Rate: 0.00469395
	LOSS [training: 0.18095978931249318 | validation: 0.2975587249975863]
	TIME [epoch: 5.61 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17940467589174142		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.17940467589174142 | validation: 0.3359490977941219]
	TIME [epoch: 5.62 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17343804510494243		[learning rate: 0.0046526]
	Learning Rate: 0.00465256
	LOSS [training: 0.17343804510494243 | validation: 0.32952574799188356]
	TIME [epoch: 5.61 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1826005020215264		[learning rate: 0.004632]
	Learning Rate: 0.00463201
	LOSS [training: 0.1826005020215264 | validation: 0.32117258643054136]
	TIME [epoch: 5.61 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1726005827112124		[learning rate: 0.0046115]
	Learning Rate: 0.00461154
	LOSS [training: 0.1726005827112124 | validation: 0.3075483558247424]
	TIME [epoch: 5.62 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17243424297264504		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.17243424297264504 | validation: 0.2920814922996251]
	TIME [epoch: 5.62 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v8_20240710_215556/states/model_facs_dec2b_2dpca_v8_216.pth
	Model improved!!!
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1791338513989198		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.1791338513989198 | validation: 0.3106858724212813]
	TIME [epoch: 5.62 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.172888235986683		[learning rate: 0.0045507]
	Learning Rate: 0.00455069
	LOSS [training: 0.172888235986683 | validation: 0.30219774642774655]
	TIME [epoch: 5.61 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16684026499254295		[learning rate: 0.0045306]
	Learning Rate: 0.00453058
	LOSS [training: 0.16684026499254295 | validation: 0.30191344756310234]
	TIME [epoch: 5.61 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1797075630081229		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.1797075630081229 | validation: 0.31256501496417466]
	TIME [epoch: 5.61 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.176483517613272		[learning rate: 0.0044906]
	Learning Rate: 0.00449063
	LOSS [training: 0.176483517613272 | validation: 0.3204219567863037]
	TIME [epoch: 5.63 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17804893656164084		[learning rate: 0.0044708]
	Learning Rate: 0.00447079
	LOSS [training: 0.17804893656164084 | validation: 0.3494427237247674]
	TIME [epoch: 5.61 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17145226506793415		[learning rate: 0.004451]
	Learning Rate: 0.00445104
	LOSS [training: 0.17145226506793415 | validation: 0.32011209133812496]
	TIME [epoch: 5.61 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17023257251598004		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.17023257251598004 | validation: 0.31008129969222326]
	TIME [epoch: 5.61 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17722850310732302		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.17722850310732302 | validation: 0.30782666520950625]
	TIME [epoch: 5.61 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17745767782647592		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.17745767782647592 | validation: 0.31021311988191136]
	TIME [epoch: 5.61 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16468100439350042		[learning rate: 0.0043729]
	Learning Rate: 0.0043729
	LOSS [training: 0.16468100439350042 | validation: 0.3214944655006562]
	TIME [epoch: 5.63 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17084986731867274		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.17084986731867274 | validation: 0.30647248750487965]
	TIME [epoch: 5.61 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17140200630610064		[learning rate: 0.0043343]
	Learning Rate: 0.00433434
	LOSS [training: 0.17140200630610064 | validation: 0.300849850382798]
	TIME [epoch: 5.61 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1693048067220165		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 0.1693048067220165 | validation: 0.32436009557737056]
	TIME [epoch: 5.61 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1809973002544542		[learning rate: 0.0042961]
	Learning Rate: 0.00429612
	LOSS [training: 0.1809973002544542 | validation: 0.3384675790526298]
	TIME [epoch: 5.61 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17721713731508976		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.17721713731508976 | validation: 0.3205934582786074]
	TIME [epoch: 5.62 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18700944718968388		[learning rate: 0.0042582]
	Learning Rate: 0.00425825
	LOSS [training: 0.18700944718968388 | validation: 0.31863277822014324]
	TIME [epoch: 5.63 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17413400248282088		[learning rate: 0.0042394]
	Learning Rate: 0.00423943
	LOSS [training: 0.17413400248282088 | validation: 0.3073415863186775]
	TIME [epoch: 5.61 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17179628353239773		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.17179628353239773 | validation: 0.34440109619721726]
	TIME [epoch: 5.61 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20447182363705188		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.20447182363705188 | validation: 0.3989449080871986]
	TIME [epoch: 5.61 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2255707128671065		[learning rate: 0.0041835]
	Learning Rate: 0.00418349
	LOSS [training: 0.2255707128671065 | validation: 0.3398655050142194]
	TIME [epoch: 5.61 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17939700667397912		[learning rate: 0.004165]
	Learning Rate: 0.004165
	LOSS [training: 0.17939700667397912 | validation: 0.327278473083141]
	TIME [epoch: 5.62 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17611994187815946		[learning rate: 0.0041466]
	Learning Rate: 0.0041466
	LOSS [training: 0.17611994187815946 | validation: 0.34224880706755173]
	TIME [epoch: 5.62 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16905618434638334		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.16905618434638334 | validation: 0.305203648045049]
	TIME [epoch: 5.61 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16573060900964154		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.16573060900964154 | validation: 0.32583684719653067]
	TIME [epoch: 5.62 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16833927199495147		[learning rate: 0.0040919]
	Learning Rate: 0.00409188
	LOSS [training: 0.16833927199495147 | validation: 0.30718929088128916]
	TIME [epoch: 5.62 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1692017417746272		[learning rate: 0.0040738]
	Learning Rate: 0.0040738
	LOSS [training: 0.1692017417746272 | validation: 0.30129847313940855]
	TIME [epoch: 5.61 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17551305398577716		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.17551305398577716 | validation: 0.3339544975027089]
	TIME [epoch: 5.62 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17559720855673094		[learning rate: 0.0040379]
	Learning Rate: 0.00403788
	LOSS [training: 0.17559720855673094 | validation: 0.3112159012716595]
	TIME [epoch: 5.62 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1737680183253683		[learning rate: 0.00402]
	Learning Rate: 0.00402004
	LOSS [training: 0.1737680183253683 | validation: 0.3793365861445006]
	TIME [epoch: 5.61 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22917329400801972		[learning rate: 0.0040023]
	Learning Rate: 0.00400228
	LOSS [training: 0.22917329400801972 | validation: 0.3070151649597588]
	TIME [epoch: 5.61 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1735882700186619		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.1735882700186619 | validation: 0.3001671225530876]
	TIME [epoch: 5.61 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1765006484136253		[learning rate: 0.003967]
	Learning Rate: 0.00396699
	LOSS [training: 0.1765006484136253 | validation: 0.3271492407842404]
	TIME [epoch: 5.62 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17260356069603242		[learning rate: 0.0039495]
	Learning Rate: 0.00394947
	LOSS [training: 0.17260356069603242 | validation: 0.3078943052303055]
	TIME [epoch: 5.63 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1664262755763485		[learning rate: 0.003932]
	Learning Rate: 0.00393202
	LOSS [training: 0.1664262755763485 | validation: 0.3072606166515623]
	TIME [epoch: 5.61 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1635230122104768		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.1635230122104768 | validation: 0.29655727089635314]
	TIME [epoch: 5.61 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16831978762834615		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.16831978762834615 | validation: 0.3201436351042086]
	TIME [epoch: 5.61 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1642565123414204		[learning rate: 0.0038801]
	Learning Rate: 0.00388013
	LOSS [training: 0.1642565123414204 | validation: 0.3059254758517347]
	TIME [epoch: 5.61 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18021215255917525		[learning rate: 0.003863]
	Learning Rate: 0.00386299
	LOSS [training: 0.18021215255917525 | validation: 0.31259854573313933]
	TIME [epoch: 5.61 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1868663287393953		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.1868663287393953 | validation: 0.3650303025190126]
	TIME [epoch: 5.63 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2142653911311637		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.2142653911311637 | validation: 0.3278215557957574]
	TIME [epoch: 5.61 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18008686217964326		[learning rate: 0.003812]
	Learning Rate: 0.00381201
	LOSS [training: 0.18008686217964326 | validation: 0.3145053337347523]
	TIME [epoch: 5.61 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16796252672580367		[learning rate: 0.0037952]
	Learning Rate: 0.00379517
	LOSS [training: 0.16796252672580367 | validation: 0.3028730938068885]
	TIME [epoch: 5.61 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16727279964358802		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.16727279964358802 | validation: 0.3140224112344293]
	TIME [epoch: 5.61 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17434376858174452		[learning rate: 0.0037617]
	Learning Rate: 0.0037617
	LOSS [training: 0.17434376858174452 | validation: 0.29646867419745004]
	TIME [epoch: 5.62 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16397302253944845		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.16397302253944845 | validation: 0.3093878150361556]
	TIME [epoch: 5.62 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16715421442008477		[learning rate: 0.0037285]
	Learning Rate: 0.00372854
	LOSS [training: 0.16715421442008477 | validation: 0.3083440208364105]
	TIME [epoch: 5.61 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16730163755113198		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.16730163755113198 | validation: 0.326611415375479]
	TIME [epoch: 5.61 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16445652782548856		[learning rate: 0.0036957]
	Learning Rate: 0.00369566
	LOSS [training: 0.16445652782548856 | validation: 0.3202875041230819]
	TIME [epoch: 5.61 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16615432106566294		[learning rate: 0.0036793]
	Learning Rate: 0.00367933
	LOSS [training: 0.16615432106566294 | validation: 0.31834675967853376]
	TIME [epoch: 5.61 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1631100230713543		[learning rate: 0.0036631]
	Learning Rate: 0.00366308
	LOSS [training: 0.1631100230713543 | validation: 0.31004489433273463]
	TIME [epoch: 5.62 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16428473974027283		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.16428473974027283 | validation: 0.3076254934272682]
	TIME [epoch: 5.62 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1696963490160066		[learning rate: 0.0036308]
	Learning Rate: 0.00363078
	LOSS [training: 0.1696963490160066 | validation: 0.31307476764085945]
	TIME [epoch: 5.61 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16871469064658176		[learning rate: 0.0036147]
	Learning Rate: 0.00361474
	LOSS [training: 0.16871469064658176 | validation: 0.31067783035418883]
	TIME [epoch: 5.61 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16627518398393892		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.16627518398393892 | validation: 0.3020487290653951]
	TIME [epoch: 5.61 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17267494064145128		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.17267494064145128 | validation: 0.2987754433959086]
	TIME [epoch: 5.61 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16750181569061057		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.16750181569061057 | validation: 0.3070373811304923]
	TIME [epoch: 5.63 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16840361134888748		[learning rate: 0.0035513]
	Learning Rate: 0.00355128
	LOSS [training: 0.16840361134888748 | validation: 0.3101842596077381]
	TIME [epoch: 5.61 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19473624033542922		[learning rate: 0.0035356]
	Learning Rate: 0.00353559
	LOSS [training: 0.19473624033542922 | validation: 0.306427078876713]
	TIME [epoch: 5.61 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.171630387108681		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.171630387108681 | validation: 0.32522106917578375]
	TIME [epoch: 5.65 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17278280144851108		[learning rate: 0.0035044]
	Learning Rate: 0.00350441
	LOSS [training: 0.17278280144851108 | validation: 0.31967940512082055]
	TIME [epoch: 5.61 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17920467805873247		[learning rate: 0.0034889]
	Learning Rate: 0.00348893
	LOSS [training: 0.17920467805873247 | validation: 0.30691768617934595]
	TIME [epoch: 5.61 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17322604358113255		[learning rate: 0.0034735]
	Learning Rate: 0.00347352
	LOSS [training: 0.17322604358113255 | validation: 0.31586269198482914]
	TIME [epoch: 5.63 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16153221434913137		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.16153221434913137 | validation: 0.31016715437646114]
	TIME [epoch: 5.65 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17161026205669144		[learning rate: 0.0034429]
	Learning Rate: 0.00344289
	LOSS [training: 0.17161026205669144 | validation: 0.30354708529382296]
	TIME [epoch: 5.61 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19356231642754762		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 0.19356231642754762 | validation: 0.3720797573720265]
	TIME [epoch: 5.61 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17735987670671532		[learning rate: 0.0034125]
	Learning Rate: 0.00341253
	LOSS [training: 0.17735987670671532 | validation: 0.3039807269747746]
	TIME [epoch: 5.61 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16411421676474658		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.16411421676474658 | validation: 0.31192381001711816]
	TIME [epoch: 5.61 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16755534906697517		[learning rate: 0.0033824]
	Learning Rate: 0.00338245
	LOSS [training: 0.16755534906697517 | validation: 0.2941205364267766]
	TIME [epoch: 5.63 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16670818212433847		[learning rate: 0.0033675]
	Learning Rate: 0.0033675
	LOSS [training: 0.16670818212433847 | validation: 0.27793987901381934]
	TIME [epoch: 5.61 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v8_20240710_215556/states/model_facs_dec2b_2dpca_v8_286.pth
	Model improved!!!
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16772493864241653		[learning rate: 0.0033526]
	Learning Rate: 0.00335262
	LOSS [training: 0.16772493864241653 | validation: 0.29226786522695164]
	TIME [epoch: 5.62 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16390765883450117		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.16390765883450117 | validation: 0.3120859973991156]
	TIME [epoch: 5.62 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16949637716838678		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.16949637716838678 | validation: 0.29204745876415616]
	TIME [epoch: 5.61 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17587939011421622		[learning rate: 0.0033084]
	Learning Rate: 0.00330838
	LOSS [training: 0.17587939011421622 | validation: 0.3042317166014752]
	TIME [epoch: 5.62 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17428424920983399		[learning rate: 0.0032938]
	Learning Rate: 0.00329376
	LOSS [training: 0.17428424920983399 | validation: 0.3246945966940523]
	TIME [epoch: 5.62 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16739635177812837		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.16739635177812837 | validation: 0.3261074814349626]
	TIME [epoch: 5.61 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16947324386003348		[learning rate: 0.0032647]
	Learning Rate: 0.00326472
	LOSS [training: 0.16947324386003348 | validation: 0.31439929770486547]
	TIME [epoch: 5.61 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17142148045392244		[learning rate: 0.0032503]
	Learning Rate: 0.0032503
	LOSS [training: 0.17142148045392244 | validation: 0.3047899501003923]
	TIME [epoch: 5.61 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17054363788336607		[learning rate: 0.0032359]
	Learning Rate: 0.00323594
	LOSS [training: 0.17054363788336607 | validation: 0.29101948695709656]
	TIME [epoch: 5.61 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16817189728448506		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.16817189728448506 | validation: 0.3074031869344801]
	TIME [epoch: 5.63 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17351010882507778		[learning rate: 0.0032074]
	Learning Rate: 0.00320741
	LOSS [training: 0.17351010882507778 | validation: 0.3038404023989062]
	TIME [epoch: 5.62 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1649790574774811		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.1649790574774811 | validation: 0.3075359181238338]
	TIME [epoch: 5.61 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16531984269078587		[learning rate: 0.0031791]
	Learning Rate: 0.00317913
	LOSS [training: 0.16531984269078587 | validation: 0.3042063259916108]
	TIME [epoch: 5.61 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17323684582660537		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.17323684582660537 | validation: 0.3081141599140714]
	TIME [epoch: 5.61 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19642218879869308		[learning rate: 0.0031511]
	Learning Rate: 0.0031511
	LOSS [training: 0.19642218879869308 | validation: 0.29162311459277196]
	TIME [epoch: 5.62 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1657295175316299		[learning rate: 0.0031372]
	Learning Rate: 0.00313717
	LOSS [training: 0.1657295175316299 | validation: 0.2966181771424058]
	TIME [epoch: 5.63 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1641762517342084		[learning rate: 0.0031233]
	Learning Rate: 0.00312331
	LOSS [training: 0.1641762517342084 | validation: 0.2924198325924158]
	TIME [epoch: 5.61 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1679683823737464		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.1679683823737464 | validation: 0.2958328078489583]
	TIME [epoch: 5.62 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1679504080882528		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.1679504080882528 | validation: 0.3122114511127343]
	TIME [epoch: 5.61 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1742981718073677		[learning rate: 0.0030821]
	Learning Rate: 0.0030821
	LOSS [training: 0.1742981718073677 | validation: 0.3052768101876303]
	TIME [epoch: 5.62 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16454149531114654		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.16454149531114654 | validation: 0.2842020808464752]
	TIME [epoch: 5.62 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15985127241613883		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.15985127241613883 | validation: 0.31366904211446006]
	TIME [epoch: 5.63 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1580597074985184		[learning rate: 0.0030414]
	Learning Rate: 0.00304142
	LOSS [training: 0.1580597074985184 | validation: 0.31274828592784387]
	TIME [epoch: 5.61 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16800800460425475		[learning rate: 0.003028]
	Learning Rate: 0.00302799
	LOSS [training: 0.16800800460425475 | validation: 0.3340432564835077]
	TIME [epoch: 5.61 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1700796231935294		[learning rate: 0.0030146]
	Learning Rate: 0.00301461
	LOSS [training: 0.1700796231935294 | validation: 0.30878794814105687]
	TIME [epoch: 5.61 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16491084235925393		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.16491084235925393 | validation: 0.3037687621916807]
	TIME [epoch: 5.62 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1681980056269035		[learning rate: 0.002988]
	Learning Rate: 0.00298803
	LOSS [training: 0.1681980056269035 | validation: 0.3334370443248339]
	TIME [epoch: 5.62 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17076291397361276		[learning rate: 0.0029748]
	Learning Rate: 0.00297483
	LOSS [training: 0.17076291397361276 | validation: 0.2835269067362817]
	TIME [epoch: 5.62 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16615052707340763		[learning rate: 0.0029617]
	Learning Rate: 0.00296168
	LOSS [training: 0.16615052707340763 | validation: 0.3070798199884053]
	TIME [epoch: 5.61 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16292743427977013		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.16292743427977013 | validation: 0.3124216149895226]
	TIME [epoch: 5.61 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16702657856394204		[learning rate: 0.0029356]
	Learning Rate: 0.00293557
	LOSS [training: 0.16702657856394204 | validation: 0.2924323707856901]
	TIME [epoch: 5.61 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17165235569074602		[learning rate: 0.0029226]
	Learning Rate: 0.0029226
	LOSS [training: 0.17165235569074602 | validation: 0.30874499133721994]
	TIME [epoch: 5.61 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1685804604069637		[learning rate: 0.0029097]
	Learning Rate: 0.00290969
	LOSS [training: 0.1685804604069637 | validation: 0.28586873439847416]
	TIME [epoch: 5.62 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1652579870284653		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.1652579870284653 | validation: 0.31547095391156316]
	TIME [epoch: 5.62 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.165596480008293		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.165596480008293 | validation: 0.2980330879201042]
	TIME [epoch: 5.61 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16099323673457405		[learning rate: 0.0028713]
	Learning Rate: 0.00287129
	LOSS [training: 0.16099323673457405 | validation: 0.325549505435286]
	TIME [epoch: 5.61 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17227501177374166		[learning rate: 0.0028586]
	Learning Rate: 0.0028586
	LOSS [training: 0.17227501177374166 | validation: 0.3230148020383467]
	TIME [epoch: 5.62 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16748469385453563		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.16748469385453563 | validation: 0.3008497950201962]
	TIME [epoch: 5.61 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17055234228957367		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.17055234228957367 | validation: 0.29190799253071037]
	TIME [epoch: 5.62 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15893852657726276		[learning rate: 0.0028209]
	Learning Rate: 0.00282088
	LOSS [training: 0.15893852657726276 | validation: 0.2994454564483855]
	TIME [epoch: 5.61 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16265236876186837		[learning rate: 0.0028084]
	Learning Rate: 0.00280842
	LOSS [training: 0.16265236876186837 | validation: 0.2989150656430193]
	TIME [epoch: 5.61 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1669466648019181		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.1669466648019181 | validation: 0.28909539470164164]
	TIME [epoch: 5.61 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16328493648100442		[learning rate: 0.0027837]
	Learning Rate: 0.00278366
	LOSS [training: 0.16328493648100442 | validation: 0.3118922660991586]
	TIME [epoch: 5.61 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1667923399958094		[learning rate: 0.0027714]
	Learning Rate: 0.00277136
	LOSS [training: 0.1667923399958094 | validation: 0.2928042947788887]
	TIME [epoch: 5.61 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16016150015364516		[learning rate: 0.0027591]
	Learning Rate: 0.00275911
	LOSS [training: 0.16016150015364516 | validation: 0.30269523918974733]
	TIME [epoch: 5.63 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16658960840531917		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.16658960840531917 | validation: 0.3207746486169158]
	TIME [epoch: 5.61 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16344429299647548		[learning rate: 0.0027348]
	Learning Rate: 0.00273478
	LOSS [training: 0.16344429299647548 | validation: 0.3056622063173609]
	TIME [epoch: 5.61 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16098193301053654		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.16098193301053654 | validation: 0.31557270559107986]
	TIME [epoch: 5.61 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16561797149298724		[learning rate: 0.0027107]
	Learning Rate: 0.00271067
	LOSS [training: 0.16561797149298724 | validation: 0.2896181847196081]
	TIME [epoch: 5.61 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15961258743139178		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.15961258743139178 | validation: 0.29692165695668954]
	TIME [epoch: 5.62 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16799595877848789		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.16799595877848789 | validation: 0.30672474466314253]
	TIME [epoch: 5.62 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16509935128618608		[learning rate: 0.0026749]
	Learning Rate: 0.0026749
	LOSS [training: 0.16509935128618608 | validation: 0.3033374517348849]
	TIME [epoch: 5.61 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16634036935076338		[learning rate: 0.0026631]
	Learning Rate: 0.00266308
	LOSS [training: 0.16634036935076338 | validation: 0.3040583208832514]
	TIME [epoch: 5.62 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16605077173995042		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.16605077173995042 | validation: 0.3026820789648041]
	TIME [epoch: 5.62 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1656778022416277		[learning rate: 0.0026396]
	Learning Rate: 0.0026396
	LOSS [training: 0.1656778022416277 | validation: 0.2999415435546274]
	TIME [epoch: 5.62 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1691995765026485		[learning rate: 0.0026279]
	Learning Rate: 0.00262794
	LOSS [training: 0.1691995765026485 | validation: 0.29687831657145236]
	TIME [epoch: 5.62 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16523685873193988		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.16523685873193988 | validation: 0.2995752956344187]
	TIME [epoch: 5.62 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16398503711929052		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.16398503711929052 | validation: 0.2931789522472954]
	TIME [epoch: 5.61 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16557854283459322		[learning rate: 0.0025933]
	Learning Rate: 0.00259326
	LOSS [training: 0.16557854283459322 | validation: 0.3144594287980822]
	TIME [epoch: 5.61 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16432178094186697		[learning rate: 0.0025818]
	Learning Rate: 0.0025818
	LOSS [training: 0.16432178094186697 | validation: 0.30173093334746565]
	TIME [epoch: 5.62 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16117872290681418		[learning rate: 0.0025704]
	Learning Rate: 0.0025704
	LOSS [training: 0.16117872290681418 | validation: 0.30381264132645647]
	TIME [epoch: 5.62 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16030831137456086		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.16030831137456086 | validation: 0.3042754106828882]
	TIME [epoch: 5.63 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16583402990902002		[learning rate: 0.0025477]
	Learning Rate: 0.00254773
	LOSS [training: 0.16583402990902002 | validation: 0.3064903276890039]
	TIME [epoch: 5.62 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17416093797599466		[learning rate: 0.0025365]
	Learning Rate: 0.00253648
	LOSS [training: 0.17416093797599466 | validation: 0.31120563450057126]
	TIME [epoch: 5.61 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16799699742861818		[learning rate: 0.0025253]
	Learning Rate: 0.00252527
	LOSS [training: 0.16799699742861818 | validation: 0.3006409678295049]
	TIME [epoch: 5.62 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15812964113855726		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.15812964113855726 | validation: 0.29537656729525785]
	TIME [epoch: 5.62 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16287056445517237		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.16287056445517237 | validation: 0.2992268303217691]
	TIME [epoch: 5.62 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16156470583933874		[learning rate: 0.0024919]
	Learning Rate: 0.00249194
	LOSS [training: 0.16156470583933874 | validation: 0.29573177618036856]
	TIME [epoch: 5.63 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17123358279240122		[learning rate: 0.0024809]
	Learning Rate: 0.00248093
	LOSS [training: 0.17123358279240122 | validation: 0.3092575825837576]
	TIME [epoch: 5.62 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16037077342002817		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.16037077342002817 | validation: 0.30234242216611235]
	TIME [epoch: 5.61 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.157808039360476		[learning rate: 0.0024591]
	Learning Rate: 0.00245906
	LOSS [training: 0.157808039360476 | validation: 0.3140349302729425]
	TIME [epoch: 5.61 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16685561214186345		[learning rate: 0.0024482]
	Learning Rate: 0.0024482
	LOSS [training: 0.16685561214186345 | validation: 0.30002170220462215]
	TIME [epoch: 5.61 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16025138421501953		[learning rate: 0.0024374]
	Learning Rate: 0.00243738
	LOSS [training: 0.16025138421501953 | validation: 0.30905472568820064]
	TIME [epoch: 5.62 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1602991352590156		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.1602991352590156 | validation: 0.31765101869036444]
	TIME [epoch: 5.63 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1738635926796166		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.1738635926796166 | validation: 0.2899312978428704]
	TIME [epoch: 5.61 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15973281879347573		[learning rate: 0.0024052]
	Learning Rate: 0.00240521
	LOSS [training: 0.15973281879347573 | validation: 0.2987726971914645]
	TIME [epoch: 5.62 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1630784829608213		[learning rate: 0.0023946]
	Learning Rate: 0.00239459
	LOSS [training: 0.1630784829608213 | validation: 0.29788887090459015]
	TIME [epoch: 5.61 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1598286403100587		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.1598286403100587 | validation: 0.31403142323045324]
	TIME [epoch: 5.61 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16249360728300105		[learning rate: 0.0023735]
	Learning Rate: 0.00237347
	LOSS [training: 0.16249360728300105 | validation: 0.3145029659690063]
	TIME [epoch: 5.62 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16203346376721053		[learning rate: 0.002363]
	Learning Rate: 0.00236299
	LOSS [training: 0.16203346376721053 | validation: 0.3012399021551713]
	TIME [epoch: 5.63 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16104627945264474		[learning rate: 0.0023525]
	Learning Rate: 0.00235255
	LOSS [training: 0.16104627945264474 | validation: 0.30956375261039126]
	TIME [epoch: 5.61 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16360613675923225		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.16360613675923225 | validation: 0.28125991968338904]
	TIME [epoch: 5.62 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15595747089615536		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.15595747089615536 | validation: 0.30258587797715636]
	TIME [epoch: 5.61 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17338170679735015		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.17338170679735015 | validation: 0.2950251907397836]
	TIME [epoch: 5.62 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1623997252482415		[learning rate: 0.0023112]
	Learning Rate: 0.00231125
	LOSS [training: 0.1623997252482415 | validation: 0.29758939776260823]
	TIME [epoch: 5.63 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16433786594207317		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.16433786594207317 | validation: 0.30242036331890787]
	TIME [epoch: 5.62 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15639395486818772		[learning rate: 0.0022909]
	Learning Rate: 0.00229087
	LOSS [training: 0.15639395486818772 | validation: 0.32013406849170506]
	TIME [epoch: 5.62 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1609670112368479		[learning rate: 0.0022807]
	Learning Rate: 0.00228075
	LOSS [training: 0.1609670112368479 | validation: 0.30588149191566427]
	TIME [epoch: 5.61 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1665067500837958		[learning rate: 0.0022707]
	Learning Rate: 0.00227067
	LOSS [training: 0.1665067500837958 | validation: 0.35042317086476593]
	TIME [epoch: 5.62 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16460769468340844		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.16460769468340844 | validation: 0.30339269742264585]
	TIME [epoch: 5.62 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16507226717318793		[learning rate: 0.0022506]
	Learning Rate: 0.00225065
	LOSS [training: 0.16507226717318793 | validation: 0.32389559945943397]
	TIME [epoch: 5.63 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17601195135341852		[learning rate: 0.0022407]
	Learning Rate: 0.0022407
	LOSS [training: 0.17601195135341852 | validation: 0.3081993350087044]
	TIME [epoch: 5.62 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16013456211747884		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.16013456211747884 | validation: 0.3003019565422511]
	TIME [epoch: 5.62 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15528740827727588		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.15528740827727588 | validation: 0.2952926601265254]
	TIME [epoch: 5.61 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15702739640907382		[learning rate: 0.0022111]
	Learning Rate: 0.00221114
	LOSS [training: 0.15702739640907382 | validation: 0.30988333293336534]
	TIME [epoch: 5.61 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16237969405432695		[learning rate: 0.0022014]
	Learning Rate: 0.00220137
	LOSS [training: 0.16237969405432695 | validation: 0.300104954047918]
	TIME [epoch: 5.61 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15775986111824455		[learning rate: 0.0021916]
	Learning Rate: 0.00219164
	LOSS [training: 0.15775986111824455 | validation: 0.27931625732429055]
	TIME [epoch: 5.63 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1576332437157985		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.1576332437157985 | validation: 0.3040200492739555]
	TIME [epoch: 5.61 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1573001901815553		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.1573001901815553 | validation: 0.32121493773693427]
	TIME [epoch: 5.61 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.155666961274044		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: 0.155666961274044 | validation: 0.29478748644653807]
	TIME [epoch: 5.61 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16231566870751904		[learning rate: 0.0021532]
	Learning Rate: 0.00215316
	LOSS [training: 0.16231566870751904 | validation: 0.32663197947180633]
	TIME [epoch: 5.62 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16132699276971582		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.16132699276971582 | validation: 0.31473414198072924]
	TIME [epoch: 5.62 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1615763777073719		[learning rate: 0.0021342]
	Learning Rate: 0.00213418
	LOSS [training: 0.1615763777073719 | validation: 0.2969941144454211]
	TIME [epoch: 5.63 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16139973055638224		[learning rate: 0.0021247]
	Learning Rate: 0.00212475
	LOSS [training: 0.16139973055638224 | validation: 0.30057426245762636]
	TIME [epoch: 5.61 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15976773621295184		[learning rate: 0.0021154]
	Learning Rate: 0.00211536
	LOSS [training: 0.15976773621295184 | validation: 0.3004276160149529]
	TIME [epoch: 5.62 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1585933760852227		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.1585933760852227 | validation: 0.30085548407200374]
	TIME [epoch: 5.61 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15930815835216083		[learning rate: 0.0020967]
	Learning Rate: 0.00209671
	LOSS [training: 0.15930815835216083 | validation: 0.31479038253306624]
	TIME [epoch: 5.62 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16072189276513846		[learning rate: 0.0020874]
	Learning Rate: 0.00208745
	LOSS [training: 0.16072189276513846 | validation: 0.2897189839531178]
	TIME [epoch: 5.62 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1689827877262687		[learning rate: 0.0020782]
	Learning Rate: 0.00207822
	LOSS [training: 0.1689827877262687 | validation: 0.2989613791038402]
	TIME [epoch: 5.63 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16298215378458328		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.16298215378458328 | validation: 0.3291437131806737]
	TIME [epoch: 5.61 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1683068701755268		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.1683068701755268 | validation: 0.3061573566896787]
	TIME [epoch: 5.62 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15713886634664576		[learning rate: 0.0020508]
	Learning Rate: 0.0020508
	LOSS [training: 0.15713886634664576 | validation: 0.29370602185453243]
	TIME [epoch: 5.62 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1525163720587914		[learning rate: 0.0020417]
	Learning Rate: 0.00204174
	LOSS [training: 0.1525163720587914 | validation: 0.2896443977941724]
	TIME [epoch: 5.62 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16251653360076307		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.16251653360076307 | validation: 0.2873834648759899]
	TIME [epoch: 5.63 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15476267276035188		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.15476267276035188 | validation: 0.2998428953418376]
	TIME [epoch: 5.62 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1555200270049515		[learning rate: 0.0020148]
	Learning Rate: 0.00201479
	LOSS [training: 0.1555200270049515 | validation: 0.30948366640208924]
	TIME [epoch: 5.62 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16481107732021388		[learning rate: 0.0020059]
	Learning Rate: 0.00200589
	LOSS [training: 0.16481107732021388 | validation: 0.30970347961559835]
	TIME [epoch: 5.62 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1630997687407063		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.1630997687407063 | validation: 0.30765504522213216]
	TIME [epoch: 5.62 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15967089500776396		[learning rate: 0.0019882]
	Learning Rate: 0.00198821
	LOSS [training: 0.15967089500776396 | validation: 0.29643017728308446]
	TIME [epoch: 5.62 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15720621749652608		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.15720621749652608 | validation: 0.31555837931261244]
	TIME [epoch: 5.63 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15838417451018136		[learning rate: 0.0019707]
	Learning Rate: 0.00197068
	LOSS [training: 0.15838417451018136 | validation: 0.31634685549684605]
	TIME [epoch: 5.62 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1553949062287961		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.1553949062287961 | validation: 0.2906198097988633]
	TIME [epoch: 5.61 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16574714679883967		[learning rate: 0.0019533]
	Learning Rate: 0.0019533
	LOSS [training: 0.16574714679883967 | validation: 0.30625327886995957]
	TIME [epoch: 5.61 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16354724904926168		[learning rate: 0.0019447]
	Learning Rate: 0.00194467
	LOSS [training: 0.16354724904926168 | validation: 0.3043810104352775]
	TIME [epoch: 5.62 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16107565863442977		[learning rate: 0.0019361]
	Learning Rate: 0.00193608
	LOSS [training: 0.16107565863442977 | validation: 0.32043451494339165]
	TIME [epoch: 5.62 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.157321862930831		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.157321862930831 | validation: 0.29947550763914627]
	TIME [epoch: 5.63 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1635816831815946		[learning rate: 0.001919]
	Learning Rate: 0.00191901
	LOSS [training: 0.1635816831815946 | validation: 0.30413487489830915]
	TIME [epoch: 5.62 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15828948146459285		[learning rate: 0.0019105]
	Learning Rate: 0.00191053
	LOSS [training: 0.15828948146459285 | validation: 0.305564183326496]
	TIME [epoch: 5.61 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16218556722318833		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.16218556722318833 | validation: 0.3069715408171554]
	TIME [epoch: 5.62 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16374118537142093		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.16374118537142093 | validation: 0.29551086985858205]
	TIME [epoch: 5.61 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16154097543042578		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.16154097543042578 | validation: 0.3000394568641392]
	TIME [epoch: 5.62 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15443100453358136		[learning rate: 0.001877]
	Learning Rate: 0.00187699
	LOSS [training: 0.15443100453358136 | validation: 0.30695651403677365]
	TIME [epoch: 5.62 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15683555130697763		[learning rate: 0.0018687]
	Learning Rate: 0.0018687
	LOSS [training: 0.15683555130697763 | validation: 0.3226393179272359]
	TIME [epoch: 5.61 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16223336154491846		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.16223336154491846 | validation: 0.46261709611248664]
	TIME [epoch: 5.62 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16682285387949053		[learning rate: 0.0018522]
	Learning Rate: 0.00185222
	LOSS [training: 0.16682285387949053 | validation: 0.3561242231812705]
	TIME [epoch: 5.62 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1607000968088132		[learning rate: 0.001844]
	Learning Rate: 0.00184404
	LOSS [training: 0.1607000968088132 | validation: 0.30946860327390735]
	TIME [epoch: 5.62 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15816073447695428		[learning rate: 0.0018359]
	Learning Rate: 0.00183589
	LOSS [training: 0.15816073447695428 | validation: 0.2951319756755051]
	TIME [epoch: 5.63 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16225525268600013		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.16225525268600013 | validation: 0.2962438383288101]
	TIME [epoch: 5.62 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16556363543986713		[learning rate: 0.0018197]
	Learning Rate: 0.0018197
	LOSS [training: 0.16556363543986713 | validation: 0.3070156261272222]
	TIME [epoch: 5.62 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16182638985464995		[learning rate: 0.0018117]
	Learning Rate: 0.00181166
	LOSS [training: 0.16182638985464995 | validation: 0.3024964985103646]
	TIME [epoch: 5.61 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16663936900536447		[learning rate: 0.0018037]
	Learning Rate: 0.00180366
	LOSS [training: 0.16663936900536447 | validation: 0.30732894323042603]
	TIME [epoch: 5.62 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15725240709586483		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.15725240709586483 | validation: 0.28690813591833847]
	TIME [epoch: 5.62 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15163674381305642		[learning rate: 0.0017878]
	Learning Rate: 0.00178775
	LOSS [training: 0.15163674381305642 | validation: 0.31086306441786876]
	TIME [epoch: 5.63 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15601576801405423		[learning rate: 0.0017799]
	Learning Rate: 0.00177985
	LOSS [training: 0.15601576801405423 | validation: 0.3072094308499502]
	TIME [epoch: 5.62 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1571594203931605		[learning rate: 0.001772]
	Learning Rate: 0.00177199
	LOSS [training: 0.1571594203931605 | validation: 0.3172870229677362]
	TIME [epoch: 5.62 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15928003414532113		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.15928003414532113 | validation: 0.2961953120858163]
	TIME [epoch: 5.61 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1560815770012705		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.1560815770012705 | validation: 0.2975618203088807]
	TIME [epoch: 5.62 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1576270074164557		[learning rate: 0.0017486]
	Learning Rate: 0.00174861
	LOSS [training: 0.1576270074164557 | validation: 0.30486805005298134]
	TIME [epoch: 5.62 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1567083746558725		[learning rate: 0.0017409]
	Learning Rate: 0.00174088
	LOSS [training: 0.1567083746558725 | validation: 0.2970074570497099]
	TIME [epoch: 5.63 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15914485863078598		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.15914485863078598 | validation: 0.29575945226803485]
	TIME [epoch: 5.62 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1590134369510682		[learning rate: 0.0017255]
	Learning Rate: 0.00172553
	LOSS [training: 0.1590134369510682 | validation: 0.3060820451174861]
	TIME [epoch: 5.62 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16458299081291577		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: 0.16458299081291577 | validation: 0.3032830862320194]
	TIME [epoch: 5.61 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15648220461423096		[learning rate: 0.0017103]
	Learning Rate: 0.00171032
	LOSS [training: 0.15648220461423096 | validation: 0.3045533655621285]
	TIME [epoch: 5.62 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16024494210278287		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.16024494210278287 | validation: 0.30333891750111347]
	TIME [epoch: 5.62 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15137057158964512		[learning rate: 0.0016952]
	Learning Rate: 0.00169524
	LOSS [training: 0.15137057158964512 | validation: 0.306701601961154]
	TIME [epoch: 5.62 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15680563674399298		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.15680563674399298 | validation: 0.32102176209850575]
	TIME [epoch: 5.61 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15404703232858466		[learning rate: 0.0016803]
	Learning Rate: 0.00168029
	LOSS [training: 0.15404703232858466 | validation: 0.28824580983041903]
	TIME [epoch: 5.62 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16297080567340916		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.16297080567340916 | validation: 0.2977928199870946]
	TIME [epoch: 5.61 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1613114263900734		[learning rate: 0.0016655]
	Learning Rate: 0.00166548
	LOSS [training: 0.1613114263900734 | validation: 0.30778257713877577]
	TIME [epoch: 5.61 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15943938991318435		[learning rate: 0.0016581]
	Learning Rate: 0.00165812
	LOSS [training: 0.15943938991318435 | validation: 0.31902979728662206]
	TIME [epoch: 5.62 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15988194852613274		[learning rate: 0.0016508]
	Learning Rate: 0.00165079
	LOSS [training: 0.15988194852613274 | validation: 0.3155056566114496]
	TIME [epoch: 5.62 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16032826914229964		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.16032826914229964 | validation: 0.3094941928959503]
	TIME [epoch: 5.61 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1614197958615729		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.1614197958615729 | validation: 0.3046843689054091]
	TIME [epoch: 5.61 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16230549482070375		[learning rate: 0.001629]
	Learning Rate: 0.00162901
	LOSS [training: 0.16230549482070375 | validation: 0.3025371105012657]
	TIME [epoch: 5.61 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15680763837173375		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.15680763837173375 | validation: 0.30839060545651803]
	TIME [epoch: 5.62 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16039501447395874		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.16039501447395874 | validation: 0.29464777077433885]
	TIME [epoch: 5.63 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15150603517274286		[learning rate: 0.0016075]
	Learning Rate: 0.00160751
	LOSS [training: 0.15150603517274286 | validation: 0.2899214059959195]
	TIME [epoch: 5.61 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15467444880586473		[learning rate: 0.0016004]
	Learning Rate: 0.00160041
	LOSS [training: 0.15467444880586473 | validation: 0.3109651860687078]
	TIME [epoch: 5.61 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15494506296076244		[learning rate: 0.0015933]
	Learning Rate: 0.00159334
	LOSS [training: 0.15494506296076244 | validation: 0.3222003784281622]
	TIME [epoch: 5.61 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15919273442052453		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.15919273442052453 | validation: 0.3227017009186864]
	TIME [epoch: 5.61 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16017525863706172		[learning rate: 0.0015793]
	Learning Rate: 0.00157929
	LOSS [training: 0.16017525863706172 | validation: 0.29966548691764444]
	TIME [epoch: 5.61 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16158980542834106		[learning rate: 0.0015723]
	Learning Rate: 0.00157231
	LOSS [training: 0.16158980542834106 | validation: 0.2893595246775851]
	TIME [epoch: 5.63 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15995378896752982		[learning rate: 0.0015654]
	Learning Rate: 0.00156536
	LOSS [training: 0.15995378896752982 | validation: 0.2876943295374201]
	TIME [epoch: 5.61 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15833191602899593		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.15833191602899593 | validation: 0.2924555980729096]
	TIME [epoch: 5.61 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15282119647880194		[learning rate: 0.0015516]
	Learning Rate: 0.00155156
	LOSS [training: 0.15282119647880194 | validation: 0.31238558883283174]
	TIME [epoch: 5.62 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1531852719726638		[learning rate: 0.0015447]
	Learning Rate: 0.00154471
	LOSS [training: 0.1531852719726638 | validation: 0.2979196325230222]
	TIME [epoch: 5.62 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16287333227794798		[learning rate: 0.0015379]
	Learning Rate: 0.00153788
	LOSS [training: 0.16287333227794798 | validation: 0.294408271129457]
	TIME [epoch: 5.62 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15405492626543613		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.15405492626543613 | validation: 0.2988802065632037]
	TIME [epoch: 5.63 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1624777858434119		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.1624777858434119 | validation: 0.29569136904142873]
	TIME [epoch: 5.62 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16088665822801954		[learning rate: 0.0015176]
	Learning Rate: 0.00151759
	LOSS [training: 0.16088665822801954 | validation: 0.30200249076635427]
	TIME [epoch: 5.62 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15835550246425337		[learning rate: 0.0015109]
	Learning Rate: 0.00151088
	LOSS [training: 0.15835550246425337 | validation: 0.31080218791592595]
	TIME [epoch: 5.62 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15804547816850117		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.15804547816850117 | validation: 0.2753282501254416]
	TIME [epoch: 5.62 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v8_20240710_215556/states/model_facs_dec2b_2dpca_v8_468.pth
	Model improved!!!
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1576163427004027		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.1576163427004027 | validation: 0.28724704581928345]
	TIME [epoch: 5.63 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16190403576759088		[learning rate: 0.0014909]
	Learning Rate: 0.00149094
	LOSS [training: 0.16190403576759088 | validation: 0.2845862613764418]
	TIME [epoch: 5.62 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15883798186857198		[learning rate: 0.0014844]
	Learning Rate: 0.00148436
	LOSS [training: 0.15883798186857198 | validation: 0.30142022697200105]
	TIME [epoch: 5.61 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14915199417891242		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.14915199417891242 | validation: 0.30938585072052976]
	TIME [epoch: 5.62 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15503978272218372		[learning rate: 0.0014713]
	Learning Rate: 0.00147127
	LOSS [training: 0.15503978272218372 | validation: 0.3055772570869139]
	TIME [epoch: 5.62 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15549646689669233		[learning rate: 0.0014648]
	Learning Rate: 0.00146477
	LOSS [training: 0.15549646689669233 | validation: 0.2918318288917873]
	TIME [epoch: 5.61 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15978316682823784		[learning rate: 0.0014583]
	Learning Rate: 0.0014583
	LOSS [training: 0.15978316682823784 | validation: 0.30035780621745384]
	TIME [epoch: 5.63 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15742992088220611		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.15742992088220611 | validation: 0.28913889013192723]
	TIME [epoch: 5.61 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15412656556513324		[learning rate: 0.0014454]
	Learning Rate: 0.00144544
	LOSS [training: 0.15412656556513324 | validation: 0.30516342734619123]
	TIME [epoch: 5.61 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1600944107974795		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.1600944107974795 | validation: 0.2964622122848324]
	TIME [epoch: 5.61 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15320528850040382		[learning rate: 0.0014327]
	Learning Rate: 0.0014327
	LOSS [training: 0.15320528850040382 | validation: 0.29993387699528873]
	TIME [epoch: 5.61 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15868822729902105		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.15868822729902105 | validation: 0.3120288854882989]
	TIME [epoch: 5.61 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15659508914971884		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.15659508914971884 | validation: 0.3180014352846349]
	TIME [epoch: 5.62 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1526015082918523		[learning rate: 0.0014138]
	Learning Rate: 0.00141379
	LOSS [training: 0.1526015082918523 | validation: 0.29817916350371493]
	TIME [epoch: 5.61 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1536323118597471		[learning rate: 0.0014075]
	Learning Rate: 0.00140754
	LOSS [training: 0.1536323118597471 | validation: 0.3086751004934721]
	TIME [epoch: 5.61 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15520263602735287		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.15520263602735287 | validation: 0.3073847563246981]
	TIME [epoch: 5.61 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1591693502728116		[learning rate: 0.0013951]
	Learning Rate: 0.00139513
	LOSS [training: 0.1591693502728116 | validation: 0.3057684557624648]
	TIME [epoch: 5.61 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15585706226051094		[learning rate: 0.001389]
	Learning Rate: 0.00138897
	LOSS [training: 0.15585706226051094 | validation: 0.31176635229911875]
	TIME [epoch: 5.61 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1606523251445484		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.1606523251445484 | validation: 0.2811860508601342]
	TIME [epoch: 5.62 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14972714735884265		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.14972714735884265 | validation: 0.290473223436776]
	TIME [epoch: 5.61 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1577553439338666		[learning rate: 0.0013706]
	Learning Rate: 0.00137064
	LOSS [training: 0.1577553439338666 | validation: 0.295948484495288]
	TIME [epoch: 5.61 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1558783667814194		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: 0.1558783667814194 | validation: 0.30789150981072777]
	TIME [epoch: 5.61 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15495120290573863		[learning rate: 0.0013586]
	Learning Rate: 0.00135855
	LOSS [training: 0.15495120290573863 | validation: 0.3017882218600944]
	TIME [epoch: 5.61 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.157518355084129		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.157518355084129 | validation: 0.290525643254877]
	TIME [epoch: 5.62 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15418897987101832		[learning rate: 0.0013466]
	Learning Rate: 0.00134658
	LOSS [training: 0.15418897987101832 | validation: 0.3066763824935618]
	TIME [epoch: 5.62 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15666249351407144		[learning rate: 0.0013406]
	Learning Rate: 0.00134063
	LOSS [training: 0.15666249351407144 | validation: 0.2942362528104473]
	TIME [epoch: 5.61 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15188821056397234		[learning rate: 0.0013347]
	Learning Rate: 0.0013347
	LOSS [training: 0.15188821056397234 | validation: 0.2816412695653233]
	TIME [epoch: 5.61 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15870509772813599		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.15870509772813599 | validation: 0.3019927788218532]
	TIME [epoch: 5.61 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1522897057387401		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.1522897057387401 | validation: 0.2838566142995938]
	TIME [epoch: 5.61 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15342069329605526		[learning rate: 0.0013171]
	Learning Rate: 0.00131709
	LOSS [training: 0.15342069329605526 | validation: 0.3034221203028646]
	TIME [epoch: 5.62 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1536544568062443		[learning rate: 0.0013113]
	Learning Rate: 0.00131127
	LOSS [training: 0.1536544568062443 | validation: 0.3068697476876939]
	TIME [epoch: 5.62 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15864736108186317		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.15864736108186317 | validation: 0.3033009845915005]
	TIME [epoch: 5.61 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15240327145261107		[learning rate: 0.0012997]
	Learning Rate: 0.00129971
	LOSS [training: 0.15240327145261107 | validation: 0.29176708241075955]
	TIME [epoch: 35.7 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15319087391531686		[learning rate: 0.001294]
	Learning Rate: 0.00129397
	LOSS [training: 0.15319087391531686 | validation: 0.30201703679479125]
	TIME [epoch: 10.9 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15699638400837074		[learning rate: 0.0012882]
	Learning Rate: 0.00128825
	LOSS [training: 0.15699638400837074 | validation: 0.30263203148535717]
	TIME [epoch: 10.8 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1577957099995488		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.1577957099995488 | validation: 0.2880052612505753]
	TIME [epoch: 10.8 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1542576325012464		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.1542576325012464 | validation: 0.30387869323095507]
	TIME [epoch: 10.8 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15688959300712818		[learning rate: 0.0012712]
	Learning Rate: 0.00127125
	LOSS [training: 0.15688959300712818 | validation: 0.3460779383865271]
	TIME [epoch: 10.8 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1584948977259963		[learning rate: 0.0012656]
	Learning Rate: 0.00126563
	LOSS [training: 0.1584948977259963 | validation: 0.30039102268234624]
	TIME [epoch: 10.8 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15149882007908605		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.15149882007908605 | validation: 0.3090200229602097]
	TIME [epoch: 10.8 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1529442981529122		[learning rate: 0.0012545]
	Learning Rate: 0.00125447
	LOSS [training: 0.1529442981529122 | validation: 0.29092993930244476]
	TIME [epoch: 10.8 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15349973445241474		[learning rate: 0.0012489]
	Learning Rate: 0.00124893
	LOSS [training: 0.15349973445241474 | validation: 0.30216663685092376]
	TIME [epoch: 10.8 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1534836986228097		[learning rate: 0.0012434]
	Learning Rate: 0.00124341
	LOSS [training: 0.1534836986228097 | validation: 0.3027599015447732]
	TIME [epoch: 10.8 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15904897633662626		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.15904897633662626 | validation: 0.29667518873992454]
	TIME [epoch: 10.8 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15613114973844924		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.15613114973844924 | validation: 0.2890957672406971]
	TIME [epoch: 10.8 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15543175075890034		[learning rate: 0.001227]
	Learning Rate: 0.001227
	LOSS [training: 0.15543175075890034 | validation: 0.30407721761972933]
	TIME [epoch: 10.9 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15286550679153801		[learning rate: 0.0012216]
	Learning Rate: 0.00122158
	LOSS [training: 0.15286550679153801 | validation: 0.31555781128108606]
	TIME [epoch: 10.8 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15630051231101666		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.15630051231101666 | validation: 0.30362135731962114]
	TIME [epoch: 10.8 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15910417782949385		[learning rate: 0.0012108]
	Learning Rate: 0.00121081
	LOSS [training: 0.15910417782949385 | validation: 0.30433467934324177]
	TIME [epoch: 10.8 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1620891965084602		[learning rate: 0.0012055]
	Learning Rate: 0.00120546
	LOSS [training: 0.1620891965084602 | validation: 0.2874531698898537]
	TIME [epoch: 10.8 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15579384396958412		[learning rate: 0.0012001]
	Learning Rate: 0.00120014
	LOSS [training: 0.15579384396958412 | validation: 0.3034747592918771]
	TIME [epoch: 10.8 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15608328158146462		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.15608328158146462 | validation: 0.29363717813508294]
	TIME [epoch: 10.8 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15810520413951684		[learning rate: 0.0011896]
	Learning Rate: 0.00118956
	LOSS [training: 0.15810520413951684 | validation: 0.30602264048258365]
	TIME [epoch: 10.8 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15432182801536684		[learning rate: 0.0011843]
	Learning Rate: 0.0011843
	LOSS [training: 0.15432182801536684 | validation: 0.2879473699497651]
	TIME [epoch: 10.8 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15489751837752916		[learning rate: 0.0011791]
	Learning Rate: 0.00117907
	LOSS [training: 0.15489751837752916 | validation: 0.2875310819768841]
	TIME [epoch: 10.8 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1538032422588453		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.1538032422588453 | validation: 0.3026061008102745]
	TIME [epoch: 10.8 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15556565632189684		[learning rate: 0.0011687]
	Learning Rate: 0.00116867
	LOSS [training: 0.15556565632189684 | validation: 0.29655739107969664]
	TIME [epoch: 10.8 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1547951767607027		[learning rate: 0.0011635]
	Learning Rate: 0.00116351
	LOSS [training: 0.1547951767607027 | validation: 0.29820791144054726]
	TIME [epoch: 10.8 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15388744706700364		[learning rate: 0.0011584]
	Learning Rate: 0.00115837
	LOSS [training: 0.15388744706700364 | validation: 0.29332208368407797]
	TIME [epoch: 10.8 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1559827715003108		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.1559827715003108 | validation: 0.2902641136329756]
	TIME [epoch: 10.8 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15532203261319116		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.15532203261319116 | validation: 0.28905764058806716]
	TIME [epoch: 10.8 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15677012562648934		[learning rate: 0.0011431]
	Learning Rate: 0.00114308
	LOSS [training: 0.15677012562648934 | validation: 0.2858604414595763]
	TIME [epoch: 10.9 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1526981185198366		[learning rate: 0.001138]
	Learning Rate: 0.00113803
	LOSS [training: 0.1526981185198366 | validation: 0.3041493849237534]
	TIME [epoch: 10.8 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15582112217851193		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.15582112217851193 | validation: 0.2832678249641108]
	TIME [epoch: 10.8 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1527256995943094		[learning rate: 0.001128]
	Learning Rate: 0.001128
	LOSS [training: 0.1527256995943094 | validation: 0.29049729871687496]
	TIME [epoch: 10.8 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15062811589694658		[learning rate: 0.001123]
	Learning Rate: 0.00112301
	LOSS [training: 0.15062811589694658 | validation: 0.3088501157818188]
	TIME [epoch: 10.8 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15037568235999715		[learning rate: 0.0011181]
	Learning Rate: 0.00111805
	LOSS [training: 0.15037568235999715 | validation: 0.3079128828143581]
	TIME [epoch: 10.8 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15479712271744422		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.15479712271744422 | validation: 0.3126378765853908]
	TIME [epoch: 10.8 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15729633158881282		[learning rate: 0.0011082]
	Learning Rate: 0.00110819
	LOSS [training: 0.15729633158881282 | validation: 0.2927985670399599]
	TIME [epoch: 10.8 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15820234959298612		[learning rate: 0.0011033]
	Learning Rate: 0.0011033
	LOSS [training: 0.15820234959298612 | validation: 0.2958912091547885]
	TIME [epoch: 10.8 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15452936604561224		[learning rate: 0.0010984]
	Learning Rate: 0.00109842
	LOSS [training: 0.15452936604561224 | validation: 0.3148521798069497]
	TIME [epoch: 10.8 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16202265821588308		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.16202265821588308 | validation: 0.2940475336249303]
	TIME [epoch: 10.9 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15431930328006296		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.15431930328006296 | validation: 0.30411019992722654]
	TIME [epoch: 10.8 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1516294485179276		[learning rate: 0.0010839]
	Learning Rate: 0.00108393
	LOSS [training: 0.1516294485179276 | validation: 0.30545138503876085]
	TIME [epoch: 10.8 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15437086246951165		[learning rate: 0.0010791]
	Learning Rate: 0.00107914
	LOSS [training: 0.15437086246951165 | validation: 0.3074897835890937]
	TIME [epoch: 10.8 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15793293157587457		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.15793293157587457 | validation: 0.3168940934693423]
	TIME [epoch: 10.8 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15640000547302474		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.15640000547302474 | validation: 0.2930443655157578]
	TIME [epoch: 10.8 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15126021985686436		[learning rate: 0.0010649]
	Learning Rate: 0.0010649
	LOSS [training: 0.15126021985686436 | validation: 0.28399577775078305]
	TIME [epoch: 10.8 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15544405475202128		[learning rate: 0.0010602]
	Learning Rate: 0.00106019
	LOSS [training: 0.15544405475202128 | validation: 0.29837004420264185]
	TIME [epoch: 10.8 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15720714272272923		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.15720714272272923 | validation: 0.2984123147501919]
	TIME [epoch: 10.8 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15223364494667907		[learning rate: 0.0010508]
	Learning Rate: 0.00105084
	LOSS [training: 0.15223364494667907 | validation: 0.2967349315475448]
	TIME [epoch: 10.8 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15156466174202757		[learning rate: 0.0010462]
	Learning Rate: 0.0010462
	LOSS [training: 0.15156466174202757 | validation: 0.2926891426958187]
	TIME [epoch: 10.9 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15126713916172782		[learning rate: 0.0010416]
	Learning Rate: 0.00104158
	LOSS [training: 0.15126713916172782 | validation: 0.35828779038631564]
	TIME [epoch: 10.8 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15370681406204584		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.15370681406204584 | validation: 0.28915922639846553]
	TIME [epoch: 10.8 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16071163115287387		[learning rate: 0.0010324]
	Learning Rate: 0.0010324
	LOSS [training: 0.16071163115287387 | validation: 0.30115628006825024]
	TIME [epoch: 10.9 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14958997109820046		[learning rate: 0.0010278]
	Learning Rate: 0.00102783
	LOSS [training: 0.14958997109820046 | validation: 0.3065315626008623]
	TIME [epoch: 10.8 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16081839897756156		[learning rate: 0.0010233]
	Learning Rate: 0.00102329
	LOSS [training: 0.16081839897756156 | validation: 0.2976462227457917]
	TIME [epoch: 10.8 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15815193158724197		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.15815193158724197 | validation: 0.3001366198967859]
	TIME [epoch: 10.9 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1537227744447274		[learning rate: 0.0010143]
	Learning Rate: 0.00101427
	LOSS [training: 0.1537227744447274 | validation: 0.2881538596322386]
	TIME [epoch: 10.8 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1542998939373737		[learning rate: 0.0010098]
	Learning Rate: 0.00100979
	LOSS [training: 0.1542998939373737 | validation: 0.3044140967062652]
	TIME [epoch: 10.8 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15156470551407022		[learning rate: 0.0010053]
	Learning Rate: 0.00100533
	LOSS [training: 0.15156470551407022 | validation: 0.30260793650404016]
	TIME [epoch: 10.8 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15356639755881543		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.15356639755881543 | validation: 0.29836412837501103]
	TIME [epoch: 10.8 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15694343754099077		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.15694343754099077 | validation: 0.2915985983507302]
	TIME [epoch: 10.8 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1509348190266327		[learning rate: 0.00099206]
	Learning Rate: 0.000992061
	LOSS [training: 0.1509348190266327 | validation: 0.2980297996897689]
	TIME [epoch: 10.8 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15489223933468316		[learning rate: 0.00098768]
	Learning Rate: 0.000987678
	LOSS [training: 0.15489223933468316 | validation: 0.3014310348449967]
	TIME [epoch: 10.8 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1527106612220384		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.1527106612220384 | validation: 0.2993604697968918]
	TIME [epoch: 10.8 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1495708839194915		[learning rate: 0.00097897]
	Learning Rate: 0.00097897
	LOSS [training: 0.1495708839194915 | validation: 0.28687912803533805]
	TIME [epoch: 10.8 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1553938280233007		[learning rate: 0.00097464]
	Learning Rate: 0.000974644
	LOSS [training: 0.1553938280233007 | validation: 0.31220090518386917]
	TIME [epoch: 10.9 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15174371789794686		[learning rate: 0.00097034]
	Learning Rate: 0.000970338
	LOSS [training: 0.15174371789794686 | validation: 0.2938311650656677]
	TIME [epoch: 10.8 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1487512077641501		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.1487512077641501 | validation: 0.3034922211181805]
	TIME [epoch: 10.8 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.155752542666406		[learning rate: 0.00096178]
	Learning Rate: 0.000961783
	LOSS [training: 0.155752542666406 | validation: 0.2898634214149635]
	TIME [epoch: 10.8 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15527575948347455		[learning rate: 0.00095753]
	Learning Rate: 0.000957533
	LOSS [training: 0.15527575948347455 | validation: 0.29168491897178234]
	TIME [epoch: 10.8 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15582025636797722		[learning rate: 0.0009533]
	Learning Rate: 0.000953303
	LOSS [training: 0.15582025636797722 | validation: 0.2857157575581106]
	TIME [epoch: 10.8 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15812965807350657		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.15812965807350657 | validation: 0.29302362517011454]
	TIME [epoch: 10.8 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15940524668017989		[learning rate: 0.0009449]
	Learning Rate: 0.000944897
	LOSS [training: 0.15940524668017989 | validation: 0.2850670950178325]
	TIME [epoch: 10.8 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14917938039607898		[learning rate: 0.00094072]
	Learning Rate: 0.000940723
	LOSS [training: 0.14917938039607898 | validation: 0.2943692931777779]
	TIME [epoch: 10.8 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15302882150767452		[learning rate: 0.00093657]
	Learning Rate: 0.000936566
	LOSS [training: 0.15302882150767452 | validation: 0.29935324621226317]
	TIME [epoch: 10.8 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15260170106410514		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.15260170106410514 | validation: 0.30366028458314914]
	TIME [epoch: 10.9 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15401907520386754		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.15401907520386754 | validation: 0.29419146316286227]
	TIME [epoch: 10.8 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14610067351864353		[learning rate: 0.00092421]
	Learning Rate: 0.000924207
	LOSS [training: 0.14610067351864353 | validation: 0.29605812753082]
	TIME [epoch: 10.8 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15247874667620942		[learning rate: 0.00092012]
	Learning Rate: 0.000920124
	LOSS [training: 0.15247874667620942 | validation: 0.29608109555397016]
	TIME [epoch: 10.8 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15186523449420086		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.15186523449420086 | validation: 0.29404894740208365]
	TIME [epoch: 10.8 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15367737552056987		[learning rate: 0.00091201]
	Learning Rate: 0.000912011
	LOSS [training: 0.15367737552056987 | validation: 0.2993588057908828]
	TIME [epoch: 10.8 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15498595004250984		[learning rate: 0.00090798]
	Learning Rate: 0.000907981
	LOSS [training: 0.15498595004250984 | validation: 0.2864254244754453]
	TIME [epoch: 10.8 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15261525236997658		[learning rate: 0.00090397]
	Learning Rate: 0.00090397
	LOSS [training: 0.15261525236997658 | validation: 0.2953245612319422]
	TIME [epoch: 10.8 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15172543699374424		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.15172543699374424 | validation: 0.30431156404111026]
	TIME [epoch: 10.8 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15425440296607018		[learning rate: 0.000896]
	Learning Rate: 0.000895999
	LOSS [training: 0.15425440296607018 | validation: 0.29205043594002317]
	TIME [epoch: 10.8 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14919698098576767		[learning rate: 0.00089204]
	Learning Rate: 0.000892041
	LOSS [training: 0.14919698098576767 | validation: 0.2860400383151879]
	TIME [epoch: 10.9 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15164838912715337		[learning rate: 0.0008881]
	Learning Rate: 0.000888099
	LOSS [training: 0.15164838912715337 | validation: 0.28226295355059094]
	TIME [epoch: 10.8 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1531628384665065		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.1531628384665065 | validation: 0.3038904088248996]
	TIME [epoch: 10.8 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1530604899712639		[learning rate: 0.00088027]
	Learning Rate: 0.000880269
	LOSS [training: 0.1530604899712639 | validation: 0.30491835071308426]
	TIME [epoch: 10.8 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15603116887057342		[learning rate: 0.00087638]
	Learning Rate: 0.00087638
	LOSS [training: 0.15603116887057342 | validation: 0.3021231815832851]
	TIME [epoch: 10.8 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1541539634545364		[learning rate: 0.00087251]
	Learning Rate: 0.000872508
	LOSS [training: 0.1541539634545364 | validation: 0.2882229908854432]
	TIME [epoch: 10.8 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15219988898726192		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.15219988898726192 | validation: 0.29825265328762984]
	TIME [epoch: 10.9 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15303143237106212		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.15303143237106212 | validation: 0.3057443484243962]
	TIME [epoch: 10.8 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15114367976713952		[learning rate: 0.00086099]
	Learning Rate: 0.000860994
	LOSS [training: 0.15114367976713952 | validation: 0.30217866044055547]
	TIME [epoch: 10.8 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15789890854162061		[learning rate: 0.00085719]
	Learning Rate: 0.00085719
	LOSS [training: 0.15789890854162061 | validation: 0.29430424207617023]
	TIME [epoch: 10.8 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1474768853071583		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.1474768853071583 | validation: 0.29580635258830174]
	TIME [epoch: 10.8 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15328430451850322		[learning rate: 0.00084963]
	Learning Rate: 0.000849632
	LOSS [training: 0.15328430451850322 | validation: 0.3003558200815283]
	TIME [epoch: 10.8 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15540348999404213		[learning rate: 0.00084588]
	Learning Rate: 0.000845878
	LOSS [training: 0.15540348999404213 | validation: 0.29929824261579474]
	TIME [epoch: 10.8 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15416484194920982		[learning rate: 0.00084214]
	Learning Rate: 0.000842141
	LOSS [training: 0.15416484194920982 | validation: 0.2883217593144534]
	TIME [epoch: 10.8 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14850156579162374		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.14850156579162374 | validation: 0.3024038710144482]
	TIME [epoch: 10.8 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15253751345038644		[learning rate: 0.00083472]
	Learning Rate: 0.000834715
	LOSS [training: 0.15253751345038644 | validation: 0.29390285388668685]
	TIME [epoch: 10.8 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15386348228637953		[learning rate: 0.00083103]
	Learning Rate: 0.000831028
	LOSS [training: 0.15386348228637953 | validation: 0.291581086944332]
	TIME [epoch: 10.9 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15563796016144255		[learning rate: 0.00082736]
	Learning Rate: 0.000827356
	LOSS [training: 0.15563796016144255 | validation: 0.29714878169092346]
	TIME [epoch: 10.8 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14913535280352558		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.14913535280352558 | validation: 0.2941333099360245]
	TIME [epoch: 10.8 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15029101285651172		[learning rate: 0.00082006]
	Learning Rate: 0.000820061
	LOSS [training: 0.15029101285651172 | validation: 0.29130876892822516]
	TIME [epoch: 10.8 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15315586493592642		[learning rate: 0.00081644]
	Learning Rate: 0.000816438
	LOSS [training: 0.15315586493592642 | validation: 0.3040178393775533]
	TIME [epoch: 10.8 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1523203534300725		[learning rate: 0.00081283]
	Learning Rate: 0.000812831
	LOSS [training: 0.1523203534300725 | validation: 0.29190235138771703]
	TIME [epoch: 10.8 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15337220463432982		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.15337220463432982 | validation: 0.3036764823806646]
	TIME [epoch: 10.8 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15774746009218168		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.15774746009218168 | validation: 0.309231254659041]
	TIME [epoch: 10.8 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15423087283771955		[learning rate: 0.0008021]
	Learning Rate: 0.000802104
	LOSS [training: 0.15423087283771955 | validation: 0.2801169939105204]
	TIME [epoch: 10.8 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14610293033725721		[learning rate: 0.00079856]
	Learning Rate: 0.00079856
	LOSS [training: 0.14610293033725721 | validation: 0.29155863279184613]
	TIME [epoch: 10.8 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15348069737053133		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.15348069737053133 | validation: 0.2878191609123847]
	TIME [epoch: 10.9 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15422329152469488		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.15422329152469488 | validation: 0.3053375065602034]
	TIME [epoch: 10.8 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15266915184382956		[learning rate: 0.00078802]
	Learning Rate: 0.000788022
	LOSS [training: 0.15266915184382956 | validation: 0.28347811700728204]
	TIME [epoch: 10.8 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.149843511596186		[learning rate: 0.00078454]
	Learning Rate: 0.000784541
	LOSS [training: 0.149843511596186 | validation: 0.30139192920488755]
	TIME [epoch: 10.8 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15060212902424974		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.15060212902424974 | validation: 0.2940729565146496]
	TIME [epoch: 10.8 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15426031071293217		[learning rate: 0.00077762]
	Learning Rate: 0.000777623
	LOSS [training: 0.15426031071293217 | validation: 0.30081620730257386]
	TIME [epoch: 10.8 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14724431338737975		[learning rate: 0.00077419]
	Learning Rate: 0.000774188
	LOSS [training: 0.14724431338737975 | validation: 0.3001668993757635]
	TIME [epoch: 10.8 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15147841243558982		[learning rate: 0.00077077]
	Learning Rate: 0.000770767
	LOSS [training: 0.15147841243558982 | validation: 0.2856891146431847]
	TIME [epoch: 10.8 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15691688328784673		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.15691688328784673 | validation: 0.2985959482976515]
	TIME [epoch: 10.8 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15099319870835143		[learning rate: 0.00076397]
	Learning Rate: 0.000763971
	LOSS [training: 0.15099319870835143 | validation: 0.3024567318961158]
	TIME [epoch: 10.8 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15367264443760625		[learning rate: 0.0007606]
	Learning Rate: 0.000760596
	LOSS [training: 0.15367264443760625 | validation: 0.2833526678253605]
	TIME [epoch: 10.9 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15309652762639786		[learning rate: 0.00075724]
	Learning Rate: 0.000757235
	LOSS [training: 0.15309652762639786 | validation: 0.30144988629959174]
	TIME [epoch: 10.8 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15680367605562556		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.15680367605562556 | validation: 0.28504329909698173]
	TIME [epoch: 10.8 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1494266970558608		[learning rate: 0.00075056]
	Learning Rate: 0.000750559
	LOSS [training: 0.1494266970558608 | validation: 0.29791921531430277]
	TIME [epoch: 10.8 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14741708105723822		[learning rate: 0.00074724]
	Learning Rate: 0.000747242
	LOSS [training: 0.14741708105723822 | validation: 0.28938825786627675]
	TIME [epoch: 10.8 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1510718194382608		[learning rate: 0.00074394]
	Learning Rate: 0.000743941
	LOSS [training: 0.1510718194382608 | validation: 0.2944276747135039]
	TIME [epoch: 10.8 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15131610582783064		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.15131610582783064 | validation: 0.30243138678898895]
	TIME [epoch: 10.9 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15222937001495035		[learning rate: 0.00073738]
	Learning Rate: 0.000737382
	LOSS [training: 0.15222937001495035 | validation: 0.29245474278689765]
	TIME [epoch: 10.8 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15686675897707208		[learning rate: 0.00073412]
	Learning Rate: 0.000734124
	LOSS [training: 0.15686675897707208 | validation: 0.29283403039563777]
	TIME [epoch: 10.8 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1469377219729514		[learning rate: 0.00073088]
	Learning Rate: 0.00073088
	LOSS [training: 0.1469377219729514 | validation: 0.30739340088477474]
	TIME [epoch: 10.8 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15160912879013827		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.15160912879013827 | validation: 0.2925703014821305]
	TIME [epoch: 10.8 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15243904580339565		[learning rate: 0.00072444]
	Learning Rate: 0.000724436
	LOSS [training: 0.15243904580339565 | validation: 0.31125622704461137]
	TIME [epoch: 10.8 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15566201822748638		[learning rate: 0.00072124]
	Learning Rate: 0.000721235
	LOSS [training: 0.15566201822748638 | validation: 0.294254324409886]
	TIME [epoch: 10.8 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15592635633473179		[learning rate: 0.00071805]
	Learning Rate: 0.000718049
	LOSS [training: 0.15592635633473179 | validation: 0.2977338582269268]
	TIME [epoch: 10.8 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15316400732997396		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.15316400732997396 | validation: 0.2989501532116107]
	TIME [epoch: 10.8 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1540896472330871		[learning rate: 0.00071172]
	Learning Rate: 0.000711718
	LOSS [training: 0.1540896472330871 | validation: 0.2901574195501007]
	TIME [epoch: 10.8 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15360007603769943		[learning rate: 0.00070857]
	Learning Rate: 0.000708573
	LOSS [training: 0.15360007603769943 | validation: 0.3036872729173113]
	TIME [epoch: 10.9 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14929011469858086		[learning rate: 0.00070544]
	Learning Rate: 0.000705442
	LOSS [training: 0.14929011469858086 | validation: 0.2906773931042078]
	TIME [epoch: 10.8 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15109920933517365		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.15109920933517365 | validation: 0.29521292500049057]
	TIME [epoch: 10.9 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14838678048576134		[learning rate: 0.00069922]
	Learning Rate: 0.000699222
	LOSS [training: 0.14838678048576134 | validation: 0.28483776883318124]
	TIME [epoch: 10.8 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1510595988866209		[learning rate: 0.00069613]
	Learning Rate: 0.000696133
	LOSS [training: 0.1510595988866209 | validation: 0.29408469307112606]
	TIME [epoch: 10.8 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15613482398109196		[learning rate: 0.00069306]
	Learning Rate: 0.000693058
	LOSS [training: 0.15613482398109196 | validation: 0.289880395857976]
	TIME [epoch: 10.8 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1510302084791039		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.1510302084791039 | validation: 0.2881410642931544]
	TIME [epoch: 10.9 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14942842117173477		[learning rate: 0.00068695]
	Learning Rate: 0.000686947
	LOSS [training: 0.14942842117173477 | validation: 0.29925690016909784]
	TIME [epoch: 10.8 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1516081014836767		[learning rate: 0.00068391]
	Learning Rate: 0.000683912
	LOSS [training: 0.1516081014836767 | validation: 0.2957626695256905]
	TIME [epoch: 10.8 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14967548089253718		[learning rate: 0.00068089]
	Learning Rate: 0.00068089
	LOSS [training: 0.14967548089253718 | validation: 0.2880647968954575]
	TIME [epoch: 10.8 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15542934041355025		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.15542934041355025 | validation: 0.29779851489313397]
	TIME [epoch: 10.9 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15369242116570286		[learning rate: 0.00067489]
	Learning Rate: 0.000674887
	LOSS [training: 0.15369242116570286 | validation: 0.29066154866093485]
	TIME [epoch: 10.8 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15561031389141042		[learning rate: 0.0006719]
	Learning Rate: 0.000671905
	LOSS [training: 0.15561031389141042 | validation: 0.2946112136276362]
	TIME [epoch: 10.9 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15366948784502857		[learning rate: 0.00066894]
	Learning Rate: 0.000668936
	LOSS [training: 0.15366948784502857 | validation: 0.28298488180946596]
	TIME [epoch: 10.8 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15168856230808528		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.15168856230808528 | validation: 0.29267714950309703]
	TIME [epoch: 10.9 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1554716383277792		[learning rate: 0.00066304]
	Learning Rate: 0.000663038
	LOSS [training: 0.1554716383277792 | validation: 0.29600249530853023]
	TIME [epoch: 10.8 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15452942917302312		[learning rate: 0.00066011]
	Learning Rate: 0.000660109
	LOSS [training: 0.15452942917302312 | validation: 0.29132203682281027]
	TIME [epoch: 10.9 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15746816970294003		[learning rate: 0.00065719]
	Learning Rate: 0.000657192
	LOSS [training: 0.15746816970294003 | validation: 0.2997856581584118]
	TIME [epoch: 10.8 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1515902484034526		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.1515902484034526 | validation: 0.2923943247270544]
	TIME [epoch: 10.9 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15080823602326518		[learning rate: 0.0006514]
	Learning Rate: 0.000651398
	LOSS [training: 0.15080823602326518 | validation: 0.2900985668048678]
	TIME [epoch: 10.8 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15630169135427197		[learning rate: 0.00064852]
	Learning Rate: 0.00064852
	LOSS [training: 0.15630169135427197 | validation: 0.28861596334743944]
	TIME [epoch: 10.9 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15673198346119585		[learning rate: 0.00064565]
	Learning Rate: 0.000645654
	LOSS [training: 0.15673198346119585 | validation: 0.30309142083005197]
	TIME [epoch: 10.8 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1511675392672837		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.1511675392672837 | validation: 0.2894855806441924]
	TIME [epoch: 10.9 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1559418975366142		[learning rate: 0.00063996]
	Learning Rate: 0.000639962
	LOSS [training: 0.1559418975366142 | validation: 0.2924782872958181]
	TIME [epoch: 10.9 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15136921783463003		[learning rate: 0.00063713]
	Learning Rate: 0.000637134
	LOSS [training: 0.15136921783463003 | validation: 0.2920681536724562]
	TIME [epoch: 10.8 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15335087601218206		[learning rate: 0.00063432]
	Learning Rate: 0.000634319
	LOSS [training: 0.15335087601218206 | validation: 0.29372964530341805]
	TIME [epoch: 10.8 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14919105837178498		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.14919105837178498 | validation: 0.2925305929519766]
	TIME [epoch: 10.9 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15575389967593065		[learning rate: 0.00062873]
	Learning Rate: 0.000628726
	LOSS [training: 0.15575389967593065 | validation: 0.30442722988270926]
	TIME [epoch: 10.8 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.152076544634486		[learning rate: 0.00062595]
	Learning Rate: 0.000625948
	LOSS [training: 0.152076544634486 | validation: 0.29183900298327997]
	TIME [epoch: 10.8 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15269678412793103		[learning rate: 0.00062318]
	Learning Rate: 0.000623183
	LOSS [training: 0.15269678412793103 | validation: 0.29432555427487045]
	TIME [epoch: 10.9 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15285300196075927		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.15285300196075927 | validation: 0.29572037396914436]
	TIME [epoch: 10.9 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15276056938676533		[learning rate: 0.00061769]
	Learning Rate: 0.000617688
	LOSS [training: 0.15276056938676533 | validation: 0.2969369552613711]
	TIME [epoch: 10.8 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v8_20240710_215556/states/model_facs_dec2b_2dpca_v8_669.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 4745.062 seconds.
