Args:
Namespace(name='model_facs_v4_dec2b_2dpca_v13', outdir='out/model_training/model_facs_v4_dec2b_2dpca_v13', training_data='data/training_data/facs_v4/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v4/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=400, ncells_sample=400, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3800872554

Training model...

Saving initial model state to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8984401261626918		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8984401261626918 | validation: 0.9709143515479085]
	TIME [epoch: 32.3 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7261600406914994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7261600406914994 | validation: 0.9056755550416978]
	TIME [epoch: 4.64 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6801805148854795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6801805148854795 | validation: 0.8415160094059531]
	TIME [epoch: 4.63 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6565248050528836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6565248050528836 | validation: 0.8202648940539741]
	TIME [epoch: 4.63 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5580661641139051		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5580661641139051 | validation: 0.7527565337773112]
	TIME [epoch: 4.64 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5612450515199575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5612450515199575 | validation: 0.8051524663698068]
	TIME [epoch: 4.63 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5575619238675478		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5575619238675478 | validation: 0.6634659931689839]
	TIME [epoch: 4.63 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47329967408931456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47329967408931456 | validation: 0.9924677133226326]
	TIME [epoch: 4.63 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5588170560605472		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5588170560605472 | validation: 0.6130130325117503]
	TIME [epoch: 4.62 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44870347222516604		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44870347222516604 | validation: 0.6331666221131665]
	TIME [epoch: 4.62 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42679891490618105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42679891490618105 | validation: 0.543348910542481]
	TIME [epoch: 4.62 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4359884952758945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4359884952758945 | validation: 0.6587070316152359]
	TIME [epoch: 4.62 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41816812014957383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41816812014957383 | validation: 0.5332423528483781]
	TIME [epoch: 4.62 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3744053422369647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3744053422369647 | validation: 0.4653234909956503]
	TIME [epoch: 4.63 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4980836466556543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4980836466556543 | validation: 0.6417574225070106]
	TIME [epoch: 4.63 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34357071900007985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34357071900007985 | validation: 0.47128633395986985]
	TIME [epoch: 4.62 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31083558763605335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31083558763605335 | validation: 0.46844382371977533]
	TIME [epoch: 4.62 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28927911663792005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28927911663792005 | validation: 0.4661593855478302]
	TIME [epoch: 4.62 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3144349278893514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3144349278893514 | validation: 0.4341635260019694]
	TIME [epoch: 4.62 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3124483671480786		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3124483671480786 | validation: 0.579021755626311]
	TIME [epoch: 4.62 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35336376397345737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35336376397345737 | validation: 0.4301698870792798]
	TIME [epoch: 4.62 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2653922510607532		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2653922510607532 | validation: 0.4358331971794542]
	TIME [epoch: 4.63 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2726933359068094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2726933359068094 | validation: 0.4067340113970447]
	TIME [epoch: 4.62 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2543886886031721		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2543886886031721 | validation: 0.5118430132485154]
	TIME [epoch: 4.62 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3025461316544512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3025461316544512 | validation: 0.4080859199903886]
	TIME [epoch: 4.62 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27424513870929185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27424513870929185 | validation: 0.3907341202554378]
	TIME [epoch: 4.62 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.244661539320513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.244661539320513 | validation: 0.39841615205852854]
	TIME [epoch: 4.63 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25209026724094574		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25209026724094574 | validation: 0.4683765309476443]
	TIME [epoch: 4.63 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28922749375452034		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28922749375452034 | validation: 0.41111623454604695]
	TIME [epoch: 4.64 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2764147101736316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2764147101736316 | validation: 0.3804445100903568]
	TIME [epoch: 4.63 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2519565363632237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2519565363632237 | validation: 0.4202207491636145]
	TIME [epoch: 4.63 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2650207631433908		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2650207631433908 | validation: 0.40010290151782596]
	TIME [epoch: 4.63 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23632420999085482		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23632420999085482 | validation: 0.4081853705890328]
	TIME [epoch: 4.62 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23753550116333116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23753550116333116 | validation: 0.5100510614193032]
	TIME [epoch: 4.63 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3243726932135709		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3243726932135709 | validation: 0.37822863778579896]
	TIME [epoch: 4.62 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23570646807785908		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23570646807785908 | validation: 0.4025842047850269]
	TIME [epoch: 4.63 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23012060537960383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23012060537960383 | validation: 0.3482058355949885]
	TIME [epoch: 4.64 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2063913236387139		[learning rate: 0.0099882]
	Learning Rate: 0.0099882
	LOSS [training: 0.2063913236387139 | validation: 0.4087586063710747]
	TIME [epoch: 4.62 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24608097591488576		[learning rate: 0.0099411]
	Learning Rate: 0.00994113
	LOSS [training: 0.24608097591488576 | validation: 0.3804090424749226]
	TIME [epoch: 4.62 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20088071084322373		[learning rate: 0.0098943]
	Learning Rate: 0.00989429
	LOSS [training: 0.20088071084322373 | validation: 0.4831867122895479]
	TIME [epoch: 4.62 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2925078153108746		[learning rate: 0.0098477]
	Learning Rate: 0.00984767
	LOSS [training: 0.2925078153108746 | validation: 0.4062915210676589]
	TIME [epoch: 4.61 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.242558741530912		[learning rate: 0.0098013]
	Learning Rate: 0.00980126
	LOSS [training: 0.242558741530912 | validation: 0.3660912707260477]
	TIME [epoch: 4.62 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20600743782015796		[learning rate: 0.0097551]
	Learning Rate: 0.00975508
	LOSS [training: 0.20600743782015796 | validation: 0.3569499636869253]
	TIME [epoch: 4.62 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22112151797189802		[learning rate: 0.0097091]
	Learning Rate: 0.00970911
	LOSS [training: 0.22112151797189802 | validation: 0.4374630312835951]
	TIME [epoch: 4.63 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22140241400783447		[learning rate: 0.0096634]
	Learning Rate: 0.00966336
	LOSS [training: 0.22140241400783447 | validation: 0.4445156948764584]
	TIME [epoch: 4.62 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24573807058705474		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.24573807058705474 | validation: 0.36162763273730336]
	TIME [epoch: 4.62 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20746003268008534		[learning rate: 0.0095725]
	Learning Rate: 0.00957251
	LOSS [training: 0.20746003268008534 | validation: 0.3803066828071862]
	TIME [epoch: 4.61 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2818612356629416		[learning rate: 0.0095274]
	Learning Rate: 0.0095274
	LOSS [training: 0.2818612356629416 | validation: 0.39690513715882597]
	TIME [epoch: 4.62 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19247520201759563		[learning rate: 0.0094825]
	Learning Rate: 0.0094825
	LOSS [training: 0.19247520201759563 | validation: 0.3653765496490865]
	TIME [epoch: 4.62 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21270061043412472		[learning rate: 0.0094378]
	Learning Rate: 0.00943782
	LOSS [training: 0.21270061043412472 | validation: 0.37706025360807865]
	TIME [epoch: 4.62 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1960761169054341		[learning rate: 0.0093933]
	Learning Rate: 0.00939335
	LOSS [training: 0.1960761169054341 | validation: 0.3418070684286934]
	TIME [epoch: 34.6 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17423257405157302		[learning rate: 0.0093491]
	Learning Rate: 0.00934909
	LOSS [training: 0.17423257405157302 | validation: 0.3274295488959982]
	TIME [epoch: 8.93 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2038477282073427		[learning rate: 0.009305]
	Learning Rate: 0.00930503
	LOSS [training: 0.2038477282073427 | validation: 0.4497929931871736]
	TIME [epoch: 8.93 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2678442237902987		[learning rate: 0.0092612]
	Learning Rate: 0.00926119
	LOSS [training: 0.2678442237902987 | validation: 0.4114591124862053]
	TIME [epoch: 8.92 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24036106561392953		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.24036106561392953 | validation: 0.4545476324880059]
	TIME [epoch: 8.92 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25460212010689376		[learning rate: 0.0091741]
	Learning Rate: 0.00917411
	LOSS [training: 0.25460212010689376 | validation: 0.4266922601043773]
	TIME [epoch: 8.91 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2073152470588287		[learning rate: 0.0091309]
	Learning Rate: 0.00913088
	LOSS [training: 0.2073152470588287 | validation: 0.6246556725071474]
	TIME [epoch: 8.93 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2587495274810362		[learning rate: 0.0090879]
	Learning Rate: 0.00908786
	LOSS [training: 0.2587495274810362 | validation: 0.35688374017779273]
	TIME [epoch: 8.92 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2107868717795272		[learning rate: 0.009045]
	Learning Rate: 0.00904503
	LOSS [training: 0.2107868717795272 | validation: 0.35962705718903054]
	TIME [epoch: 8.91 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21232369209308855		[learning rate: 0.0090024]
	Learning Rate: 0.00900241
	LOSS [training: 0.21232369209308855 | validation: 0.34202286838392904]
	TIME [epoch: 8.92 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1885223694942627		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.1885223694942627 | validation: 0.3652131474386186]
	TIME [epoch: 8.93 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22305085452562046		[learning rate: 0.0089178]
	Learning Rate: 0.00891777
	LOSS [training: 0.22305085452562046 | validation: 0.3468795847295422]
	TIME [epoch: 8.92 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26074972643727484		[learning rate: 0.0088758]
	Learning Rate: 0.00887575
	LOSS [training: 0.26074972643727484 | validation: 0.5688508989958078]
	TIME [epoch: 8.92 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22350497744451425		[learning rate: 0.0088339]
	Learning Rate: 0.00883393
	LOSS [training: 0.22350497744451425 | validation: 0.49007570201298034]
	TIME [epoch: 8.92 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1922733691593292		[learning rate: 0.0087923]
	Learning Rate: 0.0087923
	LOSS [training: 0.1922733691593292 | validation: 0.3308607533048922]
	TIME [epoch: 8.93 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21625387634419801		[learning rate: 0.0087509]
	Learning Rate: 0.00875087
	LOSS [training: 0.21625387634419801 | validation: 0.4696442170152287]
	TIME [epoch: 8.92 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22019204562092623		[learning rate: 0.0087096]
	Learning Rate: 0.00870964
	LOSS [training: 0.22019204562092623 | validation: 0.3785698580761324]
	TIME [epoch: 8.92 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20280430272703615		[learning rate: 0.0086686]
	Learning Rate: 0.00866859
	LOSS [training: 0.20280430272703615 | validation: 0.380343478770588]
	TIME [epoch: 8.92 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18157126986862313		[learning rate: 0.0086277]
	Learning Rate: 0.00862775
	LOSS [training: 0.18157126986862313 | validation: 0.3868779311262041]
	TIME [epoch: 8.93 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22559170536905304		[learning rate: 0.0085871]
	Learning Rate: 0.00858709
	LOSS [training: 0.22559170536905304 | validation: 0.3309238937269146]
	TIME [epoch: 8.92 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2087664746516531		[learning rate: 0.0085466]
	Learning Rate: 0.00854663
	LOSS [training: 0.2087664746516531 | validation: 0.3816377630400113]
	TIME [epoch: 8.92 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23678317246387431		[learning rate: 0.0085064]
	Learning Rate: 0.00850636
	LOSS [training: 0.23678317246387431 | validation: 0.38108321054749117]
	TIME [epoch: 8.92 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21535615079820358		[learning rate: 0.0084663]
	Learning Rate: 0.00846627
	LOSS [training: 0.21535615079820358 | validation: 0.34496149487520367]
	TIME [epoch: 8.94 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16887483019354804		[learning rate: 0.0084264]
	Learning Rate: 0.00842638
	LOSS [training: 0.16887483019354804 | validation: 0.35719680771316914]
	TIME [epoch: 8.92 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2017711307634737		[learning rate: 0.0083867]
	Learning Rate: 0.00838667
	LOSS [training: 0.2017711307634737 | validation: 0.4024657320611021]
	TIME [epoch: 8.92 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23419868025038076		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.23419868025038076 | validation: 0.445188925609393]
	TIME [epoch: 8.92 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20652486323965266		[learning rate: 0.0083078]
	Learning Rate: 0.00830782
	LOSS [training: 0.20652486323965266 | validation: 0.40521243514681254]
	TIME [epoch: 8.94 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19476241837277458		[learning rate: 0.0082687]
	Learning Rate: 0.00826867
	LOSS [training: 0.19476241837277458 | validation: 0.34040980418639993]
	TIME [epoch: 8.92 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18919441458314812		[learning rate: 0.0082297]
	Learning Rate: 0.00822971
	LOSS [training: 0.18919441458314812 | validation: 0.31569659586480003]
	TIME [epoch: 8.92 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20943725384313563		[learning rate: 0.0081909]
	Learning Rate: 0.00819093
	LOSS [training: 0.20943725384313563 | validation: 0.32912615896155195]
	TIME [epoch: 8.93 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20351938373475675		[learning rate: 0.0081523]
	Learning Rate: 0.00815233
	LOSS [training: 0.20351938373475675 | validation: 0.4001842278053295]
	TIME [epoch: 8.93 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17634456676149562		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.17634456676149562 | validation: 0.5071838389923228]
	TIME [epoch: 8.93 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22501333552250138		[learning rate: 0.0080757]
	Learning Rate: 0.00807569
	LOSS [training: 0.22501333552250138 | validation: 0.4480367926998418]
	TIME [epoch: 8.92 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.166829641206214		[learning rate: 0.0080376]
	Learning Rate: 0.00803763
	LOSS [training: 0.166829641206214 | validation: 0.3588496251092392]
	TIME [epoch: 8.93 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20449398682732095		[learning rate: 0.0079998]
	Learning Rate: 0.00799976
	LOSS [training: 0.20449398682732095 | validation: 0.32232612970953367]
	TIME [epoch: 8.94 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17660921978719404		[learning rate: 0.0079621]
	Learning Rate: 0.00796206
	LOSS [training: 0.17660921978719404 | validation: 0.3702097311838725]
	TIME [epoch: 8.92 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19097622327399028		[learning rate: 0.0079245]
	Learning Rate: 0.00792455
	LOSS [training: 0.19097622327399028 | validation: 0.3197652183691791]
	TIME [epoch: 8.92 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16785114113025112		[learning rate: 0.0078872]
	Learning Rate: 0.0078872
	LOSS [training: 0.16785114113025112 | validation: 0.4874969267195998]
	TIME [epoch: 8.92 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20137393125248845		[learning rate: 0.00785]
	Learning Rate: 0.00785004
	LOSS [training: 0.20137393125248845 | validation: 0.35926336745914234]
	TIME [epoch: 8.92 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1677806917718243		[learning rate: 0.007813]
	Learning Rate: 0.00781305
	LOSS [training: 0.1677806917718243 | validation: 0.38205972658243204]
	TIME [epoch: 8.91 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2079747240202042		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.2079747240202042 | validation: 0.4204380762604843]
	TIME [epoch: 8.91 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19160220822742585		[learning rate: 0.0077396]
	Learning Rate: 0.00773959
	LOSS [training: 0.19160220822742585 | validation: 0.41347537941710644]
	TIME [epoch: 8.91 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.181220018440614		[learning rate: 0.0077031]
	Learning Rate: 0.00770312
	LOSS [training: 0.181220018440614 | validation: 0.32291703814767636]
	TIME [epoch: 8.93 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16212751572812725		[learning rate: 0.0076668]
	Learning Rate: 0.00766682
	LOSS [training: 0.16212751572812725 | validation: 0.34047551918763064]
	TIME [epoch: 8.92 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18854548475464894		[learning rate: 0.0076307]
	Learning Rate: 0.0076307
	LOSS [training: 0.18854548475464894 | validation: 0.3548852959533616]
	TIME [epoch: 8.92 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.165026191278441		[learning rate: 0.0075947]
	Learning Rate: 0.00759474
	LOSS [training: 0.165026191278441 | validation: 0.3857294679396958]
	TIME [epoch: 8.92 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21256551685789218		[learning rate: 0.007559]
	Learning Rate: 0.00755895
	LOSS [training: 0.21256551685789218 | validation: 0.39941900169289074]
	TIME [epoch: 8.93 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23449357728377357		[learning rate: 0.0075233]
	Learning Rate: 0.00752333
	LOSS [training: 0.23449357728377357 | validation: 0.35249392173495]
	TIME [epoch: 8.91 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18893565023483566		[learning rate: 0.0074879]
	Learning Rate: 0.00748788
	LOSS [training: 0.18893565023483566 | validation: 0.4390869742401507]
	TIME [epoch: 8.92 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1938337647395721		[learning rate: 0.0074526]
	Learning Rate: 0.0074526
	LOSS [training: 0.1938337647395721 | validation: 0.38401756316235003]
	TIME [epoch: 8.91 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18738074331301668		[learning rate: 0.0074175]
	Learning Rate: 0.00741748
	LOSS [training: 0.18738074331301668 | validation: 0.4302875203886992]
	TIME [epoch: 8.92 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1996078776696108		[learning rate: 0.0073825]
	Learning Rate: 0.00738253
	LOSS [training: 0.1996078776696108 | validation: 0.32831516571140196]
	TIME [epoch: 8.92 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16966649650293186		[learning rate: 0.0073477]
	Learning Rate: 0.00734774
	LOSS [training: 0.16966649650293186 | validation: 0.3666240776354025]
	TIME [epoch: 8.9 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15114621485579893		[learning rate: 0.0073131]
	Learning Rate: 0.00731312
	LOSS [training: 0.15114621485579893 | validation: 0.3665126667054493]
	TIME [epoch: 8.91 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19502234168763424		[learning rate: 0.0072787]
	Learning Rate: 0.00727866
	LOSS [training: 0.19502234168763424 | validation: 0.32469368816165695]
	TIME [epoch: 8.91 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1570396858862852		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.1570396858862852 | validation: 0.323200696443699]
	TIME [epoch: 8.92 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16701759701098534		[learning rate: 0.0072102]
	Learning Rate: 0.00721022
	LOSS [training: 0.16701759701098534 | validation: 0.3510840721289388]
	TIME [epoch: 8.91 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.234403819661511		[learning rate: 0.0071762]
	Learning Rate: 0.00717625
	LOSS [training: 0.234403819661511 | validation: 0.3193716983565737]
	TIME [epoch: 8.91 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17009253930272403		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.17009253930272403 | validation: 0.3255860599170741]
	TIME [epoch: 8.91 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13739221228650766		[learning rate: 0.0071088]
	Learning Rate: 0.00710878
	LOSS [training: 0.13739221228650766 | validation: 0.3741581748737677]
	TIME [epoch: 8.92 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16096010459137455		[learning rate: 0.0070753]
	Learning Rate: 0.00707528
	LOSS [training: 0.16096010459137455 | validation: 0.3435622262363241]
	TIME [epoch: 8.92 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15228115562916048		[learning rate: 0.0070419]
	Learning Rate: 0.00704194
	LOSS [training: 0.15228115562916048 | validation: 0.3425622906916459]
	TIME [epoch: 8.91 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15633813879779343		[learning rate: 0.0070088]
	Learning Rate: 0.00700876
	LOSS [training: 0.15633813879779343 | validation: 0.445334169166955]
	TIME [epoch: 8.92 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15778459707542		[learning rate: 0.0069757]
	Learning Rate: 0.00697573
	LOSS [training: 0.15778459707542 | validation: 0.40078287475326735]
	TIME [epoch: 8.93 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1815424261365696		[learning rate: 0.0069429]
	Learning Rate: 0.00694286
	LOSS [training: 0.1815424261365696 | validation: 0.34550118869728325]
	TIME [epoch: 8.92 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17328935530591372		[learning rate: 0.0069101]
	Learning Rate: 0.00691014
	LOSS [training: 0.17328935530591372 | validation: 0.360528381834722]
	TIME [epoch: 8.91 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15829454189296135		[learning rate: 0.0068776]
	Learning Rate: 0.00687758
	LOSS [training: 0.15829454189296135 | validation: 0.4266460198167187]
	TIME [epoch: 8.92 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16716081496685892		[learning rate: 0.0068452]
	Learning Rate: 0.00684518
	LOSS [training: 0.16716081496685892 | validation: 0.36014758944162417]
	TIME [epoch: 8.92 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21213825489185892		[learning rate: 0.0068129]
	Learning Rate: 0.00681292
	LOSS [training: 0.21213825489185892 | validation: 0.29276728898185267]
	TIME [epoch: 8.92 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_119.pth
	Model improved!!!
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15608638563555882		[learning rate: 0.0067808]
	Learning Rate: 0.00678082
	LOSS [training: 0.15608638563555882 | validation: 0.35006357731916954]
	TIME [epoch: 8.91 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1713746911435535		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.1713746911435535 | validation: 0.356305325464136]
	TIME [epoch: 8.92 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17578525643434137		[learning rate: 0.0067171]
	Learning Rate: 0.00671706
	LOSS [training: 0.17578525643434137 | validation: 0.5221283159740934]
	TIME [epoch: 8.92 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15346753481831182		[learning rate: 0.0066854]
	Learning Rate: 0.00668541
	LOSS [training: 0.15346753481831182 | validation: 0.3270505385821332]
	TIME [epoch: 8.92 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14499005497503123		[learning rate: 0.0066539]
	Learning Rate: 0.00665391
	LOSS [training: 0.14499005497503123 | validation: 0.43321080063723505]
	TIME [epoch: 8.92 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17744934941011034		[learning rate: 0.0066226]
	Learning Rate: 0.00662256
	LOSS [training: 0.17744934941011034 | validation: 0.30371142932913925]
	TIME [epoch: 8.92 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17207584706158935		[learning rate: 0.0065913]
	Learning Rate: 0.00659135
	LOSS [training: 0.17207584706158935 | validation: 0.41181801908791676]
	TIME [epoch: 8.91 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2254927870664262		[learning rate: 0.0065603]
	Learning Rate: 0.00656029
	LOSS [training: 0.2254927870664262 | validation: 0.31028018824885506]
	TIME [epoch: 8.93 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1573365482041024		[learning rate: 0.0065294]
	Learning Rate: 0.00652938
	LOSS [training: 0.1573365482041024 | validation: 0.3251413293072539]
	TIME [epoch: 8.91 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14793522060565217		[learning rate: 0.0064986]
	Learning Rate: 0.00649861
	LOSS [training: 0.14793522060565217 | validation: 0.40457543655543904]
	TIME [epoch: 8.92 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1569503821098717		[learning rate: 0.006468]
	Learning Rate: 0.00646799
	LOSS [training: 0.1569503821098717 | validation: 0.3234005761151859]
	TIME [epoch: 8.91 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17663379182998085		[learning rate: 0.0064375]
	Learning Rate: 0.00643751
	LOSS [training: 0.17663379182998085 | validation: 0.4116174163803152]
	TIME [epoch: 8.93 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23839918191772697		[learning rate: 0.0064072]
	Learning Rate: 0.00640718
	LOSS [training: 0.23839918191772697 | validation: 0.3581868757262608]
	TIME [epoch: 8.92 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17696887470589073		[learning rate: 0.006377]
	Learning Rate: 0.00637698
	LOSS [training: 0.17696887470589073 | validation: 0.3376189517032227]
	TIME [epoch: 8.92 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19252842309519996		[learning rate: 0.0063469]
	Learning Rate: 0.00634694
	LOSS [training: 0.19252842309519996 | validation: 0.35767105212673783]
	TIME [epoch: 8.91 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2047443673979329		[learning rate: 0.006317]
	Learning Rate: 0.00631703
	LOSS [training: 0.2047443673979329 | validation: 0.44585763969123415]
	TIME [epoch: 8.92 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15910955137227875		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.15910955137227875 | validation: 0.3378791256154568]
	TIME [epoch: 8.92 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19160106651413464		[learning rate: 0.0062576]
	Learning Rate: 0.00625764
	LOSS [training: 0.19160106651413464 | validation: 0.4446497945854713]
	TIME [epoch: 8.91 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17899298167567768		[learning rate: 0.0062281]
	Learning Rate: 0.00622815
	LOSS [training: 0.17899298167567768 | validation: 0.3397536545572419]
	TIME [epoch: 8.91 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18297658670232084		[learning rate: 0.0061988]
	Learning Rate: 0.0061988
	LOSS [training: 0.18297658670232084 | validation: 0.3775165850031271]
	TIME [epoch: 8.91 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13572365678367326		[learning rate: 0.0061696]
	Learning Rate: 0.00616959
	LOSS [training: 0.13572365678367326 | validation: 0.30380286652618604]
	TIME [epoch: 8.92 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1546167233402941		[learning rate: 0.0061405]
	Learning Rate: 0.00614052
	LOSS [training: 0.1546167233402941 | validation: 0.3277319347259336]
	TIME [epoch: 8.91 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1402652119508105		[learning rate: 0.0061116]
	Learning Rate: 0.00611158
	LOSS [training: 0.1402652119508105 | validation: 0.47377073372801615]
	TIME [epoch: 8.91 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1748063040711009		[learning rate: 0.0060828]
	Learning Rate: 0.00608279
	LOSS [training: 0.1748063040711009 | validation: 0.31509623374479745]
	TIME [epoch: 8.91 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13476264710402094		[learning rate: 0.0060541]
	Learning Rate: 0.00605412
	LOSS [training: 0.13476264710402094 | validation: 0.3655420460488405]
	TIME [epoch: 8.92 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18101306462214017		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 0.18101306462214017 | validation: 0.318028491980872]
	TIME [epoch: 8.91 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13304470043868222		[learning rate: 0.0059972]
	Learning Rate: 0.0059972
	LOSS [training: 0.13304470043868222 | validation: 0.3972920024556513]
	TIME [epoch: 8.9 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17753070018006525		[learning rate: 0.0059689]
	Learning Rate: 0.00596894
	LOSS [training: 0.17753070018006525 | validation: 0.3315853468552429]
	TIME [epoch: 8.91 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1817419803615609		[learning rate: 0.0059408]
	Learning Rate: 0.00594082
	LOSS [training: 0.1817419803615609 | validation: 0.44380612137480097]
	TIME [epoch: 8.91 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15911106854134205		[learning rate: 0.0059128]
	Learning Rate: 0.00591282
	LOSS [training: 0.15911106854134205 | validation: 0.33702691616208735]
	TIME [epoch: 8.92 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1741156350271306		[learning rate: 0.005885]
	Learning Rate: 0.00588496
	LOSS [training: 0.1741156350271306 | validation: 0.38155485004462564]
	TIME [epoch: 8.91 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15561753516116517		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.15561753516116517 | validation: 0.37575774181382027]
	TIME [epoch: 8.91 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1616744215899046		[learning rate: 0.0058296]
	Learning Rate: 0.00582963
	LOSS [training: 0.1616744215899046 | validation: 0.3984504947466234]
	TIME [epoch: 8.91 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18860380889162304		[learning rate: 0.0058022]
	Learning Rate: 0.00580216
	LOSS [training: 0.18860380889162304 | validation: 0.35116316835887185]
	TIME [epoch: 8.93 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13621302586718292		[learning rate: 0.0057748]
	Learning Rate: 0.00577482
	LOSS [training: 0.13621302586718292 | validation: 0.39370163400780867]
	TIME [epoch: 8.91 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15398925070029737		[learning rate: 0.0057476]
	Learning Rate: 0.00574761
	LOSS [training: 0.15398925070029737 | validation: 0.37787715838846825]
	TIME [epoch: 8.92 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17855793142883686		[learning rate: 0.0057205]
	Learning Rate: 0.00572052
	LOSS [training: 0.17855793142883686 | validation: 0.31667759487915476]
	TIME [epoch: 8.91 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13429257070203876		[learning rate: 0.0056936]
	Learning Rate: 0.00569357
	LOSS [training: 0.13429257070203876 | validation: 0.3254922702894111]
	TIME [epoch: 8.93 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14831716734171485		[learning rate: 0.0056667]
	Learning Rate: 0.00566674
	LOSS [training: 0.14831716734171485 | validation: 0.3234618943463216]
	TIME [epoch: 8.91 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15004633283803184		[learning rate: 0.00564]
	Learning Rate: 0.00564004
	LOSS [training: 0.15004633283803184 | validation: 0.37082682310090326]
	TIME [epoch: 8.91 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13961203816855586		[learning rate: 0.0056135]
	Learning Rate: 0.00561346
	LOSS [training: 0.13961203816855586 | validation: 0.44492341032673827]
	TIME [epoch: 8.91 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16208016984674406		[learning rate: 0.005587]
	Learning Rate: 0.00558701
	LOSS [training: 0.16208016984674406 | validation: 0.3001460923691382]
	TIME [epoch: 8.93 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1481177836522628		[learning rate: 0.0055607]
	Learning Rate: 0.00556068
	LOSS [training: 0.1481177836522628 | validation: 0.3798517540234805]
	TIME [epoch: 8.92 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1432156491987		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.1432156491987 | validation: 0.3113064312296317]
	TIME [epoch: 8.92 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1295776566333244		[learning rate: 0.0055084]
	Learning Rate: 0.0055084
	LOSS [training: 0.1295776566333244 | validation: 0.3040658251373822]
	TIME [epoch: 8.91 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1485513936613476		[learning rate: 0.0054824]
	Learning Rate: 0.00548245
	LOSS [training: 0.1485513936613476 | validation: 0.36820584760338737]
	TIME [epoch: 8.91 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1668069528183383		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.1668069528183383 | validation: 0.32183911064722315]
	TIME [epoch: 8.93 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14529647515411226		[learning rate: 0.0054309]
	Learning Rate: 0.0054309
	LOSS [training: 0.14529647515411226 | validation: 0.3326779770409123]
	TIME [epoch: 8.92 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1710864790648067		[learning rate: 0.0054053]
	Learning Rate: 0.00540531
	LOSS [training: 0.1710864790648067 | validation: 0.3973850855707564]
	TIME [epoch: 8.92 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15032667641376599		[learning rate: 0.0053798]
	Learning Rate: 0.00537984
	LOSS [training: 0.15032667641376599 | validation: 0.31781890171821053]
	TIME [epoch: 8.92 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1651715063021718		[learning rate: 0.0053545]
	Learning Rate: 0.00535449
	LOSS [training: 0.1651715063021718 | validation: 0.34313612376120417]
	TIME [epoch: 8.93 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1832774629909734		[learning rate: 0.0053293]
	Learning Rate: 0.00532926
	LOSS [training: 0.1832774629909734 | validation: 0.31425879945784885]
	TIME [epoch: 8.92 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17035202886049505		[learning rate: 0.0053041]
	Learning Rate: 0.00530415
	LOSS [training: 0.17035202886049505 | validation: 0.3849146530644238]
	TIME [epoch: 8.92 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19931780413750705		[learning rate: 0.0052792]
	Learning Rate: 0.00527915
	LOSS [training: 0.19931780413750705 | validation: 0.34632446077274187]
	TIME [epoch: 8.92 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15805688272240923		[learning rate: 0.0052543]
	Learning Rate: 0.00525428
	LOSS [training: 0.15805688272240923 | validation: 0.3060404351252919]
	TIME [epoch: 8.92 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16236828807500459		[learning rate: 0.0052295]
	Learning Rate: 0.00522952
	LOSS [training: 0.16236828807500459 | validation: 0.3013828312713125]
	TIME [epoch: 8.92 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1445486640077421		[learning rate: 0.0052049]
	Learning Rate: 0.00520487
	LOSS [training: 0.1445486640077421 | validation: 0.31490531571821484]
	TIME [epoch: 8.92 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13718693050009814		[learning rate: 0.0051803]
	Learning Rate: 0.00518035
	LOSS [training: 0.13718693050009814 | validation: 0.420366798780798]
	TIME [epoch: 8.92 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1397023579352467		[learning rate: 0.0051559]
	Learning Rate: 0.00515594
	LOSS [training: 0.1397023579352467 | validation: 0.3485561685535929]
	TIME [epoch: 8.92 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13669379338197712		[learning rate: 0.0051316]
	Learning Rate: 0.00513164
	LOSS [training: 0.13669379338197712 | validation: 0.36539917302598757]
	TIME [epoch: 8.92 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1577700458670592		[learning rate: 0.0051075]
	Learning Rate: 0.00510746
	LOSS [training: 0.1577700458670592 | validation: 0.2876087046816747]
	TIME [epoch: 8.92 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_180.pth
	Model improved!!!
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17132038651905412		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.17132038651905412 | validation: 0.3808973093679727]
	TIME [epoch: 8.91 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15506951481411047		[learning rate: 0.0050594]
	Learning Rate: 0.00505944
	LOSS [training: 0.15506951481411047 | validation: 0.3120038164174626]
	TIME [epoch: 8.91 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1772261362145005		[learning rate: 0.0050356]
	Learning Rate: 0.0050356
	LOSS [training: 0.1772261362145005 | validation: 0.317746262655995]
	TIME [epoch: 8.92 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16382245969064224		[learning rate: 0.0050119]
	Learning Rate: 0.00501187
	LOSS [training: 0.16382245969064224 | validation: 0.33679529354191484]
	TIME [epoch: 8.9 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17082864690572208		[learning rate: 0.0049883]
	Learning Rate: 0.00498826
	LOSS [training: 0.17082864690572208 | validation: 0.3137605058388819]
	TIME [epoch: 8.91 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14714807538587993		[learning rate: 0.0049648]
	Learning Rate: 0.00496475
	LOSS [training: 0.14714807538587993 | validation: 0.3014914726848525]
	TIME [epoch: 8.9 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14953666212511474		[learning rate: 0.0049414]
	Learning Rate: 0.00494136
	LOSS [training: 0.14953666212511474 | validation: 0.3344920327529365]
	TIME [epoch: 8.92 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14595981690416138		[learning rate: 0.0049181]
	Learning Rate: 0.00491807
	LOSS [training: 0.14595981690416138 | validation: 0.34646114585603716]
	TIME [epoch: 8.9 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13761381071436735		[learning rate: 0.0048949]
	Learning Rate: 0.0048949
	LOSS [training: 0.13761381071436735 | validation: 0.32558507212762644]
	TIME [epoch: 8.91 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13670331587246987		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.13670331587246987 | validation: 0.31755185990166696]
	TIME [epoch: 8.9 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16434285504468385		[learning rate: 0.0048489]
	Learning Rate: 0.00484888
	LOSS [training: 0.16434285504468385 | validation: 0.29032839019651596]
	TIME [epoch: 8.91 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18400092323270478		[learning rate: 0.004826]
	Learning Rate: 0.00482603
	LOSS [training: 0.18400092323270478 | validation: 0.3148236503148322]
	TIME [epoch: 8.91 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17395575663121327		[learning rate: 0.0048033]
	Learning Rate: 0.00480329
	LOSS [training: 0.17395575663121327 | validation: 0.357265566542014]
	TIME [epoch: 8.91 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1702872073049538		[learning rate: 0.0047807]
	Learning Rate: 0.00478065
	LOSS [training: 0.1702872073049538 | validation: 0.3431347938378822]
	TIME [epoch: 8.9 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1680623063799498		[learning rate: 0.0047581]
	Learning Rate: 0.00475813
	LOSS [training: 0.1680623063799498 | validation: 0.31966150527942316]
	TIME [epoch: 8.91 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13482008927249456		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.13482008927249456 | validation: 0.3207468978693594]
	TIME [epoch: 8.92 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13770911190523363		[learning rate: 0.0047134]
	Learning Rate: 0.00471339
	LOSS [training: 0.13770911190523363 | validation: 0.35158997108210305]
	TIME [epoch: 8.91 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15059780880547824		[learning rate: 0.0046912]
	Learning Rate: 0.00469118
	LOSS [training: 0.15059780880547824 | validation: 0.36078250870810785]
	TIME [epoch: 8.9 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1473002599859401		[learning rate: 0.0046691]
	Learning Rate: 0.00466907
	LOSS [training: 0.1473002599859401 | validation: 0.2973034623927277]
	TIME [epoch: 8.91 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13213399882220878		[learning rate: 0.0046471]
	Learning Rate: 0.00464707
	LOSS [training: 0.13213399882220878 | validation: 0.33570941995404313]
	TIME [epoch: 8.91 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12977003581851324		[learning rate: 0.0046252]
	Learning Rate: 0.00462518
	LOSS [training: 0.12977003581851324 | validation: 0.32034086359746433]
	TIME [epoch: 8.91 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1429597515972193		[learning rate: 0.0046034]
	Learning Rate: 0.00460338
	LOSS [training: 0.1429597515972193 | validation: 0.30533029402153333]
	TIME [epoch: 8.9 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1582792916984202		[learning rate: 0.0045817]
	Learning Rate: 0.00458169
	LOSS [training: 0.1582792916984202 | validation: 0.3551638679695573]
	TIME [epoch: 8.91 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13784436001904396		[learning rate: 0.0045601]
	Learning Rate: 0.0045601
	LOSS [training: 0.13784436001904396 | validation: 0.3230323905104004]
	TIME [epoch: 8.91 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1343345901786142		[learning rate: 0.0045386]
	Learning Rate: 0.00453861
	LOSS [training: 0.1343345901786142 | validation: 0.29400289722983786]
	TIME [epoch: 8.92 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14311900505383154		[learning rate: 0.0045172]
	Learning Rate: 0.00451723
	LOSS [training: 0.14311900505383154 | validation: 0.31676297002322107]
	TIME [epoch: 8.9 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13605811061663403		[learning rate: 0.0044959]
	Learning Rate: 0.00449594
	LOSS [training: 0.13605811061663403 | validation: 0.3560166858291197]
	TIME [epoch: 8.91 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15931354409251014		[learning rate: 0.0044748]
	Learning Rate: 0.00447475
	LOSS [training: 0.15931354409251014 | validation: 0.2992613347567505]
	TIME [epoch: 8.91 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15383407502583288		[learning rate: 0.0044537]
	Learning Rate: 0.00445367
	LOSS [training: 0.15383407502583288 | validation: 0.31404056487988263]
	TIME [epoch: 8.92 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15059941758396117		[learning rate: 0.0044327]
	Learning Rate: 0.00443268
	LOSS [training: 0.15059941758396117 | validation: 0.381564900881043]
	TIME [epoch: 8.91 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14141109704393048		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.14141109704393048 | validation: 0.33396854076288174]
	TIME [epoch: 8.91 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14970745159932494		[learning rate: 0.004391]
	Learning Rate: 0.00439101
	LOSS [training: 0.14970745159932494 | validation: 0.41694063974311785]
	TIME [epoch: 8.91 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15078608749878597		[learning rate: 0.0043703]
	Learning Rate: 0.00437032
	LOSS [training: 0.15078608749878597 | validation: 0.32582599365562365]
	TIME [epoch: 8.92 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1311186509835644		[learning rate: 0.0043497]
	Learning Rate: 0.00434972
	LOSS [training: 0.1311186509835644 | validation: 0.29930449543316484]
	TIME [epoch: 8.91 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1462006212094295		[learning rate: 0.0043292]
	Learning Rate: 0.00432923
	LOSS [training: 0.1462006212094295 | validation: 0.3564230128549914]
	TIME [epoch: 8.91 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12193200559147137		[learning rate: 0.0043088]
	Learning Rate: 0.00430883
	LOSS [training: 0.12193200559147137 | validation: 0.3977804541300036]
	TIME [epoch: 8.91 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14487119112239494		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.14487119112239494 | validation: 0.31846061860794356]
	TIME [epoch: 8.92 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1295134398499902		[learning rate: 0.0042683]
	Learning Rate: 0.00426831
	LOSS [training: 0.1295134398499902 | validation: 0.3513930815519897]
	TIME [epoch: 8.92 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13692418217957933		[learning rate: 0.0042482]
	Learning Rate: 0.0042482
	LOSS [training: 0.13692418217957933 | validation: 0.3385001826123076]
	TIME [epoch: 8.91 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14051110939467232		[learning rate: 0.0042282]
	Learning Rate: 0.00422818
	LOSS [training: 0.14051110939467232 | validation: 0.3140298107949421]
	TIME [epoch: 8.91 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12531317220950533		[learning rate: 0.0042083]
	Learning Rate: 0.00420826
	LOSS [training: 0.12531317220950533 | validation: 0.3081662680829415]
	TIME [epoch: 8.92 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14713726229616164		[learning rate: 0.0041884]
	Learning Rate: 0.00418843
	LOSS [training: 0.14713726229616164 | validation: 0.3824882661212688]
	TIME [epoch: 8.92 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13416031647685167		[learning rate: 0.0041687]
	Learning Rate: 0.00416869
	LOSS [training: 0.13416031647685167 | validation: 0.32926609419413444]
	TIME [epoch: 8.91 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13531489596621948		[learning rate: 0.0041491]
	Learning Rate: 0.00414905
	LOSS [training: 0.13531489596621948 | validation: 0.33050472193659897]
	TIME [epoch: 8.91 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14631023382982022		[learning rate: 0.0041295]
	Learning Rate: 0.0041295
	LOSS [training: 0.14631023382982022 | validation: 0.3398043387712649]
	TIME [epoch: 8.91 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.141342382255632		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.141342382255632 | validation: 0.3291415952961656]
	TIME [epoch: 8.92 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13844371148006537		[learning rate: 0.0040907]
	Learning Rate: 0.00409067
	LOSS [training: 0.13844371148006537 | validation: 0.36190076816555455]
	TIME [epoch: 8.91 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14410445008201023		[learning rate: 0.0040714]
	Learning Rate: 0.0040714
	LOSS [training: 0.14410445008201023 | validation: 0.3166123304331377]
	TIME [epoch: 8.91 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14996283866580506		[learning rate: 0.0040522]
	Learning Rate: 0.00405221
	LOSS [training: 0.14996283866580506 | validation: 0.34795668357418763]
	TIME [epoch: 8.92 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1312947208006828		[learning rate: 0.0040331]
	Learning Rate: 0.00403312
	LOSS [training: 0.1312947208006828 | validation: 0.30368233550889207]
	TIME [epoch: 8.91 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14884074256012494		[learning rate: 0.0040141]
	Learning Rate: 0.00401411
	LOSS [training: 0.14884074256012494 | validation: 0.34428496719203305]
	TIME [epoch: 8.91 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13592952315602244		[learning rate: 0.0039952]
	Learning Rate: 0.0039952
	LOSS [training: 0.13592952315602244 | validation: 0.3262547923304346]
	TIME [epoch: 8.9 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13231696026996764		[learning rate: 0.0039764]
	Learning Rate: 0.00397637
	LOSS [training: 0.13231696026996764 | validation: 0.321048887638432]
	TIME [epoch: 8.91 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1254184837818872		[learning rate: 0.0039576]
	Learning Rate: 0.00395764
	LOSS [training: 0.1254184837818872 | validation: 0.3112449725519054]
	TIME [epoch: 8.91 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13990306293030202		[learning rate: 0.003939]
	Learning Rate: 0.00393899
	LOSS [training: 0.13990306293030202 | validation: 0.3120775436792084]
	TIME [epoch: 8.92 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15348259606149195		[learning rate: 0.0039204]
	Learning Rate: 0.00392043
	LOSS [training: 0.15348259606149195 | validation: 0.3544498488387077]
	TIME [epoch: 8.91 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15834842809176686		[learning rate: 0.003902]
	Learning Rate: 0.00390195
	LOSS [training: 0.15834842809176686 | validation: 0.3390301492287487]
	TIME [epoch: 8.91 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16474963030733727		[learning rate: 0.0038836]
	Learning Rate: 0.00388357
	LOSS [training: 0.16474963030733727 | validation: 0.2891498036862311]
	TIME [epoch: 8.91 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1386643449771358		[learning rate: 0.0038653]
	Learning Rate: 0.00386527
	LOSS [training: 0.1386643449771358 | validation: 0.35664779267456526]
	TIME [epoch: 8.92 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13516003232340373		[learning rate: 0.0038471]
	Learning Rate: 0.00384705
	LOSS [training: 0.13516003232340373 | validation: 0.3391188788420601]
	TIME [epoch: 8.91 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15379622136839838		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.15379622136839838 | validation: 0.3618805411113621]
	TIME [epoch: 8.91 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15283577067643322		[learning rate: 0.0038109]
	Learning Rate: 0.00381088
	LOSS [training: 0.15283577067643322 | validation: 0.29435246975358564]
	TIME [epoch: 8.9 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14218278424608843		[learning rate: 0.0037929]
	Learning Rate: 0.00379293
	LOSS [training: 0.14218278424608843 | validation: 0.2938051795104067]
	TIME [epoch: 8.91 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15836898926937956		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.15836898926937956 | validation: 0.3447712536412518]
	TIME [epoch: 8.91 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16491076008412753		[learning rate: 0.0037573]
	Learning Rate: 0.00375726
	LOSS [training: 0.16491076008412753 | validation: 0.34773545344711687]
	TIME [epoch: 8.91 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17561782710876456		[learning rate: 0.0037396]
	Learning Rate: 0.00373956
	LOSS [training: 0.17561782710876456 | validation: 0.32312713437152385]
	TIME [epoch: 8.91 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13212789710835818		[learning rate: 0.0037219]
	Learning Rate: 0.00372194
	LOSS [training: 0.13212789710835818 | validation: 0.3475782383925651]
	TIME [epoch: 8.91 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12398955588834738		[learning rate: 0.0037044]
	Learning Rate: 0.0037044
	LOSS [training: 0.12398955588834738 | validation: 0.320333037115773]
	TIME [epoch: 8.92 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12009985887656524		[learning rate: 0.0036869]
	Learning Rate: 0.00368695
	LOSS [training: 0.12009985887656524 | validation: 0.30840463577983707]
	TIME [epoch: 8.91 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12918491801450438		[learning rate: 0.0036696]
	Learning Rate: 0.00366957
	LOSS [training: 0.12918491801450438 | validation: 0.2960835276672996]
	TIME [epoch: 8.91 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.152427966525836		[learning rate: 0.0036523]
	Learning Rate: 0.00365228
	LOSS [training: 0.152427966525836 | validation: 0.3308646293952585]
	TIME [epoch: 8.91 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1328368805310059		[learning rate: 0.0036351]
	Learning Rate: 0.00363507
	LOSS [training: 0.1328368805310059 | validation: 0.309375558048245]
	TIME [epoch: 8.92 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12053615793563299		[learning rate: 0.0036179]
	Learning Rate: 0.00361794
	LOSS [training: 0.12053615793563299 | validation: 0.315531511440143]
	TIME [epoch: 8.91 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.141157679627484		[learning rate: 0.0036009]
	Learning Rate: 0.00360089
	LOSS [training: 0.141157679627484 | validation: 0.31272062432567865]
	TIME [epoch: 8.91 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13624193110798438		[learning rate: 0.0035839]
	Learning Rate: 0.00358393
	LOSS [training: 0.13624193110798438 | validation: 0.36598237900022657]
	TIME [epoch: 8.91 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13304334419530817		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.13304334419530817 | validation: 0.2992150240540963]
	TIME [epoch: 8.92 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13896403820317435		[learning rate: 0.0035502]
	Learning Rate: 0.00355023
	LOSS [training: 0.13896403820317435 | validation: 0.33905743389881865]
	TIME [epoch: 8.91 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1378828946078407		[learning rate: 0.0035335]
	Learning Rate: 0.0035335
	LOSS [training: 0.1378828946078407 | validation: 0.3275100545226864]
	TIME [epoch: 8.91 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1383190339166439		[learning rate: 0.0035168]
	Learning Rate: 0.00351685
	LOSS [training: 0.1383190339166439 | validation: 0.2988095810393174]
	TIME [epoch: 8.91 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1615912985548027		[learning rate: 0.0035003]
	Learning Rate: 0.00350028
	LOSS [training: 0.1615912985548027 | validation: 0.3167270638980749]
	TIME [epoch: 8.91 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.136337398199391		[learning rate: 0.0034838]
	Learning Rate: 0.00348378
	LOSS [training: 0.136337398199391 | validation: 0.33862877149111065]
	TIME [epoch: 8.92 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13727123436988764		[learning rate: 0.0034674]
	Learning Rate: 0.00346737
	LOSS [training: 0.13727123436988764 | validation: 0.3464590700116378]
	TIME [epoch: 8.91 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14862545606933716		[learning rate: 0.003451]
	Learning Rate: 0.00345103
	LOSS [training: 0.14862545606933716 | validation: 0.3813670934370476]
	TIME [epoch: 8.91 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13815000085209933		[learning rate: 0.0034348]
	Learning Rate: 0.00343477
	LOSS [training: 0.13815000085209933 | validation: 0.3046124177710782]
	TIME [epoch: 8.91 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12250549880370104		[learning rate: 0.0034186]
	Learning Rate: 0.00341858
	LOSS [training: 0.12250549880370104 | validation: 0.3382730807657222]
	TIME [epoch: 8.93 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1293315531764952		[learning rate: 0.0034025]
	Learning Rate: 0.00340247
	LOSS [training: 0.1293315531764952 | validation: 0.33256002458358863]
	TIME [epoch: 8.92 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14944347233886404		[learning rate: 0.0033864]
	Learning Rate: 0.00338644
	LOSS [training: 0.14944347233886404 | validation: 0.3046188769631022]
	TIME [epoch: 8.92 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1317860889035617		[learning rate: 0.0033705]
	Learning Rate: 0.00337048
	LOSS [training: 0.1317860889035617 | validation: 0.3170647602521649]
	TIME [epoch: 8.91 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1307405845995016		[learning rate: 0.0033546]
	Learning Rate: 0.0033546
	LOSS [training: 0.1307405845995016 | validation: 0.29439097374337536]
	TIME [epoch: 8.93 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13130793429539986		[learning rate: 0.0033388]
	Learning Rate: 0.00333879
	LOSS [training: 0.13130793429539986 | validation: 0.35125469785932717]
	TIME [epoch: 8.91 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11826487639502387		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.11826487639502387 | validation: 0.3055257704135198]
	TIME [epoch: 8.91 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10807466081683478		[learning rate: 0.0033074]
	Learning Rate: 0.0033074
	LOSS [training: 0.10807466081683478 | validation: 0.30863741730125077]
	TIME [epoch: 8.9 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.138935062300151		[learning rate: 0.0032918]
	Learning Rate: 0.00329182
	LOSS [training: 0.138935062300151 | validation: 0.34850471994606025]
	TIME [epoch: 8.91 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15237308174214143		[learning rate: 0.0032763]
	Learning Rate: 0.00327631
	LOSS [training: 0.15237308174214143 | validation: 0.3990569933406053]
	TIME [epoch: 8.91 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14103276720562238		[learning rate: 0.0032609]
	Learning Rate: 0.00326087
	LOSS [training: 0.14103276720562238 | validation: 0.3123611283963307]
	TIME [epoch: 8.91 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1280778555335553		[learning rate: 0.0032455]
	Learning Rate: 0.0032455
	LOSS [training: 0.1280778555335553 | validation: 0.31199361080598514]
	TIME [epoch: 8.9 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14056047408560748		[learning rate: 0.0032302]
	Learning Rate: 0.00323021
	LOSS [training: 0.14056047408560748 | validation: 0.3285971931445648]
	TIME [epoch: 8.91 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14620742504629497		[learning rate: 0.003215]
	Learning Rate: 0.00321499
	LOSS [training: 0.14620742504629497 | validation: 0.34766100026450053]
	TIME [epoch: 8.92 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15628297499052884		[learning rate: 0.0031998]
	Learning Rate: 0.00319984
	LOSS [training: 0.15628297499052884 | validation: 0.3627779832439445]
	TIME [epoch: 8.9 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14442466338129464		[learning rate: 0.0031848]
	Learning Rate: 0.00318476
	LOSS [training: 0.14442466338129464 | validation: 0.3446193434110526]
	TIME [epoch: 8.9 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12782849173414784		[learning rate: 0.0031698]
	Learning Rate: 0.00316975
	LOSS [training: 0.12782849173414784 | validation: 0.30274991156606496]
	TIME [epoch: 8.9 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13454408204572424		[learning rate: 0.0031548]
	Learning Rate: 0.00315482
	LOSS [training: 0.13454408204572424 | validation: 0.286843659186226]
	TIME [epoch: 8.91 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_282.pth
	Model improved!!!
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15119570331526794		[learning rate: 0.00314]
	Learning Rate: 0.00313995
	LOSS [training: 0.15119570331526794 | validation: 0.3596872576898955]
	TIME [epoch: 8.91 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1288394313201681		[learning rate: 0.0031252]
	Learning Rate: 0.00312516
	LOSS [training: 0.1288394313201681 | validation: 0.3142156883445231]
	TIME [epoch: 8.91 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13742952722280258		[learning rate: 0.0031104]
	Learning Rate: 0.00311043
	LOSS [training: 0.13742952722280258 | validation: 0.2977642072011397]
	TIME [epoch: 8.91 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1236329292837636		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.1236329292837636 | validation: 0.3178493003021898]
	TIME [epoch: 8.92 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12121334112671919		[learning rate: 0.0030812]
	Learning Rate: 0.00308119
	LOSS [training: 0.12121334112671919 | validation: 0.3034964773266048]
	TIME [epoch: 8.92 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1274981345083106		[learning rate: 0.0030667]
	Learning Rate: 0.00306667
	LOSS [training: 0.1274981345083106 | validation: 0.3029071947708645]
	TIME [epoch: 8.91 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12396026778451359		[learning rate: 0.0030522]
	Learning Rate: 0.00305222
	LOSS [training: 0.12396026778451359 | validation: 0.3121916792143784]
	TIME [epoch: 8.91 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12016661655362676		[learning rate: 0.0030378]
	Learning Rate: 0.00303783
	LOSS [training: 0.12016661655362676 | validation: 0.30451488978793867]
	TIME [epoch: 8.92 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12616649658592277		[learning rate: 0.0030235]
	Learning Rate: 0.00302352
	LOSS [training: 0.12616649658592277 | validation: 0.28879283078146667]
	TIME [epoch: 8.92 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1225174326290881		[learning rate: 0.0030093]
	Learning Rate: 0.00300927
	LOSS [training: 0.1225174326290881 | validation: 0.3278694418955549]
	TIME [epoch: 8.91 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11345635315948392		[learning rate: 0.0029951]
	Learning Rate: 0.00299509
	LOSS [training: 0.11345635315948392 | validation: 0.3202273249015025]
	TIME [epoch: 8.91 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1344610865189355		[learning rate: 0.002981]
	Learning Rate: 0.00298098
	LOSS [training: 0.1344610865189355 | validation: 0.3500795570349135]
	TIME [epoch: 8.91 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16374435406656357		[learning rate: 0.0029669]
	Learning Rate: 0.00296693
	LOSS [training: 0.16374435406656357 | validation: 0.3200608004767066]
	TIME [epoch: 8.92 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12449458981567012		[learning rate: 0.002953]
	Learning Rate: 0.00295295
	LOSS [training: 0.12449458981567012 | validation: 0.30028969868173605]
	TIME [epoch: 8.91 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13464775256959993		[learning rate: 0.002939]
	Learning Rate: 0.00293904
	LOSS [training: 0.13464775256959993 | validation: 0.3312418417010123]
	TIME [epoch: 8.91 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.126296372998129		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.126296372998129 | validation: 0.3123345246994057]
	TIME [epoch: 8.91 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11433058579786176		[learning rate: 0.0029114]
	Learning Rate: 0.0029114
	LOSS [training: 0.11433058579786176 | validation: 0.3225493250239765]
	TIME [epoch: 8.92 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11457391309751408		[learning rate: 0.0028977]
	Learning Rate: 0.00289769
	LOSS [training: 0.11457391309751408 | validation: 0.33385240340396993]
	TIME [epoch: 8.92 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13911805290688353		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.13911805290688353 | validation: 0.31182482925571137]
	TIME [epoch: 8.93 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1561956301256066		[learning rate: 0.0028704]
	Learning Rate: 0.00287044
	LOSS [training: 0.1561956301256066 | validation: 0.3783731958909172]
	TIME [epoch: 8.92 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14012386348636502		[learning rate: 0.0028569]
	Learning Rate: 0.00285692
	LOSS [training: 0.14012386348636502 | validation: 0.3124666717627391]
	TIME [epoch: 8.92 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12638074513580383		[learning rate: 0.0028435]
	Learning Rate: 0.00284345
	LOSS [training: 0.12638074513580383 | validation: 0.4361013239179716]
	TIME [epoch: 8.93 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1302097282300772		[learning rate: 0.0028301]
	Learning Rate: 0.00283005
	LOSS [training: 0.1302097282300772 | validation: 0.30225991374951416]
	TIME [epoch: 8.92 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11747607355157975		[learning rate: 0.0028167]
	Learning Rate: 0.00281672
	LOSS [training: 0.11747607355157975 | validation: 0.2959036786011635]
	TIME [epoch: 8.92 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11307795451457464		[learning rate: 0.0028034]
	Learning Rate: 0.00280345
	LOSS [training: 0.11307795451457464 | validation: 0.34298689880001454]
	TIME [epoch: 8.92 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12074026623323665		[learning rate: 0.0027902]
	Learning Rate: 0.00279024
	LOSS [training: 0.12074026623323665 | validation: 0.33773917115423735]
	TIME [epoch: 8.92 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1436180498328936		[learning rate: 0.0027771]
	Learning Rate: 0.00277709
	LOSS [training: 0.1436180498328936 | validation: 0.30738890244678096]
	TIME [epoch: 8.91 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12959019158165025		[learning rate: 0.002764]
	Learning Rate: 0.002764
	LOSS [training: 0.12959019158165025 | validation: 0.29765129222505304]
	TIME [epoch: 8.9 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1283835953384761		[learning rate: 0.002751]
	Learning Rate: 0.00275098
	LOSS [training: 0.1283835953384761 | validation: 0.2964301646489388]
	TIME [epoch: 8.91 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1282243353905345		[learning rate: 0.002738]
	Learning Rate: 0.00273802
	LOSS [training: 0.1282243353905345 | validation: 0.3080435674115973]
	TIME [epoch: 8.92 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13793280786233592		[learning rate: 0.0027251]
	Learning Rate: 0.00272511
	LOSS [training: 0.13793280786233592 | validation: 0.32643398524043377]
	TIME [epoch: 8.91 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12238684500417062		[learning rate: 0.0027123]
	Learning Rate: 0.00271227
	LOSS [training: 0.12238684500417062 | validation: 0.2972800800410399]
	TIME [epoch: 8.91 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12699335595359285		[learning rate: 0.0026995]
	Learning Rate: 0.00269949
	LOSS [training: 0.12699335595359285 | validation: 0.31197764638148034]
	TIME [epoch: 8.91 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1342906882948727		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.1342906882948727 | validation: 0.3062177890791776]
	TIME [epoch: 8.91 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12137951353878412		[learning rate: 0.0026741]
	Learning Rate: 0.00267411
	LOSS [training: 0.12137951353878412 | validation: 0.3728822794118013]
	TIME [epoch: 8.91 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1271692424038935		[learning rate: 0.0026615]
	Learning Rate: 0.00266151
	LOSS [training: 0.1271692424038935 | validation: 0.32132624334523135]
	TIME [epoch: 8.91 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13579762107534082		[learning rate: 0.002649]
	Learning Rate: 0.00264897
	LOSS [training: 0.13579762107534082 | validation: 0.30696508254022514]
	TIME [epoch: 8.91 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.140807863243063		[learning rate: 0.0026365]
	Learning Rate: 0.00263649
	LOSS [training: 0.140807863243063 | validation: 0.34852217493913074]
	TIME [epoch: 8.91 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1428471085883447		[learning rate: 0.0026241]
	Learning Rate: 0.00262406
	LOSS [training: 0.1428471085883447 | validation: 0.30653341329160066]
	TIME [epoch: 8.92 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12286196659251061		[learning rate: 0.0026117]
	Learning Rate: 0.0026117
	LOSS [training: 0.12286196659251061 | validation: 0.3023071048063831]
	TIME [epoch: 8.91 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14046205056723726		[learning rate: 0.0025994]
	Learning Rate: 0.00259939
	LOSS [training: 0.14046205056723726 | validation: 0.3144155870255697]
	TIME [epoch: 8.91 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13085002848869853		[learning rate: 0.0025871]
	Learning Rate: 0.00258714
	LOSS [training: 0.13085002848869853 | validation: 0.34886838880900384]
	TIME [epoch: 8.91 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12678742071796156		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.12678742071796156 | validation: 0.28570886602149664]
	TIME [epoch: 8.92 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_325.pth
	Model improved!!!
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11503586212346131		[learning rate: 0.0025628]
	Learning Rate: 0.00256282
	LOSS [training: 0.11503586212346131 | validation: 0.31653957332025073]
	TIME [epoch: 8.92 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12765606337003527		[learning rate: 0.0025507]
	Learning Rate: 0.00255074
	LOSS [training: 0.12765606337003527 | validation: 0.3080900466447277]
	TIME [epoch: 8.92 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12744686359430307		[learning rate: 0.0025387]
	Learning Rate: 0.00253872
	LOSS [training: 0.12744686359430307 | validation: 0.2963736659388483]
	TIME [epoch: 8.92 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1305447483393911		[learning rate: 0.0025268]
	Learning Rate: 0.00252676
	LOSS [training: 0.1305447483393911 | validation: 0.2972223148441009]
	TIME [epoch: 8.93 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11463247585455573		[learning rate: 0.0025149]
	Learning Rate: 0.00251485
	LOSS [training: 0.11463247585455573 | validation: 0.3206603202327679]
	TIME [epoch: 8.92 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11881456113564551		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.11881456113564551 | validation: 0.29055695351724414]
	TIME [epoch: 8.92 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11673948622586935		[learning rate: 0.0024912]
	Learning Rate: 0.00249121
	LOSS [training: 0.11673948622586935 | validation: 0.3163787193881829]
	TIME [epoch: 8.92 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12601146923287876		[learning rate: 0.0024795]
	Learning Rate: 0.00247947
	LOSS [training: 0.12601146923287876 | validation: 0.32970892809216296]
	TIME [epoch: 8.92 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12452589054249368		[learning rate: 0.0024678]
	Learning Rate: 0.00246779
	LOSS [training: 0.12452589054249368 | validation: 0.3199027244617535]
	TIME [epoch: 8.93 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11589815861239444		[learning rate: 0.0024562]
	Learning Rate: 0.00245616
	LOSS [training: 0.11589815861239444 | validation: 0.3174970191765807]
	TIME [epoch: 8.92 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13393196053305387		[learning rate: 0.0024446]
	Learning Rate: 0.00244458
	LOSS [training: 0.13393196053305387 | validation: 0.2942015136446857]
	TIME [epoch: 8.92 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13424229107231944		[learning rate: 0.0024331]
	Learning Rate: 0.00243307
	LOSS [training: 0.13424229107231944 | validation: 0.30588862267040723]
	TIME [epoch: 8.92 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14336746878161757		[learning rate: 0.0024216]
	Learning Rate: 0.0024216
	LOSS [training: 0.14336746878161757 | validation: 0.30946155149488186]
	TIME [epoch: 8.93 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12088109486358221		[learning rate: 0.0024102]
	Learning Rate: 0.00241019
	LOSS [training: 0.12088109486358221 | validation: 0.28692675960108227]
	TIME [epoch: 8.92 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13547779966405593		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.13547779966405593 | validation: 0.33189454455341316]
	TIME [epoch: 8.92 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13409905421210624		[learning rate: 0.0023875]
	Learning Rate: 0.00238753
	LOSS [training: 0.13409905421210624 | validation: 0.30847691489956736]
	TIME [epoch: 8.92 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12985988436335133		[learning rate: 0.0023763]
	Learning Rate: 0.00237628
	LOSS [training: 0.12985988436335133 | validation: 0.3122279561931466]
	TIME [epoch: 8.94 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1407269340049151		[learning rate: 0.0023651]
	Learning Rate: 0.00236508
	LOSS [training: 0.1407269340049151 | validation: 0.29012308450670266]
	TIME [epoch: 8.92 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1262083774003797		[learning rate: 0.0023539]
	Learning Rate: 0.00235394
	LOSS [training: 0.1262083774003797 | validation: 0.3245384940646041]
	TIME [epoch: 8.92 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11950290247680463		[learning rate: 0.0023428]
	Learning Rate: 0.00234285
	LOSS [training: 0.11950290247680463 | validation: 0.2833658553607568]
	TIME [epoch: 8.92 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_345.pth
	Model improved!!!
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11700496579820059		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.11700496579820059 | validation: 0.2971605091394547]
	TIME [epoch: 8.92 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1200406738739152		[learning rate: 0.0023208]
	Learning Rate: 0.00232082
	LOSS [training: 0.1200406738739152 | validation: 0.3224817658400674]
	TIME [epoch: 8.91 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13909904975442822		[learning rate: 0.0023099]
	Learning Rate: 0.00230988
	LOSS [training: 0.13909904975442822 | validation: 0.3207291068941812]
	TIME [epoch: 8.92 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16134990682607847		[learning rate: 0.002299]
	Learning Rate: 0.002299
	LOSS [training: 0.16134990682607847 | validation: 0.3282041357758001]
	TIME [epoch: 8.92 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12151641011419335		[learning rate: 0.0022882]
	Learning Rate: 0.00228816
	LOSS [training: 0.12151641011419335 | validation: 0.28923319556850813]
	TIME [epoch: 8.93 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13191617664080324		[learning rate: 0.0022774]
	Learning Rate: 0.00227738
	LOSS [training: 0.13191617664080324 | validation: 0.3191690479396513]
	TIME [epoch: 8.92 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12912982603605494		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.12912982603605494 | validation: 0.28867754203009216]
	TIME [epoch: 8.92 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10943127202720289		[learning rate: 0.002256]
	Learning Rate: 0.00225597
	LOSS [training: 0.10943127202720289 | validation: 0.3185427064818651]
	TIME [epoch: 8.92 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11811150706121722		[learning rate: 0.0022453]
	Learning Rate: 0.00224534
	LOSS [training: 0.11811150706121722 | validation: 0.36740414235005725]
	TIME [epoch: 8.93 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11356486868479673		[learning rate: 0.0022348]
	Learning Rate: 0.00223476
	LOSS [training: 0.11356486868479673 | validation: 0.31112245876279737]
	TIME [epoch: 8.92 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13838391728817562		[learning rate: 0.0022242]
	Learning Rate: 0.00222423
	LOSS [training: 0.13838391728817562 | validation: 0.30793244469007336]
	TIME [epoch: 8.92 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1356359131302289		[learning rate: 0.0022137]
	Learning Rate: 0.00221375
	LOSS [training: 0.1356359131302289 | validation: 0.32428321465445725]
	TIME [epoch: 8.92 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1269078524587665		[learning rate: 0.0022033]
	Learning Rate: 0.00220332
	LOSS [training: 0.1269078524587665 | validation: 0.4152201834356993]
	TIME [epoch: 8.93 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12633061066722287		[learning rate: 0.0021929]
	Learning Rate: 0.00219293
	LOSS [training: 0.12633061066722287 | validation: 0.28720201768236353]
	TIME [epoch: 8.93 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11699203596255182		[learning rate: 0.0021826]
	Learning Rate: 0.0021826
	LOSS [training: 0.11699203596255182 | validation: 0.34406093775318597]
	TIME [epoch: 8.92 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10775078977517873		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.10775078977517873 | validation: 0.30460215556826326]
	TIME [epoch: 8.92 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12951823591465042		[learning rate: 0.0021621]
	Learning Rate: 0.00216208
	LOSS [training: 0.12951823591465042 | validation: 0.29633607090348685]
	TIME [epoch: 8.92 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11743467511058867		[learning rate: 0.0021519]
	Learning Rate: 0.00215189
	LOSS [training: 0.11743467511058867 | validation: 0.321531775122667]
	TIME [epoch: 8.93 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13401395015980455		[learning rate: 0.0021418]
	Learning Rate: 0.00214175
	LOSS [training: 0.13401395015980455 | validation: 0.33472681922584574]
	TIME [epoch: 8.91 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12942961263617112		[learning rate: 0.0021317]
	Learning Rate: 0.00213166
	LOSS [training: 0.12942961263617112 | validation: 0.3419684742116397]
	TIME [epoch: 8.91 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13053165116609125		[learning rate: 0.0021216]
	Learning Rate: 0.00212162
	LOSS [training: 0.13053165116609125 | validation: 0.2999849028856267]
	TIME [epoch: 8.91 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12195152858263109		[learning rate: 0.0021116]
	Learning Rate: 0.00211162
	LOSS [training: 0.12195152858263109 | validation: 0.3223404026927309]
	TIME [epoch: 8.91 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12564887195262048		[learning rate: 0.0021017]
	Learning Rate: 0.00210167
	LOSS [training: 0.12564887195262048 | validation: 0.31460165707525795]
	TIME [epoch: 8.91 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11509786559643824		[learning rate: 0.0020918]
	Learning Rate: 0.00209176
	LOSS [training: 0.11509786559643824 | validation: 0.3440905580038508]
	TIME [epoch: 8.91 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13790319873712298		[learning rate: 0.0020819]
	Learning Rate: 0.00208191
	LOSS [training: 0.13790319873712298 | validation: 0.30940373458503145]
	TIME [epoch: 8.92 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11052145110867559		[learning rate: 0.0020721]
	Learning Rate: 0.0020721
	LOSS [training: 0.11052145110867559 | validation: 0.30166039138919004]
	TIME [epoch: 8.91 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11467080067389754		[learning rate: 0.0020623]
	Learning Rate: 0.00206233
	LOSS [training: 0.11467080067389754 | validation: 0.3096537716723854]
	TIME [epoch: 8.91 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13059419940902478		[learning rate: 0.0020526]
	Learning Rate: 0.00205262
	LOSS [training: 0.13059419940902478 | validation: 0.29439360541557624]
	TIME [epoch: 8.91 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11253144630976501		[learning rate: 0.0020429]
	Learning Rate: 0.00204294
	LOSS [training: 0.11253144630976501 | validation: 0.31609073519273045]
	TIME [epoch: 8.91 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11498412853324484		[learning rate: 0.0020333]
	Learning Rate: 0.00203332
	LOSS [training: 0.11498412853324484 | validation: 0.30755315853564735]
	TIME [epoch: 8.92 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1323477773417535		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.1323477773417535 | validation: 0.284495199468216]
	TIME [epoch: 8.91 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11766006849719245		[learning rate: 0.0020142]
	Learning Rate: 0.0020142
	LOSS [training: 0.11766006849719245 | validation: 0.316444959834234]
	TIME [epoch: 8.91 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1118367320750439		[learning rate: 0.0020047]
	Learning Rate: 0.00200471
	LOSS [training: 0.1118367320750439 | validation: 0.29929529458788146]
	TIME [epoch: 8.91 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11260146283213432		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.11260146283213432 | validation: 0.31521581706004037]
	TIME [epoch: 8.92 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11985460580023749		[learning rate: 0.0019859]
	Learning Rate: 0.00198586
	LOSS [training: 0.11985460580023749 | validation: 0.3031093280078206]
	TIME [epoch: 8.91 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11119930145809358		[learning rate: 0.0019765]
	Learning Rate: 0.0019765
	LOSS [training: 0.11119930145809358 | validation: 0.3332440933377307]
	TIME [epoch: 8.92 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12182320420538387		[learning rate: 0.0019672]
	Learning Rate: 0.00196719
	LOSS [training: 0.12182320420538387 | validation: 0.30737052514355157]
	TIME [epoch: 8.92 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14109440854475555		[learning rate: 0.0019579]
	Learning Rate: 0.00195792
	LOSS [training: 0.14109440854475555 | validation: 0.3294169969963353]
	TIME [epoch: 8.92 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13748009792795546		[learning rate: 0.0019487]
	Learning Rate: 0.00194869
	LOSS [training: 0.13748009792795546 | validation: 0.3052861411261455]
	TIME [epoch: 8.91 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11530245693547428		[learning rate: 0.0019395]
	Learning Rate: 0.00193951
	LOSS [training: 0.11530245693547428 | validation: 0.30290788003621966]
	TIME [epoch: 8.91 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1167767215836053		[learning rate: 0.0019304]
	Learning Rate: 0.00193037
	LOSS [training: 0.1167767215836053 | validation: 0.31917242128362594]
	TIME [epoch: 8.91 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13206630224772137		[learning rate: 0.0019213]
	Learning Rate: 0.00192128
	LOSS [training: 0.13206630224772137 | validation: 0.31065036762338394]
	TIME [epoch: 8.93 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1342616030582195		[learning rate: 0.0019122]
	Learning Rate: 0.00191222
	LOSS [training: 0.1342616030582195 | validation: 0.3300205968253355]
	TIME [epoch: 8.9 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1219022810233659		[learning rate: 0.0019032]
	Learning Rate: 0.00190321
	LOSS [training: 0.1219022810233659 | validation: 0.30840744493508504]
	TIME [epoch: 8.92 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11347520876901261		[learning rate: 0.0018942]
	Learning Rate: 0.00189424
	LOSS [training: 0.11347520876901261 | validation: 0.2938750539889443]
	TIME [epoch: 8.9 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13358696925107832		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.13358696925107832 | validation: 0.30091297696796715]
	TIME [epoch: 8.92 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13144324877396624		[learning rate: 0.0018764]
	Learning Rate: 0.00187643
	LOSS [training: 0.13144324877396624 | validation: 0.30911515312907717]
	TIME [epoch: 8.9 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11196741659327451		[learning rate: 0.0018676]
	Learning Rate: 0.00186759
	LOSS [training: 0.11196741659327451 | validation: 0.3071930538888046]
	TIME [epoch: 8.91 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11609657538835738		[learning rate: 0.0018588]
	Learning Rate: 0.00185879
	LOSS [training: 0.11609657538835738 | validation: 0.3055321169239925]
	TIME [epoch: 8.9 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12810322935579915		[learning rate: 0.00185]
	Learning Rate: 0.00185003
	LOSS [training: 0.12810322935579915 | validation: 0.30567194596239017]
	TIME [epoch: 8.92 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11433372033277163		[learning rate: 0.0018413]
	Learning Rate: 0.00184132
	LOSS [training: 0.11433372033277163 | validation: 0.42024024116809167]
	TIME [epoch: 8.92 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1241142114309342		[learning rate: 0.0018326]
	Learning Rate: 0.00183264
	LOSS [training: 0.1241142114309342 | validation: 0.28410854929986784]
	TIME [epoch: 8.91 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10688125142766813		[learning rate: 0.001824]
	Learning Rate: 0.001824
	LOSS [training: 0.10688125142766813 | validation: 0.3247699605185836]
	TIME [epoch: 8.92 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11322136716410791		[learning rate: 0.0018154]
	Learning Rate: 0.00181541
	LOSS [training: 0.11322136716410791 | validation: 0.283995563975059]
	TIME [epoch: 8.91 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11771003078358631		[learning rate: 0.0018069]
	Learning Rate: 0.00180685
	LOSS [training: 0.11771003078358631 | validation: 0.32174695225091793]
	TIME [epoch: 8.92 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12099992064780296		[learning rate: 0.0017983]
	Learning Rate: 0.00179834
	LOSS [training: 0.12099992064780296 | validation: 0.30661902376171274]
	TIME [epoch: 8.9 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.105339069537401		[learning rate: 0.0017899]
	Learning Rate: 0.00178987
	LOSS [training: 0.105339069537401 | validation: 0.3066885731572075]
	TIME [epoch: 8.9 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11767378290695617		[learning rate: 0.0017814]
	Learning Rate: 0.00178143
	LOSS [training: 0.11767378290695617 | validation: 0.30613731485147117]
	TIME [epoch: 8.91 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12126259733447274		[learning rate: 0.001773]
	Learning Rate: 0.00177304
	LOSS [training: 0.12126259733447274 | validation: 0.30417848647406487]
	TIME [epoch: 8.91 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11077102632732584		[learning rate: 0.0017647]
	Learning Rate: 0.00176468
	LOSS [training: 0.11077102632732584 | validation: 0.30161201777881164]
	TIME [epoch: 8.9 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11260024116981895		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.11260024116981895 | validation: 0.30076041748829624]
	TIME [epoch: 8.91 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12801960766278003		[learning rate: 0.0017481]
	Learning Rate: 0.00174809
	LOSS [training: 0.12801960766278003 | validation: 0.3015634029074541]
	TIME [epoch: 8.92 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13719017779052697		[learning rate: 0.0017399]
	Learning Rate: 0.00173985
	LOSS [training: 0.13719017779052697 | validation: 0.30990977144946824]
	TIME [epoch: 8.92 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11638064162929755		[learning rate: 0.0017317]
	Learning Rate: 0.00173166
	LOSS [training: 0.11638064162929755 | validation: 0.2914454764780233]
	TIME [epoch: 8.91 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12742621301555393		[learning rate: 0.0017235]
	Learning Rate: 0.0017235
	LOSS [training: 0.12742621301555393 | validation: 0.3339995675898182]
	TIME [epoch: 8.9 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11359781180755638		[learning rate: 0.0017154]
	Learning Rate: 0.00171537
	LOSS [training: 0.11359781180755638 | validation: 0.3233252403706386]
	TIME [epoch: 8.9 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11984912323063018		[learning rate: 0.0017073]
	Learning Rate: 0.00170729
	LOSS [training: 0.11984912323063018 | validation: 0.30541456030777986]
	TIME [epoch: 8.9 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12530659164858138		[learning rate: 0.0016992]
	Learning Rate: 0.00169925
	LOSS [training: 0.12530659164858138 | validation: 0.3072837507909722]
	TIME [epoch: 8.91 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11914432638886704		[learning rate: 0.0016912]
	Learning Rate: 0.00169124
	LOSS [training: 0.11914432638886704 | validation: 0.2937785812850689]
	TIME [epoch: 8.92 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11800846370198743		[learning rate: 0.0016833]
	Learning Rate: 0.00168327
	LOSS [training: 0.11800846370198743 | validation: 0.322880438690896]
	TIME [epoch: 8.9 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1086494779413839		[learning rate: 0.0016753]
	Learning Rate: 0.00167534
	LOSS [training: 0.1086494779413839 | validation: 0.3260959704278103]
	TIME [epoch: 8.93 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1278625985258362		[learning rate: 0.0016674]
	Learning Rate: 0.00166744
	LOSS [training: 0.1278625985258362 | validation: 0.303214785286838]
	TIME [epoch: 8.91 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11771647495143985		[learning rate: 0.0016596]
	Learning Rate: 0.00165959
	LOSS [training: 0.11771647495143985 | validation: 0.3137561472185324]
	TIME [epoch: 8.9 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12176137101871091		[learning rate: 0.0016518]
	Learning Rate: 0.00165177
	LOSS [training: 0.12176137101871091 | validation: 0.3052893999067603]
	TIME [epoch: 8.93 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11306512820528439		[learning rate: 0.001644]
	Learning Rate: 0.00164398
	LOSS [training: 0.11306512820528439 | validation: 0.3307341959781123]
	TIME [epoch: 8.92 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12869032041757142		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.12869032041757142 | validation: 0.31051722741382387]
	TIME [epoch: 8.92 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12019916032078251		[learning rate: 0.0016285]
	Learning Rate: 0.00162853
	LOSS [training: 0.12019916032078251 | validation: 0.3123963175738323]
	TIME [epoch: 8.91 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1270808205707609		[learning rate: 0.0016209]
	Learning Rate: 0.00162085
	LOSS [training: 0.1270808205707609 | validation: 0.3027697044657121]
	TIME [epoch: 8.91 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11953304533972309		[learning rate: 0.0016132]
	Learning Rate: 0.00161322
	LOSS [training: 0.11953304533972309 | validation: 0.29280067537539317]
	TIME [epoch: 8.91 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11123677091898951		[learning rate: 0.0016056]
	Learning Rate: 0.00160561
	LOSS [training: 0.11123677091898951 | validation: 0.31026975674282314]
	TIME [epoch: 8.92 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1191722801959499		[learning rate: 0.001598]
	Learning Rate: 0.00159805
	LOSS [training: 0.1191722801959499 | validation: 0.3169832692828545]
	TIME [epoch: 8.91 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1232077771650168		[learning rate: 0.0015905]
	Learning Rate: 0.00159052
	LOSS [training: 0.1232077771650168 | validation: 0.31365086302757583]
	TIME [epoch: 8.91 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11850472701095148		[learning rate: 0.001583]
	Learning Rate: 0.00158302
	LOSS [training: 0.11850472701095148 | validation: 0.3010320346965005]
	TIME [epoch: 8.93 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1153009425675665		[learning rate: 0.0015756]
	Learning Rate: 0.00157556
	LOSS [training: 0.1153009425675665 | validation: 0.3127186642284859]
	TIME [epoch: 8.92 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12146721583117363		[learning rate: 0.0015681]
	Learning Rate: 0.00156814
	LOSS [training: 0.12146721583117363 | validation: 0.29300191299644024]
	TIME [epoch: 8.91 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12854082429841474		[learning rate: 0.0015607]
	Learning Rate: 0.00156075
	LOSS [training: 0.12854082429841474 | validation: 0.305591621562122]
	TIME [epoch: 8.9 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11267100455017907		[learning rate: 0.0015534]
	Learning Rate: 0.0015534
	LOSS [training: 0.11267100455017907 | validation: 0.348889714465268]
	TIME [epoch: 8.92 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13324119829258435		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.13324119829258435 | validation: 0.3038232548878391]
	TIME [epoch: 8.92 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1218387451958037		[learning rate: 0.0015388]
	Learning Rate: 0.00153879
	LOSS [training: 0.1218387451958037 | validation: 0.34148940556962126]
	TIME [epoch: 8.9 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11425676796809038		[learning rate: 0.0015315]
	Learning Rate: 0.00153154
	LOSS [training: 0.11425676796809038 | validation: 0.3248354149994552]
	TIME [epoch: 8.91 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12762941876715705		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.12762941876715705 | validation: 0.298422520050743]
	TIME [epoch: 8.91 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12076707004867349		[learning rate: 0.0015171]
	Learning Rate: 0.00151714
	LOSS [training: 0.12076707004867349 | validation: 0.2899136507451948]
	TIME [epoch: 8.92 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11228313925060324		[learning rate: 0.00151]
	Learning Rate: 0.00150999
	LOSS [training: 0.11228313925060324 | validation: 0.33599844388127165]
	TIME [epoch: 8.91 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1326925202975653		[learning rate: 0.0015029]
	Learning Rate: 0.00150288
	LOSS [training: 0.1326925202975653 | validation: 0.28701592176534085]
	TIME [epoch: 8.91 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12108857795415706		[learning rate: 0.0014958]
	Learning Rate: 0.00149579
	LOSS [training: 0.12108857795415706 | validation: 0.30786707422426884]
	TIME [epoch: 8.92 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11348492055108081		[learning rate: 0.0014887]
	Learning Rate: 0.00148875
	LOSS [training: 0.11348492055108081 | validation: 0.30746647659233733]
	TIME [epoch: 8.9 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10812768586228926		[learning rate: 0.0014817]
	Learning Rate: 0.00148173
	LOSS [training: 0.10812768586228926 | validation: 0.28916045059782103]
	TIME [epoch: 8.91 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.119859875118811		[learning rate: 0.0014747]
	Learning Rate: 0.00147475
	LOSS [training: 0.119859875118811 | validation: 0.3154930738157369]
	TIME [epoch: 8.91 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12388914641728166		[learning rate: 0.0014678]
	Learning Rate: 0.0014678
	LOSS [training: 0.12388914641728166 | validation: 0.3121500328967612]
	TIME [epoch: 8.91 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10999623567409078		[learning rate: 0.0014609]
	Learning Rate: 0.00146088
	LOSS [training: 0.10999623567409078 | validation: 0.29869604091777796]
	TIME [epoch: 8.91 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11992278619516533		[learning rate: 0.001454]
	Learning Rate: 0.001454
	LOSS [training: 0.11992278619516533 | validation: 0.31833985907904694]
	TIME [epoch: 8.9 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11501374190948549		[learning rate: 0.0014471]
	Learning Rate: 0.00144715
	LOSS [training: 0.11501374190948549 | validation: 0.31146735068596476]
	TIME [epoch: 8.9 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12893988876717954		[learning rate: 0.0014403]
	Learning Rate: 0.00144033
	LOSS [training: 0.12893988876717954 | validation: 0.3244642799320623]
	TIME [epoch: 8.92 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11726673057897721		[learning rate: 0.0014335]
	Learning Rate: 0.00143354
	LOSS [training: 0.11726673057897721 | validation: 0.30544746233066317]
	TIME [epoch: 8.91 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11334298367061618		[learning rate: 0.0014268]
	Learning Rate: 0.00142679
	LOSS [training: 0.11334298367061618 | validation: 0.28681242574633353]
	TIME [epoch: 8.92 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1246537145660026		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.1246537145660026 | validation: 0.2904699899601427]
	TIME [epoch: 8.91 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11022244998324363		[learning rate: 0.0014134]
	Learning Rate: 0.00141337
	LOSS [training: 0.11022244998324363 | validation: 0.31377300264861974]
	TIME [epoch: 8.92 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13738814110821634		[learning rate: 0.0014067]
	Learning Rate: 0.00140671
	LOSS [training: 0.13738814110821634 | validation: 0.28583512995552063]
	TIME [epoch: 8.9 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10800337279045806		[learning rate: 0.0014001]
	Learning Rate: 0.00140008
	LOSS [training: 0.10800337279045806 | validation: 0.3154562449307659]
	TIME [epoch: 8.91 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11501053552262938		[learning rate: 0.0013935]
	Learning Rate: 0.00139349
	LOSS [training: 0.11501053552262938 | validation: 0.2928774494266955]
	TIME [epoch: 8.89 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12894087659233716		[learning rate: 0.0013869]
	Learning Rate: 0.00138692
	LOSS [training: 0.12894087659233716 | validation: 0.31564283185866115]
	TIME [epoch: 8.92 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1256733187579389		[learning rate: 0.0013804]
	Learning Rate: 0.00138038
	LOSS [training: 0.1256733187579389 | validation: 0.2998032295611261]
	TIME [epoch: 8.91 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11015078775383341		[learning rate: 0.0013739]
	Learning Rate: 0.00137388
	LOSS [training: 0.11015078775383341 | validation: 0.31504159119646175]
	TIME [epoch: 8.92 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11719003191655736		[learning rate: 0.0013674]
	Learning Rate: 0.00136741
	LOSS [training: 0.11719003191655736 | validation: 0.2925913327601154]
	TIME [epoch: 8.91 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11903681454174331		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.11903681454174331 | validation: 0.30655990899885877]
	TIME [epoch: 8.92 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1151575253695915		[learning rate: 0.0013545]
	Learning Rate: 0.00135455
	LOSS [training: 0.1151575253695915 | validation: 0.28796829394181717]
	TIME [epoch: 8.92 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12931920042368134		[learning rate: 0.0013482]
	Learning Rate: 0.00134817
	LOSS [training: 0.12931920042368134 | validation: 0.30868048075203364]
	TIME [epoch: 8.9 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1171161059033046		[learning rate: 0.0013418]
	Learning Rate: 0.00134181
	LOSS [training: 0.1171161059033046 | validation: 0.29360451825931816]
	TIME [epoch: 8.92 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12738966165093701		[learning rate: 0.0013355]
	Learning Rate: 0.00133549
	LOSS [training: 0.12738966165093701 | validation: 0.3166957156954573]
	TIME [epoch: 8.91 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11391571173365853		[learning rate: 0.0013292]
	Learning Rate: 0.0013292
	LOSS [training: 0.11391571173365853 | validation: 0.3004203674495291]
	TIME [epoch: 8.92 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11925937671574252		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.11925937671574252 | validation: 0.28147867210809074]
	TIME [epoch: 8.91 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_466.pth
	Model improved!!!
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11851697240479489		[learning rate: 0.0013167]
	Learning Rate: 0.0013167
	LOSS [training: 0.11851697240479489 | validation: 0.3083745399718301]
	TIME [epoch: 8.91 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13269155869594368		[learning rate: 0.0013105]
	Learning Rate: 0.0013105
	LOSS [training: 0.13269155869594368 | validation: 0.2865951763971548]
	TIME [epoch: 8.91 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11563928061691087		[learning rate: 0.0013043]
	Learning Rate: 0.00130432
	LOSS [training: 0.11563928061691087 | validation: 0.323199674054644]
	TIME [epoch: 8.93 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11247097491528288		[learning rate: 0.0012982]
	Learning Rate: 0.00129818
	LOSS [training: 0.11247097491528288 | validation: 0.30257609931987145]
	TIME [epoch: 8.91 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11358527131019208		[learning rate: 0.0012921]
	Learning Rate: 0.00129206
	LOSS [training: 0.11358527131019208 | validation: 0.30484359014084395]
	TIME [epoch: 8.91 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12207782059593096		[learning rate: 0.001286]
	Learning Rate: 0.00128597
	LOSS [training: 0.12207782059593096 | validation: 0.31959436269770397]
	TIME [epoch: 8.9 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11932373858257618		[learning rate: 0.0012799]
	Learning Rate: 0.00127991
	LOSS [training: 0.11932373858257618 | validation: 0.2926956035738555]
	TIME [epoch: 8.92 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10902138667739109		[learning rate: 0.0012739]
	Learning Rate: 0.00127388
	LOSS [training: 0.10902138667739109 | validation: 0.306382816398512]
	TIME [epoch: 8.91 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10522181023994727		[learning rate: 0.0012679]
	Learning Rate: 0.00126788
	LOSS [training: 0.10522181023994727 | validation: 0.30494656565245903]
	TIME [epoch: 8.91 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11804339551427821		[learning rate: 0.0012619]
	Learning Rate: 0.0012619
	LOSS [training: 0.11804339551427821 | validation: 0.3071131204644311]
	TIME [epoch: 8.91 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11363752966232651		[learning rate: 0.001256]
	Learning Rate: 0.00125596
	LOSS [training: 0.11363752966232651 | validation: 0.3046003387959269]
	TIME [epoch: 8.93 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10920941640956018		[learning rate: 0.00125]
	Learning Rate: 0.00125004
	LOSS [training: 0.10920941640956018 | validation: 0.3053826168106819]
	TIME [epoch: 8.91 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12630460462366822		[learning rate: 0.0012441]
	Learning Rate: 0.00124415
	LOSS [training: 0.12630460462366822 | validation: 0.3051616094371378]
	TIME [epoch: 8.91 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12671899697593392		[learning rate: 0.0012383]
	Learning Rate: 0.00123828
	LOSS [training: 0.12671899697593392 | validation: 0.3050739264936207]
	TIME [epoch: 8.91 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11680899154226612		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.11680899154226612 | validation: 0.32340538406012903]
	TIME [epoch: 8.92 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12138679805545796		[learning rate: 0.0012266]
	Learning Rate: 0.00122664
	LOSS [training: 0.12138679805545796 | validation: 0.30382623749723414]
	TIME [epoch: 8.91 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1270671535676372		[learning rate: 0.0012209]
	Learning Rate: 0.00122086
	LOSS [training: 0.1270671535676372 | validation: 0.29301015893084437]
	TIME [epoch: 8.91 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1110179726177834		[learning rate: 0.0012151]
	Learning Rate: 0.00121511
	LOSS [training: 0.1110179726177834 | validation: 0.3096954724337544]
	TIME [epoch: 8.91 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12130158656328455		[learning rate: 0.0012094]
	Learning Rate: 0.00120938
	LOSS [training: 0.12130158656328455 | validation: 0.2992537742287785]
	TIME [epoch: 8.93 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12084479073159511		[learning rate: 0.0012037]
	Learning Rate: 0.00120368
	LOSS [training: 0.12084479073159511 | validation: 0.3121305185077243]
	TIME [epoch: 8.91 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12413931963913355		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.12413931963913355 | validation: 0.2931655616240901]
	TIME [epoch: 8.91 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.115320067407675		[learning rate: 0.0011924]
	Learning Rate: 0.00119237
	LOSS [training: 0.115320067407675 | validation: 0.32005381394281224]
	TIME [epoch: 8.91 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10445854082584125		[learning rate: 0.0011867]
	Learning Rate: 0.00118675
	LOSS [training: 0.10445854082584125 | validation: 0.29724389916380395]
	TIME [epoch: 8.92 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1268776866306379		[learning rate: 0.0011812]
	Learning Rate: 0.00118116
	LOSS [training: 0.1268776866306379 | validation: 0.2924982792158941]
	TIME [epoch: 8.92 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11821532333251009		[learning rate: 0.0011756]
	Learning Rate: 0.00117559
	LOSS [training: 0.11821532333251009 | validation: 0.31285197163460265]
	TIME [epoch: 8.91 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12329950143777546		[learning rate: 0.0011701]
	Learning Rate: 0.00117005
	LOSS [training: 0.12329950143777546 | validation: 0.29665271223056044]
	TIME [epoch: 8.91 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09921470180968311		[learning rate: 0.0011645]
	Learning Rate: 0.00116454
	LOSS [training: 0.09921470180968311 | validation: 0.2860784125482278]
	TIME [epoch: 8.92 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12047129589109581		[learning rate: 0.0011591]
	Learning Rate: 0.00115905
	LOSS [training: 0.12047129589109581 | validation: 0.2985274041097416]
	TIME [epoch: 8.92 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10660760031795674		[learning rate: 0.0011536]
	Learning Rate: 0.00115359
	LOSS [training: 0.10660760031795674 | validation: 0.32102525246749936]
	TIME [epoch: 8.91 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11140579604555562		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.11140579604555562 | validation: 0.2949042699267963]
	TIME [epoch: 8.94 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10849692916809041		[learning rate: 0.0011427]
	Learning Rate: 0.00114274
	LOSS [training: 0.10849692916809041 | validation: 0.30414356036432044]
	TIME [epoch: 8.92 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1173685498591342		[learning rate: 0.0011374]
	Learning Rate: 0.00113736
	LOSS [training: 0.1173685498591342 | validation: 0.3008322512302442]
	TIME [epoch: 8.92 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11355289184419227		[learning rate: 0.001132]
	Learning Rate: 0.001132
	LOSS [training: 0.11355289184419227 | validation: 0.2990134718557788]
	TIME [epoch: 8.91 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11197510760466033		[learning rate: 0.0011267]
	Learning Rate: 0.00112667
	LOSS [training: 0.11197510760466033 | validation: 0.2908918521011142]
	TIME [epoch: 8.91 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1283850730070839		[learning rate: 0.0011214]
	Learning Rate: 0.00112136
	LOSS [training: 0.1283850730070839 | validation: 0.2882352810070141]
	TIME [epoch: 45 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10975020618151951		[learning rate: 0.0011161]
	Learning Rate: 0.00111607
	LOSS [training: 0.10975020618151951 | validation: 0.3133019728100644]
	TIME [epoch: 19.2 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10719515589340592		[learning rate: 0.0011108]
	Learning Rate: 0.00111081
	LOSS [training: 0.10719515589340592 | validation: 0.2928115442588315]
	TIME [epoch: 19.3 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10835720507935052		[learning rate: 0.0011056]
	Learning Rate: 0.00110558
	LOSS [training: 0.10835720507935052 | validation: 0.30158778503471856]
	TIME [epoch: 19.2 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13844449001470208		[learning rate: 0.0011004]
	Learning Rate: 0.00110037
	LOSS [training: 0.13844449001470208 | validation: 0.3087668808925973]
	TIME [epoch: 19.2 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13149844064879673		[learning rate: 0.0010952]
	Learning Rate: 0.00109518
	LOSS [training: 0.13149844064879673 | validation: 0.28736300893016753]
	TIME [epoch: 19.2 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12280803005541185		[learning rate: 0.00109]
	Learning Rate: 0.00109002
	LOSS [training: 0.12280803005541185 | validation: 0.33247137201798405]
	TIME [epoch: 19.2 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11701187212752717		[learning rate: 0.0010849]
	Learning Rate: 0.00108489
	LOSS [training: 0.11701187212752717 | validation: 0.28987074032124116]
	TIME [epoch: 19.2 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10941290116177542		[learning rate: 0.0010798]
	Learning Rate: 0.00107978
	LOSS [training: 0.10941290116177542 | validation: 0.29716576748367]
	TIME [epoch: 19.2 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12003261389979897		[learning rate: 0.0010747]
	Learning Rate: 0.00107469
	LOSS [training: 0.12003261389979897 | validation: 0.28439332798707206]
	TIME [epoch: 19.2 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12016887264526913		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.12016887264526913 | validation: 0.30379330290911594]
	TIME [epoch: 19.2 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1134119736055897		[learning rate: 0.0010646]
	Learning Rate: 0.00106458
	LOSS [training: 0.1134119736055897 | validation: 0.294520788486253]
	TIME [epoch: 19.2 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11084581595139026		[learning rate: 0.0010596]
	Learning Rate: 0.00105957
	LOSS [training: 0.11084581595139026 | validation: 0.2914160686980749]
	TIME [epoch: 19.2 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10583562459543013		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.10583562459543013 | validation: 0.2985144848421975]
	TIME [epoch: 19.2 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12989671794885294		[learning rate: 0.0010496]
	Learning Rate: 0.0010496
	LOSS [training: 0.12989671794885294 | validation: 0.29961822603584276]
	TIME [epoch: 19.2 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11790404437295536		[learning rate: 0.0010447]
	Learning Rate: 0.00104466
	LOSS [training: 0.11790404437295536 | validation: 0.31330265636552995]
	TIME [epoch: 19.2 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1097595628064739		[learning rate: 0.0010397]
	Learning Rate: 0.00103974
	LOSS [training: 0.1097595628064739 | validation: 0.3178793175728205]
	TIME [epoch: 19.2 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11088163847650505		[learning rate: 0.0010348]
	Learning Rate: 0.00103484
	LOSS [training: 0.11088163847650505 | validation: 0.3019376231511786]
	TIME [epoch: 19.2 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11719745723733413		[learning rate: 0.00103]
	Learning Rate: 0.00102996
	LOSS [training: 0.11719745723733413 | validation: 0.3098974457325737]
	TIME [epoch: 19.2 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11759509009422103		[learning rate: 0.0010251]
	Learning Rate: 0.00102511
	LOSS [training: 0.11759509009422103 | validation: 0.29768123037975625]
	TIME [epoch: 19.2 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11195870365364305		[learning rate: 0.0010203]
	Learning Rate: 0.00102028
	LOSS [training: 0.11195870365364305 | validation: 0.2957922099224325]
	TIME [epoch: 19.2 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10829037436476788		[learning rate: 0.0010155]
	Learning Rate: 0.00101547
	LOSS [training: 0.10829037436476788 | validation: 0.3052964965164247]
	TIME [epoch: 19.2 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1142753164705119		[learning rate: 0.0010107]
	Learning Rate: 0.00101068
	LOSS [training: 0.1142753164705119 | validation: 0.2961449843953123]
	TIME [epoch: 19.2 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11677974367642058		[learning rate: 0.0010059]
	Learning Rate: 0.00100592
	LOSS [training: 0.11677974367642058 | validation: 0.2847589334563251]
	TIME [epoch: 19.2 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11654513654789067		[learning rate: 0.0010012]
	Learning Rate: 0.00100118
	LOSS [training: 0.11654513654789067 | validation: 0.3043252823033171]
	TIME [epoch: 19.2 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11589729650206196		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.11589729650206196 | validation: 0.3255996107482269]
	TIME [epoch: 19.2 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1169659139506651		[learning rate: 0.00099177]
	Learning Rate: 0.000991768
	LOSS [training: 0.1169659139506651 | validation: 0.28692943388415204]
	TIME [epoch: 19.2 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.111609544362221		[learning rate: 0.0009871]
	Learning Rate: 0.000987095
	LOSS [training: 0.111609544362221 | validation: 0.3054645415359877]
	TIME [epoch: 19.2 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11010991732398877		[learning rate: 0.00098244]
	Learning Rate: 0.000982444
	LOSS [training: 0.11010991732398877 | validation: 0.2976004388782113]
	TIME [epoch: 19.2 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11485466786204739		[learning rate: 0.00097781]
	Learning Rate: 0.000977814
	LOSS [training: 0.11485466786204739 | validation: 0.29292382530172545]
	TIME [epoch: 19.2 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10479096011236322		[learning rate: 0.00097321]
	Learning Rate: 0.000973207
	LOSS [training: 0.10479096011236322 | validation: 0.2942902950656539]
	TIME [epoch: 19.2 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10259117349002392		[learning rate: 0.00096862]
	Learning Rate: 0.000968621
	LOSS [training: 0.10259117349002392 | validation: 0.2907755923007346]
	TIME [epoch: 19.2 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11069937626398935		[learning rate: 0.00096406]
	Learning Rate: 0.000964057
	LOSS [training: 0.11069937626398935 | validation: 0.3135186294565833]
	TIME [epoch: 19.2 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10730921982496197		[learning rate: 0.00095951]
	Learning Rate: 0.000959514
	LOSS [training: 0.10730921982496197 | validation: 0.2974052851411539]
	TIME [epoch: 19.2 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11037090541264957		[learning rate: 0.00095499]
	Learning Rate: 0.000954993
	LOSS [training: 0.11037090541264957 | validation: 0.2966037027004632]
	TIME [epoch: 19.2 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12121642311795365		[learning rate: 0.00095049]
	Learning Rate: 0.000950493
	LOSS [training: 0.12121642311795365 | validation: 0.2889235732942365]
	TIME [epoch: 19.2 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1297107158032187		[learning rate: 0.00094601]
	Learning Rate: 0.000946014
	LOSS [training: 0.1297107158032187 | validation: 0.32819926604822947]
	TIME [epoch: 19.2 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11430820088339434		[learning rate: 0.00094156]
	Learning Rate: 0.000941556
	LOSS [training: 0.11430820088339434 | validation: 0.2979483790842245]
	TIME [epoch: 19.2 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1049611375241733		[learning rate: 0.00093712]
	Learning Rate: 0.000937119
	LOSS [training: 0.1049611375241733 | validation: 0.284081725978598]
	TIME [epoch: 19.2 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10075984946663176		[learning rate: 0.0009327]
	Learning Rate: 0.000932703
	LOSS [training: 0.10075984946663176 | validation: 0.3041902828467459]
	TIME [epoch: 19.2 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10339646985311146		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.10339646985311146 | validation: 0.3087991258636551]
	TIME [epoch: 19.2 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10540489850838307		[learning rate: 0.00092393]
	Learning Rate: 0.000923934
	LOSS [training: 0.10540489850838307 | validation: 0.30580925875640497]
	TIME [epoch: 19.2 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11252685164339207		[learning rate: 0.00091958]
	Learning Rate: 0.000919581
	LOSS [training: 0.11252685164339207 | validation: 0.3065003784114145]
	TIME [epoch: 19.2 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11452001521680165		[learning rate: 0.00091525]
	Learning Rate: 0.000915247
	LOSS [training: 0.11452001521680165 | validation: 0.2823084980350206]
	TIME [epoch: 19.2 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10868119911738522		[learning rate: 0.00091093]
	Learning Rate: 0.000910934
	LOSS [training: 0.10868119911738522 | validation: 0.3053380070859748]
	TIME [epoch: 19.2 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12463069761560393		[learning rate: 0.00090664]
	Learning Rate: 0.000906642
	LOSS [training: 0.12463069761560393 | validation: 0.3043708652152148]
	TIME [epoch: 19.2 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11169253759375405		[learning rate: 0.00090237]
	Learning Rate: 0.00090237
	LOSS [training: 0.11169253759375405 | validation: 0.2961533241082681]
	TIME [epoch: 19.2 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1072731998664482		[learning rate: 0.00089812]
	Learning Rate: 0.000898118
	LOSS [training: 0.1072731998664482 | validation: 0.3017254210496193]
	TIME [epoch: 19.2 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11539863358992775		[learning rate: 0.00089389]
	Learning Rate: 0.000893886
	LOSS [training: 0.11539863358992775 | validation: 0.30397730555099856]
	TIME [epoch: 19.2 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10510653746138399		[learning rate: 0.00088967]
	Learning Rate: 0.000889674
	LOSS [training: 0.10510653746138399 | validation: 0.2866385617158028]
	TIME [epoch: 19.2 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10883789016423916		[learning rate: 0.00088548]
	Learning Rate: 0.000885481
	LOSS [training: 0.10883789016423916 | validation: 0.3089703123218659]
	TIME [epoch: 19.2 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11746499275489487		[learning rate: 0.00088131]
	Learning Rate: 0.000881309
	LOSS [training: 0.11746499275489487 | validation: 0.2884186000893792]
	TIME [epoch: 19.2 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11072976252901585		[learning rate: 0.00087716]
	Learning Rate: 0.000877156
	LOSS [training: 0.11072976252901585 | validation: 0.29019582649142905]
	TIME [epoch: 19.2 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10813593520353965		[learning rate: 0.00087302]
	Learning Rate: 0.000873023
	LOSS [training: 0.10813593520353965 | validation: 0.3046613591137425]
	TIME [epoch: 19.2 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11592126530894828		[learning rate: 0.00086891]
	Learning Rate: 0.000868909
	LOSS [training: 0.11592126530894828 | validation: 0.29784757513084864]
	TIME [epoch: 19.2 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10785617240730812		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.10785617240730812 | validation: 0.2866109304983905]
	TIME [epoch: 19.2 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11385018720212006		[learning rate: 0.00086074]
	Learning Rate: 0.00086074
	LOSS [training: 0.11385018720212006 | validation: 0.2994522950217197]
	TIME [epoch: 19.2 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11013573534525249		[learning rate: 0.00085668]
	Learning Rate: 0.000856684
	LOSS [training: 0.11013573534525249 | validation: 0.30238028944666573]
	TIME [epoch: 19.2 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11872733021223005		[learning rate: 0.00085265]
	Learning Rate: 0.000852647
	LOSS [training: 0.11872733021223005 | validation: 0.2812299874152848]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_559.pth
	Model improved!!!
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11549949542962104		[learning rate: 0.00084863]
	Learning Rate: 0.000848629
	LOSS [training: 0.11549949542962104 | validation: 0.32035166714406127]
	TIME [epoch: 19.2 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12651457658754997		[learning rate: 0.00084463]
	Learning Rate: 0.00084463
	LOSS [training: 0.12651457658754997 | validation: 0.29438286913182576]
	TIME [epoch: 19.2 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10771900158130944		[learning rate: 0.00084065]
	Learning Rate: 0.00084065
	LOSS [training: 0.10771900158130944 | validation: 0.29259587763941036]
	TIME [epoch: 19.2 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11701731919951669		[learning rate: 0.00083669]
	Learning Rate: 0.000836689
	LOSS [training: 0.11701731919951669 | validation: 0.29242105834063714]
	TIME [epoch: 19.2 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11490813963385767		[learning rate: 0.00083275]
	Learning Rate: 0.000832746
	LOSS [training: 0.11490813963385767 | validation: 0.2804660545116519]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_564.pth
	Model improved!!!
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10585212200110423		[learning rate: 0.00082882]
	Learning Rate: 0.000828822
	LOSS [training: 0.10585212200110423 | validation: 0.2979420517124173]
	TIME [epoch: 19.2 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10451330941132071		[learning rate: 0.00082492]
	Learning Rate: 0.000824917
	LOSS [training: 0.10451330941132071 | validation: 0.3065478475370347]
	TIME [epoch: 19.2 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12094811511501642		[learning rate: 0.00082103]
	Learning Rate: 0.00082103
	LOSS [training: 0.12094811511501642 | validation: 0.2929494657072064]
	TIME [epoch: 19.2 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1204233781152445		[learning rate: 0.00081716]
	Learning Rate: 0.000817161
	LOSS [training: 0.1204233781152445 | validation: 0.2875077586873087]
	TIME [epoch: 19.2 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10910735567488866		[learning rate: 0.00081331]
	Learning Rate: 0.000813311
	LOSS [training: 0.10910735567488866 | validation: 0.2871740377646219]
	TIME [epoch: 19.2 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11085356541432075		[learning rate: 0.00080948]
	Learning Rate: 0.000809478
	LOSS [training: 0.11085356541432075 | validation: 0.2785219319685726]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_570.pth
	Model improved!!!
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10820558916304823		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.10820558916304823 | validation: 0.3237049618271504]
	TIME [epoch: 19.2 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11351743541782053		[learning rate: 0.00080187]
	Learning Rate: 0.000801868
	LOSS [training: 0.11351743541782053 | validation: 0.28565499877222217]
	TIME [epoch: 19.2 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11406389725964138		[learning rate: 0.00079809]
	Learning Rate: 0.000798089
	LOSS [training: 0.11406389725964138 | validation: 0.3136880837534747]
	TIME [epoch: 19.2 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11557968821503209		[learning rate: 0.00079433]
	Learning Rate: 0.000794328
	LOSS [training: 0.11557968821503209 | validation: 0.3140578738462959]
	TIME [epoch: 19.2 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11516654230576977		[learning rate: 0.00079059]
	Learning Rate: 0.000790585
	LOSS [training: 0.11516654230576977 | validation: 0.2930990324680891]
	TIME [epoch: 19.2 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10559744566701333		[learning rate: 0.00078686]
	Learning Rate: 0.00078686
	LOSS [training: 0.10559744566701333 | validation: 0.28620422718903504]
	TIME [epoch: 19.2 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11709588548539217		[learning rate: 0.00078315]
	Learning Rate: 0.000783152
	LOSS [training: 0.11709588548539217 | validation: 0.28233877788906003]
	TIME [epoch: 19.2 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10993458954378968		[learning rate: 0.00077946]
	Learning Rate: 0.000779462
	LOSS [training: 0.10993458954378968 | validation: 0.2878516577883898]
	TIME [epoch: 19.2 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11828034436391069		[learning rate: 0.00077579]
	Learning Rate: 0.000775789
	LOSS [training: 0.11828034436391069 | validation: 0.31408230163747314]
	TIME [epoch: 19.2 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11286669059557562		[learning rate: 0.00077213]
	Learning Rate: 0.000772133
	LOSS [training: 0.11286669059557562 | validation: 0.2951522172656711]
	TIME [epoch: 19.2 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09983043082289338		[learning rate: 0.00076849]
	Learning Rate: 0.000768495
	LOSS [training: 0.09983043082289338 | validation: 0.29427353544058704]
	TIME [epoch: 19.2 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12149521312821698		[learning rate: 0.00076487]
	Learning Rate: 0.000764874
	LOSS [training: 0.12149521312821698 | validation: 0.2739253452111676]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_582.pth
	Model improved!!!
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12289177573088389		[learning rate: 0.00076127]
	Learning Rate: 0.00076127
	LOSS [training: 0.12289177573088389 | validation: 0.29835937055326955]
	TIME [epoch: 19.2 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10366783587232256		[learning rate: 0.00075768]
	Learning Rate: 0.000757682
	LOSS [training: 0.10366783587232256 | validation: 0.311485991007362]
	TIME [epoch: 19.2 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11039755747315964		[learning rate: 0.00075411]
	Learning Rate: 0.000754112
	LOSS [training: 0.11039755747315964 | validation: 0.28911818134780853]
	TIME [epoch: 19.2 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11002572401611402		[learning rate: 0.00075056]
	Learning Rate: 0.000750559
	LOSS [training: 0.11002572401611402 | validation: 0.30205700525609624]
	TIME [epoch: 19.2 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10027688772647436		[learning rate: 0.00074702]
	Learning Rate: 0.000747022
	LOSS [training: 0.10027688772647436 | validation: 0.2981876472773622]
	TIME [epoch: 19.2 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10592335726593782		[learning rate: 0.0007435]
	Learning Rate: 0.000743502
	LOSS [training: 0.10592335726593782 | validation: 0.2872230769877927]
	TIME [epoch: 19.2 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11400119341732214		[learning rate: 0.00074]
	Learning Rate: 0.000739998
	LOSS [training: 0.11400119341732214 | validation: 0.2811546001878585]
	TIME [epoch: 19.2 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10335434874624955		[learning rate: 0.00073651]
	Learning Rate: 0.000736511
	LOSS [training: 0.10335434874624955 | validation: 0.2904758700248087]
	TIME [epoch: 19.2 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11448796443545006		[learning rate: 0.00073304]
	Learning Rate: 0.000733041
	LOSS [training: 0.11448796443545006 | validation: 0.30123106595978727]
	TIME [epoch: 19.2 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10318996204413121		[learning rate: 0.00072959]
	Learning Rate: 0.000729587
	LOSS [training: 0.10318996204413121 | validation: 0.2792148793556466]
	TIME [epoch: 19.2 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1116610107287208		[learning rate: 0.00072615]
	Learning Rate: 0.000726149
	LOSS [training: 0.1116610107287208 | validation: 0.30079037840875456]
	TIME [epoch: 19.2 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1050814350695318		[learning rate: 0.00072273]
	Learning Rate: 0.000722727
	LOSS [training: 0.1050814350695318 | validation: 0.3161542640756441]
	TIME [epoch: 19.2 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10935573931592535		[learning rate: 0.00071932]
	Learning Rate: 0.000719321
	LOSS [training: 0.10935573931592535 | validation: 0.28275107130672755]
	TIME [epoch: 19.2 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11711251842907369		[learning rate: 0.00071593]
	Learning Rate: 0.000715932
	LOSS [training: 0.11711251842907369 | validation: 0.29138044618326736]
	TIME [epoch: 19.2 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09429865505069124		[learning rate: 0.00071256]
	Learning Rate: 0.000712558
	LOSS [training: 0.09429865505069124 | validation: 0.29067124537490235]
	TIME [epoch: 19.2 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10216488026526283		[learning rate: 0.0007092]
	Learning Rate: 0.000709201
	LOSS [training: 0.10216488026526283 | validation: 0.29671627508645454]
	TIME [epoch: 19.2 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10426248653081771		[learning rate: 0.00070586]
	Learning Rate: 0.000705859
	LOSS [training: 0.10426248653081771 | validation: 0.30303235594636585]
	TIME [epoch: 19.2 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10156260563301966		[learning rate: 0.00070253]
	Learning Rate: 0.000702533
	LOSS [training: 0.10156260563301966 | validation: 0.2978364808972288]
	TIME [epoch: 19.2 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11590110201338907		[learning rate: 0.00069922]
	Learning Rate: 0.000699222
	LOSS [training: 0.11590110201338907 | validation: 0.28149566591705416]
	TIME [epoch: 19.2 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11047236894758411		[learning rate: 0.00069593]
	Learning Rate: 0.000695928
	LOSS [training: 0.11047236894758411 | validation: 0.28729833612383116]
	TIME [epoch: 19.2 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12007226149666878		[learning rate: 0.00069265]
	Learning Rate: 0.000692648
	LOSS [training: 0.12007226149666878 | validation: 0.2921919912678829]
	TIME [epoch: 19.2 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10713085626957893		[learning rate: 0.00068938]
	Learning Rate: 0.000689385
	LOSS [training: 0.10713085626957893 | validation: 0.2799033233451958]
	TIME [epoch: 19.2 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10936509814311564		[learning rate: 0.00068614]
	Learning Rate: 0.000686136
	LOSS [training: 0.10936509814311564 | validation: 0.279810228406435]
	TIME [epoch: 19.2 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11487407390786394		[learning rate: 0.0006829]
	Learning Rate: 0.000682903
	LOSS [training: 0.11487407390786394 | validation: 0.2845172566065615]
	TIME [epoch: 19.2 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11757222863291603		[learning rate: 0.00067969]
	Learning Rate: 0.000679685
	LOSS [training: 0.11757222863291603 | validation: 0.2920806261845631]
	TIME [epoch: 19.2 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1108606444173561		[learning rate: 0.00067648]
	Learning Rate: 0.000676482
	LOSS [training: 0.1108606444173561 | validation: 0.28400536549258876]
	TIME [epoch: 19.2 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11504968208562577		[learning rate: 0.00067329]
	Learning Rate: 0.000673295
	LOSS [training: 0.11504968208562577 | validation: 0.29304888042870236]
	TIME [epoch: 19.2 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10769672926455393		[learning rate: 0.00067012]
	Learning Rate: 0.000670122
	LOSS [training: 0.10769672926455393 | validation: 0.2971600238397034]
	TIME [epoch: 19.2 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10747987376444361		[learning rate: 0.00066696]
	Learning Rate: 0.000666964
	LOSS [training: 0.10747987376444361 | validation: 0.28407716476945993]
	TIME [epoch: 19.2 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10970797559816226		[learning rate: 0.00066382]
	Learning Rate: 0.000663821
	LOSS [training: 0.10970797559816226 | validation: 0.2954345823849284]
	TIME [epoch: 19.2 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10811603223832349		[learning rate: 0.00066069]
	Learning Rate: 0.000660694
	LOSS [training: 0.10811603223832349 | validation: 0.2716036950339946]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_613.pth
	Model improved!!!
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10802961649133372		[learning rate: 0.00065758]
	Learning Rate: 0.00065758
	LOSS [training: 0.10802961649133372 | validation: 0.28546556758767594]
	TIME [epoch: 19.1 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11005963037277688		[learning rate: 0.00065448]
	Learning Rate: 0.000654482
	LOSS [training: 0.11005963037277688 | validation: 0.2986871067808196]
	TIME [epoch: 19.1 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10331163494788592		[learning rate: 0.0006514]
	Learning Rate: 0.000651398
	LOSS [training: 0.10331163494788592 | validation: 0.28519473453387545]
	TIME [epoch: 19.2 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1307460462349121		[learning rate: 0.00064833]
	Learning Rate: 0.000648328
	LOSS [training: 0.1307460462349121 | validation: 0.29296250009565006]
	TIME [epoch: 19.2 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1178431898563643		[learning rate: 0.00064527]
	Learning Rate: 0.000645273
	LOSS [training: 0.1178431898563643 | validation: 0.2989106306803516]
	TIME [epoch: 19.2 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12913092861419		[learning rate: 0.00064223]
	Learning Rate: 0.000642232
	LOSS [training: 0.12913092861419 | validation: 0.27231513111972994]
	TIME [epoch: 19.2 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0979370995659995		[learning rate: 0.00063921]
	Learning Rate: 0.000639206
	LOSS [training: 0.0979370995659995 | validation: 0.3226594349910053]
	TIME [epoch: 19.1 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11470133941389565		[learning rate: 0.00063619]
	Learning Rate: 0.000636194
	LOSS [training: 0.11470133941389565 | validation: 0.28152850412755204]
	TIME [epoch: 19.2 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10244586577998917		[learning rate: 0.0006332]
	Learning Rate: 0.000633196
	LOSS [training: 0.10244586577998917 | validation: 0.29373016500473276]
	TIME [epoch: 19.2 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12459986599795239		[learning rate: 0.00063021]
	Learning Rate: 0.000630213
	LOSS [training: 0.12459986599795239 | validation: 0.3020050771794129]
	TIME [epoch: 19.2 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11246917155798203		[learning rate: 0.00062724]
	Learning Rate: 0.000627243
	LOSS [training: 0.11246917155798203 | validation: 0.2858916195951019]
	TIME [epoch: 19.1 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10296467992802882		[learning rate: 0.00062429]
	Learning Rate: 0.000624287
	LOSS [training: 0.10296467992802882 | validation: 0.28107500093170085]
	TIME [epoch: 19.2 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09906356635593201		[learning rate: 0.00062135]
	Learning Rate: 0.000621346
	LOSS [training: 0.09906356635593201 | validation: 0.3079144914725005]
	TIME [epoch: 19.1 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11031704559044705		[learning rate: 0.00061842]
	Learning Rate: 0.000618418
	LOSS [training: 0.11031704559044705 | validation: 0.2792758960817375]
	TIME [epoch: 19.2 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0978001987758487		[learning rate: 0.0006155]
	Learning Rate: 0.000615504
	LOSS [training: 0.0978001987758487 | validation: 0.29017728021104483]
	TIME [epoch: 19.2 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12859353880883626		[learning rate: 0.0006126]
	Learning Rate: 0.000612604
	LOSS [training: 0.12859353880883626 | validation: 0.2751799705733967]
	TIME [epoch: 19.2 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13024548038667855		[learning rate: 0.00060972]
	Learning Rate: 0.000609717
	LOSS [training: 0.13024548038667855 | validation: 0.30301827160372047]
	TIME [epoch: 19.2 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11654554552161939		[learning rate: 0.00060684]
	Learning Rate: 0.000606844
	LOSS [training: 0.11654554552161939 | validation: 0.29832240742313065]
	TIME [epoch: 19.2 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1090351662269966		[learning rate: 0.00060398]
	Learning Rate: 0.000603984
	LOSS [training: 0.1090351662269966 | validation: 0.27879087505449124]
	TIME [epoch: 19.2 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12147602625461312		[learning rate: 0.00060114]
	Learning Rate: 0.000601138
	LOSS [training: 0.12147602625461312 | validation: 0.2903373035566734]
	TIME [epoch: 19.2 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11467717783398243		[learning rate: 0.00059831]
	Learning Rate: 0.000598306
	LOSS [training: 0.11467717783398243 | validation: 0.28881282063284003]
	TIME [epoch: 19.2 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1033058932717214		[learning rate: 0.00059549]
	Learning Rate: 0.000595486
	LOSS [training: 0.1033058932717214 | validation: 0.27745994627867954]
	TIME [epoch: 19.2 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10934438736467379		[learning rate: 0.00059268]
	Learning Rate: 0.00059268
	LOSS [training: 0.10934438736467379 | validation: 0.2784149956176248]
	TIME [epoch: 19.2 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10478018309064413		[learning rate: 0.00058989]
	Learning Rate: 0.000589888
	LOSS [training: 0.10478018309064413 | validation: 0.2891050739684845]
	TIME [epoch: 19.2 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1103373508721708		[learning rate: 0.00058711]
	Learning Rate: 0.000587108
	LOSS [training: 0.1103373508721708 | validation: 0.2890186228708848]
	TIME [epoch: 19.2 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11991748109525857		[learning rate: 0.00058434]
	Learning Rate: 0.000584341
	LOSS [training: 0.11991748109525857 | validation: 0.30972310771867667]
	TIME [epoch: 19.2 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10390408160311798		[learning rate: 0.00058159]
	Learning Rate: 0.000581588
	LOSS [training: 0.10390408160311798 | validation: 0.2811078444834033]
	TIME [epoch: 19.2 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1094032043640191		[learning rate: 0.00057885]
	Learning Rate: 0.000578847
	LOSS [training: 0.1094032043640191 | validation: 0.2785051453787361]
	TIME [epoch: 19.2 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10091214353131606		[learning rate: 0.00057612]
	Learning Rate: 0.00057612
	LOSS [training: 0.10091214353131606 | validation: 0.28123344755705587]
	TIME [epoch: 19.2 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10153989069633394		[learning rate: 0.00057341]
	Learning Rate: 0.000573405
	LOSS [training: 0.10153989069633394 | validation: 0.29310485094255917]
	TIME [epoch: 19.2 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11760095229127043		[learning rate: 0.0005707]
	Learning Rate: 0.000570703
	LOSS [training: 0.11760095229127043 | validation: 0.29528595703801674]
	TIME [epoch: 19.2 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11444909868465009		[learning rate: 0.00056801]
	Learning Rate: 0.000568014
	LOSS [training: 0.11444909868465009 | validation: 0.28956544640879417]
	TIME [epoch: 19.2 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10805674271179311		[learning rate: 0.00056534]
	Learning Rate: 0.000565337
	LOSS [training: 0.10805674271179311 | validation: 0.2880510116426746]
	TIME [epoch: 19.2 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11125823546906594		[learning rate: 0.00056267]
	Learning Rate: 0.000562673
	LOSS [training: 0.11125823546906594 | validation: 0.28949899585706634]
	TIME [epoch: 19.2 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11806738290595237		[learning rate: 0.00056002]
	Learning Rate: 0.000560022
	LOSS [training: 0.11806738290595237 | validation: 0.29416046612280267]
	TIME [epoch: 19.2 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10985525587657725		[learning rate: 0.00055738]
	Learning Rate: 0.000557383
	LOSS [training: 0.10985525587657725 | validation: 0.30376406709181053]
	TIME [epoch: 19.2 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12304099494666057		[learning rate: 0.00055476]
	Learning Rate: 0.000554757
	LOSS [training: 0.12304099494666057 | validation: 0.2895188502439937]
	TIME [epoch: 19.1 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10550428851312493		[learning rate: 0.00055214]
	Learning Rate: 0.000552143
	LOSS [training: 0.10550428851312493 | validation: 0.2780286328801377]
	TIME [epoch: 19.2 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1392433660831632		[learning rate: 0.00054954]
	Learning Rate: 0.000549541
	LOSS [training: 0.1392433660831632 | validation: 0.2928656058777699]
	TIME [epoch: 19.2 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1069289143595391		[learning rate: 0.00054695]
	Learning Rate: 0.000546951
	LOSS [training: 0.1069289143595391 | validation: 0.2873266913591702]
	TIME [epoch: 19.2 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10738372922086967		[learning rate: 0.00054437]
	Learning Rate: 0.000544374
	LOSS [training: 0.10738372922086967 | validation: 0.2882269196472175]
	TIME [epoch: 19.2 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1200135581248771		[learning rate: 0.00054181]
	Learning Rate: 0.000541809
	LOSS [training: 0.1200135581248771 | validation: 0.28547119936965637]
	TIME [epoch: 19.2 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12180058490999618		[learning rate: 0.00053926]
	Learning Rate: 0.000539256
	LOSS [training: 0.12180058490999618 | validation: 0.27653223972870034]
	TIME [epoch: 19.2 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10626911338493747		[learning rate: 0.00053671]
	Learning Rate: 0.000536715
	LOSS [training: 0.10626911338493747 | validation: 0.2838249597597488]
	TIME [epoch: 19.2 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10312910244255456		[learning rate: 0.00053419]
	Learning Rate: 0.000534186
	LOSS [training: 0.10312910244255456 | validation: 0.2917160434391951]
	TIME [epoch: 19.2 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11487266590847012		[learning rate: 0.00053167]
	Learning Rate: 0.000531669
	LOSS [training: 0.11487266590847012 | validation: 0.2890032300194913]
	TIME [epoch: 19.2 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09886698359714373		[learning rate: 0.00052916]
	Learning Rate: 0.000529163
	LOSS [training: 0.09886698359714373 | validation: 0.27785526906061175]
	TIME [epoch: 19.2 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11124211347558709		[learning rate: 0.00052667]
	Learning Rate: 0.00052667
	LOSS [training: 0.11124211347558709 | validation: 0.27668853317726105]
	TIME [epoch: 19.2 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11034386471848516		[learning rate: 0.00052419]
	Learning Rate: 0.000524188
	LOSS [training: 0.11034386471848516 | validation: 0.2784733351932967]
	TIME [epoch: 19.2 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10581683117019042		[learning rate: 0.00052172]
	Learning Rate: 0.000521718
	LOSS [training: 0.10581683117019042 | validation: 0.287387769148965]
	TIME [epoch: 19.2 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0973464897781325		[learning rate: 0.00051926]
	Learning Rate: 0.00051926
	LOSS [training: 0.0973464897781325 | validation: 0.2758557698992646]
	TIME [epoch: 19.2 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11021675701005194		[learning rate: 0.00051681]
	Learning Rate: 0.000516813
	LOSS [training: 0.11021675701005194 | validation: 0.284144326830801]
	TIME [epoch: 19.2 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10620161320728568		[learning rate: 0.00051438]
	Learning Rate: 0.000514378
	LOSS [training: 0.10620161320728568 | validation: 0.2789378627057893]
	TIME [epoch: 19.2 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10086530910901928		[learning rate: 0.00051195]
	Learning Rate: 0.000511954
	LOSS [training: 0.10086530910901928 | validation: 0.28414086608059613]
	TIME [epoch: 19.2 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09867029001639863		[learning rate: 0.00050954]
	Learning Rate: 0.000509541
	LOSS [training: 0.09867029001639863 | validation: 0.2829139097552611]
	TIME [epoch: 19.2 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11422112962264903		[learning rate: 0.00050714]
	Learning Rate: 0.00050714
	LOSS [training: 0.11422112962264903 | validation: 0.28391876366090824]
	TIME [epoch: 19.1 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10531128067486285		[learning rate: 0.00050475]
	Learning Rate: 0.000504751
	LOSS [training: 0.10531128067486285 | validation: 0.27778962328066364]
	TIME [epoch: 19.2 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11877109789451044		[learning rate: 0.00050237]
	Learning Rate: 0.000502372
	LOSS [training: 0.11877109789451044 | validation: 0.29931613430416104]
	TIME [epoch: 19.2 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11385138954278727		[learning rate: 0.00050001]
	Learning Rate: 0.000500005
	LOSS [training: 0.11385138954278727 | validation: 0.28489003179007993]
	TIME [epoch: 19.2 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11529988985600265		[learning rate: 0.00049765]
	Learning Rate: 0.000497649
	LOSS [training: 0.11529988985600265 | validation: 0.28826999611223225]
	TIME [epoch: 19.1 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10359646624851743		[learning rate: 0.0004953]
	Learning Rate: 0.000495304
	LOSS [training: 0.10359646624851743 | validation: 0.2895172012895488]
	TIME [epoch: 19.2 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10086454128378751		[learning rate: 0.00049297]
	Learning Rate: 0.00049297
	LOSS [training: 0.10086454128378751 | validation: 0.28451356929579746]
	TIME [epoch: 19.2 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1143535169774286		[learning rate: 0.00049065]
	Learning Rate: 0.000490647
	LOSS [training: 0.1143535169774286 | validation: 0.27892545084710063]
	TIME [epoch: 19.2 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10786366824535504		[learning rate: 0.00048834]
	Learning Rate: 0.000488335
	LOSS [training: 0.10786366824535504 | validation: 0.28697888272951055]
	TIME [epoch: 19.2 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10999788779256638		[learning rate: 0.00048603]
	Learning Rate: 0.000486034
	LOSS [training: 0.10999788779256638 | validation: 0.28555665197502633]
	TIME [epoch: 19.2 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10674027106032379		[learning rate: 0.00048374]
	Learning Rate: 0.000483744
	LOSS [training: 0.10674027106032379 | validation: 0.28141952527950065]
	TIME [epoch: 19.1 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11472649408871517		[learning rate: 0.00048146]
	Learning Rate: 0.000481464
	LOSS [training: 0.11472649408871517 | validation: 0.27299457291410184]
	TIME [epoch: 19.2 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10679067696592162		[learning rate: 0.0004792]
	Learning Rate: 0.000479196
	LOSS [training: 0.10679067696592162 | validation: 0.2828453911858967]
	TIME [epoch: 19.1 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1354930750413101		[learning rate: 0.00047694]
	Learning Rate: 0.000476938
	LOSS [training: 0.1354930750413101 | validation: 0.2689198909073694]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_682.pth
	Model improved!!!
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10409436110866083		[learning rate: 0.00047469]
	Learning Rate: 0.00047469
	LOSS [training: 0.10409436110866083 | validation: 0.2827533117156022]
	TIME [epoch: 19.2 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10164782707414227		[learning rate: 0.00047245]
	Learning Rate: 0.000472453
	LOSS [training: 0.10164782707414227 | validation: 0.28714300164632645]
	TIME [epoch: 19.2 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11940065215093032		[learning rate: 0.00047023]
	Learning Rate: 0.000470227
	LOSS [training: 0.11940065215093032 | validation: 0.28235530636404105]
	TIME [epoch: 19.2 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1029654216650972		[learning rate: 0.00046801]
	Learning Rate: 0.000468011
	LOSS [training: 0.1029654216650972 | validation: 0.2810900125458216]
	TIME [epoch: 19.2 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09901502230105157		[learning rate: 0.00046581]
	Learning Rate: 0.000465806
	LOSS [training: 0.09901502230105157 | validation: 0.283565906539777]
	TIME [epoch: 19.2 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10219462234343489		[learning rate: 0.00046361]
	Learning Rate: 0.000463611
	LOSS [training: 0.10219462234343489 | validation: 0.2814456704453036]
	TIME [epoch: 19.2 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1062756506866611		[learning rate: 0.00046143]
	Learning Rate: 0.000461426
	LOSS [training: 0.1062756506866611 | validation: 0.2709296524348361]
	TIME [epoch: 19.2 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10498070953687876		[learning rate: 0.00045925]
	Learning Rate: 0.000459252
	LOSS [training: 0.10498070953687876 | validation: 0.28507076784210883]
	TIME [epoch: 19.2 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11012409487419687		[learning rate: 0.00045709]
	Learning Rate: 0.000457088
	LOSS [training: 0.11012409487419687 | validation: 0.2751335188545694]
	TIME [epoch: 19.2 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1107308728661314		[learning rate: 0.00045493]
	Learning Rate: 0.000454934
	LOSS [training: 0.1107308728661314 | validation: 0.28475004571052565]
	TIME [epoch: 19.2 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.106599930831194		[learning rate: 0.00045279]
	Learning Rate: 0.000452791
	LOSS [training: 0.106599930831194 | validation: 0.28325302859601476]
	TIME [epoch: 19.2 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10414802298064016		[learning rate: 0.00045066]
	Learning Rate: 0.000450657
	LOSS [training: 0.10414802298064016 | validation: 0.2799473461586781]
	TIME [epoch: 19.2 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10480682634180362		[learning rate: 0.00044853]
	Learning Rate: 0.000448533
	LOSS [training: 0.10480682634180362 | validation: 0.2714367006750225]
	TIME [epoch: 19.2 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12138898405473962		[learning rate: 0.00044642]
	Learning Rate: 0.00044642
	LOSS [training: 0.12138898405473962 | validation: 0.2766611242259039]
	TIME [epoch: 19.2 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11608833883054848		[learning rate: 0.00044432]
	Learning Rate: 0.000444316
	LOSS [training: 0.11608833883054848 | validation: 0.28060728503969823]
	TIME [epoch: 19.2 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10418534243666697		[learning rate: 0.00044222]
	Learning Rate: 0.000442223
	LOSS [training: 0.10418534243666697 | validation: 0.28845903145977125]
	TIME [epoch: 19.2 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1232002097334293		[learning rate: 0.00044014]
	Learning Rate: 0.000440139
	LOSS [training: 0.1232002097334293 | validation: 0.27784982740634523]
	TIME [epoch: 19.2 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10093733269225828		[learning rate: 0.00043806]
	Learning Rate: 0.000438065
	LOSS [training: 0.10093733269225828 | validation: 0.27944948832580874]
	TIME [epoch: 19.2 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11601262980437567		[learning rate: 0.000436]
	Learning Rate: 0.000436001
	LOSS [training: 0.11601262980437567 | validation: 0.2796957035335432]
	TIME [epoch: 19.2 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10643304858816606		[learning rate: 0.00043395]
	Learning Rate: 0.000433946
	LOSS [training: 0.10643304858816606 | validation: 0.2843109354461009]
	TIME [epoch: 19.2 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10070735471160994		[learning rate: 0.0004319]
	Learning Rate: 0.000431901
	LOSS [training: 0.10070735471160994 | validation: 0.28051230866856036]
	TIME [epoch: 19.2 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11380901584030867		[learning rate: 0.00042987]
	Learning Rate: 0.000429866
	LOSS [training: 0.11380901584030867 | validation: 0.2801329781031889]
	TIME [epoch: 19.2 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10117415559875546		[learning rate: 0.00042784]
	Learning Rate: 0.000427841
	LOSS [training: 0.10117415559875546 | validation: 0.2792860038638716]
	TIME [epoch: 19.2 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10582177948620401		[learning rate: 0.00042582]
	Learning Rate: 0.000425825
	LOSS [training: 0.10582177948620401 | validation: 0.2844065730297617]
	TIME [epoch: 19.2 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11136244067690834		[learning rate: 0.00042382]
	Learning Rate: 0.000423818
	LOSS [training: 0.11136244067690834 | validation: 0.2780055450990945]
	TIME [epoch: 19.2 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0937589557481002		[learning rate: 0.00042182]
	Learning Rate: 0.000421821
	LOSS [training: 0.0937589557481002 | validation: 0.27255991439149263]
	TIME [epoch: 19.2 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10854243437335706		[learning rate: 0.00041983]
	Learning Rate: 0.000419833
	LOSS [training: 0.10854243437335706 | validation: 0.2789836043604275]
	TIME [epoch: 19.2 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1005773479596876		[learning rate: 0.00041786]
	Learning Rate: 0.000417855
	LOSS [training: 0.1005773479596876 | validation: 0.27725489521007624]
	TIME [epoch: 19.2 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11487630427790066		[learning rate: 0.00041589]
	Learning Rate: 0.000415886
	LOSS [training: 0.11487630427790066 | validation: 0.2646251120876556]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_711.pth
	Model improved!!!
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09665761703569771		[learning rate: 0.00041393]
	Learning Rate: 0.000413926
	LOSS [training: 0.09665761703569771 | validation: 0.2657704458013005]
	TIME [epoch: 19.2 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11555328829076222		[learning rate: 0.00041198]
	Learning Rate: 0.000411976
	LOSS [training: 0.11555328829076222 | validation: 0.28057490103911037]
	TIME [epoch: 19.2 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12089738141601847		[learning rate: 0.00041003]
	Learning Rate: 0.000410035
	LOSS [training: 0.12089738141601847 | validation: 0.28326988569303596]
	TIME [epoch: 19.2 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10451017893553237		[learning rate: 0.0004081]
	Learning Rate: 0.000408102
	LOSS [training: 0.10451017893553237 | validation: 0.2830572869942195]
	TIME [epoch: 19.2 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10625801587170015		[learning rate: 0.00040618]
	Learning Rate: 0.000406179
	LOSS [training: 0.10625801587170015 | validation: 0.28283005408654555]
	TIME [epoch: 19.2 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10070189577884434		[learning rate: 0.00040427]
	Learning Rate: 0.000404266
	LOSS [training: 0.10070189577884434 | validation: 0.2896555429130621]
	TIME [epoch: 19.2 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10174099511119375		[learning rate: 0.00040236]
	Learning Rate: 0.000402361
	LOSS [training: 0.10174099511119375 | validation: 0.27866400086303633]
	TIME [epoch: 19.2 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11772249922932351		[learning rate: 0.00040046]
	Learning Rate: 0.000400465
	LOSS [training: 0.11772249922932351 | validation: 0.2781280213059126]
	TIME [epoch: 19.2 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09824272963079804		[learning rate: 0.00039858]
	Learning Rate: 0.000398578
	LOSS [training: 0.09824272963079804 | validation: 0.27891034510057505]
	TIME [epoch: 19.2 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1155660137152908		[learning rate: 0.0003967]
	Learning Rate: 0.000396699
	LOSS [training: 0.1155660137152908 | validation: 0.28902417302294897]
	TIME [epoch: 19.2 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11390385975283356		[learning rate: 0.00039483]
	Learning Rate: 0.00039483
	LOSS [training: 0.11390385975283356 | validation: 0.2651844867901969]
	TIME [epoch: 19.2 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1073208635364183		[learning rate: 0.00039297]
	Learning Rate: 0.00039297
	LOSS [training: 0.1073208635364183 | validation: 0.2756434367867718]
	TIME [epoch: 19.2 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09927688936290288		[learning rate: 0.00039112]
	Learning Rate: 0.000391118
	LOSS [training: 0.09927688936290288 | validation: 0.2809856948868136]
	TIME [epoch: 19.2 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1139080036719336		[learning rate: 0.00038927]
	Learning Rate: 0.000389275
	LOSS [training: 0.1139080036719336 | validation: 0.27419208474737156]
	TIME [epoch: 19.2 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0952202172409373		[learning rate: 0.00038744]
	Learning Rate: 0.000387441
	LOSS [training: 0.0952202172409373 | validation: 0.2728291226357139]
	TIME [epoch: 19.2 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10572751987506925		[learning rate: 0.00038561]
	Learning Rate: 0.000385615
	LOSS [training: 0.10572751987506925 | validation: 0.27446454482669597]
	TIME [epoch: 19.2 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11642634855858769		[learning rate: 0.0003838]
	Learning Rate: 0.000383798
	LOSS [training: 0.11642634855858769 | validation: 0.283178291084327]
	TIME [epoch: 19.2 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10638754699105415		[learning rate: 0.00038199]
	Learning Rate: 0.000381989
	LOSS [training: 0.10638754699105415 | validation: 0.27215902041256107]
	TIME [epoch: 19.2 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09540252211565638		[learning rate: 0.00038019]
	Learning Rate: 0.000380189
	LOSS [training: 0.09540252211565638 | validation: 0.2855769284978176]
	TIME [epoch: 19.2 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10322812444186447		[learning rate: 0.0003784]
	Learning Rate: 0.000378398
	LOSS [training: 0.10322812444186447 | validation: 0.27824794788525586]
	TIME [epoch: 19.2 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12689812811809328		[learning rate: 0.00037661]
	Learning Rate: 0.000376615
	LOSS [training: 0.12689812811809328 | validation: 0.28558539810778705]
	TIME [epoch: 19.2 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09941457708945227		[learning rate: 0.00037484]
	Learning Rate: 0.00037484
	LOSS [training: 0.09941457708945227 | validation: 0.2813812869048545]
	TIME [epoch: 19.2 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0995435093086551		[learning rate: 0.00037307]
	Learning Rate: 0.000373074
	LOSS [training: 0.0995435093086551 | validation: 0.2801040271780268]
	TIME [epoch: 19.2 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11235941689167467		[learning rate: 0.00037132]
	Learning Rate: 0.000371316
	LOSS [training: 0.11235941689167467 | validation: 0.27436215194661345]
	TIME [epoch: 19.2 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11234210329258165		[learning rate: 0.00036957]
	Learning Rate: 0.000369566
	LOSS [training: 0.11234210329258165 | validation: 0.27484668757930497]
	TIME [epoch: 19.2 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10615842678120128		[learning rate: 0.00036782]
	Learning Rate: 0.000367825
	LOSS [training: 0.10615842678120128 | validation: 0.2766731560241909]
	TIME [epoch: 19.2 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10759445098587991		[learning rate: 0.00036609]
	Learning Rate: 0.000366092
	LOSS [training: 0.10759445098587991 | validation: 0.2787429336340038]
	TIME [epoch: 19.2 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1040545332813909		[learning rate: 0.00036437]
	Learning Rate: 0.000364367
	LOSS [training: 0.1040545332813909 | validation: 0.2912854068279004]
	TIME [epoch: 19.2 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12288819742628487		[learning rate: 0.00036265]
	Learning Rate: 0.00036265
	LOSS [training: 0.12288819742628487 | validation: 0.26240288053000155]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_740.pth
	Model improved!!!
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10041796130847704		[learning rate: 0.00036094]
	Learning Rate: 0.000360941
	LOSS [training: 0.10041796130847704 | validation: 0.2795958040500412]
	TIME [epoch: 19.2 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10563089874586512		[learning rate: 0.00035924]
	Learning Rate: 0.00035924
	LOSS [training: 0.10563089874586512 | validation: 0.282063678427269]
	TIME [epoch: 19.2 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12181435726693303		[learning rate: 0.00035755]
	Learning Rate: 0.000357547
	LOSS [training: 0.12181435726693303 | validation: 0.2830058630303603]
	TIME [epoch: 19.2 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10213176080388384		[learning rate: 0.00035586]
	Learning Rate: 0.000355862
	LOSS [training: 0.10213176080388384 | validation: 0.2843064091904878]
	TIME [epoch: 19.2 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1006506501284189		[learning rate: 0.00035419]
	Learning Rate: 0.000354185
	LOSS [training: 0.1006506501284189 | validation: 0.2805425670180197]
	TIME [epoch: 19.2 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09740551778736947		[learning rate: 0.00035252]
	Learning Rate: 0.000352517
	LOSS [training: 0.09740551778736947 | validation: 0.27792161162574025]
	TIME [epoch: 19.2 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10820135300433628		[learning rate: 0.00035086]
	Learning Rate: 0.000350855
	LOSS [training: 0.10820135300433628 | validation: 0.27749486683645447]
	TIME [epoch: 19.2 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11457661745213207		[learning rate: 0.0003492]
	Learning Rate: 0.000349202
	LOSS [training: 0.11457661745213207 | validation: 0.2755083140975262]
	TIME [epoch: 19.2 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10255633679231549		[learning rate: 0.00034756]
	Learning Rate: 0.000347557
	LOSS [training: 0.10255633679231549 | validation: 0.2676546631743602]
	TIME [epoch: 19.2 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10238318878873315		[learning rate: 0.00034592]
	Learning Rate: 0.000345919
	LOSS [training: 0.10238318878873315 | validation: 0.2851603816118862]
	TIME [epoch: 19.2 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11490913756440124		[learning rate: 0.00034429]
	Learning Rate: 0.000344289
	LOSS [training: 0.11490913756440124 | validation: 0.2864040473965897]
	TIME [epoch: 19.2 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11726749405860176		[learning rate: 0.00034267]
	Learning Rate: 0.000342667
	LOSS [training: 0.11726749405860176 | validation: 0.27636975162196964]
	TIME [epoch: 19.2 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10331304501447036		[learning rate: 0.00034105]
	Learning Rate: 0.000341052
	LOSS [training: 0.10331304501447036 | validation: 0.27790645911585743]
	TIME [epoch: 19.2 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10643716352465298		[learning rate: 0.00033944]
	Learning Rate: 0.000339445
	LOSS [training: 0.10643716352465298 | validation: 0.2876672094062517]
	TIME [epoch: 19.2 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11645207941358543		[learning rate: 0.00033785]
	Learning Rate: 0.000337845
	LOSS [training: 0.11645207941358543 | validation: 0.2882730259924153]
	TIME [epoch: 19.2 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1105511835973429		[learning rate: 0.00033625]
	Learning Rate: 0.000336253
	LOSS [training: 0.1105511835973429 | validation: 0.2773527898507828]
	TIME [epoch: 19.2 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10912990222233827		[learning rate: 0.00033467]
	Learning Rate: 0.000334669
	LOSS [training: 0.10912990222233827 | validation: 0.2829593021342797]
	TIME [epoch: 19.2 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10688555812094513		[learning rate: 0.00033309]
	Learning Rate: 0.000333092
	LOSS [training: 0.10688555812094513 | validation: 0.2785546115070563]
	TIME [epoch: 19.2 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10990789696313379		[learning rate: 0.00033152]
	Learning Rate: 0.000331522
	LOSS [training: 0.10990789696313379 | validation: 0.2782047123793808]
	TIME [epoch: 19.2 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10566463261392674		[learning rate: 0.00032996]
	Learning Rate: 0.00032996
	LOSS [training: 0.10566463261392674 | validation: 0.27441599835983543]
	TIME [epoch: 19.2 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09678531773418164		[learning rate: 0.00032841]
	Learning Rate: 0.000328405
	LOSS [training: 0.09678531773418164 | validation: 0.26932154840858574]
	TIME [epoch: 19.2 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1015573295954271		[learning rate: 0.00032686]
	Learning Rate: 0.000326858
	LOSS [training: 0.1015573295954271 | validation: 0.2754086794658604]
	TIME [epoch: 19.2 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11008687851954371		[learning rate: 0.00032532]
	Learning Rate: 0.000325318
	LOSS [training: 0.11008687851954371 | validation: 0.26871685255555433]
	TIME [epoch: 19.2 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10949572217305363		[learning rate: 0.00032378]
	Learning Rate: 0.000323785
	LOSS [training: 0.10949572217305363 | validation: 0.2751299818113131]
	TIME [epoch: 19.2 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11547224931703826		[learning rate: 0.00032226]
	Learning Rate: 0.000322259
	LOSS [training: 0.11547224931703826 | validation: 0.2844557422246701]
	TIME [epoch: 19.2 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09902623643372528		[learning rate: 0.00032074]
	Learning Rate: 0.000320741
	LOSS [training: 0.09902623643372528 | validation: 0.29333411934413883]
	TIME [epoch: 19.2 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09652968458907897		[learning rate: 0.00031923]
	Learning Rate: 0.000319229
	LOSS [training: 0.09652968458907897 | validation: 0.27215079186821856]
	TIME [epoch: 19.2 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10194840442396107		[learning rate: 0.00031772]
	Learning Rate: 0.000317725
	LOSS [training: 0.10194840442396107 | validation: 0.2754700121312867]
	TIME [epoch: 19.2 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12036483288573396		[learning rate: 0.00031623]
	Learning Rate: 0.000316228
	LOSS [training: 0.12036483288573396 | validation: 0.2884049165400281]
	TIME [epoch: 19.2 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09740452780614677		[learning rate: 0.00031474]
	Learning Rate: 0.000314738
	LOSS [training: 0.09740452780614677 | validation: 0.27047042657877407]
	TIME [epoch: 19.2 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10883571147327374		[learning rate: 0.00031325]
	Learning Rate: 0.000313255
	LOSS [training: 0.10883571147327374 | validation: 0.26949120256262293]
	TIME [epoch: 19.2 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10913183890970297		[learning rate: 0.00031178]
	Learning Rate: 0.000311778
	LOSS [training: 0.10913183890970297 | validation: 0.2793180905849223]
	TIME [epoch: 19.2 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10117508923651265		[learning rate: 0.00031031]
	Learning Rate: 0.000310309
	LOSS [training: 0.10117508923651265 | validation: 0.272370858421776]
	TIME [epoch: 19.2 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09747577440061232		[learning rate: 0.00030885]
	Learning Rate: 0.000308847
	LOSS [training: 0.09747577440061232 | validation: 0.2877056425284827]
	TIME [epoch: 19.2 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11382172159200242		[learning rate: 0.00030739]
	Learning Rate: 0.000307392
	LOSS [training: 0.11382172159200242 | validation: 0.29251686601667093]
	TIME [epoch: 19.2 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10003594097100374		[learning rate: 0.00030594]
	Learning Rate: 0.000305943
	LOSS [training: 0.10003594097100374 | validation: 0.27387895882686375]
	TIME [epoch: 19.2 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11833664455169776		[learning rate: 0.0003045]
	Learning Rate: 0.000304502
	LOSS [training: 0.11833664455169776 | validation: 0.28119404915980717]
	TIME [epoch: 19.2 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12254586420652477		[learning rate: 0.00030307]
	Learning Rate: 0.000303067
	LOSS [training: 0.12254586420652477 | validation: 0.27793682066570474]
	TIME [epoch: 19.2 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11039300452937327		[learning rate: 0.00030164]
	Learning Rate: 0.000301639
	LOSS [training: 0.11039300452937327 | validation: 0.2784097540370396]
	TIME [epoch: 19.2 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10617355854390446		[learning rate: 0.00030022]
	Learning Rate: 0.000300217
	LOSS [training: 0.10617355854390446 | validation: 0.27747690164881994]
	TIME [epoch: 19.2 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10498143308109276		[learning rate: 0.0002988]
	Learning Rate: 0.000298803
	LOSS [training: 0.10498143308109276 | validation: 0.27951433409076504]
	TIME [epoch: 19.2 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12231401423896214		[learning rate: 0.00029739]
	Learning Rate: 0.000297395
	LOSS [training: 0.12231401423896214 | validation: 0.27991811335514094]
	TIME [epoch: 19.2 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09964492449249407		[learning rate: 0.00029599]
	Learning Rate: 0.000295993
	LOSS [training: 0.09964492449249407 | validation: 0.27445756951863176]
	TIME [epoch: 19.2 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10835684222501522		[learning rate: 0.0002946]
	Learning Rate: 0.000294599
	LOSS [training: 0.10835684222501522 | validation: 0.28216505457932795]
	TIME [epoch: 19.2 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09930875675434275		[learning rate: 0.00029321]
	Learning Rate: 0.00029321
	LOSS [training: 0.09930875675434275 | validation: 0.27426486191666805]
	TIME [epoch: 19.2 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1022616558998263		[learning rate: 0.00029183]
	Learning Rate: 0.000291829
	LOSS [training: 0.1022616558998263 | validation: 0.26973322820310464]
	TIME [epoch: 19.2 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11149807261762901		[learning rate: 0.00029045]
	Learning Rate: 0.000290454
	LOSS [training: 0.11149807261762901 | validation: 0.29683897913184054]
	TIME [epoch: 19.2 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10788796021577277		[learning rate: 0.00028909]
	Learning Rate: 0.000289085
	LOSS [training: 0.10788796021577277 | validation: 0.2845952579058923]
	TIME [epoch: 19.2 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10840990287915032		[learning rate: 0.00028772]
	Learning Rate: 0.000287723
	LOSS [training: 0.10840990287915032 | validation: 0.2793986003054616]
	TIME [epoch: 19.2 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10464890325794024		[learning rate: 0.00028637]
	Learning Rate: 0.000286367
	LOSS [training: 0.10464890325794024 | validation: 0.28995920643396156]
	TIME [epoch: 19.2 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09471149112160808		[learning rate: 0.00028502]
	Learning Rate: 0.000285018
	LOSS [training: 0.09471149112160808 | validation: 0.2745264153282748]
	TIME [epoch: 19.2 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09499362157582214		[learning rate: 0.00028367]
	Learning Rate: 0.000283675
	LOSS [training: 0.09499362157582214 | validation: 0.26824443697670247]
	TIME [epoch: 19.2 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1224255110265709		[learning rate: 0.00028234]
	Learning Rate: 0.000282338
	LOSS [training: 0.1224255110265709 | validation: 0.27117588942986]
	TIME [epoch: 19.2 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09920959063653101		[learning rate: 0.00028101]
	Learning Rate: 0.000281008
	LOSS [training: 0.09920959063653101 | validation: 0.27901335654623655]
	TIME [epoch: 19.2 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11187290265445902		[learning rate: 0.00027968]
	Learning Rate: 0.000279683
	LOSS [training: 0.11187290265445902 | validation: 0.2731205081334353]
	TIME [epoch: 19.2 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09560380334985219		[learning rate: 0.00027837]
	Learning Rate: 0.000278366
	LOSS [training: 0.09560380334985219 | validation: 0.2740200940435624]
	TIME [epoch: 19.2 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13070883482277834		[learning rate: 0.00027705]
	Learning Rate: 0.000277054
	LOSS [training: 0.13070883482277834 | validation: 0.26539447968935825]
	TIME [epoch: 19.2 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09817502383721025		[learning rate: 0.00027575]
	Learning Rate: 0.000275748
	LOSS [training: 0.09817502383721025 | validation: 0.26639335181781376]
	TIME [epoch: 19.2 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10082807425921617		[learning rate: 0.00027445]
	Learning Rate: 0.000274449
	LOSS [training: 0.10082807425921617 | validation: 0.27773428151790513]
	TIME [epoch: 19.2 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11304811493780789		[learning rate: 0.00027316]
	Learning Rate: 0.000273156
	LOSS [training: 0.11304811493780789 | validation: 0.2772292294692285]
	TIME [epoch: 19.2 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09785665639097087		[learning rate: 0.00027187]
	Learning Rate: 0.000271869
	LOSS [training: 0.09785665639097087 | validation: 0.27329022126298574]
	TIME [epoch: 19.3 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10223321199659088		[learning rate: 0.00027059]
	Learning Rate: 0.000270587
	LOSS [training: 0.10223321199659088 | validation: 0.2745679381969934]
	TIME [epoch: 19.2 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10483371037586943		[learning rate: 0.00026931]
	Learning Rate: 0.000269312
	LOSS [training: 0.10483371037586943 | validation: 0.2767044944887995]
	TIME [epoch: 19.2 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1291393247309215		[learning rate: 0.00026804]
	Learning Rate: 0.000268043
	LOSS [training: 0.1291393247309215 | validation: 0.28242925215715925]
	TIME [epoch: 19.1 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09864506433107853		[learning rate: 0.00026678]
	Learning Rate: 0.00026678
	LOSS [training: 0.09864506433107853 | validation: 0.27065943843568147]
	TIME [epoch: 19.2 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11448228806063393		[learning rate: 0.00026552]
	Learning Rate: 0.000265523
	LOSS [training: 0.11448228806063393 | validation: 0.2738477754039923]
	TIME [epoch: 19.2 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1189594587150295		[learning rate: 0.00026427]
	Learning Rate: 0.000264272
	LOSS [training: 0.1189594587150295 | validation: 0.2726637723086952]
	TIME [epoch: 19.1 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10108504709282105		[learning rate: 0.00026303]
	Learning Rate: 0.000263027
	LOSS [training: 0.10108504709282105 | validation: 0.2774473487365288]
	TIME [epoch: 19.2 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09948465764948068		[learning rate: 0.00026179]
	Learning Rate: 0.000261787
	LOSS [training: 0.09948465764948068 | validation: 0.2845924697864171]
	TIME [epoch: 19.1 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11023389027473171		[learning rate: 0.00026055]
	Learning Rate: 0.000260554
	LOSS [training: 0.11023389027473171 | validation: 0.2680522293547172]
	TIME [epoch: 19.2 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10237387805505259		[learning rate: 0.00025933]
	Learning Rate: 0.000259326
	LOSS [training: 0.10237387805505259 | validation: 0.27599373475207123]
	TIME [epoch: 19.2 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09559451848889217		[learning rate: 0.0002581]
	Learning Rate: 0.000258104
	LOSS [training: 0.09559451848889217 | validation: 0.27624500444262395]
	TIME [epoch: 19.2 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11101177893911487		[learning rate: 0.00025689]
	Learning Rate: 0.000256888
	LOSS [training: 0.11101177893911487 | validation: 0.27100336578984885]
	TIME [epoch: 19.1 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09553246436669664		[learning rate: 0.00025568]
	Learning Rate: 0.000255677
	LOSS [training: 0.09553246436669664 | validation: 0.2699250262513627]
	TIME [epoch: 19.2 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09768565755214549		[learning rate: 0.00025447]
	Learning Rate: 0.000254473
	LOSS [training: 0.09768565755214549 | validation: 0.2743910760114078]
	TIME [epoch: 19.2 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11038946345382929		[learning rate: 0.00025327]
	Learning Rate: 0.000253274
	LOSS [training: 0.11038946345382929 | validation: 0.28234632520038605]
	TIME [epoch: 19.2 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09044967312546962		[learning rate: 0.00025208]
	Learning Rate: 0.00025208
	LOSS [training: 0.09044967312546962 | validation: 0.2682253489589129]
	TIME [epoch: 19.2 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10427372415379028		[learning rate: 0.00025089]
	Learning Rate: 0.000250892
	LOSS [training: 0.10427372415379028 | validation: 0.28153318974863895]
	TIME [epoch: 19.2 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10700918487193162		[learning rate: 0.00024971]
	Learning Rate: 0.00024971
	LOSS [training: 0.10700918487193162 | validation: 0.27944244853261424]
	TIME [epoch: 19.2 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09838585239597361		[learning rate: 0.00024853]
	Learning Rate: 0.000248533
	LOSS [training: 0.09838585239597361 | validation: 0.27219159420577993]
	TIME [epoch: 19.2 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09190637314732926		[learning rate: 0.00024736]
	Learning Rate: 0.000247362
	LOSS [training: 0.09190637314732926 | validation: 0.2795220949295944]
	TIME [epoch: 19.2 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10267748191855591		[learning rate: 0.0002462]
	Learning Rate: 0.000246197
	LOSS [training: 0.10267748191855591 | validation: 0.2707211251935654]
	TIME [epoch: 19.2 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09753649236218694		[learning rate: 0.00024504]
	Learning Rate: 0.000245037
	LOSS [training: 0.09753649236218694 | validation: 0.2665353473617186]
	TIME [epoch: 19.2 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11512315672066031		[learning rate: 0.00024388]
	Learning Rate: 0.000243882
	LOSS [training: 0.11512315672066031 | validation: 0.27113318080226134]
	TIME [epoch: 19.2 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09962590690824971		[learning rate: 0.00024273]
	Learning Rate: 0.000242733
	LOSS [training: 0.09962590690824971 | validation: 0.2706183720439033]
	TIME [epoch: 19.2 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10356404654888056		[learning rate: 0.00024159]
	Learning Rate: 0.000241589
	LOSS [training: 0.10356404654888056 | validation: 0.2828905225536344]
	TIME [epoch: 19.2 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10812418969437507		[learning rate: 0.00024045]
	Learning Rate: 0.00024045
	LOSS [training: 0.10812418969437507 | validation: 0.28234217871377876]
	TIME [epoch: 19.2 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09705287440712973		[learning rate: 0.00023932]
	Learning Rate: 0.000239317
	LOSS [training: 0.09705287440712973 | validation: 0.2685097385388512]
	TIME [epoch: 19.2 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09956783883108984		[learning rate: 0.00023819]
	Learning Rate: 0.00023819
	LOSS [training: 0.09956783883108984 | validation: 0.27849107433674686]
	TIME [epoch: 19.2 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10833674083422856		[learning rate: 0.00023707]
	Learning Rate: 0.000237067
	LOSS [training: 0.10833674083422856 | validation: 0.2695456268047037]
	TIME [epoch: 19.2 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09906028077504901		[learning rate: 0.00023595]
	Learning Rate: 0.00023595
	LOSS [training: 0.09906028077504901 | validation: 0.285430380116381]
	TIME [epoch: 19.2 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10499404431072268		[learning rate: 0.00023484]
	Learning Rate: 0.000234838
	LOSS [training: 0.10499404431072268 | validation: 0.28241343524009554]
	TIME [epoch: 19.2 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1001053946335034		[learning rate: 0.00023373]
	Learning Rate: 0.000233732
	LOSS [training: 0.1001053946335034 | validation: 0.2770262206952521]
	TIME [epoch: 19.2 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11116959549607923		[learning rate: 0.00023263]
	Learning Rate: 0.00023263
	LOSS [training: 0.11116959549607923 | validation: 0.2765156560093214]
	TIME [epoch: 19.2 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09821304709718086		[learning rate: 0.00023153]
	Learning Rate: 0.000231534
	LOSS [training: 0.09821304709718086 | validation: 0.28719680442276]
	TIME [epoch: 19.2 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11221288745866947		[learning rate: 0.00023044]
	Learning Rate: 0.000230443
	LOSS [training: 0.11221288745866947 | validation: 0.28030883463692635]
	TIME [epoch: 19.2 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10896432342369837		[learning rate: 0.00022936]
	Learning Rate: 0.000229357
	LOSS [training: 0.10896432342369837 | validation: 0.27960332875098254]
	TIME [epoch: 19.2 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10116099331363379		[learning rate: 0.00022828]
	Learning Rate: 0.000228277
	LOSS [training: 0.10116099331363379 | validation: 0.2769160334666886]
	TIME [epoch: 19.2 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09854506642807156		[learning rate: 0.0002272]
	Learning Rate: 0.000227201
	LOSS [training: 0.09854506642807156 | validation: 0.27674630269717976]
	TIME [epoch: 19.2 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0995098056464711		[learning rate: 0.00022613]
	Learning Rate: 0.00022613
	LOSS [training: 0.0995098056464711 | validation: 0.27984704698330787]
	TIME [epoch: 19.2 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1013033659933924		[learning rate: 0.00022506]
	Learning Rate: 0.000225065
	LOSS [training: 0.1013033659933924 | validation: 0.27715927059204315]
	TIME [epoch: 19.2 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10449331775096402		[learning rate: 0.000224]
	Learning Rate: 0.000224004
	LOSS [training: 0.10449331775096402 | validation: 0.2731074571330698]
	TIME [epoch: 19.2 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09828810832934234		[learning rate: 0.00022295]
	Learning Rate: 0.000222949
	LOSS [training: 0.09828810832934234 | validation: 0.2750018784071776]
	TIME [epoch: 19.2 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10878620560880378		[learning rate: 0.0002219]
	Learning Rate: 0.000221898
	LOSS [training: 0.10878620560880378 | validation: 0.27045564829935365]
	TIME [epoch: 19.2 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12132094447742864		[learning rate: 0.00022085]
	Learning Rate: 0.000220853
	LOSS [training: 0.12132094447742864 | validation: 0.2733051987027471]
	TIME [epoch: 19.2 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09879796081007816		[learning rate: 0.00021981]
	Learning Rate: 0.000219812
	LOSS [training: 0.09879796081007816 | validation: 0.27731173484864424]
	TIME [epoch: 19.2 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11221766793054577		[learning rate: 0.00021878]
	Learning Rate: 0.000218776
	LOSS [training: 0.11221766793054577 | validation: 0.26947781146909167]
	TIME [epoch: 19.2 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11089214355861116		[learning rate: 0.00021775]
	Learning Rate: 0.000217745
	LOSS [training: 0.11089214355861116 | validation: 0.2773492833144472]
	TIME [epoch: 19.2 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11895326595938191		[learning rate: 0.00021672]
	Learning Rate: 0.000216719
	LOSS [training: 0.11895326595938191 | validation: 0.2697047219917035]
	TIME [epoch: 19.1 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09599223563858938		[learning rate: 0.0002157]
	Learning Rate: 0.000215698
	LOSS [training: 0.09599223563858938 | validation: 0.2841059093963475]
	TIME [epoch: 19.2 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11103054649700975		[learning rate: 0.00021468]
	Learning Rate: 0.000214682
	LOSS [training: 0.11103054649700975 | validation: 0.2773480905951027]
	TIME [epoch: 19.2 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1000470029907419		[learning rate: 0.00021367]
	Learning Rate: 0.00021367
	LOSS [training: 0.1000470029907419 | validation: 0.2865196249870548]
	TIME [epoch: 19.2 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10138003469393082		[learning rate: 0.00021266]
	Learning Rate: 0.000212663
	LOSS [training: 0.10138003469393082 | validation: 0.2783496206418235]
	TIME [epoch: 19.2 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10232041121031207		[learning rate: 0.00021166]
	Learning Rate: 0.000211661
	LOSS [training: 0.10232041121031207 | validation: 0.26522395114878056]
	TIME [epoch: 19.2 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10084940796530799		[learning rate: 0.00021066]
	Learning Rate: 0.000210664
	LOSS [training: 0.10084940796530799 | validation: 0.2689553661326651]
	TIME [epoch: 19.2 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09979956516754679		[learning rate: 0.00020967]
	Learning Rate: 0.000209671
	LOSS [training: 0.09979956516754679 | validation: 0.2692078446345984]
	TIME [epoch: 19.2 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11300058098936047		[learning rate: 0.00020868]
	Learning Rate: 0.000208683
	LOSS [training: 0.11300058098936047 | validation: 0.27822870002803424]
	TIME [epoch: 19.2 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0982969557649494		[learning rate: 0.0002077]
	Learning Rate: 0.0002077
	LOSS [training: 0.0982969557649494 | validation: 0.26510476751520434]
	TIME [epoch: 19.1 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11035367506743307		[learning rate: 0.00020672]
	Learning Rate: 0.000206721
	LOSS [training: 0.11035367506743307 | validation: 0.2714443636350256]
	TIME [epoch: 19.2 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1053143619855189		[learning rate: 0.00020575]
	Learning Rate: 0.000205747
	LOSS [training: 0.1053143619855189 | validation: 0.26695844250006695]
	TIME [epoch: 19.2 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10433790966285174		[learning rate: 0.00020478]
	Learning Rate: 0.000204777
	LOSS [training: 0.10433790966285174 | validation: 0.27554414389831106]
	TIME [epoch: 19.2 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1073382242787372		[learning rate: 0.00020381]
	Learning Rate: 0.000203812
	LOSS [training: 0.1073382242787372 | validation: 0.2713126875029862]
	TIME [epoch: 19.2 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1105512602595339		[learning rate: 0.00020285]
	Learning Rate: 0.000202852
	LOSS [training: 0.1105512602595339 | validation: 0.2813431200549304]
	TIME [epoch: 19.2 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11220823731894675		[learning rate: 0.0002019]
	Learning Rate: 0.000201896
	LOSS [training: 0.11220823731894675 | validation: 0.26575897323029496]
	TIME [epoch: 19.1 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09899582722957083		[learning rate: 0.00020094]
	Learning Rate: 0.000200945
	LOSS [training: 0.09899582722957083 | validation: 0.2710335477375598]
	TIME [epoch: 19.2 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1025135358519692		[learning rate: 0.0002]
	Learning Rate: 0.000199998
	LOSS [training: 0.1025135358519692 | validation: 0.2781404887727618]
	TIME [epoch: 19.1 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09861199377856797		[learning rate: 0.00019906]
	Learning Rate: 0.000199056
	LOSS [training: 0.09861199377856797 | validation: 0.2663139862019829]
	TIME [epoch: 19.2 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11435477718457422		[learning rate: 0.00019812]
	Learning Rate: 0.000198118
	LOSS [training: 0.11435477718457422 | validation: 0.27418593904372346]
	TIME [epoch: 19.2 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10315789520631297		[learning rate: 0.00019718]
	Learning Rate: 0.000197184
	LOSS [training: 0.10315789520631297 | validation: 0.27605132302698765]
	TIME [epoch: 19.1 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10201546352585156		[learning rate: 0.00019625]
	Learning Rate: 0.000196255
	LOSS [training: 0.10201546352585156 | validation: 0.272411672081271]
	TIME [epoch: 19.2 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10448032049436397		[learning rate: 0.00019533]
	Learning Rate: 0.00019533
	LOSS [training: 0.10448032049436397 | validation: 0.2654094963142288]
	TIME [epoch: 19.2 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1043839589336284		[learning rate: 0.00019441]
	Learning Rate: 0.00019441
	LOSS [training: 0.1043839589336284 | validation: 0.2809470502323516]
	TIME [epoch: 19.2 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11616878265888309		[learning rate: 0.00019349]
	Learning Rate: 0.000193494
	LOSS [training: 0.11616878265888309 | validation: 0.2737523893746845]
	TIME [epoch: 19.2 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11336535132598283		[learning rate: 0.00019258]
	Learning Rate: 0.000192582
	LOSS [training: 0.11336535132598283 | validation: 0.28011266902907234]
	TIME [epoch: 19.2 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09583834997526997		[learning rate: 0.00019167]
	Learning Rate: 0.000191674
	LOSS [training: 0.09583834997526997 | validation: 0.2797394510609583]
	TIME [epoch: 19.2 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10042928250664113		[learning rate: 0.00019077]
	Learning Rate: 0.000190771
	LOSS [training: 0.10042928250664113 | validation: 0.2849937353044878]
	TIME [epoch: 19.2 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.097463613609917		[learning rate: 0.00018987]
	Learning Rate: 0.000189872
	LOSS [training: 0.097463613609917 | validation: 0.27660500119728004]
	TIME [epoch: 19.2 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09972905916556311		[learning rate: 0.00018898]
	Learning Rate: 0.000188978
	LOSS [training: 0.09972905916556311 | validation: 0.2688761738497887]
	TIME [epoch: 19.2 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1161206435656172		[learning rate: 0.00018809]
	Learning Rate: 0.000188087
	LOSS [training: 0.1161206435656172 | validation: 0.27155837565296914]
	TIME [epoch: 19.2 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10623653532569857		[learning rate: 0.0001872]
	Learning Rate: 0.000187201
	LOSS [training: 0.10623653532569857 | validation: 0.27463732856010303]
	TIME [epoch: 19.2 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10974737960278055		[learning rate: 0.00018632]
	Learning Rate: 0.000186319
	LOSS [training: 0.10974737960278055 | validation: 0.27528433588005663]
	TIME [epoch: 19.2 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11619869484561518		[learning rate: 0.00018544]
	Learning Rate: 0.000185441
	LOSS [training: 0.11619869484561518 | validation: 0.2669010435232487]
	TIME [epoch: 19.2 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10534000103763343		[learning rate: 0.00018457]
	Learning Rate: 0.000184567
	LOSS [training: 0.10534000103763343 | validation: 0.26838688679045974]
	TIME [epoch: 19.2 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09467108734610105		[learning rate: 0.0001837]
	Learning Rate: 0.000183697
	LOSS [training: 0.09467108734610105 | validation: 0.2710441574631488]
	TIME [epoch: 19.2 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09451593996587708		[learning rate: 0.00018283]
	Learning Rate: 0.000182832
	LOSS [training: 0.09451593996587708 | validation: 0.2849173628910023]
	TIME [epoch: 19.2 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09599981814628762		[learning rate: 0.00018197]
	Learning Rate: 0.00018197
	LOSS [training: 0.09599981814628762 | validation: 0.2683947110373972]
	TIME [epoch: 19.2 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10435810586476962		[learning rate: 0.00018111]
	Learning Rate: 0.000181113
	LOSS [training: 0.10435810586476962 | validation: 0.272724165921718]
	TIME [epoch: 19.2 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1002949232310233		[learning rate: 0.00018026]
	Learning Rate: 0.000180259
	LOSS [training: 0.1002949232310233 | validation: 0.27791902414602004]
	TIME [epoch: 19.2 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11334800747783022		[learning rate: 0.00017941]
	Learning Rate: 0.00017941
	LOSS [training: 0.11334800747783022 | validation: 0.2741438823100971]
	TIME [epoch: 19.2 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1001657262410476		[learning rate: 0.00017856]
	Learning Rate: 0.000178564
	LOSS [training: 0.1001657262410476 | validation: 0.27996207242964166]
	TIME [epoch: 19.2 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10785427527187047		[learning rate: 0.00017772]
	Learning Rate: 0.000177723
	LOSS [training: 0.10785427527187047 | validation: 0.2773907451284924]
	TIME [epoch: 19.2 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10875343697175172		[learning rate: 0.00017689]
	Learning Rate: 0.000176886
	LOSS [training: 0.10875343697175172 | validation: 0.2707340190899446]
	TIME [epoch: 19.2 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09855382130502399		[learning rate: 0.00017605]
	Learning Rate: 0.000176052
	LOSS [training: 0.09855382130502399 | validation: 0.2724874309890949]
	TIME [epoch: 19.1 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11233041804594378		[learning rate: 0.00017522]
	Learning Rate: 0.000175222
	LOSS [training: 0.11233041804594378 | validation: 0.27688238633625933]
	TIME [epoch: 19.2 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11324547433062135		[learning rate: 0.0001744]
	Learning Rate: 0.000174397
	LOSS [training: 0.11324547433062135 | validation: 0.2794403888427807]
	TIME [epoch: 19.2 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10248529446461326		[learning rate: 0.00017358]
	Learning Rate: 0.000173575
	LOSS [training: 0.10248529446461326 | validation: 0.28417205767773834]
	TIME [epoch: 19.2 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10103764971349985		[learning rate: 0.00017276]
	Learning Rate: 0.000172757
	LOSS [training: 0.10103764971349985 | validation: 0.2735610474982765]
	TIME [epoch: 19.2 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11176471288995511		[learning rate: 0.00017194]
	Learning Rate: 0.000171943
	LOSS [training: 0.11176471288995511 | validation: 0.27532780216013497]
	TIME [epoch: 19.2 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10917720174073986		[learning rate: 0.00017113]
	Learning Rate: 0.000171133
	LOSS [training: 0.10917720174073986 | validation: 0.27690425101775423]
	TIME [epoch: 19.2 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09678116689111356		[learning rate: 0.00017033]
	Learning Rate: 0.000170326
	LOSS [training: 0.09678116689111356 | validation: 0.27754632695734976]
	TIME [epoch: 19.1 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09915484275827853		[learning rate: 0.00016952]
	Learning Rate: 0.000169524
	LOSS [training: 0.09915484275827853 | validation: 0.27798591061916056]
	TIME [epoch: 19.2 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11727450558023142		[learning rate: 0.00016873]
	Learning Rate: 0.000168725
	LOSS [training: 0.11727450558023142 | validation: 0.2717144404747083]
	TIME [epoch: 19.2 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10152397948280618		[learning rate: 0.00016793]
	Learning Rate: 0.00016793
	LOSS [training: 0.10152397948280618 | validation: 0.2694352595828305]
	TIME [epoch: 19.2 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11642388023427878		[learning rate: 0.00016714]
	Learning Rate: 0.000167139
	LOSS [training: 0.11642388023427878 | validation: 0.2790476353182462]
	TIME [epoch: 19.2 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09184047682736239		[learning rate: 0.00016635]
	Learning Rate: 0.000166351
	LOSS [training: 0.09184047682736239 | validation: 0.27040942035157356]
	TIME [epoch: 19.2 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09646812926049862		[learning rate: 0.00016557]
	Learning Rate: 0.000165567
	LOSS [training: 0.09646812926049862 | validation: 0.27237074477985235]
	TIME [epoch: 19.2 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09875220988835524		[learning rate: 0.00016479]
	Learning Rate: 0.000164787
	LOSS [training: 0.09875220988835524 | validation: 0.27177685015324565]
	TIME [epoch: 19.2 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09690032401658676		[learning rate: 0.00016401]
	Learning Rate: 0.000164011
	LOSS [training: 0.09690032401658676 | validation: 0.2737413976185374]
	TIME [epoch: 19.2 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09932412201891105		[learning rate: 0.00016324]
	Learning Rate: 0.000163238
	LOSS [training: 0.09932412201891105 | validation: 0.27009405338806186]
	TIME [epoch: 19.2 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10565162167861047		[learning rate: 0.00016247]
	Learning Rate: 0.000162468
	LOSS [training: 0.10565162167861047 | validation: 0.2658817569516245]
	TIME [epoch: 19.2 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10412773512508926		[learning rate: 0.0001617]
	Learning Rate: 0.000161703
	LOSS [training: 0.10412773512508926 | validation: 0.2762640452548286]
	TIME [epoch: 19.2 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10983350561612752		[learning rate: 0.00016094]
	Learning Rate: 0.000160941
	LOSS [training: 0.10983350561612752 | validation: 0.2785971285929583]
	TIME [epoch: 19.2 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10430239953269561		[learning rate: 0.00016018]
	Learning Rate: 0.000160183
	LOSS [training: 0.10430239953269561 | validation: 0.27100738121757645]
	TIME [epoch: 19.2 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10341796306677009		[learning rate: 0.00015943]
	Learning Rate: 0.000159428
	LOSS [training: 0.10341796306677009 | validation: 0.2844634167781103]
	TIME [epoch: 19.2 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09546276903727034		[learning rate: 0.00015868]
	Learning Rate: 0.000158677
	LOSS [training: 0.09546276903727034 | validation: 0.2706898149608466]
	TIME [epoch: 19.2 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10539783307961353		[learning rate: 0.00015793]
	Learning Rate: 0.000157929
	LOSS [training: 0.10539783307961353 | validation: 0.2760771441941735]
	TIME [epoch: 19.2 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10347761622287807		[learning rate: 0.00015718]
	Learning Rate: 0.000157185
	LOSS [training: 0.10347761622287807 | validation: 0.27895792528753405]
	TIME [epoch: 19.2 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1146968536051637		[learning rate: 0.00015644]
	Learning Rate: 0.000156444
	LOSS [training: 0.1146968536051637 | validation: 0.2836475305320171]
	TIME [epoch: 19.2 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09622415086782192		[learning rate: 0.00015571]
	Learning Rate: 0.000155707
	LOSS [training: 0.09622415086782192 | validation: 0.27497522742792146]
	TIME [epoch: 19.2 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10879091991683089		[learning rate: 0.00015497]
	Learning Rate: 0.000154973
	LOSS [training: 0.10879091991683089 | validation: 0.2763947129587809]
	TIME [epoch: 19.2 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10249206312555792		[learning rate: 0.00015424]
	Learning Rate: 0.000154243
	LOSS [training: 0.10249206312555792 | validation: 0.27754310051607195]
	TIME [epoch: 19.1 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10750629105604471		[learning rate: 0.00015352]
	Learning Rate: 0.000153516
	LOSS [training: 0.10750629105604471 | validation: 0.2778761093217683]
	TIME [epoch: 19.2 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10357911073095485		[learning rate: 0.00015279]
	Learning Rate: 0.000152793
	LOSS [training: 0.10357911073095485 | validation: 0.26490064382570866]
	TIME [epoch: 19.2 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0990846227204873		[learning rate: 0.00015207]
	Learning Rate: 0.000152073
	LOSS [training: 0.0990846227204873 | validation: 0.2717059496728532]
	TIME [epoch: 19.2 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11009419924715733		[learning rate: 0.00015136]
	Learning Rate: 0.000151356
	LOSS [training: 0.11009419924715733 | validation: 0.26826353627123173]
	TIME [epoch: 19.2 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09187700893732079		[learning rate: 0.00015064]
	Learning Rate: 0.000150643
	LOSS [training: 0.09187700893732079 | validation: 0.26180173053095074]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_926.pth
	Model improved!!!
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10145103841502717		[learning rate: 0.00014993]
	Learning Rate: 0.000149933
	LOSS [training: 0.10145103841502717 | validation: 0.2759281272202211]
	TIME [epoch: 19.2 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11041136185472712		[learning rate: 0.00014923]
	Learning Rate: 0.000149227
	LOSS [training: 0.11041136185472712 | validation: 0.2671084269623191]
	TIME [epoch: 19.2 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11143850794761535		[learning rate: 0.00014852]
	Learning Rate: 0.000148523
	LOSS [training: 0.11143850794761535 | validation: 0.27858880624727206]
	TIME [epoch: 19.2 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09658742431782957		[learning rate: 0.00014782]
	Learning Rate: 0.000147824
	LOSS [training: 0.09658742431782957 | validation: 0.2738042598748298]
	TIME [epoch: 19.2 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09924082945392411		[learning rate: 0.00014713]
	Learning Rate: 0.000147127
	LOSS [training: 0.09924082945392411 | validation: 0.27724056783316514]
	TIME [epoch: 19.2 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10022601669318312		[learning rate: 0.00014643]
	Learning Rate: 0.000146434
	LOSS [training: 0.10022601669318312 | validation: 0.27259538671965006]
	TIME [epoch: 19.2 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10168170304259541		[learning rate: 0.00014574]
	Learning Rate: 0.000145744
	LOSS [training: 0.10168170304259541 | validation: 0.2729595772281294]
	TIME [epoch: 19.2 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10477187363269148		[learning rate: 0.00014506]
	Learning Rate: 0.000145057
	LOSS [training: 0.10477187363269148 | validation: 0.2818331425392595]
	TIME [epoch: 19.2 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09481915482483044		[learning rate: 0.00014437]
	Learning Rate: 0.000144373
	LOSS [training: 0.09481915482483044 | validation: 0.2684104288078366]
	TIME [epoch: 19.2 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09963767231379718		[learning rate: 0.00014369]
	Learning Rate: 0.000143693
	LOSS [training: 0.09963767231379718 | validation: 0.26604393464162324]
	TIME [epoch: 19.2 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09590218482099301		[learning rate: 0.00014302]
	Learning Rate: 0.000143016
	LOSS [training: 0.09590218482099301 | validation: 0.2704450902368569]
	TIME [epoch: 19.2 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09894558306222438		[learning rate: 0.00014234]
	Learning Rate: 0.000142342
	LOSS [training: 0.09894558306222438 | validation: 0.27373857906389076]
	TIME [epoch: 19.2 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10430151029776406		[learning rate: 0.00014167]
	Learning Rate: 0.000141671
	LOSS [training: 0.10430151029776406 | validation: 0.27190918639729905]
	TIME [epoch: 19.2 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0935586854025781		[learning rate: 0.000141]
	Learning Rate: 0.000141004
	LOSS [training: 0.0935586854025781 | validation: 0.2742000825925572]
	TIME [epoch: 19.2 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09328610603425724		[learning rate: 0.00014034]
	Learning Rate: 0.000140339
	LOSS [training: 0.09328610603425724 | validation: 0.2852380385123498]
	TIME [epoch: 19.2 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11032034028361509		[learning rate: 0.00013968]
	Learning Rate: 0.000139678
	LOSS [training: 0.11032034028361509 | validation: 0.27926393236894165]
	TIME [epoch: 19.2 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10389778780356743		[learning rate: 0.00013902]
	Learning Rate: 0.00013902
	LOSS [training: 0.10389778780356743 | validation: 0.28419704810845947]
	TIME [epoch: 19.2 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11061520102509954		[learning rate: 0.00013836]
	Learning Rate: 0.000138365
	LOSS [training: 0.11061520102509954 | validation: 0.2703397957022716]
	TIME [epoch: 19.2 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09446179494338931		[learning rate: 0.00013771]
	Learning Rate: 0.000137713
	LOSS [training: 0.09446179494338931 | validation: 0.284302010138445]
	TIME [epoch: 19.2 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11004312144217274		[learning rate: 0.00013706]
	Learning Rate: 0.000137064
	LOSS [training: 0.11004312144217274 | validation: 0.28072195787151555]
	TIME [epoch: 19.2 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10867020607685425		[learning rate: 0.00013642]
	Learning Rate: 0.000136418
	LOSS [training: 0.10867020607685425 | validation: 0.2728049009814929]
	TIME [epoch: 19.2 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11776227949196469		[learning rate: 0.00013578]
	Learning Rate: 0.000135775
	LOSS [training: 0.11776227949196469 | validation: 0.2733435383964119]
	TIME [epoch: 19.2 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10004344394331557		[learning rate: 0.00013514]
	Learning Rate: 0.000135135
	LOSS [training: 0.10004344394331557 | validation: 0.2695756924816275]
	TIME [epoch: 19.2 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09020568729879283		[learning rate: 0.0001345]
	Learning Rate: 0.000134499
	LOSS [training: 0.09020568729879283 | validation: 0.2793616548918862]
	TIME [epoch: 19.2 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0918881465388056		[learning rate: 0.00013386]
	Learning Rate: 0.000133865
	LOSS [training: 0.0918881465388056 | validation: 0.28110836999437167]
	TIME [epoch: 19.2 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11886556376910926		[learning rate: 0.00013323]
	Learning Rate: 0.000133234
	LOSS [training: 0.11886556376910926 | validation: 0.2823082786612861]
	TIME [epoch: 19.2 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1086612532073112		[learning rate: 0.00013261]
	Learning Rate: 0.000132606
	LOSS [training: 0.1086612532073112 | validation: 0.27257050137637984]
	TIME [epoch: 19.2 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11885032903209727		[learning rate: 0.00013198]
	Learning Rate: 0.000131981
	LOSS [training: 0.11885032903209727 | validation: 0.2693445154980275]
	TIME [epoch: 19.2 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09940756559881703		[learning rate: 0.00013136]
	Learning Rate: 0.000131359
	LOSS [training: 0.09940756559881703 | validation: 0.2721377149656037]
	TIME [epoch: 19.2 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10749742519167971		[learning rate: 0.00013074]
	Learning Rate: 0.000130741
	LOSS [training: 0.10749742519167971 | validation: 0.26710082311902156]
	TIME [epoch: 19.2 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09934631891784523		[learning rate: 0.00013012]
	Learning Rate: 0.000130124
	LOSS [training: 0.09934631891784523 | validation: 0.2754557380552346]
	TIME [epoch: 19.2 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09884797371792306		[learning rate: 0.00012951]
	Learning Rate: 0.000129511
	LOSS [training: 0.09884797371792306 | validation: 0.27452236800656143]
	TIME [epoch: 19.2 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10543231580962584		[learning rate: 0.0001289]
	Learning Rate: 0.000128901
	LOSS [training: 0.10543231580962584 | validation: 0.26795888568682036]
	TIME [epoch: 19.2 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11208746165471918		[learning rate: 0.00012829]
	Learning Rate: 0.000128294
	LOSS [training: 0.11208746165471918 | validation: 0.2688633207839674]
	TIME [epoch: 19.2 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11698181166370034		[learning rate: 0.00012769]
	Learning Rate: 0.000127689
	LOSS [training: 0.11698181166370034 | validation: 0.2720425044179038]
	TIME [epoch: 19.2 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11339415089662855		[learning rate: 0.00012709]
	Learning Rate: 0.000127087
	LOSS [training: 0.11339415089662855 | validation: 0.27055540871844125]
	TIME [epoch: 19.2 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09822679587802183		[learning rate: 0.00012649]
	Learning Rate: 0.000126489
	LOSS [training: 0.09822679587802183 | validation: 0.272184296082825]
	TIME [epoch: 19.2 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09845236885872738		[learning rate: 0.00012589]
	Learning Rate: 0.000125893
	LOSS [training: 0.09845236885872738 | validation: 0.2776467987039494]
	TIME [epoch: 19.2 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10370920238372464		[learning rate: 0.0001253]
	Learning Rate: 0.000125299
	LOSS [training: 0.10370920238372464 | validation: 0.27282683728954343]
	TIME [epoch: 19.2 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10038459891392751		[learning rate: 0.00012471]
	Learning Rate: 0.000124709
	LOSS [training: 0.10038459891392751 | validation: 0.2707469630418439]
	TIME [epoch: 19.2 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1194611630358054		[learning rate: 0.00012412]
	Learning Rate: 0.000124121
	LOSS [training: 0.1194611630358054 | validation: 0.27164124018770713]
	TIME [epoch: 19.2 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10039990559243968		[learning rate: 0.00012354]
	Learning Rate: 0.000123536
	LOSS [training: 0.10039990559243968 | validation: 0.26742741418288124]
	TIME [epoch: 19.2 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09884920996569227		[learning rate: 0.00012295]
	Learning Rate: 0.000122954
	LOSS [training: 0.09884920996569227 | validation: 0.27441232019257694]
	TIME [epoch: 19.2 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10674287444324701		[learning rate: 0.00012237]
	Learning Rate: 0.000122375
	LOSS [training: 0.10674287444324701 | validation: 0.2681836409282372]
	TIME [epoch: 19.2 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10000080598104534		[learning rate: 0.0001218]
	Learning Rate: 0.000121798
	LOSS [training: 0.10000080598104534 | validation: 0.26818937010241245]
	TIME [epoch: 19.2 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11345891076478254		[learning rate: 0.00012122]
	Learning Rate: 0.000121224
	LOSS [training: 0.11345891076478254 | validation: 0.27333873487538213]
	TIME [epoch: 19.2 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09925717872749362		[learning rate: 0.00012065]
	Learning Rate: 0.000120653
	LOSS [training: 0.09925717872749362 | validation: 0.2659878871164722]
	TIME [epoch: 19.2 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1032224528398844		[learning rate: 0.00012008]
	Learning Rate: 0.000120085
	LOSS [training: 0.1032224528398844 | validation: 0.2849976003427853]
	TIME [epoch: 19.2 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10079733654796097		[learning rate: 0.00011952]
	Learning Rate: 0.000119519
	LOSS [training: 0.10079733654796097 | validation: 0.2711585246343826]
	TIME [epoch: 19.2 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10564926915868261		[learning rate: 0.00011896]
	Learning Rate: 0.000118956
	LOSS [training: 0.10564926915868261 | validation: 0.2817353342104193]
	TIME [epoch: 19.2 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10242733181368907		[learning rate: 0.00011839]
	Learning Rate: 0.000118395
	LOSS [training: 0.10242733181368907 | validation: 0.27308591381185643]
	TIME [epoch: 19.2 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12238400755693413		[learning rate: 0.00011784]
	Learning Rate: 0.000117837
	LOSS [training: 0.12238400755693413 | validation: 0.2688345070211912]
	TIME [epoch: 19.2 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10396486795067271		[learning rate: 0.00011728]
	Learning Rate: 0.000117282
	LOSS [training: 0.10396486795067271 | validation: 0.2843471960039663]
	TIME [epoch: 19.2 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10329774942160037		[learning rate: 0.00011673]
	Learning Rate: 0.000116729
	LOSS [training: 0.10329774942160037 | validation: 0.26572718623984803]
	TIME [epoch: 19.2 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.103000836561081		[learning rate: 0.00011618]
	Learning Rate: 0.000116179
	LOSS [training: 0.103000836561081 | validation: 0.2643098071490491]
	TIME [epoch: 19.2 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09987865298377059		[learning rate: 0.00011563]
	Learning Rate: 0.000115632
	LOSS [training: 0.09987865298377059 | validation: 0.27669536054661614]
	TIME [epoch: 19.2 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10277443161889616		[learning rate: 0.00011509]
	Learning Rate: 0.000115087
	LOSS [training: 0.10277443161889616 | validation: 0.2740713745241017]
	TIME [epoch: 19.2 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0949764065744964		[learning rate: 0.00011454]
	Learning Rate: 0.000114545
	LOSS [training: 0.0949764065744964 | validation: 0.27198815517395586]
	TIME [epoch: 19.1 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09849259974568689		[learning rate: 0.000114]
	Learning Rate: 0.000114005
	LOSS [training: 0.09849259974568689 | validation: 0.2707878784609729]
	TIME [epoch: 19.2 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13002279330938113		[learning rate: 0.00011347]
	Learning Rate: 0.000113468
	LOSS [training: 0.13002279330938113 | validation: 0.28100967847597896]
	TIME [epoch: 19.2 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12862397398374542		[learning rate: 0.00011293]
	Learning Rate: 0.000112933
	LOSS [training: 0.12862397398374542 | validation: 0.2716074999106292]
	TIME [epoch: 19.2 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12800229209086134		[learning rate: 0.0001124]
	Learning Rate: 0.000112401
	LOSS [training: 0.12800229209086134 | validation: 0.26305954791627006]
	TIME [epoch: 19.2 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10264357971549953		[learning rate: 0.00011187]
	Learning Rate: 0.000111871
	LOSS [training: 0.10264357971549953 | validation: 0.2747132766753232]
	TIME [epoch: 19.2 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10148363717486684		[learning rate: 0.00011134]
	Learning Rate: 0.000111344
	LOSS [training: 0.10148363717486684 | validation: 0.26732332023131894]
	TIME [epoch: 19.2 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10032196384101691		[learning rate: 0.00011082]
	Learning Rate: 0.000110819
	LOSS [training: 0.10032196384101691 | validation: 0.28079480426680137]
	TIME [epoch: 19.2 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09104534955363941		[learning rate: 0.0001103]
	Learning Rate: 0.000110297
	LOSS [training: 0.09104534955363941 | validation: 0.2615271370189173]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_992.pth
	Model improved!!!
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09852635481503375		[learning rate: 0.00010978]
	Learning Rate: 0.000109777
	LOSS [training: 0.09852635481503375 | validation: 0.2745642547777535]
	TIME [epoch: 19.2 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10415546605745109		[learning rate: 0.00010926]
	Learning Rate: 0.00010926
	LOSS [training: 0.10415546605745109 | validation: 0.27259542269214415]
	TIME [epoch: 19.2 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10556918587588086		[learning rate: 0.00010875]
	Learning Rate: 0.000108745
	LOSS [training: 0.10556918587588086 | validation: 0.27078474245335643]
	TIME [epoch: 19.2 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10065812657358522		[learning rate: 0.00010823]
	Learning Rate: 0.000108233
	LOSS [training: 0.10065812657358522 | validation: 0.28874539173148545]
	TIME [epoch: 19.2 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09218108400662656		[learning rate: 0.00010772]
	Learning Rate: 0.000107723
	LOSS [training: 0.09218108400662656 | validation: 0.2707325677166545]
	TIME [epoch: 19.2 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10670651825255098		[learning rate: 0.00010722]
	Learning Rate: 0.000107215
	LOSS [training: 0.10670651825255098 | validation: 0.2663252732613532]
	TIME [epoch: 19.2 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1153558164173728		[learning rate: 0.00010671]
	Learning Rate: 0.00010671
	LOSS [training: 0.1153558164173728 | validation: 0.2751949848415216]
	TIME [epoch: 19.2 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11672487653067778		[learning rate: 0.00010621]
	Learning Rate: 0.000106207
	LOSS [training: 0.11672487653067778 | validation: 0.27043277007912425]
	TIME [epoch: 19.2 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11289556781592128		[learning rate: 0.00010571]
	Learning Rate: 0.000105707
	LOSS [training: 0.11289556781592128 | validation: 0.26687254251186016]
	TIME [epoch: 68.5 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10104859038774616		[learning rate: 0.00010521]
	Learning Rate: 0.000105209
	LOSS [training: 0.10104859038774616 | validation: 0.26675321117181666]
	TIME [epoch: 41 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11028240334454972		[learning rate: 0.00010471]
	Learning Rate: 0.000104713
	LOSS [training: 0.11028240334454972 | validation: 0.27842296377300074]
	TIME [epoch: 41 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09992178032378267		[learning rate: 0.00010422]
	Learning Rate: 0.000104219
	LOSS [training: 0.09992178032378267 | validation: 0.27406449492553187]
	TIME [epoch: 41 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11592790655661867		[learning rate: 0.00010373]
	Learning Rate: 0.000103728
	LOSS [training: 0.11592790655661867 | validation: 0.27130318433341566]
	TIME [epoch: 40.9 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08960571706160138		[learning rate: 0.00010324]
	Learning Rate: 0.00010324
	LOSS [training: 0.08960571706160138 | validation: 0.267563496398712]
	TIME [epoch: 40.9 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09568059838492254		[learning rate: 0.00010275]
	Learning Rate: 0.000102753
	LOSS [training: 0.09568059838492254 | validation: 0.26912230952208155]
	TIME [epoch: 41 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10806558734603827		[learning rate: 0.00010227]
	Learning Rate: 0.000102269
	LOSS [training: 0.10806558734603827 | validation: 0.2786037293280431]
	TIME [epoch: 41 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10423400927579038		[learning rate: 0.00010179]
	Learning Rate: 0.000101787
	LOSS [training: 0.10423400927579038 | validation: 0.28310751871762113]
	TIME [epoch: 41 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11247222059113823		[learning rate: 0.00010131]
	Learning Rate: 0.000101307
	LOSS [training: 0.11247222059113823 | validation: 0.2717168871388471]
	TIME [epoch: 41 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10490389850473777		[learning rate: 0.00010083]
	Learning Rate: 0.00010083
	LOSS [training: 0.10490389850473777 | validation: 0.27057704536652655]
	TIME [epoch: 41 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10521681009920933		[learning rate: 0.00010035]
	Learning Rate: 0.000100355
	LOSS [training: 0.10521681009920933 | validation: 0.27200964795205795]
	TIME [epoch: 41 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1118710472567599		[learning rate: 9.9882e-05]
	Learning Rate: 9.9882e-05
	LOSS [training: 0.1118710472567599 | validation: 0.2782478057960578]
	TIME [epoch: 41 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10867268217136647		[learning rate: 9.9411e-05]
	Learning Rate: 9.94113e-05
	LOSS [training: 0.10867268217136647 | validation: 0.27329993448688816]
	TIME [epoch: 41 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09852288038543802		[learning rate: 9.8943e-05]
	Learning Rate: 9.89429e-05
	LOSS [training: 0.09852288038543802 | validation: 0.26851656487573433]
	TIME [epoch: 41 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09442599424798426		[learning rate: 9.8477e-05]
	Learning Rate: 9.84767e-05
	LOSS [training: 0.09442599424798426 | validation: 0.2811161132573331]
	TIME [epoch: 41 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11129653753190981		[learning rate: 9.8013e-05]
	Learning Rate: 9.80126e-05
	LOSS [training: 0.11129653753190981 | validation: 0.2735336299462995]
	TIME [epoch: 41 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10296551020976108		[learning rate: 9.7551e-05]
	Learning Rate: 9.75508e-05
	LOSS [training: 0.10296551020976108 | validation: 0.2712247745721255]
	TIME [epoch: 41 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10401467548515222		[learning rate: 9.7091e-05]
	Learning Rate: 9.70911e-05
	LOSS [training: 0.10401467548515222 | validation: 0.27021099761078654]
	TIME [epoch: 41 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1134110201220051		[learning rate: 9.6634e-05]
	Learning Rate: 9.66336e-05
	LOSS [training: 0.1134110201220051 | validation: 0.25825318588100254]
	TIME [epoch: 41 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_1020.pth
	Model improved!!!
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10169529160972446		[learning rate: 9.6178e-05]
	Learning Rate: 9.61783e-05
	LOSS [training: 0.10169529160972446 | validation: 0.2760373947627493]
	TIME [epoch: 41 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09118860568985263		[learning rate: 9.5725e-05]
	Learning Rate: 9.57251e-05
	LOSS [training: 0.09118860568985263 | validation: 0.2772367851103281]
	TIME [epoch: 41 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10611544815630733		[learning rate: 9.5274e-05]
	Learning Rate: 9.5274e-05
	LOSS [training: 0.10611544815630733 | validation: 0.270070130649121]
	TIME [epoch: 41 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10430288523878826		[learning rate: 9.4825e-05]
	Learning Rate: 9.48251e-05
	LOSS [training: 0.10430288523878826 | validation: 0.2726867734484067]
	TIME [epoch: 41 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10443520114197036		[learning rate: 9.4378e-05]
	Learning Rate: 9.43782e-05
	LOSS [training: 0.10443520114197036 | validation: 0.26690176924707126]
	TIME [epoch: 41 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10459166777276341		[learning rate: 9.3934e-05]
	Learning Rate: 9.39335e-05
	LOSS [training: 0.10459166777276341 | validation: 0.27740846237330274]
	TIME [epoch: 41 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12551476710126583		[learning rate: 9.3491e-05]
	Learning Rate: 9.34909e-05
	LOSS [training: 0.12551476710126583 | validation: 0.2636113937933095]
	TIME [epoch: 41 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10608974477962377		[learning rate: 9.305e-05]
	Learning Rate: 9.30504e-05
	LOSS [training: 0.10608974477962377 | validation: 0.273227289612707]
	TIME [epoch: 41 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11205206654718344		[learning rate: 9.2612e-05]
	Learning Rate: 9.26119e-05
	LOSS [training: 0.11205206654718344 | validation: 0.2773010622103272]
	TIME [epoch: 41 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10146082627749761		[learning rate: 9.2175e-05]
	Learning Rate: 9.21755e-05
	LOSS [training: 0.10146082627749761 | validation: 0.27033494390125024]
	TIME [epoch: 41 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10320725029925193		[learning rate: 9.1741e-05]
	Learning Rate: 9.17411e-05
	LOSS [training: 0.10320725029925193 | validation: 0.2692088676359565]
	TIME [epoch: 41 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09679268833805608		[learning rate: 9.1309e-05]
	Learning Rate: 9.13088e-05
	LOSS [training: 0.09679268833805608 | validation: 0.26885672891394635]
	TIME [epoch: 41 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11455592499481435		[learning rate: 9.0879e-05]
	Learning Rate: 9.08786e-05
	LOSS [training: 0.11455592499481435 | validation: 0.27185657881418523]
	TIME [epoch: 41 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09359136070430489		[learning rate: 9.045e-05]
	Learning Rate: 9.04504e-05
	LOSS [training: 0.09359136070430489 | validation: 0.2658519925883704]
	TIME [epoch: 40.9 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09380197717935636		[learning rate: 9.0024e-05]
	Learning Rate: 9.00241e-05
	LOSS [training: 0.09380197717935636 | validation: 0.2747329528633651]
	TIME [epoch: 40.9 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10998606925503429		[learning rate: 8.96e-05]
	Learning Rate: 8.96e-05
	LOSS [training: 0.10998606925503429 | validation: 0.26760944401931225]
	TIME [epoch: 40.9 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09911074099539621		[learning rate: 8.9178e-05]
	Learning Rate: 8.91777e-05
	LOSS [training: 0.09911074099539621 | validation: 0.2712785917964635]
	TIME [epoch: 40.9 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11169408935964394		[learning rate: 8.8758e-05]
	Learning Rate: 8.87575e-05
	LOSS [training: 0.11169408935964394 | validation: 0.26307313736827787]
	TIME [epoch: 40.9 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12257713504309209		[learning rate: 8.8339e-05]
	Learning Rate: 8.83393e-05
	LOSS [training: 0.12257713504309209 | validation: 0.2587125846623051]
	TIME [epoch: 40.9 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12523410323492612		[learning rate: 8.7923e-05]
	Learning Rate: 8.7923e-05
	LOSS [training: 0.12523410323492612 | validation: 0.2742976029201233]
	TIME [epoch: 41 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10599820835651799		[learning rate: 8.7509e-05]
	Learning Rate: 8.75087e-05
	LOSS [training: 0.10599820835651799 | validation: 0.2775507211333378]
	TIME [epoch: 40.9 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09631786703272706		[learning rate: 8.7096e-05]
	Learning Rate: 8.70964e-05
	LOSS [training: 0.09631786703272706 | validation: 0.27725402240835545]
	TIME [epoch: 40.9 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09923702501359458		[learning rate: 8.6686e-05]
	Learning Rate: 8.6686e-05
	LOSS [training: 0.09923702501359458 | validation: 0.27873674761325784]
	TIME [epoch: 40.9 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09875978890223165		[learning rate: 8.6277e-05]
	Learning Rate: 8.62775e-05
	LOSS [training: 0.09875978890223165 | validation: 0.26879458053155886]
	TIME [epoch: 40.9 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1060728927015317		[learning rate: 8.5871e-05]
	Learning Rate: 8.58709e-05
	LOSS [training: 0.1060728927015317 | validation: 0.26835557064853444]
	TIME [epoch: 40.9 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10279087450960775		[learning rate: 8.5466e-05]
	Learning Rate: 8.54663e-05
	LOSS [training: 0.10279087450960775 | validation: 0.25613349616990727]
	TIME [epoch: 41 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_1046.pth
	Model improved!!!
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09666113594542196		[learning rate: 8.5064e-05]
	Learning Rate: 8.50636e-05
	LOSS [training: 0.09666113594542196 | validation: 0.2790781973598562]
	TIME [epoch: 41 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11512910180926385		[learning rate: 8.4663e-05]
	Learning Rate: 8.46628e-05
	LOSS [training: 0.11512910180926385 | validation: 0.2765132916455969]
	TIME [epoch: 40.9 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10688054572636109		[learning rate: 8.4264e-05]
	Learning Rate: 8.42638e-05
	LOSS [training: 0.10688054572636109 | validation: 0.27486098986442187]
	TIME [epoch: 40.9 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09859989701396438		[learning rate: 8.3867e-05]
	Learning Rate: 8.38667e-05
	LOSS [training: 0.09859989701396438 | validation: 0.27448665815203555]
	TIME [epoch: 41 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11303239589223275		[learning rate: 8.3472e-05]
	Learning Rate: 8.34716e-05
	LOSS [training: 0.11303239589223275 | validation: 0.2697239223556512]
	TIME [epoch: 40.9 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1049307700923484		[learning rate: 8.3078e-05]
	Learning Rate: 8.30782e-05
	LOSS [training: 0.1049307700923484 | validation: 0.26790123107643726]
	TIME [epoch: 41 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11174568361334923		[learning rate: 8.2687e-05]
	Learning Rate: 8.26868e-05
	LOSS [training: 0.11174568361334923 | validation: 0.2636837121140102]
	TIME [epoch: 41 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10482382177322017		[learning rate: 8.2297e-05]
	Learning Rate: 8.22971e-05
	LOSS [training: 0.10482382177322017 | validation: 0.2739100712230077]
	TIME [epoch: 40.9 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10296186052921036		[learning rate: 8.1909e-05]
	Learning Rate: 8.19093e-05
	LOSS [training: 0.10296186052921036 | validation: 0.2643534871138962]
	TIME [epoch: 40.9 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09339143653099817		[learning rate: 8.1523e-05]
	Learning Rate: 8.15234e-05
	LOSS [training: 0.09339143653099817 | validation: 0.2617478842107822]
	TIME [epoch: 40.9 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11559506608836963		[learning rate: 8.1139e-05]
	Learning Rate: 8.11392e-05
	LOSS [training: 0.11559506608836963 | validation: 0.2659045026544014]
	TIME [epoch: 40.9 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11777726048457703		[learning rate: 8.0757e-05]
	Learning Rate: 8.07569e-05
	LOSS [training: 0.11777726048457703 | validation: 0.27101909105210137]
	TIME [epoch: 40.9 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1001675218468701		[learning rate: 8.0376e-05]
	Learning Rate: 8.03763e-05
	LOSS [training: 0.1001675218468701 | validation: 0.27390324838596647]
	TIME [epoch: 41 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09777259345593925		[learning rate: 7.9998e-05]
	Learning Rate: 7.99976e-05
	LOSS [training: 0.09777259345593925 | validation: 0.27141185972493176]
	TIME [epoch: 40.9 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10276319170913333		[learning rate: 7.9621e-05]
	Learning Rate: 7.96206e-05
	LOSS [training: 0.10276319170913333 | validation: 0.26862166463332326]
	TIME [epoch: 40.9 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11893254633359505		[learning rate: 7.9245e-05]
	Learning Rate: 7.92455e-05
	LOSS [training: 0.11893254633359505 | validation: 0.2718449982491109]
	TIME [epoch: 40.9 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1005032572177739		[learning rate: 7.8872e-05]
	Learning Rate: 7.8872e-05
	LOSS [training: 0.1005032572177739 | validation: 0.26813746681771766]
	TIME [epoch: 40.9 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10079381226509378		[learning rate: 7.85e-05]
	Learning Rate: 7.85004e-05
	LOSS [training: 0.10079381226509378 | validation: 0.2714588272022575]
	TIME [epoch: 40.9 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10628470052270299		[learning rate: 7.813e-05]
	Learning Rate: 7.81305e-05
	LOSS [training: 0.10628470052270299 | validation: 0.27596719056026797]
	TIME [epoch: 41 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09884807508967622		[learning rate: 7.7762e-05]
	Learning Rate: 7.77623e-05
	LOSS [training: 0.09884807508967622 | validation: 0.2712409880865121]
	TIME [epoch: 40.9 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09176691990843347		[learning rate: 7.7396e-05]
	Learning Rate: 7.73959e-05
	LOSS [training: 0.09176691990843347 | validation: 0.27559815185976405]
	TIME [epoch: 40.9 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10554215767906394		[learning rate: 7.7031e-05]
	Learning Rate: 7.70312e-05
	LOSS [training: 0.10554215767906394 | validation: 0.2685652753579285]
	TIME [epoch: 40.9 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09775280522268522		[learning rate: 7.6668e-05]
	Learning Rate: 7.66682e-05
	LOSS [training: 0.09775280522268522 | validation: 0.26606550246008986]
	TIME [epoch: 40.9 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0960757469636181		[learning rate: 7.6307e-05]
	Learning Rate: 7.63069e-05
	LOSS [training: 0.0960757469636181 | validation: 0.27106342370619546]
	TIME [epoch: 40.9 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10917313418920438		[learning rate: 7.5947e-05]
	Learning Rate: 7.59474e-05
	LOSS [training: 0.10917313418920438 | validation: 0.267491179742146]
	TIME [epoch: 41 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09479111434896223		[learning rate: 7.559e-05]
	Learning Rate: 7.55895e-05
	LOSS [training: 0.09479111434896223 | validation: 0.2704266223918738]
	TIME [epoch: 40.9 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09975510561635915		[learning rate: 7.5233e-05]
	Learning Rate: 7.52333e-05
	LOSS [training: 0.09975510561635915 | validation: 0.2662314052910291]
	TIME [epoch: 41 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11423395487443633		[learning rate: 7.4879e-05]
	Learning Rate: 7.48788e-05
	LOSS [training: 0.11423395487443633 | validation: 0.2743488081250677]
	TIME [epoch: 40.9 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10102590574012138		[learning rate: 7.4526e-05]
	Learning Rate: 7.4526e-05
	LOSS [training: 0.10102590574012138 | validation: 0.2780122108148375]
	TIME [epoch: 41 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11078709643859538		[learning rate: 7.4175e-05]
	Learning Rate: 7.41748e-05
	LOSS [training: 0.11078709643859538 | validation: 0.2649377371009052]
	TIME [epoch: 41 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09589704295856268		[learning rate: 7.3825e-05]
	Learning Rate: 7.38253e-05
	LOSS [training: 0.09589704295856268 | validation: 0.2775315213205979]
	TIME [epoch: 40.9 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10125863355768042		[learning rate: 7.3477e-05]
	Learning Rate: 7.34774e-05
	LOSS [training: 0.10125863355768042 | validation: 0.27622740099348364]
	TIME [epoch: 40.9 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09568527402679516		[learning rate: 7.3131e-05]
	Learning Rate: 7.31312e-05
	LOSS [training: 0.09568527402679516 | validation: 0.262352510409241]
	TIME [epoch: 40.9 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09630915774119392		[learning rate: 7.2787e-05]
	Learning Rate: 7.27866e-05
	LOSS [training: 0.09630915774119392 | validation: 0.2685527354637629]
	TIME [epoch: 40.9 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10374883585617788		[learning rate: 7.2444e-05]
	Learning Rate: 7.24436e-05
	LOSS [training: 0.10374883585617788 | validation: 0.2780402404520416]
	TIME [epoch: 40.9 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09891601793168164		[learning rate: 7.2102e-05]
	Learning Rate: 7.21022e-05
	LOSS [training: 0.09891601793168164 | validation: 0.27433474949510495]
	TIME [epoch: 40.9 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09181876021855218		[learning rate: 7.1762e-05]
	Learning Rate: 7.17625e-05
	LOSS [training: 0.09181876021855218 | validation: 0.2736790769459361]
	TIME [epoch: 40.9 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10832690232410977		[learning rate: 7.1424e-05]
	Learning Rate: 7.14243e-05
	LOSS [training: 0.10832690232410977 | validation: 0.2687844050814087]
	TIME [epoch: 40.9 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09359713407105141		[learning rate: 7.1088e-05]
	Learning Rate: 7.10878e-05
	LOSS [training: 0.09359713407105141 | validation: 0.27568078022380643]
	TIME [epoch: 40.9 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10437289566170695		[learning rate: 7.0753e-05]
	Learning Rate: 7.07528e-05
	LOSS [training: 0.10437289566170695 | validation: 0.2760381891477871]
	TIME [epoch: 41 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09283114849692607		[learning rate: 7.0419e-05]
	Learning Rate: 7.04194e-05
	LOSS [training: 0.09283114849692607 | validation: 0.27588105971679266]
	TIME [epoch: 40.9 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09187667249531117		[learning rate: 7.0088e-05]
	Learning Rate: 7.00876e-05
	LOSS [training: 0.09187667249531117 | validation: 0.27058827033280225]
	TIME [epoch: 40.9 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10801171925063725		[learning rate: 6.9757e-05]
	Learning Rate: 6.97573e-05
	LOSS [training: 0.10801171925063725 | validation: 0.27665894163224497]
	TIME [epoch: 40.9 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12111113489559434		[learning rate: 6.9429e-05]
	Learning Rate: 6.94286e-05
	LOSS [training: 0.12111113489559434 | validation: 0.27417519899742887]
	TIME [epoch: 40.9 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09604013412916079		[learning rate: 6.9101e-05]
	Learning Rate: 6.91015e-05
	LOSS [training: 0.09604013412916079 | validation: 0.27250917779437817]
	TIME [epoch: 41 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12001635628124264		[learning rate: 6.8776e-05]
	Learning Rate: 6.87758e-05
	LOSS [training: 0.12001635628124264 | validation: 0.2669974341918281]
	TIME [epoch: 40.9 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11273397588066097		[learning rate: 6.8452e-05]
	Learning Rate: 6.84518e-05
	LOSS [training: 0.11273397588066097 | validation: 0.27001809616343775]
	TIME [epoch: 40.9 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09733691427230175		[learning rate: 6.8129e-05]
	Learning Rate: 6.81292e-05
	LOSS [training: 0.09733691427230175 | validation: 0.2681663277641323]
	TIME [epoch: 40.9 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09063622140470681		[learning rate: 6.7808e-05]
	Learning Rate: 6.78082e-05
	LOSS [training: 0.09063622140470681 | validation: 0.2709195652844102]
	TIME [epoch: 41 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1097018871153901		[learning rate: 6.7489e-05]
	Learning Rate: 6.74887e-05
	LOSS [training: 0.1097018871153901 | validation: 0.2690636984127162]
	TIME [epoch: 41 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10146381959777911		[learning rate: 6.7171e-05]
	Learning Rate: 6.71706e-05
	LOSS [training: 0.10146381959777911 | validation: 0.2661118076783359]
	TIME [epoch: 40.9 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11003299540407523		[learning rate: 6.6854e-05]
	Learning Rate: 6.68541e-05
	LOSS [training: 0.11003299540407523 | validation: 0.2737580426352159]
	TIME [epoch: 40.9 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09511407378614832		[learning rate: 6.6539e-05]
	Learning Rate: 6.65391e-05
	LOSS [training: 0.09511407378614832 | validation: 0.2697222128545109]
	TIME [epoch: 41 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10300595022395168		[learning rate: 6.6226e-05]
	Learning Rate: 6.62256e-05
	LOSS [training: 0.10300595022395168 | validation: 0.27641660668693047]
	TIME [epoch: 41 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09568443011766961		[learning rate: 6.5914e-05]
	Learning Rate: 6.59135e-05
	LOSS [training: 0.09568443011766961 | validation: 0.2745606241770047]
	TIME [epoch: 41 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10044715263611922		[learning rate: 6.5603e-05]
	Learning Rate: 6.56029e-05
	LOSS [training: 0.10044715263611922 | validation: 0.26689582798088174]
	TIME [epoch: 40.9 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10601200508284439		[learning rate: 6.5294e-05]
	Learning Rate: 6.52938e-05
	LOSS [training: 0.10601200508284439 | validation: 0.2778589004876966]
	TIME [epoch: 40.9 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10707285603975403		[learning rate: 6.4986e-05]
	Learning Rate: 6.49861e-05
	LOSS [training: 0.10707285603975403 | validation: 0.276670637438226]
	TIME [epoch: 40.9 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10917899294061595		[learning rate: 6.468e-05]
	Learning Rate: 6.46799e-05
	LOSS [training: 0.10917899294061595 | validation: 0.27189724860793074]
	TIME [epoch: 40.9 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09614499667827167		[learning rate: 6.4375e-05]
	Learning Rate: 6.43751e-05
	LOSS [training: 0.09614499667827167 | validation: 0.2636256355512164]
	TIME [epoch: 40.9 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10313432244424829		[learning rate: 6.4072e-05]
	Learning Rate: 6.40718e-05
	LOSS [training: 0.10313432244424829 | validation: 0.2707163964014729]
	TIME [epoch: 40.9 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11077978686723186		[learning rate: 6.377e-05]
	Learning Rate: 6.37698e-05
	LOSS [training: 0.11077978686723186 | validation: 0.2634453304042637]
	TIME [epoch: 40.9 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10092620642752666		[learning rate: 6.3469e-05]
	Learning Rate: 6.34694e-05
	LOSS [training: 0.10092620642752666 | validation: 0.27593933643085683]
	TIME [epoch: 40.9 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1238584889574332		[learning rate: 6.317e-05]
	Learning Rate: 6.31703e-05
	LOSS [training: 0.1238584889574332 | validation: 0.270261899524504]
	TIME [epoch: 40.9 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12143547666697793		[learning rate: 6.2873e-05]
	Learning Rate: 6.28726e-05
	LOSS [training: 0.12143547666697793 | validation: 0.2679671954610338]
	TIME [epoch: 40.9 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10425411058857187		[learning rate: 6.2576e-05]
	Learning Rate: 6.25764e-05
	LOSS [training: 0.10425411058857187 | validation: 0.27127084244264105]
	TIME [epoch: 40.9 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11197345537849562		[learning rate: 6.2281e-05]
	Learning Rate: 6.22815e-05
	LOSS [training: 0.11197345537849562 | validation: 0.26631420139383866]
	TIME [epoch: 40.9 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09710204100703194		[learning rate: 6.1988e-05]
	Learning Rate: 6.1988e-05
	LOSS [training: 0.09710204100703194 | validation: 0.2754326127934725]
	TIME [epoch: 40.9 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10334776860463965		[learning rate: 6.1696e-05]
	Learning Rate: 6.16959e-05
	LOSS [training: 0.10334776860463965 | validation: 0.2686777157585509]
	TIME [epoch: 40.9 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1076571518647123		[learning rate: 6.1405e-05]
	Learning Rate: 6.14052e-05
	LOSS [training: 0.1076571518647123 | validation: 0.27860771082773406]
	TIME [epoch: 40.9 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10460618413081678		[learning rate: 6.1116e-05]
	Learning Rate: 6.11158e-05
	LOSS [training: 0.10460618413081678 | validation: 0.27749754215481814]
	TIME [epoch: 40.9 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09589298896842446		[learning rate: 6.0828e-05]
	Learning Rate: 6.08279e-05
	LOSS [training: 0.09589298896842446 | validation: 0.2675859327885174]
	TIME [epoch: 40.9 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09130635005904414		[learning rate: 6.0541e-05]
	Learning Rate: 6.05412e-05
	LOSS [training: 0.09130635005904414 | validation: 0.272667685976184]
	TIME [epoch: 41 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1062327952600758		[learning rate: 6.0256e-05]
	Learning Rate: 6.0256e-05
	LOSS [training: 0.1062327952600758 | validation: 0.2708090339560228]
	TIME [epoch: 41 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10203942500339727		[learning rate: 5.9972e-05]
	Learning Rate: 5.9972e-05
	LOSS [training: 0.10203942500339727 | validation: 0.2781501175528734]
	TIME [epoch: 40.9 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09067695410690223		[learning rate: 5.9689e-05]
	Learning Rate: 5.96894e-05
	LOSS [training: 0.09067695410690223 | validation: 0.2697669864012555]
	TIME [epoch: 41 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10166048158150638		[learning rate: 5.9408e-05]
	Learning Rate: 5.94082e-05
	LOSS [training: 0.10166048158150638 | validation: 0.2761770029327187]
	TIME [epoch: 40.9 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10957267167746931		[learning rate: 5.9128e-05]
	Learning Rate: 5.91282e-05
	LOSS [training: 0.10957267167746931 | validation: 0.280600781277331]
	TIME [epoch: 40.9 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10533798951134482		[learning rate: 5.885e-05]
	Learning Rate: 5.88496e-05
	LOSS [training: 0.10533798951134482 | validation: 0.2756051974982376]
	TIME [epoch: 40.9 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1286703827676024		[learning rate: 5.8572e-05]
	Learning Rate: 5.85723e-05
	LOSS [training: 0.1286703827676024 | validation: 0.2692364825245958]
	TIME [epoch: 40.9 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09469321522623883		[learning rate: 5.8296e-05]
	Learning Rate: 5.82963e-05
	LOSS [training: 0.09469321522623883 | validation: 0.26947709854393365]
	TIME [epoch: 40.9 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10603631870069996		[learning rate: 5.8022e-05]
	Learning Rate: 5.80216e-05
	LOSS [training: 0.10603631870069996 | validation: 0.2705148330670791]
	TIME [epoch: 40.9 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09935552715999448		[learning rate: 5.7748e-05]
	Learning Rate: 5.77482e-05
	LOSS [training: 0.09935552715999448 | validation: 0.26730180253480595]
	TIME [epoch: 40.9 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09770442395421174		[learning rate: 5.7476e-05]
	Learning Rate: 5.74761e-05
	LOSS [training: 0.09770442395421174 | validation: 0.26783352709984565]
	TIME [epoch: 40.9 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10510708016395479		[learning rate: 5.7205e-05]
	Learning Rate: 5.72053e-05
	LOSS [training: 0.10510708016395479 | validation: 0.27011074553309217]
	TIME [epoch: 40.9 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10585034861483417		[learning rate: 5.6936e-05]
	Learning Rate: 5.69357e-05
	LOSS [training: 0.10585034861483417 | validation: 0.27204749181528065]
	TIME [epoch: 41 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09586041104869007		[learning rate: 5.6667e-05]
	Learning Rate: 5.66674e-05
	LOSS [training: 0.09586041104869007 | validation: 0.27441877453304164]
	TIME [epoch: 40.9 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09981230416032841		[learning rate: 5.64e-05]
	Learning Rate: 5.64004e-05
	LOSS [training: 0.09981230416032841 | validation: 0.2701918970391527]
	TIME [epoch: 40.9 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09659368025969099		[learning rate: 5.6135e-05]
	Learning Rate: 5.61346e-05
	LOSS [training: 0.09659368025969099 | validation: 0.2781389397603763]
	TIME [epoch: 40.9 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09985062779980253		[learning rate: 5.587e-05]
	Learning Rate: 5.58701e-05
	LOSS [training: 0.09985062779980253 | validation: 0.2732991561180529]
	TIME [epoch: 41 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10994488964659029		[learning rate: 5.5607e-05]
	Learning Rate: 5.56068e-05
	LOSS [training: 0.10994488964659029 | validation: 0.2724329228896309]
	TIME [epoch: 40.9 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09544734777816266		[learning rate: 5.5345e-05]
	Learning Rate: 5.53448e-05
	LOSS [training: 0.09544734777816266 | validation: 0.26602989514792946]
	TIME [epoch: 40.9 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09684623624798122		[learning rate: 5.5084e-05]
	Learning Rate: 5.5084e-05
	LOSS [training: 0.09684623624798122 | validation: 0.27494987142332716]
	TIME [epoch: 40.9 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11030830542103298		[learning rate: 5.4824e-05]
	Learning Rate: 5.48245e-05
	LOSS [training: 0.11030830542103298 | validation: 0.2650328951485426]
	TIME [epoch: 40.9 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09024137898306998		[learning rate: 5.4566e-05]
	Learning Rate: 5.45661e-05
	LOSS [training: 0.09024137898306998 | validation: 0.25993268990248314]
	TIME [epoch: 40.9 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11214391209869218		[learning rate: 5.4309e-05]
	Learning Rate: 5.4309e-05
	LOSS [training: 0.11214391209869218 | validation: 0.2712583491572162]
	TIME [epoch: 40.9 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10038641800540642		[learning rate: 5.4053e-05]
	Learning Rate: 5.40531e-05
	LOSS [training: 0.10038641800540642 | validation: 0.2710802968544665]
	TIME [epoch: 40.9 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10655524463704967		[learning rate: 5.3798e-05]
	Learning Rate: 5.37984e-05
	LOSS [training: 0.10655524463704967 | validation: 0.26431269244968125]
	TIME [epoch: 40.9 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08949833611068217		[learning rate: 5.3545e-05]
	Learning Rate: 5.35449e-05
	LOSS [training: 0.08949833611068217 | validation: 0.27066752387594933]
	TIME [epoch: 40.9 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09928872620132206		[learning rate: 5.3293e-05]
	Learning Rate: 5.32926e-05
	LOSS [training: 0.09928872620132206 | validation: 0.2602390722852822]
	TIME [epoch: 41 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11105425454113599		[learning rate: 5.3041e-05]
	Learning Rate: 5.30415e-05
	LOSS [training: 0.11105425454113599 | validation: 0.2768459210815272]
	TIME [epoch: 40.9 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10151653938908739		[learning rate: 5.2792e-05]
	Learning Rate: 5.27915e-05
	LOSS [training: 0.10151653938908739 | validation: 0.27701749068467824]
	TIME [epoch: 41 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0967368558977929		[learning rate: 5.2543e-05]
	Learning Rate: 5.25428e-05
	LOSS [training: 0.0967368558977929 | validation: 0.27123071291310574]
	TIME [epoch: 40.9 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09494437163396202		[learning rate: 5.2295e-05]
	Learning Rate: 5.22952e-05
	LOSS [training: 0.09494437163396202 | validation: 0.270837382414928]
	TIME [epoch: 40.9 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1121300729798071		[learning rate: 5.2049e-05]
	Learning Rate: 5.20488e-05
	LOSS [training: 0.1121300729798071 | validation: 0.261362346193012]
	TIME [epoch: 40.9 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10360825952116867		[learning rate: 5.1803e-05]
	Learning Rate: 5.18035e-05
	LOSS [training: 0.10360825952116867 | validation: 0.2712876979825718]
	TIME [epoch: 40.9 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09562257077838573		[learning rate: 5.1559e-05]
	Learning Rate: 5.15594e-05
	LOSS [training: 0.09562257077838573 | validation: 0.26462191390802686]
	TIME [epoch: 41 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10082273200694976		[learning rate: 5.1316e-05]
	Learning Rate: 5.13164e-05
	LOSS [training: 0.10082273200694976 | validation: 0.267828969678167]
	TIME [epoch: 40.9 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10789641139826611		[learning rate: 5.1075e-05]
	Learning Rate: 5.10746e-05
	LOSS [training: 0.10789641139826611 | validation: 0.2628092649469143]
	TIME [epoch: 40.9 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09066702370799293		[learning rate: 5.0834e-05]
	Learning Rate: 5.0834e-05
	LOSS [training: 0.09066702370799293 | validation: 0.2586832214453989]
	TIME [epoch: 41 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09848513485580258		[learning rate: 5.0594e-05]
	Learning Rate: 5.05944e-05
	LOSS [training: 0.09848513485580258 | validation: 0.2685430223287388]
	TIME [epoch: 40.9 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09611401734790272		[learning rate: 5.0356e-05]
	Learning Rate: 5.0356e-05
	LOSS [training: 0.09611401734790272 | validation: 0.27559872443290584]
	TIME [epoch: 41 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10200634782341268		[learning rate: 5.0119e-05]
	Learning Rate: 5.01187e-05
	LOSS [training: 0.10200634782341268 | validation: 0.26380587899568525]
	TIME [epoch: 41 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09361395535226712		[learning rate: 4.9883e-05]
	Learning Rate: 4.98826e-05
	LOSS [training: 0.09361395535226712 | validation: 0.2700983627460336]
	TIME [epoch: 41 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10956274156437508		[learning rate: 4.9648e-05]
	Learning Rate: 4.96475e-05
	LOSS [training: 0.10956274156437508 | validation: 0.272870667158954]
	TIME [epoch: 40.9 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09965019110871774		[learning rate: 4.9414e-05]
	Learning Rate: 4.94136e-05
	LOSS [training: 0.09965019110871774 | validation: 0.2608797063916324]
	TIME [epoch: 40.9 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11404309576423216		[learning rate: 4.9181e-05]
	Learning Rate: 4.91807e-05
	LOSS [training: 0.11404309576423216 | validation: 0.26500803971772535]
	TIME [epoch: 40.9 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1012785862838806		[learning rate: 4.8949e-05]
	Learning Rate: 4.8949e-05
	LOSS [training: 0.1012785862838806 | validation: 0.2737627950948348]
	TIME [epoch: 40.9 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11217859451841472		[learning rate: 4.8718e-05]
	Learning Rate: 4.87183e-05
	LOSS [training: 0.11217859451841472 | validation: 0.2721074547614628]
	TIME [epoch: 40.9 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09523325192311038		[learning rate: 4.8489e-05]
	Learning Rate: 4.84888e-05
	LOSS [training: 0.09523325192311038 | validation: 0.25991632982951934]
	TIME [epoch: 40.9 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10367972336589225		[learning rate: 4.826e-05]
	Learning Rate: 4.82603e-05
	LOSS [training: 0.10367972336589225 | validation: 0.2713791385504747]
	TIME [epoch: 40.9 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09706645017435482		[learning rate: 4.8033e-05]
	Learning Rate: 4.80329e-05
	LOSS [training: 0.09706645017435482 | validation: 0.269503808337829]
	TIME [epoch: 40.9 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10448344925907685		[learning rate: 4.7807e-05]
	Learning Rate: 4.78065e-05
	LOSS [training: 0.10448344925907685 | validation: 0.2726252722169495]
	TIME [epoch: 40.9 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10960447930111498		[learning rate: 4.7581e-05]
	Learning Rate: 4.75813e-05
	LOSS [training: 0.10960447930111498 | validation: 0.2693118239362753]
	TIME [epoch: 41 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10605731417363728		[learning rate: 4.7357e-05]
	Learning Rate: 4.73571e-05
	LOSS [training: 0.10605731417363728 | validation: 0.27018011985538865]
	TIME [epoch: 40.9 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09501158296056902		[learning rate: 4.7134e-05]
	Learning Rate: 4.71339e-05
	LOSS [training: 0.09501158296056902 | validation: 0.2730788218325821]
	TIME [epoch: 41 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10990229267673166		[learning rate: 4.6912e-05]
	Learning Rate: 4.69118e-05
	LOSS [training: 0.10990229267673166 | validation: 0.2733148331282828]
	TIME [epoch: 40.9 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10891420233774321		[learning rate: 4.6691e-05]
	Learning Rate: 4.66907e-05
	LOSS [training: 0.10891420233774321 | validation: 0.27101729531668833]
	TIME [epoch: 40.9 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10601601493204418		[learning rate: 4.6471e-05]
	Learning Rate: 4.64707e-05
	LOSS [training: 0.10601601493204418 | validation: 0.2697026820609115]
	TIME [epoch: 40.9 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10122276389330019		[learning rate: 4.6252e-05]
	Learning Rate: 4.62518e-05
	LOSS [training: 0.10122276389330019 | validation: 0.27030595399735796]
	TIME [epoch: 40.9 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1142177974740329		[learning rate: 4.6034e-05]
	Learning Rate: 4.60338e-05
	LOSS [training: 0.1142177974740329 | validation: 0.27220146932946415]
	TIME [epoch: 40.9 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11446975412967436		[learning rate: 4.5817e-05]
	Learning Rate: 4.58169e-05
	LOSS [training: 0.11446975412967436 | validation: 0.27649135010452885]
	TIME [epoch: 40.9 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10600111964428065		[learning rate: 4.5601e-05]
	Learning Rate: 4.5601e-05
	LOSS [training: 0.10600111964428065 | validation: 0.26449148519427745]
	TIME [epoch: 40.9 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10056732862294944		[learning rate: 4.5386e-05]
	Learning Rate: 4.53861e-05
	LOSS [training: 0.10056732862294944 | validation: 0.2746063191744984]
	TIME [epoch: 40.9 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10308626809525329		[learning rate: 4.5172e-05]
	Learning Rate: 4.51723e-05
	LOSS [training: 0.10308626809525329 | validation: 0.26676385097268923]
	TIME [epoch: 40.9 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11535791007388166		[learning rate: 4.4959e-05]
	Learning Rate: 4.49594e-05
	LOSS [training: 0.11535791007388166 | validation: 0.27053104438185827]
	TIME [epoch: 40.9 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09472430102829824		[learning rate: 4.4748e-05]
	Learning Rate: 4.47475e-05
	LOSS [training: 0.09472430102829824 | validation: 0.2704285548141923]
	TIME [epoch: 40.9 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09966602255420723		[learning rate: 4.4537e-05]
	Learning Rate: 4.45367e-05
	LOSS [training: 0.09966602255420723 | validation: 0.2735495399961163]
	TIME [epoch: 40.9 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0942124284224432		[learning rate: 4.4327e-05]
	Learning Rate: 4.43268e-05
	LOSS [training: 0.0942124284224432 | validation: 0.2666156291401796]
	TIME [epoch: 40.9 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09754383093752714		[learning rate: 4.4118e-05]
	Learning Rate: 4.4118e-05
	LOSS [training: 0.09754383093752714 | validation: 0.25760594465499725]
	TIME [epoch: 40.9 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09238567595319977		[learning rate: 4.391e-05]
	Learning Rate: 4.39101e-05
	LOSS [training: 0.09238567595319977 | validation: 0.2751996093290667]
	TIME [epoch: 40.9 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10375891872726431		[learning rate: 4.3703e-05]
	Learning Rate: 4.37032e-05
	LOSS [training: 0.10375891872726431 | validation: 0.2758174766549516]
	TIME [epoch: 40.9 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0993174934623345		[learning rate: 4.3497e-05]
	Learning Rate: 4.34972e-05
	LOSS [training: 0.0993174934623345 | validation: 0.27120051739636125]
	TIME [epoch: 40.9 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10097165219161792		[learning rate: 4.3292e-05]
	Learning Rate: 4.32923e-05
	LOSS [training: 0.10097165219161792 | validation: 0.27385297049829205]
	TIME [epoch: 40.9 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09612454976301821		[learning rate: 4.3088e-05]
	Learning Rate: 4.30883e-05
	LOSS [training: 0.09612454976301821 | validation: 0.2736831942891761]
	TIME [epoch: 40.9 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08752421947705001		[learning rate: 4.2885e-05]
	Learning Rate: 4.28852e-05
	LOSS [training: 0.08752421947705001 | validation: 0.27121345971078104]
	TIME [epoch: 40.9 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09400039673273261		[learning rate: 4.2683e-05]
	Learning Rate: 4.26831e-05
	LOSS [training: 0.09400039673273261 | validation: 0.2712566679964892]
	TIME [epoch: 40.9 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10425937505094297		[learning rate: 4.2482e-05]
	Learning Rate: 4.2482e-05
	LOSS [training: 0.10425937505094297 | validation: 0.26797434962160177]
	TIME [epoch: 40.9 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10226667159873458		[learning rate: 4.2282e-05]
	Learning Rate: 4.22818e-05
	LOSS [training: 0.10226667159873458 | validation: 0.2751555133511008]
	TIME [epoch: 40.9 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10917301280369365		[learning rate: 4.2083e-05]
	Learning Rate: 4.20826e-05
	LOSS [training: 0.10917301280369365 | validation: 0.2740587285780848]
	TIME [epoch: 40.9 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09679222831135734		[learning rate: 4.1884e-05]
	Learning Rate: 4.18843e-05
	LOSS [training: 0.09679222831135734 | validation: 0.25371808456040446]
	TIME [epoch: 40.9 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_1197.pth
	Model improved!!!
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10119236745224588		[learning rate: 4.1687e-05]
	Learning Rate: 4.16869e-05
	LOSS [training: 0.10119236745224588 | validation: 0.2773034560091859]
	TIME [epoch: 41 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09851360824557655		[learning rate: 4.1491e-05]
	Learning Rate: 4.14905e-05
	LOSS [training: 0.09851360824557655 | validation: 0.27213099393433987]
	TIME [epoch: 40.9 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09802147448388356		[learning rate: 4.1295e-05]
	Learning Rate: 4.1295e-05
	LOSS [training: 0.09802147448388356 | validation: 0.26859961035025937]
	TIME [epoch: 41 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10045149436273136		[learning rate: 4.11e-05]
	Learning Rate: 4.11004e-05
	LOSS [training: 0.10045149436273136 | validation: 0.27439199611221676]
	TIME [epoch: 41 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.095789154309495		[learning rate: 4.0907e-05]
	Learning Rate: 4.09067e-05
	LOSS [training: 0.095789154309495 | validation: 0.2666447318615227]
	TIME [epoch: 40.9 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10351364420334927		[learning rate: 4.0714e-05]
	Learning Rate: 4.0714e-05
	LOSS [training: 0.10351364420334927 | validation: 0.2783070099828472]
	TIME [epoch: 41 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09580303528201745		[learning rate: 4.0522e-05]
	Learning Rate: 4.05221e-05
	LOSS [training: 0.09580303528201745 | validation: 0.2728814376722489]
	TIME [epoch: 41 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11076753212756776		[learning rate: 4.0331e-05]
	Learning Rate: 4.03312e-05
	LOSS [training: 0.11076753212756776 | validation: 0.279284263024267]
	TIME [epoch: 40.9 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10987203275237561		[learning rate: 4.0141e-05]
	Learning Rate: 4.01412e-05
	LOSS [training: 0.10987203275237561 | validation: 0.2627089816125658]
	TIME [epoch: 41 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10806710821990897		[learning rate: 3.9952e-05]
	Learning Rate: 3.9952e-05
	LOSS [training: 0.10806710821990897 | validation: 0.26999520565163376]
	TIME [epoch: 40.9 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0975009041727464		[learning rate: 3.9764e-05]
	Learning Rate: 3.97637e-05
	LOSS [training: 0.0975009041727464 | validation: 0.27561200693736776]
	TIME [epoch: 41 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11658606874243019		[learning rate: 3.9576e-05]
	Learning Rate: 3.95764e-05
	LOSS [training: 0.11658606874243019 | validation: 0.26746830310716374]
	TIME [epoch: 41 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09905748755160755		[learning rate: 3.939e-05]
	Learning Rate: 3.93899e-05
	LOSS [training: 0.09905748755160755 | validation: 0.2774660382795323]
	TIME [epoch: 41 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1006851313852169		[learning rate: 3.9204e-05]
	Learning Rate: 3.92043e-05
	LOSS [training: 0.1006851313852169 | validation: 0.27137767556681447]
	TIME [epoch: 40.9 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0977117389690513		[learning rate: 3.902e-05]
	Learning Rate: 3.90195e-05
	LOSS [training: 0.0977117389690513 | validation: 0.25866404795235287]
	TIME [epoch: 40.9 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09368872188679439		[learning rate: 3.8836e-05]
	Learning Rate: 3.88357e-05
	LOSS [training: 0.09368872188679439 | validation: 0.2657000453816047]
	TIME [epoch: 40.9 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09417790858736763		[learning rate: 3.8653e-05]
	Learning Rate: 3.86527e-05
	LOSS [training: 0.09417790858736763 | validation: 0.2686862507614966]
	TIME [epoch: 41 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10831425868472391		[learning rate: 3.8471e-05]
	Learning Rate: 3.84705e-05
	LOSS [training: 0.10831425868472391 | validation: 0.27726381643066716]
	TIME [epoch: 40.9 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09316829682334986		[learning rate: 3.8289e-05]
	Learning Rate: 3.82893e-05
	LOSS [training: 0.09316829682334986 | validation: 0.27098038212494246]
	TIME [epoch: 40.9 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10173535055196087		[learning rate: 3.8109e-05]
	Learning Rate: 3.81088e-05
	LOSS [training: 0.10173535055196087 | validation: 0.270881585252612]
	TIME [epoch: 40.9 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10659122780993674		[learning rate: 3.7929e-05]
	Learning Rate: 3.79293e-05
	LOSS [training: 0.10659122780993674 | validation: 0.275317055653567]
	TIME [epoch: 40.9 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10086818681109136		[learning rate: 3.7751e-05]
	Learning Rate: 3.77505e-05
	LOSS [training: 0.10086818681109136 | validation: 0.2705121206866524]
	TIME [epoch: 40.9 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10510086185907037		[learning rate: 3.7573e-05]
	Learning Rate: 3.75726e-05
	LOSS [training: 0.10510086185907037 | validation: 0.2697850061534845]
	TIME [epoch: 40.9 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10025105501904304		[learning rate: 3.7396e-05]
	Learning Rate: 3.73956e-05
	LOSS [training: 0.10025105501904304 | validation: 0.2664480126801908]
	TIME [epoch: 40.9 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11242228491554548		[learning rate: 3.7219e-05]
	Learning Rate: 3.72194e-05
	LOSS [training: 0.11242228491554548 | validation: 0.27479260724902704]
	TIME [epoch: 40.9 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09880719981595866		[learning rate: 3.7044e-05]
	Learning Rate: 3.7044e-05
	LOSS [training: 0.09880719981595866 | validation: 0.27260634338749734]
	TIME [epoch: 40.9 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09513716504764429		[learning rate: 3.6869e-05]
	Learning Rate: 3.68695e-05
	LOSS [training: 0.09513716504764429 | validation: 0.2702304193386032]
	TIME [epoch: 40.9 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09811126358736129		[learning rate: 3.6696e-05]
	Learning Rate: 3.66957e-05
	LOSS [training: 0.09811126358736129 | validation: 0.2644150223164259]
	TIME [epoch: 40.9 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1124922077141011		[learning rate: 3.6523e-05]
	Learning Rate: 3.65228e-05
	LOSS [training: 0.1124922077141011 | validation: 0.2611916073568028]
	TIME [epoch: 40.9 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10202933412823864		[learning rate: 3.6351e-05]
	Learning Rate: 3.63507e-05
	LOSS [training: 0.10202933412823864 | validation: 0.2658598991090907]
	TIME [epoch: 40.9 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09979885124048002		[learning rate: 3.6179e-05]
	Learning Rate: 3.61794e-05
	LOSS [training: 0.09979885124048002 | validation: 0.2749148740273052]
	TIME [epoch: 40.9 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0953100685358787		[learning rate: 3.6009e-05]
	Learning Rate: 3.60089e-05
	LOSS [training: 0.0953100685358787 | validation: 0.2764657186997439]
	TIME [epoch: 40.9 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.114614476942484		[learning rate: 3.5839e-05]
	Learning Rate: 3.58393e-05
	LOSS [training: 0.114614476942484 | validation: 0.27113979409275835]
	TIME [epoch: 41 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.105185318428517		[learning rate: 3.567e-05]
	Learning Rate: 3.56704e-05
	LOSS [training: 0.105185318428517 | validation: 0.2739094248520724]
	TIME [epoch: 40.9 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10004060175674573		[learning rate: 3.5502e-05]
	Learning Rate: 3.55023e-05
	LOSS [training: 0.10004060175674573 | validation: 0.275070957130655]
	TIME [epoch: 40.9 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09460451232526515		[learning rate: 3.5335e-05]
	Learning Rate: 3.5335e-05
	LOSS [training: 0.09460451232526515 | validation: 0.2787317345857282]
	TIME [epoch: 40.9 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10104378027386758		[learning rate: 3.5169e-05]
	Learning Rate: 3.51685e-05
	LOSS [training: 0.10104378027386758 | validation: 0.2731984894310799]
	TIME [epoch: 40.9 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09298698451908653		[learning rate: 3.5003e-05]
	Learning Rate: 3.50028e-05
	LOSS [training: 0.09298698451908653 | validation: 0.2784190096940734]
	TIME [epoch: 40.9 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12861343368159844		[learning rate: 3.4838e-05]
	Learning Rate: 3.48379e-05
	LOSS [training: 0.12861343368159844 | validation: 0.2694474525831174]
	TIME [epoch: 40.9 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10565609694768496		[learning rate: 3.4674e-05]
	Learning Rate: 3.46737e-05
	LOSS [training: 0.10565609694768496 | validation: 0.2663593189641931]
	TIME [epoch: 40.9 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11121969197319176		[learning rate: 3.451e-05]
	Learning Rate: 3.45103e-05
	LOSS [training: 0.11121969197319176 | validation: 0.2698994785840599]
	TIME [epoch: 40.9 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09723087778665203		[learning rate: 3.4348e-05]
	Learning Rate: 3.43477e-05
	LOSS [training: 0.09723087778665203 | validation: 0.26924184385943095]
	TIME [epoch: 41 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0947830368931149		[learning rate: 3.4186e-05]
	Learning Rate: 3.41858e-05
	LOSS [training: 0.0947830368931149 | validation: 0.2673644306388571]
	TIME [epoch: 41 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09155319784334946		[learning rate: 3.4025e-05]
	Learning Rate: 3.40248e-05
	LOSS [training: 0.09155319784334946 | validation: 0.2730696046339644]
	TIME [epoch: 41 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09729183720260871		[learning rate: 3.3864e-05]
	Learning Rate: 3.38644e-05
	LOSS [training: 0.09729183720260871 | validation: 0.2686334651007792]
	TIME [epoch: 41 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10085723558552796		[learning rate: 3.3705e-05]
	Learning Rate: 3.37048e-05
	LOSS [training: 0.10085723558552796 | validation: 0.2698325487150043]
	TIME [epoch: 41 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09780782632547982		[learning rate: 3.3546e-05]
	Learning Rate: 3.3546e-05
	LOSS [training: 0.09780782632547982 | validation: 0.2768921739192057]
	TIME [epoch: 41 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10832699077214636		[learning rate: 3.3388e-05]
	Learning Rate: 3.33879e-05
	LOSS [training: 0.10832699077214636 | validation: 0.2717987602522779]
	TIME [epoch: 41 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0952071971019758		[learning rate: 3.3231e-05]
	Learning Rate: 3.32306e-05
	LOSS [training: 0.0952071971019758 | validation: 0.273239516641766]
	TIME [epoch: 41 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1049789635712588		[learning rate: 3.3074e-05]
	Learning Rate: 3.3074e-05
	LOSS [training: 0.1049789635712588 | validation: 0.2774005765731685]
	TIME [epoch: 41 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10738647443766611		[learning rate: 3.2918e-05]
	Learning Rate: 3.29182e-05
	LOSS [training: 0.10738647443766611 | validation: 0.2760523539035758]
	TIME [epoch: 40.9 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11268817774614044		[learning rate: 3.2763e-05]
	Learning Rate: 3.27631e-05
	LOSS [training: 0.11268817774614044 | validation: 0.2727950774861932]
	TIME [epoch: 40.9 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10508405905262519		[learning rate: 3.2609e-05]
	Learning Rate: 3.26087e-05
	LOSS [training: 0.10508405905262519 | validation: 0.27347930495256534]
	TIME [epoch: 40.9 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09817110227804951		[learning rate: 3.2455e-05]
	Learning Rate: 3.2455e-05
	LOSS [training: 0.09817110227804951 | validation: 0.2723825922517715]
	TIME [epoch: 40.9 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10966263850995443		[learning rate: 3.2302e-05]
	Learning Rate: 3.23021e-05
	LOSS [training: 0.10966263850995443 | validation: 0.27286129164553036]
	TIME [epoch: 41 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09904621180669124		[learning rate: 3.215e-05]
	Learning Rate: 3.21499e-05
	LOSS [training: 0.09904621180669124 | validation: 0.2848190830497186]
	TIME [epoch: 40.9 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09499587334100344		[learning rate: 3.1998e-05]
	Learning Rate: 3.19984e-05
	LOSS [training: 0.09499587334100344 | validation: 0.27369818899073334]
	TIME [epoch: 40.9 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09458813108588221		[learning rate: 3.1848e-05]
	Learning Rate: 3.18476e-05
	LOSS [training: 0.09458813108588221 | validation: 0.2696818072031664]
	TIME [epoch: 40.9 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11090640101727155		[learning rate: 3.1698e-05]
	Learning Rate: 3.16976e-05
	LOSS [training: 0.11090640101727155 | validation: 0.26593566901294285]
	TIME [epoch: 40.9 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11245225546220602		[learning rate: 3.1548e-05]
	Learning Rate: 3.15482e-05
	LOSS [training: 0.11245225546220602 | validation: 0.2703954555384615]
	TIME [epoch: 40.9 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09237030814725061		[learning rate: 3.14e-05]
	Learning Rate: 3.13995e-05
	LOSS [training: 0.09237030814725061 | validation: 0.2720406475378483]
	TIME [epoch: 40.9 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10278288893965729		[learning rate: 3.1252e-05]
	Learning Rate: 3.12516e-05
	LOSS [training: 0.10278288893965729 | validation: 0.271574248130552]
	TIME [epoch: 40.9 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08955132151579222		[learning rate: 3.1104e-05]
	Learning Rate: 3.11043e-05
	LOSS [training: 0.08955132151579222 | validation: 0.26063414117933564]
	TIME [epoch: 40.9 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1201467540964875		[learning rate: 3.0958e-05]
	Learning Rate: 3.09577e-05
	LOSS [training: 0.1201467540964875 | validation: 0.27004663093025444]
	TIME [epoch: 40.9 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10641713268183271		[learning rate: 3.0812e-05]
	Learning Rate: 3.08119e-05
	LOSS [training: 0.10641713268183271 | validation: 0.2652811088760738]
	TIME [epoch: 40.9 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11012377760045064		[learning rate: 3.0667e-05]
	Learning Rate: 3.06667e-05
	LOSS [training: 0.11012377760045064 | validation: 0.26677350701685193]
	TIME [epoch: 40.9 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09775187292267781		[learning rate: 3.0522e-05]
	Learning Rate: 3.05222e-05
	LOSS [training: 0.09775187292267781 | validation: 0.2723575180737598]
	TIME [epoch: 41 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10279493629856681		[learning rate: 3.0378e-05]
	Learning Rate: 3.03783e-05
	LOSS [training: 0.10279493629856681 | validation: 0.26469769180625313]
	TIME [epoch: 40.9 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10434631796054943		[learning rate: 3.0235e-05]
	Learning Rate: 3.02352e-05
	LOSS [training: 0.10434631796054943 | validation: 0.27612550756360776]
	TIME [epoch: 40.9 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09443591299186985		[learning rate: 3.0093e-05]
	Learning Rate: 3.00927e-05
	LOSS [training: 0.09443591299186985 | validation: 0.2728262473254549]
	TIME [epoch: 40.9 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09872971254744362		[learning rate: 2.9951e-05]
	Learning Rate: 2.99509e-05
	LOSS [training: 0.09872971254744362 | validation: 0.2672557877891374]
	TIME [epoch: 41 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1123518534306005		[learning rate: 2.981e-05]
	Learning Rate: 2.98098e-05
	LOSS [training: 0.1123518534306005 | validation: 0.2700286655134228]
	TIME [epoch: 40.9 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09386772288284514		[learning rate: 2.9669e-05]
	Learning Rate: 2.96693e-05
	LOSS [training: 0.09386772288284514 | validation: 0.2716898337179507]
	TIME [epoch: 40.9 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10919735939478831		[learning rate: 2.953e-05]
	Learning Rate: 2.95295e-05
	LOSS [training: 0.10919735939478831 | validation: 0.27346648878860735]
	TIME [epoch: 41 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1124780866612235		[learning rate: 2.939e-05]
	Learning Rate: 2.93904e-05
	LOSS [training: 0.1124780866612235 | validation: 0.28055854025835075]
	TIME [epoch: 40.9 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10019699791191602		[learning rate: 2.9252e-05]
	Learning Rate: 2.92519e-05
	LOSS [training: 0.10019699791191602 | validation: 0.27160546640712724]
	TIME [epoch: 40.9 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09863544913617538		[learning rate: 2.9114e-05]
	Learning Rate: 2.91141e-05
	LOSS [training: 0.09863544913617538 | validation: 0.26458641512297154]
	TIME [epoch: 40.9 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10474138588746024		[learning rate: 2.8977e-05]
	Learning Rate: 2.89769e-05
	LOSS [training: 0.10474138588746024 | validation: 0.2649799676662225]
	TIME [epoch: 41 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09465730171230455		[learning rate: 2.884e-05]
	Learning Rate: 2.88403e-05
	LOSS [training: 0.09465730171230455 | validation: 0.268305417243899]
	TIME [epoch: 41 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12380177694389355		[learning rate: 2.8704e-05]
	Learning Rate: 2.87044e-05
	LOSS [training: 0.12380177694389355 | validation: 0.2775286092033982]
	TIME [epoch: 41 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.109864828861248		[learning rate: 2.8569e-05]
	Learning Rate: 2.85692e-05
	LOSS [training: 0.109864828861248 | validation: 0.2752267334282062]
	TIME [epoch: 41 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09505109150867437		[learning rate: 2.8435e-05]
	Learning Rate: 2.84345e-05
	LOSS [training: 0.09505109150867437 | validation: 0.27372203615168605]
	TIME [epoch: 41 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10279884625961745		[learning rate: 2.8301e-05]
	Learning Rate: 2.83005e-05
	LOSS [training: 0.10279884625961745 | validation: 0.27537838286380656]
	TIME [epoch: 40.9 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11649549298875028		[learning rate: 2.8167e-05]
	Learning Rate: 2.81672e-05
	LOSS [training: 0.11649549298875028 | validation: 0.2722680444839327]
	TIME [epoch: 41 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09767650743884844		[learning rate: 2.8034e-05]
	Learning Rate: 2.80345e-05
	LOSS [training: 0.09767650743884844 | validation: 0.2663985877059817]
	TIME [epoch: 41 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09127528891443627		[learning rate: 2.7902e-05]
	Learning Rate: 2.79024e-05
	LOSS [training: 0.09127528891443627 | validation: 0.2660492375493782]
	TIME [epoch: 41 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11126862863783007		[learning rate: 2.7771e-05]
	Learning Rate: 2.77709e-05
	LOSS [training: 0.11126862863783007 | validation: 0.26712206996763116]
	TIME [epoch: 40.9 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10911906478188532		[learning rate: 2.764e-05]
	Learning Rate: 2.764e-05
	LOSS [training: 0.10911906478188532 | validation: 0.26634462015685595]
	TIME [epoch: 40.9 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09302258258221036		[learning rate: 2.751e-05]
	Learning Rate: 2.75098e-05
	LOSS [training: 0.09302258258221036 | validation: 0.2721892650972699]
	TIME [epoch: 41 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11541560611904296		[learning rate: 2.738e-05]
	Learning Rate: 2.73802e-05
	LOSS [training: 0.11541560611904296 | validation: 0.27167283871661113]
	TIME [epoch: 41 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09512602130532913		[learning rate: 2.7251e-05]
	Learning Rate: 2.72511e-05
	LOSS [training: 0.09512602130532913 | validation: 0.27023940342500385]
	TIME [epoch: 40.9 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09826147541923788		[learning rate: 2.7123e-05]
	Learning Rate: 2.71227e-05
	LOSS [training: 0.09826147541923788 | validation: 0.27655849305173114]
	TIME [epoch: 41 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0984444356011696		[learning rate: 2.6995e-05]
	Learning Rate: 2.69949e-05
	LOSS [training: 0.0984444356011696 | validation: 0.27344856167617054]
	TIME [epoch: 41 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1154986836967957		[learning rate: 2.6868e-05]
	Learning Rate: 2.68677e-05
	LOSS [training: 0.1154986836967957 | validation: 0.2689523107498407]
	TIME [epoch: 41 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09723764466042734		[learning rate: 2.6741e-05]
	Learning Rate: 2.67411e-05
	LOSS [training: 0.09723764466042734 | validation: 0.2706651651289529]
	TIME [epoch: 41 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11408538146630025		[learning rate: 2.6615e-05]
	Learning Rate: 2.66151e-05
	LOSS [training: 0.11408538146630025 | validation: 0.2795154730964702]
	TIME [epoch: 40.9 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09490637701038743		[learning rate: 2.649e-05]
	Learning Rate: 2.64897e-05
	LOSS [training: 0.09490637701038743 | validation: 0.2684506611292846]
	TIME [epoch: 40.9 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09463103461976807		[learning rate: 2.6365e-05]
	Learning Rate: 2.63649e-05
	LOSS [training: 0.09463103461976807 | validation: 0.26589984360388325]
	TIME [epoch: 40.9 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11094410816410469		[learning rate: 2.6241e-05]
	Learning Rate: 2.62406e-05
	LOSS [training: 0.11094410816410469 | validation: 0.2716641463632539]
	TIME [epoch: 40.9 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1010242633509674		[learning rate: 2.6117e-05]
	Learning Rate: 2.6117e-05
	LOSS [training: 0.1010242633509674 | validation: 0.2682477513060597]
	TIME [epoch: 40.9 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09128039770931715		[learning rate: 2.5994e-05]
	Learning Rate: 2.59939e-05
	LOSS [training: 0.09128039770931715 | validation: 0.27216610375713135]
	TIME [epoch: 40.9 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12302783749501146		[learning rate: 2.5871e-05]
	Learning Rate: 2.58714e-05
	LOSS [training: 0.12302783749501146 | validation: 0.2807567066628896]
	TIME [epoch: 40.9 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10711501021719917		[learning rate: 2.575e-05]
	Learning Rate: 2.57495e-05
	LOSS [training: 0.10711501021719917 | validation: 0.27152366440942216]
	TIME [epoch: 40.9 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11829630041571004		[learning rate: 2.5628e-05]
	Learning Rate: 2.56282e-05
	LOSS [training: 0.11829630041571004 | validation: 0.26837706705663655]
	TIME [epoch: 41 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11893362347277292		[learning rate: 2.5507e-05]
	Learning Rate: 2.55074e-05
	LOSS [training: 0.11893362347277292 | validation: 0.2812916524474313]
	TIME [epoch: 41 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10406968619442715		[learning rate: 2.5387e-05]
	Learning Rate: 2.53872e-05
	LOSS [training: 0.10406968619442715 | validation: 0.27476199738089935]
	TIME [epoch: 41 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10363845725982464		[learning rate: 2.5268e-05]
	Learning Rate: 2.52676e-05
	LOSS [training: 0.10363845725982464 | validation: 0.2750070360872653]
	TIME [epoch: 41 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09956313470048403		[learning rate: 2.5149e-05]
	Learning Rate: 2.51485e-05
	LOSS [training: 0.09956313470048403 | validation: 0.26871552682032895]
	TIME [epoch: 40.9 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10694645590110693		[learning rate: 2.503e-05]
	Learning Rate: 2.503e-05
	LOSS [training: 0.10694645590110693 | validation: 0.2676017996274881]
	TIME [epoch: 41 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09692476653635902		[learning rate: 2.4912e-05]
	Learning Rate: 2.49121e-05
	LOSS [training: 0.09692476653635902 | validation: 0.2716563334711338]
	TIME [epoch: 41 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1079299311406133		[learning rate: 2.4795e-05]
	Learning Rate: 2.47947e-05
	LOSS [training: 0.1079299311406133 | validation: 0.2673821779646549]
	TIME [epoch: 41 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10137620356928093		[learning rate: 2.4678e-05]
	Learning Rate: 2.46779e-05
	LOSS [training: 0.10137620356928093 | validation: 0.26836393709804757]
	TIME [epoch: 41 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1035482341644139		[learning rate: 2.4562e-05]
	Learning Rate: 2.45616e-05
	LOSS [training: 0.1035482341644139 | validation: 0.2682613532570717]
	TIME [epoch: 41 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09676485134077903		[learning rate: 2.4446e-05]
	Learning Rate: 2.44459e-05
	LOSS [training: 0.09676485134077903 | validation: 0.2751449767048931]
	TIME [epoch: 40.9 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09973595605750198		[learning rate: 2.4331e-05]
	Learning Rate: 2.43307e-05
	LOSS [training: 0.09973595605750198 | validation: 0.2735416097817653]
	TIME [epoch: 41 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10591136807936849		[learning rate: 2.4216e-05]
	Learning Rate: 2.4216e-05
	LOSS [training: 0.10591136807936849 | validation: 0.26321974830524214]
	TIME [epoch: 41 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10525263291014034		[learning rate: 2.4102e-05]
	Learning Rate: 2.41019e-05
	LOSS [training: 0.10525263291014034 | validation: 0.26929181568544625]
	TIME [epoch: 41 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13113958957356361		[learning rate: 2.3988e-05]
	Learning Rate: 2.39883e-05
	LOSS [training: 0.13113958957356361 | validation: 0.2598465347995873]
	TIME [epoch: 41 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09223509292202442		[learning rate: 2.3875e-05]
	Learning Rate: 2.38753e-05
	LOSS [training: 0.09223509292202442 | validation: 0.2689621229214664]
	TIME [epoch: 41 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09360256678099046		[learning rate: 2.3763e-05]
	Learning Rate: 2.37628e-05
	LOSS [training: 0.09360256678099046 | validation: 0.2702227011556035]
	TIME [epoch: 41 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1050947938209643		[learning rate: 2.3651e-05]
	Learning Rate: 2.36508e-05
	LOSS [training: 0.1050947938209643 | validation: 0.2631601334833171]
	TIME [epoch: 41 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0943676604608219		[learning rate: 2.3539e-05]
	Learning Rate: 2.35394e-05
	LOSS [training: 0.0943676604608219 | validation: 0.2712746409335445]
	TIME [epoch: 41 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12453479812753035		[learning rate: 2.3428e-05]
	Learning Rate: 2.34285e-05
	LOSS [training: 0.12453479812753035 | validation: 0.27382894569697547]
	TIME [epoch: 41 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09208360083390946		[learning rate: 2.3318e-05]
	Learning Rate: 2.33181e-05
	LOSS [training: 0.09208360083390946 | validation: 0.2714713979268832]
	TIME [epoch: 41 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09237593612953167		[learning rate: 2.3208e-05]
	Learning Rate: 2.32082e-05
	LOSS [training: 0.09237593612953167 | validation: 0.2688023558517464]
	TIME [epoch: 41 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09691222250177471		[learning rate: 2.3099e-05]
	Learning Rate: 2.30988e-05
	LOSS [training: 0.09691222250177471 | validation: 0.2724536546410136]
	TIME [epoch: 41 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1048852963701096		[learning rate: 2.299e-05]
	Learning Rate: 2.299e-05
	LOSS [training: 0.1048852963701096 | validation: 0.2739051926416225]
	TIME [epoch: 41 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10683951077114792		[learning rate: 2.2882e-05]
	Learning Rate: 2.28816e-05
	LOSS [training: 0.10683951077114792 | validation: 0.27188258541673477]
	TIME [epoch: 41 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10853735881473689		[learning rate: 2.2774e-05]
	Learning Rate: 2.27738e-05
	LOSS [training: 0.10853735881473689 | validation: 0.2647487079604343]
	TIME [epoch: 41 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10505260897397972		[learning rate: 2.2667e-05]
	Learning Rate: 2.26665e-05
	LOSS [training: 0.10505260897397972 | validation: 0.26789321134656746]
	TIME [epoch: 41 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09308860041668923		[learning rate: 2.256e-05]
	Learning Rate: 2.25597e-05
	LOSS [training: 0.09308860041668923 | validation: 0.27133170607164037]
	TIME [epoch: 40.9 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09584808398660251		[learning rate: 2.2453e-05]
	Learning Rate: 2.24534e-05
	LOSS [training: 0.09584808398660251 | validation: 0.26963214510681943]
	TIME [epoch: 41 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11421695622495634		[learning rate: 2.2348e-05]
	Learning Rate: 2.23476e-05
	LOSS [training: 0.11421695622495634 | validation: 0.2652965355593388]
	TIME [epoch: 40.9 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10664840793358304		[learning rate: 2.2242e-05]
	Learning Rate: 2.22423e-05
	LOSS [training: 0.10664840793358304 | validation: 0.2740999927959139]
	TIME [epoch: 41 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.093435336785445		[learning rate: 2.2137e-05]
	Learning Rate: 2.21375e-05
	LOSS [training: 0.093435336785445 | validation: 0.2707273215384074]
	TIME [epoch: 41 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09304852867330682		[learning rate: 2.2033e-05]
	Learning Rate: 2.20332e-05
	LOSS [training: 0.09304852867330682 | validation: 0.26596837689074954]
	TIME [epoch: 41 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09516013122868376		[learning rate: 2.1929e-05]
	Learning Rate: 2.19293e-05
	LOSS [training: 0.09516013122868376 | validation: 0.2787867930608002]
	TIME [epoch: 41 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09993747250850224		[learning rate: 2.1826e-05]
	Learning Rate: 2.1826e-05
	LOSS [training: 0.09993747250850224 | validation: 0.2661039721952587]
	TIME [epoch: 40.9 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09270146503381768		[learning rate: 2.1723e-05]
	Learning Rate: 2.17232e-05
	LOSS [training: 0.09270146503381768 | validation: 0.26716995852043024]
	TIME [epoch: 41 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09548946992177905		[learning rate: 2.1621e-05]
	Learning Rate: 2.16208e-05
	LOSS [training: 0.09548946992177905 | validation: 0.27021016683280896]
	TIME [epoch: 41 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10167347107707002		[learning rate: 2.1519e-05]
	Learning Rate: 2.15189e-05
	LOSS [training: 0.10167347107707002 | validation: 0.2708590658110176]
	TIME [epoch: 41 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09143168408871782		[learning rate: 2.1418e-05]
	Learning Rate: 2.14175e-05
	LOSS [training: 0.09143168408871782 | validation: 0.27200928943773683]
	TIME [epoch: 41 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09367252584829712		[learning rate: 2.1317e-05]
	Learning Rate: 2.13166e-05
	LOSS [training: 0.09367252584829712 | validation: 0.27387800909430826]
	TIME [epoch: 41 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10216764260438682		[learning rate: 2.1216e-05]
	Learning Rate: 2.12162e-05
	LOSS [training: 0.10216764260438682 | validation: 0.27246219335401467]
	TIME [epoch: 41 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09808767753313535		[learning rate: 2.1116e-05]
	Learning Rate: 2.11162e-05
	LOSS [training: 0.09808767753313535 | validation: 0.2754386530154694]
	TIME [epoch: 41 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10719804131925875		[learning rate: 2.1017e-05]
	Learning Rate: 2.10167e-05
	LOSS [training: 0.10719804131925875 | validation: 0.2714756647099318]
	TIME [epoch: 41 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09794510753017782		[learning rate: 2.0918e-05]
	Learning Rate: 2.09177e-05
	LOSS [training: 0.09794510753017782 | validation: 0.27493664936587126]
	TIME [epoch: 41 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09139576261421911		[learning rate: 2.0819e-05]
	Learning Rate: 2.08191e-05
	LOSS [training: 0.09139576261421911 | validation: 0.27075944818793307]
	TIME [epoch: 41 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09342591416327643		[learning rate: 2.0721e-05]
	Learning Rate: 2.0721e-05
	LOSS [training: 0.09342591416327643 | validation: 0.2684826617542095]
	TIME [epoch: 41 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10619659400861808		[learning rate: 2.0623e-05]
	Learning Rate: 2.06233e-05
	LOSS [training: 0.10619659400861808 | validation: 0.26732208308926475]
	TIME [epoch: 41 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09362098405170055		[learning rate: 2.0526e-05]
	Learning Rate: 2.05262e-05
	LOSS [training: 0.09362098405170055 | validation: 0.26465098878830795]
	TIME [epoch: 41 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09489260589265672		[learning rate: 2.0429e-05]
	Learning Rate: 2.04294e-05
	LOSS [training: 0.09489260589265672 | validation: 0.2655432773746622]
	TIME [epoch: 41 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09407558759453753		[learning rate: 2.0333e-05]
	Learning Rate: 2.03332e-05
	LOSS [training: 0.09407558759453753 | validation: 0.2726154508559513]
	TIME [epoch: 41 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10453879910640289		[learning rate: 2.0237e-05]
	Learning Rate: 2.02374e-05
	LOSS [training: 0.10453879910640289 | validation: 0.265738908802502]
	TIME [epoch: 41 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09453532187956332		[learning rate: 2.0142e-05]
	Learning Rate: 2.0142e-05
	LOSS [training: 0.09453532187956332 | validation: 0.26927940682655527]
	TIME [epoch: 41 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09033455125152079		[learning rate: 2.0047e-05]
	Learning Rate: 2.00471e-05
	LOSS [training: 0.09033455125152079 | validation: 0.2643348702288688]
	TIME [epoch: 41 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10676587933841818		[learning rate: 1.9953e-05]
	Learning Rate: 1.99526e-05
	LOSS [training: 0.10676587933841818 | validation: 0.26710415274542276]
	TIME [epoch: 41 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10766871794672593		[learning rate: 1.9859e-05]
	Learning Rate: 1.98586e-05
	LOSS [training: 0.10766871794672593 | validation: 0.2705197224867612]
	TIME [epoch: 40.9 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10601798032853472		[learning rate: 1.9765e-05]
	Learning Rate: 1.9765e-05
	LOSS [training: 0.10601798032853472 | validation: 0.27166795869631766]
	TIME [epoch: 41 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09976929312863772		[learning rate: 1.9672e-05]
	Learning Rate: 1.96719e-05
	LOSS [training: 0.09976929312863772 | validation: 0.2737637456888118]
	TIME [epoch: 41 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10526606665739065		[learning rate: 1.9579e-05]
	Learning Rate: 1.95792e-05
	LOSS [training: 0.10526606665739065 | validation: 0.271320047534834]
	TIME [epoch: 40.9 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09865556727727309		[learning rate: 1.9487e-05]
	Learning Rate: 1.94869e-05
	LOSS [training: 0.09865556727727309 | validation: 0.26618208560237727]
	TIME [epoch: 41 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09951197996100929		[learning rate: 1.9395e-05]
	Learning Rate: 1.93951e-05
	LOSS [training: 0.09951197996100929 | validation: 0.2815129737328089]
	TIME [epoch: 41 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0998430184924846		[learning rate: 1.9304e-05]
	Learning Rate: 1.93037e-05
	LOSS [training: 0.0998430184924846 | validation: 0.2656162326642012]
	TIME [epoch: 41 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09504723918527141		[learning rate: 1.9213e-05]
	Learning Rate: 1.92128e-05
	LOSS [training: 0.09504723918527141 | validation: 0.2693980425012894]
	TIME [epoch: 41 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09535772178330464		[learning rate: 1.9122e-05]
	Learning Rate: 1.91222e-05
	LOSS [training: 0.09535772178330464 | validation: 0.26846439085154433]
	TIME [epoch: 41 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10514150035169861		[learning rate: 1.9032e-05]
	Learning Rate: 1.90321e-05
	LOSS [training: 0.10514150035169861 | validation: 0.26121357349128316]
	TIME [epoch: 41 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10496025558689034		[learning rate: 1.8942e-05]
	Learning Rate: 1.89424e-05
	LOSS [training: 0.10496025558689034 | validation: 0.2744133914875253]
	TIME [epoch: 40.9 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10412068018990633		[learning rate: 1.8853e-05]
	Learning Rate: 1.88532e-05
	LOSS [training: 0.10412068018990633 | validation: 0.2665660171293122]
	TIME [epoch: 41 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10935512175814568		[learning rate: 1.8764e-05]
	Learning Rate: 1.87643e-05
	LOSS [training: 0.10935512175814568 | validation: 0.27170643356354296]
	TIME [epoch: 41 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09626710156147152		[learning rate: 1.8676e-05]
	Learning Rate: 1.86759e-05
	LOSS [training: 0.09626710156147152 | validation: 0.2737251823400756]
	TIME [epoch: 41 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09910523018290596		[learning rate: 1.8588e-05]
	Learning Rate: 1.85879e-05
	LOSS [training: 0.09910523018290596 | validation: 0.2695418566289482]
	TIME [epoch: 40.9 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12047318820981942		[learning rate: 1.85e-05]
	Learning Rate: 1.85003e-05
	LOSS [training: 0.12047318820981942 | validation: 0.2706742432968413]
	TIME [epoch: 41 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10581978626424902		[learning rate: 1.8413e-05]
	Learning Rate: 1.84132e-05
	LOSS [training: 0.10581978626424902 | validation: 0.26222425613020117]
	TIME [epoch: 41 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10146903241273929		[learning rate: 1.8326e-05]
	Learning Rate: 1.83264e-05
	LOSS [training: 0.10146903241273929 | validation: 0.27758072984018245]
	TIME [epoch: 41 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09231440598435703		[learning rate: 1.824e-05]
	Learning Rate: 1.824e-05
	LOSS [training: 0.09231440598435703 | validation: 0.27511085814195047]
	TIME [epoch: 40.9 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10753132201397107		[learning rate: 1.8154e-05]
	Learning Rate: 1.81541e-05
	LOSS [training: 0.10753132201397107 | validation: 0.26680206992000904]
	TIME [epoch: 40.9 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11508469808781982		[learning rate: 1.8069e-05]
	Learning Rate: 1.80685e-05
	LOSS [training: 0.11508469808781982 | validation: 0.2810140973082968]
	TIME [epoch: 41 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09812868773344563		[learning rate: 1.7983e-05]
	Learning Rate: 1.79834e-05
	LOSS [training: 0.09812868773344563 | validation: 0.2734653282494018]
	TIME [epoch: 40.9 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10763570427946013		[learning rate: 1.7899e-05]
	Learning Rate: 1.78987e-05
	LOSS [training: 0.10763570427946013 | validation: 0.2744199738891494]
	TIME [epoch: 40.9 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09475247425561406		[learning rate: 1.7814e-05]
	Learning Rate: 1.78143e-05
	LOSS [training: 0.09475247425561406 | validation: 0.2741779039779352]
	TIME [epoch: 40.9 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0982304693427197		[learning rate: 1.773e-05]
	Learning Rate: 1.77304e-05
	LOSS [training: 0.0982304693427197 | validation: 0.26698354545040787]
	TIME [epoch: 40.9 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09533566516973924		[learning rate: 1.7647e-05]
	Learning Rate: 1.76468e-05
	LOSS [training: 0.09533566516973924 | validation: 0.2709296227555969]
	TIME [epoch: 40.9 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10376162314828855		[learning rate: 1.7564e-05]
	Learning Rate: 1.75637e-05
	LOSS [training: 0.10376162314828855 | validation: 0.27857781341869636]
	TIME [epoch: 40.9 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10184430869885214		[learning rate: 1.7481e-05]
	Learning Rate: 1.74809e-05
	LOSS [training: 0.10184430869885214 | validation: 0.2705790074239907]
	TIME [epoch: 40.9 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11238720200950855		[learning rate: 1.7399e-05]
	Learning Rate: 1.73985e-05
	LOSS [training: 0.11238720200950855 | validation: 0.28123382290758175]
	TIME [epoch: 40.9 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10880418295993577		[learning rate: 1.7317e-05]
	Learning Rate: 1.73166e-05
	LOSS [training: 0.10880418295993577 | validation: 0.27488916543359676]
	TIME [epoch: 40.9 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09298779381698545		[learning rate: 1.7235e-05]
	Learning Rate: 1.7235e-05
	LOSS [training: 0.09298779381698545 | validation: 0.27356429976513996]
	TIME [epoch: 41 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1037974896903761		[learning rate: 1.7154e-05]
	Learning Rate: 1.71538e-05
	LOSS [training: 0.1037974896903761 | validation: 0.27171728417727187]
	TIME [epoch: 41 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09907214974477874		[learning rate: 1.7073e-05]
	Learning Rate: 1.70729e-05
	LOSS [training: 0.09907214974477874 | validation: 0.2793433061508491]
	TIME [epoch: 41 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10835811606735526		[learning rate: 1.6992e-05]
	Learning Rate: 1.69925e-05
	LOSS [training: 0.10835811606735526 | validation: 0.2736317837007369]
	TIME [epoch: 41 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11756393256330075		[learning rate: 1.6912e-05]
	Learning Rate: 1.69124e-05
	LOSS [training: 0.11756393256330075 | validation: 0.2730963325732708]
	TIME [epoch: 41 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09700075668343225		[learning rate: 1.6833e-05]
	Learning Rate: 1.68327e-05
	LOSS [training: 0.09700075668343225 | validation: 0.2783679761927845]
	TIME [epoch: 41 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11213538385490553		[learning rate: 1.6753e-05]
	Learning Rate: 1.67534e-05
	LOSS [training: 0.11213538385490553 | validation: 0.2744921769300773]
	TIME [epoch: 41 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0875629128787027		[learning rate: 1.6674e-05]
	Learning Rate: 1.66744e-05
	LOSS [training: 0.0875629128787027 | validation: 0.2730300303866098]
	TIME [epoch: 41 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10534037477623344		[learning rate: 1.6596e-05]
	Learning Rate: 1.65959e-05
	LOSS [training: 0.10534037477623344 | validation: 0.2692638392847878]
	TIME [epoch: 41 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11973903701382357		[learning rate: 1.6518e-05]
	Learning Rate: 1.65177e-05
	LOSS [training: 0.11973903701382357 | validation: 0.27668078555061804]
	TIME [epoch: 41 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10993209653229208		[learning rate: 1.644e-05]
	Learning Rate: 1.64398e-05
	LOSS [training: 0.10993209653229208 | validation: 0.26716008662868856]
	TIME [epoch: 40.9 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1123496389397797		[learning rate: 1.6362e-05]
	Learning Rate: 1.63624e-05
	LOSS [training: 0.1123496389397797 | validation: 0.27645508219692755]
	TIME [epoch: 40.9 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11874360773464468		[learning rate: 1.6285e-05]
	Learning Rate: 1.62853e-05
	LOSS [training: 0.11874360773464468 | validation: 0.27673696192907]
	TIME [epoch: 40.9 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11448527080426607		[learning rate: 1.6209e-05]
	Learning Rate: 1.62085e-05
	LOSS [training: 0.11448527080426607 | validation: 0.27072519552357777]
	TIME [epoch: 41 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240719_004707/states/model_facs_v4_dec2b_2dpca_v13_1398.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 30375.148 seconds.
