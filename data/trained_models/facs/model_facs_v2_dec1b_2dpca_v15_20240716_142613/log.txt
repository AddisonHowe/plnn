Args:
Namespace(name='model_facs_v2_dec1b_2dpca_v15', outdir='out/model_training/model_facs_v2_dec1b_2dpca_v15', training_data='data/training_data/facs_v2/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs_v2/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=100, ncells_sample=100, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3539336138

Training model...

Saving initial model state to: out/model_training/model_facs_v2_dec1b_2dpca_v15_20240716_142613/states/model_facs_v2_dec1b_2dpca_v15_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.26506257781395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.26506257781395 | validation: 1.1117443326390313]
	TIME [epoch: 32.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v15_20240716_142613/states/model_facs_v2_dec1b_2dpca_v15_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.160169343102103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.160169343102103 | validation: 1.0726039341926614]
	TIME [epoch: 7.13 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v15_20240716_142613/states/model_facs_v2_dec1b_2dpca_v15_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.126629194018406		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.126629194018406 | validation: 1.0264988747325308]
	TIME [epoch: 7.11 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v15_20240716_142613/states/model_facs_v2_dec1b_2dpca_v15_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0503087170540104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0503087170540104 | validation: 0.9375867518033143]
	TIME [epoch: 7.11 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v15_20240716_142613/states/model_facs_v2_dec1b_2dpca_v15_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.970560097669052		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.970560097669052 | validation: 0.8501836667102511]
	TIME [epoch: 7.11 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v15_20240716_142613/states/model_facs_v2_dec1b_2dpca_v15_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8814734728601		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8814734728601 | validation: 0.8643115008123019]
	TIME [epoch: 7.1 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.872600426041878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.872600426041878 | validation: 0.755711285926516]
	TIME [epoch: 7.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v15_20240716_142613/states/model_facs_v2_dec1b_2dpca_v15_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.74753264650893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.74753264650893 | validation: 0.7720238568459052]
	TIME [epoch: 7.11 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6828808289875918		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6828808289875918 | validation: 0.5760935961338387]
	TIME [epoch: 7.11 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v15_20240716_142613/states/model_facs_v2_dec1b_2dpca_v15_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5549416569847303		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5549416569847303 | validation: 0.5516141238728787]
	TIME [epoch: 7.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v15_20240716_142613/states/model_facs_v2_dec1b_2dpca_v15_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5174092901479286		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5174092901479286 | validation: 0.5210205342802828]
	TIME [epoch: 7.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v15_20240716_142613/states/model_facs_v2_dec1b_2dpca_v15_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4782356677921511		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4782356677921511 | validation: 0.660927157311386]
	TIME [epoch: 7.1 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.47903983572297393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47903983572297393 | validation: 0.4558482925717918]
	TIME [epoch: 7.11 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v15_20240716_142613/states/model_facs_v2_dec1b_2dpca_v15_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4103706377299112		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4103706377299112 | validation: 0.384748993313183]
	TIME [epoch: 7.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v15_20240716_142613/states/model_facs_v2_dec1b_2dpca_v15_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3921419270408427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3921419270408427 | validation: 0.3770218718754312]
	TIME [epoch: 7.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v15_20240716_142613/states/model_facs_v2_dec1b_2dpca_v15_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3743108136101962		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3743108136101962 | validation: 0.34890747614856726]
	TIME [epoch: 7.09 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v15_20240716_142613/states/model_facs_v2_dec1b_2dpca_v15_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35863344920989426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35863344920989426 | validation: 0.3260351091828556]
	TIME [epoch: 7.11 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v15_20240716_142613/states/model_facs_v2_dec1b_2dpca_v15_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3470878824642994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3470878824642994 | validation: 0.3848973774755203]
	TIME [epoch: 7.11 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3452032398166865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3452032398166865 | validation: 0.367874273788955]
	TIME [epoch: 7.1 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35514388596226865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35514388596226865 | validation: 0.3342255674898892]
	TIME [epoch: 7.1 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32181722507654803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32181722507654803 | validation: 0.2947758154053832]
	TIME [epoch: 7.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v15_20240716_142613/states/model_facs_v2_dec1b_2dpca_v15_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3330684061409271		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3330684061409271 | validation: 0.35731835099784603]
	TIME [epoch: 7.13 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3288192382136693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3288192382136693 | validation: 0.39987504948545427]
	TIME [epoch: 7.1 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33617300170921827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33617300170921827 | validation: 0.2977666330832579]
	TIME [epoch: 7.1 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3246882265907491		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3246882265907491 | validation: 0.2977744506262793]
	TIME [epoch: 7.1 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32332878114860936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32332878114860936 | validation: 0.31168852371047545]
	TIME [epoch: 7.1 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.304805943142673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.304805943142673 | validation: 0.25727302845653194]
	TIME [epoch: 7.11 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v15_20240716_142613/states/model_facs_v2_dec1b_2dpca_v15_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29465796202034256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29465796202034256 | validation: 0.28611725162578583]
	TIME [epoch: 7.1 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2997706858551769		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2997706858551769 | validation: 0.25750251958777276]
	TIME [epoch: 7.1 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31004244648303725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31004244648303725 | validation: 0.285597604105703]
	TIME [epoch: 7.1 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3137325188076239		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3137325188076239 | validation: 0.28101844924163394]
	TIME [epoch: 7.11 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28791576530505525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28791576530505525 | validation: 0.3074953142114977]
	TIME [epoch: 7.11 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3111795408969078		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3111795408969078 | validation: 0.28663369605688394]
	TIME [epoch: 7.1 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2823971525209721		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2823971525209721 | validation: 0.2502177047838735]
	TIME [epoch: 7.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v15_20240716_142613/states/model_facs_v2_dec1b_2dpca_v15_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30004266215360736		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30004266215360736 | validation: 0.27115560508895775]
	TIME [epoch: 7.1 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28781401906602316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28781401906602316 | validation: 0.25485518807113505]
	TIME [epoch: 7.11 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.282095928124072		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.282095928124072 | validation: 0.35249530591082184]
	TIME [epoch: 7.1 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3116962881221921		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3116962881221921 | validation: 0.29288478943831847]
	TIME [epoch: 7.1 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29263401695833297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29263401695833297 | validation: 0.2725783382469052]
	TIME [epoch: 7.1 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2965618392190311		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2965618392190311 | validation: 0.23264935788400803]
	TIME [epoch: 7.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v15_20240716_142613/states/model_facs_v2_dec1b_2dpca_v15_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27761278934077516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27761278934077516 | validation: 0.2742521710079803]
	TIME [epoch: 7.12 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3056329533081226		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3056329533081226 | validation: 0.25317870232960277]
	TIME [epoch: 7.1 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28136998412152936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28136998412152936 | validation: 0.28109310464967785]
	TIME [epoch: 7.1 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2886080988074451		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2886080988074451 | validation: 0.24090056915168648]
	TIME [epoch: 7.1 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2763252876503428		[learning rate: 0.0099823]
	Learning Rate: 0.0099823
	LOSS [training: 0.2763252876503428 | validation: 0.2457351185141185]
	TIME [epoch: 7.11 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28308071996160417		[learning rate: 0.0099426]
	Learning Rate: 0.0099426
	LOSS [training: 0.28308071996160417 | validation: 0.30410309651323914]
	TIME [epoch: 7.1 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27306464248529444		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.27306464248529444 | validation: 0.27017542926637855]
	TIME [epoch: 7.1 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2727881005349413		[learning rate: 0.0098637]
	Learning Rate: 0.00986367
	LOSS [training: 0.2727881005349413 | validation: 0.23694221978839072]
	TIME [epoch: 7.1 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28182276571042597		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 0.28182276571042597 | validation: 0.22714564529569908]
	TIME [epoch: 7.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v15_20240716_142613/states/model_facs_v2_dec1b_2dpca_v15_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2660795854001392		[learning rate: 0.0097854]
	Learning Rate: 0.00978536
	LOSS [training: 0.2660795854001392 | validation: 0.23023355727174466]
	TIME [epoch: 7.12 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28303642747425684		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.28303642747425684 | validation: 0.31600685015393454]
	TIME [epoch: 37.2 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28962832307756003		[learning rate: 0.0097077]
	Learning Rate: 0.00970768
	LOSS [training: 0.28962832307756003 | validation: 0.24731191644074474]
	TIME [epoch: 13.6 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26825868875764175		[learning rate: 0.0096691]
	Learning Rate: 0.00966907
	LOSS [training: 0.26825868875764175 | validation: 0.20786253362706245]
	TIME [epoch: 13.6 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v15_20240716_142613/states/model_facs_v2_dec1b_2dpca_v15_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2676847807492757		[learning rate: 0.0096306]
	Learning Rate: 0.00963061
	LOSS [training: 0.2676847807492757 | validation: 0.23260278686128685]
	TIME [epoch: 13.6 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28136972105764735		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.28136972105764735 | validation: 0.22454039739232287]
	TIME [epoch: 13.6 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2547833530722468		[learning rate: 0.0095542]
	Learning Rate: 0.00955415
	LOSS [training: 0.2547833530722468 | validation: 0.2193844362046394]
	TIME [epoch: 13.6 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27960962650281235		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 0.27960962650281235 | validation: 0.2225760179749785]
	TIME [epoch: 13.6 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2639432169234862		[learning rate: 0.0094783]
	Learning Rate: 0.00947831
	LOSS [training: 0.2639432169234862 | validation: 0.2501656309770929]
	TIME [epoch: 13.6 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25902039695384316		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.25902039695384316 | validation: 0.2432926623152961]
	TIME [epoch: 13.6 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25876291673408947		[learning rate: 0.0094031]
	Learning Rate: 0.00940306
	LOSS [training: 0.25876291673408947 | validation: 0.2403858553039963]
	TIME [epoch: 13.6 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2779430374273321		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.2779430374273321 | validation: 0.22452697825342355]
	TIME [epoch: 13.7 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2657267694913133		[learning rate: 0.0093284]
	Learning Rate: 0.00932841
	LOSS [training: 0.2657267694913133 | validation: 0.2607947800760005]
	TIME [epoch: 13.6 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26961434162676995		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.26961434162676995 | validation: 0.24242581527699808]
	TIME [epoch: 13.6 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25882950378096736		[learning rate: 0.0092544]
	Learning Rate: 0.00925435
	LOSS [training: 0.25882950378096736 | validation: 0.20287378854544427]
	TIME [epoch: 13.6 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v15_20240716_142613/states/model_facs_v2_dec1b_2dpca_v15_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2715926890367785		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.2715926890367785 | validation: 0.2131306809809872]
	TIME [epoch: 13.6 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24876599973228875		[learning rate: 0.0091809]
	Learning Rate: 0.00918089
	LOSS [training: 0.24876599973228875 | validation: 0.22648925975565826]
	TIME [epoch: 13.6 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26021680441514733		[learning rate: 0.0091444]
	Learning Rate: 0.00914437
	LOSS [training: 0.26021680441514733 | validation: 0.25289583885083355]
	TIME [epoch: 13.6 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2561427419185158		[learning rate: 0.009108]
	Learning Rate: 0.009108
	LOSS [training: 0.2561427419185158 | validation: 0.22429512300217164]
	TIME [epoch: 13.6 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26740817711250436		[learning rate: 0.0090718]
	Learning Rate: 0.00907178
	LOSS [training: 0.26740817711250436 | validation: 0.21627625925670202]
	TIME [epoch: 13.6 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25927702629688176		[learning rate: 0.0090357]
	Learning Rate: 0.00903569
	LOSS [training: 0.25927702629688176 | validation: 0.20572057647915493]
	TIME [epoch: 13.6 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2501984566453565		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.2501984566453565 | validation: 0.1997642549001372]
	TIME [epoch: 13.6 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v15_20240716_142613/states/model_facs_v2_dec1b_2dpca_v15_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2598620416289376		[learning rate: 0.008964]
	Learning Rate: 0.00896396
	LOSS [training: 0.2598620416289376 | validation: 0.21127908884734606]
	TIME [epoch: 13.6 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26347483976377895		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 0.26347483976377895 | validation: 0.20771991237585388]
	TIME [epoch: 13.6 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2662293545688274		[learning rate: 0.0088928]
	Learning Rate: 0.0088928
	LOSS [training: 0.2662293545688274 | validation: 0.228782099137316]
	TIME [epoch: 13.6 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26707660313517884		[learning rate: 0.0088574]
	Learning Rate: 0.00885743
	LOSS [training: 0.26707660313517884 | validation: 0.204722139169925]
	TIME [epoch: 13.6 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2576267403712258		[learning rate: 0.0088222]
	Learning Rate: 0.0088222
	LOSS [training: 0.2576267403712258 | validation: 0.21779684515745812]
	TIME [epoch: 13.6 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24363674589347153		[learning rate: 0.0087871]
	Learning Rate: 0.00878711
	LOSS [training: 0.24363674589347153 | validation: 0.29517318669859616]
	TIME [epoch: 13.6 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2643277964638172		[learning rate: 0.0087522]
	Learning Rate: 0.00875216
	LOSS [training: 0.2643277964638172 | validation: 0.25772479482630606]
	TIME [epoch: 13.6 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25646762767973463		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.25646762767973463 | validation: 0.21624491014495512]
	TIME [epoch: 13.6 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2573177194760665		[learning rate: 0.0086827]
	Learning Rate: 0.00868268
	LOSS [training: 0.2573177194760665 | validation: 0.20837193157013661]
	TIME [epoch: 13.6 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2554223860557345		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.2554223860557345 | validation: 0.23538100848342874]
	TIME [epoch: 13.6 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25112723771995404		[learning rate: 0.0086138]
	Learning Rate: 0.00861375
	LOSS [training: 0.25112723771995404 | validation: 0.2131292169029288]
	TIME [epoch: 13.6 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27401458298318804		[learning rate: 0.0085795]
	Learning Rate: 0.00857949
	LOSS [training: 0.27401458298318804 | validation: 0.23817063706527847]
	TIME [epoch: 13.6 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.253420089386052		[learning rate: 0.0085454]
	Learning Rate: 0.00854537
	LOSS [training: 0.253420089386052 | validation: 0.2157939880830373]
	TIME [epoch: 13.6 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2539823596340689		[learning rate: 0.0085114]
	Learning Rate: 0.00851138
	LOSS [training: 0.2539823596340689 | validation: 0.2050759840893445]
	TIME [epoch: 13.6 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2570353922225324		[learning rate: 0.0084775]
	Learning Rate: 0.00847753
	LOSS [training: 0.2570353922225324 | validation: 0.22330444087100382]
	TIME [epoch: 13.6 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26437783953408817		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.26437783953408817 | validation: 0.21204147375966992]
	TIME [epoch: 13.6 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2585176672157351		[learning rate: 0.0084102]
	Learning Rate: 0.00841023
	LOSS [training: 0.2585176672157351 | validation: 0.19317194117066]
	TIME [epoch: 13.6 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v15_20240716_142613/states/model_facs_v2_dec1b_2dpca_v15_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2713077733163526		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 0.2713077733163526 | validation: 0.20323983339483637]
	TIME [epoch: 13.6 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25886753304031124		[learning rate: 0.0083435]
	Learning Rate: 0.00834346
	LOSS [training: 0.25886753304031124 | validation: 0.23880756597133335]
	TIME [epoch: 13.6 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2715181536981597		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.2715181536981597 | validation: 0.21146410590086565]
	TIME [epoch: 13.6 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2637341736005985		[learning rate: 0.0082772]
	Learning Rate: 0.00827722
	LOSS [training: 0.2637341736005985 | validation: 0.2131958509996414]
	TIME [epoch: 13.6 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22802998498846958		[learning rate: 0.0082443]
	Learning Rate: 0.0082443
	LOSS [training: 0.22802998498846958 | validation: 0.21627131418918735]
	TIME [epoch: 13.6 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26075125300939894		[learning rate: 0.0082115]
	Learning Rate: 0.00821151
	LOSS [training: 0.26075125300939894 | validation: 0.21640769451998407]
	TIME [epoch: 13.6 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24628206428701194		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.24628206428701194 | validation: 0.19823324423501537]
	TIME [epoch: 13.6 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24751853165282509		[learning rate: 0.0081463]
	Learning Rate: 0.00814632
	LOSS [training: 0.24751853165282509 | validation: 0.2038923008751846]
	TIME [epoch: 13.6 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2671135151189819		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.2671135151189819 | validation: 0.21757629739173553]
	TIME [epoch: 13.6 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24581782489518947		[learning rate: 0.0080816]
	Learning Rate: 0.00808165
	LOSS [training: 0.24581782489518947 | validation: 0.19454645865296194]
	TIME [epoch: 13.6 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2535303593819596		[learning rate: 0.0080495]
	Learning Rate: 0.00804951
	LOSS [training: 0.2535303593819596 | validation: 0.22002040255137092]
	TIME [epoch: 13.6 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2505401785664779		[learning rate: 0.0080175]
	Learning Rate: 0.00801749
	LOSS [training: 0.2505401785664779 | validation: 0.21765651459231594]
	TIME [epoch: 13.6 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2611383864677336		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.2611383864677336 | validation: 0.19674328223496745]
	TIME [epoch: 13.6 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2560135985964293		[learning rate: 0.0079538]
	Learning Rate: 0.00795384
	LOSS [training: 0.2560135985964293 | validation: 0.1970883772848423]
	TIME [epoch: 13.6 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23997177750936258		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.23997177750936258 | validation: 0.21900684075571758]
	TIME [epoch: 13.6 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2518241251041105		[learning rate: 0.0078907]
	Learning Rate: 0.0078907
	LOSS [training: 0.2518241251041105 | validation: 0.197453829230959]
	TIME [epoch: 13.6 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24754643230439777		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 0.24754643230439777 | validation: 0.19817999630111838]
	TIME [epoch: 13.6 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25313066047983557		[learning rate: 0.0078281]
	Learning Rate: 0.00782805
	LOSS [training: 0.25313066047983557 | validation: 0.20786845014036573]
	TIME [epoch: 13.6 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2577298712577653		[learning rate: 0.0077969]
	Learning Rate: 0.00779692
	LOSS [training: 0.2577298712577653 | validation: 0.19152074483167766]
	TIME [epoch: 13.6 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v15_20240716_142613/states/model_facs_v2_dec1b_2dpca_v15_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24918778318204446		[learning rate: 0.0077659]
	Learning Rate: 0.00776591
	LOSS [training: 0.24918778318204446 | validation: 0.2015348549245087]
	TIME [epoch: 13.6 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24613985669692356		[learning rate: 0.007735]
	Learning Rate: 0.00773502
	LOSS [training: 0.24613985669692356 | validation: 0.19600743816301514]
	TIME [epoch: 13.6 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25591338828485455		[learning rate: 0.0077043]
	Learning Rate: 0.00770426
	LOSS [training: 0.25591338828485455 | validation: 0.2109438074193347]
	TIME [epoch: 13.6 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2511894265602792		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.2511894265602792 | validation: 0.19973346787762775]
	TIME [epoch: 13.6 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23655830990768464		[learning rate: 0.0076431]
	Learning Rate: 0.00764309
	LOSS [training: 0.23655830990768464 | validation: 0.2043734575550436]
	TIME [epoch: 13.6 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2539672434363721		[learning rate: 0.0076127]
	Learning Rate: 0.00761269
	LOSS [training: 0.2539672434363721 | validation: 0.19480258788136323]
	TIME [epoch: 13.6 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26163305941843673		[learning rate: 0.0075824]
	Learning Rate: 0.00758242
	LOSS [training: 0.26163305941843673 | validation: 0.21563581589775965]
	TIME [epoch: 13.7 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24446307621802565		[learning rate: 0.0075523]
	Learning Rate: 0.00755226
	LOSS [training: 0.24446307621802565 | validation: 0.19276786172721067]
	TIME [epoch: 13.6 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2517075060281986		[learning rate: 0.0075222]
	Learning Rate: 0.00752222
	LOSS [training: 0.2517075060281986 | validation: 0.2062789633396739]
	TIME [epoch: 13.6 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24612755830279343		[learning rate: 0.0074923]
	Learning Rate: 0.0074923
	LOSS [training: 0.24612755830279343 | validation: 0.21749701445207906]
	TIME [epoch: 13.6 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25521680248811035		[learning rate: 0.0074625]
	Learning Rate: 0.0074625
	LOSS [training: 0.25521680248811035 | validation: 0.20892969733305958]
	TIME [epoch: 13.6 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24659398871143548		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.24659398871143548 | validation: 0.21394070724566813]
	TIME [epoch: 13.6 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26139014795391424		[learning rate: 0.0074033]
	Learning Rate: 0.00740326
	LOSS [training: 0.26139014795391424 | validation: 0.2091399000021968]
	TIME [epoch: 13.6 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25390994291375313		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.25390994291375313 | validation: 0.2070053588022608]
	TIME [epoch: 13.6 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2553803597500728		[learning rate: 0.0073445]
	Learning Rate: 0.00734449
	LOSS [training: 0.2553803597500728 | validation: 0.21586975254228608]
	TIME [epoch: 13.6 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24605856446384955		[learning rate: 0.0073153]
	Learning Rate: 0.00731528
	LOSS [training: 0.24605856446384955 | validation: 0.23415571595128953]
	TIME [epoch: 13.6 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25363743023751634		[learning rate: 0.0072862]
	Learning Rate: 0.00728618
	LOSS [training: 0.25363743023751634 | validation: 0.19022180391645]
	TIME [epoch: 13.6 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v15_20240716_142613/states/model_facs_v2_dec1b_2dpca_v15_124.pth
	Model improved!!!
EPOCH 125/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.252293400472112		[learning rate: 0.0072572]
	Learning Rate: 0.0072572
	LOSS [training: 0.252293400472112 | validation: 0.20671688623421516]
	TIME [epoch: 13.7 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2498236879138181		[learning rate: 0.0072283]
	Learning Rate: 0.00722834
	LOSS [training: 0.2498236879138181 | validation: 0.20317087837985665]
	TIME [epoch: 13.6 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24044129309275897		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.24044129309275897 | validation: 0.20688197095958633]
	TIME [epoch: 13.6 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24170231140792872		[learning rate: 0.007171]
	Learning Rate: 0.00717095
	LOSS [training: 0.24170231140792872 | validation: 0.21088518129470338]
	TIME [epoch: 13.6 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26249640644011785		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.26249640644011785 | validation: 0.22211093503945975]
	TIME [epoch: 13.6 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2364620804688962		[learning rate: 0.007114]
	Learning Rate: 0.00711403
	LOSS [training: 0.2364620804688962 | validation: 0.2070480117984562]
	TIME [epoch: 13.6 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23686149570602055		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.23686149570602055 | validation: 0.20936606907081318]
	TIME [epoch: 13.6 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2416695058170633		[learning rate: 0.0070575]
	Learning Rate: 0.00705755
	LOSS [training: 0.2416695058170633 | validation: 0.1998238762467789]
	TIME [epoch: 13.6 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2584966083906617		[learning rate: 0.0070295]
	Learning Rate: 0.00702948
	LOSS [training: 0.2584966083906617 | validation: 0.20794707925739306]
	TIME [epoch: 13.6 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25101308265866396		[learning rate: 0.0070015]
	Learning Rate: 0.00700152
	LOSS [training: 0.25101308265866396 | validation: 0.20383927969277854]
	TIME [epoch: 13.6 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24052795387485362		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.24052795387485362 | validation: 0.23206031300061838]
	TIME [epoch: 13.6 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2642012534786727		[learning rate: 0.0069459]
	Learning Rate: 0.00694594
	LOSS [training: 0.2642012534786727 | validation: 0.20038147855591468]
	TIME [epoch: 13.6 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25123916115885947		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 0.25123916115885947 | validation: 0.1943411590400465]
	TIME [epoch: 13.6 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24228933547189455		[learning rate: 0.0068908]
	Learning Rate: 0.00689079
	LOSS [training: 0.24228933547189455 | validation: 0.19898573568514785]
	TIME [epoch: 13.6 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24181057586220364		[learning rate: 0.0068634]
	Learning Rate: 0.00686339
	LOSS [training: 0.24181057586220364 | validation: 0.20990973185214973]
	TIME [epoch: 13.6 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23690908092604682		[learning rate: 0.0068361]
	Learning Rate: 0.00683609
	LOSS [training: 0.23690908092604682 | validation: 0.20771131338917068]
	TIME [epoch: 13.6 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24719635476318716		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.24719635476318716 | validation: 0.20440348713423445]
	TIME [epoch: 13.6 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2506328524599978		[learning rate: 0.0067818]
	Learning Rate: 0.00678182
	LOSS [training: 0.2506328524599978 | validation: 0.18540195728591286]
	TIME [epoch: 13.6 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v15_20240716_142613/states/model_facs_v2_dec1b_2dpca_v15_142.pth
	Model improved!!!
EPOCH 143/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24488724463288378		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.24488724463288378 | validation: 0.20894307524742853]
	TIME [epoch: 13.6 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2514016422270362		[learning rate: 0.006728]
	Learning Rate: 0.00672798
	LOSS [training: 0.2514016422270362 | validation: 0.19484563916874093]
	TIME [epoch: 13.6 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24710874916493855		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 0.24710874916493855 | validation: 0.19829183927823055]
	TIME [epoch: 13.6 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23667545503675683		[learning rate: 0.0066746]
	Learning Rate: 0.00667457
	LOSS [training: 0.23667545503675683 | validation: 0.1891993944430213]
	TIME [epoch: 13.6 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2514647063137562		[learning rate: 0.006648]
	Learning Rate: 0.00664802
	LOSS [training: 0.2514647063137562 | validation: 0.21622191837082383]
	TIME [epoch: 13.6 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24951783161187702		[learning rate: 0.0066216]
	Learning Rate: 0.00662158
	LOSS [training: 0.24951783161187702 | validation: 0.21119175723939768]
	TIME [epoch: 13.6 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24616113969496123		[learning rate: 0.0065952]
	Learning Rate: 0.00659524
	LOSS [training: 0.24616113969496123 | validation: 0.21154699154522189]
	TIME [epoch: 13.6 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24396588441286385		[learning rate: 0.006569]
	Learning Rate: 0.00656901
	LOSS [training: 0.24396588441286385 | validation: 0.19280500410807583]
	TIME [epoch: 13.6 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24226149353722276		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.24226149353722276 | validation: 0.2054731189999805]
	TIME [epoch: 13.6 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2426987602139226		[learning rate: 0.0065169]
	Learning Rate: 0.00651686
	LOSS [training: 0.2426987602139226 | validation: 0.20107690357946245]
	TIME [epoch: 13.6 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25847612184628255		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 0.25847612184628255 | validation: 0.19998644461451723]
	TIME [epoch: 13.6 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24546226436872734		[learning rate: 0.0064651]
	Learning Rate: 0.00646512
	LOSS [training: 0.24546226436872734 | validation: 0.18816837321943986]
	TIME [epoch: 13.6 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.243299032962242		[learning rate: 0.0064394]
	Learning Rate: 0.00643941
	LOSS [training: 0.243299032962242 | validation: 0.20060107114549855]
	TIME [epoch: 13.6 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23928063031704364		[learning rate: 0.0064138]
	Learning Rate: 0.0064138
	LOSS [training: 0.23928063031704364 | validation: 0.19873154384044062]
	TIME [epoch: 13.6 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2476633139490193		[learning rate: 0.0063883]
	Learning Rate: 0.00638829
	LOSS [training: 0.2476633139490193 | validation: 0.1899795252602901]
	TIME [epoch: 13.6 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25153243420302274		[learning rate: 0.0063629]
	Learning Rate: 0.00636288
	LOSS [training: 0.25153243420302274 | validation: 0.18789920096828905]
	TIME [epoch: 13.6 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2542212648332851		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.2542212648332851 | validation: 0.20122540337495637]
	TIME [epoch: 13.6 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2318261430505445		[learning rate: 0.0063124]
	Learning Rate: 0.00631237
	LOSS [training: 0.2318261430505445 | validation: 0.19419891983238133]
	TIME [epoch: 13.6 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23497321859496503		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.23497321859496503 | validation: 0.18110317224381667]
	TIME [epoch: 13.6 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v15_20240716_142613/states/model_facs_v2_dec1b_2dpca_v15_161.pth
	Model improved!!!
EPOCH 162/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24438904690594093		[learning rate: 0.0062623]
	Learning Rate: 0.00626226
	LOSS [training: 0.24438904690594093 | validation: 0.22916115686460842]
	TIME [epoch: 13.6 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23578607621033873		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.23578607621033873 | validation: 0.2027042473346595]
	TIME [epoch: 13.6 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23215355939790028		[learning rate: 0.0062125]
	Learning Rate: 0.00621254
	LOSS [training: 0.23215355939790028 | validation: 0.20283656671784583]
	TIME [epoch: 13.6 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.234296477204206		[learning rate: 0.0061878]
	Learning Rate: 0.00618783
	LOSS [training: 0.234296477204206 | validation: 0.2196537417497452]
	TIME [epoch: 13.6 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25716272057847284		[learning rate: 0.0061632]
	Learning Rate: 0.00616322
	LOSS [training: 0.25716272057847284 | validation: 0.20381261578857254]
	TIME [epoch: 13.6 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2520654694101354		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.2520654694101354 | validation: 0.19198303481138707]
	TIME [epoch: 13.6 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.240793693307349		[learning rate: 0.0061143]
	Learning Rate: 0.00611429
	LOSS [training: 0.240793693307349 | validation: 0.20444954933150333]
	TIME [epoch: 13.6 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24131818949295245		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 0.24131818949295245 | validation: 0.19292803753392263]
	TIME [epoch: 13.6 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.242710639372064		[learning rate: 0.0060658]
	Learning Rate: 0.00606575
	LOSS [training: 0.242710639372064 | validation: 0.204559218194121]
	TIME [epoch: 13.6 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2381864293394162		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.2381864293394162 | validation: 0.1982907849634788]
	TIME [epoch: 13.6 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2398448890864891		[learning rate: 0.0060176]
	Learning Rate: 0.0060176
	LOSS [training: 0.2398448890864891 | validation: 0.2144755712029592]
	TIME [epoch: 13.6 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2525040219996234		[learning rate: 0.0059937]
	Learning Rate: 0.00599366
	LOSS [training: 0.2525040219996234 | validation: 0.20751761411054637]
	TIME [epoch: 13.6 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24529539428363853		[learning rate: 0.0059698]
	Learning Rate: 0.00596982
	LOSS [training: 0.24529539428363853 | validation: 0.20316311959849567]
	TIME [epoch: 13.6 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23985154823777174		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.23985154823777174 | validation: 0.19230358110967322]
	TIME [epoch: 13.6 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2461290705798786		[learning rate: 0.0059224]
	Learning Rate: 0.00592243
	LOSS [training: 0.2461290705798786 | validation: 0.2000081303443951]
	TIME [epoch: 13.6 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2343485627454275		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 0.2343485627454275 | validation: 0.19122266954348974]
	TIME [epoch: 13.6 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24196666872278907		[learning rate: 0.0058754]
	Learning Rate: 0.00587541
	LOSS [training: 0.24196666872278907 | validation: 0.19978354618938932]
	TIME [epoch: 13.6 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25111733472971237		[learning rate: 0.005852]
	Learning Rate: 0.00585205
	LOSS [training: 0.25111733472971237 | validation: 0.19992702365096576]
	TIME [epoch: 13.6 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2418731181018111		[learning rate: 0.0058288]
	Learning Rate: 0.00582877
	LOSS [training: 0.2418731181018111 | validation: 0.20481316007343192]
	TIME [epoch: 13.6 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2288537482022845		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.2288537482022845 | validation: 0.1971971478312795]
	TIME [epoch: 13.6 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24695722626182967		[learning rate: 0.0057825]
	Learning Rate: 0.0057825
	LOSS [training: 0.24695722626182967 | validation: 0.20270549351157005]
	TIME [epoch: 13.6 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2424874621579951		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.2424874621579951 | validation: 0.20665801949988807]
	TIME [epoch: 13.6 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25159905952610795		[learning rate: 0.0057366]
	Learning Rate: 0.00573659
	LOSS [training: 0.25159905952610795 | validation: 0.1914024484086927]
	TIME [epoch: 13.6 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24930334053524955		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 0.24930334053524955 | validation: 0.1810055798424858]
	TIME [epoch: 13.6 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v15_20240716_142613/states/model_facs_v2_dec1b_2dpca_v15_185.pth
	Model improved!!!
EPOCH 186/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23106491624614867		[learning rate: 0.005691]
	Learning Rate: 0.00569105
	LOSS [training: 0.23106491624614867 | validation: 0.204557389874038]
	TIME [epoch: 13.6 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.239795283142751		[learning rate: 0.0056684]
	Learning Rate: 0.00566841
	LOSS [training: 0.239795283142751 | validation: 0.19975505377640843]
	TIME [epoch: 13.6 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23444244449242024		[learning rate: 0.0056459]
	Learning Rate: 0.00564587
	LOSS [training: 0.23444244449242024 | validation: 0.18645964833129242]
	TIME [epoch: 13.6 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23860820143555753		[learning rate: 0.0056234]
	Learning Rate: 0.00562341
	LOSS [training: 0.23860820143555753 | validation: 0.1927645944411822]
	TIME [epoch: 13.6 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24395555784336245		[learning rate: 0.005601]
	Learning Rate: 0.00560105
	LOSS [training: 0.24395555784336245 | validation: 0.21884809980178038]
	TIME [epoch: 13.6 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24493715925837817		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.24493715925837817 | validation: 0.20765060519340234]
	TIME [epoch: 13.6 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22022593269678656		[learning rate: 0.0055566]
	Learning Rate: 0.00555658
	LOSS [training: 0.22022593269678656 | validation: 0.1972149692541115]
	TIME [epoch: 13.6 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2423626129617319		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.2423626129617319 | validation: 0.19767684901012061]
	TIME [epoch: 13.6 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24318226736877302		[learning rate: 0.0055125]
	Learning Rate: 0.00551247
	LOSS [training: 0.24318226736877302 | validation: 0.20883356517999344]
	TIME [epoch: 13.6 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2453493248678859		[learning rate: 0.0054905]
	Learning Rate: 0.00549054
	LOSS [training: 0.2453493248678859 | validation: 0.1918454175272723]
	TIME [epoch: 13.6 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24120296660765023		[learning rate: 0.0054687]
	Learning Rate: 0.00546871
	LOSS [training: 0.24120296660765023 | validation: 0.21510198639747383]
	TIME [epoch: 13.6 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2413076555127186		[learning rate: 0.005447]
	Learning Rate: 0.00544696
	LOSS [training: 0.2413076555127186 | validation: 0.22950005188494832]
	TIME [epoch: 13.6 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.247427268749875		[learning rate: 0.0054253]
	Learning Rate: 0.00542529
	LOSS [training: 0.247427268749875 | validation: 0.18879488001675399]
	TIME [epoch: 13.6 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22547776655000965		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.22547776655000965 | validation: 0.2046406647530838]
	TIME [epoch: 13.6 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24415434127345145		[learning rate: 0.0053822]
	Learning Rate: 0.00538222
	LOSS [training: 0.24415434127345145 | validation: 0.1865595624221545]
	TIME [epoch: 13.6 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23758232686515163		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.23758232686515163 | validation: 0.2058489065829292]
	TIME [epoch: 13.6 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22460012021095638		[learning rate: 0.0053395]
	Learning Rate: 0.00533949
	LOSS [training: 0.22460012021095638 | validation: 0.19215362427964786]
	TIME [epoch: 13.6 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24283792653274705		[learning rate: 0.0053183]
	Learning Rate: 0.00531826
	LOSS [training: 0.24283792653274705 | validation: 0.20165193055890174]
	TIME [epoch: 13.6 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25629324644669066		[learning rate: 0.0052971]
	Learning Rate: 0.0052971
	LOSS [training: 0.25629324644669066 | validation: 0.19676138983526156]
	TIME [epoch: 13.6 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2297336490013556		[learning rate: 0.005276]
	Learning Rate: 0.00527604
	LOSS [training: 0.2297336490013556 | validation: 0.19178860501950495]
	TIME [epoch: 13.6 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2381719665353497		[learning rate: 0.0052551]
	Learning Rate: 0.00525505
	LOSS [training: 0.2381719665353497 | validation: 0.2078166724625663]
	TIME [epoch: 13.6 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24274198630514887		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.24274198630514887 | validation: 0.20521187276613362]
	TIME [epoch: 13.7 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24202675974827048		[learning rate: 0.0052133]
	Learning Rate: 0.00521333
	LOSS [training: 0.24202675974827048 | validation: 0.18891148355492254]
	TIME [epoch: 13.6 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23831370877525757		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 0.23831370877525757 | validation: 0.19739175503889206]
	TIME [epoch: 13.6 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2395432562584902		[learning rate: 0.0051719]
	Learning Rate: 0.00517194
	LOSS [training: 0.2395432562584902 | validation: 0.17876969811280202]
	TIME [epoch: 13.6 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v15_20240716_142613/states/model_facs_v2_dec1b_2dpca_v15_210.pth
	Model improved!!!
EPOCH 211/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23821123061399677		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.23821123061399677 | validation: 0.19147759291951]
	TIME [epoch: 13.6 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24276308605508165		[learning rate: 0.0051309]
	Learning Rate: 0.00513089
	LOSS [training: 0.24276308605508165 | validation: 0.18893374860675147]
	TIME [epoch: 13.6 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23099427654349597		[learning rate: 0.0051105]
	Learning Rate: 0.00511048
	LOSS [training: 0.23099427654349597 | validation: 0.20035719111051425]
	TIME [epoch: 13.6 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22666656943697353		[learning rate: 0.0050902]
	Learning Rate: 0.00509015
	LOSS [training: 0.22666656943697353 | validation: 0.19290639024473]
	TIME [epoch: 13.6 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2383607157912152		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.2383607157912152 | validation: 0.18377295198921345]
	TIME [epoch: 13.6 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23149802889993376		[learning rate: 0.0050497]
	Learning Rate: 0.00504974
	LOSS [training: 0.23149802889993376 | validation: 0.1884257394638546]
	TIME [epoch: 13.6 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2369802648596172		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 0.2369802648596172 | validation: 0.2000904276328499]
	TIME [epoch: 13.6 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2296893372172618		[learning rate: 0.0050097]
	Learning Rate: 0.00500965
	LOSS [training: 0.2296893372172618 | validation: 0.19817514660234084]
	TIME [epoch: 13.6 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24590248247741853		[learning rate: 0.0049897]
	Learning Rate: 0.00498973
	LOSS [training: 0.24590248247741853 | validation: 0.1920504413584259]
	TIME [epoch: 13.6 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23731560140817898		[learning rate: 0.0049699]
	Learning Rate: 0.00496988
	LOSS [training: 0.23731560140817898 | validation: 0.21171563941981003]
	TIME [epoch: 13.6 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25038146860915694		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.25038146860915694 | validation: 0.18945037228308376]
	TIME [epoch: 13.6 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22940555184741612		[learning rate: 0.0049304]
	Learning Rate: 0.00493043
	LOSS [training: 0.22940555184741612 | validation: 0.20586460957590677]
	TIME [epoch: 13.6 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23762314100548754		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.23762314100548754 | validation: 0.2010318619521204]
	TIME [epoch: 13.6 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23502233163483544		[learning rate: 0.0048913]
	Learning Rate: 0.00489129
	LOSS [training: 0.23502233163483544 | validation: 0.18348812335888415]
	TIME [epoch: 13.6 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2319815562757616		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.2319815562757616 | validation: 0.2089818314558904]
	TIME [epoch: 13.6 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23176703078271213		[learning rate: 0.0048525]
	Learning Rate: 0.00485245
	LOSS [training: 0.23176703078271213 | validation: 0.19086145115390288]
	TIME [epoch: 13.6 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23737727513061177		[learning rate: 0.0048332]
	Learning Rate: 0.00483316
	LOSS [training: 0.23737727513061177 | validation: 0.2048595573874433]
	TIME [epoch: 13.6 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23628585522156406		[learning rate: 0.0048139]
	Learning Rate: 0.00481393
	LOSS [training: 0.23628585522156406 | validation: 0.20894488535674816]
	TIME [epoch: 13.6 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24756640313283265		[learning rate: 0.0047948]
	Learning Rate: 0.00479479
	LOSS [training: 0.24756640313283265 | validation: 0.1941583925697105]
	TIME [epoch: 13.6 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24518185666233722		[learning rate: 0.0047757]
	Learning Rate: 0.00477572
	LOSS [training: 0.24518185666233722 | validation: 0.197997464252619]
	TIME [epoch: 13.6 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23551671356822285		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.23551671356822285 | validation: 0.19068353993106163]
	TIME [epoch: 13.6 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22736854725883948		[learning rate: 0.0047378]
	Learning Rate: 0.0047378
	LOSS [training: 0.22736854725883948 | validation: 0.21032907651657534]
	TIME [epoch: 13.6 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24136323917658561		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 0.24136323917658561 | validation: 0.19020191234311523]
	TIME [epoch: 13.6 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2272726563317938		[learning rate: 0.0047002]
	Learning Rate: 0.00470019
	LOSS [training: 0.2272726563317938 | validation: 0.1774281275585317]
	TIME [epoch: 13.6 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v15_20240716_142613/states/model_facs_v2_dec1b_2dpca_v15_234.pth
	Model improved!!!
EPOCH 235/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2449057232383845		[learning rate: 0.0046815]
	Learning Rate: 0.0046815
	LOSS [training: 0.2449057232383845 | validation: 0.19123499349586723]
	TIME [epoch: 13.6 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.239813799394781		[learning rate: 0.0046629]
	Learning Rate: 0.00466288
	LOSS [training: 0.239813799394781 | validation: 0.19765659473638242]
	TIME [epoch: 13.6 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24119020684362974		[learning rate: 0.0046443]
	Learning Rate: 0.00464433
	LOSS [training: 0.24119020684362974 | validation: 0.20608105770061386]
	TIME [epoch: 13.6 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23893697402435674		[learning rate: 0.0046259]
	Learning Rate: 0.00462586
	LOSS [training: 0.23893697402435674 | validation: 0.19394229115248254]
	TIME [epoch: 13.6 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23777324263263758		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.23777324263263758 | validation: 0.19623612739231358]
	TIME [epoch: 13.6 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23103729847342638		[learning rate: 0.0045891]
	Learning Rate: 0.00458913
	LOSS [training: 0.23103729847342638 | validation: 0.1842693849437806]
	TIME [epoch: 13.6 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22915361999961656		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.22915361999961656 | validation: 0.1942385075305072]
	TIME [epoch: 13.6 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23592528476656455		[learning rate: 0.0045527]
	Learning Rate: 0.0045527
	LOSS [training: 0.23592528476656455 | validation: 0.19253091358712762]
	TIME [epoch: 13.6 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23798362350174618		[learning rate: 0.0045346]
	Learning Rate: 0.00453459
	LOSS [training: 0.23798362350174618 | validation: 0.20799888847930906]
	TIME [epoch: 13.6 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2327383870843486		[learning rate: 0.0045166]
	Learning Rate: 0.00451656
	LOSS [training: 0.2327383870843486 | validation: 0.18855018862079437]
	TIME [epoch: 13.6 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23028627543099167		[learning rate: 0.0044986]
	Learning Rate: 0.0044986
	LOSS [training: 0.23028627543099167 | validation: 0.19377541858760972]
	TIME [epoch: 13.6 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23572018012382737		[learning rate: 0.0044807]
	Learning Rate: 0.0044807
	LOSS [training: 0.23572018012382737 | validation: 0.18824893387671424]
	TIME [epoch: 13.6 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22201824141115717		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.22201824141115717 | validation: 0.1862020147742008]
	TIME [epoch: 13.6 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23851090510121972		[learning rate: 0.0044451]
	Learning Rate: 0.00444513
	LOSS [training: 0.23851090510121972 | validation: 0.2007989606536444]
	TIME [epoch: 13.6 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25255474999506256		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 0.25255474999506256 | validation: 0.19888967877319508]
	TIME [epoch: 13.6 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25102790496512156		[learning rate: 0.0044098]
	Learning Rate: 0.00440984
	LOSS [training: 0.25102790496512156 | validation: 0.18534291597395322]
	TIME [epoch: 13.6 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2331171348565261		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.2331171348565261 | validation: 0.20295118663385497]
	TIME [epoch: 13.6 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23771280107553222		[learning rate: 0.0043748]
	Learning Rate: 0.00437483
	LOSS [training: 0.23771280107553222 | validation: 0.18420666340216746]
	TIME [epoch: 13.6 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22868631551777727		[learning rate: 0.0043574]
	Learning Rate: 0.00435743
	LOSS [training: 0.22868631551777727 | validation: 0.19125100070780945]
	TIME [epoch: 13.6 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23302660727955982		[learning rate: 0.0043401]
	Learning Rate: 0.0043401
	LOSS [training: 0.23302660727955982 | validation: 0.18293742618950082]
	TIME [epoch: 13.6 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23589637065732852		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.23589637065732852 | validation: 0.2047826947684977]
	TIME [epoch: 13.6 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22847577894887902		[learning rate: 0.0043056]
	Learning Rate: 0.00430565
	LOSS [training: 0.22847577894887902 | validation: 0.20864732925851515]
	TIME [epoch: 13.6 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24187739649984888		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.24187739649984888 | validation: 0.19668031301036706]
	TIME [epoch: 13.6 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23199288506734758		[learning rate: 0.0042715]
	Learning Rate: 0.00427147
	LOSS [training: 0.23199288506734758 | validation: 0.19289924206195028]
	TIME [epoch: 13.6 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2520099547140266		[learning rate: 0.0042545]
	Learning Rate: 0.00425448
	LOSS [training: 0.2520099547140266 | validation: 0.2101510745755498]
	TIME [epoch: 13.6 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24642397069077443		[learning rate: 0.0042376]
	Learning Rate: 0.00423756
	LOSS [training: 0.24642397069077443 | validation: 0.19313953837828768]
	TIME [epoch: 13.6 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2360188939371372		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.2360188939371372 | validation: 0.19033985432169245]
	TIME [epoch: 13.6 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23682994787812467		[learning rate: 0.0042039]
	Learning Rate: 0.00420391
	LOSS [training: 0.23682994787812467 | validation: 0.20225388583010656]
	TIME [epoch: 13.6 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23062658823472232		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.23062658823472232 | validation: 0.20693671781593329]
	TIME [epoch: 13.6 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2277612022856548		[learning rate: 0.0041705]
	Learning Rate: 0.00417054
	LOSS [training: 0.2277612022856548 | validation: 0.19157849935706156]
	TIME [epoch: 13.6 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2357805591323571		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 0.2357805591323571 | validation: 0.20238692485966556]
	TIME [epoch: 13.6 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2388368526152808		[learning rate: 0.0041374]
	Learning Rate: 0.00413743
	LOSS [training: 0.2388368526152808 | validation: 0.192426806483758]
	TIME [epoch: 13.6 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23114961600094017		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.23114961600094017 | validation: 0.1938768540722465]
	TIME [epoch: 13.6 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23284316980743386		[learning rate: 0.0041046]
	Learning Rate: 0.00410458
	LOSS [training: 0.23284316980743386 | validation: 0.1954550399752617]
	TIME [epoch: 13.6 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23730735074534945		[learning rate: 0.0040883]
	Learning Rate: 0.00408826
	LOSS [training: 0.23730735074534945 | validation: 0.19883104218103032]
	TIME [epoch: 13.6 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23469970020070555		[learning rate: 0.004072]
	Learning Rate: 0.004072
	LOSS [training: 0.23469970020070555 | validation: 0.20062361802018364]
	TIME [epoch: 13.6 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22700552999864168		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.22700552999864168 | validation: 0.21540882844606934]
	TIME [epoch: 13.6 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.237925643277639		[learning rate: 0.0040397]
	Learning Rate: 0.00403967
	LOSS [training: 0.237925643277639 | validation: 0.19077503971226104]
	TIME [epoch: 13.6 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22235669500069882		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 0.22235669500069882 | validation: 0.18909746837046346]
	TIME [epoch: 13.6 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23821403929645582		[learning rate: 0.0040076]
	Learning Rate: 0.0040076
	LOSS [training: 0.23821403929645582 | validation: 0.1982784639478498]
	TIME [epoch: 13.6 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23859011239276884		[learning rate: 0.0039917]
	Learning Rate: 0.00399166
	LOSS [training: 0.23859011239276884 | validation: 0.1806673922649689]
	TIME [epoch: 13.6 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2500440111690892		[learning rate: 0.0039758]
	Learning Rate: 0.00397579
	LOSS [training: 0.2500440111690892 | validation: 0.1875415117908477]
	TIME [epoch: 13.6 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2279313559946471		[learning rate: 0.00396]
	Learning Rate: 0.00395997
	LOSS [training: 0.2279313559946471 | validation: 0.20253263511405883]
	TIME [epoch: 13.6 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22058318944845265		[learning rate: 0.0039442]
	Learning Rate: 0.00394422
	LOSS [training: 0.22058318944845265 | validation: 0.184487717851566]
	TIME [epoch: 13.6 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24160956544630757		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.24160956544630757 | validation: 0.1989290553747315]
	TIME [epoch: 13.6 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2337569058508917		[learning rate: 0.0039129]
	Learning Rate: 0.00391291
	LOSS [training: 0.2337569058508917 | validation: 0.18850016383751006]
	TIME [epoch: 13.6 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25381569723794606		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.25381569723794606 | validation: 0.18764162818825753]
	TIME [epoch: 13.6 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2383747630866182		[learning rate: 0.0038818]
	Learning Rate: 0.00388185
	LOSS [training: 0.2383747630866182 | validation: 0.2019488988022519]
	TIME [epoch: 13.6 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24029073840099746		[learning rate: 0.0038664]
	Learning Rate: 0.00386641
	LOSS [training: 0.24029073840099746 | validation: 0.18864723488768095]
	TIME [epoch: 13.6 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24497524763396644		[learning rate: 0.003851]
	Learning Rate: 0.00385103
	LOSS [training: 0.24497524763396644 | validation: 0.19714692961591657]
	TIME [epoch: 13.7 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2370263238169342		[learning rate: 0.0038357]
	Learning Rate: 0.00383571
	LOSS [training: 0.2370263238169342 | validation: 0.19375967768626215]
	TIME [epoch: 13.6 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2376405286380034		[learning rate: 0.0038205]
	Learning Rate: 0.00382046
	LOSS [training: 0.2376405286380034 | validation: 0.19317819089819604]
	TIME [epoch: 13.6 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21874463498986688		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.21874463498986688 | validation: 0.18684555145828624]
	TIME [epoch: 13.6 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23518538172392958		[learning rate: 0.0037901]
	Learning Rate: 0.00379013
	LOSS [training: 0.23518538172392958 | validation: 0.20375001970574713]
	TIME [epoch: 13.6 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23281621724146362		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.23281621724146362 | validation: 0.18722104454171581]
	TIME [epoch: 13.6 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2245148674194133		[learning rate: 0.00376]
	Learning Rate: 0.00376004
	LOSS [training: 0.2245148674194133 | validation: 0.1972095733926326]
	TIME [epoch: 13.6 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23532220191736927		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.23532220191736927 | validation: 0.20261868921073495]
	TIME [epoch: 13.6 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23951847681425834		[learning rate: 0.0037302]
	Learning Rate: 0.00373019
	LOSS [training: 0.23951847681425834 | validation: 0.1827281392256596]
	TIME [epoch: 13.6 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23421564133040645		[learning rate: 0.0037154]
	Learning Rate: 0.00371535
	LOSS [training: 0.23421564133040645 | validation: 0.19529220057921343]
	TIME [epoch: 13.6 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23317478699797578		[learning rate: 0.0037006]
	Learning Rate: 0.00370058
	LOSS [training: 0.23317478699797578 | validation: 0.19509306975676016]
	TIME [epoch: 13.6 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23626718367013		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.23626718367013 | validation: 0.19500076302493122]
	TIME [epoch: 13.6 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22784229533047362		[learning rate: 0.0036712]
	Learning Rate: 0.0036712
	LOSS [training: 0.22784229533047362 | validation: 0.19718772851177116]
	TIME [epoch: 13.6 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23210823726723642		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 0.23210823726723642 | validation: 0.1959682994355984]
	TIME [epoch: 13.6 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2354181071958083		[learning rate: 0.0036421]
	Learning Rate: 0.00364205
	LOSS [training: 0.2354181071958083 | validation: 0.1924698358617623]
	TIME [epoch: 13.6 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2462305955161749		[learning rate: 0.0036276]
	Learning Rate: 0.00362757
	LOSS [training: 0.2462305955161749 | validation: 0.19648667084735505]
	TIME [epoch: 13.6 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2442914184916063		[learning rate: 0.0036131]
	Learning Rate: 0.00361314
	LOSS [training: 0.2442914184916063 | validation: 0.1906282916763869]
	TIME [epoch: 13.6 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2377650547025864		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.2377650547025864 | validation: 0.1999905146358723]
	TIME [epoch: 13.6 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24102057391122816		[learning rate: 0.0035845]
	Learning Rate: 0.00358445
	LOSS [training: 0.24102057391122816 | validation: 0.19158134560484713]
	TIME [epoch: 13.6 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2464898047024765		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.2464898047024765 | validation: 0.19447429773251929]
	TIME [epoch: 13.6 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22744166237120206		[learning rate: 0.003556]
	Learning Rate: 0.003556
	LOSS [training: 0.22744166237120206 | validation: 0.1896512132861518]
	TIME [epoch: 13.6 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2302568908279623		[learning rate: 0.0035419]
	Learning Rate: 0.00354185
	LOSS [training: 0.2302568908279623 | validation: 0.1981614836249364]
	TIME [epoch: 13.6 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2514203467586026		[learning rate: 0.0035278]
	Learning Rate: 0.00352777
	LOSS [training: 0.2514203467586026 | validation: 0.18605766818071762]
	TIME [epoch: 13.6 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2407028353727457		[learning rate: 0.0035137]
	Learning Rate: 0.00351374
	LOSS [training: 0.2407028353727457 | validation: 0.19062149698409311]
	TIME [epoch: 13.6 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22695945505579232		[learning rate: 0.0034998]
	Learning Rate: 0.00349976
	LOSS [training: 0.22695945505579232 | validation: 0.19260098933693018]
	TIME [epoch: 13.6 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2405959718302945		[learning rate: 0.0034858]
	Learning Rate: 0.00348584
	LOSS [training: 0.2405959718302945 | validation: 0.20287089064232786]
	TIME [epoch: 13.6 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24483048263373672		[learning rate: 0.003472]
	Learning Rate: 0.00347198
	LOSS [training: 0.24483048263373672 | validation: 0.18646741334941602]
	TIME [epoch: 13.6 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23042266860295177		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.23042266860295177 | validation: 0.18658760141778946]
	TIME [epoch: 13.6 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2367349458877094		[learning rate: 0.0034444]
	Learning Rate: 0.00344441
	LOSS [training: 0.2367349458877094 | validation: 0.19100748159302544]
	TIME [epoch: 13.6 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24322965325065443		[learning rate: 0.0034307]
	Learning Rate: 0.00343071
	LOSS [training: 0.24322965325065443 | validation: 0.1973981103337722]
	TIME [epoch: 13.6 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23727070887961985		[learning rate: 0.0034171]
	Learning Rate: 0.00341707
	LOSS [training: 0.23727070887961985 | validation: 0.18824861451252803]
	TIME [epoch: 13.6 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2333435679107455		[learning rate: 0.0034035]
	Learning Rate: 0.00340348
	LOSS [training: 0.2333435679107455 | validation: 0.208020410546653]
	TIME [epoch: 13.6 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23457398332050927		[learning rate: 0.0033899]
	Learning Rate: 0.00338994
	LOSS [training: 0.23457398332050927 | validation: 0.18814900775551235]
	TIME [epoch: 13.6 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2266773954436765		[learning rate: 0.0033765]
	Learning Rate: 0.00337646
	LOSS [training: 0.2266773954436765 | validation: 0.19438135135342755]
	TIME [epoch: 13.6 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22560562358491656		[learning rate: 0.003363]
	Learning Rate: 0.00336303
	LOSS [training: 0.22560562358491656 | validation: 0.20066164673349657]
	TIME [epoch: 13.6 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2274657055875651		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.2274657055875651 | validation: 0.20131596239520522]
	TIME [epoch: 13.6 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22722823578090998		[learning rate: 0.0033363]
	Learning Rate: 0.00333633
	LOSS [training: 0.22722823578090998 | validation: 0.1929112905676573]
	TIME [epoch: 13.6 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22940822160235458		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.22940822160235458 | validation: 0.1865356106385723]
	TIME [epoch: 13.6 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22882985185044882		[learning rate: 0.0033098]
	Learning Rate: 0.00330985
	LOSS [training: 0.22882985185044882 | validation: 0.18814660072994868]
	TIME [epoch: 13.6 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22849142185656313		[learning rate: 0.0032967]
	Learning Rate: 0.00329668
	LOSS [training: 0.22849142185656313 | validation: 0.19007500700796326]
	TIME [epoch: 13.6 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22344560317255258		[learning rate: 0.0032836]
	Learning Rate: 0.00328357
	LOSS [training: 0.22344560317255258 | validation: 0.18931146231458224]
	TIME [epoch: 13.6 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22470295579081057		[learning rate: 0.0032705]
	Learning Rate: 0.00327051
	LOSS [training: 0.22470295579081057 | validation: 0.19890289028958993]
	TIME [epoch: 13.6 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23795267271816517		[learning rate: 0.0032575]
	Learning Rate: 0.0032575
	LOSS [training: 0.23795267271816517 | validation: 0.19233688505854765]
	TIME [epoch: 13.6 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23301403318586963		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.23301403318586963 | validation: 0.1871697093142724]
	TIME [epoch: 13.6 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23758537497994178		[learning rate: 0.0032316]
	Learning Rate: 0.00323164
	LOSS [training: 0.23758537497994178 | validation: 0.20995480907017247]
	TIME [epoch: 13.6 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23937210492040684		[learning rate: 0.0032188]
	Learning Rate: 0.00321879
	LOSS [training: 0.23937210492040684 | validation: 0.1809032854418164]
	TIME [epoch: 13.6 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22699350967709644		[learning rate: 0.003206]
	Learning Rate: 0.00320599
	LOSS [training: 0.22699350967709644 | validation: 0.190454708799041]
	TIME [epoch: 13.6 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22956440095172337		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.22956440095172337 | validation: 0.18948799299468605]
	TIME [epoch: 13.6 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22350016912179044		[learning rate: 0.0031805]
	Learning Rate: 0.00318053
	LOSS [training: 0.22350016912179044 | validation: 0.19132753427163196]
	TIME [epoch: 13.6 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23411296878856763		[learning rate: 0.0031679]
	Learning Rate: 0.00316788
	LOSS [training: 0.23411296878856763 | validation: 0.1821343522978219]
	TIME [epoch: 13.6 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23220329367080417		[learning rate: 0.0031553]
	Learning Rate: 0.00315528
	LOSS [training: 0.23220329367080417 | validation: 0.19880614019522178]
	TIME [epoch: 13.6 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23650086356230623		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.23650086356230623 | validation: 0.1981368296532649]
	TIME [epoch: 13.6 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2381521848914016		[learning rate: 0.0031302]
	Learning Rate: 0.00313023
	LOSS [training: 0.2381521848914016 | validation: 0.1941373778747406]
	TIME [epoch: 13.6 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23729508971129454		[learning rate: 0.0031178]
	Learning Rate: 0.00311779
	LOSS [training: 0.23729508971129454 | validation: 0.19142927233713797]
	TIME [epoch: 13.6 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24359360661475504		[learning rate: 0.0031054]
	Learning Rate: 0.00310538
	LOSS [training: 0.24359360661475504 | validation: 0.1984024941449743]
	TIME [epoch: 13.6 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2267327422953486		[learning rate: 0.003093]
	Learning Rate: 0.00309303
	LOSS [training: 0.2267327422953486 | validation: 0.18883067148567018]
	TIME [epoch: 13.6 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23563995248304806		[learning rate: 0.0030807]
	Learning Rate: 0.00308073
	LOSS [training: 0.23563995248304806 | validation: 0.19569923822020563]
	TIME [epoch: 13.6 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24567083377097562		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.24567083377097562 | validation: 0.18990309199315064]
	TIME [epoch: 13.6 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24187480263678351		[learning rate: 0.0030563]
	Learning Rate: 0.00305627
	LOSS [training: 0.24187480263678351 | validation: 0.18742055925367404]
	TIME [epoch: 13.6 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23566934693877822		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.23566934693877822 | validation: 0.195665358599703]
	TIME [epoch: 13.6 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23481294543334683		[learning rate: 0.003032]
	Learning Rate: 0.00303201
	LOSS [training: 0.23481294543334683 | validation: 0.19875161726930088]
	TIME [epoch: 13.6 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23352579103193316		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.23352579103193316 | validation: 0.18398953770876386]
	TIME [epoch: 13.6 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2371270001729271		[learning rate: 0.0030079]
	Learning Rate: 0.00300794
	LOSS [training: 0.2371270001729271 | validation: 0.1959267984082687]
	TIME [epoch: 13.6 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2400500105363467		[learning rate: 0.002996]
	Learning Rate: 0.00299598
	LOSS [training: 0.2400500105363467 | validation: 0.1907605455498271]
	TIME [epoch: 13.6 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22734541728634605		[learning rate: 0.0029841]
	Learning Rate: 0.00298406
	LOSS [training: 0.22734541728634605 | validation: 0.19771581319770676]
	TIME [epoch: 13.6 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23798029296389714		[learning rate: 0.0029722]
	Learning Rate: 0.00297219
	LOSS [training: 0.23798029296389714 | validation: 0.18139394456624722]
	TIME [epoch: 13.6 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22338184673545733		[learning rate: 0.0029604]
	Learning Rate: 0.00296037
	LOSS [training: 0.22338184673545733 | validation: 0.19236565895929206]
	TIME [epoch: 13.6 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22838212335078845		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.22838212335078845 | validation: 0.19489433522858574]
	TIME [epoch: 13.6 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22921416253112226		[learning rate: 0.0029369]
	Learning Rate: 0.00293687
	LOSS [training: 0.22921416253112226 | validation: 0.18763689822913615]
	TIME [epoch: 13.6 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2256375474025972		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.2256375474025972 | validation: 0.19064809051946144]
	TIME [epoch: 13.6 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2453646778754962		[learning rate: 0.0029136]
	Learning Rate: 0.00291355
	LOSS [training: 0.2453646778754962 | validation: 0.19016890091321673]
	TIME [epoch: 13.6 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23694573423554022		[learning rate: 0.002902]
	Learning Rate: 0.00290197
	LOSS [training: 0.23694573423554022 | validation: 0.18973642947442657]
	TIME [epoch: 13.6 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22244602511079975		[learning rate: 0.0028904]
	Learning Rate: 0.00289042
	LOSS [training: 0.22244602511079975 | validation: 0.19091631450644062]
	TIME [epoch: 13.6 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23988411526415623		[learning rate: 0.0028789]
	Learning Rate: 0.00287893
	LOSS [training: 0.23988411526415623 | validation: 0.19794771285929944]
	TIME [epoch: 13.6 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2391818213449873		[learning rate: 0.0028675]
	Learning Rate: 0.00286748
	LOSS [training: 0.2391818213449873 | validation: 0.19259280597686473]
	TIME [epoch: 13.6 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23686531834567603		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.23686531834567603 | validation: 0.1834539312402572]
	TIME [epoch: 13.6 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2280086026632249		[learning rate: 0.0028447]
	Learning Rate: 0.00284471
	LOSS [training: 0.2280086026632249 | validation: 0.20278547246012132]
	TIME [epoch: 13.6 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2457992488492428		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.2457992488492428 | validation: 0.18462666405935102]
	TIME [epoch: 13.6 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23173251135659115		[learning rate: 0.0028221]
	Learning Rate: 0.00282213
	LOSS [training: 0.23173251135659115 | validation: 0.20622297635862447]
	TIME [epoch: 13.6 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22662509932376146		[learning rate: 0.0028109]
	Learning Rate: 0.00281091
	LOSS [training: 0.22662509932376146 | validation: 0.1878738328504181]
	TIME [epoch: 13.6 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22853015144171224		[learning rate: 0.0027997]
	Learning Rate: 0.00279973
	LOSS [training: 0.22853015144171224 | validation: 0.18302690742562033]
	TIME [epoch: 13.6 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23232408737223428		[learning rate: 0.0027886]
	Learning Rate: 0.00278859
	LOSS [training: 0.23232408737223428 | validation: 0.17869827686369807]
	TIME [epoch: 13.6 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22416681755221898		[learning rate: 0.0027775]
	Learning Rate: 0.0027775
	LOSS [training: 0.22416681755221898 | validation: 0.19558972107498016]
	TIME [epoch: 13.6 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23404258406320844		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.23404258406320844 | validation: 0.1940212494542602]
	TIME [epoch: 13.6 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23244659235331813		[learning rate: 0.0027554]
	Learning Rate: 0.00275545
	LOSS [training: 0.23244659235331813 | validation: 0.18545626891857028]
	TIME [epoch: 13.6 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22627724392462914		[learning rate: 0.0027445]
	Learning Rate: 0.00274449
	LOSS [training: 0.22627724392462914 | validation: 0.1916108597334059]
	TIME [epoch: 13.6 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.229331633168063		[learning rate: 0.0027336]
	Learning Rate: 0.00273357
	LOSS [training: 0.229331633168063 | validation: 0.18886372105381946]
	TIME [epoch: 13.6 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23262628911778327		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.23262628911778327 | validation: 0.19447172355194695]
	TIME [epoch: 13.6 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23188333834872032		[learning rate: 0.0027119]
	Learning Rate: 0.00271187
	LOSS [training: 0.23188333834872032 | validation: 0.1920736394592639]
	TIME [epoch: 13.6 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23052836378866293		[learning rate: 0.0027011]
	Learning Rate: 0.00270109
	LOSS [training: 0.23052836378866293 | validation: 0.18509438377869902]
	TIME [epoch: 13.6 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22237346439838415		[learning rate: 0.0026903]
	Learning Rate: 0.00269034
	LOSS [training: 0.22237346439838415 | validation: 0.2022805402664276]
	TIME [epoch: 13.6 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23955599480749054		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.23955599480749054 | validation: 0.20642723988533312]
	TIME [epoch: 13.6 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2393714322858355		[learning rate: 0.002669]
	Learning Rate: 0.00266899
	LOSS [training: 0.2393714322858355 | validation: 0.1903380187680729]
	TIME [epoch: 13.6 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23574649434959427		[learning rate: 0.0026584]
	Learning Rate: 0.00265837
	LOSS [training: 0.23574649434959427 | validation: 0.18329675028236428]
	TIME [epoch: 13.6 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23218393957609443		[learning rate: 0.0026478]
	Learning Rate: 0.0026478
	LOSS [training: 0.23218393957609443 | validation: 0.1861262691028342]
	TIME [epoch: 13.6 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22018658260758983		[learning rate: 0.0026373]
	Learning Rate: 0.00263727
	LOSS [training: 0.22018658260758983 | validation: 0.18524795018214]
	TIME [epoch: 13.6 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23401059462185567		[learning rate: 0.0026268]
	Learning Rate: 0.00262678
	LOSS [training: 0.23401059462185567 | validation: 0.19541311845082276]
	TIME [epoch: 13.6 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23631043101854665		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.23631043101854665 | validation: 0.19823826051942625]
	TIME [epoch: 13.6 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2294805926487925		[learning rate: 0.0026059]
	Learning Rate: 0.00260592
	LOSS [training: 0.2294805926487925 | validation: 0.1855837542016956]
	TIME [epoch: 13.6 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23602138761432837		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.23602138761432837 | validation: 0.19646481734932433]
	TIME [epoch: 13.6 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2354985199206154		[learning rate: 0.0025852]
	Learning Rate: 0.00258523
	LOSS [training: 0.2354985199206154 | validation: 0.19198927411461097]
	TIME [epoch: 13.6 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2414645640887996		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.2414645640887996 | validation: 0.17855541942417988]
	TIME [epoch: 13.7 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22365681584815775		[learning rate: 0.0025647]
	Learning Rate: 0.00256471
	LOSS [training: 0.22365681584815775 | validation: 0.194179241564715]
	TIME [epoch: 13.6 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23651069554620946		[learning rate: 0.0025545]
	Learning Rate: 0.00255451
	LOSS [training: 0.23651069554620946 | validation: 0.19069087646047725]
	TIME [epoch: 13.6 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23863251833812338		[learning rate: 0.0025444]
	Learning Rate: 0.00254435
	LOSS [training: 0.23863251833812338 | validation: 0.19158102066372018]
	TIME [epoch: 13.6 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23664579792199522		[learning rate: 0.0025342]
	Learning Rate: 0.00253423
	LOSS [training: 0.23664579792199522 | validation: 0.19320587478210144]
	TIME [epoch: 13.6 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22999170900677526		[learning rate: 0.0025242]
	Learning Rate: 0.00252415
	LOSS [training: 0.22999170900677526 | validation: 0.20097997032461742]
	TIME [epoch: 13.6 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21826124842509131		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.21826124842509131 | validation: 0.18419721206769274]
	TIME [epoch: 13.6 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2284893850395006		[learning rate: 0.0025041]
	Learning Rate: 0.00250411
	LOSS [training: 0.2284893850395006 | validation: 0.20039613332063438]
	TIME [epoch: 13.6 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23213338841176842		[learning rate: 0.0024942]
	Learning Rate: 0.00249415
	LOSS [training: 0.23213338841176842 | validation: 0.18828161148309558]
	TIME [epoch: 13.6 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22382608155619468		[learning rate: 0.0024842]
	Learning Rate: 0.00248423
	LOSS [training: 0.22382608155619468 | validation: 0.1958322878756634]
	TIME [epoch: 13.6 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23861718312218683		[learning rate: 0.0024744]
	Learning Rate: 0.00247435
	LOSS [training: 0.23861718312218683 | validation: 0.18719981278192707]
	TIME [epoch: 13.6 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22494480383178062		[learning rate: 0.0024645]
	Learning Rate: 0.00246451
	LOSS [training: 0.22494480383178062 | validation: 0.18829507962450925]
	TIME [epoch: 13.6 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23033211290551117		[learning rate: 0.0024547]
	Learning Rate: 0.00245471
	LOSS [training: 0.23033211290551117 | validation: 0.19322705204427446]
	TIME [epoch: 13.6 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23707668757288566		[learning rate: 0.0024449]
	Learning Rate: 0.00244495
	LOSS [training: 0.23707668757288566 | validation: 0.1920262059597337]
	TIME [epoch: 13.6 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22792008904418648		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.22792008904418648 | validation: 0.18367589631007547]
	TIME [epoch: 13.6 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22172446529574388		[learning rate: 0.0024255]
	Learning Rate: 0.00242554
	LOSS [training: 0.22172446529574388 | validation: 0.19310732471426043]
	TIME [epoch: 13.6 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22814915544593298		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.22814915544593298 | validation: 0.19230601172762346]
	TIME [epoch: 13.6 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22216160772893875		[learning rate: 0.0024063]
	Learning Rate: 0.00240628
	LOSS [training: 0.22216160772893875 | validation: 0.18879631686708215]
	TIME [epoch: 13.6 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.236407913809111		[learning rate: 0.0023967]
	Learning Rate: 0.00239671
	LOSS [training: 0.236407913809111 | validation: 0.19395834077042465]
	TIME [epoch: 13.6 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23658592299575576		[learning rate: 0.0023872]
	Learning Rate: 0.00238718
	LOSS [training: 0.23658592299575576 | validation: 0.1975074316741578]
	TIME [epoch: 13.6 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2331820048078825		[learning rate: 0.0023777]
	Learning Rate: 0.00237768
	LOSS [training: 0.2331820048078825 | validation: 0.19817713879238302]
	TIME [epoch: 13.6 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23189246769286026		[learning rate: 0.0023682]
	Learning Rate: 0.00236823
	LOSS [training: 0.23189246769286026 | validation: 0.18661193124256292]
	TIME [epoch: 13.6 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22592671111767754		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.22592671111767754 | validation: 0.1821685426852707]
	TIME [epoch: 13.6 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2351461987624487		[learning rate: 0.0023494]
	Learning Rate: 0.00234942
	LOSS [training: 0.2351461987624487 | validation: 0.2037636320320873]
	TIME [epoch: 13.6 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2354491326608706		[learning rate: 0.0023401]
	Learning Rate: 0.00234008
	LOSS [training: 0.2354491326608706 | validation: 0.19954850427526818]
	TIME [epoch: 13.6 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22916102191007484		[learning rate: 0.0023308]
	Learning Rate: 0.00233077
	LOSS [training: 0.22916102191007484 | validation: 0.18694172186788424]
	TIME [epoch: 13.6 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24042314832415373		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.24042314832415373 | validation: 0.18534054271541878]
	TIME [epoch: 13.6 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23411741758294724		[learning rate: 0.0023123]
	Learning Rate: 0.00231227
	LOSS [training: 0.23411741758294724 | validation: 0.18794063875384534]
	TIME [epoch: 13.6 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2321403683448534		[learning rate: 0.0023031]
	Learning Rate: 0.00230307
	LOSS [training: 0.2321403683448534 | validation: 0.1869231847208746]
	TIME [epoch: 13.6 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23035477314943778		[learning rate: 0.0022939]
	Learning Rate: 0.00229391
	LOSS [training: 0.23035477314943778 | validation: 0.20283412844699544]
	TIME [epoch: 13.6 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22957459301824448		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.22957459301824448 | validation: 0.1834447126178626]
	TIME [epoch: 13.6 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22762710803994754		[learning rate: 0.0022757]
	Learning Rate: 0.0022757
	LOSS [training: 0.22762710803994754 | validation: 0.18896931411107148]
	TIME [epoch: 13.6 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23146689272994442		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.23146689272994442 | validation: 0.19422602067127362]
	TIME [epoch: 13.6 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2389825882208003		[learning rate: 0.0022576]
	Learning Rate: 0.00225764
	LOSS [training: 0.2389825882208003 | validation: 0.18392623924230803]
	TIME [epoch: 13.6 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22177042897326932		[learning rate: 0.0022487]
	Learning Rate: 0.00224866
	LOSS [training: 0.22177042897326932 | validation: 0.18508247242369022]
	TIME [epoch: 13.6 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22005109745920168		[learning rate: 0.0022397]
	Learning Rate: 0.00223971
	LOSS [training: 0.22005109745920168 | validation: 0.18972069449140339]
	TIME [epoch: 13.6 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22138247733563793		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.22138247733563793 | validation: 0.18490645211017204]
	TIME [epoch: 13.6 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23780282836291017		[learning rate: 0.0022219]
	Learning Rate: 0.00222193
	LOSS [training: 0.23780282836291017 | validation: 0.18217277858052347]
	TIME [epoch: 13.6 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23882538985448656		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.23882538985448656 | validation: 0.20051480264018187]
	TIME [epoch: 13.6 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22799627885890253		[learning rate: 0.0022043]
	Learning Rate: 0.00220429
	LOSS [training: 0.22799627885890253 | validation: 0.19008305190387734]
	TIME [epoch: 13.6 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23444722743925248		[learning rate: 0.0021955]
	Learning Rate: 0.00219553
	LOSS [training: 0.23444722743925248 | validation: 0.1814622507413573]
	TIME [epoch: 13.6 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2370104443860074		[learning rate: 0.0021868]
	Learning Rate: 0.00218679
	LOSS [training: 0.2370104443860074 | validation: 0.18115299085505593]
	TIME [epoch: 13.6 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22565940602911283		[learning rate: 0.0021781]
	Learning Rate: 0.0021781
	LOSS [training: 0.22565940602911283 | validation: 0.1867342371486057]
	TIME [epoch: 13.6 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2362737188624187		[learning rate: 0.0021694]
	Learning Rate: 0.00216943
	LOSS [training: 0.2362737188624187 | validation: 0.18693955252860378]
	TIME [epoch: 13.6 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21876844985771343		[learning rate: 0.0021608]
	Learning Rate: 0.0021608
	LOSS [training: 0.21876844985771343 | validation: 0.1990867867096638]
	TIME [epoch: 13.6 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2233507262114778		[learning rate: 0.0021522]
	Learning Rate: 0.00215221
	LOSS [training: 0.2233507262114778 | validation: 0.18648883548747758]
	TIME [epoch: 13.6 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23444731312736725		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.23444731312736725 | validation: 0.19830543013416432]
	TIME [epoch: 13.6 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23032107833004434		[learning rate: 0.0021351]
	Learning Rate: 0.00213512
	LOSS [training: 0.23032107833004434 | validation: 0.20261793300397887]
	TIME [epoch: 13.6 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23003113284052545		[learning rate: 0.0021266]
	Learning Rate: 0.00212663
	LOSS [training: 0.23003113284052545 | validation: 0.19055253338630967]
	TIME [epoch: 13.6 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22676880854195694		[learning rate: 0.0021182]
	Learning Rate: 0.00211817
	LOSS [training: 0.22676880854195694 | validation: 0.19002207814997454]
	TIME [epoch: 13.6 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23026489750418355		[learning rate: 0.0021097]
	Learning Rate: 0.00210975
	LOSS [training: 0.23026489750418355 | validation: 0.19349158851354642]
	TIME [epoch: 13.6 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v15_20240716_142613/states/model_facs_v2_dec1b_2dpca_v15_435.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 5685.033 seconds.
