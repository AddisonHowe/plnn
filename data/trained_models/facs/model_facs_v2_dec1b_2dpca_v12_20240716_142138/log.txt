Args:
Namespace(name='model_facs_v2_dec1b_2dpca_v12', outdir='out/model_training/model_facs_v2_dec1b_2dpca_v12', training_data='data/training_data/facs_v2/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs_v2/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=800, ncells_sample=800, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1145164285

Training model...

Saving initial model state to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.3742246822591362		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3742246822591362 | validation: 1.1642482114145558]
	TIME [epoch: 42.2 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.255293204001009		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.255293204001009 | validation: 1.0527443436182065]
	TIME [epoch: 13.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.1885464243605215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1885464243605215 | validation: 0.9666361422705888]
	TIME [epoch: 13.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.1541674428158495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1541674428158495 | validation: 0.959833914340218]
	TIME [epoch: 13.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.066467664554698		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.066467664554698 | validation: 0.882476020772924]
	TIME [epoch: 13.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.034444384533163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.034444384533163 | validation: 0.8355790773977155]
	TIME [epoch: 13.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9820751297039085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9820751297039085 | validation: 0.7869920149150887]
	TIME [epoch: 13.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8691332183822459		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8691332183822459 | validation: 0.7309464618768768]
	TIME [epoch: 13.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.854638398896978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.854638398896978 | validation: 0.7609292794688834]
	TIME [epoch: 13.7 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.878623548793567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.878623548793567 | validation: 0.6404964732742631]
	TIME [epoch: 13.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.760641960667003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.760641960667003 | validation: 0.595860962618702]
	TIME [epoch: 13.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6720700310473855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6720700310473855 | validation: 0.553350231996464]
	TIME [epoch: 13.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5503320873527797		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5503320873527797 | validation: 0.8899031434244675]
	TIME [epoch: 13.7 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5498289837708572		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5498289837708572 | validation: 0.3944164021794567]
	TIME [epoch: 13.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42369519207385764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42369519207385764 | validation: 0.3946231773236012]
	TIME [epoch: 13.7 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4614304058720069		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4614304058720069 | validation: 0.34126838335980836]
	TIME [epoch: 13.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3985695420593677		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3985695420593677 | validation: 0.3520633790471178]
	TIME [epoch: 13.7 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39574905112949094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39574905112949094 | validation: 0.3405719407914761]
	TIME [epoch: 13.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3969605609773083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3969605609773083 | validation: 0.49222004756565874]
	TIME [epoch: 13.7 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38937175053732576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38937175053732576 | validation: 0.3159625556371317]
	TIME [epoch: 13.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35697635627545493		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35697635627545493 | validation: 0.4019408221356491]
	TIME [epoch: 13.7 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38092135669623595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38092135669623595 | validation: 0.316774219657044]
	TIME [epoch: 13.7 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3408683463948843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3408683463948843 | validation: 0.31628625514637587]
	TIME [epoch: 13.8 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3633051275997423		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3633051275997423 | validation: 0.2827408142472618]
	TIME [epoch: 13.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3152384424642902		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3152384424642902 | validation: 0.29217569508114216]
	TIME [epoch: 13.7 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32554047195680924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32554047195680924 | validation: 0.28269983958907197]
	TIME [epoch: 13.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3363379482808274		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3363379482808274 | validation: 0.2657894223267683]
	TIME [epoch: 13.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3256721185607365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3256721185607365 | validation: 0.30514648550105133]
	TIME [epoch: 13.8 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.305616348995267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.305616348995267 | validation: 0.31583215924991986]
	TIME [epoch: 13.7 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33793727216297825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33793727216297825 | validation: 0.2756282380708743]
	TIME [epoch: 13.7 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2972898694987122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2972898694987122 | validation: 0.2813940214615104]
	TIME [epoch: 13.7 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.335469488626404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.335469488626404 | validation: 0.26086964745630825]
	TIME [epoch: 13.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29120397355697036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29120397355697036 | validation: 0.252376272139599]
	TIME [epoch: 13.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29732303351330963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29732303351330963 | validation: 0.24869588522898423]
	TIME [epoch: 13.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2868513708743669		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2868513708743669 | validation: 0.2763500435045933]
	TIME [epoch: 13.7 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30001254031812175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30001254031812175 | validation: 0.25912357212999176]
	TIME [epoch: 13.7 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2805976280117442		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2805976280117442 | validation: 0.23772942978193665]
	TIME [epoch: 13.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2767154235543038		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2767154235543038 | validation: 0.2762327124761163]
	TIME [epoch: 13.7 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29804979922787583		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29804979922787583 | validation: 0.2772569993962068]
	TIME [epoch: 13.7 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28632975230013785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28632975230013785 | validation: 0.23587401101902072]
	TIME [epoch: 13.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2885783030774197		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2885783030774197 | validation: 0.2669412108234407]
	TIME [epoch: 13.8 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2792187239154963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2792187239154963 | validation: 0.31832174105478495]
	TIME [epoch: 13.8 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.288870052825952		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.288870052825952 | validation: 0.2353449941224643]
	TIME [epoch: 13.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2960721897071978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2960721897071978 | validation: 0.2623660123972648]
	TIME [epoch: 13.7 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27455527381024303		[learning rate: 0.0099823]
	Learning Rate: 0.0099823
	LOSS [training: 0.27455527381024303 | validation: 0.2643863077628745]
	TIME [epoch: 13.7 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3045960857437684		[learning rate: 0.0099426]
	Learning Rate: 0.0099426
	LOSS [training: 0.3045960857437684 | validation: 0.2604524633036357]
	TIME [epoch: 13.8 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28742627822233197		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.28742627822233197 | validation: 0.26272693508992073]
	TIME [epoch: 13.7 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2736025782000042		[learning rate: 0.0098637]
	Learning Rate: 0.00986367
	LOSS [training: 0.2736025782000042 | validation: 0.2374326204964185]
	TIME [epoch: 13.8 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27027403944142864		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 0.27027403944142864 | validation: 0.24929450141948814]
	TIME [epoch: 13.7 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29489409688324975		[learning rate: 0.0097854]
	Learning Rate: 0.00978536
	LOSS [training: 0.29489409688324975 | validation: 0.21900941416830172]
	TIME [epoch: 13.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.275586076669397		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.275586076669397 | validation: 0.22087605496494697]
	TIME [epoch: 52.7 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2723452641541358		[learning rate: 0.0097077]
	Learning Rate: 0.00970768
	LOSS [training: 0.2723452641541358 | validation: 0.2348235676971377]
	TIME [epoch: 26.6 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29548348895421256		[learning rate: 0.0096691]
	Learning Rate: 0.00966907
	LOSS [training: 0.29548348895421256 | validation: 0.2414172499237897]
	TIME [epoch: 26.6 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.281333042886212		[learning rate: 0.0096306]
	Learning Rate: 0.00963061
	LOSS [training: 0.281333042886212 | validation: 0.23122052739456586]
	TIME [epoch: 26.6 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27153512835741106		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.27153512835741106 | validation: 0.22275733886498691]
	TIME [epoch: 26.6 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26774182364150995		[learning rate: 0.0095542]
	Learning Rate: 0.00955415
	LOSS [training: 0.26774182364150995 | validation: 0.2262274201744127]
	TIME [epoch: 26.6 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29572450237734144		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 0.29572450237734144 | validation: 0.305623657446882]
	TIME [epoch: 26.6 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2867279452739676		[learning rate: 0.0094783]
	Learning Rate: 0.00947831
	LOSS [training: 0.2867279452739676 | validation: 0.24050676662590167]
	TIME [epoch: 26.6 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2679496487915562		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.2679496487915562 | validation: 0.21881129560857362]
	TIME [epoch: 26.6 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27937218231361755		[learning rate: 0.0094031]
	Learning Rate: 0.00940306
	LOSS [training: 0.27937218231361755 | validation: 0.22944694154659317]
	TIME [epoch: 26.6 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26623605328766375		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.26623605328766375 | validation: 0.2319794478664286]
	TIME [epoch: 26.6 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2720894209336992		[learning rate: 0.0093284]
	Learning Rate: 0.00932841
	LOSS [training: 0.2720894209336992 | validation: 0.24794241532826308]
	TIME [epoch: 26.6 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26264080809261203		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.26264080809261203 | validation: 0.23382760181980453]
	TIME [epoch: 26.6 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26642991714166503		[learning rate: 0.0092544]
	Learning Rate: 0.00925435
	LOSS [training: 0.26642991714166503 | validation: 0.23202092317647444]
	TIME [epoch: 26.6 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2666051344423252		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.2666051344423252 | validation: 0.23922364119742312]
	TIME [epoch: 26.6 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2576354707900024		[learning rate: 0.0091809]
	Learning Rate: 0.00918089
	LOSS [training: 0.2576354707900024 | validation: 0.22552207125322857]
	TIME [epoch: 26.6 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2719737843494847		[learning rate: 0.0091444]
	Learning Rate: 0.00914437
	LOSS [training: 0.2719737843494847 | validation: 0.23267603911627943]
	TIME [epoch: 26.6 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2665865762575994		[learning rate: 0.009108]
	Learning Rate: 0.009108
	LOSS [training: 0.2665865762575994 | validation: 0.21879147475409363]
	TIME [epoch: 26.6 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2811373555197087		[learning rate: 0.0090718]
	Learning Rate: 0.00907178
	LOSS [training: 0.2811373555197087 | validation: 0.20564948772348365]
	TIME [epoch: 26.6 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25683785492987826		[learning rate: 0.0090357]
	Learning Rate: 0.00903569
	LOSS [training: 0.25683785492987826 | validation: 0.21147095948133474]
	TIME [epoch: 26.6 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27626346154650167		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.27626346154650167 | validation: 0.23432437327003605]
	TIME [epoch: 26.6 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2559265382143447		[learning rate: 0.008964]
	Learning Rate: 0.00896396
	LOSS [training: 0.2559265382143447 | validation: 0.24103951982995983]
	TIME [epoch: 26.6 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25786152584174016		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 0.25786152584174016 | validation: 0.19954364647164202]
	TIME [epoch: 26.6 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2657933638963634		[learning rate: 0.0088928]
	Learning Rate: 0.0088928
	LOSS [training: 0.2657933638963634 | validation: 0.20818958991501796]
	TIME [epoch: 26.6 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2688752876013147		[learning rate: 0.0088574]
	Learning Rate: 0.00885743
	LOSS [training: 0.2688752876013147 | validation: 0.22414510085806402]
	TIME [epoch: 26.6 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2677804377752548		[learning rate: 0.0088222]
	Learning Rate: 0.0088222
	LOSS [training: 0.2677804377752548 | validation: 0.20572466361855174]
	TIME [epoch: 26.6 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26421572773483026		[learning rate: 0.0087871]
	Learning Rate: 0.00878711
	LOSS [training: 0.26421572773483026 | validation: 0.2337990392334764]
	TIME [epoch: 26.6 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25957696430009364		[learning rate: 0.0087522]
	Learning Rate: 0.00875216
	LOSS [training: 0.25957696430009364 | validation: 0.21333833734452795]
	TIME [epoch: 26.6 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2548806654903524		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.2548806654903524 | validation: 0.21596143755853192]
	TIME [epoch: 26.6 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25461606309884366		[learning rate: 0.0086827]
	Learning Rate: 0.00868268
	LOSS [training: 0.25461606309884366 | validation: 0.3217715665816895]
	TIME [epoch: 26.6 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2745167218421056		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.2745167218421056 | validation: 0.21667860699205183]
	TIME [epoch: 26.6 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2615807074085803		[learning rate: 0.0086138]
	Learning Rate: 0.00861375
	LOSS [training: 0.2615807074085803 | validation: 0.21538895979364853]
	TIME [epoch: 26.6 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2627856686960515		[learning rate: 0.0085795]
	Learning Rate: 0.00857949
	LOSS [training: 0.2627856686960515 | validation: 0.23933029629511382]
	TIME [epoch: 26.6 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2554095987127213		[learning rate: 0.0085454]
	Learning Rate: 0.00854537
	LOSS [training: 0.2554095987127213 | validation: 0.2513557581006425]
	TIME [epoch: 26.6 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26562652671711245		[learning rate: 0.0085114]
	Learning Rate: 0.00851138
	LOSS [training: 0.26562652671711245 | validation: 0.2210816037829077]
	TIME [epoch: 26.6 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.260022476182934		[learning rate: 0.0084775]
	Learning Rate: 0.00847753
	LOSS [training: 0.260022476182934 | validation: 0.20351770421460819]
	TIME [epoch: 26.6 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26822491897617123		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.26822491897617123 | validation: 0.2550711922956602]
	TIME [epoch: 26.6 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2565356100312936		[learning rate: 0.0084102]
	Learning Rate: 0.00841023
	LOSS [training: 0.2565356100312936 | validation: 0.21749863707444606]
	TIME [epoch: 26.6 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25949597767381916		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 0.25949597767381916 | validation: 0.20377235034133548]
	TIME [epoch: 26.6 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2511569050572768		[learning rate: 0.0083435]
	Learning Rate: 0.00834346
	LOSS [training: 0.2511569050572768 | validation: 0.21020499370116222]
	TIME [epoch: 26.5 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25907096996755336		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.25907096996755336 | validation: 0.20351376430051166]
	TIME [epoch: 26.6 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2724225944246342		[learning rate: 0.0082772]
	Learning Rate: 0.00827722
	LOSS [training: 0.2724225944246342 | validation: 0.2651584698740373]
	TIME [epoch: 26.6 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26703696785457265		[learning rate: 0.0082443]
	Learning Rate: 0.0082443
	LOSS [training: 0.26703696785457265 | validation: 0.22548098400958771]
	TIME [epoch: 26.6 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26098708356256917		[learning rate: 0.0082115]
	Learning Rate: 0.00821151
	LOSS [training: 0.26098708356256917 | validation: 0.2473914663881534]
	TIME [epoch: 26.6 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2618662495316543		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.2618662495316543 | validation: 0.21083911375323588]
	TIME [epoch: 26.6 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25590063735425467		[learning rate: 0.0081463]
	Learning Rate: 0.00814632
	LOSS [training: 0.25590063735425467 | validation: 0.20217584407047076]
	TIME [epoch: 26.6 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2593265551987845		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.2593265551987845 | validation: 0.224963472031805]
	TIME [epoch: 26.6 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25674029303173995		[learning rate: 0.0080816]
	Learning Rate: 0.00808165
	LOSS [training: 0.25674029303173995 | validation: 0.19938933062400205]
	TIME [epoch: 26.6 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2622329905229731		[learning rate: 0.0080495]
	Learning Rate: 0.00804951
	LOSS [training: 0.2622329905229731 | validation: 0.21243088495151966]
	TIME [epoch: 26.6 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25207103566461997		[learning rate: 0.0080175]
	Learning Rate: 0.00801749
	LOSS [training: 0.25207103566461997 | validation: 0.2231733197833043]
	TIME [epoch: 26.6 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.268320504685841		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.268320504685841 | validation: 0.20278703237448928]
	TIME [epoch: 26.6 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25288809180411226		[learning rate: 0.0079538]
	Learning Rate: 0.00795384
	LOSS [training: 0.25288809180411226 | validation: 0.20846567114058892]
	TIME [epoch: 26.6 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25408091060200333		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.25408091060200333 | validation: 0.20581779394463723]
	TIME [epoch: 26.6 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2494028061986585		[learning rate: 0.0078907]
	Learning Rate: 0.0078907
	LOSS [training: 0.2494028061986585 | validation: 0.20456094429888597]
	TIME [epoch: 26.6 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25221551089566197		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 0.25221551089566197 | validation: 0.21677059554302652]
	TIME [epoch: 26.6 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26584247353928586		[learning rate: 0.0078281]
	Learning Rate: 0.00782805
	LOSS [training: 0.26584247353928586 | validation: 0.20348580704737557]
	TIME [epoch: 26.6 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24897794027005218		[learning rate: 0.0077969]
	Learning Rate: 0.00779692
	LOSS [training: 0.24897794027005218 | validation: 0.1998116224038891]
	TIME [epoch: 26.6 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26112492591862924		[learning rate: 0.0077659]
	Learning Rate: 0.00776591
	LOSS [training: 0.26112492591862924 | validation: 0.20710419024186938]
	TIME [epoch: 26.6 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25204286153652306		[learning rate: 0.007735]
	Learning Rate: 0.00773502
	LOSS [training: 0.25204286153652306 | validation: 0.2406465564676251]
	TIME [epoch: 26.6 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24786126099701603		[learning rate: 0.0077043]
	Learning Rate: 0.00770426
	LOSS [training: 0.24786126099701603 | validation: 0.22165323212475324]
	TIME [epoch: 26.6 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25960172043210383		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.25960172043210383 | validation: 0.21188334854397012]
	TIME [epoch: 26.6 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24482907376810326		[learning rate: 0.0076431]
	Learning Rate: 0.00764309
	LOSS [training: 0.24482907376810326 | validation: 0.22657436050643387]
	TIME [epoch: 26.6 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26356659073633965		[learning rate: 0.0076127]
	Learning Rate: 0.00761269
	LOSS [training: 0.26356659073633965 | validation: 0.20070022059088782]
	TIME [epoch: 26.6 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2623914446774275		[learning rate: 0.0075824]
	Learning Rate: 0.00758242
	LOSS [training: 0.2623914446774275 | validation: 0.217151726638874]
	TIME [epoch: 26.6 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2595399342695648		[learning rate: 0.0075523]
	Learning Rate: 0.00755226
	LOSS [training: 0.2595399342695648 | validation: 0.20657844257851893]
	TIME [epoch: 26.6 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2500177359964225		[learning rate: 0.0075222]
	Learning Rate: 0.00752222
	LOSS [training: 0.2500177359964225 | validation: 0.2002034850369844]
	TIME [epoch: 26.6 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25413849933009103		[learning rate: 0.0074923]
	Learning Rate: 0.0074923
	LOSS [training: 0.25413849933009103 | validation: 0.2031054679887844]
	TIME [epoch: 26.6 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24922770273566344		[learning rate: 0.0074625]
	Learning Rate: 0.0074625
	LOSS [training: 0.24922770273566344 | validation: 0.25174150075158674]
	TIME [epoch: 26.6 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27082518585914545		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.27082518585914545 | validation: 0.2464361263487133]
	TIME [epoch: 26.6 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25468095765205057		[learning rate: 0.0074033]
	Learning Rate: 0.00740326
	LOSS [training: 0.25468095765205057 | validation: 0.20629061166708834]
	TIME [epoch: 26.6 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25055428948808767		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.25055428948808767 | validation: 0.2101459388465614]
	TIME [epoch: 26.6 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24940158923049704		[learning rate: 0.0073445]
	Learning Rate: 0.00734449
	LOSS [training: 0.24940158923049704 | validation: 0.21539840646214872]
	TIME [epoch: 26.6 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26101822745591796		[learning rate: 0.0073153]
	Learning Rate: 0.00731528
	LOSS [training: 0.26101822745591796 | validation: 0.19882859193681884]
	TIME [epoch: 26.6 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_123.pth
	Model improved!!!
EPOCH 124/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2488045923898291		[learning rate: 0.0072862]
	Learning Rate: 0.00728618
	LOSS [training: 0.2488045923898291 | validation: 0.24361459383005934]
	TIME [epoch: 26.6 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2532174954905099		[learning rate: 0.0072572]
	Learning Rate: 0.0072572
	LOSS [training: 0.2532174954905099 | validation: 0.19353597906466935]
	TIME [epoch: 26.6 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_125.pth
	Model improved!!!
EPOCH 126/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2536106582118062		[learning rate: 0.0072283]
	Learning Rate: 0.00722834
	LOSS [training: 0.2536106582118062 | validation: 0.22154255962970928]
	TIME [epoch: 26.6 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24405151448782325		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.24405151448782325 | validation: 0.20247972817305784]
	TIME [epoch: 26.6 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24307429989009804		[learning rate: 0.007171]
	Learning Rate: 0.00717095
	LOSS [training: 0.24307429989009804 | validation: 0.20241061696166343]
	TIME [epoch: 26.6 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2523512797450472		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.2523512797450472 | validation: 0.20150369929171266]
	TIME [epoch: 26.6 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25249415773352596		[learning rate: 0.007114]
	Learning Rate: 0.00711403
	LOSS [training: 0.25249415773352596 | validation: 0.2109582074651879]
	TIME [epoch: 26.6 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2506739359141308		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.2506739359141308 | validation: 0.22400536202201243]
	TIME [epoch: 26.6 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2519645661734922		[learning rate: 0.0070575]
	Learning Rate: 0.00705755
	LOSS [training: 0.2519645661734922 | validation: 0.2275199284648865]
	TIME [epoch: 26.6 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2620505994655998		[learning rate: 0.0070295]
	Learning Rate: 0.00702948
	LOSS [training: 0.2620505994655998 | validation: 0.21355906917408252]
	TIME [epoch: 26.6 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2545434910487164		[learning rate: 0.0070015]
	Learning Rate: 0.00700152
	LOSS [training: 0.2545434910487164 | validation: 0.21438152041052297]
	TIME [epoch: 26.6 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2539097099772741		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.2539097099772741 | validation: 0.21854106302169302]
	TIME [epoch: 26.6 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2501156788428568		[learning rate: 0.0069459]
	Learning Rate: 0.00694594
	LOSS [training: 0.2501156788428568 | validation: 0.20447768798759772]
	TIME [epoch: 26.6 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24529111600674236		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 0.24529111600674236 | validation: 0.2223561661289636]
	TIME [epoch: 26.6 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24987804472106015		[learning rate: 0.0068908]
	Learning Rate: 0.00689079
	LOSS [training: 0.24987804472106015 | validation: 0.19716107110133457]
	TIME [epoch: 26.6 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2471503880418494		[learning rate: 0.0068634]
	Learning Rate: 0.00686339
	LOSS [training: 0.2471503880418494 | validation: 0.2148229965315595]
	TIME [epoch: 26.6 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25031427746397095		[learning rate: 0.0068361]
	Learning Rate: 0.00683609
	LOSS [training: 0.25031427746397095 | validation: 0.20949861117954302]
	TIME [epoch: 26.6 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25682469983452666		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.25682469983452666 | validation: 0.19872804286628296]
	TIME [epoch: 26.6 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2409209290584918		[learning rate: 0.0067818]
	Learning Rate: 0.00678182
	LOSS [training: 0.2409209290584918 | validation: 0.2183824827396872]
	TIME [epoch: 26.6 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2581886045770802		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.2581886045770802 | validation: 0.2032573834756671]
	TIME [epoch: 26.6 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25505945127681096		[learning rate: 0.006728]
	Learning Rate: 0.00672798
	LOSS [training: 0.25505945127681096 | validation: 0.20861474673511182]
	TIME [epoch: 26.6 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2538993223649769		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 0.2538993223649769 | validation: 0.2158036499743951]
	TIME [epoch: 26.6 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24763272890387705		[learning rate: 0.0066746]
	Learning Rate: 0.00667457
	LOSS [training: 0.24763272890387705 | validation: 0.22253330486161121]
	TIME [epoch: 26.6 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26592513474359186		[learning rate: 0.006648]
	Learning Rate: 0.00664802
	LOSS [training: 0.26592513474359186 | validation: 0.1992098293489237]
	TIME [epoch: 26.6 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.242107549215153		[learning rate: 0.0066216]
	Learning Rate: 0.00662158
	LOSS [training: 0.242107549215153 | validation: 0.20923553820865295]
	TIME [epoch: 26.6 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24043804997736412		[learning rate: 0.0065952]
	Learning Rate: 0.00659524
	LOSS [training: 0.24043804997736412 | validation: 0.1910559550505522]
	TIME [epoch: 26.6 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_149.pth
	Model improved!!!
EPOCH 150/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2547741813356696		[learning rate: 0.006569]
	Learning Rate: 0.00656901
	LOSS [training: 0.2547741813356696 | validation: 0.22580918877725686]
	TIME [epoch: 26.6 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24223285028739017		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.24223285028739017 | validation: 0.21767021072003576]
	TIME [epoch: 26.6 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2540295272854117		[learning rate: 0.0065169]
	Learning Rate: 0.00651686
	LOSS [training: 0.2540295272854117 | validation: 0.20183370534801154]
	TIME [epoch: 26.6 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24346251216263498		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 0.24346251216263498 | validation: 0.22332141944317963]
	TIME [epoch: 26.6 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25015278430024684		[learning rate: 0.0064651]
	Learning Rate: 0.00646512
	LOSS [training: 0.25015278430024684 | validation: 0.2041371215455917]
	TIME [epoch: 26.6 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25636056505990445		[learning rate: 0.0064394]
	Learning Rate: 0.00643941
	LOSS [training: 0.25636056505990445 | validation: 0.20213036647111862]
	TIME [epoch: 26.6 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26023196970655504		[learning rate: 0.0064138]
	Learning Rate: 0.0064138
	LOSS [training: 0.26023196970655504 | validation: 0.21327100647851202]
	TIME [epoch: 26.6 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25428465239840725		[learning rate: 0.0063883]
	Learning Rate: 0.00638829
	LOSS [training: 0.25428465239840725 | validation: 0.19705551796011428]
	TIME [epoch: 26.6 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24567535006259872		[learning rate: 0.0063629]
	Learning Rate: 0.00636288
	LOSS [training: 0.24567535006259872 | validation: 0.19835562080687574]
	TIME [epoch: 26.6 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2511864869635041		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.2511864869635041 | validation: 0.20705924272810336]
	TIME [epoch: 26.6 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24655429804554543		[learning rate: 0.0063124]
	Learning Rate: 0.00631237
	LOSS [training: 0.24655429804554543 | validation: 0.2134553947090207]
	TIME [epoch: 26.6 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24370464929511323		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.24370464929511323 | validation: 0.21464968404828988]
	TIME [epoch: 26.6 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25432956380045796		[learning rate: 0.0062623]
	Learning Rate: 0.00626226
	LOSS [training: 0.25432956380045796 | validation: 0.23405557003163707]
	TIME [epoch: 26.5 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24686194076279		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.24686194076279 | validation: 0.19712721133869926]
	TIME [epoch: 26.6 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2433315675787012		[learning rate: 0.0062125]
	Learning Rate: 0.00621254
	LOSS [training: 0.2433315675787012 | validation: 0.20801734824960533]
	TIME [epoch: 26.6 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2455137093493232		[learning rate: 0.0061878]
	Learning Rate: 0.00618783
	LOSS [training: 0.2455137093493232 | validation: 0.19905577132443578]
	TIME [epoch: 26.6 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23769097130420402		[learning rate: 0.0061632]
	Learning Rate: 0.00616322
	LOSS [training: 0.23769097130420402 | validation: 0.1969963206930299]
	TIME [epoch: 26.6 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.242988691881186		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.242988691881186 | validation: 0.2178643336631378]
	TIME [epoch: 26.5 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24761182795075148		[learning rate: 0.0061143]
	Learning Rate: 0.00611429
	LOSS [training: 0.24761182795075148 | validation: 0.23162873431956976]
	TIME [epoch: 26.5 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24067141697232916		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 0.24067141697232916 | validation: 0.19737051000578723]
	TIME [epoch: 26.6 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25146755470819676		[learning rate: 0.0060658]
	Learning Rate: 0.00606575
	LOSS [training: 0.25146755470819676 | validation: 0.20415569054934482]
	TIME [epoch: 26.6 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24797611813161444		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.24797611813161444 | validation: 0.2001222609794912]
	TIME [epoch: 26.6 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23824002629643015		[learning rate: 0.0060176]
	Learning Rate: 0.0060176
	LOSS [training: 0.23824002629643015 | validation: 0.23473397411585073]
	TIME [epoch: 26.6 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24512268639297174		[learning rate: 0.0059937]
	Learning Rate: 0.00599366
	LOSS [training: 0.24512268639297174 | validation: 0.2130079802892749]
	TIME [epoch: 26.6 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24551935684256435		[learning rate: 0.0059698]
	Learning Rate: 0.00596982
	LOSS [training: 0.24551935684256435 | validation: 0.2071965977546053]
	TIME [epoch: 26.5 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2685987876799184		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.2685987876799184 | validation: 0.21573903815992823]
	TIME [epoch: 26.4 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25047795568524756		[learning rate: 0.0059224]
	Learning Rate: 0.00592243
	LOSS [training: 0.25047795568524756 | validation: 0.21772582749738892]
	TIME [epoch: 26.6 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24612070802339905		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 0.24612070802339905 | validation: 0.1995817111571369]
	TIME [epoch: 26.6 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24306308796837758		[learning rate: 0.0058754]
	Learning Rate: 0.00587541
	LOSS [training: 0.24306308796837758 | validation: 0.20698976566302701]
	TIME [epoch: 26.6 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2523081051997064		[learning rate: 0.005852]
	Learning Rate: 0.00585205
	LOSS [training: 0.2523081051997064 | validation: 0.2107488414042596]
	TIME [epoch: 26.6 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24897675996781132		[learning rate: 0.0058288]
	Learning Rate: 0.00582877
	LOSS [training: 0.24897675996781132 | validation: 0.1942100124032877]
	TIME [epoch: 26.6 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24608159325393186		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.24608159325393186 | validation: 0.21637342264849385]
	TIME [epoch: 26.6 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24665430785090672		[learning rate: 0.0057825]
	Learning Rate: 0.0057825
	LOSS [training: 0.24665430785090672 | validation: 0.21350804144371027]
	TIME [epoch: 26.5 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2505830873791124		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.2505830873791124 | validation: 0.21747768782334034]
	TIME [epoch: 26.6 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24126581646272166		[learning rate: 0.0057366]
	Learning Rate: 0.00573659
	LOSS [training: 0.24126581646272166 | validation: 0.1972960108288996]
	TIME [epoch: 26.6 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23801312829920532		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 0.23801312829920532 | validation: 0.20730899082028514]
	TIME [epoch: 26.6 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.244839380333774		[learning rate: 0.005691]
	Learning Rate: 0.00569105
	LOSS [training: 0.244839380333774 | validation: 0.2010882920631974]
	TIME [epoch: 26.6 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2398633147818946		[learning rate: 0.0056684]
	Learning Rate: 0.00566841
	LOSS [training: 0.2398633147818946 | validation: 0.2042669441690536]
	TIME [epoch: 26.6 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23664046141652642		[learning rate: 0.0056459]
	Learning Rate: 0.00564587
	LOSS [training: 0.23664046141652642 | validation: 0.19562117537266077]
	TIME [epoch: 26.6 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23721736741294575		[learning rate: 0.0056234]
	Learning Rate: 0.00562341
	LOSS [training: 0.23721736741294575 | validation: 0.19920022281072763]
	TIME [epoch: 26.6 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23538819249773482		[learning rate: 0.005601]
	Learning Rate: 0.00560105
	LOSS [training: 0.23538819249773482 | validation: 0.20789301273538668]
	TIME [epoch: 26.4 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2480692180729277		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.2480692180729277 | validation: 0.20206273098819874]
	TIME [epoch: 26.6 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24053869418893717		[learning rate: 0.0055566]
	Learning Rate: 0.00555658
	LOSS [training: 0.24053869418893717 | validation: 0.1953624852184435]
	TIME [epoch: 26.6 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24577408324511202		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.24577408324511202 | validation: 0.1889336634663737]
	TIME [epoch: 26.6 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_193.pth
	Model improved!!!
EPOCH 194/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2386979626271329		[learning rate: 0.0055125]
	Learning Rate: 0.00551247
	LOSS [training: 0.2386979626271329 | validation: 0.19848066062421907]
	TIME [epoch: 26.6 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24266645719346158		[learning rate: 0.0054905]
	Learning Rate: 0.00549054
	LOSS [training: 0.24266645719346158 | validation: 0.20727588917223772]
	TIME [epoch: 26.6 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2478920922005761		[learning rate: 0.0054687]
	Learning Rate: 0.00546871
	LOSS [training: 0.2478920922005761 | validation: 0.19872361229264573]
	TIME [epoch: 26.6 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24377317777559593		[learning rate: 0.005447]
	Learning Rate: 0.00544696
	LOSS [training: 0.24377317777559593 | validation: 0.2030599173262527]
	TIME [epoch: 26.6 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2362786580212014		[learning rate: 0.0054253]
	Learning Rate: 0.00542529
	LOSS [training: 0.2362786580212014 | validation: 0.19227584337353712]
	TIME [epoch: 26.6 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23795408628259956		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.23795408628259956 | validation: 0.20085197397449303]
	TIME [epoch: 26.6 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24962336805909502		[learning rate: 0.0053822]
	Learning Rate: 0.00538222
	LOSS [training: 0.24962336805909502 | validation: 0.19309411915534755]
	TIME [epoch: 26.6 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23634108444125537		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.23634108444125537 | validation: 0.19325798322105775]
	TIME [epoch: 26.6 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23668299691418554		[learning rate: 0.0053395]
	Learning Rate: 0.00533949
	LOSS [training: 0.23668299691418554 | validation: 0.21174104419581533]
	TIME [epoch: 26.6 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24950256444689956		[learning rate: 0.0053183]
	Learning Rate: 0.00531826
	LOSS [training: 0.24950256444689956 | validation: 0.19848054259561237]
	TIME [epoch: 26.6 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24356997379232936		[learning rate: 0.0052971]
	Learning Rate: 0.0052971
	LOSS [training: 0.24356997379232936 | validation: 0.1930982120887996]
	TIME [epoch: 26.6 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23565409035915608		[learning rate: 0.005276]
	Learning Rate: 0.00527604
	LOSS [training: 0.23565409035915608 | validation: 0.1990956897186526]
	TIME [epoch: 26.6 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23773576368144267		[learning rate: 0.0052551]
	Learning Rate: 0.00525505
	LOSS [training: 0.23773576368144267 | validation: 0.20266335257591134]
	TIME [epoch: 26.6 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24740995398821466		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.24740995398821466 | validation: 0.19736271438420688]
	TIME [epoch: 26.6 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24297477198780612		[learning rate: 0.0052133]
	Learning Rate: 0.00521333
	LOSS [training: 0.24297477198780612 | validation: 0.20580742243379652]
	TIME [epoch: 26.6 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24275730703154844		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 0.24275730703154844 | validation: 0.19321810219003865]
	TIME [epoch: 26.6 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24083313056039218		[learning rate: 0.0051719]
	Learning Rate: 0.00517194
	LOSS [training: 0.24083313056039218 | validation: 0.19476677512131255]
	TIME [epoch: 26.6 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2350895341487276		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.2350895341487276 | validation: 0.20868337262586575]
	TIME [epoch: 26.6 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2491791565796193		[learning rate: 0.0051309]
	Learning Rate: 0.00513089
	LOSS [training: 0.2491791565796193 | validation: 0.204468376307933]
	TIME [epoch: 26.6 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2335432846490025		[learning rate: 0.0051105]
	Learning Rate: 0.00511048
	LOSS [training: 0.2335432846490025 | validation: 0.20786462896160032]
	TIME [epoch: 26.6 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24477002675634527		[learning rate: 0.0050902]
	Learning Rate: 0.00509015
	LOSS [training: 0.24477002675634527 | validation: 0.1957117526329375]
	TIME [epoch: 26.6 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24284110782167667		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.24284110782167667 | validation: 0.20257251002524562]
	TIME [epoch: 26.6 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23948933256470387		[learning rate: 0.0050497]
	Learning Rate: 0.00504974
	LOSS [training: 0.23948933256470387 | validation: 0.20622989809284414]
	TIME [epoch: 26.6 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24490289386153888		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 0.24490289386153888 | validation: 0.19875690823705047]
	TIME [epoch: 26.6 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23868048361831176		[learning rate: 0.0050097]
	Learning Rate: 0.00500965
	LOSS [training: 0.23868048361831176 | validation: 0.19366578440298068]
	TIME [epoch: 26.6 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2310428110771357		[learning rate: 0.0049897]
	Learning Rate: 0.00498973
	LOSS [training: 0.2310428110771357 | validation: 0.19102284747101494]
	TIME [epoch: 26.6 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24602327285022854		[learning rate: 0.0049699]
	Learning Rate: 0.00496988
	LOSS [training: 0.24602327285022854 | validation: 0.20495047871550276]
	TIME [epoch: 26.6 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23870941397431755		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.23870941397431755 | validation: 0.20217674674754021]
	TIME [epoch: 26.6 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24892674125823502		[learning rate: 0.0049304]
	Learning Rate: 0.00493043
	LOSS [training: 0.24892674125823502 | validation: 0.19405355503816718]
	TIME [epoch: 26.6 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23753885829055965		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.23753885829055965 | validation: 0.20132337363354758]
	TIME [epoch: 26.6 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24161753424664584		[learning rate: 0.0048913]
	Learning Rate: 0.00489129
	LOSS [training: 0.24161753424664584 | validation: 0.19377799174052696]
	TIME [epoch: 26.6 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24130265521958297		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.24130265521958297 | validation: 0.21045127164157487]
	TIME [epoch: 26.6 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23908584802917832		[learning rate: 0.0048525]
	Learning Rate: 0.00485245
	LOSS [training: 0.23908584802917832 | validation: 0.19792234646194523]
	TIME [epoch: 26.6 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23815369757464394		[learning rate: 0.0048332]
	Learning Rate: 0.00483316
	LOSS [training: 0.23815369757464394 | validation: 0.2048737527157754]
	TIME [epoch: 26.6 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24062311588176577		[learning rate: 0.0048139]
	Learning Rate: 0.00481393
	LOSS [training: 0.24062311588176577 | validation: 0.20447533376121996]
	TIME [epoch: 26.6 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2605824605273111		[learning rate: 0.0047948]
	Learning Rate: 0.00479479
	LOSS [training: 0.2605824605273111 | validation: 0.204285148180192]
	TIME [epoch: 26.6 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24063598036720166		[learning rate: 0.0047757]
	Learning Rate: 0.00477572
	LOSS [training: 0.24063598036720166 | validation: 0.1932000028631705]
	TIME [epoch: 26.6 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24093182092293886		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.24093182092293886 | validation: 0.20514676495501685]
	TIME [epoch: 26.6 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2404769130541386		[learning rate: 0.0047378]
	Learning Rate: 0.0047378
	LOSS [training: 0.2404769130541386 | validation: 0.1924711554136088]
	TIME [epoch: 26.6 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23843910305490182		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 0.23843910305490182 | validation: 0.1925894163736263]
	TIME [epoch: 26.6 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2381150195786004		[learning rate: 0.0047002]
	Learning Rate: 0.00470019
	LOSS [training: 0.2381150195786004 | validation: 0.2002231429372571]
	TIME [epoch: 26.6 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24131321647265233		[learning rate: 0.0046815]
	Learning Rate: 0.0046815
	LOSS [training: 0.24131321647265233 | validation: 0.19828709685659143]
	TIME [epoch: 26.6 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24167507886856734		[learning rate: 0.0046629]
	Learning Rate: 0.00466288
	LOSS [training: 0.24167507886856734 | validation: 0.19924956097259378]
	TIME [epoch: 26.6 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24219793348759464		[learning rate: 0.0046443]
	Learning Rate: 0.00464433
	LOSS [training: 0.24219793348759464 | validation: 0.20259598531636147]
	TIME [epoch: 26.6 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23223785352075532		[learning rate: 0.0046259]
	Learning Rate: 0.00462586
	LOSS [training: 0.23223785352075532 | validation: 0.1992615835659636]
	TIME [epoch: 26.6 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2438916882530602		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.2438916882530602 | validation: 0.24467558561668215]
	TIME [epoch: 26.6 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25552195119044396		[learning rate: 0.0045891]
	Learning Rate: 0.00458913
	LOSS [training: 0.25552195119044396 | validation: 0.19177388223587938]
	TIME [epoch: 26.6 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23757014774404844		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.23757014774404844 | validation: 0.19487655076040003]
	TIME [epoch: 26.6 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23913441293464144		[learning rate: 0.0045527]
	Learning Rate: 0.0045527
	LOSS [training: 0.23913441293464144 | validation: 0.199505831617248]
	TIME [epoch: 26.6 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24140559893558855		[learning rate: 0.0045346]
	Learning Rate: 0.00453459
	LOSS [training: 0.24140559893558855 | validation: 0.19914030960996548]
	TIME [epoch: 26.6 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23643094936791054		[learning rate: 0.0045166]
	Learning Rate: 0.00451656
	LOSS [training: 0.23643094936791054 | validation: 0.20715651028252885]
	TIME [epoch: 26.6 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23872528032610862		[learning rate: 0.0044986]
	Learning Rate: 0.0044986
	LOSS [training: 0.23872528032610862 | validation: 0.20449002067946626]
	TIME [epoch: 26.6 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23316942391453896		[learning rate: 0.0044807]
	Learning Rate: 0.0044807
	LOSS [training: 0.23316942391453896 | validation: 0.19919390691114708]
	TIME [epoch: 26.6 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24044656772313053		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.24044656772313053 | validation: 0.19507402814621427]
	TIME [epoch: 26.6 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23990689205872315		[learning rate: 0.0044451]
	Learning Rate: 0.00444513
	LOSS [training: 0.23990689205872315 | validation: 0.20263806812521334]
	TIME [epoch: 26.6 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2379843282980767		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 0.2379843282980767 | validation: 0.19885345563986903]
	TIME [epoch: 26.6 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2350842294419077		[learning rate: 0.0044098]
	Learning Rate: 0.00440984
	LOSS [training: 0.2350842294419077 | validation: 0.19437236222561605]
	TIME [epoch: 26.6 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23479312966474197		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.23479312966474197 | validation: 0.1911221571976402]
	TIME [epoch: 26.6 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23640845187627946		[learning rate: 0.0043748]
	Learning Rate: 0.00437483
	LOSS [training: 0.23640845187627946 | validation: 0.20104523317063155]
	TIME [epoch: 26.6 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2487389129490531		[learning rate: 0.0043574]
	Learning Rate: 0.00435743
	LOSS [training: 0.2487389129490531 | validation: 0.1931228909395547]
	TIME [epoch: 26.6 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24154356569312072		[learning rate: 0.0043401]
	Learning Rate: 0.0043401
	LOSS [training: 0.24154356569312072 | validation: 0.19574261681371632]
	TIME [epoch: 26.6 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23096224093685253		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.23096224093685253 | validation: 0.22965809482519353]
	TIME [epoch: 26.6 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2395777499680747		[learning rate: 0.0043056]
	Learning Rate: 0.00430565
	LOSS [training: 0.2395777499680747 | validation: 0.1883514902468587]
	TIME [epoch: 26.6 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_256.pth
	Model improved!!!
EPOCH 257/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2336722909995441		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.2336722909995441 | validation: 0.2059866763989318]
	TIME [epoch: 26.6 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24574520784099724		[learning rate: 0.0042715]
	Learning Rate: 0.00427147
	LOSS [training: 0.24574520784099724 | validation: 0.18881604682218095]
	TIME [epoch: 26.6 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2327202156442388		[learning rate: 0.0042545]
	Learning Rate: 0.00425448
	LOSS [training: 0.2327202156442388 | validation: 0.19600877483165022]
	TIME [epoch: 26.6 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22645909955461926		[learning rate: 0.0042376]
	Learning Rate: 0.00423756
	LOSS [training: 0.22645909955461926 | validation: 0.1990334998022184]
	TIME [epoch: 26.6 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25002721228307717		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.25002721228307717 | validation: 0.20299175432962197]
	TIME [epoch: 26.6 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2363050939755142		[learning rate: 0.0042039]
	Learning Rate: 0.00420391
	LOSS [training: 0.2363050939755142 | validation: 0.20132331750050123]
	TIME [epoch: 26.6 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2386845372824205		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.2386845372824205 | validation: 0.19419383275097427]
	TIME [epoch: 26.6 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23617402369963092		[learning rate: 0.0041705]
	Learning Rate: 0.00417054
	LOSS [training: 0.23617402369963092 | validation: 0.2287619517743292]
	TIME [epoch: 26.6 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24771708301232837		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 0.24771708301232837 | validation: 0.20361218295425373]
	TIME [epoch: 26.6 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27128301825855095		[learning rate: 0.0041374]
	Learning Rate: 0.00413743
	LOSS [training: 0.27128301825855095 | validation: 0.2067851822286418]
	TIME [epoch: 26.6 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24067680395285176		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.24067680395285176 | validation: 0.19915720641837387]
	TIME [epoch: 26.6 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24071733982171295		[learning rate: 0.0041046]
	Learning Rate: 0.00410458
	LOSS [training: 0.24071733982171295 | validation: 0.19066173311140636]
	TIME [epoch: 26.6 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24462824453460755		[learning rate: 0.0040883]
	Learning Rate: 0.00408826
	LOSS [training: 0.24462824453460755 | validation: 0.18653472415991454]
	TIME [epoch: 26.6 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_269.pth
	Model improved!!!
EPOCH 270/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2371679462643192		[learning rate: 0.004072]
	Learning Rate: 0.004072
	LOSS [training: 0.2371679462643192 | validation: 0.1936933006682764]
	TIME [epoch: 26.5 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23773898784610903		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.23773898784610903 | validation: 0.23101158379035333]
	TIME [epoch: 26.6 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24044537261892762		[learning rate: 0.0040397]
	Learning Rate: 0.00403967
	LOSS [training: 0.24044537261892762 | validation: 0.19186161886178993]
	TIME [epoch: 26.5 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23810340627433269		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 0.23810340627433269 | validation: 0.20300476456964697]
	TIME [epoch: 26.5 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2376833277770371		[learning rate: 0.0040076]
	Learning Rate: 0.0040076
	LOSS [training: 0.2376833277770371 | validation: 0.21328582167206428]
	TIME [epoch: 26.5 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23465279870631875		[learning rate: 0.0039917]
	Learning Rate: 0.00399166
	LOSS [training: 0.23465279870631875 | validation: 0.20350500637543836]
	TIME [epoch: 26.6 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2387323389962496		[learning rate: 0.0039758]
	Learning Rate: 0.00397579
	LOSS [training: 0.2387323389962496 | validation: 0.1907743107074608]
	TIME [epoch: 26.6 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23674414668459948		[learning rate: 0.00396]
	Learning Rate: 0.00395997
	LOSS [training: 0.23674414668459948 | validation: 0.20201294015006113]
	TIME [epoch: 26.6 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24228009804052825		[learning rate: 0.0039442]
	Learning Rate: 0.00394422
	LOSS [training: 0.24228009804052825 | validation: 0.19895180383733918]
	TIME [epoch: 26.6 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23587308376866054		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.23587308376866054 | validation: 0.19649584768109649]
	TIME [epoch: 26.6 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24086472910327414		[learning rate: 0.0039129]
	Learning Rate: 0.00391291
	LOSS [training: 0.24086472910327414 | validation: 0.19772424051568901]
	TIME [epoch: 26.6 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2381468003802088		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.2381468003802088 | validation: 0.1956693093203407]
	TIME [epoch: 26.6 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23722998781850352		[learning rate: 0.0038818]
	Learning Rate: 0.00388185
	LOSS [training: 0.23722998781850352 | validation: 0.19909221609461664]
	TIME [epoch: 26.6 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23195235997788835		[learning rate: 0.0038664]
	Learning Rate: 0.00386641
	LOSS [training: 0.23195235997788835 | validation: 0.20060099557192443]
	TIME [epoch: 26.6 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23976711141704954		[learning rate: 0.003851]
	Learning Rate: 0.00385103
	LOSS [training: 0.23976711141704954 | validation: 0.1994741330801391]
	TIME [epoch: 26.6 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23656118826841505		[learning rate: 0.0038357]
	Learning Rate: 0.00383571
	LOSS [training: 0.23656118826841505 | validation: 0.2078631390364866]
	TIME [epoch: 26.6 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2419611404480278		[learning rate: 0.0038205]
	Learning Rate: 0.00382046
	LOSS [training: 0.2419611404480278 | validation: 0.1933989189039283]
	TIME [epoch: 26.6 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23846567661096282		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.23846567661096282 | validation: 0.19252532126274965]
	TIME [epoch: 26.6 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23231001654947578		[learning rate: 0.0037901]
	Learning Rate: 0.00379013
	LOSS [training: 0.23231001654947578 | validation: 0.19144073699874686]
	TIME [epoch: 26.9 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23562857058191378		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.23562857058191378 | validation: 0.1913204367322658]
	TIME [epoch: 26.6 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23908388488241183		[learning rate: 0.00376]
	Learning Rate: 0.00376004
	LOSS [training: 0.23908388488241183 | validation: 0.1924770987727923]
	TIME [epoch: 26.6 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23030068227501982		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.23030068227501982 | validation: 0.19598893611398735]
	TIME [epoch: 26.6 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23162125611959672		[learning rate: 0.0037302]
	Learning Rate: 0.00373019
	LOSS [training: 0.23162125611959672 | validation: 0.19643683809014026]
	TIME [epoch: 26.6 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2352087930026331		[learning rate: 0.0037154]
	Learning Rate: 0.00371535
	LOSS [training: 0.2352087930026331 | validation: 0.20409454433515464]
	TIME [epoch: 26.6 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.232934829058452		[learning rate: 0.0037006]
	Learning Rate: 0.00370058
	LOSS [training: 0.232934829058452 | validation: 0.1962243421679863]
	TIME [epoch: 26.6 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23662990147637208		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.23662990147637208 | validation: 0.1989176706949173]
	TIME [epoch: 26.6 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24168473539364863		[learning rate: 0.0036712]
	Learning Rate: 0.0036712
	LOSS [training: 0.24168473539364863 | validation: 0.19012810653845602]
	TIME [epoch: 26.6 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2410456511359239		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 0.2410456511359239 | validation: 0.19847112108323914]
	TIME [epoch: 26.6 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22905432972504217		[learning rate: 0.0036421]
	Learning Rate: 0.00364205
	LOSS [training: 0.22905432972504217 | validation: 0.19927101892011825]
	TIME [epoch: 26.6 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2438191430633494		[learning rate: 0.0036276]
	Learning Rate: 0.00362757
	LOSS [training: 0.2438191430633494 | validation: 0.2030965898846823]
	TIME [epoch: 26.6 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24346064391825145		[learning rate: 0.0036131]
	Learning Rate: 0.00361314
	LOSS [training: 0.24346064391825145 | validation: 0.1929495894904704]
	TIME [epoch: 26.5 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22904708465876591		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.22904708465876591 | validation: 0.19226356799612226]
	TIME [epoch: 26.5 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23057912306956807		[learning rate: 0.0035845]
	Learning Rate: 0.00358445
	LOSS [training: 0.23057912306956807 | validation: 0.1916589791817689]
	TIME [epoch: 26.5 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23371331766624978		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.23371331766624978 | validation: 0.19075043832009578]
	TIME [epoch: 26.4 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23597728250481198		[learning rate: 0.003556]
	Learning Rate: 0.003556
	LOSS [training: 0.23597728250481198 | validation: 0.18639225435975176]
	TIME [epoch: 26.5 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_304.pth
	Model improved!!!
EPOCH 305/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2320812985959335		[learning rate: 0.0035419]
	Learning Rate: 0.00354185
	LOSS [training: 0.2320812985959335 | validation: 0.19357209994037136]
	TIME [epoch: 26.6 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24288511663474052		[learning rate: 0.0035278]
	Learning Rate: 0.00352777
	LOSS [training: 0.24288511663474052 | validation: 0.1909712201444081]
	TIME [epoch: 26.6 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2324627178440623		[learning rate: 0.0035137]
	Learning Rate: 0.00351374
	LOSS [training: 0.2324627178440623 | validation: 0.19162062329442747]
	TIME [epoch: 26.6 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22958886406821832		[learning rate: 0.0034998]
	Learning Rate: 0.00349976
	LOSS [training: 0.22958886406821832 | validation: 0.19690962990086552]
	TIME [epoch: 26.6 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23811013156880717		[learning rate: 0.0034858]
	Learning Rate: 0.00348584
	LOSS [training: 0.23811013156880717 | validation: 0.1913268170070553]
	TIME [epoch: 26.6 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23589879435054495		[learning rate: 0.003472]
	Learning Rate: 0.00347198
	LOSS [training: 0.23589879435054495 | validation: 0.19792029924572946]
	TIME [epoch: 26.6 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2316757011892574		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.2316757011892574 | validation: 0.19393133673373253]
	TIME [epoch: 26.5 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24478028406097593		[learning rate: 0.0034444]
	Learning Rate: 0.00344441
	LOSS [training: 0.24478028406097593 | validation: 0.19874967394803753]
	TIME [epoch: 26.6 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23709078987725674		[learning rate: 0.0034307]
	Learning Rate: 0.00343071
	LOSS [training: 0.23709078987725674 | validation: 0.1880964755815327]
	TIME [epoch: 26.6 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2360635528127194		[learning rate: 0.0034171]
	Learning Rate: 0.00341707
	LOSS [training: 0.2360635528127194 | validation: 0.19811416138939228]
	TIME [epoch: 26.5 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24454441429831084		[learning rate: 0.0034035]
	Learning Rate: 0.00340348
	LOSS [training: 0.24454441429831084 | validation: 0.19449781593449558]
	TIME [epoch: 26.6 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23132627260926877		[learning rate: 0.0033899]
	Learning Rate: 0.00338994
	LOSS [training: 0.23132627260926877 | validation: 0.19225516648691227]
	TIME [epoch: 26.6 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23869124696118815		[learning rate: 0.0033765]
	Learning Rate: 0.00337646
	LOSS [training: 0.23869124696118815 | validation: 0.19251600119220463]
	TIME [epoch: 26.6 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23232954158623004		[learning rate: 0.003363]
	Learning Rate: 0.00336303
	LOSS [training: 0.23232954158623004 | validation: 0.1907278901287411]
	TIME [epoch: 26.6 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.229133231756597		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.229133231756597 | validation: 0.1930287927588995]
	TIME [epoch: 26.6 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23139472750744428		[learning rate: 0.0033363]
	Learning Rate: 0.00333633
	LOSS [training: 0.23139472750744428 | validation: 0.20064626334852237]
	TIME [epoch: 26.6 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24086628952088274		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.24086628952088274 | validation: 0.1905850140545831]
	TIME [epoch: 26.6 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23993620727477716		[learning rate: 0.0033098]
	Learning Rate: 0.00330985
	LOSS [training: 0.23993620727477716 | validation: 0.19420477242368278]
	TIME [epoch: 26.5 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2389549542521461		[learning rate: 0.0032967]
	Learning Rate: 0.00329668
	LOSS [training: 0.2389549542521461 | validation: 0.19619786538664247]
	TIME [epoch: 26.5 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24323947498696288		[learning rate: 0.0032836]
	Learning Rate: 0.00328357
	LOSS [training: 0.24323947498696288 | validation: 0.20351596035918945]
	TIME [epoch: 26.5 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.236340641199504		[learning rate: 0.0032705]
	Learning Rate: 0.00327051
	LOSS [training: 0.236340641199504 | validation: 0.1956057956328825]
	TIME [epoch: 26.4 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23553175088909478		[learning rate: 0.0032575]
	Learning Rate: 0.0032575
	LOSS [training: 0.23553175088909478 | validation: 0.19132298076345206]
	TIME [epoch: 26.6 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23242291780685356		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.23242291780685356 | validation: 0.18837947654465795]
	TIME [epoch: 26.6 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23711060855795627		[learning rate: 0.0032316]
	Learning Rate: 0.00323164
	LOSS [training: 0.23711060855795627 | validation: 0.1901236462146922]
	TIME [epoch: 26.5 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23006145382183185		[learning rate: 0.0032188]
	Learning Rate: 0.00321879
	LOSS [training: 0.23006145382183185 | validation: 0.19947722424641257]
	TIME [epoch: 26.5 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23521517170088047		[learning rate: 0.003206]
	Learning Rate: 0.00320599
	LOSS [training: 0.23521517170088047 | validation: 0.20206655818008645]
	TIME [epoch: 26.5 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23185862583804548		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.23185862583804548 | validation: 0.1921477124242078]
	TIME [epoch: 26.6 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2302831198444849		[learning rate: 0.0031805]
	Learning Rate: 0.00318053
	LOSS [training: 0.2302831198444849 | validation: 0.19075206072443826]
	TIME [epoch: 26.5 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23414264350136785		[learning rate: 0.0031679]
	Learning Rate: 0.00316788
	LOSS [training: 0.23414264350136785 | validation: 0.21350362084364116]
	TIME [epoch: 26.5 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23440393771017065		[learning rate: 0.0031553]
	Learning Rate: 0.00315528
	LOSS [training: 0.23440393771017065 | validation: 0.18939100351598998]
	TIME [epoch: 26.5 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2361585790371243		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.2361585790371243 | validation: 0.19270414247480733]
	TIME [epoch: 26.6 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23231094213750036		[learning rate: 0.0031302]
	Learning Rate: 0.00313023
	LOSS [training: 0.23231094213750036 | validation: 0.18704067218636933]
	TIME [epoch: 26.5 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.236315181805587		[learning rate: 0.0031178]
	Learning Rate: 0.00311779
	LOSS [training: 0.236315181805587 | validation: 0.19051232821877667]
	TIME [epoch: 26.5 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2299061483913296		[learning rate: 0.0031054]
	Learning Rate: 0.00310538
	LOSS [training: 0.2299061483913296 | validation: 0.19381154603247513]
	TIME [epoch: 26.6 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24376817314156599		[learning rate: 0.003093]
	Learning Rate: 0.00309303
	LOSS [training: 0.24376817314156599 | validation: 0.2015746180703401]
	TIME [epoch: 26.6 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23486257497647797		[learning rate: 0.0030807]
	Learning Rate: 0.00308073
	LOSS [training: 0.23486257497647797 | validation: 0.1880667424670655]
	TIME [epoch: 26.5 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23485082958251383		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.23485082958251383 | validation: 0.18951955500312137]
	TIME [epoch: 26.6 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2391924804647084		[learning rate: 0.0030563]
	Learning Rate: 0.00305627
	LOSS [training: 0.2391924804647084 | validation: 0.2010988096739242]
	TIME [epoch: 26.5 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2378401889472438		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.2378401889472438 | validation: 0.19347171734396446]
	TIME [epoch: 26.5 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23982957915158684		[learning rate: 0.003032]
	Learning Rate: 0.00303201
	LOSS [training: 0.23982957915158684 | validation: 0.19262830428712224]
	TIME [epoch: 26.5 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23453583389887342		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.23453583389887342 | validation: 0.18647361281609104]
	TIME [epoch: 26.6 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2322523579080018		[learning rate: 0.0030079]
	Learning Rate: 0.00300794
	LOSS [training: 0.2322523579080018 | validation: 0.18816933102946676]
	TIME [epoch: 26.6 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22935982958833456		[learning rate: 0.002996]
	Learning Rate: 0.00299598
	LOSS [training: 0.22935982958833456 | validation: 0.21833916315296661]
	TIME [epoch: 26.6 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23631207984935246		[learning rate: 0.0029841]
	Learning Rate: 0.00298406
	LOSS [training: 0.23631207984935246 | validation: 0.20541907646562133]
	TIME [epoch: 26.4 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2511929867000532		[learning rate: 0.0029722]
	Learning Rate: 0.00297219
	LOSS [training: 0.2511929867000532 | validation: 0.19104873122034116]
	TIME [epoch: 26.6 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2387806734577362		[learning rate: 0.0029604]
	Learning Rate: 0.00296037
	LOSS [training: 0.2387806734577362 | validation: 0.19012643394332113]
	TIME [epoch: 26.6 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24135314326808815		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.24135314326808815 | validation: 0.1901757544647969]
	TIME [epoch: 26.6 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23969184044548403		[learning rate: 0.0029369]
	Learning Rate: 0.00293687
	LOSS [training: 0.23969184044548403 | validation: 0.19265519024895128]
	TIME [epoch: 26.6 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22492803381233703		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.22492803381233703 | validation: 0.19084303439445602]
	TIME [epoch: 26.6 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23648322470516728		[learning rate: 0.0029136]
	Learning Rate: 0.00291355
	LOSS [training: 0.23648322470516728 | validation: 0.19920595043176242]
	TIME [epoch: 26.5 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2383496765294725		[learning rate: 0.002902]
	Learning Rate: 0.00290197
	LOSS [training: 0.2383496765294725 | validation: 0.1965362576738927]
	TIME [epoch: 26.4 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23510281929602486		[learning rate: 0.0028904]
	Learning Rate: 0.00289042
	LOSS [training: 0.23510281929602486 | validation: 0.19634127505332352]
	TIME [epoch: 26.6 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23529321369095277		[learning rate: 0.0028789]
	Learning Rate: 0.00287893
	LOSS [training: 0.23529321369095277 | validation: 0.20125525107455783]
	TIME [epoch: 26.6 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22597812858656915		[learning rate: 0.0028675]
	Learning Rate: 0.00286748
	LOSS [training: 0.22597812858656915 | validation: 0.19567354375518178]
	TIME [epoch: 26.5 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23353852284451737		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.23353852284451737 | validation: 0.18847335838770846]
	TIME [epoch: 26.5 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23422370359608916		[learning rate: 0.0028447]
	Learning Rate: 0.00284471
	LOSS [training: 0.23422370359608916 | validation: 0.18780570264856233]
	TIME [epoch: 26.5 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2278538754769474		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.2278538754769474 | validation: 0.1874280393706218]
	TIME [epoch: 26.5 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2349943838611454		[learning rate: 0.0028221]
	Learning Rate: 0.00282213
	LOSS [training: 0.2349943838611454 | validation: 0.20587511799954053]
	TIME [epoch: 26.5 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24249568700999602		[learning rate: 0.0028109]
	Learning Rate: 0.00281091
	LOSS [training: 0.24249568700999602 | validation: 0.19707593961847242]
	TIME [epoch: 26.6 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23597740611361415		[learning rate: 0.0027997]
	Learning Rate: 0.00279973
	LOSS [training: 0.23597740611361415 | validation: 0.18466851513010052]
	TIME [epoch: 26.5 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_364.pth
	Model improved!!!
EPOCH 365/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2280537118205999		[learning rate: 0.0027886]
	Learning Rate: 0.00278859
	LOSS [training: 0.2280537118205999 | validation: 0.1979170971081004]
	TIME [epoch: 26.5 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23630298209022488		[learning rate: 0.0027775]
	Learning Rate: 0.0027775
	LOSS [training: 0.23630298209022488 | validation: 0.19328735420716892]
	TIME [epoch: 26.4 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2351313619348926		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.2351313619348926 | validation: 0.19549770025114097]
	TIME [epoch: 26.5 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23838526730706283		[learning rate: 0.0027554]
	Learning Rate: 0.00275545
	LOSS [training: 0.23838526730706283 | validation: 0.19227868768458803]
	TIME [epoch: 26.5 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2588699599118951		[learning rate: 0.0027445]
	Learning Rate: 0.00274449
	LOSS [training: 0.2588699599118951 | validation: 0.2102184201597574]
	TIME [epoch: 26.6 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2557423857756612		[learning rate: 0.0027336]
	Learning Rate: 0.00273357
	LOSS [training: 0.2557423857756612 | validation: 0.20672614304063935]
	TIME [epoch: 26.6 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25155480204075764		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.25155480204075764 | validation: 0.20633557064839864]
	TIME [epoch: 26.5 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2568671351609205		[learning rate: 0.0027119]
	Learning Rate: 0.00271187
	LOSS [training: 0.2568671351609205 | validation: 0.2011394582850695]
	TIME [epoch: 26.6 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24107198001800828		[learning rate: 0.0027011]
	Learning Rate: 0.00270109
	LOSS [training: 0.24107198001800828 | validation: 0.1956279315955743]
	TIME [epoch: 26.5 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23573582533334322		[learning rate: 0.0026903]
	Learning Rate: 0.00269034
	LOSS [training: 0.23573582533334322 | validation: 0.19113512656413462]
	TIME [epoch: 26.5 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2396799125105673		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.2396799125105673 | validation: 0.1958638587199819]
	TIME [epoch: 26.5 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2384072852789853		[learning rate: 0.002669]
	Learning Rate: 0.00266899
	LOSS [training: 0.2384072852789853 | validation: 0.19891790791082858]
	TIME [epoch: 26.5 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24363404142287826		[learning rate: 0.0026584]
	Learning Rate: 0.00265837
	LOSS [training: 0.24363404142287826 | validation: 0.20337565295340002]
	TIME [epoch: 26.6 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23451969441570542		[learning rate: 0.0026478]
	Learning Rate: 0.0026478
	LOSS [training: 0.23451969441570542 | validation: 0.19635942582683968]
	TIME [epoch: 26.4 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23578208435470202		[learning rate: 0.0026373]
	Learning Rate: 0.00263727
	LOSS [training: 0.23578208435470202 | validation: 0.19452717721346452]
	TIME [epoch: 26.5 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2345226334174329		[learning rate: 0.0026268]
	Learning Rate: 0.00262678
	LOSS [training: 0.2345226334174329 | validation: 0.19322558334766898]
	TIME [epoch: 26.5 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23837647679625842		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.23837647679625842 | validation: 0.1995730076718379]
	TIME [epoch: 26.5 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23824211339483659		[learning rate: 0.0026059]
	Learning Rate: 0.00260592
	LOSS [training: 0.23824211339483659 | validation: 0.2088272894533784]
	TIME [epoch: 26.5 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25225688127501716		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.25225688127501716 | validation: 0.19824722698655084]
	TIME [epoch: 26.5 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2425351725894883		[learning rate: 0.0025852]
	Learning Rate: 0.00258523
	LOSS [training: 0.2425351725894883 | validation: 0.19456769940481727]
	TIME [epoch: 26.5 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23933283919869874		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.23933283919869874 | validation: 0.18939040344658276]
	TIME [epoch: 26.5 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23800549892136472		[learning rate: 0.0025647]
	Learning Rate: 0.00256471
	LOSS [training: 0.23800549892136472 | validation: 0.19239956050229745]
	TIME [epoch: 26.6 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2394085705589443		[learning rate: 0.0025545]
	Learning Rate: 0.00255451
	LOSS [training: 0.2394085705589443 | validation: 0.19185764946904071]
	TIME [epoch: 26.6 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23814951626510814		[learning rate: 0.0025444]
	Learning Rate: 0.00254435
	LOSS [training: 0.23814951626510814 | validation: 0.20213157965899115]
	TIME [epoch: 26.6 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23628701174994005		[learning rate: 0.0025342]
	Learning Rate: 0.00253423
	LOSS [training: 0.23628701174994005 | validation: 0.1907058498163342]
	TIME [epoch: 26.5 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2286688931209953		[learning rate: 0.0025242]
	Learning Rate: 0.00252415
	LOSS [training: 0.2286688931209953 | validation: 0.1946726432551479]
	TIME [epoch: 26.5 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2340760772898981		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.2340760772898981 | validation: 0.1964718277595283]
	TIME [epoch: 26.5 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23479395942103626		[learning rate: 0.0025041]
	Learning Rate: 0.00250411
	LOSS [training: 0.23479395942103626 | validation: 0.20611291847191215]
	TIME [epoch: 26.5 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23812965632866628		[learning rate: 0.0024942]
	Learning Rate: 0.00249415
	LOSS [training: 0.23812965632866628 | validation: 0.19176111908927626]
	TIME [epoch: 26.5 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23275610319365705		[learning rate: 0.0024842]
	Learning Rate: 0.00248423
	LOSS [training: 0.23275610319365705 | validation: 0.19204171829265138]
	TIME [epoch: 26.5 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23251352964339952		[learning rate: 0.0024744]
	Learning Rate: 0.00247435
	LOSS [training: 0.23251352964339952 | validation: 0.19649483743740997]
	TIME [epoch: 26.5 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24277844914212274		[learning rate: 0.0024645]
	Learning Rate: 0.00246451
	LOSS [training: 0.24277844914212274 | validation: 0.1926394648694982]
	TIME [epoch: 26.5 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23276826592723104		[learning rate: 0.0024547]
	Learning Rate: 0.00245471
	LOSS [training: 0.23276826592723104 | validation: 0.19124610574447284]
	TIME [epoch: 26.5 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2345294728456617		[learning rate: 0.0024449]
	Learning Rate: 0.00244495
	LOSS [training: 0.2345294728456617 | validation: 0.19541793081064923]
	TIME [epoch: 26.5 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2308198951568517		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.2308198951568517 | validation: 0.19724142323378346]
	TIME [epoch: 26.5 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23553045673171688		[learning rate: 0.0024255]
	Learning Rate: 0.00242554
	LOSS [training: 0.23553045673171688 | validation: 0.19554276457263198]
	TIME [epoch: 26.4 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23733418559872974		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.23733418559872974 | validation: 0.19165916966043034]
	TIME [epoch: 26.6 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24013458380973077		[learning rate: 0.0024063]
	Learning Rate: 0.00240628
	LOSS [training: 0.24013458380973077 | validation: 0.19217612883048124]
	TIME [epoch: 26.5 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2327829159238822		[learning rate: 0.0023967]
	Learning Rate: 0.00239671
	LOSS [training: 0.2327829159238822 | validation: 0.1983311525980041]
	TIME [epoch: 26.6 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23873399661380346		[learning rate: 0.0023872]
	Learning Rate: 0.00238718
	LOSS [training: 0.23873399661380346 | validation: 0.1977137743866044]
	TIME [epoch: 26.5 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22956325778475184		[learning rate: 0.0023777]
	Learning Rate: 0.00237768
	LOSS [training: 0.22956325778475184 | validation: 0.1904879898928787]
	TIME [epoch: 26.4 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2350134532013738		[learning rate: 0.0023682]
	Learning Rate: 0.00236823
	LOSS [training: 0.2350134532013738 | validation: 0.19228614667953095]
	TIME [epoch: 26.5 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23403985869029237		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.23403985869029237 | validation: 0.19361655731332011]
	TIME [epoch: 26.5 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2397397728989329		[learning rate: 0.0023494]
	Learning Rate: 0.00234942
	LOSS [training: 0.2397397728989329 | validation: 0.1890862755447023]
	TIME [epoch: 26.5 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2409633512110108		[learning rate: 0.0023401]
	Learning Rate: 0.00234008
	LOSS [training: 0.2409633512110108 | validation: 0.19826513299613163]
	TIME [epoch: 26.5 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23672959844000666		[learning rate: 0.0023308]
	Learning Rate: 0.00233077
	LOSS [training: 0.23672959844000666 | validation: 0.19381539363527014]
	TIME [epoch: 26.6 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23061181237381556		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.23061181237381556 | validation: 0.20398222631918736]
	TIME [epoch: 26.5 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2264358984054331		[learning rate: 0.0023123]
	Learning Rate: 0.00231227
	LOSS [training: 0.2264358984054331 | validation: 0.18936238091200314]
	TIME [epoch: 26.5 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23142857999007116		[learning rate: 0.0023031]
	Learning Rate: 0.00230307
	LOSS [training: 0.23142857999007116 | validation: 0.19337398353613494]
	TIME [epoch: 26.6 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23440492402398652		[learning rate: 0.0022939]
	Learning Rate: 0.00229391
	LOSS [training: 0.23440492402398652 | validation: 0.19417658850820044]
	TIME [epoch: 26.6 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2321317856822121		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.2321317856822121 | validation: 0.20748476892520742]
	TIME [epoch: 26.5 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23236468616033332		[learning rate: 0.0022757]
	Learning Rate: 0.0022757
	LOSS [training: 0.23236468616033332 | validation: 0.1940210611341431]
	TIME [epoch: 26.5 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2389950492777649		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.2389950492777649 | validation: 0.2024569501095707]
	TIME [epoch: 26.5 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23711196042127533		[learning rate: 0.0022576]
	Learning Rate: 0.00225764
	LOSS [training: 0.23711196042127533 | validation: 0.19806687129386846]
	TIME [epoch: 26.5 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23393712697586289		[learning rate: 0.0022487]
	Learning Rate: 0.00224866
	LOSS [training: 0.23393712697586289 | validation: 0.19292854733502232]
	TIME [epoch: 26.5 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23127628734030475		[learning rate: 0.0022397]
	Learning Rate: 0.00223971
	LOSS [training: 0.23127628734030475 | validation: 0.19258687497673743]
	TIME [epoch: 26.4 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2276350882710972		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.2276350882710972 | validation: 0.19120613541859255]
	TIME [epoch: 26.6 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22969908281322057		[learning rate: 0.0022219]
	Learning Rate: 0.00222193
	LOSS [training: 0.22969908281322057 | validation: 0.1899222149175927]
	TIME [epoch: 26.6 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22937087909242568		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.22937087909242568 | validation: 0.1933318164061795]
	TIME [epoch: 26.5 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23535864234568227		[learning rate: 0.0022043]
	Learning Rate: 0.00220429
	LOSS [training: 0.23535864234568227 | validation: 0.18955710444541088]
	TIME [epoch: 26.5 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2441341405969738		[learning rate: 0.0021955]
	Learning Rate: 0.00219553
	LOSS [training: 0.2441341405969738 | validation: 0.2107519263694521]
	TIME [epoch: 26.6 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2399824834962883		[learning rate: 0.0021868]
	Learning Rate: 0.00218679
	LOSS [training: 0.2399824834962883 | validation: 0.193268112479434]
	TIME [epoch: 26.6 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2349568122734697		[learning rate: 0.0021781]
	Learning Rate: 0.0021781
	LOSS [training: 0.2349568122734697 | validation: 0.19275844816527604]
	TIME [epoch: 26.6 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24148619449270997		[learning rate: 0.0021694]
	Learning Rate: 0.00216943
	LOSS [training: 0.24148619449270997 | validation: 0.1927159259052588]
	TIME [epoch: 26.6 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23172478611306369		[learning rate: 0.0021608]
	Learning Rate: 0.0021608
	LOSS [training: 0.23172478611306369 | validation: 0.19393267460414038]
	TIME [epoch: 26.6 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23500985213041206		[learning rate: 0.0021522]
	Learning Rate: 0.00215221
	LOSS [training: 0.23500985213041206 | validation: 0.19708314527487567]
	TIME [epoch: 26.6 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2355261053105482		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.2355261053105482 | validation: 0.19139586653143953]
	TIME [epoch: 26.6 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23545496758181134		[learning rate: 0.0021351]
	Learning Rate: 0.00213512
	LOSS [training: 0.23545496758181134 | validation: 0.1929293152071341]
	TIME [epoch: 26.6 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22920687211987342		[learning rate: 0.0021266]
	Learning Rate: 0.00212663
	LOSS [training: 0.22920687211987342 | validation: 0.18751961020006752]
	TIME [epoch: 26.6 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23401484976869824		[learning rate: 0.0021182]
	Learning Rate: 0.00211817
	LOSS [training: 0.23401484976869824 | validation: 0.19026735256149505]
	TIME [epoch: 26.6 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22664140049939407		[learning rate: 0.0021097]
	Learning Rate: 0.00210975
	LOSS [training: 0.22664140049939407 | validation: 0.1921926498076679]
	TIME [epoch: 26.5 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23900043422570802		[learning rate: 0.0021014]
	Learning Rate: 0.00210136
	LOSS [training: 0.23900043422570802 | validation: 0.19134373997653537]
	TIME [epoch: 26.6 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2375895165801911		[learning rate: 0.002093]
	Learning Rate: 0.002093
	LOSS [training: 0.2375895165801911 | validation: 0.18894587312898242]
	TIME [epoch: 26.6 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23041165033331762		[learning rate: 0.0020847]
	Learning Rate: 0.00208468
	LOSS [training: 0.23041165033331762 | validation: 0.19254583802679764]
	TIME [epoch: 26.5 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23517393005959367		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.23517393005959367 | validation: 0.18750002318748335]
	TIME [epoch: 26.4 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22808641534633217		[learning rate: 0.0020681]
	Learning Rate: 0.00206813
	LOSS [training: 0.22808641534633217 | validation: 0.19810755770655525]
	TIME [epoch: 26.5 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23510165410836065		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.23510165410836065 | validation: 0.1946732504199146]
	TIME [epoch: 26.6 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23039948833852528		[learning rate: 0.0020517]
	Learning Rate: 0.00205171
	LOSS [training: 0.23039948833852528 | validation: 0.1929178682084803]
	TIME [epoch: 26.6 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22952263543694038		[learning rate: 0.0020435]
	Learning Rate: 0.00204355
	LOSS [training: 0.22952263543694038 | validation: 0.19369919964605992]
	TIME [epoch: 26.6 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23964629744886098		[learning rate: 0.0020354]
	Learning Rate: 0.00203542
	LOSS [training: 0.23964629744886098 | validation: 0.18804758814572636]
	TIME [epoch: 26.6 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23041120455101666		[learning rate: 0.0020273]
	Learning Rate: 0.00202732
	LOSS [training: 0.23041120455101666 | validation: 0.18976251661478072]
	TIME [epoch: 26.6 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23153806609503313		[learning rate: 0.0020193]
	Learning Rate: 0.00201926
	LOSS [training: 0.23153806609503313 | validation: 0.19427527012075102]
	TIME [epoch: 26.6 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23182004859449368		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.23182004859449368 | validation: 0.1942859529593663]
	TIME [epoch: 26.6 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22997757007826816		[learning rate: 0.0020032]
	Learning Rate: 0.00200323
	LOSS [training: 0.22997757007826816 | validation: 0.1960206276315004]
	TIME [epoch: 26.5 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23153647015098353		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.23153647015098353 | validation: 0.19142017996469446]
	TIME [epoch: 26.4 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23124504824110037		[learning rate: 0.0019873]
	Learning Rate: 0.00198733
	LOSS [training: 0.23124504824110037 | validation: 0.19676603018797123]
	TIME [epoch: 26.5 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24154840941538908		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.24154840941538908 | validation: 0.1923848619691477]
	TIME [epoch: 26.5 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22706473158855628		[learning rate: 0.0019715]
	Learning Rate: 0.00197155
	LOSS [training: 0.22706473158855628 | validation: 0.19172300487196203]
	TIME [epoch: 26.5 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23240693064447482		[learning rate: 0.0019637]
	Learning Rate: 0.00196371
	LOSS [training: 0.23240693064447482 | validation: 0.19076236673966868]
	TIME [epoch: 26.6 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23506985937179115		[learning rate: 0.0019559]
	Learning Rate: 0.0019559
	LOSS [training: 0.23506985937179115 | validation: 0.19432980471524547]
	TIME [epoch: 26.5 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23957892796721023		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.23957892796721023 | validation: 0.18545818204469905]
	TIME [epoch: 26.5 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.229185489410648		[learning rate: 0.0019404]
	Learning Rate: 0.00194037
	LOSS [training: 0.229185489410648 | validation: 0.19178186631244212]
	TIME [epoch: 26.5 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2315193896773841		[learning rate: 0.0019327]
	Learning Rate: 0.00193265
	LOSS [training: 0.2315193896773841 | validation: 0.19140793561697297]
	TIME [epoch: 26.5 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23268579086879143		[learning rate: 0.001925]
	Learning Rate: 0.00192497
	LOSS [training: 0.23268579086879143 | validation: 0.18308693639794002]
	TIME [epoch: 26.5 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_458.pth
	Model improved!!!
EPOCH 459/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22905427360532846		[learning rate: 0.0019173]
	Learning Rate: 0.00191731
	LOSS [training: 0.22905427360532846 | validation: 0.18789588727125234]
	TIME [epoch: 26.5 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23553189295113328		[learning rate: 0.0019097]
	Learning Rate: 0.00190968
	LOSS [training: 0.23553189295113328 | validation: 0.19083100393930272]
	TIME [epoch: 26.5 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23119345396228408		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.23119345396228408 | validation: 0.1918164089963804]
	TIME [epoch: 26.5 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22705271910774064		[learning rate: 0.0018945]
	Learning Rate: 0.00189452
	LOSS [training: 0.22705271910774064 | validation: 0.18775719357816872]
	TIME [epoch: 26.5 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23588176121277046		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.23588176121277046 | validation: 0.19444689655226904]
	TIME [epoch: 26.5 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22731875965971632		[learning rate: 0.0018795]
	Learning Rate: 0.00187948
	LOSS [training: 0.22731875965971632 | validation: 0.18970606368224535]
	TIME [epoch: 26.5 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23553090595547677		[learning rate: 0.001872]
	Learning Rate: 0.00187201
	LOSS [training: 0.23553090595547677 | validation: 0.19308752573036783]
	TIME [epoch: 26.4 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23229783415165425		[learning rate: 0.0018646]
	Learning Rate: 0.00186456
	LOSS [training: 0.23229783415165425 | validation: 0.1917281048570318]
	TIME [epoch: 26.4 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23143429993946305		[learning rate: 0.0018571]
	Learning Rate: 0.00185715
	LOSS [training: 0.23143429993946305 | validation: 0.19272800503084783]
	TIME [epoch: 26.4 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23165466181790326		[learning rate: 0.0018498]
	Learning Rate: 0.00184976
	LOSS [training: 0.23165466181790326 | validation: 0.191376194225284]
	TIME [epoch: 26.4 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2321630257755588		[learning rate: 0.0018424]
	Learning Rate: 0.0018424
	LOSS [training: 0.2321630257755588 | validation: 0.1900029384033326]
	TIME [epoch: 26.5 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23108624147653434		[learning rate: 0.0018351]
	Learning Rate: 0.00183508
	LOSS [training: 0.23108624147653434 | validation: 0.19145425407306269]
	TIME [epoch: 26.6 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23325266242201956		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.23325266242201956 | validation: 0.19123111642358936]
	TIME [epoch: 26.5 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2364643899671336		[learning rate: 0.0018205]
	Learning Rate: 0.00182051
	LOSS [training: 0.2364643899671336 | validation: 0.18513671723026298]
	TIME [epoch: 26.5 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22699774229651995		[learning rate: 0.0018133]
	Learning Rate: 0.00181327
	LOSS [training: 0.22699774229651995 | validation: 0.18934974668081997]
	TIME [epoch: 26.5 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23037322283574305		[learning rate: 0.0018061]
	Learning Rate: 0.00180605
	LOSS [training: 0.23037322283574305 | validation: 0.1924826513318074]
	TIME [epoch: 26.5 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23240151678512833		[learning rate: 0.0017989]
	Learning Rate: 0.00179887
	LOSS [training: 0.23240151678512833 | validation: 0.19229408818346763]
	TIME [epoch: 26.5 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23205394324993384		[learning rate: 0.0017917]
	Learning Rate: 0.00179172
	LOSS [training: 0.23205394324993384 | validation: 0.19211546251358363]
	TIME [epoch: 26.5 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2345621672058344		[learning rate: 0.0017846]
	Learning Rate: 0.00178459
	LOSS [training: 0.2345621672058344 | validation: 0.19202679927344288]
	TIME [epoch: 26.5 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23379496542725814		[learning rate: 0.0017775]
	Learning Rate: 0.00177749
	LOSS [training: 0.23379496542725814 | validation: 0.19427720850210545]
	TIME [epoch: 26.5 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23183099576043434		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.23183099576043434 | validation: 0.18863472087738958]
	TIME [epoch: 26.5 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23015749698733418		[learning rate: 0.0017634]
	Learning Rate: 0.00176338
	LOSS [training: 0.23015749698733418 | validation: 0.19423088295918883]
	TIME [epoch: 26.6 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23185506057956953		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.23185506057956953 | validation: 0.1934356418312544]
	TIME [epoch: 26.5 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22793169068542016		[learning rate: 0.0017494]
	Learning Rate: 0.00174938
	LOSS [training: 0.22793169068542016 | validation: 0.1931756008334335]
	TIME [epoch: 26.5 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2268600462551854		[learning rate: 0.0017424]
	Learning Rate: 0.00174242
	LOSS [training: 0.2268600462551854 | validation: 0.19231111224765324]
	TIME [epoch: 26.5 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2331536674324918		[learning rate: 0.0017355]
	Learning Rate: 0.00173549
	LOSS [training: 0.2331536674324918 | validation: 0.18891996036688674]
	TIME [epoch: 26.6 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22938921071404536		[learning rate: 0.0017286]
	Learning Rate: 0.00172859
	LOSS [training: 0.22938921071404536 | validation: 0.19052411316920997]
	TIME [epoch: 26.4 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23514609607434642		[learning rate: 0.0017217]
	Learning Rate: 0.00172172
	LOSS [training: 0.23514609607434642 | validation: 0.19541744101913916]
	TIME [epoch: 26.5 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23315365742917527		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.23315365742917527 | validation: 0.18996744386763154]
	TIME [epoch: 26.5 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23045252466189525		[learning rate: 0.001708]
	Learning Rate: 0.00170805
	LOSS [training: 0.23045252466189525 | validation: 0.19261880746541032]
	TIME [epoch: 26.6 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23028776622250158		[learning rate: 0.0017013]
	Learning Rate: 0.00170125
	LOSS [training: 0.23028776622250158 | validation: 0.1933888124707543]
	TIME [epoch: 26.5 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23318014204971116		[learning rate: 0.0016945]
	Learning Rate: 0.00169449
	LOSS [training: 0.23318014204971116 | validation: 0.18635640305270046]
	TIME [epoch: 26.6 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23325722530215032		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.23325722530215032 | validation: 0.19437028577359688]
	TIME [epoch: 26.5 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2351824828621877		[learning rate: 0.001681]
	Learning Rate: 0.00168104
	LOSS [training: 0.2351824828621877 | validation: 0.1880919401179714]
	TIME [epoch: 26.6 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23405195165583242		[learning rate: 0.0016743]
	Learning Rate: 0.00167435
	LOSS [training: 0.23405195165583242 | validation: 0.1969290245506795]
	TIME [epoch: 26.5 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23071009477186166		[learning rate: 0.0016677]
	Learning Rate: 0.00166769
	LOSS [training: 0.23071009477186166 | validation: 0.19177951298989426]
	TIME [epoch: 26.4 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22862711357164966		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.22862711357164966 | validation: 0.19386596380842133]
	TIME [epoch: 26.6 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23446206314373302		[learning rate: 0.0016545]
	Learning Rate: 0.00165445
	LOSS [training: 0.23446206314373302 | validation: 0.18892837169053073]
	TIME [epoch: 26.5 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23734475286154044		[learning rate: 0.0016479]
	Learning Rate: 0.00164787
	LOSS [training: 0.23734475286154044 | validation: 0.18828151228135842]
	TIME [epoch: 26.4 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22708175893455587		[learning rate: 0.0016413]
	Learning Rate: 0.00164132
	LOSS [training: 0.22708175893455587 | validation: 0.19768053635671928]
	TIME [epoch: 26.4 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.226903509829662		[learning rate: 0.0016348]
	Learning Rate: 0.00163479
	LOSS [training: 0.226903509829662 | validation: 0.18910553360899612]
	TIME [epoch: 26.4 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2280937439686335		[learning rate: 0.0016283]
	Learning Rate: 0.00162829
	LOSS [training: 0.2280937439686335 | validation: 0.18824330228283348]
	TIME [epoch: 26.4 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2307262041485563		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.2307262041485563 | validation: 0.18949850131993612]
	TIME [epoch: 82.7 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23399192664337823		[learning rate: 0.0016154]
	Learning Rate: 0.00161536
	LOSS [training: 0.23399192664337823 | validation: 0.18837201389017988]
	TIME [epoch: 57 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2301102982639769		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.2301102982639769 | validation: 0.19183664296038433]
	TIME [epoch: 56.9 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2295867768581475		[learning rate: 0.0016025]
	Learning Rate: 0.00160254
	LOSS [training: 0.2295867768581475 | validation: 0.19250414834706486]
	TIME [epoch: 56.9 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23543132839060565		[learning rate: 0.0015962]
	Learning Rate: 0.00159616
	LOSS [training: 0.23543132839060565 | validation: 0.18941507973912958]
	TIME [epoch: 56.9 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22695363298054805		[learning rate: 0.0015898]
	Learning Rate: 0.00158981
	LOSS [training: 0.22695363298054805 | validation: 0.1963742680468357]
	TIME [epoch: 56.9 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22523461886619905		[learning rate: 0.0015835]
	Learning Rate: 0.00158349
	LOSS [training: 0.22523461886619905 | validation: 0.18816147562635402]
	TIME [epoch: 56.9 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22915080811037372		[learning rate: 0.0015772]
	Learning Rate: 0.00157719
	LOSS [training: 0.22915080811037372 | validation: 0.1934543337470695]
	TIME [epoch: 56.9 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23356644582127506		[learning rate: 0.0015709]
	Learning Rate: 0.00157092
	LOSS [training: 0.23356644582127506 | validation: 0.19772525276394126]
	TIME [epoch: 57 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2305638873887085		[learning rate: 0.0015647]
	Learning Rate: 0.00156467
	LOSS [training: 0.2305638873887085 | validation: 0.18946832446054923]
	TIME [epoch: 56.9 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2316699545271072		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.2316699545271072 | validation: 0.193239821095932]
	TIME [epoch: 57 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2296876496205915		[learning rate: 0.0015522]
	Learning Rate: 0.00155225
	LOSS [training: 0.2296876496205915 | validation: 0.1938504913923903]
	TIME [epoch: 56.9 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23386452409755126		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.23386452409755126 | validation: 0.19016260212974298]
	TIME [epoch: 56.9 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2362519237663621		[learning rate: 0.0015399]
	Learning Rate: 0.00153993
	LOSS [training: 0.2362519237663621 | validation: 0.19214662625579626]
	TIME [epoch: 56.9 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2279193050134135		[learning rate: 0.0015338]
	Learning Rate: 0.0015338
	LOSS [training: 0.2279193050134135 | validation: 0.1929596723563347]
	TIME [epoch: 56.9 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22513811590512223		[learning rate: 0.0015277]
	Learning Rate: 0.0015277
	LOSS [training: 0.22513811590512223 | validation: 0.19099706914943015]
	TIME [epoch: 56.9 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2294447746240652		[learning rate: 0.0015216]
	Learning Rate: 0.00152163
	LOSS [training: 0.2294447746240652 | validation: 0.18997830098831478]
	TIME [epoch: 57 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2325886244568625		[learning rate: 0.0015156]
	Learning Rate: 0.00151557
	LOSS [training: 0.2325886244568625 | validation: 0.18718650954644037]
	TIME [epoch: 56.9 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22633311449409652		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.22633311449409652 | validation: 0.19008938151803892]
	TIME [epoch: 56.9 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22725480482010982		[learning rate: 0.0015035]
	Learning Rate: 0.00150354
	LOSS [training: 0.22725480482010982 | validation: 0.1952550765665829]
	TIME [epoch: 56.9 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2255501166871005		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.2255501166871005 | validation: 0.1899710258208409]
	TIME [epoch: 57 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22711578035800187		[learning rate: 0.0014916]
	Learning Rate: 0.00149161
	LOSS [training: 0.22711578035800187 | validation: 0.19298201933506717]
	TIME [epoch: 56.9 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22620809530387062		[learning rate: 0.0014857]
	Learning Rate: 0.00148567
	LOSS [training: 0.22620809530387062 | validation: 0.19749291569997357]
	TIME [epoch: 57 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22912242113330597		[learning rate: 0.0014798]
	Learning Rate: 0.00147976
	LOSS [training: 0.22912242113330597 | validation: 0.19118276338908105]
	TIME [epoch: 56.9 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2297644608747853		[learning rate: 0.0014739]
	Learning Rate: 0.00147388
	LOSS [training: 0.2297644608747853 | validation: 0.19199919903991097]
	TIME [epoch: 57 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22987563083190551		[learning rate: 0.001468]
	Learning Rate: 0.00146802
	LOSS [training: 0.22987563083190551 | validation: 0.20134408888682853]
	TIME [epoch: 56.9 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23386687002905285		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.23386687002905285 | validation: 0.18806705508887456]
	TIME [epoch: 57 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2314801830709741		[learning rate: 0.0014564]
	Learning Rate: 0.00145636
	LOSS [training: 0.2314801830709741 | validation: 0.1873533095072249]
	TIME [epoch: 57 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2240585127690868		[learning rate: 0.0014506]
	Learning Rate: 0.00145057
	LOSS [training: 0.2240585127690868 | validation: 0.19124525240514073]
	TIME [epoch: 57 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2315656032397873		[learning rate: 0.0014448]
	Learning Rate: 0.0014448
	LOSS [training: 0.2315656032397873 | validation: 0.19397256492745965]
	TIME [epoch: 56.9 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2289713963753383		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.2289713963753383 | validation: 0.18861778275420968]
	TIME [epoch: 57 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22820344804684745		[learning rate: 0.0014333]
	Learning Rate: 0.00143333
	LOSS [training: 0.22820344804684745 | validation: 0.19234330545404493]
	TIME [epoch: 56.9 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23493555728909854		[learning rate: 0.0014276]
	Learning Rate: 0.00142763
	LOSS [training: 0.23493555728909854 | validation: 0.18914216920128607]
	TIME [epoch: 57 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2288131691094725		[learning rate: 0.001422]
	Learning Rate: 0.00142195
	LOSS [training: 0.2288131691094725 | validation: 0.19068714743182244]
	TIME [epoch: 56.9 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2353267345589559		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.2353267345589559 | validation: 0.18988033947622213]
	TIME [epoch: 57 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22663112010229977		[learning rate: 0.0014107]
	Learning Rate: 0.00141066
	LOSS [training: 0.22663112010229977 | validation: 0.19222302291285695]
	TIME [epoch: 56.9 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22601856908086113		[learning rate: 0.0014051]
	Learning Rate: 0.00140505
	LOSS [training: 0.22601856908086113 | validation: 0.18487405421561612]
	TIME [epoch: 57 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23202019160264767		[learning rate: 0.0013995]
	Learning Rate: 0.00139946
	LOSS [training: 0.23202019160264767 | validation: 0.1883975955374933]
	TIME [epoch: 56.9 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23148231313988632		[learning rate: 0.0013939]
	Learning Rate: 0.0013939
	LOSS [training: 0.23148231313988632 | validation: 0.18732679325520452]
	TIME [epoch: 56.9 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23091700245777502		[learning rate: 0.0013884]
	Learning Rate: 0.00138835
	LOSS [training: 0.23091700245777502 | validation: 0.18812325879208944]
	TIME [epoch: 56.9 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22635067474533624		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.22635067474533624 | validation: 0.19085869827912966]
	TIME [epoch: 56.9 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2285929238145869		[learning rate: 0.0013773]
	Learning Rate: 0.00137733
	LOSS [training: 0.2285929238145869 | validation: 0.19447720953218212]
	TIME [epoch: 56.9 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2225254052035157		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.2225254052035157 | validation: 0.191401631186582]
	TIME [epoch: 57 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23365949081975193		[learning rate: 0.0013664]
	Learning Rate: 0.0013664
	LOSS [training: 0.23365949081975193 | validation: 0.19093478791461013]
	TIME [epoch: 56.9 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2338298692028133		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.2338298692028133 | validation: 0.188931237862449]
	TIME [epoch: 57 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2263615651416654		[learning rate: 0.0013555]
	Learning Rate: 0.00135555
	LOSS [training: 0.2263615651416654 | validation: 0.19314236461692108]
	TIME [epoch: 56.9 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22835310653415253		[learning rate: 0.0013502]
	Learning Rate: 0.00135016
	LOSS [training: 0.22835310653415253 | validation: 0.19511145783169942]
	TIME [epoch: 57 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2299175625632403		[learning rate: 0.0013448]
	Learning Rate: 0.00134479
	LOSS [training: 0.2299175625632403 | validation: 0.1922358363386274]
	TIME [epoch: 57 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22897951696450386		[learning rate: 0.0013394]
	Learning Rate: 0.00133944
	LOSS [training: 0.22897951696450386 | validation: 0.19067650982113898]
	TIME [epoch: 57 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23519067567312119		[learning rate: 0.0013341]
	Learning Rate: 0.00133411
	LOSS [training: 0.23519067567312119 | validation: 0.19053579024774042]
	TIME [epoch: 56.9 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22868504525862654		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.22868504525862654 | validation: 0.19002944226918989]
	TIME [epoch: 57 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22128593015664946		[learning rate: 0.0013235]
	Learning Rate: 0.00132352
	LOSS [training: 0.22128593015664946 | validation: 0.19169753554372954]
	TIME [epoch: 57 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22744229625558887		[learning rate: 0.0013183]
	Learning Rate: 0.00131826
	LOSS [training: 0.22744229625558887 | validation: 0.19494407022276797]
	TIME [epoch: 57 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2256033143915389		[learning rate: 0.001313]
	Learning Rate: 0.00131301
	LOSS [training: 0.2256033143915389 | validation: 0.18926812220033212]
	TIME [epoch: 56.9 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22756812065788987		[learning rate: 0.0013078]
	Learning Rate: 0.00130779
	LOSS [training: 0.22756812065788987 | validation: 0.18898891545901625]
	TIME [epoch: 57 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2266522434308325		[learning rate: 0.0013026]
	Learning Rate: 0.00130259
	LOSS [training: 0.2266522434308325 | validation: 0.19639704851437087]
	TIME [epoch: 57 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22488427956444548		[learning rate: 0.0012974]
	Learning Rate: 0.00129741
	LOSS [training: 0.22488427956444548 | validation: 0.19184054130037073]
	TIME [epoch: 56.9 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22118483391463933		[learning rate: 0.0012922]
	Learning Rate: 0.00129225
	LOSS [training: 0.22118483391463933 | validation: 0.1921133720014227]
	TIME [epoch: 56.9 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2259668497440692		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.2259668497440692 | validation: 0.1913336469387402]
	TIME [epoch: 56.9 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23204799533212522		[learning rate: 0.001282]
	Learning Rate: 0.00128199
	LOSS [training: 0.23204799533212522 | validation: 0.18748228839981412]
	TIME [epoch: 56.9 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23396407733578123		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.23396407733578123 | validation: 0.1903983975032725]
	TIME [epoch: 57 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23129019383941488		[learning rate: 0.0012718]
	Learning Rate: 0.00127181
	LOSS [training: 0.23129019383941488 | validation: 0.19084734029662737]
	TIME [epoch: 56.9 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22811985962093534		[learning rate: 0.0012668]
	Learning Rate: 0.00126675
	LOSS [training: 0.22811985962093534 | validation: 0.190044281514526]
	TIME [epoch: 57 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2266659479265224		[learning rate: 0.0012617]
	Learning Rate: 0.00126172
	LOSS [training: 0.2266659479265224 | validation: 0.1888941409273488]
	TIME [epoch: 56.9 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22895307661974565		[learning rate: 0.0012567]
	Learning Rate: 0.0012567
	LOSS [training: 0.22895307661974565 | validation: 0.1885659051764918]
	TIME [epoch: 57 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23146208266979362		[learning rate: 0.0012517]
	Learning Rate: 0.0012517
	LOSS [training: 0.23146208266979362 | validation: 0.18578921654196853]
	TIME [epoch: 56.9 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2260171551151985		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.2260171551151985 | validation: 0.18330688769016473]
	TIME [epoch: 57 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22738634116486717		[learning rate: 0.0012418]
	Learning Rate: 0.00124176
	LOSS [training: 0.22738634116486717 | validation: 0.1873210773542507]
	TIME [epoch: 56.9 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22817687281557042		[learning rate: 0.0012368]
	Learning Rate: 0.00123682
	LOSS [training: 0.22817687281557042 | validation: 0.19364337105347507]
	TIME [epoch: 57 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22868210681578838		[learning rate: 0.0012319]
	Learning Rate: 0.0012319
	LOSS [training: 0.22868210681578838 | validation: 0.20194357979788835]
	TIME [epoch: 56.9 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2350107745950292		[learning rate: 0.001227]
	Learning Rate: 0.001227
	LOSS [training: 0.2350107745950292 | validation: 0.18899111845781236]
	TIME [epoch: 57 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2275950130362487		[learning rate: 0.0012221]
	Learning Rate: 0.00122212
	LOSS [training: 0.2275950130362487 | validation: 0.1916505717557146]
	TIME [epoch: 56.9 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2256877512616024		[learning rate: 0.0012173]
	Learning Rate: 0.00121726
	LOSS [training: 0.2256877512616024 | validation: 0.19070179832060702]
	TIME [epoch: 57 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2268013883049018		[learning rate: 0.0012124]
	Learning Rate: 0.00121242
	LOSS [training: 0.2268013883049018 | validation: 0.18692828086797503]
	TIME [epoch: 56.9 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22283079573317627		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.22283079573317627 | validation: 0.1897028203041154]
	TIME [epoch: 57 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2298946129356925		[learning rate: 0.0012028]
	Learning Rate: 0.0012028
	LOSS [training: 0.2298946129356925 | validation: 0.1896638366158911]
	TIME [epoch: 56.9 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2286835615936194		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.2286835615936194 | validation: 0.1899950755232023]
	TIME [epoch: 56.9 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2298331868456449		[learning rate: 0.0011932]
	Learning Rate: 0.00119325
	LOSS [training: 0.2298331868456449 | validation: 0.195389987843458]
	TIME [epoch: 57 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22967632736509971		[learning rate: 0.0011885]
	Learning Rate: 0.0011885
	LOSS [training: 0.22967632736509971 | validation: 0.1865866802227621]
	TIME [epoch: 57 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22435093931094327		[learning rate: 0.0011838]
	Learning Rate: 0.00118378
	LOSS [training: 0.22435093931094327 | validation: 0.1933241170031406]
	TIME [epoch: 56.9 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23116308768851213		[learning rate: 0.0011791]
	Learning Rate: 0.00117907
	LOSS [training: 0.23116308768851213 | validation: 0.18865151663324548]
	TIME [epoch: 57 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22985798888537085		[learning rate: 0.0011744]
	Learning Rate: 0.00117438
	LOSS [training: 0.22985798888537085 | validation: 0.1872112396973002]
	TIME [epoch: 56.9 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22598687971186968		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.22598687971186968 | validation: 0.18948750672754106]
	TIME [epoch: 57 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2277814218256226		[learning rate: 0.0011651]
	Learning Rate: 0.00116505
	LOSS [training: 0.2277814218256226 | validation: 0.1902352944191303]
	TIME [epoch: 57 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22664655122975214		[learning rate: 0.0011604]
	Learning Rate: 0.00116042
	LOSS [training: 0.22664655122975214 | validation: 0.1876993159577059]
	TIME [epoch: 56.9 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.228787271825174		[learning rate: 0.0011558]
	Learning Rate: 0.00115581
	LOSS [training: 0.228787271825174 | validation: 0.1936683722399856]
	TIME [epoch: 56.9 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22136072572217647		[learning rate: 0.0011512]
	Learning Rate: 0.00115121
	LOSS [training: 0.22136072572217647 | validation: 0.18979035474496458]
	TIME [epoch: 57 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2254821836931732		[learning rate: 0.0011466]
	Learning Rate: 0.00114663
	LOSS [training: 0.2254821836931732 | validation: 0.18623413892244356]
	TIME [epoch: 56.9 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23123850202151164		[learning rate: 0.0011421]
	Learning Rate: 0.00114207
	LOSS [training: 0.23123850202151164 | validation: 0.1912083304223607]
	TIME [epoch: 57 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22766707938482134		[learning rate: 0.0011375]
	Learning Rate: 0.00113753
	LOSS [training: 0.22766707938482134 | validation: 0.18507623352736066]
	TIME [epoch: 56.9 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22872278162354698		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.22872278162354698 | validation: 0.18543327277422314]
	TIME [epoch: 57 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23241372878160244		[learning rate: 0.0011285]
	Learning Rate: 0.0011285
	LOSS [training: 0.23241372878160244 | validation: 0.18795942304544347]
	TIME [epoch: 56.9 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22787657770606304		[learning rate: 0.001124]
	Learning Rate: 0.00112401
	LOSS [training: 0.22787657770606304 | validation: 0.18539331651665963]
	TIME [epoch: 57 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2240218589566723		[learning rate: 0.0011195]
	Learning Rate: 0.00111954
	LOSS [training: 0.2240218589566723 | validation: 0.18888798645979907]
	TIME [epoch: 56.9 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23391856861444127		[learning rate: 0.0011151]
	Learning Rate: 0.00111508
	LOSS [training: 0.23391856861444127 | validation: 0.18671278164082167]
	TIME [epoch: 57 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22943466011691266		[learning rate: 0.0011106]
	Learning Rate: 0.00111065
	LOSS [training: 0.22943466011691266 | validation: 0.1894081039959909]
	TIME [epoch: 56.9 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2307911945611706		[learning rate: 0.0011062]
	Learning Rate: 0.00110623
	LOSS [training: 0.2307911945611706 | validation: 0.19029459514443847]
	TIME [epoch: 56.9 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23391420848287256		[learning rate: 0.0011018]
	Learning Rate: 0.00110183
	LOSS [training: 0.23391420848287256 | validation: 0.18710681290620265]
	TIME [epoch: 56.9 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22702561483613026		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.22702561483613026 | validation: 0.19049463647433323]
	TIME [epoch: 57 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2334405758051933		[learning rate: 0.0010931]
	Learning Rate: 0.00109309
	LOSS [training: 0.2334405758051933 | validation: 0.18822337482502322]
	TIME [epoch: 57 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2261557395980722		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.2261557395980722 | validation: 0.1886033608899588]
	TIME [epoch: 56.9 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22627984450902877		[learning rate: 0.0010844]
	Learning Rate: 0.00108441
	LOSS [training: 0.22627984450902877 | validation: 0.19129707919493866]
	TIME [epoch: 56.9 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2319642092034338		[learning rate: 0.0010801]
	Learning Rate: 0.00108009
	LOSS [training: 0.2319642092034338 | validation: 0.18468978522933308]
	TIME [epoch: 56.9 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2263768354505205		[learning rate: 0.0010758]
	Learning Rate: 0.0010758
	LOSS [training: 0.2263768354505205 | validation: 0.18651051613496888]
	TIME [epoch: 56.9 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2294656080648282		[learning rate: 0.0010715]
	Learning Rate: 0.00107152
	LOSS [training: 0.2294656080648282 | validation: 0.1872151481500269]
	TIME [epoch: 56.9 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23094027097608164		[learning rate: 0.0010673]
	Learning Rate: 0.00106726
	LOSS [training: 0.23094027097608164 | validation: 0.18950827229883704]
	TIME [epoch: 56.9 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23010961512425976		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.23010961512425976 | validation: 0.18581014295898482]
	TIME [epoch: 56.9 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22854906551034107		[learning rate: 0.0010588]
	Learning Rate: 0.00105878
	LOSS [training: 0.22854906551034107 | validation: 0.187323581786643]
	TIME [epoch: 56.9 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2253463880162636		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.2253463880162636 | validation: 0.18923645865031538]
	TIME [epoch: 56.9 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2258225738033119		[learning rate: 0.0010504]
	Learning Rate: 0.00105038
	LOSS [training: 0.2258225738033119 | validation: 0.18958710871319107]
	TIME [epoch: 56.9 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22366230160265196		[learning rate: 0.0010462]
	Learning Rate: 0.0010462
	LOSS [training: 0.22366230160265196 | validation: 0.1932379635891409]
	TIME [epoch: 56.9 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22784421713305317		[learning rate: 0.001042]
	Learning Rate: 0.00104204
	LOSS [training: 0.22784421713305317 | validation: 0.1904772216729466]
	TIME [epoch: 56.9 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23288949125911035		[learning rate: 0.0010379]
	Learning Rate: 0.0010379
	LOSS [training: 0.23288949125911035 | validation: 0.18909373830240367]
	TIME [epoch: 56.9 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23198004800969235		[learning rate: 0.0010338]
	Learning Rate: 0.00103377
	LOSS [training: 0.23198004800969235 | validation: 0.19312390461227852]
	TIME [epoch: 56.9 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23377705061859919		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.23377705061859919 | validation: 0.1896951912831517]
	TIME [epoch: 56.9 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23140421978522627		[learning rate: 0.0010256]
	Learning Rate: 0.00102556
	LOSS [training: 0.23140421978522627 | validation: 0.18774925935332715]
	TIME [epoch: 56.9 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22335481878004293		[learning rate: 0.0010215]
	Learning Rate: 0.00102148
	LOSS [training: 0.22335481878004293 | validation: 0.19006245684334003]
	TIME [epoch: 56.9 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23660636284424452		[learning rate: 0.0010174]
	Learning Rate: 0.00101742
	LOSS [training: 0.23660636284424452 | validation: 0.19418126805025088]
	TIME [epoch: 57 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22881246080169193		[learning rate: 0.0010134]
	Learning Rate: 0.00101337
	LOSS [training: 0.22881246080169193 | validation: 0.19003400136976856]
	TIME [epoch: 57 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22786149640675724		[learning rate: 0.0010093]
	Learning Rate: 0.00100934
	LOSS [training: 0.22786149640675724 | validation: 0.18504886960530456]
	TIME [epoch: 56.9 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23552823470450374		[learning rate: 0.0010053]
	Learning Rate: 0.00100533
	LOSS [training: 0.23552823470450374 | validation: 0.1857216966453294]
	TIME [epoch: 56.9 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22556800833270557		[learning rate: 0.0010013]
	Learning Rate: 0.00100133
	LOSS [training: 0.22556800833270557 | validation: 0.18870362767951407]
	TIME [epoch: 57 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22253960842162243		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.22253960842162243 | validation: 0.1893362202285525]
	TIME [epoch: 57 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2215333250084406		[learning rate: 0.00099338]
	Learning Rate: 0.00099338
	LOSS [training: 0.2215333250084406 | validation: 0.1884405031636765]
	TIME [epoch: 56.9 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23058636454517759		[learning rate: 0.00098943]
	Learning Rate: 0.000989429
	LOSS [training: 0.23058636454517759 | validation: 0.18510167247246656]
	TIME [epoch: 57 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22813487322887915		[learning rate: 0.00098549]
	Learning Rate: 0.000985494
	LOSS [training: 0.22813487322887915 | validation: 0.18809447815310149]
	TIME [epoch: 56.9 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22421658822996665		[learning rate: 0.00098157]
	Learning Rate: 0.000981574
	LOSS [training: 0.22421658822996665 | validation: 0.1934557227070489]
	TIME [epoch: 56.9 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2260291787235436		[learning rate: 0.00097767]
	Learning Rate: 0.00097767
	LOSS [training: 0.2260291787235436 | validation: 0.18825037120870322]
	TIME [epoch: 56.9 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23006320039903605		[learning rate: 0.00097378]
	Learning Rate: 0.000973782
	LOSS [training: 0.23006320039903605 | validation: 0.1915632438012]
	TIME [epoch: 56.9 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23017919217932592		[learning rate: 0.00096991]
	Learning Rate: 0.000969909
	LOSS [training: 0.23017919217932592 | validation: 0.19406419720221596]
	TIME [epoch: 56.9 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22592055401714553		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.22592055401714553 | validation: 0.18843019931838562]
	TIME [epoch: 56.9 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2282010464420624		[learning rate: 0.00096221]
	Learning Rate: 0.000962209
	LOSS [training: 0.2282010464420624 | validation: 0.18576927523397058]
	TIME [epoch: 56.9 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23139750170458429		[learning rate: 0.00095838]
	Learning Rate: 0.000958382
	LOSS [training: 0.23139750170458429 | validation: 0.18641144733605963]
	TIME [epoch: 56.9 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22406840705565376		[learning rate: 0.00095457]
	Learning Rate: 0.00095457
	LOSS [training: 0.22406840705565376 | validation: 0.19079570832890652]
	TIME [epoch: 56.9 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23222680676471075		[learning rate: 0.00095077]
	Learning Rate: 0.000950773
	LOSS [training: 0.23222680676471075 | validation: 0.19200818236674871]
	TIME [epoch: 57 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22246988422952935		[learning rate: 0.00094699]
	Learning Rate: 0.000946992
	LOSS [training: 0.22246988422952935 | validation: 0.19525307967867084]
	TIME [epoch: 56.9 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23077610687790903		[learning rate: 0.00094323]
	Learning Rate: 0.000943225
	LOSS [training: 0.23077610687790903 | validation: 0.19236544508649378]
	TIME [epoch: 57 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23008430035177913		[learning rate: 0.00093947]
	Learning Rate: 0.000939474
	LOSS [training: 0.23008430035177913 | validation: 0.19015363721508524]
	TIME [epoch: 56.9 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22872990266320434		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.22872990266320434 | validation: 0.18906637339947335]
	TIME [epoch: 56.9 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22481411485984454		[learning rate: 0.00093202]
	Learning Rate: 0.000932015
	LOSS [training: 0.22481411485984454 | validation: 0.19087512556437863]
	TIME [epoch: 56.9 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2255505397991058		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.2255505397991058 | validation: 0.18653762675471158]
	TIME [epoch: 56.9 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22975332245019242		[learning rate: 0.00092462]
	Learning Rate: 0.000924616
	LOSS [training: 0.22975332245019242 | validation: 0.18889902955919813]
	TIME [epoch: 56.9 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2295644891223917		[learning rate: 0.00092094]
	Learning Rate: 0.000920939
	LOSS [training: 0.2295644891223917 | validation: 0.1900919191854678]
	TIME [epoch: 56.9 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22982207848380445		[learning rate: 0.00091728]
	Learning Rate: 0.000917276
	LOSS [training: 0.22982207848380445 | validation: 0.18903913574422812]
	TIME [epoch: 56.9 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23304585344584913		[learning rate: 0.00091363]
	Learning Rate: 0.000913628
	LOSS [training: 0.23304585344584913 | validation: 0.19063223646357705]
	TIME [epoch: 56.9 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22428067144440936		[learning rate: 0.00090999]
	Learning Rate: 0.000909994
	LOSS [training: 0.22428067144440936 | validation: 0.1895136946328572]
	TIME [epoch: 56.9 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.224855802212612		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.224855802212612 | validation: 0.18605647442108306]
	TIME [epoch: 57 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22860357111852558		[learning rate: 0.00090277]
	Learning Rate: 0.00090277
	LOSS [training: 0.22860357111852558 | validation: 0.19017330226055035]
	TIME [epoch: 56.9 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22649703049253528		[learning rate: 0.00089918]
	Learning Rate: 0.000899179
	LOSS [training: 0.22649703049253528 | validation: 0.1889292650181456]
	TIME [epoch: 56.9 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22075543780401977		[learning rate: 0.0008956]
	Learning Rate: 0.000895603
	LOSS [training: 0.22075543780401977 | validation: 0.1920222271796974]
	TIME [epoch: 56.9 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22528609656812915		[learning rate: 0.00089204]
	Learning Rate: 0.000892041
	LOSS [training: 0.22528609656812915 | validation: 0.18795094541459065]
	TIME [epoch: 56.9 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22788134102298466		[learning rate: 0.00088849]
	Learning Rate: 0.000888493
	LOSS [training: 0.22788134102298466 | validation: 0.19072384604724668]
	TIME [epoch: 56.9 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22304369269541194		[learning rate: 0.00088496]
	Learning Rate: 0.000884959
	LOSS [training: 0.22304369269541194 | validation: 0.19058460564788643]
	TIME [epoch: 56.9 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22692664668641693		[learning rate: 0.00088144]
	Learning Rate: 0.000881439
	LOSS [training: 0.22692664668641693 | validation: 0.19030689583144617]
	TIME [epoch: 56.9 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.229122148644973		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.229122148644973 | validation: 0.18821432070882424]
	TIME [epoch: 56.9 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22504297045674568		[learning rate: 0.00087444]
	Learning Rate: 0.000874441
	LOSS [training: 0.22504297045674568 | validation: 0.1876169606755563]
	TIME [epoch: 56.9 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2229912411771537		[learning rate: 0.00087096]
	Learning Rate: 0.000870964
	LOSS [training: 0.2229912411771537 | validation: 0.19022043697296115]
	TIME [epoch: 56.9 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22352816842887252		[learning rate: 0.0008675]
	Learning Rate: 0.0008675
	LOSS [training: 0.22352816842887252 | validation: 0.18998950073609563]
	TIME [epoch: 56.9 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22262312805091936		[learning rate: 0.00086405]
	Learning Rate: 0.000864049
	LOSS [training: 0.22262312805091936 | validation: 0.18621544111394311]
	TIME [epoch: 56.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v12_20240716_142138/states/model_facs_v2_dec1b_2dpca_v12_659.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 21843.367 seconds.
