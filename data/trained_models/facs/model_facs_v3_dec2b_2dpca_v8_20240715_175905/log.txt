Args:
Namespace(name='model_facs_v3_dec2b_2dpca_v8', outdir='out/model_training/model_facs_v3_dec2b_2dpca_v8', training_data='data/training_data/facs_v3/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v3/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=400, ncells_sample=400, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[500, 1000, 1500], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.02, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 157983703

Training model...

Saving initial model state to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1510106545664325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1510106545664325 | validation: 1.219960749536555]
	TIME [epoch: 34.5 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6713898523693339		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6713898523693339 | validation: 0.808277326431899]
	TIME [epoch: 4.88 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5418605295615214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5418605295615214 | validation: 0.7434662211894988]
	TIME [epoch: 4.88 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5374192709559692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5374192709559692 | validation: 0.7251869239126457]
	TIME [epoch: 4.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5233115834575832		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5233115834575832 | validation: 0.9134007888844321]
	TIME [epoch: 4.88 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5710184772336605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5710184772336605 | validation: 0.6684628029002602]
	TIME [epoch: 4.88 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4864413631415885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4864413631415885 | validation: 0.6810754127795573]
	TIME [epoch: 4.88 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45530783927931895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45530783927931895 | validation: 0.7761232528247948]
	TIME [epoch: 4.86 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5345890851271083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5345890851271083 | validation: 0.7385748440135977]
	TIME [epoch: 4.87 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5431879956155019		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5431879956155019 | validation: 0.6659826990804432]
	TIME [epoch: 4.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.464676768325685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.464676768325685 | validation: 0.6503899312457484]
	TIME [epoch: 4.87 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5051912220953227		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5051912220953227 | validation: 0.7651714737430984]
	TIME [epoch: 4.87 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5094374531237511		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5094374531237511 | validation: 0.6598338045937396]
	TIME [epoch: 4.86 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4581141001259869		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4581141001259869 | validation: 0.6485596596843728]
	TIME [epoch: 4.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49347683832107675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49347683832107675 | validation: 0.6518645351190325]
	TIME [epoch: 4.87 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47057291003979645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47057291003979645 | validation: 0.7957490273164476]
	TIME [epoch: 4.87 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47050678301788035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47050678301788035 | validation: 0.6541947802973411]
	TIME [epoch: 4.88 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4518732169745306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4518732169745306 | validation: 0.616557876926763]
	TIME [epoch: 4.87 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44534506571112314		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44534506571112314 | validation: 0.6447830764026885]
	TIME [epoch: 4.87 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4483570964848601		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4483570964848601 | validation: 0.6326210454584197]
	TIME [epoch: 4.87 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41170180642075865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41170180642075865 | validation: 0.5525406430857482]
	TIME [epoch: 4.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3479510258754519		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3479510258754519 | validation: 0.7323469760704261]
	TIME [epoch: 4.9 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3617389413957418		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3617389413957418 | validation: 0.6441569492187029]
	TIME [epoch: 4.86 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44949475451992443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44949475451992443 | validation: 0.572115359665629]
	TIME [epoch: 4.86 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.344654177926511		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.344654177926511 | validation: 0.5330683491102256]
	TIME [epoch: 4.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31560384555775145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31560384555775145 | validation: 0.508399939611362]
	TIME [epoch: 4.87 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2896695303801336		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2896695303801336 | validation: 0.509716994601995]
	TIME [epoch: 4.87 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3202454568692151		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3202454568692151 | validation: 0.5907065230578525]
	TIME [epoch: 4.87 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35316083079337063		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35316083079337063 | validation: 0.5222265141846161]
	TIME [epoch: 4.85 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3041943424698601		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3041943424698601 | validation: 0.49876682696221314]
	TIME [epoch: 4.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.312992940896313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.312992940896313 | validation: 0.5582285246211364]
	TIME [epoch: 4.86 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3143473926528947		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3143473926528947 | validation: 0.5384416965357133]
	TIME [epoch: 4.86 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29913181389131016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29913181389131016 | validation: 0.4623143849943999]
	TIME [epoch: 4.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.284585184356791		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.284585184356791 | validation: 0.5418883266310789]
	TIME [epoch: 4.86 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3449333435237566		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3449333435237566 | validation: 0.6542247255434608]
	TIME [epoch: 4.86 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3113611378318573		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3113611378318573 | validation: 0.4911231492011888]
	TIME [epoch: 4.86 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2755947044214747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2755947044214747 | validation: 0.4960619943639872]
	TIME [epoch: 4.86 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2672763581191968		[learning rate: 0.0099882]
	Learning Rate: 0.0099882
	LOSS [training: 0.2672763581191968 | validation: 0.495697498389701]
	TIME [epoch: 4.86 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2803503429332261		[learning rate: 0.0099411]
	Learning Rate: 0.00994113
	LOSS [training: 0.2803503429332261 | validation: 0.48854106101455597]
	TIME [epoch: 4.86 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2934023559767832		[learning rate: 0.0098943]
	Learning Rate: 0.00989429
	LOSS [training: 0.2934023559767832 | validation: 0.4562974888832528]
	TIME [epoch: 4.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28317086611910647		[learning rate: 0.0098477]
	Learning Rate: 0.00984767
	LOSS [training: 0.28317086611910647 | validation: 0.4690676745606305]
	TIME [epoch: 4.87 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.293438761730109		[learning rate: 0.0098013]
	Learning Rate: 0.00980126
	LOSS [training: 0.293438761730109 | validation: 0.4623946473232957]
	TIME [epoch: 4.86 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2818982487553938		[learning rate: 0.0097551]
	Learning Rate: 0.00975508
	LOSS [training: 0.2818982487553938 | validation: 0.5528022641134988]
	TIME [epoch: 4.86 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3151144679782499		[learning rate: 0.0097091]
	Learning Rate: 0.00970911
	LOSS [training: 0.3151144679782499 | validation: 0.5039917284502875]
	TIME [epoch: 4.87 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2983306081397984		[learning rate: 0.0096634]
	Learning Rate: 0.00966336
	LOSS [training: 0.2983306081397984 | validation: 0.4292331532731116]
	TIME [epoch: 4.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23784236002659812		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.23784236002659812 | validation: 0.4815529757099764]
	TIME [epoch: 4.89 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2783426651064401		[learning rate: 0.0095725]
	Learning Rate: 0.00957251
	LOSS [training: 0.2783426651064401 | validation: 0.4529091936821817]
	TIME [epoch: 4.87 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23221684706127466		[learning rate: 0.0095274]
	Learning Rate: 0.0095274
	LOSS [training: 0.23221684706127466 | validation: 0.43170341208814855]
	TIME [epoch: 4.87 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23444163286309527		[learning rate: 0.0094825]
	Learning Rate: 0.0094825
	LOSS [training: 0.23444163286309527 | validation: 0.4746380235137453]
	TIME [epoch: 4.87 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2996190985398255		[learning rate: 0.0094378]
	Learning Rate: 0.00943782
	LOSS [training: 0.2996190985398255 | validation: 0.519036714384831]
	TIME [epoch: 4.87 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28264710619892064		[learning rate: 0.0093933]
	Learning Rate: 0.00939335
	LOSS [training: 0.28264710619892064 | validation: 0.44858655439661743]
	TIME [epoch: 4.87 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25303517107917434		[learning rate: 0.0093491]
	Learning Rate: 0.00934909
	LOSS [training: 0.25303517107917434 | validation: 0.4216451255618634]
	TIME [epoch: 4.87 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2191196637685397		[learning rate: 0.009305]
	Learning Rate: 0.00930503
	LOSS [training: 0.2191196637685397 | validation: 0.44670004885238507]
	TIME [epoch: 4.87 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24721360955687227		[learning rate: 0.0092612]
	Learning Rate: 0.00926119
	LOSS [training: 0.24721360955687227 | validation: 0.5144843077600714]
	TIME [epoch: 4.86 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2745275498771384		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.2745275498771384 | validation: 0.4173016339247936]
	TIME [epoch: 4.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24902847470388784		[learning rate: 0.0091741]
	Learning Rate: 0.00917411
	LOSS [training: 0.24902847470388784 | validation: 0.4406477734545886]
	TIME [epoch: 4.88 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24711103978833326		[learning rate: 0.0091309]
	Learning Rate: 0.00913088
	LOSS [training: 0.24711103978833326 | validation: 0.5738733607198994]
	TIME [epoch: 4.87 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30465415345129643		[learning rate: 0.0090879]
	Learning Rate: 0.00908786
	LOSS [training: 0.30465415345129643 | validation: 0.42793215093076675]
	TIME [epoch: 4.86 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24200977516928351		[learning rate: 0.009045]
	Learning Rate: 0.00904503
	LOSS [training: 0.24200977516928351 | validation: 0.41677904207206495]
	TIME [epoch: 4.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19513066458477665		[learning rate: 0.0090024]
	Learning Rate: 0.00900241
	LOSS [training: 0.19513066458477665 | validation: 0.5452785920684506]
	TIME [epoch: 4.87 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3032877470530609		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.3032877470530609 | validation: 0.4185012280192904]
	TIME [epoch: 4.86 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2285611790785672		[learning rate: 0.0089178]
	Learning Rate: 0.00891777
	LOSS [training: 0.2285611790785672 | validation: 0.4087268185305777]
	TIME [epoch: 4.87 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23856823233191116		[learning rate: 0.0088758]
	Learning Rate: 0.00887575
	LOSS [training: 0.23856823233191116 | validation: 0.42063864992778854]
	TIME [epoch: 4.87 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27095648588603505		[learning rate: 0.0088339]
	Learning Rate: 0.00883393
	LOSS [training: 0.27095648588603505 | validation: 0.39881801073567535]
	TIME [epoch: 4.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23804541053629064		[learning rate: 0.0087923]
	Learning Rate: 0.0087923
	LOSS [training: 0.23804541053629064 | validation: 0.4569956592582136]
	TIME [epoch: 4.87 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22068989312303436		[learning rate: 0.0087509]
	Learning Rate: 0.00875087
	LOSS [training: 0.22068989312303436 | validation: 0.4540686506205956]
	TIME [epoch: 4.88 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23486145455883392		[learning rate: 0.0087096]
	Learning Rate: 0.00870964
	LOSS [training: 0.23486145455883392 | validation: 0.41252350770544477]
	TIME [epoch: 4.86 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20955114957202498		[learning rate: 0.0086686]
	Learning Rate: 0.00866859
	LOSS [training: 0.20955114957202498 | validation: 0.39223858665880806]
	TIME [epoch: 4.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20352248094574446		[learning rate: 0.0086277]
	Learning Rate: 0.00862775
	LOSS [training: 0.20352248094574446 | validation: 0.5090395607993856]
	TIME [epoch: 4.86 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27506845674574754		[learning rate: 0.0085871]
	Learning Rate: 0.00858709
	LOSS [training: 0.27506845674574754 | validation: 0.378080044849974]
	TIME [epoch: 4.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19168014725436205		[learning rate: 0.0085466]
	Learning Rate: 0.00854663
	LOSS [training: 0.19168014725436205 | validation: 0.3752361730868749]
	TIME [epoch: 4.87 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22081547573203597		[learning rate: 0.0085064]
	Learning Rate: 0.00850636
	LOSS [training: 0.22081547573203597 | validation: 0.5067905703387561]
	TIME [epoch: 4.87 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24185736218588666		[learning rate: 0.0084663]
	Learning Rate: 0.00846627
	LOSS [training: 0.24185736218588666 | validation: 0.4466677971951312]
	TIME [epoch: 4.86 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22980628089127808		[learning rate: 0.0084264]
	Learning Rate: 0.00842638
	LOSS [training: 0.22980628089127808 | validation: 0.4252551207218506]
	TIME [epoch: 4.86 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22202934555841466		[learning rate: 0.0083867]
	Learning Rate: 0.00838667
	LOSS [training: 0.22202934555841466 | validation: 0.4136299488988694]
	TIME [epoch: 4.86 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2211279515667828		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.2211279515667828 | validation: 0.5539353263794689]
	TIME [epoch: 4.87 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24042937953359228		[learning rate: 0.0083078]
	Learning Rate: 0.00830782
	LOSS [training: 0.24042937953359228 | validation: 0.3699742107988925]
	TIME [epoch: 4.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20372969537357014		[learning rate: 0.0082687]
	Learning Rate: 0.00826867
	LOSS [training: 0.20372969537357014 | validation: 0.3892739406797773]
	TIME [epoch: 4.87 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21824198405094486		[learning rate: 0.0082297]
	Learning Rate: 0.00822971
	LOSS [training: 0.21824198405094486 | validation: 0.3704200069458967]
	TIME [epoch: 4.86 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24778104066295448		[learning rate: 0.0081909]
	Learning Rate: 0.00819093
	LOSS [training: 0.24778104066295448 | validation: 0.3845308683379957]
	TIME [epoch: 4.86 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22269962826326728		[learning rate: 0.0081523]
	Learning Rate: 0.00815233
	LOSS [training: 0.22269962826326728 | validation: 0.3883446815135306]
	TIME [epoch: 4.86 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18213360655126423		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.18213360655126423 | validation: 0.3565687409596197]
	TIME [epoch: 4.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16594703985447848		[learning rate: 0.0080757]
	Learning Rate: 0.00807569
	LOSS [training: 0.16594703985447848 | validation: 0.36007024036206736]
	TIME [epoch: 4.86 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22410204883834528		[learning rate: 0.0080376]
	Learning Rate: 0.00803763
	LOSS [training: 0.22410204883834528 | validation: 0.47911934545038654]
	TIME [epoch: 4.86 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19741832813868296		[learning rate: 0.0079998]
	Learning Rate: 0.00799976
	LOSS [training: 0.19741832813868296 | validation: 0.3822918754477047]
	TIME [epoch: 4.87 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21836947513860686		[learning rate: 0.0079621]
	Learning Rate: 0.00796206
	LOSS [training: 0.21836947513860686 | validation: 0.36550619899300424]
	TIME [epoch: 4.87 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25160738002096983		[learning rate: 0.0079245]
	Learning Rate: 0.00792455
	LOSS [training: 0.25160738002096983 | validation: 0.3814275006777756]
	TIME [epoch: 4.86 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18393591043446136		[learning rate: 0.0078872]
	Learning Rate: 0.0078872
	LOSS [training: 0.18393591043446136 | validation: 0.3578631165187096]
	TIME [epoch: 4.86 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19081090434155296		[learning rate: 0.00785]
	Learning Rate: 0.00785004
	LOSS [training: 0.19081090434155296 | validation: 0.39449179425038616]
	TIME [epoch: 4.86 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23863711900555945		[learning rate: 0.007813]
	Learning Rate: 0.00781305
	LOSS [training: 0.23863711900555945 | validation: 0.3808477972813812]
	TIME [epoch: 4.86 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25271005501668065		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.25271005501668065 | validation: 0.41859330110029475]
	TIME [epoch: 4.86 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21185508122609123		[learning rate: 0.0077396]
	Learning Rate: 0.00773959
	LOSS [training: 0.21185508122609123 | validation: 0.41945519829965366]
	TIME [epoch: 4.86 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22365712962036463		[learning rate: 0.0077031]
	Learning Rate: 0.00770312
	LOSS [training: 0.22365712962036463 | validation: 0.3569735736626649]
	TIME [epoch: 4.86 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20235977120349102		[learning rate: 0.0076668]
	Learning Rate: 0.00766682
	LOSS [training: 0.20235977120349102 | validation: 0.4233614417112158]
	TIME [epoch: 4.89 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21042002488305386		[learning rate: 0.0076307]
	Learning Rate: 0.0076307
	LOSS [training: 0.21042002488305386 | validation: 0.3425296341573371]
	TIME [epoch: 4.9 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17749637391236758		[learning rate: 0.0075947]
	Learning Rate: 0.00759474
	LOSS [training: 0.17749637391236758 | validation: 0.3905457739726004]
	TIME [epoch: 4.87 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18676302300876152		[learning rate: 0.007559]
	Learning Rate: 0.00755895
	LOSS [training: 0.18676302300876152 | validation: 0.40707728967243756]
	TIME [epoch: 4.87 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2072252765151234		[learning rate: 0.0075233]
	Learning Rate: 0.00752333
	LOSS [training: 0.2072252765151234 | validation: 0.5337259137251489]
	TIME [epoch: 4.87 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22752149538438426		[learning rate: 0.0074879]
	Learning Rate: 0.00748788
	LOSS [training: 0.22752149538438426 | validation: 0.42299008973182545]
	TIME [epoch: 4.86 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1639592024844744		[learning rate: 0.0074526]
	Learning Rate: 0.0074526
	LOSS [training: 0.1639592024844744 | validation: 0.3638769294695655]
	TIME [epoch: 4.86 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19046552351155774		[learning rate: 0.0074175]
	Learning Rate: 0.00741748
	LOSS [training: 0.19046552351155774 | validation: 0.4007220869436176]
	TIME [epoch: 4.87 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24279976237020925		[learning rate: 0.0073825]
	Learning Rate: 0.00738253
	LOSS [training: 0.24279976237020925 | validation: 0.3850143331231438]
	TIME [epoch: 4.86 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1832087801230164		[learning rate: 0.0073477]
	Learning Rate: 0.00734774
	LOSS [training: 0.1832087801230164 | validation: 0.3472458812406015]
	TIME [epoch: 4.86 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1960791611863233		[learning rate: 0.0073131]
	Learning Rate: 0.00731312
	LOSS [training: 0.1960791611863233 | validation: 0.3745805131518263]
	TIME [epoch: 4.86 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17321313721718992		[learning rate: 0.0072787]
	Learning Rate: 0.00727866
	LOSS [training: 0.17321313721718992 | validation: 0.3581137971636167]
	TIME [epoch: 4.87 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1718935411401134		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.1718935411401134 | validation: 0.5325540390978483]
	TIME [epoch: 4.87 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2347300749265575		[learning rate: 0.0072102]
	Learning Rate: 0.00721022
	LOSS [training: 0.2347300749265575 | validation: 0.3704797215148756]
	TIME [epoch: 4.86 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20428389025235394		[learning rate: 0.0071762]
	Learning Rate: 0.00717625
	LOSS [training: 0.20428389025235394 | validation: 0.3936807519392099]
	TIME [epoch: 4.86 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18401218779114906		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.18401218779114906 | validation: 0.39510257302227186]
	TIME [epoch: 4.86 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22372536343354102		[learning rate: 0.0071088]
	Learning Rate: 0.00710878
	LOSS [training: 0.22372536343354102 | validation: 0.3609217589984872]
	TIME [epoch: 4.86 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1866232685584185		[learning rate: 0.0070753]
	Learning Rate: 0.00707528
	LOSS [training: 0.1866232685584185 | validation: 0.3376072745318272]
	TIME [epoch: 4.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_111.pth
	Model improved!!!
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18816249902389592		[learning rate: 0.0070419]
	Learning Rate: 0.00704194
	LOSS [training: 0.18816249902389592 | validation: 0.37001824557374247]
	TIME [epoch: 4.86 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1588276399006832		[learning rate: 0.0070088]
	Learning Rate: 0.00700876
	LOSS [training: 0.1588276399006832 | validation: 0.34611355791571286]
	TIME [epoch: 4.86 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18371229935676844		[learning rate: 0.0069757]
	Learning Rate: 0.00697573
	LOSS [training: 0.18371229935676844 | validation: 0.3568009807888642]
	TIME [epoch: 4.86 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16831849475153737		[learning rate: 0.0069429]
	Learning Rate: 0.00694286
	LOSS [training: 0.16831849475153737 | validation: 0.3563679923569314]
	TIME [epoch: 4.87 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1625887948023978		[learning rate: 0.0069101]
	Learning Rate: 0.00691014
	LOSS [training: 0.1625887948023978 | validation: 0.4726355889901705]
	TIME [epoch: 4.86 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20413312590537427		[learning rate: 0.0068776]
	Learning Rate: 0.00687758
	LOSS [training: 0.20413312590537427 | validation: 0.5025160962642885]
	TIME [epoch: 4.86 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18748590177569907		[learning rate: 0.0068452]
	Learning Rate: 0.00684518
	LOSS [training: 0.18748590177569907 | validation: 0.4564899435574575]
	TIME [epoch: 4.87 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20133465837324865		[learning rate: 0.0068129]
	Learning Rate: 0.00681292
	LOSS [training: 0.20133465837324865 | validation: 0.5612107834545977]
	TIME [epoch: 4.86 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21197062423009336		[learning rate: 0.0067808]
	Learning Rate: 0.00678082
	LOSS [training: 0.21197062423009336 | validation: 0.38946835058264045]
	TIME [epoch: 4.86 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1569263409625018		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.1569263409625018 | validation: 0.33124114219565737]
	TIME [epoch: 4.85 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16390187137860873		[learning rate: 0.0067171]
	Learning Rate: 0.00671706
	LOSS [training: 0.16390187137860873 | validation: 0.43077896148565414]
	TIME [epoch: 4.86 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17087260585713204		[learning rate: 0.0066854]
	Learning Rate: 0.00668541
	LOSS [training: 0.17087260585713204 | validation: 0.5003791263141842]
	TIME [epoch: 4.86 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1844522455202076		[learning rate: 0.0066539]
	Learning Rate: 0.00665391
	LOSS [training: 0.1844522455202076 | validation: 0.3399431376201223]
	TIME [epoch: 4.88 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18171643589640601		[learning rate: 0.0066226]
	Learning Rate: 0.00662256
	LOSS [training: 0.18171643589640601 | validation: 0.37487758987814984]
	TIME [epoch: 4.87 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19227533376548933		[learning rate: 0.0065913]
	Learning Rate: 0.00659135
	LOSS [training: 0.19227533376548933 | validation: 0.3691540648958831]
	TIME [epoch: 4.87 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20152237935341574		[learning rate: 0.0065603]
	Learning Rate: 0.00656029
	LOSS [training: 0.20152237935341574 | validation: 0.341521280293869]
	TIME [epoch: 4.9 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17137237199683011		[learning rate: 0.0065294]
	Learning Rate: 0.00652938
	LOSS [training: 0.17137237199683011 | validation: 0.3320199224161427]
	TIME [epoch: 4.87 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1441107643565781		[learning rate: 0.0064986]
	Learning Rate: 0.00649861
	LOSS [training: 0.1441107643565781 | validation: 0.4254973797828564]
	TIME [epoch: 4.88 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22100806119229646		[learning rate: 0.006468]
	Learning Rate: 0.00646799
	LOSS [training: 0.22100806119229646 | validation: 0.3403875184384248]
	TIME [epoch: 4.86 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16918956003823124		[learning rate: 0.0064375]
	Learning Rate: 0.00643751
	LOSS [training: 0.16918956003823124 | validation: 0.3441953111355124]
	TIME [epoch: 5.15 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18645814489095158		[learning rate: 0.0064072]
	Learning Rate: 0.00640718
	LOSS [training: 0.18645814489095158 | validation: 0.40273013599415924]
	TIME [epoch: 4.9 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1786953410484981		[learning rate: 0.006377]
	Learning Rate: 0.00637698
	LOSS [training: 0.1786953410484981 | validation: 0.3278514815232194]
	TIME [epoch: 4.89 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_133.pth
	Model improved!!!
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1838341602253429		[learning rate: 0.0063469]
	Learning Rate: 0.00634694
	LOSS [training: 0.1838341602253429 | validation: 0.37005523038661214]
	TIME [epoch: 4.87 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1940638160668196		[learning rate: 0.006317]
	Learning Rate: 0.00631703
	LOSS [training: 0.1940638160668196 | validation: 0.353465965673521]
	TIME [epoch: 4.88 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18828188436324841		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.18828188436324841 | validation: 0.3299557992328771]
	TIME [epoch: 4.9 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20058325977287328		[learning rate: 0.0062576]
	Learning Rate: 0.00625764
	LOSS [training: 0.20058325977287328 | validation: 0.34332515005248837]
	TIME [epoch: 4.88 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17943987815041557		[learning rate: 0.0062281]
	Learning Rate: 0.00622815
	LOSS [training: 0.17943987815041557 | validation: 0.32314934881521407]
	TIME [epoch: 4.87 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_138.pth
	Model improved!!!
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15584173521045783		[learning rate: 0.0061988]
	Learning Rate: 0.0061988
	LOSS [training: 0.15584173521045783 | validation: 0.4427741071781098]
	TIME [epoch: 4.87 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20253586525176545		[learning rate: 0.0061696]
	Learning Rate: 0.00616959
	LOSS [training: 0.20253586525176545 | validation: 0.32545450599173537]
	TIME [epoch: 4.86 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17444969598192583		[learning rate: 0.0061405]
	Learning Rate: 0.00614052
	LOSS [training: 0.17444969598192583 | validation: 0.5279692555620704]
	TIME [epoch: 4.88 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17685412741979373		[learning rate: 0.0061116]
	Learning Rate: 0.00611158
	LOSS [training: 0.17685412741979373 | validation: 0.33229900402873175]
	TIME [epoch: 4.86 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15341626643384812		[learning rate: 0.0060828]
	Learning Rate: 0.00608279
	LOSS [training: 0.15341626643384812 | validation: 0.3230315953391909]
	TIME [epoch: 4.87 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_143.pth
	Model improved!!!
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1617867716397203		[learning rate: 0.0060541]
	Learning Rate: 0.00605412
	LOSS [training: 0.1617867716397203 | validation: 0.3288681395982558]
	TIME [epoch: 4.87 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19730166385658726		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 0.19730166385658726 | validation: 0.4456995008682595]
	TIME [epoch: 4.88 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18011200306045497		[learning rate: 0.0059972]
	Learning Rate: 0.0059972
	LOSS [training: 0.18011200306045497 | validation: 0.35569559886891755]
	TIME [epoch: 4.87 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16567109893907628		[learning rate: 0.0059689]
	Learning Rate: 0.00596894
	LOSS [training: 0.16567109893907628 | validation: 0.3195791218451431]
	TIME [epoch: 4.87 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_147.pth
	Model improved!!!
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1500057673084659		[learning rate: 0.0059408]
	Learning Rate: 0.00594082
	LOSS [training: 0.1500057673084659 | validation: 0.30939985102573897]
	TIME [epoch: 4.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_148.pth
	Model improved!!!
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19928956286724203		[learning rate: 0.0059128]
	Learning Rate: 0.00591282
	LOSS [training: 0.19928956286724203 | validation: 0.37689975693966943]
	TIME [epoch: 4.87 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17881243768051555		[learning rate: 0.005885]
	Learning Rate: 0.00588496
	LOSS [training: 0.17881243768051555 | validation: 0.4279918825073027]
	TIME [epoch: 4.86 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16650907483454352		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.16650907483454352 | validation: 0.3737169561124299]
	TIME [epoch: 4.87 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16705212009143092		[learning rate: 0.0058296]
	Learning Rate: 0.00582963
	LOSS [training: 0.16705212009143092 | validation: 0.4061077195331327]
	TIME [epoch: 4.86 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16073356948593875		[learning rate: 0.0058022]
	Learning Rate: 0.00580216
	LOSS [training: 0.16073356948593875 | validation: 0.31079965230586937]
	TIME [epoch: 4.87 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16145142626044068		[learning rate: 0.0057748]
	Learning Rate: 0.00577482
	LOSS [training: 0.16145142626044068 | validation: 0.3852879312673346]
	TIME [epoch: 4.86 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1598377184159967		[learning rate: 0.0057476]
	Learning Rate: 0.00574761
	LOSS [training: 0.1598377184159967 | validation: 0.35293960797536816]
	TIME [epoch: 4.88 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1590519452695028		[learning rate: 0.0057205]
	Learning Rate: 0.00572052
	LOSS [training: 0.1590519452695028 | validation: 0.35881570636135535]
	TIME [epoch: 4.87 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19032515640847936		[learning rate: 0.0056936]
	Learning Rate: 0.00569357
	LOSS [training: 0.19032515640847936 | validation: 0.41902195965689204]
	TIME [epoch: 4.87 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19196099096646507		[learning rate: 0.0056667]
	Learning Rate: 0.00566674
	LOSS [training: 0.19196099096646507 | validation: 0.3373261216613144]
	TIME [epoch: 4.86 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16417295337188798		[learning rate: 0.00564]
	Learning Rate: 0.00564004
	LOSS [training: 0.16417295337188798 | validation: 0.3503021385675257]
	TIME [epoch: 4.86 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19446726954131083		[learning rate: 0.0056135]
	Learning Rate: 0.00561346
	LOSS [training: 0.19446726954131083 | validation: 0.4387704621972842]
	TIME [epoch: 4.87 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20077184392830533		[learning rate: 0.005587]
	Learning Rate: 0.00558701
	LOSS [training: 0.20077184392830533 | validation: 0.34723314191639826]
	TIME [epoch: 4.86 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18160513532731765		[learning rate: 0.0055607]
	Learning Rate: 0.00556068
	LOSS [training: 0.18160513532731765 | validation: 0.47138630500129935]
	TIME [epoch: 4.86 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16528320787577483		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.16528320787577483 | validation: 0.34702747411852125]
	TIME [epoch: 4.87 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1487202811291192		[learning rate: 0.0055084]
	Learning Rate: 0.0055084
	LOSS [training: 0.1487202811291192 | validation: 0.35604838910684383]
	TIME [epoch: 4.87 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17642405465051908		[learning rate: 0.0054824]
	Learning Rate: 0.00548245
	LOSS [training: 0.17642405465051908 | validation: 0.31888289969775463]
	TIME [epoch: 4.87 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16470803740649126		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.16470803740649126 | validation: 0.3283588116635934]
	TIME [epoch: 4.86 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17538390696610115		[learning rate: 0.0054309]
	Learning Rate: 0.0054309
	LOSS [training: 0.17538390696610115 | validation: 0.32059375914947075]
	TIME [epoch: 4.87 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14203948002424507		[learning rate: 0.0054053]
	Learning Rate: 0.00540531
	LOSS [training: 0.14203948002424507 | validation: 0.4091740358414069]
	TIME [epoch: 4.87 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16659395154132825		[learning rate: 0.0053798]
	Learning Rate: 0.00537984
	LOSS [training: 0.16659395154132825 | validation: 0.2919519928494157]
	TIME [epoch: 4.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_169.pth
	Model improved!!!
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1772013010214745		[learning rate: 0.0053545]
	Learning Rate: 0.00535449
	LOSS [training: 0.1772013010214745 | validation: 0.2999304960835134]
	TIME [epoch: 4.86 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17732136445051128		[learning rate: 0.0053293]
	Learning Rate: 0.00532926
	LOSS [training: 0.17732136445051128 | validation: 0.33487103515349437]
	TIME [epoch: 4.86 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16530495956819435		[learning rate: 0.0053041]
	Learning Rate: 0.00530415
	LOSS [training: 0.16530495956819435 | validation: 0.40153238571572103]
	TIME [epoch: 4.86 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16244772308967786		[learning rate: 0.0052792]
	Learning Rate: 0.00527915
	LOSS [training: 0.16244772308967786 | validation: 0.3252826732712261]
	TIME [epoch: 4.86 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16311305037394513		[learning rate: 0.0052543]
	Learning Rate: 0.00525428
	LOSS [training: 0.16311305037394513 | validation: 0.31332032953645844]
	TIME [epoch: 4.87 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1491565840581411		[learning rate: 0.0052295]
	Learning Rate: 0.00522952
	LOSS [training: 0.1491565840581411 | validation: 0.37335463556477]
	TIME [epoch: 4.88 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17328210181664216		[learning rate: 0.0052049]
	Learning Rate: 0.00520487
	LOSS [training: 0.17328210181664216 | validation: 0.334477066318837]
	TIME [epoch: 4.86 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13776436943509632		[learning rate: 0.0051803]
	Learning Rate: 0.00518035
	LOSS [training: 0.13776436943509632 | validation: 0.4079379208662649]
	TIME [epoch: 4.87 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17710134943421849		[learning rate: 0.0051559]
	Learning Rate: 0.00515594
	LOSS [training: 0.17710134943421849 | validation: 0.40404390588810973]
	TIME [epoch: 4.86 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22369401549623694		[learning rate: 0.0051316]
	Learning Rate: 0.00513164
	LOSS [training: 0.22369401549623694 | validation: 0.3718367544854499]
	TIME [epoch: 4.87 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1675783656836233		[learning rate: 0.0051075]
	Learning Rate: 0.00510746
	LOSS [training: 0.1675783656836233 | validation: 0.4079825793111791]
	TIME [epoch: 4.87 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15640229508024533		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.15640229508024533 | validation: 0.4351451985952443]
	TIME [epoch: 4.87 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16939640278897694		[learning rate: 0.0050594]
	Learning Rate: 0.00505944
	LOSS [training: 0.16939640278897694 | validation: 0.31806607360391725]
	TIME [epoch: 4.87 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.170736515246722		[learning rate: 0.0050356]
	Learning Rate: 0.0050356
	LOSS [training: 0.170736515246722 | validation: 0.31123001453787763]
	TIME [epoch: 4.86 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15705186861858342		[learning rate: 0.0050119]
	Learning Rate: 0.00501187
	LOSS [training: 0.15705186861858342 | validation: 0.34927180086776866]
	TIME [epoch: 4.87 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16142431605958038		[learning rate: 0.0049883]
	Learning Rate: 0.00498826
	LOSS [training: 0.16142431605958038 | validation: 0.38600795640634405]
	TIME [epoch: 4.87 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15678078878565774		[learning rate: 0.0049648]
	Learning Rate: 0.00496475
	LOSS [training: 0.15678078878565774 | validation: 0.3051799337216756]
	TIME [epoch: 4.86 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15345616678458643		[learning rate: 0.0049414]
	Learning Rate: 0.00494136
	LOSS [training: 0.15345616678458643 | validation: 0.35411721023548054]
	TIME [epoch: 4.87 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1487465829434838		[learning rate: 0.0049181]
	Learning Rate: 0.00491807
	LOSS [training: 0.1487465829434838 | validation: 0.3607556408098571]
	TIME [epoch: 4.86 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14042492872488194		[learning rate: 0.0048949]
	Learning Rate: 0.0048949
	LOSS [training: 0.14042492872488194 | validation: 0.34532525864633856]
	TIME [epoch: 4.87 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1618030213393463		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.1618030213393463 | validation: 0.3192763654691813]
	TIME [epoch: 4.86 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1381772406861709		[learning rate: 0.0048489]
	Learning Rate: 0.00484888
	LOSS [training: 0.1381772406861709 | validation: 0.44547058990969196]
	TIME [epoch: 4.87 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17463273799481804		[learning rate: 0.004826]
	Learning Rate: 0.00482603
	LOSS [training: 0.17463273799481804 | validation: 0.35499901679450857]
	TIME [epoch: 4.86 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16379109104004308		[learning rate: 0.0048033]
	Learning Rate: 0.00480329
	LOSS [training: 0.16379109104004308 | validation: 0.38883675074958257]
	TIME [epoch: 4.88 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1543126702492038		[learning rate: 0.0047807]
	Learning Rate: 0.00478065
	LOSS [training: 0.1543126702492038 | validation: 0.3565258740115491]
	TIME [epoch: 4.86 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16526177900235775		[learning rate: 0.0047581]
	Learning Rate: 0.00475813
	LOSS [training: 0.16526177900235775 | validation: 0.39927817155839923]
	TIME [epoch: 4.91 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18537577080991458		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.18537577080991458 | validation: 0.4169876097000477]
	TIME [epoch: 4.89 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15129278158244966		[learning rate: 0.0047134]
	Learning Rate: 0.00471339
	LOSS [training: 0.15129278158244966 | validation: 0.32758476418414484]
	TIME [epoch: 4.88 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16856444066136947		[learning rate: 0.0046912]
	Learning Rate: 0.00469118
	LOSS [training: 0.16856444066136947 | validation: 0.3184004793490002]
	TIME [epoch: 4.87 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1679538962453314		[learning rate: 0.0046691]
	Learning Rate: 0.00466907
	LOSS [training: 0.1679538962453314 | validation: 0.31109656195911684]
	TIME [epoch: 4.9 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1617206731387861		[learning rate: 0.0046471]
	Learning Rate: 0.00464707
	LOSS [training: 0.1617206731387861 | validation: 0.29922678489141064]
	TIME [epoch: 4.89 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1466180420220642		[learning rate: 0.0046252]
	Learning Rate: 0.00462518
	LOSS [training: 0.1466180420220642 | validation: 0.32147626907391563]
	TIME [epoch: 4.87 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15206947985030317		[learning rate: 0.0046034]
	Learning Rate: 0.00460338
	LOSS [training: 0.15206947985030317 | validation: 0.3079624016979612]
	TIME [epoch: 4.87 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16017074209425242		[learning rate: 0.0045817]
	Learning Rate: 0.00458169
	LOSS [training: 0.16017074209425242 | validation: 0.2988265826482871]
	TIME [epoch: 4.9 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17246289426047273		[learning rate: 0.0045601]
	Learning Rate: 0.0045601
	LOSS [training: 0.17246289426047273 | validation: 0.33618373354900166]
	TIME [epoch: 4.89 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17974726617216874		[learning rate: 0.0045386]
	Learning Rate: 0.00453861
	LOSS [training: 0.17974726617216874 | validation: 0.30929483603666014]
	TIME [epoch: 4.89 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.166735261728775		[learning rate: 0.0045172]
	Learning Rate: 0.00451723
	LOSS [training: 0.166735261728775 | validation: 0.32798586842846045]
	TIME [epoch: 4.88 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1598577729801287		[learning rate: 0.0044959]
	Learning Rate: 0.00449594
	LOSS [training: 0.1598577729801287 | validation: 0.35290240856017263]
	TIME [epoch: 4.86 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15166559063578872		[learning rate: 0.0044748]
	Learning Rate: 0.00447475
	LOSS [training: 0.15166559063578872 | validation: 0.318226593525949]
	TIME [epoch: 4.89 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16738562402653256		[learning rate: 0.0044537]
	Learning Rate: 0.00445367
	LOSS [training: 0.16738562402653256 | validation: 0.3773251466534806]
	TIME [epoch: 4.87 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16815801725486146		[learning rate: 0.0044327]
	Learning Rate: 0.00443268
	LOSS [training: 0.16815801725486146 | validation: 0.3325787957422816]
	TIME [epoch: 4.87 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1313818909362886		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.1313818909362886 | validation: 0.29696615043710084]
	TIME [epoch: 4.87 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15710484035298045		[learning rate: 0.004391]
	Learning Rate: 0.00439101
	LOSS [training: 0.15710484035298045 | validation: 0.33552625194499514]
	TIME [epoch: 4.9 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1751558962256973		[learning rate: 0.0043703]
	Learning Rate: 0.00437032
	LOSS [training: 0.1751558962256973 | validation: 0.31941167579910207]
	TIME [epoch: 4.86 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16346173070864073		[learning rate: 0.0043497]
	Learning Rate: 0.00434972
	LOSS [training: 0.16346173070864073 | validation: 0.2968714445435482]
	TIME [epoch: 4.88 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17265291230049018		[learning rate: 0.0043292]
	Learning Rate: 0.00432923
	LOSS [training: 0.17265291230049018 | validation: 0.34409285556948827]
	TIME [epoch: 4.87 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12754907540247454		[learning rate: 0.0043088]
	Learning Rate: 0.00430883
	LOSS [training: 0.12754907540247454 | validation: 0.32044955244014284]
	TIME [epoch: 4.87 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14914803441677554		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.14914803441677554 | validation: 0.3347750311577389]
	TIME [epoch: 4.9 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17959211381631052		[learning rate: 0.0042683]
	Learning Rate: 0.00426831
	LOSS [training: 0.17959211381631052 | validation: 0.3054573383962783]
	TIME [epoch: 4.89 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15105957585700758		[learning rate: 0.0042482]
	Learning Rate: 0.0042482
	LOSS [training: 0.15105957585700758 | validation: 0.33045641779831364]
	TIME [epoch: 4.87 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16901976546253528		[learning rate: 0.0042282]
	Learning Rate: 0.00422818
	LOSS [training: 0.16901976546253528 | validation: 0.327525336575415]
	TIME [epoch: 4.87 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15689254610905684		[learning rate: 0.0042083]
	Learning Rate: 0.00420826
	LOSS [training: 0.15689254610905684 | validation: 0.29499862929765164]
	TIME [epoch: 4.88 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1562479852297164		[learning rate: 0.0041884]
	Learning Rate: 0.00418843
	LOSS [training: 0.1562479852297164 | validation: 0.3040828036407233]
	TIME [epoch: 4.87 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14902869960325055		[learning rate: 0.0041687]
	Learning Rate: 0.00416869
	LOSS [training: 0.14902869960325055 | validation: 0.32456924550631205]
	TIME [epoch: 4.88 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16489662419324666		[learning rate: 0.0041491]
	Learning Rate: 0.00414905
	LOSS [training: 0.16489662419324666 | validation: 0.46730726680336043]
	TIME [epoch: 4.87 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17661125940439876		[learning rate: 0.0041295]
	Learning Rate: 0.0041295
	LOSS [training: 0.17661125940439876 | validation: 0.3761194918419263]
	TIME [epoch: 4.87 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15376204147154382		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.15376204147154382 | validation: 0.32949291220052623]
	TIME [epoch: 4.9 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13989963515622758		[learning rate: 0.0040907]
	Learning Rate: 0.00409067
	LOSS [training: 0.13989963515622758 | validation: 0.3000234612832508]
	TIME [epoch: 4.86 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15011926184280622		[learning rate: 0.0040714]
	Learning Rate: 0.0040714
	LOSS [training: 0.15011926184280622 | validation: 0.3297011297058598]
	TIME [epoch: 4.86 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16887036667711103		[learning rate: 0.0040522]
	Learning Rate: 0.00405221
	LOSS [training: 0.16887036667711103 | validation: 0.29049623535724167]
	TIME [epoch: 4.87 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_229.pth
	Model improved!!!
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15434664592920827		[learning rate: 0.0040331]
	Learning Rate: 0.00403312
	LOSS [training: 0.15434664592920827 | validation: 0.3032185829509896]
	TIME [epoch: 4.88 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15797178444888488		[learning rate: 0.0040141]
	Learning Rate: 0.00401411
	LOSS [training: 0.15797178444888488 | validation: 0.28944107061828667]
	TIME [epoch: 4.89 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_231.pth
	Model improved!!!
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15957426930892626		[learning rate: 0.0039952]
	Learning Rate: 0.0039952
	LOSS [training: 0.15957426930892626 | validation: 0.322794069725255]
	TIME [epoch: 4.87 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16309771270732382		[learning rate: 0.0039764]
	Learning Rate: 0.00397637
	LOSS [training: 0.16309771270732382 | validation: 0.3309961312697345]
	TIME [epoch: 4.86 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14281028156734463		[learning rate: 0.0039576]
	Learning Rate: 0.00395764
	LOSS [training: 0.14281028156734463 | validation: 0.4503012514755979]
	TIME [epoch: 4.87 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17827374109355695		[learning rate: 0.003939]
	Learning Rate: 0.00393899
	LOSS [training: 0.17827374109355695 | validation: 0.29667292207013757]
	TIME [epoch: 4.88 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15710418744015833		[learning rate: 0.0039204]
	Learning Rate: 0.00392043
	LOSS [training: 0.15710418744015833 | validation: 0.36049494156550704]
	TIME [epoch: 4.88 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13958163517419606		[learning rate: 0.003902]
	Learning Rate: 0.00390195
	LOSS [training: 0.13958163517419606 | validation: 0.30446325007332753]
	TIME [epoch: 4.87 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1561194992618154		[learning rate: 0.0038836]
	Learning Rate: 0.00388357
	LOSS [training: 0.1561194992618154 | validation: 0.31398860128657924]
	TIME [epoch: 4.89 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1638265464167387		[learning rate: 0.0038653]
	Learning Rate: 0.00386527
	LOSS [training: 0.1638265464167387 | validation: 0.33387055417012684]
	TIME [epoch: 4.88 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1536680058729716		[learning rate: 0.0038471]
	Learning Rate: 0.00384705
	LOSS [training: 0.1536680058729716 | validation: 0.2837090622959897]
	TIME [epoch: 4.87 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_240.pth
	Model improved!!!
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15754677751646917		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.15754677751646917 | validation: 0.3903542421768837]
	TIME [epoch: 4.87 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16070559991785904		[learning rate: 0.0038109]
	Learning Rate: 0.00381088
	LOSS [training: 0.16070559991785904 | validation: 0.3313594793977502]
	TIME [epoch: 4.86 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1567253141457774		[learning rate: 0.0037929]
	Learning Rate: 0.00379293
	LOSS [training: 0.1567253141457774 | validation: 0.33075542080696535]
	TIME [epoch: 4.86 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15998275476299595		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.15998275476299595 | validation: 0.2867812693579661]
	TIME [epoch: 4.87 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13703011810276033		[learning rate: 0.0037573]
	Learning Rate: 0.00375726
	LOSS [training: 0.13703011810276033 | validation: 0.32521427468055986]
	TIME [epoch: 4.87 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13950249138747567		[learning rate: 0.0037396]
	Learning Rate: 0.00373956
	LOSS [training: 0.13950249138747567 | validation: 0.3151737772849999]
	TIME [epoch: 4.87 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14014410369180696		[learning rate: 0.0037219]
	Learning Rate: 0.00372194
	LOSS [training: 0.14014410369180696 | validation: 0.34554961134583156]
	TIME [epoch: 4.86 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13241040866505058		[learning rate: 0.0037044]
	Learning Rate: 0.0037044
	LOSS [training: 0.13241040866505058 | validation: 0.38761839501399425]
	TIME [epoch: 4.88 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16702101061325592		[learning rate: 0.0036869]
	Learning Rate: 0.00368695
	LOSS [training: 0.16702101061325592 | validation: 0.3518048638946857]
	TIME [epoch: 4.87 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17580118820042923		[learning rate: 0.0036696]
	Learning Rate: 0.00366957
	LOSS [training: 0.17580118820042923 | validation: 0.3401580934447443]
	TIME [epoch: 4.86 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15284709001600588		[learning rate: 0.0036523]
	Learning Rate: 0.00365228
	LOSS [training: 0.15284709001600588 | validation: 0.2938147741351381]
	TIME [epoch: 4.89 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14720161468592569		[learning rate: 0.0036351]
	Learning Rate: 0.00363507
	LOSS [training: 0.14720161468592569 | validation: 0.32808834255566965]
	TIME [epoch: 4.87 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14427182290581908		[learning rate: 0.0036179]
	Learning Rate: 0.00361794
	LOSS [training: 0.14427182290581908 | validation: 0.364697253086393]
	TIME [epoch: 4.87 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14599661147434026		[learning rate: 0.0036009]
	Learning Rate: 0.00360089
	LOSS [training: 0.14599661147434026 | validation: 0.34993704722036506]
	TIME [epoch: 4.87 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.141597972656434		[learning rate: 0.0035839]
	Learning Rate: 0.00358393
	LOSS [training: 0.141597972656434 | validation: 0.3133085164473828]
	TIME [epoch: 4.87 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1530293536094816		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.1530293536094816 | validation: 0.33690402721932344]
	TIME [epoch: 4.87 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14973335371355287		[learning rate: 0.0035502]
	Learning Rate: 0.00355023
	LOSS [training: 0.14973335371355287 | validation: 0.30979408155384]
	TIME [epoch: 4.88 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14529519818457026		[learning rate: 0.0035335]
	Learning Rate: 0.0035335
	LOSS [training: 0.14529519818457026 | validation: 0.2984765465961611]
	TIME [epoch: 4.87 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13187098437728348		[learning rate: 0.0035168]
	Learning Rate: 0.00351685
	LOSS [training: 0.13187098437728348 | validation: 0.31528881229654526]
	TIME [epoch: 4.91 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1577675446439779		[learning rate: 0.0035003]
	Learning Rate: 0.00350028
	LOSS [training: 0.1577675446439779 | validation: 0.3029474788750365]
	TIME [epoch: 4.86 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1649233089135061		[learning rate: 0.0034838]
	Learning Rate: 0.00348378
	LOSS [training: 0.1649233089135061 | validation: 0.3087141875863187]
	TIME [epoch: 4.89 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1694163763552424		[learning rate: 0.0034674]
	Learning Rate: 0.00346737
	LOSS [training: 0.1694163763552424 | validation: 0.31843504094019287]
	TIME [epoch: 4.87 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14309597297604765		[learning rate: 0.003451]
	Learning Rate: 0.00345103
	LOSS [training: 0.14309597297604765 | validation: 0.309090389175524]
	TIME [epoch: 4.86 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14650689730998295		[learning rate: 0.0034348]
	Learning Rate: 0.00343477
	LOSS [training: 0.14650689730998295 | validation: 0.33026401967485175]
	TIME [epoch: 4.89 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15977109954446944		[learning rate: 0.0034186]
	Learning Rate: 0.00341858
	LOSS [training: 0.15977109954446944 | validation: 0.29670783042257953]
	TIME [epoch: 4.9 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1267978000201556		[learning rate: 0.0034025]
	Learning Rate: 0.00340247
	LOSS [training: 0.1267978000201556 | validation: 0.3264761259460858]
	TIME [epoch: 4.87 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14906360670260801		[learning rate: 0.0033864]
	Learning Rate: 0.00338644
	LOSS [training: 0.14906360670260801 | validation: 0.33223852350269106]
	TIME [epoch: 4.87 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14081561916276406		[learning rate: 0.0033705]
	Learning Rate: 0.00337048
	LOSS [training: 0.14081561916276406 | validation: 0.31545189522356626]
	TIME [epoch: 4.86 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15322719833187756		[learning rate: 0.0033546]
	Learning Rate: 0.0033546
	LOSS [training: 0.15322719833187756 | validation: 0.2904092283149608]
	TIME [epoch: 4.89 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16855818415885543		[learning rate: 0.0033388]
	Learning Rate: 0.00333879
	LOSS [training: 0.16855818415885543 | validation: 0.3901996587584455]
	TIME [epoch: 4.88 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1616541485478707		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.1616541485478707 | validation: 0.3266182416674234]
	TIME [epoch: 4.86 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17151909147622207		[learning rate: 0.0033074]
	Learning Rate: 0.0033074
	LOSS [training: 0.17151909147622207 | validation: 0.3429860389909232]
	TIME [epoch: 4.87 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1810981853922197		[learning rate: 0.0032918]
	Learning Rate: 0.00329182
	LOSS [training: 0.1810981853922197 | validation: 0.317659668497425]
	TIME [epoch: 4.9 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14711826652187257		[learning rate: 0.0032763]
	Learning Rate: 0.00327631
	LOSS [training: 0.14711826652187257 | validation: 0.283985968674198]
	TIME [epoch: 4.87 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16155997964094243		[learning rate: 0.0032609]
	Learning Rate: 0.00326087
	LOSS [training: 0.16155997964094243 | validation: 0.346315871789248]
	TIME [epoch: 4.88 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15332293537794076		[learning rate: 0.0032455]
	Learning Rate: 0.0032455
	LOSS [training: 0.15332293537794076 | validation: 0.3092323497675917]
	TIME [epoch: 4.88 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13893800270904155		[learning rate: 0.0032302]
	Learning Rate: 0.00323021
	LOSS [training: 0.13893800270904155 | validation: 0.2910516115325869]
	TIME [epoch: 4.87 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1315812708686563		[learning rate: 0.003215]
	Learning Rate: 0.00321499
	LOSS [training: 0.1315812708686563 | validation: 0.3058578158499017]
	TIME [epoch: 4.86 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13913665215886714		[learning rate: 0.0031998]
	Learning Rate: 0.00319984
	LOSS [training: 0.13913665215886714 | validation: 0.3523396493117632]
	TIME [epoch: 4.88 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13202128448441705		[learning rate: 0.0031848]
	Learning Rate: 0.00318476
	LOSS [training: 0.13202128448441705 | validation: 0.3302823099735994]
	TIME [epoch: 4.88 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14679000854991908		[learning rate: 0.0031698]
	Learning Rate: 0.00316975
	LOSS [training: 0.14679000854991908 | validation: 0.31089694866155454]
	TIME [epoch: 4.87 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13351906941336456		[learning rate: 0.0031548]
	Learning Rate: 0.00315482
	LOSS [training: 0.13351906941336456 | validation: 0.3098260803018306]
	TIME [epoch: 4.87 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13854406666517		[learning rate: 0.00314]
	Learning Rate: 0.00313995
	LOSS [training: 0.13854406666517 | validation: 0.2996000563069122]
	TIME [epoch: 4.87 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14673505184453026		[learning rate: 0.0031252]
	Learning Rate: 0.00312516
	LOSS [training: 0.14673505184453026 | validation: 0.4083065079448763]
	TIME [epoch: 4.89 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15643973512805243		[learning rate: 0.0031104]
	Learning Rate: 0.00311043
	LOSS [training: 0.15643973512805243 | validation: 0.29893236101746634]
	TIME [epoch: 4.87 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15030858922395424		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.15030858922395424 | validation: 0.3199422468889454]
	TIME [epoch: 4.9 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.131253417398657		[learning rate: 0.0030812]
	Learning Rate: 0.00308119
	LOSS [training: 0.131253417398657 | validation: 0.3229442485029474]
	TIME [epoch: 4.87 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14228264741067684		[learning rate: 0.0030667]
	Learning Rate: 0.00306667
	LOSS [training: 0.14228264741067684 | validation: 0.32241609556418177]
	TIME [epoch: 4.87 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17741143916551674		[learning rate: 0.0030522]
	Learning Rate: 0.00305222
	LOSS [training: 0.17741143916551674 | validation: 0.3277553428519706]
	TIME [epoch: 4.86 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15537583892632192		[learning rate: 0.0030378]
	Learning Rate: 0.00303783
	LOSS [training: 0.15537583892632192 | validation: 0.2887530746311953]
	TIME [epoch: 4.87 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15990602554242445		[learning rate: 0.0030235]
	Learning Rate: 0.00302352
	LOSS [training: 0.15990602554242445 | validation: 0.31569995807006923]
	TIME [epoch: 4.86 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14399474931812323		[learning rate: 0.0030093]
	Learning Rate: 0.00300927
	LOSS [training: 0.14399474931812323 | validation: 0.3364691761898904]
	TIME [epoch: 4.87 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15040878544406855		[learning rate: 0.0029951]
	Learning Rate: 0.00299509
	LOSS [training: 0.15040878544406855 | validation: 0.3329101879517801]
	TIME [epoch: 4.87 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13785724643448652		[learning rate: 0.002981]
	Learning Rate: 0.00298098
	LOSS [training: 0.13785724643448652 | validation: 0.3284582003933779]
	TIME [epoch: 4.87 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1511586777553975		[learning rate: 0.0029669]
	Learning Rate: 0.00296693
	LOSS [training: 0.1511586777553975 | validation: 0.30487057594555944]
	TIME [epoch: 4.86 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14907055431105654		[learning rate: 0.002953]
	Learning Rate: 0.00295295
	LOSS [training: 0.14907055431105654 | validation: 0.3212924569572945]
	TIME [epoch: 4.88 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15731965145775184		[learning rate: 0.002939]
	Learning Rate: 0.00293904
	LOSS [training: 0.15731965145775184 | validation: 0.2880550741509638]
	TIME [epoch: 4.87 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15916083563724898		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.15916083563724898 | validation: 0.297678539164052]
	TIME [epoch: 4.87 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14792108697975714		[learning rate: 0.0029114]
	Learning Rate: 0.0029114
	LOSS [training: 0.14792108697975714 | validation: 0.311985824300279]
	TIME [epoch: 4.87 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13176589943327532		[learning rate: 0.0028977]
	Learning Rate: 0.00289769
	LOSS [training: 0.13176589943327532 | validation: 0.29842818261350285]
	TIME [epoch: 4.86 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1334036252626364		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.1334036252626364 | validation: 0.3022607618942969]
	TIME [epoch: 4.87 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13533225614770128		[learning rate: 0.0028704]
	Learning Rate: 0.00287044
	LOSS [training: 0.13533225614770128 | validation: 0.3899530086939185]
	TIME [epoch: 4.87 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16072014408316468		[learning rate: 0.0028569]
	Learning Rate: 0.00285692
	LOSS [training: 0.16072014408316468 | validation: 0.3133196960341337]
	TIME [epoch: 4.87 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14630863847106618		[learning rate: 0.0028435]
	Learning Rate: 0.00284345
	LOSS [training: 0.14630863847106618 | validation: 0.32525935433689773]
	TIME [epoch: 4.86 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15315020200732982		[learning rate: 0.0028301]
	Learning Rate: 0.00283005
	LOSS [training: 0.15315020200732982 | validation: 0.31224201782367594]
	TIME [epoch: 4.88 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14823670230531982		[learning rate: 0.0028167]
	Learning Rate: 0.00281672
	LOSS [training: 0.14823670230531982 | validation: 0.30365268316111954]
	TIME [epoch: 4.87 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13146868323531755		[learning rate: 0.0028034]
	Learning Rate: 0.00280345
	LOSS [training: 0.13146868323531755 | validation: 0.272592615054145]
	TIME [epoch: 4.87 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_307.pth
	Model improved!!!
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1462613476875515		[learning rate: 0.0027902]
	Learning Rate: 0.00279024
	LOSS [training: 0.1462613476875515 | validation: 0.3228108912843017]
	TIME [epoch: 4.87 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14325399583433132		[learning rate: 0.0027771]
	Learning Rate: 0.00277709
	LOSS [training: 0.14325399583433132 | validation: 0.3076742000438776]
	TIME [epoch: 4.87 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1395750486350612		[learning rate: 0.002764]
	Learning Rate: 0.002764
	LOSS [training: 0.1395750486350612 | validation: 0.3427623584723532]
	TIME [epoch: 4.87 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1678928904807165		[learning rate: 0.002751]
	Learning Rate: 0.00275098
	LOSS [training: 0.1678928904807165 | validation: 0.3084373375901463]
	TIME [epoch: 4.87 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16339775897479972		[learning rate: 0.002738]
	Learning Rate: 0.00273802
	LOSS [training: 0.16339775897479972 | validation: 0.28543321402779015]
	TIME [epoch: 4.87 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18728901270595988		[learning rate: 0.0027251]
	Learning Rate: 0.00272511
	LOSS [training: 0.18728901270595988 | validation: 0.35625500188578074]
	TIME [epoch: 4.87 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13624898552131107		[learning rate: 0.0027123]
	Learning Rate: 0.00271227
	LOSS [training: 0.13624898552131107 | validation: 0.3139033815335194]
	TIME [epoch: 4.86 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13520940038876728		[learning rate: 0.0026995]
	Learning Rate: 0.00269949
	LOSS [training: 0.13520940038876728 | validation: 0.2919148693262654]
	TIME [epoch: 4.87 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14988478161394736		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.14988478161394736 | validation: 0.30876393131254004]
	TIME [epoch: 4.87 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13452691216335752		[learning rate: 0.0026741]
	Learning Rate: 0.00267411
	LOSS [training: 0.13452691216335752 | validation: 0.2889783255133264]
	TIME [epoch: 4.87 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13650164144895707		[learning rate: 0.0026615]
	Learning Rate: 0.00266151
	LOSS [training: 0.13650164144895707 | validation: 0.3000420054130096]
	TIME [epoch: 4.87 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13730784288132328		[learning rate: 0.002649]
	Learning Rate: 0.00264897
	LOSS [training: 0.13730784288132328 | validation: 0.3009201003714905]
	TIME [epoch: 4.87 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14217878654656496		[learning rate: 0.0026365]
	Learning Rate: 0.00263649
	LOSS [training: 0.14217878654656496 | validation: 0.33355685833307097]
	TIME [epoch: 4.87 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13754481093350696		[learning rate: 0.0026241]
	Learning Rate: 0.00262406
	LOSS [training: 0.13754481093350696 | validation: 0.3380221933636804]
	TIME [epoch: 4.87 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.144149887596371		[learning rate: 0.0026117]
	Learning Rate: 0.0026117
	LOSS [training: 0.144149887596371 | validation: 0.32575773722913975]
	TIME [epoch: 4.87 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14484534734172444		[learning rate: 0.0025994]
	Learning Rate: 0.00259939
	LOSS [training: 0.14484534734172444 | validation: 0.28462444903277656]
	TIME [epoch: 4.86 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15383299924825128		[learning rate: 0.0025871]
	Learning Rate: 0.00258714
	LOSS [training: 0.15383299924825128 | validation: 0.341391430606958]
	TIME [epoch: 4.86 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13346195079593218		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.13346195079593218 | validation: 0.2923811344676022]
	TIME [epoch: 4.86 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15114915845748572		[learning rate: 0.0025628]
	Learning Rate: 0.00256282
	LOSS [training: 0.15114915845748572 | validation: 0.3244201564626177]
	TIME [epoch: 4.87 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14184600735189692		[learning rate: 0.0025507]
	Learning Rate: 0.00255074
	LOSS [training: 0.14184600735189692 | validation: 0.29295115758021517]
	TIME [epoch: 4.86 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1407640200009586		[learning rate: 0.0025387]
	Learning Rate: 0.00253872
	LOSS [training: 0.1407640200009586 | validation: 0.29349955160774926]
	TIME [epoch: 4.87 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14284159280124611		[learning rate: 0.0025268]
	Learning Rate: 0.00252676
	LOSS [training: 0.14284159280124611 | validation: 0.3142729102910192]
	TIME [epoch: 4.86 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13875015554400688		[learning rate: 0.0025149]
	Learning Rate: 0.00251485
	LOSS [training: 0.13875015554400688 | validation: 0.2952645994577833]
	TIME [epoch: 4.86 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14238367960882903		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.14238367960882903 | validation: 0.30625560828718823]
	TIME [epoch: 4.9 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13129501753585557		[learning rate: 0.0024912]
	Learning Rate: 0.00249121
	LOSS [training: 0.13129501753585557 | validation: 0.3111348333651672]
	TIME [epoch: 4.91 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1509377044849637		[learning rate: 0.0024795]
	Learning Rate: 0.00247947
	LOSS [training: 0.1509377044849637 | validation: 0.28404292629546324]
	TIME [epoch: 4.87 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13435600298850434		[learning rate: 0.0024678]
	Learning Rate: 0.00246779
	LOSS [training: 0.13435600298850434 | validation: 0.3535654168386183]
	TIME [epoch: 4.87 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14674278839496846		[learning rate: 0.0024562]
	Learning Rate: 0.00245616
	LOSS [training: 0.14674278839496846 | validation: 0.3246129573169728]
	TIME [epoch: 4.87 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15968780945913497		[learning rate: 0.0024446]
	Learning Rate: 0.00244458
	LOSS [training: 0.15968780945913497 | validation: 0.3180690551120405]
	TIME [epoch: 4.92 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1477702712066636		[learning rate: 0.0024331]
	Learning Rate: 0.00243307
	LOSS [training: 0.1477702712066636 | validation: 0.31205834597166876]
	TIME [epoch: 4.88 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13397720064557353		[learning rate: 0.0024216]
	Learning Rate: 0.0024216
	LOSS [training: 0.13397720064557353 | validation: 0.3134464662085535]
	TIME [epoch: 4.86 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14873802578287199		[learning rate: 0.0024102]
	Learning Rate: 0.00241019
	LOSS [training: 0.14873802578287199 | validation: 0.2866909484476606]
	TIME [epoch: 4.87 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13743810406265677		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.13743810406265677 | validation: 0.3004110510059956]
	TIME [epoch: 4.9 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13890831037926155		[learning rate: 0.0023875]
	Learning Rate: 0.00238753
	LOSS [training: 0.13890831037926155 | validation: 0.3222601572181346]
	TIME [epoch: 4.91 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13712765905938568		[learning rate: 0.0023763]
	Learning Rate: 0.00237628
	LOSS [training: 0.13712765905938568 | validation: 0.28057473066305866]
	TIME [epoch: 4.9 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1790852283347192		[learning rate: 0.0023651]
	Learning Rate: 0.00236508
	LOSS [training: 0.1790852283347192 | validation: 0.3296984278712218]
	TIME [epoch: 4.88 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1414808434645855		[learning rate: 0.0023539]
	Learning Rate: 0.00235394
	LOSS [training: 0.1414808434645855 | validation: 0.3194124859529645]
	TIME [epoch: 4.87 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1500749717843542		[learning rate: 0.0023428]
	Learning Rate: 0.00234285
	LOSS [training: 0.1500749717843542 | validation: 0.28708828258529434]
	TIME [epoch: 4.91 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1398150930021545		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.1398150930021545 | validation: 0.29402649897116206]
	TIME [epoch: 4.88 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1761134977389876		[learning rate: 0.0023208]
	Learning Rate: 0.00232082
	LOSS [training: 0.1761134977389876 | validation: 0.30736217540950045]
	TIME [epoch: 4.87 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15722218972535582		[learning rate: 0.0023099]
	Learning Rate: 0.00230988
	LOSS [training: 0.15722218972535582 | validation: 0.3259512437233424]
	TIME [epoch: 4.87 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13311116648148855		[learning rate: 0.002299]
	Learning Rate: 0.002299
	LOSS [training: 0.13311116648148855 | validation: 0.3495630682800822]
	TIME [epoch: 4.87 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16141352530800274		[learning rate: 0.0022882]
	Learning Rate: 0.00228816
	LOSS [training: 0.16141352530800274 | validation: 0.31754751012574456]
	TIME [epoch: 4.87 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13963726071195146		[learning rate: 0.0022774]
	Learning Rate: 0.00227738
	LOSS [training: 0.13963726071195146 | validation: 0.3154470558824094]
	TIME [epoch: 4.9 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16205970914056317		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.16205970914056317 | validation: 0.3441344986021873]
	TIME [epoch: 4.89 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14537640580328134		[learning rate: 0.002256]
	Learning Rate: 0.00225597
	LOSS [training: 0.14537640580328134 | validation: 0.3043605208253296]
	TIME [epoch: 4.88 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1317163338933871		[learning rate: 0.0022453]
	Learning Rate: 0.00224534
	LOSS [training: 0.1317163338933871 | validation: 0.29704219655377395]
	TIME [epoch: 4.88 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1385537657216685		[learning rate: 0.0022348]
	Learning Rate: 0.00223476
	LOSS [training: 0.1385537657216685 | validation: 0.28498401488765446]
	TIME [epoch: 4.91 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14289208524569844		[learning rate: 0.0022242]
	Learning Rate: 0.00222423
	LOSS [training: 0.14289208524569844 | validation: 0.3397557045705518]
	TIME [epoch: 4.9 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1529811562784826		[learning rate: 0.0022137]
	Learning Rate: 0.00221375
	LOSS [training: 0.1529811562784826 | validation: 0.29474308489078554]
	TIME [epoch: 4.89 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13237370989666844		[learning rate: 0.0022033]
	Learning Rate: 0.00220332
	LOSS [training: 0.13237370989666844 | validation: 0.31668240236723205]
	TIME [epoch: 4.88 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12876128550910187		[learning rate: 0.0021929]
	Learning Rate: 0.00219293
	LOSS [training: 0.12876128550910187 | validation: 0.30984940396191935]
	TIME [epoch: 4.87 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13982069646181036		[learning rate: 0.0021826]
	Learning Rate: 0.0021826
	LOSS [training: 0.13982069646181036 | validation: 0.30681747270808124]
	TIME [epoch: 4.86 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13610871237045702		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.13610871237045702 | validation: 0.29924657649507636]
	TIME [epoch: 4.9 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1454088678492172		[learning rate: 0.0021621]
	Learning Rate: 0.00216208
	LOSS [training: 0.1454088678492172 | validation: 0.2973950481751833]
	TIME [epoch: 4.87 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13553541068616343		[learning rate: 0.0021519]
	Learning Rate: 0.00215189
	LOSS [training: 0.13553541068616343 | validation: 0.29048341361493296]
	TIME [epoch: 4.89 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14143329938429514		[learning rate: 0.0021418]
	Learning Rate: 0.00214175
	LOSS [training: 0.14143329938429514 | validation: 0.2945090316142]
	TIME [epoch: 4.87 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14955684388941415		[learning rate: 0.0021317]
	Learning Rate: 0.00213166
	LOSS [training: 0.14955684388941415 | validation: 0.30922747832668357]
	TIME [epoch: 4.88 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1357883554707928		[learning rate: 0.0021216]
	Learning Rate: 0.00212162
	LOSS [training: 0.1357883554707928 | validation: 0.298307312105485]
	TIME [epoch: 4.9 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17000624159105399		[learning rate: 0.0021116]
	Learning Rate: 0.00211162
	LOSS [training: 0.17000624159105399 | validation: 0.3117549323224743]
	TIME [epoch: 4.86 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15293898016907265		[learning rate: 0.0021017]
	Learning Rate: 0.00210167
	LOSS [training: 0.15293898016907265 | validation: 0.35274962479634636]
	TIME [epoch: 4.87 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14578006610915073		[learning rate: 0.0020918]
	Learning Rate: 0.00209176
	LOSS [training: 0.14578006610915073 | validation: 0.3145257773783163]
	TIME [epoch: 4.86 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13262083973503258		[learning rate: 0.0020819]
	Learning Rate: 0.00208191
	LOSS [training: 0.13262083973503258 | validation: 0.29571710187798755]
	TIME [epoch: 4.86 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14386085961961353		[learning rate: 0.0020721]
	Learning Rate: 0.0020721
	LOSS [training: 0.14386085961961353 | validation: 0.32824590485258065]
	TIME [epoch: 4.86 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17539905699320818		[learning rate: 0.0020623]
	Learning Rate: 0.00206233
	LOSS [training: 0.17539905699320818 | validation: 0.315213088074539]
	TIME [epoch: 4.86 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13827213283328146		[learning rate: 0.0020526]
	Learning Rate: 0.00205262
	LOSS [training: 0.13827213283328146 | validation: 0.30960313803862977]
	TIME [epoch: 4.87 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15478735295118473		[learning rate: 0.0020429]
	Learning Rate: 0.00204294
	LOSS [training: 0.15478735295118473 | validation: 0.29998941136052354]
	TIME [epoch: 4.97 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1276055824232324		[learning rate: 0.0020333]
	Learning Rate: 0.00203332
	LOSS [training: 0.1276055824232324 | validation: 0.2809052546201822]
	TIME [epoch: 4.87 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15270145436203678		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.15270145436203678 | validation: 0.3009047184414681]
	TIME [epoch: 4.87 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14056013602510942		[learning rate: 0.0020142]
	Learning Rate: 0.0020142
	LOSS [training: 0.14056013602510942 | validation: 0.3181614772388944]
	TIME [epoch: 4.87 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17414033109213878		[learning rate: 0.0020047]
	Learning Rate: 0.00200471
	LOSS [training: 0.17414033109213878 | validation: 0.34265588931044055]
	TIME [epoch: 4.87 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15778693220788004		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.15778693220788004 | validation: 0.3104655945687264]
	TIME [epoch: 4.86 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13601149931509882		[learning rate: 0.0019859]
	Learning Rate: 0.00198586
	LOSS [training: 0.13601149931509882 | validation: 0.3514815422004672]
	TIME [epoch: 4.86 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1435568052815262		[learning rate: 0.0019765]
	Learning Rate: 0.0019765
	LOSS [training: 0.1435568052815262 | validation: 0.31620738718779395]
	TIME [epoch: 4.87 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16170067585432574		[learning rate: 0.0019672]
	Learning Rate: 0.00196719
	LOSS [training: 0.16170067585432574 | validation: 0.2939205609565964]
	TIME [epoch: 4.86 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13438824825752113		[learning rate: 0.0019579]
	Learning Rate: 0.00195792
	LOSS [training: 0.13438824825752113 | validation: 0.3167025185700644]
	TIME [epoch: 4.86 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14812047022243643		[learning rate: 0.0019487]
	Learning Rate: 0.00194869
	LOSS [training: 0.14812047022243643 | validation: 0.3046031274723571]
	TIME [epoch: 4.87 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1413945375505775		[learning rate: 0.0019395]
	Learning Rate: 0.00193951
	LOSS [training: 0.1413945375505775 | validation: 0.28867363037569477]
	TIME [epoch: 4.86 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1470691955545875		[learning rate: 0.0019304]
	Learning Rate: 0.00193037
	LOSS [training: 0.1470691955545875 | validation: 0.29818570024501184]
	TIME [epoch: 4.87 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1437140566425505		[learning rate: 0.0019213]
	Learning Rate: 0.00192128
	LOSS [training: 0.1437140566425505 | validation: 0.30589478469229253]
	TIME [epoch: 4.87 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13618709050245628		[learning rate: 0.0019122]
	Learning Rate: 0.00191222
	LOSS [training: 0.13618709050245628 | validation: 0.2936015104978403]
	TIME [epoch: 4.86 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13256551398579794		[learning rate: 0.0019032]
	Learning Rate: 0.00190321
	LOSS [training: 0.13256551398579794 | validation: 0.2912523976020019]
	TIME [epoch: 4.87 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13320532789964706		[learning rate: 0.0018942]
	Learning Rate: 0.00189424
	LOSS [training: 0.13320532789964706 | validation: 0.3322568082506208]
	TIME [epoch: 4.87 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1504714257859075		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.1504714257859075 | validation: 0.30821483736006045]
	TIME [epoch: 4.86 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1257175644824679		[learning rate: 0.0018764]
	Learning Rate: 0.00187643
	LOSS [training: 0.1257175644824679 | validation: 0.3269455234371584]
	TIME [epoch: 4.86 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1309616031357939		[learning rate: 0.0018676]
	Learning Rate: 0.00186759
	LOSS [training: 0.1309616031357939 | validation: 0.2924720469746693]
	TIME [epoch: 4.86 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12508212126319737		[learning rate: 0.0018588]
	Learning Rate: 0.00185879
	LOSS [training: 0.12508212126319737 | validation: 0.30592215701077685]
	TIME [epoch: 4.87 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1517673181963319		[learning rate: 0.00185]
	Learning Rate: 0.00185003
	LOSS [training: 0.1517673181963319 | validation: 0.30598101692505697]
	TIME [epoch: 4.86 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15405112966980783		[learning rate: 0.0018413]
	Learning Rate: 0.00184132
	LOSS [training: 0.15405112966980783 | validation: 0.30030278322386955]
	TIME [epoch: 4.87 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12878163362420542		[learning rate: 0.0018326]
	Learning Rate: 0.00183264
	LOSS [training: 0.12878163362420542 | validation: 0.3154141729023307]
	TIME [epoch: 4.89 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1283284931399626		[learning rate: 0.001824]
	Learning Rate: 0.001824
	LOSS [training: 0.1283284931399626 | validation: 0.2815952302212076]
	TIME [epoch: 4.86 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13550694116442727		[learning rate: 0.0018154]
	Learning Rate: 0.00181541
	LOSS [training: 0.13550694116442727 | validation: 0.30865645427774757]
	TIME [epoch: 4.87 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16149458411338669		[learning rate: 0.0018069]
	Learning Rate: 0.00180685
	LOSS [training: 0.16149458411338669 | validation: 0.30120043137501096]
	TIME [epoch: 4.86 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14493844420888197		[learning rate: 0.0017983]
	Learning Rate: 0.00179834
	LOSS [training: 0.14493844420888197 | validation: 0.2914883493769872]
	TIME [epoch: 4.86 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16001377125504074		[learning rate: 0.0017899]
	Learning Rate: 0.00178987
	LOSS [training: 0.16001377125504074 | validation: 0.3288449177213414]
	TIME [epoch: 4.87 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16788154587629778		[learning rate: 0.0017814]
	Learning Rate: 0.00178143
	LOSS [training: 0.16788154587629778 | validation: 0.2988893513325828]
	TIME [epoch: 4.86 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1471337268468671		[learning rate: 0.001773]
	Learning Rate: 0.00177304
	LOSS [training: 0.1471337268468671 | validation: 0.309889529760833]
	TIME [epoch: 4.87 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1601255290382996		[learning rate: 0.0017647]
	Learning Rate: 0.00176468
	LOSS [training: 0.1601255290382996 | validation: 0.3103960915487161]
	TIME [epoch: 4.87 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13668199158976568		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.13668199158976568 | validation: 0.32458286375930046]
	TIME [epoch: 4.87 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13874837188388373		[learning rate: 0.0017481]
	Learning Rate: 0.00174809
	LOSS [training: 0.13874837188388373 | validation: 0.2882974854706685]
	TIME [epoch: 4.87 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15279405979919863		[learning rate: 0.0017399]
	Learning Rate: 0.00173985
	LOSS [training: 0.15279405979919863 | validation: 0.304782963078647]
	TIME [epoch: 4.86 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1326055815618825		[learning rate: 0.0017317]
	Learning Rate: 0.00173166
	LOSS [training: 0.1326055815618825 | validation: 0.3126117691414109]
	TIME [epoch: 4.86 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15035764693683118		[learning rate: 0.0017235]
	Learning Rate: 0.0017235
	LOSS [training: 0.15035764693683118 | validation: 0.3297270536474791]
	TIME [epoch: 4.86 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13165232417042216		[learning rate: 0.0017154]
	Learning Rate: 0.00171537
	LOSS [training: 0.13165232417042216 | validation: 0.3090764874449375]
	TIME [epoch: 4.87 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15995628279459878		[learning rate: 0.0017073]
	Learning Rate: 0.00170729
	LOSS [training: 0.15995628279459878 | validation: 0.31309746384265547]
	TIME [epoch: 4.86 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14303737337873257		[learning rate: 0.0016992]
	Learning Rate: 0.00169925
	LOSS [training: 0.14303737337873257 | validation: 0.3035914552166884]
	TIME [epoch: 4.86 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14824314195651409		[learning rate: 0.0016912]
	Learning Rate: 0.00169124
	LOSS [training: 0.14824314195651409 | validation: 0.30243522293168096]
	TIME [epoch: 4.87 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13882539635312457		[learning rate: 0.0016833]
	Learning Rate: 0.00168327
	LOSS [training: 0.13882539635312457 | validation: 0.3094477257872301]
	TIME [epoch: 4.87 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1447879049085638		[learning rate: 0.0016753]
	Learning Rate: 0.00167534
	LOSS [training: 0.1447879049085638 | validation: 0.29978926862433086]
	TIME [epoch: 4.86 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13559684698141233		[learning rate: 0.0016674]
	Learning Rate: 0.00166744
	LOSS [training: 0.13559684698141233 | validation: 0.2892382223422262]
	TIME [epoch: 4.88 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13487108893903998		[learning rate: 0.0016596]
	Learning Rate: 0.00165959
	LOSS [training: 0.13487108893903998 | validation: 0.30900887603191507]
	TIME [epoch: 4.86 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.133137716706371		[learning rate: 0.0016518]
	Learning Rate: 0.00165177
	LOSS [training: 0.133137716706371 | validation: 0.2928657651448796]
	TIME [epoch: 4.86 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1486341284317084		[learning rate: 0.001644]
	Learning Rate: 0.00164398
	LOSS [training: 0.1486341284317084 | validation: 0.3087332499266177]
	TIME [epoch: 4.86 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15938082765929595		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.15938082765929595 | validation: 0.3511933921937747]
	TIME [epoch: 4.86 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1398131489279571		[learning rate: 0.0016285]
	Learning Rate: 0.00162853
	LOSS [training: 0.1398131489279571 | validation: 0.3054505190841276]
	TIME [epoch: 4.86 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14044236735542742		[learning rate: 0.0016209]
	Learning Rate: 0.00162085
	LOSS [training: 0.14044236735542742 | validation: 0.29421125768224277]
	TIME [epoch: 4.86 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1312797701790998		[learning rate: 0.0016132]
	Learning Rate: 0.00161322
	LOSS [training: 0.1312797701790998 | validation: 0.30230338381830346]
	TIME [epoch: 4.86 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1308150987509918		[learning rate: 0.0016056]
	Learning Rate: 0.00160561
	LOSS [training: 0.1308150987509918 | validation: 0.30253179523492935]
	TIME [epoch: 4.89 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13591132326998556		[learning rate: 0.001598]
	Learning Rate: 0.00159805
	LOSS [training: 0.13591132326998556 | validation: 0.28462363153734915]
	TIME [epoch: 4.91 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15319650519897782		[learning rate: 0.0015905]
	Learning Rate: 0.00159052
	LOSS [training: 0.15319650519897782 | validation: 0.34676358758685766]
	TIME [epoch: 4.9 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14746583638984145		[learning rate: 0.001583]
	Learning Rate: 0.00158302
	LOSS [training: 0.14746583638984145 | validation: 0.3032544779784582]
	TIME [epoch: 4.87 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13949945132331862		[learning rate: 0.0015756]
	Learning Rate: 0.00157556
	LOSS [training: 0.13949945132331862 | validation: 0.29719377939939234]
	TIME [epoch: 4.88 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16097293995896664		[learning rate: 0.0015681]
	Learning Rate: 0.00156814
	LOSS [training: 0.16097293995896664 | validation: 0.31700219468445234]
	TIME [epoch: 4.91 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1495673177782095		[learning rate: 0.0015607]
	Learning Rate: 0.00156075
	LOSS [training: 0.1495673177782095 | validation: 0.30667789962199943]
	TIME [epoch: 4.91 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16415226096819674		[learning rate: 0.0015534]
	Learning Rate: 0.0015534
	LOSS [training: 0.16415226096819674 | validation: 0.306830674110992]
	TIME [epoch: 4.88 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14375773448153575		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.14375773448153575 | validation: 0.33538499563684615]
	TIME [epoch: 4.87 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14417813407246716		[learning rate: 0.0015388]
	Learning Rate: 0.00153879
	LOSS [training: 0.14417813407246716 | validation: 0.314574179702962]
	TIME [epoch: 4.86 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14790002899795274		[learning rate: 0.0015315]
	Learning Rate: 0.00153154
	LOSS [training: 0.14790002899795274 | validation: 0.3067118501269859]
	TIME [epoch: 4.89 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1382430357953447		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.1382430357953447 | validation: 0.31094793194840076]
	TIME [epoch: 4.86 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13288815824469832		[learning rate: 0.0015171]
	Learning Rate: 0.00151714
	LOSS [training: 0.13288815824469832 | validation: 0.29777251978216157]
	TIME [epoch: 4.9 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13710391414361212		[learning rate: 0.00151]
	Learning Rate: 0.00150999
	LOSS [training: 0.13710391414361212 | validation: 0.29918816743147325]
	TIME [epoch: 4.89 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13958715995918058		[learning rate: 0.0015029]
	Learning Rate: 0.00150288
	LOSS [training: 0.13958715995918058 | validation: 0.2938013553242251]
	TIME [epoch: 4.87 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12072117637425128		[learning rate: 0.0014958]
	Learning Rate: 0.00149579
	LOSS [training: 0.12072117637425128 | validation: 0.301530198099194]
	TIME [epoch: 4.91 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1349137173655125		[learning rate: 0.0014887]
	Learning Rate: 0.00148875
	LOSS [training: 0.1349137173655125 | validation: 0.2982185146975756]
	TIME [epoch: 4.9 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12899752650278817		[learning rate: 0.0014817]
	Learning Rate: 0.00148173
	LOSS [training: 0.12899752650278817 | validation: 0.30317351189282593]
	TIME [epoch: 4.88 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13924634763506563		[learning rate: 0.0014747]
	Learning Rate: 0.00147475
	LOSS [training: 0.13924634763506563 | validation: 0.30872158309709097]
	TIME [epoch: 4.87 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13071687862674033		[learning rate: 0.0014678]
	Learning Rate: 0.0014678
	LOSS [training: 0.13071687862674033 | validation: 0.2908024304313744]
	TIME [epoch: 4.87 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1395165581522333		[learning rate: 0.0014609]
	Learning Rate: 0.00146088
	LOSS [training: 0.1395165581522333 | validation: 0.30830058494174234]
	TIME [epoch: 4.86 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15662771232606026		[learning rate: 0.001454]
	Learning Rate: 0.001454
	LOSS [training: 0.15662771232606026 | validation: 0.31789211625200053]
	TIME [epoch: 4.92 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14908600381603596		[learning rate: 0.0014471]
	Learning Rate: 0.00144715
	LOSS [training: 0.14908600381603596 | validation: 0.3485487727099365]
	TIME [epoch: 4.88 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15008198858414235		[learning rate: 0.0014403]
	Learning Rate: 0.00144033
	LOSS [training: 0.15008198858414235 | validation: 0.29454566568547536]
	TIME [epoch: 4.88 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15588623236716304		[learning rate: 0.0014335]
	Learning Rate: 0.00143354
	LOSS [training: 0.15588623236716304 | validation: 0.3227284787192343]
	TIME [epoch: 4.87 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1339505854658207		[learning rate: 0.0014268]
	Learning Rate: 0.00142679
	LOSS [training: 0.1339505854658207 | validation: 0.29353944424065115]
	TIME [epoch: 4.88 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12022574574519204		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.12022574574519204 | validation: 0.3095053318638652]
	TIME [epoch: 4.91 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13987820886377952		[learning rate: 0.0014134]
	Learning Rate: 0.00141337
	LOSS [training: 0.13987820886377952 | validation: 0.3090109068365007]
	TIME [epoch: 4.9 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13238623813572223		[learning rate: 0.0014067]
	Learning Rate: 0.00140671
	LOSS [training: 0.13238623813572223 | validation: 0.310053718708965]
	TIME [epoch: 4.89 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14363482844933984		[learning rate: 0.0014001]
	Learning Rate: 0.00140008
	LOSS [training: 0.14363482844933984 | validation: 0.3150044785580246]
	TIME [epoch: 4.86 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16130768947758545		[learning rate: 0.0013935]
	Learning Rate: 0.00139349
	LOSS [training: 0.16130768947758545 | validation: 0.31252742604144834]
	TIME [epoch: 4.88 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12516883447300683		[learning rate: 0.0013869]
	Learning Rate: 0.00138692
	LOSS [training: 0.12516883447300683 | validation: 0.32355962671883914]
	TIME [epoch: 4.91 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14404996403581702		[learning rate: 0.0013804]
	Learning Rate: 0.00138038
	LOSS [training: 0.14404996403581702 | validation: 0.29755947506320835]
	TIME [epoch: 4.89 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1483186579445948		[learning rate: 0.0013739]
	Learning Rate: 0.00137388
	LOSS [training: 0.1483186579445948 | validation: 0.3096659059732671]
	TIME [epoch: 4.88 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14375793526817474		[learning rate: 0.0013674]
	Learning Rate: 0.00136741
	LOSS [training: 0.14375793526817474 | validation: 0.30656027794020546]
	TIME [epoch: 4.9 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12892470944014572		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.12892470944014572 | validation: 0.30033287817307247]
	TIME [epoch: 4.89 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.136611052805244		[learning rate: 0.0013545]
	Learning Rate: 0.00135455
	LOSS [training: 0.136611052805244 | validation: 0.3059354972547423]
	TIME [epoch: 4.88 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12739210930933792		[learning rate: 0.0013482]
	Learning Rate: 0.00134817
	LOSS [training: 0.12739210930933792 | validation: 0.28923968824819546]
	TIME [epoch: 4.9 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13720279512622388		[learning rate: 0.0013418]
	Learning Rate: 0.00134181
	LOSS [training: 0.13720279512622388 | validation: 0.2890491333880414]
	TIME [epoch: 4.91 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15872892220548418		[learning rate: 0.0013355]
	Learning Rate: 0.00133549
	LOSS [training: 0.15872892220548418 | validation: 0.31523874737723373]
	TIME [epoch: 4.89 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13549516955566074		[learning rate: 0.0013292]
	Learning Rate: 0.0013292
	LOSS [training: 0.13549516955566074 | validation: 0.2933262643071901]
	TIME [epoch: 4.9 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13509134089192273		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.13509134089192273 | validation: 0.29490370504190144]
	TIME [epoch: 4.87 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14604820177567143		[learning rate: 0.0013167]
	Learning Rate: 0.0013167
	LOSS [training: 0.14604820177567143 | validation: 0.3064017537520669]
	TIME [epoch: 4.9 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15754221161701698		[learning rate: 0.0013105]
	Learning Rate: 0.0013105
	LOSS [training: 0.15754221161701698 | validation: 0.31457270416533567]
	TIME [epoch: 4.87 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17120238816865666		[learning rate: 0.0013043]
	Learning Rate: 0.00130432
	LOSS [training: 0.17120238816865666 | validation: 0.29938092639711794]
	TIME [epoch: 4.87 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1289801715183583		[learning rate: 0.0012982]
	Learning Rate: 0.00129818
	LOSS [training: 0.1289801715183583 | validation: 0.30379402149928103]
	TIME [epoch: 4.91 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1364735947163513		[learning rate: 0.0012921]
	Learning Rate: 0.00129206
	LOSS [training: 0.1364735947163513 | validation: 0.2966059225536037]
	TIME [epoch: 4.91 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1255777752307124		[learning rate: 0.001286]
	Learning Rate: 0.00128597
	LOSS [training: 0.1255777752307124 | validation: 0.3061459777627518]
	TIME [epoch: 4.88 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13602850396187866		[learning rate: 0.0012799]
	Learning Rate: 0.00127991
	LOSS [training: 0.13602850396187866 | validation: 0.3164139561436068]
	TIME [epoch: 4.88 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1418729154103604		[learning rate: 0.0012739]
	Learning Rate: 0.00127388
	LOSS [training: 0.1418729154103604 | validation: 0.3024658309136938]
	TIME [epoch: 4.86 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15996703833708859		[learning rate: 0.0012679]
	Learning Rate: 0.00126788
	LOSS [training: 0.15996703833708859 | validation: 0.30941122952419203]
	TIME [epoch: 4.87 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15930336007972773		[learning rate: 0.0012619]
	Learning Rate: 0.0012619
	LOSS [training: 0.15930336007972773 | validation: 0.2935206137367317]
	TIME [epoch: 4.87 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1281340161513369		[learning rate: 0.001256]
	Learning Rate: 0.00125596
	LOSS [training: 0.1281340161513369 | validation: 0.2883261752947674]
	TIME [epoch: 4.9 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14109975714506348		[learning rate: 0.00125]
	Learning Rate: 0.00125004
	LOSS [training: 0.14109975714506348 | validation: 0.29157835940079774]
	TIME [epoch: 4.89 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13766378511659225		[learning rate: 0.0012441]
	Learning Rate: 0.00124415
	LOSS [training: 0.13766378511659225 | validation: 0.30572920104779916]
	TIME [epoch: 4.88 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1572845064151374		[learning rate: 0.0012383]
	Learning Rate: 0.00123828
	LOSS [training: 0.1572845064151374 | validation: 0.30034069666488095]
	TIME [epoch: 4.87 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13090596232840207		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.13090596232840207 | validation: 0.28625765919119217]
	TIME [epoch: 4.87 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1404409574537291		[learning rate: 0.0012266]
	Learning Rate: 0.00122664
	LOSS [training: 0.1404409574537291 | validation: 0.2982396586045418]
	TIME [epoch: 4.87 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12184458063406996		[learning rate: 0.0012209]
	Learning Rate: 0.00122086
	LOSS [training: 0.12184458063406996 | validation: 0.28788378599033754]
	TIME [epoch: 4.88 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1298529375983618		[learning rate: 0.0012151]
	Learning Rate: 0.00121511
	LOSS [training: 0.1298529375983618 | validation: 0.3324397361668243]
	TIME [epoch: 4.88 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13087866331291834		[learning rate: 0.0012094]
	Learning Rate: 0.00120938
	LOSS [training: 0.13087866331291834 | validation: 0.29580065908895975]
	TIME [epoch: 4.87 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14488020556318593		[learning rate: 0.0012037]
	Learning Rate: 0.00120368
	LOSS [training: 0.14488020556318593 | validation: 0.31204632813895034]
	TIME [epoch: 4.88 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13890471951625144		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.13890471951625144 | validation: 0.29031247993339643]
	TIME [epoch: 4.9 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13726019865130545		[learning rate: 0.0011924]
	Learning Rate: 0.00119237
	LOSS [training: 0.13726019865130545 | validation: 0.315866231659128]
	TIME [epoch: 4.88 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14077765824802818		[learning rate: 0.0011867]
	Learning Rate: 0.00118675
	LOSS [training: 0.14077765824802818 | validation: 0.30057130056889203]
	TIME [epoch: 4.88 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1354179232248		[learning rate: 0.0011812]
	Learning Rate: 0.00118116
	LOSS [training: 0.1354179232248 | validation: 0.3125460990298754]
	TIME [epoch: 4.89 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12829853989336024		[learning rate: 0.0011756]
	Learning Rate: 0.00117559
	LOSS [training: 0.12829853989336024 | validation: 0.2938503113309419]
	TIME [epoch: 4.87 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15375494414043323		[learning rate: 0.0011701]
	Learning Rate: 0.00117005
	LOSS [training: 0.15375494414043323 | validation: 0.31813140355943753]
	TIME [epoch: 4.87 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15174306961495743		[learning rate: 0.0011645]
	Learning Rate: 0.00116454
	LOSS [training: 0.15174306961495743 | validation: 0.31382980856554066]
	TIME [epoch: 4.87 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14108534050488217		[learning rate: 0.0011591]
	Learning Rate: 0.00115905
	LOSS [training: 0.14108534050488217 | validation: 0.29197144022146415]
	TIME [epoch: 4.89 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14747420165001837		[learning rate: 0.0011536]
	Learning Rate: 0.00115359
	LOSS [training: 0.14747420165001837 | validation: 0.28942122235805207]
	TIME [epoch: 4.89 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12132445500150103		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.12132445500150103 | validation: 0.2918153678239994]
	TIME [epoch: 4.88 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14519888986228255		[learning rate: 0.0011427]
	Learning Rate: 0.00114274
	LOSS [training: 0.14519888986228255 | validation: 0.3030041240902763]
	TIME [epoch: 4.88 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12776408392280078		[learning rate: 0.0011374]
	Learning Rate: 0.00113736
	LOSS [training: 0.12776408392280078 | validation: 0.2891421861802207]
	TIME [epoch: 4.87 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1474033526371476		[learning rate: 0.001132]
	Learning Rate: 0.001132
	LOSS [training: 0.1474033526371476 | validation: 0.3154116103665815]
	TIME [epoch: 4.86 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1361496396919923		[learning rate: 0.0011267]
	Learning Rate: 0.00112667
	LOSS [training: 0.1361496396919923 | validation: 0.3217097347322837]
	TIME [epoch: 4.86 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13515886064659197		[learning rate: 0.0011214]
	Learning Rate: 0.00112136
	LOSS [training: 0.13515886064659197 | validation: 0.30648206953441215]
	TIME [epoch: 30.8 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.153363922163363		[learning rate: 0.0011161]
	Learning Rate: 0.00111607
	LOSS [training: 0.153363922163363 | validation: 0.30242820724212893]
	TIME [epoch: 9.42 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14777265974790574		[learning rate: 0.0011108]
	Learning Rate: 0.00111081
	LOSS [training: 0.14777265974790574 | validation: 0.2971359108952091]
	TIME [epoch: 9.4 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14653557080805463		[learning rate: 0.0011056]
	Learning Rate: 0.00110558
	LOSS [training: 0.14653557080805463 | validation: 0.2831397551674832]
	TIME [epoch: 9.4 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1466420584486116		[learning rate: 0.0011004]
	Learning Rate: 0.00110037
	LOSS [training: 0.1466420584486116 | validation: 0.3118868800335526]
	TIME [epoch: 9.39 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13969080567271136		[learning rate: 0.0010952]
	Learning Rate: 0.00109518
	LOSS [training: 0.13969080567271136 | validation: 0.30429647088991013]
	TIME [epoch: 9.39 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14186660013112198		[learning rate: 0.00109]
	Learning Rate: 0.00109002
	LOSS [training: 0.14186660013112198 | validation: 0.2980984447738749]
	TIME [epoch: 9.4 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1466388585684792		[learning rate: 0.0010849]
	Learning Rate: 0.00108489
	LOSS [training: 0.1466388585684792 | validation: 0.3290547753333675]
	TIME [epoch: 9.41 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v8_20240715_175905/states/model_facs_v3_dec2b_2dpca_v8_508.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 2605.006 seconds.
