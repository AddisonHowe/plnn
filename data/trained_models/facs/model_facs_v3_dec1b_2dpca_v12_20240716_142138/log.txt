Args:
Namespace(name='model_facs_v3_dec1b_2dpca_v12', outdir='out/model_training/model_facs_v3_dec1b_2dpca_v12', training_data='data/training_data/facs_v3/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs_v3/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=800, ncells_sample=800, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2481365083

Training model...

Saving initial model state to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.5601628663900924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5601628663900924 | validation: 1.2172503068454699]
	TIME [epoch: 26.5 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.359093555157364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.359093555157364 | validation: 1.1685183481836912]
	TIME [epoch: 10.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.2779983261892691		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2779983261892691 | validation: 1.1345705465567206]
	TIME [epoch: 10.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.2359195556956373		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2359195556956373 | validation: 1.135301726153584]
	TIME [epoch: 10.4 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.2260812230992402		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2260812230992402 | validation: 1.0973207027954655]
	TIME [epoch: 10.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.1888176349908273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1888176349908273 | validation: 1.0563106625140992]
	TIME [epoch: 10.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.1653440213648043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1653440213648043 | validation: 1.0513409829141203]
	TIME [epoch: 10.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.1331011187379991		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1331011187379991 | validation: 1.0051491553881933]
	TIME [epoch: 10.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.0545692309575012		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0545692309575012 | validation: 0.9295749833777214]
	TIME [epoch: 10.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9833579864567467		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9833579864567467 | validation: 0.9260219302551889]
	TIME [epoch: 10.5 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9462884509963203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9462884509963203 | validation: 0.8111827906808914]
	TIME [epoch: 10.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8838241771020288		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8838241771020288 | validation: 0.7585462974713277]
	TIME [epoch: 10.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8046928645351369		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8046928645351369 | validation: 0.7077119707665501]
	TIME [epoch: 10.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7614820819879097		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7614820819879097 | validation: 0.7653211503295527]
	TIME [epoch: 10.4 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7197386603659796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7197386603659796 | validation: 0.6793538889521585]
	TIME [epoch: 10.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6542601482089738		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6542601482089738 | validation: 0.6924268852087199]
	TIME [epoch: 10.4 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6680059687309692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6680059687309692 | validation: 0.55711753303152]
	TIME [epoch: 10.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5599024564150589		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5599024564150589 | validation: 0.6280184708636354]
	TIME [epoch: 10.4 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5651467529913161		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5651467529913161 | validation: 0.5361387699127825]
	TIME [epoch: 10.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5257522333945486		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5257522333945486 | validation: 0.44916712888138105]
	TIME [epoch: 10.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5034543784939478		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5034543784939478 | validation: 0.4141653194998545]
	TIME [epoch: 10.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5147428694437436		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5147428694437436 | validation: 0.3897078427437848]
	TIME [epoch: 10.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.43917221119309907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43917221119309907 | validation: 0.3546777137951217]
	TIME [epoch: 10.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4094158008606708		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4094158008606708 | validation: 0.38527246874326726]
	TIME [epoch: 10.4 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5028789942577964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5028789942577964 | validation: 0.3410413911864496]
	TIME [epoch: 10.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4046145626620968		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4046145626620968 | validation: 0.38355288593258136]
	TIME [epoch: 10.4 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.401412415613823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.401412415613823 | validation: 0.3342449705254933]
	TIME [epoch: 10.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.38995814404024615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38995814404024615 | validation: 0.30492270994137205]
	TIME [epoch: 10.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3720176310864373		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3720176310864373 | validation: 0.3143163335915246]
	TIME [epoch: 10.4 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.39469412739954685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39469412739954685 | validation: 0.28799065302353316]
	TIME [epoch: 10.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37640116156916587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37640116156916587 | validation: 0.34596117629180256]
	TIME [epoch: 10.4 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3816072199858726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3816072199858726 | validation: 0.2980321197149231]
	TIME [epoch: 10.4 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37067341738923965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37067341738923965 | validation: 0.3090431287263721]
	TIME [epoch: 10.4 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34189118023474413		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34189118023474413 | validation: 0.28241979102416087]
	TIME [epoch: 10.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3771770835084755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3771770835084755 | validation: 0.2767235360396484]
	TIME [epoch: 10.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3365060837737854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3365060837737854 | validation: 0.28285210397680227]
	TIME [epoch: 10.4 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3434044229786186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3434044229786186 | validation: 0.29183461322909193]
	TIME [epoch: 10.4 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33775280774530403		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33775280774530403 | validation: 0.2818693538165979]
	TIME [epoch: 10.4 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3417943319665338		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3417943319665338 | validation: 0.2770701399916208]
	TIME [epoch: 10.4 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3364665860729798		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3364665860729798 | validation: 0.319015833480493]
	TIME [epoch: 10.4 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3214377428379025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3214377428379025 | validation: 0.2939812600350802]
	TIME [epoch: 10.4 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35915089836068353		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35915089836068353 | validation: 0.2655475287480732]
	TIME [epoch: 10.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3175244232560738		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3175244232560738 | validation: 0.278126814925611]
	TIME [epoch: 10.4 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.36547239196253795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36547239196253795 | validation: 0.26232177140083285]
	TIME [epoch: 10.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32466049086768234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32466049086768234 | validation: 0.2691696426734066]
	TIME [epoch: 10.4 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30815691985316845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30815691985316845 | validation: 0.2705880332186121]
	TIME [epoch: 10.4 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3264210297867707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3264210297867707 | validation: 0.2868572141015937]
	TIME [epoch: 10.4 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33840845970476874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33840845970476874 | validation: 0.3086540808427484]
	TIME [epoch: 10.4 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3360662931404413		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3360662931404413 | validation: 0.26064255420000854]
	TIME [epoch: 10.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31065517279088667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31065517279088667 | validation: 0.2700171746608875]
	TIME [epoch: 10.5 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3335510108295723		[learning rate: 0.0099705]
	Learning Rate: 0.00997052
	LOSS [training: 0.3335510108295723 | validation: 0.24520339933350238]
	TIME [epoch: 33.9 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31045227738430303		[learning rate: 0.0099353]
	Learning Rate: 0.00993527
	LOSS [training: 0.31045227738430303 | validation: 0.26524885276108273]
	TIME [epoch: 20 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31025054871267116		[learning rate: 0.0099001]
	Learning Rate: 0.00990013
	LOSS [training: 0.31025054871267116 | validation: 0.2518119753255116]
	TIME [epoch: 20.1 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31447884424612194		[learning rate: 0.0098651]
	Learning Rate: 0.00986512
	LOSS [training: 0.31447884424612194 | validation: 0.251401315593223]
	TIME [epoch: 20 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30449346840717245		[learning rate: 0.0098302]
	Learning Rate: 0.00983024
	LOSS [training: 0.30449346840717245 | validation: 0.25413008472528914]
	TIME [epoch: 20 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3116530624160889		[learning rate: 0.0097955]
	Learning Rate: 0.00979548
	LOSS [training: 0.3116530624160889 | validation: 0.2411850190784805]
	TIME [epoch: 20.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.313168254357608		[learning rate: 0.0097608]
	Learning Rate: 0.00976084
	LOSS [training: 0.313168254357608 | validation: 0.24935637486799705]
	TIME [epoch: 20.1 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31936703140351547		[learning rate: 0.0097263]
	Learning Rate: 0.00972632
	LOSS [training: 0.31936703140351547 | validation: 0.25529319852451954]
	TIME [epoch: 20.1 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2971781591852653		[learning rate: 0.0096919]
	Learning Rate: 0.00969193
	LOSS [training: 0.2971781591852653 | validation: 0.2950562285816001]
	TIME [epoch: 20 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3057219372686653		[learning rate: 0.0096577]
	Learning Rate: 0.00965766
	LOSS [training: 0.3057219372686653 | validation: 0.2470199498390902]
	TIME [epoch: 20 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29969382447052806		[learning rate: 0.0096235]
	Learning Rate: 0.00962351
	LOSS [training: 0.29969382447052806 | validation: 0.2423984726726267]
	TIME [epoch: 20 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2874006135801109		[learning rate: 0.0095895]
	Learning Rate: 0.00958948
	LOSS [training: 0.2874006135801109 | validation: 0.25400018967998783]
	TIME [epoch: 20 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30260697226143907		[learning rate: 0.0095556]
	Learning Rate: 0.00955557
	LOSS [training: 0.30260697226143907 | validation: 0.245349156354689]
	TIME [epoch: 20 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2895213051308129		[learning rate: 0.0095218]
	Learning Rate: 0.00952177
	LOSS [training: 0.2895213051308129 | validation: 0.2571376195721474]
	TIME [epoch: 20 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30525221129233393		[learning rate: 0.0094881]
	Learning Rate: 0.0094881
	LOSS [training: 0.30525221129233393 | validation: 0.24441992448483268]
	TIME [epoch: 20 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2881612608091781		[learning rate: 0.0094546]
	Learning Rate: 0.00945455
	LOSS [training: 0.2881612608091781 | validation: 0.24575131694614702]
	TIME [epoch: 20 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3046381887674389		[learning rate: 0.0094211]
	Learning Rate: 0.00942112
	LOSS [training: 0.3046381887674389 | validation: 0.23936130834805702]
	TIME [epoch: 20 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3036927555674251		[learning rate: 0.0093878]
	Learning Rate: 0.00938781
	LOSS [training: 0.3036927555674251 | validation: 0.24122319724280347]
	TIME [epoch: 20 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3063321044249135		[learning rate: 0.0093546]
	Learning Rate: 0.00935461
	LOSS [training: 0.3063321044249135 | validation: 0.23007126645907486]
	TIME [epoch: 20 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29667101312109806		[learning rate: 0.0093215]
	Learning Rate: 0.00932153
	LOSS [training: 0.29667101312109806 | validation: 0.2557176763488934]
	TIME [epoch: 20 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29494732505685234		[learning rate: 0.0092886]
	Learning Rate: 0.00928857
	LOSS [training: 0.29494732505685234 | validation: 0.24111312059729859]
	TIME [epoch: 20 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29451178988821997		[learning rate: 0.0092557]
	Learning Rate: 0.00925572
	LOSS [training: 0.29451178988821997 | validation: 0.23085199221644653]
	TIME [epoch: 20 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.289312731318595		[learning rate: 0.009223]
	Learning Rate: 0.00922299
	LOSS [training: 0.289312731318595 | validation: 0.23349002920301518]
	TIME [epoch: 20 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29690239424448944		[learning rate: 0.0091904]
	Learning Rate: 0.00919038
	LOSS [training: 0.29690239424448944 | validation: 0.24703721641762083]
	TIME [epoch: 20 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2959434535983494		[learning rate: 0.0091579]
	Learning Rate: 0.00915788
	LOSS [training: 0.2959434535983494 | validation: 0.2512132695939304]
	TIME [epoch: 20 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2894470525938269		[learning rate: 0.0091255]
	Learning Rate: 0.00912549
	LOSS [training: 0.2894470525938269 | validation: 0.23897343224284312]
	TIME [epoch: 20 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2918961796904665		[learning rate: 0.0090932]
	Learning Rate: 0.00909323
	LOSS [training: 0.2918961796904665 | validation: 0.23976540118265327]
	TIME [epoch: 20 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30236842427402294		[learning rate: 0.0090611]
	Learning Rate: 0.00906107
	LOSS [training: 0.30236842427402294 | validation: 0.22567236773505733]
	TIME [epoch: 20 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28617107638703193		[learning rate: 0.009029]
	Learning Rate: 0.00902903
	LOSS [training: 0.28617107638703193 | validation: 0.22758729732941402]
	TIME [epoch: 20.1 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28104292862892205		[learning rate: 0.0089971]
	Learning Rate: 0.0089971
	LOSS [training: 0.28104292862892205 | validation: 0.2330985590370515]
	TIME [epoch: 20.1 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.275332065376021		[learning rate: 0.0089653]
	Learning Rate: 0.00896528
	LOSS [training: 0.275332065376021 | validation: 0.26320811556994866]
	TIME [epoch: 20 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31396685173079397		[learning rate: 0.0089336]
	Learning Rate: 0.00893358
	LOSS [training: 0.31396685173079397 | validation: 0.2320055902532176]
	TIME [epoch: 20 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2775412680979773		[learning rate: 0.008902]
	Learning Rate: 0.00890199
	LOSS [training: 0.2775412680979773 | validation: 0.23440991658900012]
	TIME [epoch: 20 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27986129226926143		[learning rate: 0.0088705]
	Learning Rate: 0.00887051
	LOSS [training: 0.27986129226926143 | validation: 0.26491257486705305]
	TIME [epoch: 20 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2983276052672856		[learning rate: 0.0088391]
	Learning Rate: 0.00883914
	LOSS [training: 0.2983276052672856 | validation: 0.24939382941991659]
	TIME [epoch: 20 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29233271536619215		[learning rate: 0.0088079]
	Learning Rate: 0.00880789
	LOSS [training: 0.29233271536619215 | validation: 0.22729051782844714]
	TIME [epoch: 20.1 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2817590357811311		[learning rate: 0.0087767]
	Learning Rate: 0.00877674
	LOSS [training: 0.2817590357811311 | validation: 0.23334327757053322]
	TIME [epoch: 20.1 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2812394251871429		[learning rate: 0.0087457]
	Learning Rate: 0.00874571
	LOSS [training: 0.2812394251871429 | validation: 0.22615306504029237]
	TIME [epoch: 20 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28445996671531726		[learning rate: 0.0087148]
	Learning Rate: 0.00871478
	LOSS [training: 0.28445996671531726 | validation: 0.2420851668201684]
	TIME [epoch: 20 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29531659764779566		[learning rate: 0.008684]
	Learning Rate: 0.00868396
	LOSS [training: 0.29531659764779566 | validation: 0.24048382902088655]
	TIME [epoch: 20 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2862132077938549		[learning rate: 0.0086533]
	Learning Rate: 0.00865326
	LOSS [training: 0.2862132077938549 | validation: 0.22993045497333114]
	TIME [epoch: 20 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2875538575064036		[learning rate: 0.0086227]
	Learning Rate: 0.00862265
	LOSS [training: 0.2875538575064036 | validation: 0.2205829511728675]
	TIME [epoch: 20 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27326941929666876		[learning rate: 0.0085922]
	Learning Rate: 0.00859216
	LOSS [training: 0.27326941929666876 | validation: 0.23705852723810442]
	TIME [epoch: 20.1 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27294314231146943		[learning rate: 0.0085618]
	Learning Rate: 0.00856178
	LOSS [training: 0.27294314231146943 | validation: 0.22735037444339082]
	TIME [epoch: 20.1 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28486525423965253		[learning rate: 0.0085315]
	Learning Rate: 0.0085315
	LOSS [training: 0.28486525423965253 | validation: 0.22963330330700565]
	TIME [epoch: 20 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27335414849962064		[learning rate: 0.0085013]
	Learning Rate: 0.00850134
	LOSS [training: 0.27335414849962064 | validation: 0.21631762777759037]
	TIME [epoch: 20 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2893364994700443		[learning rate: 0.0084713]
	Learning Rate: 0.00847127
	LOSS [training: 0.2893364994700443 | validation: 0.2242569230870683]
	TIME [epoch: 20.1 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27242796784335394		[learning rate: 0.0084413]
	Learning Rate: 0.00844132
	LOSS [training: 0.27242796784335394 | validation: 0.23065072058933636]
	TIME [epoch: 20.1 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28538206076165834		[learning rate: 0.0084115]
	Learning Rate: 0.00841147
	LOSS [training: 0.28538206076165834 | validation: 0.21947037326466248]
	TIME [epoch: 20 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27138364788065256		[learning rate: 0.0083817]
	Learning Rate: 0.00838172
	LOSS [training: 0.27138364788065256 | validation: 0.22365278927648094]
	TIME [epoch: 20.1 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27582088671580024		[learning rate: 0.0083521]
	Learning Rate: 0.00835208
	LOSS [training: 0.27582088671580024 | validation: 0.22590430422827276]
	TIME [epoch: 20.1 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27944378624484606		[learning rate: 0.0083225]
	Learning Rate: 0.00832255
	LOSS [training: 0.27944378624484606 | validation: 0.2347633600447895]
	TIME [epoch: 20.1 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2778661276236682		[learning rate: 0.0082931]
	Learning Rate: 0.00829312
	LOSS [training: 0.2778661276236682 | validation: 0.22765758211104967]
	TIME [epoch: 20.1 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28649253695698007		[learning rate: 0.0082638]
	Learning Rate: 0.00826379
	LOSS [training: 0.28649253695698007 | validation: 0.24687583588796672]
	TIME [epoch: 20.1 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29484172951964754		[learning rate: 0.0082346]
	Learning Rate: 0.00823457
	LOSS [training: 0.29484172951964754 | validation: 0.21590536705741017]
	TIME [epoch: 20.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_105.pth
	Model improved!!!
EPOCH 106/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27195665184194484		[learning rate: 0.0082055]
	Learning Rate: 0.00820545
	LOSS [training: 0.27195665184194484 | validation: 0.2175725305534108]
	TIME [epoch: 20 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2724007612379636		[learning rate: 0.0081764]
	Learning Rate: 0.00817644
	LOSS [training: 0.2724007612379636 | validation: 0.2255105391238709]
	TIME [epoch: 20.1 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2729151832989359		[learning rate: 0.0081475]
	Learning Rate: 0.00814752
	LOSS [training: 0.2729151832989359 | validation: 0.22068492378422128]
	TIME [epoch: 20 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2769808814670951		[learning rate: 0.0081187]
	Learning Rate: 0.00811871
	LOSS [training: 0.2769808814670951 | validation: 0.22465686032021254]
	TIME [epoch: 20.1 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27313942833985494		[learning rate: 0.00809]
	Learning Rate: 0.00809
	LOSS [training: 0.27313942833985494 | validation: 0.22384481696303632]
	TIME [epoch: 20 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26995483879262494		[learning rate: 0.0080614]
	Learning Rate: 0.0080614
	LOSS [training: 0.26995483879262494 | validation: 0.236006915592852]
	TIME [epoch: 20.1 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2713626226779888		[learning rate: 0.0080329]
	Learning Rate: 0.00803289
	LOSS [training: 0.2713626226779888 | validation: 0.21960036139503175]
	TIME [epoch: 20 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2673210108338135		[learning rate: 0.0080045]
	Learning Rate: 0.00800448
	LOSS [training: 0.2673210108338135 | validation: 0.23211310758559875]
	TIME [epoch: 20.1 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2726353987044388		[learning rate: 0.0079762]
	Learning Rate: 0.00797618
	LOSS [training: 0.2726353987044388 | validation: 0.22825269803715456]
	TIME [epoch: 20 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27187143726051016		[learning rate: 0.007948]
	Learning Rate: 0.00794797
	LOSS [training: 0.27187143726051016 | validation: 0.2290900284021709]
	TIME [epoch: 20 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2785178616401472		[learning rate: 0.0079199]
	Learning Rate: 0.00791987
	LOSS [training: 0.2785178616401472 | validation: 0.2199330748652577]
	TIME [epoch: 20 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26970140197787523		[learning rate: 0.0078919]
	Learning Rate: 0.00789186
	LOSS [training: 0.26970140197787523 | validation: 0.22358422658787536]
	TIME [epoch: 20 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.263977564875512		[learning rate: 0.007864]
	Learning Rate: 0.00786395
	LOSS [training: 0.263977564875512 | validation: 0.23445143595088105]
	TIME [epoch: 20.1 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.271393911791496		[learning rate: 0.0078361]
	Learning Rate: 0.00783615
	LOSS [training: 0.271393911791496 | validation: 0.21608505174231332]
	TIME [epoch: 20 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27931432922949867		[learning rate: 0.0078084]
	Learning Rate: 0.00780844
	LOSS [training: 0.27931432922949867 | validation: 0.24054347325007944]
	TIME [epoch: 20 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2778233408716186		[learning rate: 0.0077808]
	Learning Rate: 0.00778083
	LOSS [training: 0.2778233408716186 | validation: 0.22122318458373255]
	TIME [epoch: 20 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26715880435526956		[learning rate: 0.0077533]
	Learning Rate: 0.00775331
	LOSS [training: 0.26715880435526956 | validation: 0.22116492943459426]
	TIME [epoch: 20.1 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.274661510790515		[learning rate: 0.0077259]
	Learning Rate: 0.00772589
	LOSS [training: 0.274661510790515 | validation: 0.2204649026518981]
	TIME [epoch: 20 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2629845014908619		[learning rate: 0.0076986]
	Learning Rate: 0.00769857
	LOSS [training: 0.2629845014908619 | validation: 0.2282539325779538]
	TIME [epoch: 20 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2835291593092505		[learning rate: 0.0076714]
	Learning Rate: 0.00767135
	LOSS [training: 0.2835291593092505 | validation: 0.2254994636593389]
	TIME [epoch: 20 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28306809609561984		[learning rate: 0.0076442]
	Learning Rate: 0.00764422
	LOSS [training: 0.28306809609561984 | validation: 0.2205027642621288]
	TIME [epoch: 20 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2654719696169763		[learning rate: 0.0076172]
	Learning Rate: 0.00761719
	LOSS [training: 0.2654719696169763 | validation: 0.22358728273526185]
	TIME [epoch: 20.1 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2621601539594676		[learning rate: 0.0075903]
	Learning Rate: 0.00759025
	LOSS [training: 0.2621601539594676 | validation: 0.21991433755808903]
	TIME [epoch: 20 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26349755007723863		[learning rate: 0.0075634]
	Learning Rate: 0.00756341
	LOSS [training: 0.26349755007723863 | validation: 0.21397771398063764]
	TIME [epoch: 20 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_129.pth
	Model improved!!!
EPOCH 130/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26831399932588407		[learning rate: 0.0075367]
	Learning Rate: 0.00753667
	LOSS [training: 0.26831399932588407 | validation: 0.21208942323283808]
	TIME [epoch: 20 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_130.pth
	Model improved!!!
EPOCH 131/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27224985701111654		[learning rate: 0.00751]
	Learning Rate: 0.00751002
	LOSS [training: 0.27224985701111654 | validation: 0.22769957491296283]
	TIME [epoch: 20.1 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27864269860614765		[learning rate: 0.0074835]
	Learning Rate: 0.00748346
	LOSS [training: 0.27864269860614765 | validation: 0.24508079858503473]
	TIME [epoch: 20.1 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2757071627943883		[learning rate: 0.007457]
	Learning Rate: 0.007457
	LOSS [training: 0.2757071627943883 | validation: 0.21573133767668273]
	TIME [epoch: 20.1 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27143740757626333		[learning rate: 0.0074306]
	Learning Rate: 0.00743063
	LOSS [training: 0.27143740757626333 | validation: 0.22696689672384568]
	TIME [epoch: 20.1 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27879260046077686		[learning rate: 0.0074044]
	Learning Rate: 0.00740435
	LOSS [training: 0.27879260046077686 | validation: 0.21767214601290813]
	TIME [epoch: 20.1 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2698029325424938		[learning rate: 0.0073782]
	Learning Rate: 0.00737817
	LOSS [training: 0.2698029325424938 | validation: 0.21475569528432342]
	TIME [epoch: 20.1 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25830814691587295		[learning rate: 0.0073521]
	Learning Rate: 0.00735208
	LOSS [training: 0.25830814691587295 | validation: 0.22822045098479177]
	TIME [epoch: 20 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27338347792978107		[learning rate: 0.0073261]
	Learning Rate: 0.00732608
	LOSS [training: 0.27338347792978107 | validation: 0.2147332263649046]
	TIME [epoch: 20.1 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.263285736534933		[learning rate: 0.0073002]
	Learning Rate: 0.00730018
	LOSS [training: 0.263285736534933 | validation: 0.23004909733256151]
	TIME [epoch: 20 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27592874351412		[learning rate: 0.0072744]
	Learning Rate: 0.00727436
	LOSS [training: 0.27592874351412 | validation: 0.21953698715699915]
	TIME [epoch: 20 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2695086320338508		[learning rate: 0.0072486]
	Learning Rate: 0.00724864
	LOSS [training: 0.2695086320338508 | validation: 0.2153308314550988]
	TIME [epoch: 20 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25817920788684295		[learning rate: 0.007223]
	Learning Rate: 0.007223
	LOSS [training: 0.25817920788684295 | validation: 0.21491467052333033]
	TIME [epoch: 20 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2624797288365782		[learning rate: 0.0071975]
	Learning Rate: 0.00719746
	LOSS [training: 0.2624797288365782 | validation: 0.24068740476300907]
	TIME [epoch: 20 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26791527613732014		[learning rate: 0.007172]
	Learning Rate: 0.00717201
	LOSS [training: 0.26791527613732014 | validation: 0.21833539175673553]
	TIME [epoch: 20 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2604516055297017		[learning rate: 0.0071467]
	Learning Rate: 0.00714665
	LOSS [training: 0.2604516055297017 | validation: 0.22170773227192883]
	TIME [epoch: 20.1 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2682612874007726		[learning rate: 0.0071214]
	Learning Rate: 0.00712138
	LOSS [training: 0.2682612874007726 | validation: 0.22354613246365473]
	TIME [epoch: 20 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26991664143694044		[learning rate: 0.0070962]
	Learning Rate: 0.0070962
	LOSS [training: 0.26991664143694044 | validation: 0.2161497437667918]
	TIME [epoch: 20.1 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25568918070155383		[learning rate: 0.0070711]
	Learning Rate: 0.0070711
	LOSS [training: 0.25568918070155383 | validation: 0.21975135231084963]
	TIME [epoch: 20 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2774430273768376		[learning rate: 0.0070461]
	Learning Rate: 0.0070461
	LOSS [training: 0.2774430273768376 | validation: 0.2246043421724803]
	TIME [epoch: 20 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26463158315843405		[learning rate: 0.0070212]
	Learning Rate: 0.00702118
	LOSS [training: 0.26463158315843405 | validation: 0.22318216610341352]
	TIME [epoch: 20 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2625321955772149		[learning rate: 0.0069964]
	Learning Rate: 0.00699635
	LOSS [training: 0.2625321955772149 | validation: 0.21621850292292222]
	TIME [epoch: 20 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2687694677164865		[learning rate: 0.0069716]
	Learning Rate: 0.00697161
	LOSS [training: 0.2687694677164865 | validation: 0.2222318584911725]
	TIME [epoch: 20 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2581960462854593		[learning rate: 0.006947]
	Learning Rate: 0.00694696
	LOSS [training: 0.2581960462854593 | validation: 0.22733639100597766]
	TIME [epoch: 20 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26544355945100867		[learning rate: 0.0069224]
	Learning Rate: 0.00692239
	LOSS [training: 0.26544355945100867 | validation: 0.22348398591380375]
	TIME [epoch: 20.1 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28163295992693876		[learning rate: 0.0068979]
	Learning Rate: 0.00689792
	LOSS [training: 0.28163295992693876 | validation: 0.22413785405491854]
	TIME [epoch: 20 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25980897866436037		[learning rate: 0.0068735]
	Learning Rate: 0.00687352
	LOSS [training: 0.25980897866436037 | validation: 0.2136140163036416]
	TIME [epoch: 20.1 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2718814351109727		[learning rate: 0.0068492]
	Learning Rate: 0.00684922
	LOSS [training: 0.2718814351109727 | validation: 0.21993105439713104]
	TIME [epoch: 20 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2686653902734563		[learning rate: 0.006825]
	Learning Rate: 0.006825
	LOSS [training: 0.2686653902734563 | validation: 0.21795691508419993]
	TIME [epoch: 20 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26113260958470125		[learning rate: 0.0068009]
	Learning Rate: 0.00680086
	LOSS [training: 0.26113260958470125 | validation: 0.21929000583559652]
	TIME [epoch: 20 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26970936299573134		[learning rate: 0.0067768]
	Learning Rate: 0.00677681
	LOSS [training: 0.26970936299573134 | validation: 0.21907151723769477]
	TIME [epoch: 20 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2637964250102691		[learning rate: 0.0067529]
	Learning Rate: 0.00675285
	LOSS [training: 0.2637964250102691 | validation: 0.21932098514273218]
	TIME [epoch: 20 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2679632290738922		[learning rate: 0.006729]
	Learning Rate: 0.00672897
	LOSS [training: 0.2679632290738922 | validation: 0.2103748397549213]
	TIME [epoch: 20 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_162.pth
	Model improved!!!
EPOCH 163/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2610474355327959		[learning rate: 0.0067052]
	Learning Rate: 0.00670518
	LOSS [training: 0.2610474355327959 | validation: 0.21432892499801975]
	TIME [epoch: 20.2 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25596648807994216		[learning rate: 0.0066815]
	Learning Rate: 0.00668147
	LOSS [training: 0.25596648807994216 | validation: 0.22828508267747266]
	TIME [epoch: 20.2 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2670855602942047		[learning rate: 0.0066578]
	Learning Rate: 0.00665784
	LOSS [training: 0.2670855602942047 | validation: 0.22218053349109274]
	TIME [epoch: 20.2 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27118899632065524		[learning rate: 0.0066343]
	Learning Rate: 0.0066343
	LOSS [training: 0.27118899632065524 | validation: 0.21516207626262923]
	TIME [epoch: 20.2 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26549061251475864		[learning rate: 0.0066108]
	Learning Rate: 0.00661084
	LOSS [training: 0.26549061251475864 | validation: 0.22231534694135008]
	TIME [epoch: 20.2 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2774637254087532		[learning rate: 0.0065875]
	Learning Rate: 0.00658746
	LOSS [training: 0.2774637254087532 | validation: 0.22036288254210615]
	TIME [epoch: 20.2 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25965379191127713		[learning rate: 0.0065642]
	Learning Rate: 0.00656416
	LOSS [training: 0.25965379191127713 | validation: 0.21660750611464855]
	TIME [epoch: 20.2 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2690800615788767		[learning rate: 0.006541]
	Learning Rate: 0.00654095
	LOSS [training: 0.2690800615788767 | validation: 0.2190878674047164]
	TIME [epoch: 20.2 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2621082702649971		[learning rate: 0.0065178]
	Learning Rate: 0.00651782
	LOSS [training: 0.2621082702649971 | validation: 0.21591826246858248]
	TIME [epoch: 20.2 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26208133873401346		[learning rate: 0.0064948]
	Learning Rate: 0.00649477
	LOSS [training: 0.26208133873401346 | validation: 0.22797517818488364]
	TIME [epoch: 20.1 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26923158363795846		[learning rate: 0.0064718]
	Learning Rate: 0.00647181
	LOSS [training: 0.26923158363795846 | validation: 0.2107953791962637]
	TIME [epoch: 20.2 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25703917534447296		[learning rate: 0.0064489]
	Learning Rate: 0.00644892
	LOSS [training: 0.25703917534447296 | validation: 0.21688925575784918]
	TIME [epoch: 20.2 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26077060342805364		[learning rate: 0.0064261]
	Learning Rate: 0.00642612
	LOSS [training: 0.26077060342805364 | validation: 0.2204771698840086]
	TIME [epoch: 20.1 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26253922981796024		[learning rate: 0.0064034]
	Learning Rate: 0.00640339
	LOSS [training: 0.26253922981796024 | validation: 0.22732397540887112]
	TIME [epoch: 20.2 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25966797001823666		[learning rate: 0.0063808]
	Learning Rate: 0.00638075
	LOSS [training: 0.25966797001823666 | validation: 0.21563160581435642]
	TIME [epoch: 20.1 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2616968250391892		[learning rate: 0.0063582]
	Learning Rate: 0.00635819
	LOSS [training: 0.2616968250391892 | validation: 0.21820907698308503]
	TIME [epoch: 20.2 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26119264413890386		[learning rate: 0.0063357]
	Learning Rate: 0.0063357
	LOSS [training: 0.26119264413890386 | validation: 0.22172971285183046]
	TIME [epoch: 20.2 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26092384944854996		[learning rate: 0.0063133]
	Learning Rate: 0.0063133
	LOSS [training: 0.26092384944854996 | validation: 0.22202783021995898]
	TIME [epoch: 20.1 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.260040956569391		[learning rate: 0.006291]
	Learning Rate: 0.00629097
	LOSS [training: 0.260040956569391 | validation: 0.21631209318156325]
	TIME [epoch: 20.2 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2584106266406853		[learning rate: 0.0062687]
	Learning Rate: 0.00626873
	LOSS [training: 0.2584106266406853 | validation: 0.21243425884725253]
	TIME [epoch: 20.1 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2538526316059662		[learning rate: 0.0062466]
	Learning Rate: 0.00624656
	LOSS [training: 0.2538526316059662 | validation: 0.22702691098825464]
	TIME [epoch: 20.2 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2590630825736447		[learning rate: 0.0062245]
	Learning Rate: 0.00622447
	LOSS [training: 0.2590630825736447 | validation: 0.21300534329497225]
	TIME [epoch: 20.1 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25639830955290793		[learning rate: 0.0062025]
	Learning Rate: 0.00620246
	LOSS [training: 0.25639830955290793 | validation: 0.22623486510523377]
	TIME [epoch: 20.2 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2629499585983786		[learning rate: 0.0061805]
	Learning Rate: 0.00618053
	LOSS [training: 0.2629499585983786 | validation: 0.21650942194479642]
	TIME [epoch: 20.1 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25325752263783524		[learning rate: 0.0061587]
	Learning Rate: 0.00615867
	LOSS [training: 0.25325752263783524 | validation: 0.2200408647377346]
	TIME [epoch: 20.1 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26093747143521895		[learning rate: 0.0061369]
	Learning Rate: 0.00613689
	LOSS [training: 0.26093747143521895 | validation: 0.21796409595348143]
	TIME [epoch: 20.2 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2635815216632063		[learning rate: 0.0061152]
	Learning Rate: 0.00611519
	LOSS [training: 0.2635815216632063 | validation: 0.21561304556494001]
	TIME [epoch: 20.2 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26171307803489485		[learning rate: 0.0060936]
	Learning Rate: 0.00609357
	LOSS [training: 0.26171307803489485 | validation: 0.22471457642199208]
	TIME [epoch: 20.2 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2564741203094832		[learning rate: 0.006072]
	Learning Rate: 0.00607202
	LOSS [training: 0.2564741203094832 | validation: 0.21236386211134003]
	TIME [epoch: 20.2 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2574098787704035		[learning rate: 0.0060505]
	Learning Rate: 0.00605055
	LOSS [training: 0.2574098787704035 | validation: 0.2170041190637771]
	TIME [epoch: 20.1 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2680000954176429		[learning rate: 0.0060292]
	Learning Rate: 0.00602915
	LOSS [training: 0.2680000954176429 | validation: 0.21563593841794398]
	TIME [epoch: 20.2 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25565903456295813		[learning rate: 0.0060078]
	Learning Rate: 0.00600783
	LOSS [training: 0.25565903456295813 | validation: 0.21804801634654628]
	TIME [epoch: 20.2 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2577174226368288		[learning rate: 0.0059866]
	Learning Rate: 0.00598659
	LOSS [training: 0.2577174226368288 | validation: 0.21725993519154313]
	TIME [epoch: 20.2 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25647219971246205		[learning rate: 0.0059654]
	Learning Rate: 0.00596542
	LOSS [training: 0.25647219971246205 | validation: 0.22152270789961864]
	TIME [epoch: 20.2 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25668200782579326		[learning rate: 0.0059443]
	Learning Rate: 0.00594433
	LOSS [training: 0.25668200782579326 | validation: 0.21212711826989458]
	TIME [epoch: 20.2 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2593827054594992		[learning rate: 0.0059233]
	Learning Rate: 0.0059233
	LOSS [training: 0.2593827054594992 | validation: 0.22881426610519892]
	TIME [epoch: 20.2 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2712709551833147		[learning rate: 0.0059024]
	Learning Rate: 0.00590236
	LOSS [training: 0.2712709551833147 | validation: 0.22318404753784496]
	TIME [epoch: 20.2 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2530445278455632		[learning rate: 0.0058815]
	Learning Rate: 0.00588149
	LOSS [training: 0.2530445278455632 | validation: 0.21669905860047428]
	TIME [epoch: 20.1 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25720591640682383		[learning rate: 0.0058607]
	Learning Rate: 0.00586069
	LOSS [training: 0.25720591640682383 | validation: 0.21611045257803224]
	TIME [epoch: 20 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26452151279893726		[learning rate: 0.00584]
	Learning Rate: 0.00583996
	LOSS [training: 0.26452151279893726 | validation: 0.2184093868896412]
	TIME [epoch: 20 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2655752257653962		[learning rate: 0.0058193]
	Learning Rate: 0.00581931
	LOSS [training: 0.2655752257653962 | validation: 0.21750484131990291]
	TIME [epoch: 20 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25909386159740094		[learning rate: 0.0057987]
	Learning Rate: 0.00579874
	LOSS [training: 0.25909386159740094 | validation: 0.211467148734082]
	TIME [epoch: 20.2 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2528514268526055		[learning rate: 0.0057782]
	Learning Rate: 0.00577823
	LOSS [training: 0.2528514268526055 | validation: 0.2129371710163225]
	TIME [epoch: 20.2 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2594471681418202		[learning rate: 0.0057578]
	Learning Rate: 0.0057578
	LOSS [training: 0.2594471681418202 | validation: 0.2190908088499272]
	TIME [epoch: 20.2 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25635965728225185		[learning rate: 0.0057374]
	Learning Rate: 0.00573744
	LOSS [training: 0.25635965728225185 | validation: 0.21627034534455167]
	TIME [epoch: 20.1 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25991834737940195		[learning rate: 0.0057171]
	Learning Rate: 0.00571715
	LOSS [training: 0.25991834737940195 | validation: 0.21757383397242255]
	TIME [epoch: 20.1 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2544920479305744		[learning rate: 0.0056969]
	Learning Rate: 0.00569693
	LOSS [training: 0.2544920479305744 | validation: 0.21445657332365822]
	TIME [epoch: 20.2 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2536640283986728		[learning rate: 0.0056768]
	Learning Rate: 0.00567679
	LOSS [training: 0.2536640283986728 | validation: 0.21923848286841924]
	TIME [epoch: 20.1 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2594071019667477		[learning rate: 0.0056567]
	Learning Rate: 0.00565671
	LOSS [training: 0.2594071019667477 | validation: 0.22588567894174597]
	TIME [epoch: 20.2 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27094870868854953		[learning rate: 0.0056367]
	Learning Rate: 0.00563671
	LOSS [training: 0.27094870868854953 | validation: 0.21183147671355446]
	TIME [epoch: 20.2 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26219297163521615		[learning rate: 0.0056168]
	Learning Rate: 0.00561678
	LOSS [training: 0.26219297163521615 | validation: 0.21429934110221635]
	TIME [epoch: 20.1 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2585056733122095		[learning rate: 0.0055969]
	Learning Rate: 0.00559691
	LOSS [training: 0.2585056733122095 | validation: 0.20968462938201043]
	TIME [epoch: 20.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_214.pth
	Model improved!!!
EPOCH 215/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2558921239564995		[learning rate: 0.0055771]
	Learning Rate: 0.00557712
	LOSS [training: 0.2558921239564995 | validation: 0.21124703394445454]
	TIME [epoch: 20.1 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25310228262258133		[learning rate: 0.0055574]
	Learning Rate: 0.0055574
	LOSS [training: 0.25310228262258133 | validation: 0.22467875957906921]
	TIME [epoch: 20 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2551383197106064		[learning rate: 0.0055378]
	Learning Rate: 0.00553775
	LOSS [training: 0.2551383197106064 | validation: 0.214365393682372]
	TIME [epoch: 20 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25219614604729984		[learning rate: 0.0055182]
	Learning Rate: 0.00551817
	LOSS [training: 0.25219614604729984 | validation: 0.21373113720628206]
	TIME [epoch: 20.1 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25222763161816814		[learning rate: 0.0054987]
	Learning Rate: 0.00549865
	LOSS [training: 0.25222763161816814 | validation: 0.2210452883050408]
	TIME [epoch: 20.1 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2593248014855779		[learning rate: 0.0054792]
	Learning Rate: 0.00547921
	LOSS [training: 0.2593248014855779 | validation: 0.20985316215475258]
	TIME [epoch: 20.1 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2584618501214851		[learning rate: 0.0054598]
	Learning Rate: 0.00545983
	LOSS [training: 0.2584618501214851 | validation: 0.2148244938715796]
	TIME [epoch: 20.1 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25711764081169164		[learning rate: 0.0054405]
	Learning Rate: 0.00544053
	LOSS [training: 0.25711764081169164 | validation: 0.2256289678154208]
	TIME [epoch: 20.1 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2568406448394786		[learning rate: 0.0054213]
	Learning Rate: 0.00542129
	LOSS [training: 0.2568406448394786 | validation: 0.2117334277871019]
	TIME [epoch: 20.1 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2533338531555401		[learning rate: 0.0054021]
	Learning Rate: 0.00540212
	LOSS [training: 0.2533338531555401 | validation: 0.21683833778143075]
	TIME [epoch: 20.1 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25367568818333597		[learning rate: 0.005383]
	Learning Rate: 0.00538302
	LOSS [training: 0.25367568818333597 | validation: 0.22653641774706862]
	TIME [epoch: 20.1 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26286911311671046		[learning rate: 0.005364]
	Learning Rate: 0.00536398
	LOSS [training: 0.26286911311671046 | validation: 0.21388868964071892]
	TIME [epoch: 20.1 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25088820671052603		[learning rate: 0.005345]
	Learning Rate: 0.00534501
	LOSS [training: 0.25088820671052603 | validation: 0.21871624548205154]
	TIME [epoch: 20.1 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25581448707057386		[learning rate: 0.0053261]
	Learning Rate: 0.00532611
	LOSS [training: 0.25581448707057386 | validation: 0.21849448296066382]
	TIME [epoch: 20.1 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2581335996690078		[learning rate: 0.0053073]
	Learning Rate: 0.00530728
	LOSS [training: 0.2581335996690078 | validation: 0.21687423801000366]
	TIME [epoch: 20.1 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25591165156577944		[learning rate: 0.0052885]
	Learning Rate: 0.00528851
	LOSS [training: 0.25591165156577944 | validation: 0.21172563516000514]
	TIME [epoch: 20.1 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2532681316479349		[learning rate: 0.0052698]
	Learning Rate: 0.00526981
	LOSS [training: 0.2532681316479349 | validation: 0.22223080374773238]
	TIME [epoch: 20.2 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25848983240347606		[learning rate: 0.0052512]
	Learning Rate: 0.00525117
	LOSS [training: 0.25848983240347606 | validation: 0.2115950388061792]
	TIME [epoch: 20.1 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25926071175685567		[learning rate: 0.0052326]
	Learning Rate: 0.0052326
	LOSS [training: 0.25926071175685567 | validation: 0.21751469986879482]
	TIME [epoch: 20.1 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2512431723245798		[learning rate: 0.0052141]
	Learning Rate: 0.0052141
	LOSS [training: 0.2512431723245798 | validation: 0.21798379553405436]
	TIME [epoch: 20.1 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25912122846837154		[learning rate: 0.0051957]
	Learning Rate: 0.00519566
	LOSS [training: 0.25912122846837154 | validation: 0.21935942193833774]
	TIME [epoch: 20.1 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25374103846924273		[learning rate: 0.0051773]
	Learning Rate: 0.00517729
	LOSS [training: 0.25374103846924273 | validation: 0.2157515465157985]
	TIME [epoch: 20.1 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25786334526495036		[learning rate: 0.005159]
	Learning Rate: 0.00515898
	LOSS [training: 0.25786334526495036 | validation: 0.21666902024411167]
	TIME [epoch: 20.1 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2568597948253641		[learning rate: 0.0051407]
	Learning Rate: 0.00514074
	LOSS [training: 0.2568597948253641 | validation: 0.21948524661393817]
	TIME [epoch: 20.1 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26181599119743854		[learning rate: 0.0051226]
	Learning Rate: 0.00512256
	LOSS [training: 0.26181599119743854 | validation: 0.21111001463676637]
	TIME [epoch: 20.1 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2546774413501392		[learning rate: 0.0051044]
	Learning Rate: 0.00510445
	LOSS [training: 0.2546774413501392 | validation: 0.21657055310868306]
	TIME [epoch: 20.1 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2529070473934851		[learning rate: 0.0050864]
	Learning Rate: 0.0050864
	LOSS [training: 0.2529070473934851 | validation: 0.2186066235066691]
	TIME [epoch: 20.1 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2599574065701589		[learning rate: 0.0050684]
	Learning Rate: 0.00506841
	LOSS [training: 0.2599574065701589 | validation: 0.215048829468153]
	TIME [epoch: 20.1 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2558293457054935		[learning rate: 0.0050505]
	Learning Rate: 0.00505049
	LOSS [training: 0.2558293457054935 | validation: 0.21523666851798917]
	TIME [epoch: 20.1 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2458707802862051		[learning rate: 0.0050326]
	Learning Rate: 0.00503263
	LOSS [training: 0.2458707802862051 | validation: 0.21420133632261354]
	TIME [epoch: 20.1 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2487581912012001		[learning rate: 0.0050148]
	Learning Rate: 0.00501483
	LOSS [training: 0.2487581912012001 | validation: 0.22045542491717846]
	TIME [epoch: 20.1 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26323567632870715		[learning rate: 0.0049971]
	Learning Rate: 0.0049971
	LOSS [training: 0.26323567632870715 | validation: 0.21748995832521745]
	TIME [epoch: 20.1 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26353855329569864		[learning rate: 0.0049794]
	Learning Rate: 0.00497943
	LOSS [training: 0.26353855329569864 | validation: 0.218164996837764]
	TIME [epoch: 20.1 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25250131834265777		[learning rate: 0.0049618]
	Learning Rate: 0.00496182
	LOSS [training: 0.25250131834265777 | validation: 0.21581977075817366]
	TIME [epoch: 20.1 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2521523960008371		[learning rate: 0.0049443]
	Learning Rate: 0.00494427
	LOSS [training: 0.2521523960008371 | validation: 0.2240761688538772]
	TIME [epoch: 20.1 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.252335873031806		[learning rate: 0.0049268]
	Learning Rate: 0.00492679
	LOSS [training: 0.252335873031806 | validation: 0.21966830648538965]
	TIME [epoch: 20 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2586021956866738		[learning rate: 0.0049094]
	Learning Rate: 0.00490937
	LOSS [training: 0.2586021956866738 | validation: 0.21977945038943245]
	TIME [epoch: 20.1 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2569026955489178		[learning rate: 0.004892]
	Learning Rate: 0.00489201
	LOSS [training: 0.2569026955489178 | validation: 0.22002077028092812]
	TIME [epoch: 20.1 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2642814462368847		[learning rate: 0.0048747]
	Learning Rate: 0.00487471
	LOSS [training: 0.2642814462368847 | validation: 0.21450895405023535]
	TIME [epoch: 20.1 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2538943060996562		[learning rate: 0.0048575]
	Learning Rate: 0.00485747
	LOSS [training: 0.2538943060996562 | validation: 0.21446047820101027]
	TIME [epoch: 20.1 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25416805933143155		[learning rate: 0.0048403]
	Learning Rate: 0.00484029
	LOSS [training: 0.25416805933143155 | validation: 0.21185537271362237]
	TIME [epoch: 20.1 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25292352933475704		[learning rate: 0.0048232]
	Learning Rate: 0.00482318
	LOSS [training: 0.25292352933475704 | validation: 0.22129629303525142]
	TIME [epoch: 20.1 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.256364005605453		[learning rate: 0.0048061]
	Learning Rate: 0.00480612
	LOSS [training: 0.256364005605453 | validation: 0.2147257241639607]
	TIME [epoch: 20.1 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24961426478717222		[learning rate: 0.0047891]
	Learning Rate: 0.00478913
	LOSS [training: 0.24961426478717222 | validation: 0.21394824509313032]
	TIME [epoch: 20.1 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2479452186509461		[learning rate: 0.0047722]
	Learning Rate: 0.00477219
	LOSS [training: 0.2479452186509461 | validation: 0.21759686244101709]
	TIME [epoch: 20.1 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25455593912917823		[learning rate: 0.0047553]
	Learning Rate: 0.00475532
	LOSS [training: 0.25455593912917823 | validation: 0.22271613117034791]
	TIME [epoch: 20.1 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2550748242450134		[learning rate: 0.0047385]
	Learning Rate: 0.0047385
	LOSS [training: 0.2550748242450134 | validation: 0.2141819158716612]
	TIME [epoch: 20.1 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2509720511997077		[learning rate: 0.0047217]
	Learning Rate: 0.00472175
	LOSS [training: 0.2509720511997077 | validation: 0.2162555694487342]
	TIME [epoch: 20.1 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24878722573011433		[learning rate: 0.004705]
	Learning Rate: 0.00470505
	LOSS [training: 0.24878722573011433 | validation: 0.2124785704928033]
	TIME [epoch: 20.1 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2479219780034804		[learning rate: 0.0046884]
	Learning Rate: 0.00468841
	LOSS [training: 0.2479219780034804 | validation: 0.21637545414367215]
	TIME [epoch: 20.1 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.255707270243418		[learning rate: 0.0046718]
	Learning Rate: 0.00467183
	LOSS [training: 0.255707270243418 | validation: 0.21254931828150697]
	TIME [epoch: 20.1 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25526357453770626		[learning rate: 0.0046553]
	Learning Rate: 0.00465531
	LOSS [training: 0.25526357453770626 | validation: 0.21512869210164406]
	TIME [epoch: 20.1 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2498769866597478		[learning rate: 0.0046388]
	Learning Rate: 0.00463885
	LOSS [training: 0.2498769866597478 | validation: 0.22064450746338612]
	TIME [epoch: 20.1 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24958648946819414		[learning rate: 0.0046224]
	Learning Rate: 0.00462245
	LOSS [training: 0.24958648946819414 | validation: 0.2144197142876821]
	TIME [epoch: 20.1 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2529774623959394		[learning rate: 0.0046061]
	Learning Rate: 0.0046061
	LOSS [training: 0.2529774623959394 | validation: 0.2198914079656898]
	TIME [epoch: 20.1 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2532909570542573		[learning rate: 0.0045898]
	Learning Rate: 0.00458981
	LOSS [training: 0.2532909570542573 | validation: 0.22429790685368514]
	TIME [epoch: 20.1 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2746195379683328		[learning rate: 0.0045736]
	Learning Rate: 0.00457358
	LOSS [training: 0.2746195379683328 | validation: 0.2158548988967825]
	TIME [epoch: 20.1 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2667332720660683		[learning rate: 0.0045574]
	Learning Rate: 0.00455741
	LOSS [training: 0.2667332720660683 | validation: 0.21609009795522777]
	TIME [epoch: 20.2 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2521675442123622		[learning rate: 0.0045413]
	Learning Rate: 0.00454129
	LOSS [training: 0.2521675442123622 | validation: 0.21046854121825062]
	TIME [epoch: 20.1 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25396546363493305		[learning rate: 0.0045252]
	Learning Rate: 0.00452523
	LOSS [training: 0.25396546363493305 | validation: 0.21130679756434442]
	TIME [epoch: 20.1 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24539972438376137		[learning rate: 0.0045092]
	Learning Rate: 0.00450923
	LOSS [training: 0.24539972438376137 | validation: 0.21694300707007094]
	TIME [epoch: 20.1 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2514428386172177		[learning rate: 0.0044933]
	Learning Rate: 0.00449329
	LOSS [training: 0.2514428386172177 | validation: 0.21399440087304905]
	TIME [epoch: 20.1 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2531626334503226		[learning rate: 0.0044774]
	Learning Rate: 0.0044774
	LOSS [training: 0.2531626334503226 | validation: 0.2212555586988972]
	TIME [epoch: 20.1 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2603747682942223		[learning rate: 0.0044616]
	Learning Rate: 0.00446156
	LOSS [training: 0.2603747682942223 | validation: 0.21336474503188133]
	TIME [epoch: 20.1 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24827071525709546		[learning rate: 0.0044458]
	Learning Rate: 0.00444579
	LOSS [training: 0.24827071525709546 | validation: 0.2050895283025657]
	TIME [epoch: 20.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_279.pth
	Model improved!!!
EPOCH 280/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2513171123540919		[learning rate: 0.0044301]
	Learning Rate: 0.00443007
	LOSS [training: 0.2513171123540919 | validation: 0.21919146015609167]
	TIME [epoch: 20.1 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2551395169077357		[learning rate: 0.0044144]
	Learning Rate: 0.0044144
	LOSS [training: 0.2551395169077357 | validation: 0.2131024288043175]
	TIME [epoch: 20.2 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2524362229351131		[learning rate: 0.0043988]
	Learning Rate: 0.00439879
	LOSS [training: 0.2524362229351131 | validation: 0.21213092392812283]
	TIME [epoch: 20.1 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2616381099391944		[learning rate: 0.0043832]
	Learning Rate: 0.00438324
	LOSS [training: 0.2616381099391944 | validation: 0.2402606237900322]
	TIME [epoch: 20.1 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2618504305048702		[learning rate: 0.0043677]
	Learning Rate: 0.00436774
	LOSS [training: 0.2618504305048702 | validation: 0.21771460002130186]
	TIME [epoch: 20.1 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24972729430726806		[learning rate: 0.0043523]
	Learning Rate: 0.00435229
	LOSS [training: 0.24972729430726806 | validation: 0.22035649520445938]
	TIME [epoch: 20.1 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25343684632993235		[learning rate: 0.0043369]
	Learning Rate: 0.0043369
	LOSS [training: 0.25343684632993235 | validation: 0.21964440270161262]
	TIME [epoch: 20.1 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24353172432117812		[learning rate: 0.0043216]
	Learning Rate: 0.00432156
	LOSS [training: 0.24353172432117812 | validation: 0.21459287160989488]
	TIME [epoch: 20.1 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2522501459264821		[learning rate: 0.0043063]
	Learning Rate: 0.00430628
	LOSS [training: 0.2522501459264821 | validation: 0.2212650160236252]
	TIME [epoch: 20.1 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2538764146353983		[learning rate: 0.0042911]
	Learning Rate: 0.00429106
	LOSS [training: 0.2538764146353983 | validation: 0.22123268605875585]
	TIME [epoch: 20.1 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2538995155313538		[learning rate: 0.0042759]
	Learning Rate: 0.00427588
	LOSS [training: 0.2538995155313538 | validation: 0.21667316094868494]
	TIME [epoch: 20.1 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25434104300252264		[learning rate: 0.0042608]
	Learning Rate: 0.00426076
	LOSS [training: 0.25434104300252264 | validation: 0.2207858076445806]
	TIME [epoch: 20.1 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25743351384546537		[learning rate: 0.0042457]
	Learning Rate: 0.00424569
	LOSS [training: 0.25743351384546537 | validation: 0.21566763652326104]
	TIME [epoch: 20.1 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24616937462714691		[learning rate: 0.0042307]
	Learning Rate: 0.00423068
	LOSS [training: 0.24616937462714691 | validation: 0.21966125125206276]
	TIME [epoch: 20.1 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25609565185603334		[learning rate: 0.0042157]
	Learning Rate: 0.00421572
	LOSS [training: 0.25609565185603334 | validation: 0.21674671562966924]
	TIME [epoch: 20.1 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2479733663099232		[learning rate: 0.0042008]
	Learning Rate: 0.00420081
	LOSS [training: 0.2479733663099232 | validation: 0.21413198230172656]
	TIME [epoch: 20.1 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25368794354683416		[learning rate: 0.004186]
	Learning Rate: 0.00418596
	LOSS [training: 0.25368794354683416 | validation: 0.2173459053832259]
	TIME [epoch: 20.1 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24770647266695447		[learning rate: 0.0041712]
	Learning Rate: 0.00417116
	LOSS [training: 0.24770647266695447 | validation: 0.21725592657931814]
	TIME [epoch: 20.1 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.250208176886753		[learning rate: 0.0041564]
	Learning Rate: 0.00415641
	LOSS [training: 0.250208176886753 | validation: 0.21956123195215574]
	TIME [epoch: 20.1 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2481239902757948		[learning rate: 0.0041417]
	Learning Rate: 0.00414171
	LOSS [training: 0.2481239902757948 | validation: 0.21464160430761892]
	TIME [epoch: 20.1 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24862448723976635		[learning rate: 0.0041271]
	Learning Rate: 0.00412706
	LOSS [training: 0.24862448723976635 | validation: 0.21241554496263362]
	TIME [epoch: 20.1 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2546993994821107		[learning rate: 0.0041125]
	Learning Rate: 0.00411247
	LOSS [training: 0.2546993994821107 | validation: 0.21396280240958912]
	TIME [epoch: 20.2 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2519639868171971		[learning rate: 0.0040979]
	Learning Rate: 0.00409793
	LOSS [training: 0.2519639868171971 | validation: 0.2130048138692875]
	TIME [epoch: 20.2 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24515203815655429		[learning rate: 0.0040834]
	Learning Rate: 0.00408344
	LOSS [training: 0.24515203815655429 | validation: 0.21926332119018493]
	TIME [epoch: 20.2 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24820830492492682		[learning rate: 0.004069]
	Learning Rate: 0.004069
	LOSS [training: 0.24820830492492682 | validation: 0.21516773380688092]
	TIME [epoch: 20.2 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24900666066330537		[learning rate: 0.0040546]
	Learning Rate: 0.00405461
	LOSS [training: 0.24900666066330537 | validation: 0.21333408992074981]
	TIME [epoch: 20.2 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24819919820174682		[learning rate: 0.0040403]
	Learning Rate: 0.00404027
	LOSS [training: 0.24819919820174682 | validation: 0.2161480870821853]
	TIME [epoch: 20.2 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2526900430361507		[learning rate: 0.004026]
	Learning Rate: 0.00402598
	LOSS [training: 0.2526900430361507 | validation: 0.21587642631183485]
	TIME [epoch: 20.2 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24574329107886828		[learning rate: 0.0040117]
	Learning Rate: 0.00401175
	LOSS [training: 0.24574329107886828 | validation: 0.22098846910670597]
	TIME [epoch: 20.2 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24966129394490974		[learning rate: 0.0039976]
	Learning Rate: 0.00399756
	LOSS [training: 0.24966129394490974 | validation: 0.21366226120021384]
	TIME [epoch: 20.2 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2513170308491468		[learning rate: 0.0039834]
	Learning Rate: 0.00398342
	LOSS [training: 0.2513170308491468 | validation: 0.2106942992175577]
	TIME [epoch: 20.2 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2549529553181455		[learning rate: 0.0039693]
	Learning Rate: 0.00396934
	LOSS [training: 0.2549529553181455 | validation: 0.23958424873345824]
	TIME [epoch: 20.2 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2585568537359479		[learning rate: 0.0039553]
	Learning Rate: 0.0039553
	LOSS [training: 0.2585568537359479 | validation: 0.21070624620710285]
	TIME [epoch: 20.2 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2502309813201102		[learning rate: 0.0039413]
	Learning Rate: 0.00394131
	LOSS [training: 0.2502309813201102 | validation: 0.20772639010248278]
	TIME [epoch: 20.2 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2477297296342049		[learning rate: 0.0039274]
	Learning Rate: 0.00392738
	LOSS [training: 0.2477297296342049 | validation: 0.21207755032874873]
	TIME [epoch: 20.2 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24665969211859604		[learning rate: 0.0039135]
	Learning Rate: 0.00391349
	LOSS [training: 0.24665969211859604 | validation: 0.21682556340032]
	TIME [epoch: 20.2 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25374863906498163		[learning rate: 0.0038997]
	Learning Rate: 0.00389965
	LOSS [training: 0.25374863906498163 | validation: 0.21695024967259458]
	TIME [epoch: 20.2 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24862272604795202		[learning rate: 0.0038859]
	Learning Rate: 0.00388586
	LOSS [training: 0.24862272604795202 | validation: 0.21341141952690643]
	TIME [epoch: 20.2 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2555177917318157		[learning rate: 0.0038721]
	Learning Rate: 0.00387212
	LOSS [training: 0.2555177917318157 | validation: 0.21545173307768023]
	TIME [epoch: 20.2 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24739906414480273		[learning rate: 0.0038584]
	Learning Rate: 0.00385843
	LOSS [training: 0.24739906414480273 | validation: 0.21482642477826847]
	TIME [epoch: 20.2 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2534287325827567		[learning rate: 0.0038448]
	Learning Rate: 0.00384478
	LOSS [training: 0.2534287325827567 | validation: 0.2122795416078887]
	TIME [epoch: 20.2 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2442283196021766		[learning rate: 0.0038312]
	Learning Rate: 0.00383119
	LOSS [training: 0.2442283196021766 | validation: 0.21192296046719009]
	TIME [epoch: 20.2 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2546813390705534		[learning rate: 0.0038176]
	Learning Rate: 0.00381764
	LOSS [training: 0.2546813390705534 | validation: 0.2113499911462105]
	TIME [epoch: 20.2 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.250648513499201		[learning rate: 0.0038041]
	Learning Rate: 0.00380414
	LOSS [training: 0.250648513499201 | validation: 0.2189384670732693]
	TIME [epoch: 20.2 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2538721276560763		[learning rate: 0.0037907]
	Learning Rate: 0.00379069
	LOSS [training: 0.2538721276560763 | validation: 0.21604530180068263]
	TIME [epoch: 20.2 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2509824840149533		[learning rate: 0.0037773]
	Learning Rate: 0.00377728
	LOSS [training: 0.2509824840149533 | validation: 0.20987308699011614]
	TIME [epoch: 20.2 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24639882729453613		[learning rate: 0.0037639]
	Learning Rate: 0.00376393
	LOSS [training: 0.24639882729453613 | validation: 0.21158847974936892]
	TIME [epoch: 20.2 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2490899546174974		[learning rate: 0.0037506]
	Learning Rate: 0.00375062
	LOSS [training: 0.2490899546174974 | validation: 0.21223430123729176]
	TIME [epoch: 20.2 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24408100023511226		[learning rate: 0.0037374]
	Learning Rate: 0.00373735
	LOSS [training: 0.24408100023511226 | validation: 0.21397121777876466]
	TIME [epoch: 20.2 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2464193171690706		[learning rate: 0.0037241]
	Learning Rate: 0.00372414
	LOSS [training: 0.2464193171690706 | validation: 0.2114912297356213]
	TIME [epoch: 20.2 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24755956997492579		[learning rate: 0.003711]
	Learning Rate: 0.00371097
	LOSS [training: 0.24755956997492579 | validation: 0.21820687183449178]
	TIME [epoch: 20.2 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2475383814673109		[learning rate: 0.0036978]
	Learning Rate: 0.00369785
	LOSS [training: 0.2475383814673109 | validation: 0.21458320405441583]
	TIME [epoch: 20.2 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24676989310449557		[learning rate: 0.0036848]
	Learning Rate: 0.00368477
	LOSS [training: 0.24676989310449557 | validation: 0.22382600954520915]
	TIME [epoch: 20.2 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2501094188288338		[learning rate: 0.0036717]
	Learning Rate: 0.00367174
	LOSS [training: 0.2501094188288338 | validation: 0.22099065238918794]
	TIME [epoch: 20.2 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2501157568779135		[learning rate: 0.0036588]
	Learning Rate: 0.00365875
	LOSS [training: 0.2501157568779135 | validation: 0.21572451783749513]
	TIME [epoch: 20.2 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25243655891580635		[learning rate: 0.0036458]
	Learning Rate: 0.00364582
	LOSS [training: 0.25243655891580635 | validation: 0.2085499564466434]
	TIME [epoch: 20.2 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2487074609405402		[learning rate: 0.0036329]
	Learning Rate: 0.00363292
	LOSS [training: 0.2487074609405402 | validation: 0.2183894520669245]
	TIME [epoch: 20.2 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25711249048899587		[learning rate: 0.0036201]
	Learning Rate: 0.00362008
	LOSS [training: 0.25711249048899587 | validation: 0.2073421250848062]
	TIME [epoch: 20.2 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2427277878291124		[learning rate: 0.0036073]
	Learning Rate: 0.00360728
	LOSS [training: 0.2427277878291124 | validation: 0.21141632199041008]
	TIME [epoch: 20.2 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24609410993115466		[learning rate: 0.0035945]
	Learning Rate: 0.00359452
	LOSS [training: 0.24609410993115466 | validation: 0.2136825615788676]
	TIME [epoch: 20.2 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24826935878481604		[learning rate: 0.0035818]
	Learning Rate: 0.00358181
	LOSS [training: 0.24826935878481604 | validation: 0.2058010961303442]
	TIME [epoch: 20.2 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24687961358079155		[learning rate: 0.0035691]
	Learning Rate: 0.00356914
	LOSS [training: 0.24687961358079155 | validation: 0.21040513572714642]
	TIME [epoch: 20.2 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2484187313241025		[learning rate: 0.0035565]
	Learning Rate: 0.00355652
	LOSS [training: 0.2484187313241025 | validation: 0.21129923071247553]
	TIME [epoch: 20.2 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.250064148593411		[learning rate: 0.0035439]
	Learning Rate: 0.00354395
	LOSS [training: 0.250064148593411 | validation: 0.21195611993376745]
	TIME [epoch: 20.2 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2514113020938495		[learning rate: 0.0035314]
	Learning Rate: 0.00353141
	LOSS [training: 0.2514113020938495 | validation: 0.21033069373354873]
	TIME [epoch: 20.2 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2505241684599428		[learning rate: 0.0035189]
	Learning Rate: 0.00351893
	LOSS [training: 0.2505241684599428 | validation: 0.20849914770375982]
	TIME [epoch: 20.2 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24535522658774037		[learning rate: 0.0035065]
	Learning Rate: 0.00350648
	LOSS [training: 0.24535522658774037 | validation: 0.20848037957628457]
	TIME [epoch: 20.2 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24489780398653826		[learning rate: 0.0034941]
	Learning Rate: 0.00349408
	LOSS [training: 0.24489780398653826 | validation: 0.21731857496601656]
	TIME [epoch: 20.2 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24783004268137587		[learning rate: 0.0034817]
	Learning Rate: 0.00348173
	LOSS [training: 0.24783004268137587 | validation: 0.21525682299697063]
	TIME [epoch: 20.1 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24924399856144405		[learning rate: 0.0034694]
	Learning Rate: 0.00346942
	LOSS [training: 0.24924399856144405 | validation: 0.22865946686989239]
	TIME [epoch: 20.1 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2602550922258156		[learning rate: 0.0034571]
	Learning Rate: 0.00345715
	LOSS [training: 0.2602550922258156 | validation: 0.2218386256955443]
	TIME [epoch: 20.2 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25592482676538814		[learning rate: 0.0034449]
	Learning Rate: 0.00344492
	LOSS [training: 0.25592482676538814 | validation: 0.21560255680340074]
	TIME [epoch: 20.1 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24468720746536063		[learning rate: 0.0034327]
	Learning Rate: 0.00343274
	LOSS [training: 0.24468720746536063 | validation: 0.2099433215530643]
	TIME [epoch: 20.1 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24432124185204465		[learning rate: 0.0034206]
	Learning Rate: 0.0034206
	LOSS [training: 0.24432124185204465 | validation: 0.21198937037988325]
	TIME [epoch: 20.1 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24436312167528743		[learning rate: 0.0034085]
	Learning Rate: 0.00340851
	LOSS [training: 0.24436312167528743 | validation: 0.21088030441731725]
	TIME [epoch: 20.1 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26066425624695905		[learning rate: 0.0033965]
	Learning Rate: 0.00339645
	LOSS [training: 0.26066425624695905 | validation: 0.20588249521230959]
	TIME [epoch: 20.2 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24545464824132757		[learning rate: 0.0033844]
	Learning Rate: 0.00338444
	LOSS [training: 0.24545464824132757 | validation: 0.21235315173380687]
	TIME [epoch: 20.2 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24499278561384794		[learning rate: 0.0033725]
	Learning Rate: 0.00337247
	LOSS [training: 0.24499278561384794 | validation: 0.21046353159176362]
	TIME [epoch: 20.1 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2519069054886237		[learning rate: 0.0033605]
	Learning Rate: 0.00336055
	LOSS [training: 0.2519069054886237 | validation: 0.21001716237045587]
	TIME [epoch: 20.1 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2486369978906139		[learning rate: 0.0033487]
	Learning Rate: 0.00334867
	LOSS [training: 0.2486369978906139 | validation: 0.2104082092288538]
	TIME [epoch: 20.2 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24901694761833107		[learning rate: 0.0033368]
	Learning Rate: 0.00333682
	LOSS [training: 0.24901694761833107 | validation: 0.20675203213274201]
	TIME [epoch: 20.2 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25183403052907516		[learning rate: 0.003325]
	Learning Rate: 0.00332502
	LOSS [training: 0.25183403052907516 | validation: 0.20469058090284942]
	TIME [epoch: 20.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_361.pth
	Model improved!!!
EPOCH 362/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24982843874572083		[learning rate: 0.0033133]
	Learning Rate: 0.00331327
	LOSS [training: 0.24982843874572083 | validation: 0.21120897150013834]
	TIME [epoch: 20.2 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25056349510696735		[learning rate: 0.0033016]
	Learning Rate: 0.00330155
	LOSS [training: 0.25056349510696735 | validation: 0.20804842394266082]
	TIME [epoch: 20.1 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24910449438823035		[learning rate: 0.0032899]
	Learning Rate: 0.00328988
	LOSS [training: 0.24910449438823035 | validation: 0.20902244158169178]
	TIME [epoch: 20.2 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24041870955595843		[learning rate: 0.0032782]
	Learning Rate: 0.00327824
	LOSS [training: 0.24041870955595843 | validation: 0.2070191879947056]
	TIME [epoch: 20.1 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.251315502986404		[learning rate: 0.0032666]
	Learning Rate: 0.00326665
	LOSS [training: 0.251315502986404 | validation: 0.21628702615350165]
	TIME [epoch: 20.1 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24934071501662233		[learning rate: 0.0032551]
	Learning Rate: 0.0032551
	LOSS [training: 0.24934071501662233 | validation: 0.21621579459432164]
	TIME [epoch: 20.1 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25160717636528057		[learning rate: 0.0032436]
	Learning Rate: 0.00324359
	LOSS [training: 0.25160717636528057 | validation: 0.21593785003010205]
	TIME [epoch: 20.1 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2547884038653363		[learning rate: 0.0032321]
	Learning Rate: 0.00323212
	LOSS [training: 0.2547884038653363 | validation: 0.21113750456380784]
	TIME [epoch: 20.1 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2518279446148965		[learning rate: 0.0032207]
	Learning Rate: 0.00322069
	LOSS [training: 0.2518279446148965 | validation: 0.21372045885307242]
	TIME [epoch: 20.1 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24679133221053876		[learning rate: 0.0032093]
	Learning Rate: 0.0032093
	LOSS [training: 0.24679133221053876 | validation: 0.2096759320224299]
	TIME [epoch: 20.1 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25538838904685346		[learning rate: 0.003198]
	Learning Rate: 0.00319795
	LOSS [training: 0.25538838904685346 | validation: 0.22013513835626952]
	TIME [epoch: 20.1 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2555225859829468		[learning rate: 0.0031866]
	Learning Rate: 0.00318664
	LOSS [training: 0.2555225859829468 | validation: 0.21364776421272613]
	TIME [epoch: 20.1 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25043239204731454		[learning rate: 0.0031754]
	Learning Rate: 0.00317537
	LOSS [training: 0.25043239204731454 | validation: 0.21435976986426702]
	TIME [epoch: 20.2 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24843516059888845		[learning rate: 0.0031641]
	Learning Rate: 0.00316415
	LOSS [training: 0.24843516059888845 | validation: 0.21238303643018455]
	TIME [epoch: 20.1 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25298839780880783		[learning rate: 0.003153]
	Learning Rate: 0.00315296
	LOSS [training: 0.25298839780880783 | validation: 0.20972670997539086]
	TIME [epoch: 20.1 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24359005452900653		[learning rate: 0.0031418]
	Learning Rate: 0.00314181
	LOSS [training: 0.24359005452900653 | validation: 0.21087103721345346]
	TIME [epoch: 20.1 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24776207404993555		[learning rate: 0.0031307]
	Learning Rate: 0.0031307
	LOSS [training: 0.24776207404993555 | validation: 0.2076427597670556]
	TIME [epoch: 20.1 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24543079708105422		[learning rate: 0.0031196]
	Learning Rate: 0.00311963
	LOSS [training: 0.24543079708105422 | validation: 0.21166966421314318]
	TIME [epoch: 20.1 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24799845966201642		[learning rate: 0.0031086]
	Learning Rate: 0.00310859
	LOSS [training: 0.24799845966201642 | validation: 0.218664721231025]
	TIME [epoch: 20.1 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2519035763565039		[learning rate: 0.0030976]
	Learning Rate: 0.0030976
	LOSS [training: 0.2519035763565039 | validation: 0.2201500982222407]
	TIME [epoch: 20.1 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2530071788325196		[learning rate: 0.0030866]
	Learning Rate: 0.00308665
	LOSS [training: 0.2530071788325196 | validation: 0.21615572577216374]
	TIME [epoch: 20.1 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.250489617543795		[learning rate: 0.0030757]
	Learning Rate: 0.00307573
	LOSS [training: 0.250489617543795 | validation: 0.212138560093078]
	TIME [epoch: 20.1 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24673622440013396		[learning rate: 0.0030649]
	Learning Rate: 0.00306486
	LOSS [training: 0.24673622440013396 | validation: 0.21336326103753384]
	TIME [epoch: 20.1 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24941904496849623		[learning rate: 0.003054]
	Learning Rate: 0.00305402
	LOSS [training: 0.24941904496849623 | validation: 0.20840446036344265]
	TIME [epoch: 20.1 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24690820077870482		[learning rate: 0.0030432]
	Learning Rate: 0.00304322
	LOSS [training: 0.24690820077870482 | validation: 0.21820731026210832]
	TIME [epoch: 20.1 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2468750557264043		[learning rate: 0.0030325]
	Learning Rate: 0.00303246
	LOSS [training: 0.2468750557264043 | validation: 0.21465950589964797]
	TIME [epoch: 20.1 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2487339002505621		[learning rate: 0.0030217]
	Learning Rate: 0.00302174
	LOSS [training: 0.2487339002505621 | validation: 0.2071957525564474]
	TIME [epoch: 20.1 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.247003154529019		[learning rate: 0.003011]
	Learning Rate: 0.00301105
	LOSS [training: 0.247003154529019 | validation: 0.20933210728175297]
	TIME [epoch: 20.1 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2469955806828048		[learning rate: 0.0030004]
	Learning Rate: 0.0030004
	LOSS [training: 0.2469955806828048 | validation: 0.21223182073593477]
	TIME [epoch: 20.1 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24891302692170258		[learning rate: 0.0029898]
	Learning Rate: 0.00298979
	LOSS [training: 0.24891302692170258 | validation: 0.21597192848123897]
	TIME [epoch: 20.1 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24814155366646615		[learning rate: 0.0029792]
	Learning Rate: 0.00297922
	LOSS [training: 0.24814155366646615 | validation: 0.2132628307160161]
	TIME [epoch: 20.2 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24465257933378703		[learning rate: 0.0029687]
	Learning Rate: 0.00296869
	LOSS [training: 0.24465257933378703 | validation: 0.20985838546638208]
	TIME [epoch: 20.1 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24582546564195754		[learning rate: 0.0029582]
	Learning Rate: 0.00295819
	LOSS [training: 0.24582546564195754 | validation: 0.21248562215380679]
	TIME [epoch: 20.1 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2424043336142466		[learning rate: 0.0029477]
	Learning Rate: 0.00294773
	LOSS [training: 0.2424043336142466 | validation: 0.21568109083643341]
	TIME [epoch: 20.1 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2439055333466269		[learning rate: 0.0029373]
	Learning Rate: 0.0029373
	LOSS [training: 0.2439055333466269 | validation: 0.21373152625092479]
	TIME [epoch: 20.1 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2416800547907769		[learning rate: 0.0029269]
	Learning Rate: 0.00292692
	LOSS [training: 0.2416800547907769 | validation: 0.21179224838072944]
	TIME [epoch: 20.1 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24843743497838267		[learning rate: 0.0029166]
	Learning Rate: 0.00291657
	LOSS [training: 0.24843743497838267 | validation: 0.21272158256622636]
	TIME [epoch: 20.1 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2455447795991381		[learning rate: 0.0029063]
	Learning Rate: 0.00290625
	LOSS [training: 0.2455447795991381 | validation: 0.21170824918490325]
	TIME [epoch: 20.1 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2429797874895676		[learning rate: 0.002896]
	Learning Rate: 0.00289598
	LOSS [training: 0.2429797874895676 | validation: 0.2110156463409291]
	TIME [epoch: 20.1 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24798012234755287		[learning rate: 0.0028857]
	Learning Rate: 0.00288573
	LOSS [training: 0.24798012234755287 | validation: 0.213182939651881]
	TIME [epoch: 20.2 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25362224312934606		[learning rate: 0.0028755]
	Learning Rate: 0.00287553
	LOSS [training: 0.25362224312934606 | validation: 0.21136422458326284]
	TIME [epoch: 20.1 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24712793267813926		[learning rate: 0.0028654]
	Learning Rate: 0.00286536
	LOSS [training: 0.24712793267813926 | validation: 0.21456483573609003]
	TIME [epoch: 20.1 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24935827350129944		[learning rate: 0.0028552]
	Learning Rate: 0.00285523
	LOSS [training: 0.24935827350129944 | validation: 0.20667963282162433]
	TIME [epoch: 20.1 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24829217233226522		[learning rate: 0.0028451]
	Learning Rate: 0.00284513
	LOSS [training: 0.24829217233226522 | validation: 0.21642768134982088]
	TIME [epoch: 20.1 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.246205865650614		[learning rate: 0.0028351]
	Learning Rate: 0.00283507
	LOSS [training: 0.246205865650614 | validation: 0.20933259319241676]
	TIME [epoch: 20.1 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24707848213812308		[learning rate: 0.002825]
	Learning Rate: 0.00282505
	LOSS [training: 0.24707848213812308 | validation: 0.20933428130678303]
	TIME [epoch: 20.1 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2446162217491159		[learning rate: 0.0028151]
	Learning Rate: 0.00281506
	LOSS [training: 0.2446162217491159 | validation: 0.20783991430672155]
	TIME [epoch: 20.1 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2503359890219088		[learning rate: 0.0028051]
	Learning Rate: 0.0028051
	LOSS [training: 0.2503359890219088 | validation: 0.2128317450975815]
	TIME [epoch: 20.1 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23935522005919796		[learning rate: 0.0027952]
	Learning Rate: 0.00279518
	LOSS [training: 0.23935522005919796 | validation: 0.21314575281916168]
	TIME [epoch: 20.1 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2466739604866706		[learning rate: 0.0027853]
	Learning Rate: 0.0027853
	LOSS [training: 0.2466739604866706 | validation: 0.21180344664967596]
	TIME [epoch: 20.1 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25001936080835546		[learning rate: 0.0027754]
	Learning Rate: 0.00277545
	LOSS [training: 0.25001936080835546 | validation: 0.2096132332296296]
	TIME [epoch: 20.1 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24713917138628605		[learning rate: 0.0027656]
	Learning Rate: 0.00276564
	LOSS [training: 0.24713917138628605 | validation: 0.21086542132015315]
	TIME [epoch: 20.1 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24331177481258415		[learning rate: 0.0027559]
	Learning Rate: 0.00275586
	LOSS [training: 0.24331177481258415 | validation: 0.2122686430766251]
	TIME [epoch: 20.1 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25129122203803056		[learning rate: 0.0027461]
	Learning Rate: 0.00274611
	LOSS [training: 0.25129122203803056 | validation: 0.20754286348101444]
	TIME [epoch: 20.1 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.250850035059649		[learning rate: 0.0027364]
	Learning Rate: 0.0027364
	LOSS [training: 0.250850035059649 | validation: 0.21865527360285048]
	TIME [epoch: 20.1 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24590665746426532		[learning rate: 0.0027267]
	Learning Rate: 0.00272672
	LOSS [training: 0.24590665746426532 | validation: 0.21318937918894712]
	TIME [epoch: 20.1 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24875720718056138		[learning rate: 0.0027171]
	Learning Rate: 0.00271708
	LOSS [training: 0.24875720718056138 | validation: 0.2131402349076572]
	TIME [epoch: 20.1 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24582846097714395		[learning rate: 0.0027075]
	Learning Rate: 0.00270747
	LOSS [training: 0.24582846097714395 | validation: 0.21213707328879497]
	TIME [epoch: 20.1 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24860557993244958		[learning rate: 0.0026979]
	Learning Rate: 0.0026979
	LOSS [training: 0.24860557993244958 | validation: 0.2121526233366629]
	TIME [epoch: 20.1 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2458657325621714		[learning rate: 0.0026884]
	Learning Rate: 0.00268836
	LOSS [training: 0.2458657325621714 | validation: 0.2075572247416902]
	TIME [epoch: 20.1 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2538423458443198		[learning rate: 0.0026789]
	Learning Rate: 0.00267885
	LOSS [training: 0.2538423458443198 | validation: 0.21031403508874305]
	TIME [epoch: 20.1 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2438179335823928		[learning rate: 0.0026694]
	Learning Rate: 0.00266938
	LOSS [training: 0.2438179335823928 | validation: 0.211261444554796]
	TIME [epoch: 20.1 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24397009644154574		[learning rate: 0.0026599]
	Learning Rate: 0.00265994
	LOSS [training: 0.24397009644154574 | validation: 0.21047799317512078]
	TIME [epoch: 20.1 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2432966671156197		[learning rate: 0.0026505]
	Learning Rate: 0.00265053
	LOSS [training: 0.2432966671156197 | validation: 0.21295388710436028]
	TIME [epoch: 20.1 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2462999033260689		[learning rate: 0.0026412]
	Learning Rate: 0.00264116
	LOSS [training: 0.2462999033260689 | validation: 0.21449363355199988]
	TIME [epoch: 20.1 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24477205843304262		[learning rate: 0.0026318]
	Learning Rate: 0.00263182
	LOSS [training: 0.24477205843304262 | validation: 0.21474948980507821]
	TIME [epoch: 20.1 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24378132504632588		[learning rate: 0.0026225]
	Learning Rate: 0.00262251
	LOSS [training: 0.24378132504632588 | validation: 0.21070186928615584]
	TIME [epoch: 20.2 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24522603731083084		[learning rate: 0.0026132]
	Learning Rate: 0.00261324
	LOSS [training: 0.24522603731083084 | validation: 0.2131392989066474]
	TIME [epoch: 20.1 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24738076922780572		[learning rate: 0.002604]
	Learning Rate: 0.002604
	LOSS [training: 0.24738076922780572 | validation: 0.21038277574551678]
	TIME [epoch: 20.1 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24792989237366422		[learning rate: 0.0025948]
	Learning Rate: 0.00259479
	LOSS [training: 0.24792989237366422 | validation: 0.21153830809028845]
	TIME [epoch: 20.1 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24676282523530055		[learning rate: 0.0025856]
	Learning Rate: 0.00258562
	LOSS [training: 0.24676282523530055 | validation: 0.20622844653839545]
	TIME [epoch: 20.1 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24791917311598977		[learning rate: 0.0025765]
	Learning Rate: 0.00257647
	LOSS [training: 0.24791917311598977 | validation: 0.2060245934000485]
	TIME [epoch: 20.1 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2459910508333807		[learning rate: 0.0025674]
	Learning Rate: 0.00256736
	LOSS [training: 0.2459910508333807 | validation: 0.20939881438206495]
	TIME [epoch: 20.1 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2455810507654589		[learning rate: 0.0025583]
	Learning Rate: 0.00255828
	LOSS [training: 0.2455810507654589 | validation: 0.20721711095883455]
	TIME [epoch: 20.1 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24091921165609276		[learning rate: 0.0025492]
	Learning Rate: 0.00254924
	LOSS [training: 0.24091921165609276 | validation: 0.2206983982394179]
	TIME [epoch: 20.1 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25029076579633475		[learning rate: 0.0025402]
	Learning Rate: 0.00254022
	LOSS [training: 0.25029076579633475 | validation: 0.2118003597476375]
	TIME [epoch: 20.1 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25283779613669327		[learning rate: 0.0025312]
	Learning Rate: 0.00253124
	LOSS [training: 0.25283779613669327 | validation: 0.2078572831595124]
	TIME [epoch: 20.1 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2444938932124263		[learning rate: 0.0025223]
	Learning Rate: 0.00252229
	LOSS [training: 0.2444938932124263 | validation: 0.21106643960652605]
	TIME [epoch: 20.1 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25132475845827346		[learning rate: 0.0025134]
	Learning Rate: 0.00251337
	LOSS [training: 0.25132475845827346 | validation: 0.21169362753915477]
	TIME [epoch: 20.1 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.242207853827174		[learning rate: 0.0025045]
	Learning Rate: 0.00250448
	LOSS [training: 0.242207853827174 | validation: 0.20695643167625888]
	TIME [epoch: 20.1 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25006001589704757		[learning rate: 0.0024956]
	Learning Rate: 0.00249563
	LOSS [training: 0.25006001589704757 | validation: 0.2121638223353691]
	TIME [epoch: 20.1 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24368965779115723		[learning rate: 0.0024868]
	Learning Rate: 0.0024868
	LOSS [training: 0.24368965779115723 | validation: 0.2085554225277646]
	TIME [epoch: 20.1 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24394343469077537		[learning rate: 0.002478]
	Learning Rate: 0.00247801
	LOSS [training: 0.24394343469077537 | validation: 0.2100048484555105]
	TIME [epoch: 20.1 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24625919784643924		[learning rate: 0.0024692]
	Learning Rate: 0.00246924
	LOSS [training: 0.24625919784643924 | validation: 0.21088376420967264]
	TIME [epoch: 20.1 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25666424638652136		[learning rate: 0.0024605]
	Learning Rate: 0.00246051
	LOSS [training: 0.25666424638652136 | validation: 0.20614712732887774]
	TIME [epoch: 20.1 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24685752649554546		[learning rate: 0.0024518]
	Learning Rate: 0.00245181
	LOSS [training: 0.24685752649554546 | validation: 0.20670795407974518]
	TIME [epoch: 20.1 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2536322532167095		[learning rate: 0.0024431]
	Learning Rate: 0.00244314
	LOSS [training: 0.2536322532167095 | validation: 0.2111771100132011]
	TIME [epoch: 20.1 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24860418666530726		[learning rate: 0.0024345]
	Learning Rate: 0.0024345
	LOSS [training: 0.24860418666530726 | validation: 0.20779704863500106]
	TIME [epoch: 20.1 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24503278892485017		[learning rate: 0.0024259]
	Learning Rate: 0.00242589
	LOSS [training: 0.24503278892485017 | validation: 0.20480933761282044]
	TIME [epoch: 20.1 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2503664010251991		[learning rate: 0.0024173]
	Learning Rate: 0.00241732
	LOSS [training: 0.2503664010251991 | validation: 0.21134713217193327]
	TIME [epoch: 20.1 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24780862661223632		[learning rate: 0.0024088]
	Learning Rate: 0.00240877
	LOSS [training: 0.24780862661223632 | validation: 0.21275315846079276]
	TIME [epoch: 20.1 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2468368413480604		[learning rate: 0.0024002]
	Learning Rate: 0.00240025
	LOSS [training: 0.2468368413480604 | validation: 0.21104223021516377]
	TIME [epoch: 20.1 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25107628865601117		[learning rate: 0.0023918]
	Learning Rate: 0.00239176
	LOSS [training: 0.25107628865601117 | validation: 0.21175283234993084]
	TIME [epoch: 20.1 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2466909010407857		[learning rate: 0.0023833]
	Learning Rate: 0.0023833
	LOSS [training: 0.2466909010407857 | validation: 0.21315489001319904]
	TIME [epoch: 20.1 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2501509981118197		[learning rate: 0.0023749]
	Learning Rate: 0.00237488
	LOSS [training: 0.2501509981118197 | validation: 0.21039373273672352]
	TIME [epoch: 20.1 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2459627988200488		[learning rate: 0.0023665]
	Learning Rate: 0.00236648
	LOSS [training: 0.2459627988200488 | validation: 0.20661255238940296]
	TIME [epoch: 20.1 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2461307649234384		[learning rate: 0.0023581]
	Learning Rate: 0.00235811
	LOSS [training: 0.2461307649234384 | validation: 0.20909936181886496]
	TIME [epoch: 20.1 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24586971970354807		[learning rate: 0.0023498]
	Learning Rate: 0.00234977
	LOSS [training: 0.24586971970354807 | validation: 0.20953263689397636]
	TIME [epoch: 20.1 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24976963652616954		[learning rate: 0.0023415]
	Learning Rate: 0.00234146
	LOSS [training: 0.24976963652616954 | validation: 0.2058693263286428]
	TIME [epoch: 20.1 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.246147988838766		[learning rate: 0.0023332]
	Learning Rate: 0.00233318
	LOSS [training: 0.246147988838766 | validation: 0.20657184618463392]
	TIME [epoch: 20.1 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24335878860699808		[learning rate: 0.0023249]
	Learning Rate: 0.00232493
	LOSS [training: 0.24335878860699808 | validation: 0.2149625044278201]
	TIME [epoch: 20.1 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2501743226415241		[learning rate: 0.0023167]
	Learning Rate: 0.00231671
	LOSS [training: 0.2501743226415241 | validation: 0.21151058942492237]
	TIME [epoch: 20.1 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24957410467347954		[learning rate: 0.0023085]
	Learning Rate: 0.00230852
	LOSS [training: 0.24957410467347954 | validation: 0.20442836079181398]
	TIME [epoch: 20.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_464.pth
	Model improved!!!
EPOCH 465/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2433787082366042		[learning rate: 0.0023004]
	Learning Rate: 0.00230035
	LOSS [training: 0.2433787082366042 | validation: 0.21265379322872108]
	TIME [epoch: 20.1 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24579774806450003		[learning rate: 0.0022922]
	Learning Rate: 0.00229222
	LOSS [training: 0.24579774806450003 | validation: 0.20727513025125113]
	TIME [epoch: 20.1 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2498948844423564		[learning rate: 0.0022841]
	Learning Rate: 0.00228411
	LOSS [training: 0.2498948844423564 | validation: 0.2086233976316088]
	TIME [epoch: 20.1 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.249938027996637		[learning rate: 0.002276]
	Learning Rate: 0.00227604
	LOSS [training: 0.249938027996637 | validation: 0.20475558199907057]
	TIME [epoch: 20.1 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24832146980289782		[learning rate: 0.002268]
	Learning Rate: 0.00226799
	LOSS [training: 0.24832146980289782 | validation: 0.20395515839478429]
	TIME [epoch: 20.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_469.pth
	Model improved!!!
EPOCH 470/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24832581127918188		[learning rate: 0.00226]
	Learning Rate: 0.00225997
	LOSS [training: 0.24832581127918188 | validation: 0.2077833707775297]
	TIME [epoch: 20.2 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.245489972652327		[learning rate: 0.002252]
	Learning Rate: 0.00225198
	LOSS [training: 0.245489972652327 | validation: 0.20532544488628632]
	TIME [epoch: 20.1 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2483589859229912		[learning rate: 0.002244]
	Learning Rate: 0.00224401
	LOSS [training: 0.2483589859229912 | validation: 0.2089131798376016]
	TIME [epoch: 20.1 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24534711845542836		[learning rate: 0.0022361]
	Learning Rate: 0.00223608
	LOSS [training: 0.24534711845542836 | validation: 0.21012750269585437]
	TIME [epoch: 20.1 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24698024999371712		[learning rate: 0.0022282]
	Learning Rate: 0.00222817
	LOSS [training: 0.24698024999371712 | validation: 0.2057348570637852]
	TIME [epoch: 20.1 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24529324429251795		[learning rate: 0.0022203]
	Learning Rate: 0.00222029
	LOSS [training: 0.24529324429251795 | validation: 0.20517379050922818]
	TIME [epoch: 20.1 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24719716802711433		[learning rate: 0.0022124]
	Learning Rate: 0.00221244
	LOSS [training: 0.24719716802711433 | validation: 0.20496320644878666]
	TIME [epoch: 20.1 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2454101467592882		[learning rate: 0.0022046]
	Learning Rate: 0.00220462
	LOSS [training: 0.2454101467592882 | validation: 0.2061151104029484]
	TIME [epoch: 20.1 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24607424107039708		[learning rate: 0.0021968]
	Learning Rate: 0.00219682
	LOSS [training: 0.24607424107039708 | validation: 0.20893057863002745]
	TIME [epoch: 20.1 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2408892881922147		[learning rate: 0.0021891]
	Learning Rate: 0.00218905
	LOSS [training: 0.2408892881922147 | validation: 0.20891449919182584]
	TIME [epoch: 20.1 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24423002223555304		[learning rate: 0.0021813]
	Learning Rate: 0.00218131
	LOSS [training: 0.24423002223555304 | validation: 0.21033525147935786]
	TIME [epoch: 20.1 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24479499881614622		[learning rate: 0.0021736]
	Learning Rate: 0.0021736
	LOSS [training: 0.24479499881614622 | validation: 0.21149897052013902]
	TIME [epoch: 20.1 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2454942275687054		[learning rate: 0.0021659]
	Learning Rate: 0.00216591
	LOSS [training: 0.2454942275687054 | validation: 0.20415833455535148]
	TIME [epoch: 20.1 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2464630254867134		[learning rate: 0.0021583]
	Learning Rate: 0.00215825
	LOSS [training: 0.2464630254867134 | validation: 0.20556110644166709]
	TIME [epoch: 20.2 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24543992488343633		[learning rate: 0.0021506]
	Learning Rate: 0.00215062
	LOSS [training: 0.24543992488343633 | validation: 0.21348573205690635]
	TIME [epoch: 20.1 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24380667404193665		[learning rate: 0.002143]
	Learning Rate: 0.00214302
	LOSS [training: 0.24380667404193665 | validation: 0.20840841000985666]
	TIME [epoch: 20.1 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2495889141437836		[learning rate: 0.0021354]
	Learning Rate: 0.00213544
	LOSS [training: 0.2495889141437836 | validation: 0.20835521801795248]
	TIME [epoch: 20.1 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24584978911809188		[learning rate: 0.0021279]
	Learning Rate: 0.00212789
	LOSS [training: 0.24584978911809188 | validation: 0.20644761707416456]
	TIME [epoch: 20.1 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24176882324627091		[learning rate: 0.0021204]
	Learning Rate: 0.00212036
	LOSS [training: 0.24176882324627091 | validation: 0.20643772436300142]
	TIME [epoch: 20.1 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24684793594070387		[learning rate: 0.0021129]
	Learning Rate: 0.00211287
	LOSS [training: 0.24684793594070387 | validation: 0.2083073355790228]
	TIME [epoch: 20.2 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24550968849263033		[learning rate: 0.0021054]
	Learning Rate: 0.00210539
	LOSS [training: 0.24550968849263033 | validation: 0.21661793897446904]
	TIME [epoch: 20.1 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24534940360117843		[learning rate: 0.0020979]
	Learning Rate: 0.00209795
	LOSS [training: 0.24534940360117843 | validation: 0.2099517646878868]
	TIME [epoch: 20.1 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24310563451346648		[learning rate: 0.0020905]
	Learning Rate: 0.00209053
	LOSS [training: 0.24310563451346648 | validation: 0.21108107894981676]
	TIME [epoch: 20.2 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24836287578728297		[learning rate: 0.0020831]
	Learning Rate: 0.00208314
	LOSS [training: 0.24836287578728297 | validation: 0.21101887130563907]
	TIME [epoch: 20.1 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.242505638992183		[learning rate: 0.0020758]
	Learning Rate: 0.00207577
	LOSS [training: 0.242505638992183 | validation: 0.20895387369695156]
	TIME [epoch: 20.1 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24505439093854045		[learning rate: 0.0020684]
	Learning Rate: 0.00206843
	LOSS [training: 0.24505439093854045 | validation: 0.21077634397179024]
	TIME [epoch: 20.1 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24628549556022072		[learning rate: 0.0020611]
	Learning Rate: 0.00206112
	LOSS [training: 0.24628549556022072 | validation: 0.20795453549455173]
	TIME [epoch: 20.1 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24792027400877426		[learning rate: 0.0020538]
	Learning Rate: 0.00205383
	LOSS [training: 0.24792027400877426 | validation: 0.21232441920323147]
	TIME [epoch: 20.2 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24371924063023112		[learning rate: 0.0020466]
	Learning Rate: 0.00204657
	LOSS [training: 0.24371924063023112 | validation: 0.20943194041404206]
	TIME [epoch: 20.1 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24306582421746648		[learning rate: 0.0020393]
	Learning Rate: 0.00203933
	LOSS [training: 0.24306582421746648 | validation: 0.2049378795431287]
	TIME [epoch: 20.1 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24966913625599263		[learning rate: 0.0020321]
	Learning Rate: 0.00203212
	LOSS [training: 0.24966913625599263 | validation: 0.20986024162901443]
	TIME [epoch: 20.1 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2473242175975199		[learning rate: 0.0020249]
	Learning Rate: 0.00202493
	LOSS [training: 0.2473242175975199 | validation: 0.21083493373617354]
	TIME [epoch: 56.7 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24873851699377716		[learning rate: 0.0020178]
	Learning Rate: 0.00201777
	LOSS [training: 0.24873851699377716 | validation: 0.20896754331856301]
	TIME [epoch: 42.8 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2451082526149694		[learning rate: 0.0020106]
	Learning Rate: 0.00201064
	LOSS [training: 0.2451082526149694 | validation: 0.20736683437605122]
	TIME [epoch: 42.8 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2470450143562435		[learning rate: 0.0020035]
	Learning Rate: 0.00200353
	LOSS [training: 0.2470450143562435 | validation: 0.20857148179670584]
	TIME [epoch: 42.8 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24049655347566223		[learning rate: 0.0019964]
	Learning Rate: 0.00199644
	LOSS [training: 0.24049655347566223 | validation: 0.2079104789561928]
	TIME [epoch: 42.8 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24509723271729866		[learning rate: 0.0019894]
	Learning Rate: 0.00198938
	LOSS [training: 0.24509723271729866 | validation: 0.20993050830164767]
	TIME [epoch: 42.8 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24278865688785634		[learning rate: 0.0019823]
	Learning Rate: 0.00198235
	LOSS [training: 0.24278865688785634 | validation: 0.21182395481591146]
	TIME [epoch: 42.7 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24880509840429457		[learning rate: 0.0019753]
	Learning Rate: 0.00197534
	LOSS [training: 0.24880509840429457 | validation: 0.20761653661301144]
	TIME [epoch: 42.8 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24585224176586096		[learning rate: 0.0019684]
	Learning Rate: 0.00196835
	LOSS [training: 0.24585224176586096 | validation: 0.2120848761423057]
	TIME [epoch: 42.8 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24294187558394273		[learning rate: 0.0019614]
	Learning Rate: 0.00196139
	LOSS [training: 0.24294187558394273 | validation: 0.21636343839674751]
	TIME [epoch: 42.8 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2481726502420156		[learning rate: 0.0019545]
	Learning Rate: 0.00195445
	LOSS [training: 0.2481726502420156 | validation: 0.21335384372206892]
	TIME [epoch: 42.8 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24992840654925275		[learning rate: 0.0019475]
	Learning Rate: 0.00194754
	LOSS [training: 0.24992840654925275 | validation: 0.2125148782857884]
	TIME [epoch: 42.8 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2448926293389854		[learning rate: 0.0019407]
	Learning Rate: 0.00194066
	LOSS [training: 0.2448926293389854 | validation: 0.21092345828407394]
	TIME [epoch: 42.8 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24521470572976392		[learning rate: 0.0019338]
	Learning Rate: 0.00193379
	LOSS [training: 0.24521470572976392 | validation: 0.2135042229493059]
	TIME [epoch: 42.8 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24772709042329402		[learning rate: 0.001927]
	Learning Rate: 0.00192696
	LOSS [training: 0.24772709042329402 | validation: 0.21479748594761777]
	TIME [epoch: 42.8 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24042594589098756		[learning rate: 0.0019201]
	Learning Rate: 0.00192014
	LOSS [training: 0.24042594589098756 | validation: 0.21132795323396497]
	TIME [epoch: 42.8 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24471722052674558		[learning rate: 0.0019134]
	Learning Rate: 0.00191335
	LOSS [training: 0.24471722052674558 | validation: 0.21214121181682472]
	TIME [epoch: 42.8 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24659791142310775		[learning rate: 0.0019066]
	Learning Rate: 0.00190659
	LOSS [training: 0.24659791142310775 | validation: 0.21071264474496684]
	TIME [epoch: 42.8 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24607655955276395		[learning rate: 0.0018998]
	Learning Rate: 0.00189984
	LOSS [training: 0.24607655955276395 | validation: 0.2109064853214536]
	TIME [epoch: 42.8 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24726788683665682		[learning rate: 0.0018931]
	Learning Rate: 0.00189313
	LOSS [training: 0.24726788683665682 | validation: 0.20776559969388106]
	TIME [epoch: 42.8 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24318220376938338		[learning rate: 0.0018864]
	Learning Rate: 0.00188643
	LOSS [training: 0.24318220376938338 | validation: 0.20664968103306883]
	TIME [epoch: 42.8 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2458561334804206		[learning rate: 0.0018798]
	Learning Rate: 0.00187976
	LOSS [training: 0.2458561334804206 | validation: 0.21414765089227766]
	TIME [epoch: 42.8 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24069883554257296		[learning rate: 0.0018731]
	Learning Rate: 0.00187311
	LOSS [training: 0.24069883554257296 | validation: 0.21263002384808288]
	TIME [epoch: 42.8 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24664996348689816		[learning rate: 0.0018665]
	Learning Rate: 0.00186649
	LOSS [training: 0.24664996348689816 | validation: 0.20799919389170757]
	TIME [epoch: 42.8 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24277604146493922		[learning rate: 0.0018599]
	Learning Rate: 0.00185989
	LOSS [training: 0.24277604146493922 | validation: 0.2087955874583835]
	TIME [epoch: 42.8 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24362391729900335		[learning rate: 0.0018533]
	Learning Rate: 0.00185331
	LOSS [training: 0.24362391729900335 | validation: 0.213872593746468]
	TIME [epoch: 42.8 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24883495582934678		[learning rate: 0.0018468]
	Learning Rate: 0.00184676
	LOSS [training: 0.24883495582934678 | validation: 0.20814640206485416]
	TIME [epoch: 42.8 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24481707630056007		[learning rate: 0.0018402]
	Learning Rate: 0.00184023
	LOSS [training: 0.24481707630056007 | validation: 0.20789729077855346]
	TIME [epoch: 42.7 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24120291635775568		[learning rate: 0.0018337]
	Learning Rate: 0.00183372
	LOSS [training: 0.24120291635775568 | validation: 0.2091766942473845]
	TIME [epoch: 42.8 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2449657001415745		[learning rate: 0.0018272]
	Learning Rate: 0.00182724
	LOSS [training: 0.2449657001415745 | validation: 0.21122726682951298]
	TIME [epoch: 42.8 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2412489784763562		[learning rate: 0.0018208]
	Learning Rate: 0.00182078
	LOSS [training: 0.2412489784763562 | validation: 0.20661248942131208]
	TIME [epoch: 42.8 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23997202784333918		[learning rate: 0.0018143]
	Learning Rate: 0.00181434
	LOSS [training: 0.23997202784333918 | validation: 0.21423530597218124]
	TIME [epoch: 42.8 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24423449172226333		[learning rate: 0.0018079]
	Learning Rate: 0.00180792
	LOSS [training: 0.24423449172226333 | validation: 0.20972823694083614]
	TIME [epoch: 42.7 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24686963894549943		[learning rate: 0.0018015]
	Learning Rate: 0.00180153
	LOSS [training: 0.24686963894549943 | validation: 0.210643792987211]
	TIME [epoch: 42.8 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2398040674695815		[learning rate: 0.0017952]
	Learning Rate: 0.00179516
	LOSS [training: 0.2398040674695815 | validation: 0.20962304852792207]
	TIME [epoch: 42.8 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2481649638320059		[learning rate: 0.0017888]
	Learning Rate: 0.00178881
	LOSS [training: 0.2481649638320059 | validation: 0.20574925217214374]
	TIME [epoch: 42.8 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24469329598666537		[learning rate: 0.0017825]
	Learning Rate: 0.00178248
	LOSS [training: 0.24469329598666537 | validation: 0.2061148384726254]
	TIME [epoch: 42.8 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24453136462478184		[learning rate: 0.0017762]
	Learning Rate: 0.00177618
	LOSS [training: 0.24453136462478184 | validation: 0.20912717211496124]
	TIME [epoch: 42.8 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24446636334865746		[learning rate: 0.0017699]
	Learning Rate: 0.0017699
	LOSS [training: 0.24446636334865746 | validation: 0.20536703057565128]
	TIME [epoch: 42.8 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2473721128265949		[learning rate: 0.0017636]
	Learning Rate: 0.00176364
	LOSS [training: 0.2473721128265949 | validation: 0.20814248664161433]
	TIME [epoch: 42.8 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24369237920630415		[learning rate: 0.0017574]
	Learning Rate: 0.0017574
	LOSS [training: 0.24369237920630415 | validation: 0.2110546183220828]
	TIME [epoch: 42.8 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2482125369796709		[learning rate: 0.0017512]
	Learning Rate: 0.00175119
	LOSS [training: 0.2482125369796709 | validation: 0.20832880233540746]
	TIME [epoch: 42.8 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24281178356362676		[learning rate: 0.001745]
	Learning Rate: 0.001745
	LOSS [training: 0.24281178356362676 | validation: 0.20565856476578478]
	TIME [epoch: 42.8 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.243102778708966		[learning rate: 0.0017388]
	Learning Rate: 0.00173883
	LOSS [training: 0.243102778708966 | validation: 0.2041147045376243]
	TIME [epoch: 42.8 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24346602151391436		[learning rate: 0.0017327]
	Learning Rate: 0.00173268
	LOSS [training: 0.24346602151391436 | validation: 0.20556974097963399]
	TIME [epoch: 42.8 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24279921834922427		[learning rate: 0.0017266]
	Learning Rate: 0.00172655
	LOSS [training: 0.24279921834922427 | validation: 0.20906527117197476]
	TIME [epoch: 42.8 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2450809715769203		[learning rate: 0.0017204]
	Learning Rate: 0.00172045
	LOSS [training: 0.2450809715769203 | validation: 0.2047211353627736]
	TIME [epoch: 42.8 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24559941741154145		[learning rate: 0.0017144]
	Learning Rate: 0.00171436
	LOSS [training: 0.24559941741154145 | validation: 0.21732633738607285]
	TIME [epoch: 42.8 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2540502461764876		[learning rate: 0.0017083]
	Learning Rate: 0.0017083
	LOSS [training: 0.2540502461764876 | validation: 0.21029479822870134]
	TIME [epoch: 42.8 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25102291012179034		[learning rate: 0.0017023]
	Learning Rate: 0.00170226
	LOSS [training: 0.25102291012179034 | validation: 0.20664381527515366]
	TIME [epoch: 42.8 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24286879932276006		[learning rate: 0.0016962]
	Learning Rate: 0.00169624
	LOSS [training: 0.24286879932276006 | validation: 0.2069277982986763]
	TIME [epoch: 42.8 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2468414318031813		[learning rate: 0.0016902]
	Learning Rate: 0.00169024
	LOSS [training: 0.2468414318031813 | validation: 0.21104673718479586]
	TIME [epoch: 42.8 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.241272784008791		[learning rate: 0.0016843]
	Learning Rate: 0.00168426
	LOSS [training: 0.241272784008791 | validation: 0.2165786277681371]
	TIME [epoch: 42.8 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24296543280531466		[learning rate: 0.0016783]
	Learning Rate: 0.00167831
	LOSS [training: 0.24296543280531466 | validation: 0.21111059394044132]
	TIME [epoch: 42.8 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24128617572090916		[learning rate: 0.0016724]
	Learning Rate: 0.00167237
	LOSS [training: 0.24128617572090916 | validation: 0.20770910797503245]
	TIME [epoch: 42.8 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24079319081336026		[learning rate: 0.0016665]
	Learning Rate: 0.00166646
	LOSS [training: 0.24079319081336026 | validation: 0.20885297243646178]
	TIME [epoch: 42.8 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2400041909442935		[learning rate: 0.0016606]
	Learning Rate: 0.00166057
	LOSS [training: 0.2400041909442935 | validation: 0.2120850056358159]
	TIME [epoch: 42.8 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24105785551945877		[learning rate: 0.0016547]
	Learning Rate: 0.00165469
	LOSS [training: 0.24105785551945877 | validation: 0.2068437799433045]
	TIME [epoch: 42.8 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24284201222987464		[learning rate: 0.0016488]
	Learning Rate: 0.00164884
	LOSS [training: 0.24284201222987464 | validation: 0.2083347695750343]
	TIME [epoch: 42.8 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24232186047429768		[learning rate: 0.001643]
	Learning Rate: 0.00164301
	LOSS [training: 0.24232186047429768 | validation: 0.2066211455229669]
	TIME [epoch: 42.8 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2441339571674864		[learning rate: 0.0016372]
	Learning Rate: 0.0016372
	LOSS [training: 0.2441339571674864 | validation: 0.20858039785570961]
	TIME [epoch: 42.8 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24365123382091022		[learning rate: 0.0016314]
	Learning Rate: 0.00163141
	LOSS [training: 0.24365123382091022 | validation: 0.21083517076674757]
	TIME [epoch: 42.8 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24139491914977393		[learning rate: 0.0016256]
	Learning Rate: 0.00162564
	LOSS [training: 0.24139491914977393 | validation: 0.21005373797863697]
	TIME [epoch: 42.8 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.245839291693953		[learning rate: 0.0016199]
	Learning Rate: 0.0016199
	LOSS [training: 0.245839291693953 | validation: 0.2144261620606481]
	TIME [epoch: 42.8 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24281477514381966		[learning rate: 0.0016142]
	Learning Rate: 0.00161417
	LOSS [training: 0.24281477514381966 | validation: 0.21066444924498065]
	TIME [epoch: 42.8 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24005968844137862		[learning rate: 0.0016085]
	Learning Rate: 0.00160846
	LOSS [training: 0.24005968844137862 | validation: 0.206523635435531]
	TIME [epoch: 42.8 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24499343697475984		[learning rate: 0.0016028]
	Learning Rate: 0.00160277
	LOSS [training: 0.24499343697475984 | validation: 0.2061659219122995]
	TIME [epoch: 42.8 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24383968575998247		[learning rate: 0.0015971]
	Learning Rate: 0.0015971
	LOSS [training: 0.24383968575998247 | validation: 0.21142837102289996]
	TIME [epoch: 42.8 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24082876658809202		[learning rate: 0.0015915]
	Learning Rate: 0.00159146
	LOSS [training: 0.24082876658809202 | validation: 0.21030305979027392]
	TIME [epoch: 42.8 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24152508903872708		[learning rate: 0.0015858]
	Learning Rate: 0.00158583
	LOSS [training: 0.24152508903872708 | validation: 0.21506473746546534]
	TIME [epoch: 42.8 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2411089002138461		[learning rate: 0.0015802]
	Learning Rate: 0.00158022
	LOSS [training: 0.2411089002138461 | validation: 0.2122756917262863]
	TIME [epoch: 42.8 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2424048392947806		[learning rate: 0.0015746]
	Learning Rate: 0.00157463
	LOSS [training: 0.2424048392947806 | validation: 0.2119234077284382]
	TIME [epoch: 42.8 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2424577176571813		[learning rate: 0.0015691]
	Learning Rate: 0.00156907
	LOSS [training: 0.2424577176571813 | validation: 0.2101731431643643]
	TIME [epoch: 42.8 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24402475700676818		[learning rate: 0.0015635]
	Learning Rate: 0.00156352
	LOSS [training: 0.24402475700676818 | validation: 0.21152077172771128]
	TIME [epoch: 42.8 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.241104525660683		[learning rate: 0.001558]
	Learning Rate: 0.00155799
	LOSS [training: 0.241104525660683 | validation: 0.20984950134994557]
	TIME [epoch: 42.8 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23689404751408946		[learning rate: 0.0015525]
	Learning Rate: 0.00155248
	LOSS [training: 0.23689404751408946 | validation: 0.21202435669932576]
	TIME [epoch: 42.8 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24262900320620054		[learning rate: 0.001547]
	Learning Rate: 0.00154699
	LOSS [training: 0.24262900320620054 | validation: 0.21385283519759501]
	TIME [epoch: 42.8 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24203482318252867		[learning rate: 0.0015415]
	Learning Rate: 0.00154152
	LOSS [training: 0.24203482318252867 | validation: 0.2131975156148756]
	TIME [epoch: 42.8 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24204371711199854		[learning rate: 0.0015361]
	Learning Rate: 0.00153607
	LOSS [training: 0.24204371711199854 | validation: 0.21210744068046283]
	TIME [epoch: 42.8 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24215974391097375		[learning rate: 0.0015306]
	Learning Rate: 0.00153064
	LOSS [training: 0.24215974391097375 | validation: 0.2093079458454395]
	TIME [epoch: 42.8 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24238719142541998		[learning rate: 0.0015252]
	Learning Rate: 0.00152522
	LOSS [training: 0.24238719142541998 | validation: 0.21144034470422773]
	TIME [epoch: 42.8 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24327550338542245		[learning rate: 0.0015198]
	Learning Rate: 0.00151983
	LOSS [training: 0.24327550338542245 | validation: 0.2074921281790766]
	TIME [epoch: 42.8 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24343706124401396		[learning rate: 0.0015145]
	Learning Rate: 0.00151446
	LOSS [training: 0.24343706124401396 | validation: 0.2111425797919136]
	TIME [epoch: 42.8 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24693799877600028		[learning rate: 0.0015091]
	Learning Rate: 0.0015091
	LOSS [training: 0.24693799877600028 | validation: 0.2133386283235848]
	TIME [epoch: 42.8 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24116043760674696		[learning rate: 0.0015038]
	Learning Rate: 0.00150376
	LOSS [training: 0.24116043760674696 | validation: 0.20617674092685362]
	TIME [epoch: 42.8 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24383375473185898		[learning rate: 0.0014984]
	Learning Rate: 0.00149845
	LOSS [training: 0.24383375473185898 | validation: 0.20742855193439133]
	TIME [epoch: 42.8 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24654466266243832		[learning rate: 0.0014931]
	Learning Rate: 0.00149315
	LOSS [training: 0.24654466266243832 | validation: 0.20736527162826732]
	TIME [epoch: 42.8 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2389553969373606		[learning rate: 0.0014879]
	Learning Rate: 0.00148787
	LOSS [training: 0.2389553969373606 | validation: 0.20651315393745961]
	TIME [epoch: 42.8 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24167469703341893		[learning rate: 0.0014826]
	Learning Rate: 0.00148261
	LOSS [training: 0.24167469703341893 | validation: 0.2071653567437611]
	TIME [epoch: 42.8 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24338899683235934		[learning rate: 0.0014774]
	Learning Rate: 0.00147736
	LOSS [training: 0.24338899683235934 | validation: 0.20638478111274267]
	TIME [epoch: 42.8 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24572114799529413		[learning rate: 0.0014721]
	Learning Rate: 0.00147214
	LOSS [training: 0.24572114799529413 | validation: 0.21110110517835193]
	TIME [epoch: 42.8 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24578868846411384		[learning rate: 0.0014669]
	Learning Rate: 0.00146693
	LOSS [training: 0.24578868846411384 | validation: 0.21235359882301036]
	TIME [epoch: 42.8 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24198599793170886		[learning rate: 0.0014617]
	Learning Rate: 0.00146175
	LOSS [training: 0.24198599793170886 | validation: 0.20935592191381108]
	TIME [epoch: 42.8 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24422007805324283		[learning rate: 0.0014566]
	Learning Rate: 0.00145658
	LOSS [training: 0.24422007805324283 | validation: 0.21030699921852306]
	TIME [epoch: 42.8 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24196100319203184		[learning rate: 0.0014514]
	Learning Rate: 0.00145143
	LOSS [training: 0.24196100319203184 | validation: 0.20482805211041413]
	TIME [epoch: 42.8 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24248681977765432		[learning rate: 0.0014463]
	Learning Rate: 0.00144629
	LOSS [training: 0.24248681977765432 | validation: 0.21164970099305158]
	TIME [epoch: 42.8 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24463458268893878		[learning rate: 0.0014412]
	Learning Rate: 0.00144118
	LOSS [training: 0.24463458268893878 | validation: 0.21178210143620957]
	TIME [epoch: 42.8 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2453068125255011		[learning rate: 0.0014361]
	Learning Rate: 0.00143608
	LOSS [training: 0.2453068125255011 | validation: 0.20616375845292606]
	TIME [epoch: 42.7 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2420785462398191		[learning rate: 0.001431]
	Learning Rate: 0.001431
	LOSS [training: 0.2420785462398191 | validation: 0.2166261989216936]
	TIME [epoch: 42.8 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24482537008314154		[learning rate: 0.0014259]
	Learning Rate: 0.00142594
	LOSS [training: 0.24482537008314154 | validation: 0.21522512381008588]
	TIME [epoch: 42.8 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2541728365174128		[learning rate: 0.0014209]
	Learning Rate: 0.0014209
	LOSS [training: 0.2541728365174128 | validation: 0.23847579351688805]
	TIME [epoch: 42.8 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26302042588336444		[learning rate: 0.0014159]
	Learning Rate: 0.00141588
	LOSS [training: 0.26302042588336444 | validation: 0.2324116162276228]
	TIME [epoch: 42.8 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2560313105489678		[learning rate: 0.0014109]
	Learning Rate: 0.00141087
	LOSS [training: 0.2560313105489678 | validation: 0.22326368953398154]
	TIME [epoch: 42.8 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24941523457262418		[learning rate: 0.0014059]
	Learning Rate: 0.00140588
	LOSS [training: 0.24941523457262418 | validation: 0.22393346003594566]
	TIME [epoch: 42.7 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24736540473091007		[learning rate: 0.0014009]
	Learning Rate: 0.00140091
	LOSS [training: 0.24736540473091007 | validation: 0.2201228985506206]
	TIME [epoch: 42.7 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24830591423175466		[learning rate: 0.001396]
	Learning Rate: 0.00139596
	LOSS [training: 0.24830591423175466 | validation: 0.21466377115931068]
	TIME [epoch: 42.8 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2466270322975748		[learning rate: 0.001391]
	Learning Rate: 0.00139102
	LOSS [training: 0.2466270322975748 | validation: 0.21903362040590807]
	TIME [epoch: 42.8 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2413188089404442		[learning rate: 0.0013861]
	Learning Rate: 0.0013861
	LOSS [training: 0.2413188089404442 | validation: 0.21407948093446522]
	TIME [epoch: 42.8 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24198718012353407		[learning rate: 0.0013812]
	Learning Rate: 0.0013812
	LOSS [training: 0.24198718012353407 | validation: 0.21309061347448682]
	TIME [epoch: 42.8 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24638813546114333		[learning rate: 0.0013763]
	Learning Rate: 0.00137632
	LOSS [training: 0.24638813546114333 | validation: 0.21509741279918942]
	TIME [epoch: 42.8 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24169674543540257		[learning rate: 0.0013714]
	Learning Rate: 0.00137145
	LOSS [training: 0.24169674543540257 | validation: 0.2095891719358259]
	TIME [epoch: 42.8 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24324955692791572		[learning rate: 0.0013666]
	Learning Rate: 0.0013666
	LOSS [training: 0.24324955692791572 | validation: 0.2123426666686945]
	TIME [epoch: 42.8 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2413536086739713		[learning rate: 0.0013618]
	Learning Rate: 0.00136177
	LOSS [training: 0.2413536086739713 | validation: 0.2076414192121327]
	TIME [epoch: 42.7 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24337893483347228		[learning rate: 0.001357]
	Learning Rate: 0.00135695
	LOSS [training: 0.24337893483347228 | validation: 0.21338199325806545]
	TIME [epoch: 42.8 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2402677788761971		[learning rate: 0.0013522]
	Learning Rate: 0.00135215
	LOSS [training: 0.2402677788761971 | validation: 0.2103793992981211]
	TIME [epoch: 42.7 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24087176501091515		[learning rate: 0.0013474]
	Learning Rate: 0.00134737
	LOSS [training: 0.24087176501091515 | validation: 0.2122144912519645]
	TIME [epoch: 42.8 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2407613579074603		[learning rate: 0.0013426]
	Learning Rate: 0.00134261
	LOSS [training: 0.2407613579074603 | validation: 0.21003596716041262]
	TIME [epoch: 42.7 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24439104271992906		[learning rate: 0.0013379]
	Learning Rate: 0.00133786
	LOSS [training: 0.24439104271992906 | validation: 0.20715791581495657]
	TIME [epoch: 42.8 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24121743072257051		[learning rate: 0.0013331]
	Learning Rate: 0.00133313
	LOSS [training: 0.24121743072257051 | validation: 0.20842282998222167]
	TIME [epoch: 42.7 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2397201985075191		[learning rate: 0.0013284]
	Learning Rate: 0.00132841
	LOSS [training: 0.2397201985075191 | validation: 0.20730531749734676]
	TIME [epoch: 42.8 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24228533251832682		[learning rate: 0.0013237]
	Learning Rate: 0.00132372
	LOSS [training: 0.24228533251832682 | validation: 0.21069142446786254]
	TIME [epoch: 42.7 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24185150255598475		[learning rate: 0.001319]
	Learning Rate: 0.00131904
	LOSS [training: 0.24185150255598475 | validation: 0.20857432417725574]
	TIME [epoch: 42.8 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24336864842929276		[learning rate: 0.0013144]
	Learning Rate: 0.00131437
	LOSS [training: 0.24336864842929276 | validation: 0.20826637603540826]
	TIME [epoch: 42.7 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24347710935222375		[learning rate: 0.0013097]
	Learning Rate: 0.00130972
	LOSS [training: 0.24347710935222375 | validation: 0.20636853219643442]
	TIME [epoch: 42.7 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2438518796486225		[learning rate: 0.0013051]
	Learning Rate: 0.00130509
	LOSS [training: 0.2438518796486225 | validation: 0.2075779219280804]
	TIME [epoch: 42.7 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24592245820517578		[learning rate: 0.0013005]
	Learning Rate: 0.00130048
	LOSS [training: 0.24592245820517578 | validation: 0.21269277185858337]
	TIME [epoch: 42.7 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24393611464915557		[learning rate: 0.0012959]
	Learning Rate: 0.00129588
	LOSS [training: 0.24393611464915557 | validation: 0.21897216680572593]
	TIME [epoch: 42.8 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24792304316379107		[learning rate: 0.0012913]
	Learning Rate: 0.0012913
	LOSS [training: 0.24792304316379107 | validation: 0.2146220565560772]
	TIME [epoch: 42.8 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24561057489710367		[learning rate: 0.0012867]
	Learning Rate: 0.00128673
	LOSS [training: 0.24561057489710367 | validation: 0.21142627097632052]
	TIME [epoch: 42.8 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2463648872655088		[learning rate: 0.0012822]
	Learning Rate: 0.00128218
	LOSS [training: 0.2463648872655088 | validation: 0.20744410251370513]
	TIME [epoch: 42.7 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2441564414049611		[learning rate: 0.0012776]
	Learning Rate: 0.00127765
	LOSS [training: 0.2441564414049611 | validation: 0.2096790691420971]
	TIME [epoch: 42.7 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24072613997332995		[learning rate: 0.0012731]
	Learning Rate: 0.00127313
	LOSS [training: 0.24072613997332995 | validation: 0.21147726080849819]
	TIME [epoch: 42.8 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2419497013776807		[learning rate: 0.0012686]
	Learning Rate: 0.00126863
	LOSS [training: 0.2419497013776807 | validation: 0.2087392434800915]
	TIME [epoch: 42.8 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24345834620161746		[learning rate: 0.0012641]
	Learning Rate: 0.00126414
	LOSS [training: 0.24345834620161746 | validation: 0.20320697693401266]
	TIME [epoch: 42.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_634.pth
	Model improved!!!
EPOCH 635/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2376214408189996		[learning rate: 0.0012597]
	Learning Rate: 0.00125967
	LOSS [training: 0.2376214408189996 | validation: 0.2077027555773902]
	TIME [epoch: 42.7 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24018954853992358		[learning rate: 0.0012552]
	Learning Rate: 0.00125521
	LOSS [training: 0.24018954853992358 | validation: 0.20619737032709828]
	TIME [epoch: 42.7 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24131685694281568		[learning rate: 0.0012508]
	Learning Rate: 0.00125078
	LOSS [training: 0.24131685694281568 | validation: 0.20578729531386153]
	TIME [epoch: 42.7 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24323237322078892		[learning rate: 0.0012464]
	Learning Rate: 0.00124635
	LOSS [training: 0.24323237322078892 | validation: 0.2085841583725308]
	TIME [epoch: 42.8 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24481559411169793		[learning rate: 0.0012419]
	Learning Rate: 0.00124195
	LOSS [training: 0.24481559411169793 | validation: 0.20264693703947337]
	TIME [epoch: 42.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_639.pth
	Model improved!!!
EPOCH 640/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24360936177212397		[learning rate: 0.0012376]
	Learning Rate: 0.00123755
	LOSS [training: 0.24360936177212397 | validation: 0.20094801693463618]
	TIME [epoch: 42.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_640.pth
	Model improved!!!
EPOCH 641/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24319710477855472		[learning rate: 0.0012332]
	Learning Rate: 0.00123318
	LOSS [training: 0.24319710477855472 | validation: 0.2059295327035689]
	TIME [epoch: 42.8 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24319987097859616		[learning rate: 0.0012288]
	Learning Rate: 0.00122882
	LOSS [training: 0.24319987097859616 | validation: 0.20356558813260853]
	TIME [epoch: 42.8 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2400322169935465		[learning rate: 0.0012245]
	Learning Rate: 0.00122447
	LOSS [training: 0.2400322169935465 | validation: 0.20943293898270535]
	TIME [epoch: 42.8 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24310959396121043		[learning rate: 0.0012201]
	Learning Rate: 0.00122014
	LOSS [training: 0.24310959396121043 | validation: 0.20852924199534995]
	TIME [epoch: 42.8 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24451316155076608		[learning rate: 0.0012158]
	Learning Rate: 0.00121583
	LOSS [training: 0.24451316155076608 | validation: 0.20779300329886805]
	TIME [epoch: 42.7 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23831852530560083		[learning rate: 0.0012115]
	Learning Rate: 0.00121153
	LOSS [training: 0.23831852530560083 | validation: 0.20576079499796415]
	TIME [epoch: 42.7 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2434181997866699		[learning rate: 0.0012072]
	Learning Rate: 0.00120724
	LOSS [training: 0.2434181997866699 | validation: 0.2087463389414456]
	TIME [epoch: 42.7 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24339811265087016		[learning rate: 0.001203]
	Learning Rate: 0.00120297
	LOSS [training: 0.24339811265087016 | validation: 0.20663957934131258]
	TIME [epoch: 42.8 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24094311326662873		[learning rate: 0.0011987]
	Learning Rate: 0.00119872
	LOSS [training: 0.24094311326662873 | validation: 0.20758029255758054]
	TIME [epoch: 42.7 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24698811985877908		[learning rate: 0.0011945]
	Learning Rate: 0.00119448
	LOSS [training: 0.24698811985877908 | validation: 0.21198260738772218]
	TIME [epoch: 42.8 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24295075378946152		[learning rate: 0.0011903]
	Learning Rate: 0.00119026
	LOSS [training: 0.24295075378946152 | validation: 0.20921150915978606]
	TIME [epoch: 42.8 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24889013987092912		[learning rate: 0.001186]
	Learning Rate: 0.00118605
	LOSS [training: 0.24889013987092912 | validation: 0.21021326897217024]
	TIME [epoch: 42.8 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2445284509744958		[learning rate: 0.0011819]
	Learning Rate: 0.00118185
	LOSS [training: 0.2445284509744958 | validation: 0.20432798633435195]
	TIME [epoch: 42.8 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24293490741286727		[learning rate: 0.0011777]
	Learning Rate: 0.00117768
	LOSS [training: 0.24293490741286727 | validation: 0.20637261325125927]
	TIME [epoch: 42.8 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24186251741344358		[learning rate: 0.0011735]
	Learning Rate: 0.00117351
	LOSS [training: 0.24186251741344358 | validation: 0.20884313711032196]
	TIME [epoch: 42.7 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24444789718852247		[learning rate: 0.0011694]
	Learning Rate: 0.00116936
	LOSS [training: 0.24444789718852247 | validation: 0.20722148728395143]
	TIME [epoch: 42.8 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23967304839201567		[learning rate: 0.0011652]
	Learning Rate: 0.00116523
	LOSS [training: 0.23967304839201567 | validation: 0.20822771831719322]
	TIME [epoch: 42.7 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24304593669694416		[learning rate: 0.0011611]
	Learning Rate: 0.00116111
	LOSS [training: 0.24304593669694416 | validation: 0.20341593720296397]
	TIME [epoch: 42.8 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23905247774134275		[learning rate: 0.001157]
	Learning Rate: 0.001157
	LOSS [training: 0.23905247774134275 | validation: 0.2157157987637947]
	TIME [epoch: 42.8 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2411219566605837		[learning rate: 0.0011529]
	Learning Rate: 0.00115291
	LOSS [training: 0.2411219566605837 | validation: 0.21349304550827633]
	TIME [epoch: 42.8 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24373802416985293		[learning rate: 0.0011488]
	Learning Rate: 0.00114883
	LOSS [training: 0.24373802416985293 | validation: 0.21439359233326974]
	TIME [epoch: 42.7 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24463876755931016		[learning rate: 0.0011448]
	Learning Rate: 0.00114477
	LOSS [training: 0.24463876755931016 | validation: 0.20738009765809742]
	TIME [epoch: 42.8 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2432701447868805		[learning rate: 0.0011407]
	Learning Rate: 0.00114072
	LOSS [training: 0.2432701447868805 | validation: 0.2124260106764766]
	TIME [epoch: 42.8 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23858914281673183		[learning rate: 0.0011367]
	Learning Rate: 0.00113669
	LOSS [training: 0.23858914281673183 | validation: 0.21061891944479566]
	TIME [epoch: 42.8 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24076648221318		[learning rate: 0.0011327]
	Learning Rate: 0.00113267
	LOSS [training: 0.24076648221318 | validation: 0.21222361893232664]
	TIME [epoch: 42.7 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24239947916340862		[learning rate: 0.0011287]
	Learning Rate: 0.00112866
	LOSS [training: 0.24239947916340862 | validation: 0.20961349200863708]
	TIME [epoch: 42.8 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24089725296117534		[learning rate: 0.0011247]
	Learning Rate: 0.00112467
	LOSS [training: 0.24089725296117534 | validation: 0.21154683431389548]
	TIME [epoch: 42.7 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24319926678008616		[learning rate: 0.0011207]
	Learning Rate: 0.00112069
	LOSS [training: 0.24319926678008616 | validation: 0.21316067745794923]
	TIME [epoch: 42.8 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24197138136021037		[learning rate: 0.0011167]
	Learning Rate: 0.00111673
	LOSS [training: 0.24197138136021037 | validation: 0.21000611424855223]
	TIME [epoch: 42.8 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23780373696822696		[learning rate: 0.0011128]
	Learning Rate: 0.00111278
	LOSS [training: 0.23780373696822696 | validation: 0.21004829590341303]
	TIME [epoch: 42.8 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2404993225019223		[learning rate: 0.0011088]
	Learning Rate: 0.00110885
	LOSS [training: 0.2404993225019223 | validation: 0.2094702513777485]
	TIME [epoch: 42.7 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24497269260923418		[learning rate: 0.0011049]
	Learning Rate: 0.00110493
	LOSS [training: 0.24497269260923418 | validation: 0.20698395314199863]
	TIME [epoch: 42.8 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24002805013108006		[learning rate: 0.001101]
	Learning Rate: 0.00110102
	LOSS [training: 0.24002805013108006 | validation: 0.2092425122513773]
	TIME [epoch: 42.8 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24430890149334672		[learning rate: 0.0010971]
	Learning Rate: 0.00109713
	LOSS [training: 0.24430890149334672 | validation: 0.21082136363520432]
	TIME [epoch: 42.8 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24362991414154936		[learning rate: 0.0010932]
	Learning Rate: 0.00109325
	LOSS [training: 0.24362991414154936 | validation: 0.21408775177729494]
	TIME [epoch: 42.8 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24646714676006132		[learning rate: 0.0010894]
	Learning Rate: 0.00108938
	LOSS [training: 0.24646714676006132 | validation: 0.21704457721181125]
	TIME [epoch: 42.8 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24273469906289305		[learning rate: 0.0010855]
	Learning Rate: 0.00108553
	LOSS [training: 0.24273469906289305 | validation: 0.20993709865340787]
	TIME [epoch: 42.7 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2434709638643692		[learning rate: 0.0010817]
	Learning Rate: 0.00108169
	LOSS [training: 0.2434709638643692 | validation: 0.216777655430357]
	TIME [epoch: 42.7 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24294393538926728		[learning rate: 0.0010779]
	Learning Rate: 0.00107786
	LOSS [training: 0.24294393538926728 | validation: 0.2128565129354114]
	TIME [epoch: 42.7 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24450601877188258		[learning rate: 0.0010741]
	Learning Rate: 0.00107405
	LOSS [training: 0.24450601877188258 | validation: 0.21354710800067664]
	TIME [epoch: 42.8 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24324132983157784		[learning rate: 0.0010703]
	Learning Rate: 0.00107025
	LOSS [training: 0.24324132983157784 | validation: 0.21047509630498115]
	TIME [epoch: 42.8 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24335007167956446		[learning rate: 0.0010665]
	Learning Rate: 0.00106647
	LOSS [training: 0.24335007167956446 | validation: 0.21398659788365815]
	TIME [epoch: 42.8 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24111572690096025		[learning rate: 0.0010627]
	Learning Rate: 0.0010627
	LOSS [training: 0.24111572690096025 | validation: 0.21300626090288793]
	TIME [epoch: 42.7 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2454963554342889		[learning rate: 0.0010589]
	Learning Rate: 0.00105894
	LOSS [training: 0.2454963554342889 | validation: 0.21426658257812375]
	TIME [epoch: 42.8 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24468370348133575		[learning rate: 0.0010552]
	Learning Rate: 0.0010552
	LOSS [training: 0.24468370348133575 | validation: 0.21442346573196716]
	TIME [epoch: 42.7 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23939723383308223		[learning rate: 0.0010515]
	Learning Rate: 0.00105147
	LOSS [training: 0.23939723383308223 | validation: 0.21331640134460597]
	TIME [epoch: 42.8 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2399395828096176		[learning rate: 0.0010477]
	Learning Rate: 0.00104775
	LOSS [training: 0.2399395828096176 | validation: 0.21488055333963668]
	TIME [epoch: 42.8 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24304314635673643		[learning rate: 0.001044]
	Learning Rate: 0.00104404
	LOSS [training: 0.24304314635673643 | validation: 0.21570058699777003]
	TIME [epoch: 42.8 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24097061580573673		[learning rate: 0.0010404]
	Learning Rate: 0.00104035
	LOSS [training: 0.24097061580573673 | validation: 0.21207247181044311]
	TIME [epoch: 42.7 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24209186735801125		[learning rate: 0.0010367]
	Learning Rate: 0.00103667
	LOSS [training: 0.24209186735801125 | validation: 0.21217540146158034]
	TIME [epoch: 42.8 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24133934606182553		[learning rate: 0.001033]
	Learning Rate: 0.00103301
	LOSS [training: 0.24133934606182553 | validation: 0.21069916388254498]
	TIME [epoch: 42.8 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24388092312884693		[learning rate: 0.0010294]
	Learning Rate: 0.00102935
	LOSS [training: 0.24388092312884693 | validation: 0.21519661905390927]
	TIME [epoch: 42.8 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24451611744498802		[learning rate: 0.0010257]
	Learning Rate: 0.00102571
	LOSS [training: 0.24451611744498802 | validation: 0.21425959797683855]
	TIME [epoch: 42.8 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2475204804958623		[learning rate: 0.0010221]
	Learning Rate: 0.00102209
	LOSS [training: 0.2475204804958623 | validation: 0.21313884684405654]
	TIME [epoch: 42.8 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24790746320255486		[learning rate: 0.0010185]
	Learning Rate: 0.00101847
	LOSS [training: 0.24790746320255486 | validation: 0.20876101074375347]
	TIME [epoch: 42.7 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24407162957159853		[learning rate: 0.0010149]
	Learning Rate: 0.00101487
	LOSS [training: 0.24407162957159853 | validation: 0.2106482576648238]
	TIME [epoch: 42.8 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.245266139652953		[learning rate: 0.0010113]
	Learning Rate: 0.00101128
	LOSS [training: 0.245266139652953 | validation: 0.2078224972769056]
	TIME [epoch: 42.7 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24174753982237496		[learning rate: 0.0010077]
	Learning Rate: 0.0010077
	LOSS [training: 0.24174753982237496 | validation: 0.20734543500073555]
	TIME [epoch: 42.8 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24343024602378274		[learning rate: 0.0010041]
	Learning Rate: 0.00100414
	LOSS [training: 0.24343024602378274 | validation: 0.20788115385678113]
	TIME [epoch: 42.7 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24247948338808376		[learning rate: 0.0010006]
	Learning Rate: 0.00100059
	LOSS [training: 0.24247948338808376 | validation: 0.21199991045800695]
	TIME [epoch: 42.8 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24757465968953085		[learning rate: 0.00099705]
	Learning Rate: 0.000997052
	LOSS [training: 0.24757465968953085 | validation: 0.2111469499326922]
	TIME [epoch: 42.7 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2402943669274212		[learning rate: 0.00099353]
	Learning Rate: 0.000993527
	LOSS [training: 0.2402943669274212 | validation: 0.20610239338176667]
	TIME [epoch: 42.7 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24290109026850001		[learning rate: 0.00099001]
	Learning Rate: 0.000990013
	LOSS [training: 0.24290109026850001 | validation: 0.20857544646036538]
	TIME [epoch: 42.7 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24212567403898125		[learning rate: 0.00098651]
	Learning Rate: 0.000986513
	LOSS [training: 0.24212567403898125 | validation: 0.20984772135102786]
	TIME [epoch: 42.8 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24133865377067207		[learning rate: 0.00098302]
	Learning Rate: 0.000983024
	LOSS [training: 0.24133865377067207 | validation: 0.2111875246196513]
	TIME [epoch: 42.8 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24363340087551902		[learning rate: 0.00097955]
	Learning Rate: 0.000979548
	LOSS [training: 0.24363340087551902 | validation: 0.20898880226604785]
	TIME [epoch: 42.8 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2406626153688318		[learning rate: 0.00097608]
	Learning Rate: 0.000976084
	LOSS [training: 0.2406626153688318 | validation: 0.20635116459958835]
	TIME [epoch: 42.8 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24392442529737224		[learning rate: 0.00097263]
	Learning Rate: 0.000972632
	LOSS [training: 0.24392442529737224 | validation: 0.20357408508844843]
	TIME [epoch: 42.8 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2394906298884845		[learning rate: 0.00096919]
	Learning Rate: 0.000969193
	LOSS [training: 0.2394906298884845 | validation: 0.20275068362145698]
	TIME [epoch: 42.8 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24271619377648493		[learning rate: 0.00096577]
	Learning Rate: 0.000965766
	LOSS [training: 0.24271619377648493 | validation: 0.20579962968281046]
	TIME [epoch: 42.8 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24113177426029145		[learning rate: 0.00096235]
	Learning Rate: 0.000962351
	LOSS [training: 0.24113177426029145 | validation: 0.20487274105416114]
	TIME [epoch: 42.7 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2432524886667907		[learning rate: 0.00095895]
	Learning Rate: 0.000958948
	LOSS [training: 0.2432524886667907 | validation: 0.20541994847120745]
	TIME [epoch: 42.7 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2405751805835515		[learning rate: 0.00095556]
	Learning Rate: 0.000955557
	LOSS [training: 0.2405751805835515 | validation: 0.2070688669614241]
	TIME [epoch: 42.8 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24516238491626388		[learning rate: 0.00095218]
	Learning Rate: 0.000952178
	LOSS [training: 0.24516238491626388 | validation: 0.2015326899621807]
	TIME [epoch: 42.8 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24280158209681155		[learning rate: 0.00094881]
	Learning Rate: 0.00094881
	LOSS [training: 0.24280158209681155 | validation: 0.20348803548236322]
	TIME [epoch: 42.7 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.244025975952044		[learning rate: 0.00094546]
	Learning Rate: 0.000945455
	LOSS [training: 0.244025975952044 | validation: 0.20322325401411412]
	TIME [epoch: 42.8 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24305120746619824		[learning rate: 0.00094211]
	Learning Rate: 0.000942112
	LOSS [training: 0.24305120746619824 | validation: 0.20476997584162765]
	TIME [epoch: 42.8 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24296987609143897		[learning rate: 0.00093878]
	Learning Rate: 0.000938781
	LOSS [training: 0.24296987609143897 | validation: 0.20555715714498865]
	TIME [epoch: 42.8 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24732589108898517		[learning rate: 0.00093546]
	Learning Rate: 0.000935461
	LOSS [training: 0.24732589108898517 | validation: 0.1990447970362096]
	TIME [epoch: 42.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_719.pth
	Model improved!!!
EPOCH 720/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24319296161076112		[learning rate: 0.00093215]
	Learning Rate: 0.000932153
	LOSS [training: 0.24319296161076112 | validation: 0.20211808259956537]
	TIME [epoch: 42.8 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24246153333847867		[learning rate: 0.00092886]
	Learning Rate: 0.000928857
	LOSS [training: 0.24246153333847867 | validation: 0.20438696685945068]
	TIME [epoch: 42.8 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24228507889638629		[learning rate: 0.00092557]
	Learning Rate: 0.000925572
	LOSS [training: 0.24228507889638629 | validation: 0.2002141816282789]
	TIME [epoch: 42.8 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23906046145172163		[learning rate: 0.0009223]
	Learning Rate: 0.000922299
	LOSS [training: 0.23906046145172163 | validation: 0.2079610198159755]
	TIME [epoch: 42.7 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24041658210713743		[learning rate: 0.00091904]
	Learning Rate: 0.000919038
	LOSS [training: 0.24041658210713743 | validation: 0.20512913959941814]
	TIME [epoch: 42.7 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24035948461460951		[learning rate: 0.00091579]
	Learning Rate: 0.000915788
	LOSS [training: 0.24035948461460951 | validation: 0.20674152921588923]
	TIME [epoch: 42.7 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24254703764589083		[learning rate: 0.00091255]
	Learning Rate: 0.000912549
	LOSS [training: 0.24254703764589083 | validation: 0.20222382952802712]
	TIME [epoch: 42.8 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24141158833462875		[learning rate: 0.00090932]
	Learning Rate: 0.000909323
	LOSS [training: 0.24141158833462875 | validation: 0.21108261313957755]
	TIME [epoch: 42.7 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2427180295354114		[learning rate: 0.00090611]
	Learning Rate: 0.000906107
	LOSS [training: 0.2427180295354114 | validation: 0.20754139595558385]
	TIME [epoch: 42.8 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24286289886406429		[learning rate: 0.0009029]
	Learning Rate: 0.000902903
	LOSS [training: 0.24286289886406429 | validation: 0.2043951570245373]
	TIME [epoch: 42.8 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24348691228182215		[learning rate: 0.00089971]
	Learning Rate: 0.00089971
	LOSS [training: 0.24348691228182215 | validation: 0.20228378510580253]
	TIME [epoch: 42.8 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2420929089071564		[learning rate: 0.00089653]
	Learning Rate: 0.000896529
	LOSS [training: 0.2420929089071564 | validation: 0.20802910586471052]
	TIME [epoch: 42.8 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24051724933053445		[learning rate: 0.00089336]
	Learning Rate: 0.000893358
	LOSS [training: 0.24051724933053445 | validation: 0.20491927496539772]
	TIME [epoch: 42.8 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23967406160134605		[learning rate: 0.0008902]
	Learning Rate: 0.000890199
	LOSS [training: 0.23967406160134605 | validation: 0.20643289575295798]
	TIME [epoch: 42.7 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2432498505412173		[learning rate: 0.00088705]
	Learning Rate: 0.000887051
	LOSS [training: 0.2432498505412173 | validation: 0.2073876300148892]
	TIME [epoch: 42.8 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24467031483314824		[learning rate: 0.00088391]
	Learning Rate: 0.000883914
	LOSS [training: 0.24467031483314824 | validation: 0.20846093388681966]
	TIME [epoch: 42.7 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2436950651773048		[learning rate: 0.00088079]
	Learning Rate: 0.000880789
	LOSS [training: 0.2436950651773048 | validation: 0.20576331813244528]
	TIME [epoch: 42.8 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2381269561243753		[learning rate: 0.00087767]
	Learning Rate: 0.000877674
	LOSS [training: 0.2381269561243753 | validation: 0.2058579099679354]
	TIME [epoch: 42.7 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.237785186799097		[learning rate: 0.00087457]
	Learning Rate: 0.000874571
	LOSS [training: 0.237785186799097 | validation: 0.20460489065871937]
	TIME [epoch: 42.8 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24254150580578823		[learning rate: 0.00087148]
	Learning Rate: 0.000871478
	LOSS [training: 0.24254150580578823 | validation: 0.20770044105179744]
	TIME [epoch: 42.8 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2395282162299989		[learning rate: 0.0008684]
	Learning Rate: 0.000868396
	LOSS [training: 0.2395282162299989 | validation: 0.20464078755374113]
	TIME [epoch: 42.8 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24137688309814107		[learning rate: 0.00086533]
	Learning Rate: 0.000865326
	LOSS [training: 0.24137688309814107 | validation: 0.20354843799367886]
	TIME [epoch: 42.8 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24198649201984035		[learning rate: 0.00086227]
	Learning Rate: 0.000862266
	LOSS [training: 0.24198649201984035 | validation: 0.2074524358431656]
	TIME [epoch: 42.8 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24193055152960127		[learning rate: 0.00085922]
	Learning Rate: 0.000859216
	LOSS [training: 0.24193055152960127 | validation: 0.20580988381693038]
	TIME [epoch: 42.7 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24164642199956474		[learning rate: 0.00085618]
	Learning Rate: 0.000856178
	LOSS [training: 0.24164642199956474 | validation: 0.20736871889921718]
	TIME [epoch: 42.8 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2426204371163474		[learning rate: 0.00085315]
	Learning Rate: 0.00085315
	LOSS [training: 0.2426204371163474 | validation: 0.20640429525014267]
	TIME [epoch: 42.8 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2435032393917842		[learning rate: 0.00085013]
	Learning Rate: 0.000850134
	LOSS [training: 0.2435032393917842 | validation: 0.20581559868831373]
	TIME [epoch: 42.8 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24182248636192918		[learning rate: 0.00084713]
	Learning Rate: 0.000847127
	LOSS [training: 0.24182248636192918 | validation: 0.20554261171981633]
	TIME [epoch: 42.7 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23923770255732632		[learning rate: 0.00084413]
	Learning Rate: 0.000844132
	LOSS [training: 0.23923770255732632 | validation: 0.20525738616905484]
	TIME [epoch: 42.8 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23978121315144588		[learning rate: 0.00084115]
	Learning Rate: 0.000841147
	LOSS [training: 0.23978121315144588 | validation: 0.2068367068242813]
	TIME [epoch: 42.7 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2416266336118026		[learning rate: 0.00083817]
	Learning Rate: 0.000838172
	LOSS [training: 0.2416266336118026 | validation: 0.20385153968079894]
	TIME [epoch: 42.7 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24253605765932207		[learning rate: 0.00083521]
	Learning Rate: 0.000835209
	LOSS [training: 0.24253605765932207 | validation: 0.203691483828531]
	TIME [epoch: 42.7 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.243116852680049		[learning rate: 0.00083225]
	Learning Rate: 0.000832255
	LOSS [training: 0.243116852680049 | validation: 0.20742384541685008]
	TIME [epoch: 42.8 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2403142446260277		[learning rate: 0.00082931]
	Learning Rate: 0.000829312
	LOSS [training: 0.2403142446260277 | validation: 0.20496829117234086]
	TIME [epoch: 42.7 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24334996713932186		[learning rate: 0.00082638]
	Learning Rate: 0.000826379
	LOSS [training: 0.24334996713932186 | validation: 0.20761670168514684]
	TIME [epoch: 42.8 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24332772066609618		[learning rate: 0.00082346]
	Learning Rate: 0.000823457
	LOSS [training: 0.24332772066609618 | validation: 0.20563001350916502]
	TIME [epoch: 42.7 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2437213881025496		[learning rate: 0.00082055]
	Learning Rate: 0.000820545
	LOSS [training: 0.2437213881025496 | validation: 0.2066547401478081]
	TIME [epoch: 42.8 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23709392646758565		[learning rate: 0.00081764]
	Learning Rate: 0.000817644
	LOSS [training: 0.23709392646758565 | validation: 0.2075254681941864]
	TIME [epoch: 42.8 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2409276993793491		[learning rate: 0.00081475]
	Learning Rate: 0.000814752
	LOSS [training: 0.2409276993793491 | validation: 0.20675210999543409]
	TIME [epoch: 42.8 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24186003003622433		[learning rate: 0.00081187]
	Learning Rate: 0.000811871
	LOSS [training: 0.24186003003622433 | validation: 0.20490997580502923]
	TIME [epoch: 42.7 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24192112876195085		[learning rate: 0.000809]
	Learning Rate: 0.000809
	LOSS [training: 0.24192112876195085 | validation: 0.20986259162860016]
	TIME [epoch: 42.8 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24174499017966852		[learning rate: 0.00080614]
	Learning Rate: 0.00080614
	LOSS [training: 0.24174499017966852 | validation: 0.20777081632724417]
	TIME [epoch: 42.7 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24212422059911884		[learning rate: 0.00080329]
	Learning Rate: 0.000803289
	LOSS [training: 0.24212422059911884 | validation: 0.20523384799913186]
	TIME [epoch: 42.8 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2413417228467655		[learning rate: 0.00080045]
	Learning Rate: 0.000800448
	LOSS [training: 0.2413417228467655 | validation: 0.20068397918720948]
	TIME [epoch: 42.7 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2406760950146023		[learning rate: 0.00079762]
	Learning Rate: 0.000797618
	LOSS [training: 0.2406760950146023 | validation: 0.20904680316715982]
	TIME [epoch: 42.8 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23987056521345282		[learning rate: 0.0007948]
	Learning Rate: 0.000794797
	LOSS [training: 0.23987056521345282 | validation: 0.20876182997473433]
	TIME [epoch: 42.7 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2440303262076761		[learning rate: 0.00079199]
	Learning Rate: 0.000791987
	LOSS [training: 0.2440303262076761 | validation: 0.20878399930718103]
	TIME [epoch: 42.8 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24043843488454453		[learning rate: 0.00078919]
	Learning Rate: 0.000789186
	LOSS [training: 0.24043843488454453 | validation: 0.208593785941815]
	TIME [epoch: 42.8 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2392990269526839		[learning rate: 0.0007864]
	Learning Rate: 0.000786396
	LOSS [training: 0.2392990269526839 | validation: 0.209291176159005]
	TIME [epoch: 42.8 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24181606534870612		[learning rate: 0.00078361]
	Learning Rate: 0.000783615
	LOSS [training: 0.24181606534870612 | validation: 0.20722405158975965]
	TIME [epoch: 42.7 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24032263753214922		[learning rate: 0.00078084]
	Learning Rate: 0.000780844
	LOSS [training: 0.24032263753214922 | validation: 0.2092304388452293]
	TIME [epoch: 42.8 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24417260700957688		[learning rate: 0.00077808]
	Learning Rate: 0.000778082
	LOSS [training: 0.24417260700957688 | validation: 0.20519155269977443]
	TIME [epoch: 42.7 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24297384528094226		[learning rate: 0.00077533]
	Learning Rate: 0.000775331
	LOSS [training: 0.24297384528094226 | validation: 0.20748034968616058]
	TIME [epoch: 42.7 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24282328013618684		[learning rate: 0.00077259]
	Learning Rate: 0.000772589
	LOSS [training: 0.24282328013618684 | validation: 0.20572878474082543]
	TIME [epoch: 42.7 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23651427527519517		[learning rate: 0.00076986]
	Learning Rate: 0.000769857
	LOSS [training: 0.23651427527519517 | validation: 0.20879494439347032]
	TIME [epoch: 42.7 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23642060961403732		[learning rate: 0.00076714]
	Learning Rate: 0.000767135
	LOSS [training: 0.23642060961403732 | validation: 0.20591212810978013]
	TIME [epoch: 42.7 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.238469352430156		[learning rate: 0.00076442]
	Learning Rate: 0.000764422
	LOSS [training: 0.238469352430156 | validation: 0.20796284852020355]
	TIME [epoch: 42.7 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24188190985474656		[learning rate: 0.00076172]
	Learning Rate: 0.000761719
	LOSS [training: 0.24188190985474656 | validation: 0.2080372768534274]
	TIME [epoch: 42.7 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24373184459075115		[learning rate: 0.00075903]
	Learning Rate: 0.000759026
	LOSS [training: 0.24373184459075115 | validation: 0.20601242168532147]
	TIME [epoch: 42.7 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24337749024297026		[learning rate: 0.00075634]
	Learning Rate: 0.000756342
	LOSS [training: 0.24337749024297026 | validation: 0.20884702700491609]
	TIME [epoch: 42.7 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24257763682767422		[learning rate: 0.00075367]
	Learning Rate: 0.000753667
	LOSS [training: 0.24257763682767422 | validation: 0.2044422917347435]
	TIME [epoch: 42.7 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2416073893388708		[learning rate: 0.000751]
	Learning Rate: 0.000751002
	LOSS [training: 0.2416073893388708 | validation: 0.2077447235975174]
	TIME [epoch: 42.7 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24245890448440707		[learning rate: 0.00074835]
	Learning Rate: 0.000748346
	LOSS [training: 0.24245890448440707 | validation: 0.20656563833563119]
	TIME [epoch: 42.7 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23807073477234256		[learning rate: 0.0007457]
	Learning Rate: 0.0007457
	LOSS [training: 0.23807073477234256 | validation: 0.20321872386462275]
	TIME [epoch: 42.7 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24244399297666722		[learning rate: 0.00074306]
	Learning Rate: 0.000743063
	LOSS [training: 0.24244399297666722 | validation: 0.20320932808610687]
	TIME [epoch: 42.7 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2432302161160409		[learning rate: 0.00074044]
	Learning Rate: 0.000740435
	LOSS [training: 0.2432302161160409 | validation: 0.20014612094229153]
	TIME [epoch: 42.7 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24383488863126238		[learning rate: 0.00073782]
	Learning Rate: 0.000737817
	LOSS [training: 0.24383488863126238 | validation: 0.20699059087166644]
	TIME [epoch: 42.8 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24324166884870005		[learning rate: 0.00073521]
	Learning Rate: 0.000735208
	LOSS [training: 0.24324166884870005 | validation: 0.2068394695165164]
	TIME [epoch: 42.7 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23991464891706005		[learning rate: 0.00073261]
	Learning Rate: 0.000732608
	LOSS [training: 0.23991464891706005 | validation: 0.20279730686496325]
	TIME [epoch: 42.7 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24052566004120735		[learning rate: 0.00073002]
	Learning Rate: 0.000730018
	LOSS [training: 0.24052566004120735 | validation: 0.2042407864515882]
	TIME [epoch: 42.7 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24019757177331325		[learning rate: 0.00072744]
	Learning Rate: 0.000727436
	LOSS [training: 0.24019757177331325 | validation: 0.20654240184211412]
	TIME [epoch: 42.7 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23918464028718656		[learning rate: 0.00072486]
	Learning Rate: 0.000724864
	LOSS [training: 0.23918464028718656 | validation: 0.20623765944247455]
	TIME [epoch: 42.7 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24195670325264515		[learning rate: 0.0007223]
	Learning Rate: 0.000722301
	LOSS [training: 0.24195670325264515 | validation: 0.2064398481361235]
	TIME [epoch: 42.8 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24175627589152357		[learning rate: 0.00071975]
	Learning Rate: 0.000719746
	LOSS [training: 0.24175627589152357 | validation: 0.20601888068877017]
	TIME [epoch: 42.7 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24142755381388045		[learning rate: 0.0007172]
	Learning Rate: 0.000717201
	LOSS [training: 0.24142755381388045 | validation: 0.20781195729487667]
	TIME [epoch: 42.8 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24087951657921594		[learning rate: 0.00071467]
	Learning Rate: 0.000714665
	LOSS [training: 0.24087951657921594 | validation: 0.20527817075074495]
	TIME [epoch: 42.7 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2433625055341826		[learning rate: 0.00071214]
	Learning Rate: 0.000712138
	LOSS [training: 0.2433625055341826 | validation: 0.2054444097858515]
	TIME [epoch: 42.7 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24227187564550798		[learning rate: 0.00070962]
	Learning Rate: 0.00070962
	LOSS [training: 0.24227187564550798 | validation: 0.2060947983301335]
	TIME [epoch: 42.7 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23664884267392158		[learning rate: 0.00070711]
	Learning Rate: 0.00070711
	LOSS [training: 0.23664884267392158 | validation: 0.2064385749503273]
	TIME [epoch: 42.7 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24059267954125954		[learning rate: 0.00070461]
	Learning Rate: 0.00070461
	LOSS [training: 0.24059267954125954 | validation: 0.20536695548917208]
	TIME [epoch: 42.7 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2415563343825586		[learning rate: 0.00070212]
	Learning Rate: 0.000702118
	LOSS [training: 0.2415563343825586 | validation: 0.2086171971706571]
	TIME [epoch: 42.8 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23913009139423824		[learning rate: 0.00069964]
	Learning Rate: 0.000699635
	LOSS [training: 0.23913009139423824 | validation: 0.20914836256652164]
	TIME [epoch: 42.8 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2437714648016852		[learning rate: 0.00069716]
	Learning Rate: 0.000697161
	LOSS [training: 0.2437714648016852 | validation: 0.2092157199079351]
	TIME [epoch: 42.8 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2381808126602655		[learning rate: 0.0006947]
	Learning Rate: 0.000694696
	LOSS [training: 0.2381808126602655 | validation: 0.20775545346471533]
	TIME [epoch: 42.8 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23872099896779833		[learning rate: 0.00069224]
	Learning Rate: 0.00069224
	LOSS [training: 0.23872099896779833 | validation: 0.20548655484071748]
	TIME [epoch: 42.8 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24212946525349713		[learning rate: 0.00068979]
	Learning Rate: 0.000689792
	LOSS [training: 0.24212946525349713 | validation: 0.2105155827247263]
	TIME [epoch: 42.8 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2391079657332639		[learning rate: 0.00068735]
	Learning Rate: 0.000687352
	LOSS [training: 0.2391079657332639 | validation: 0.20670872167825083]
	TIME [epoch: 42.8 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24069851619615337		[learning rate: 0.00068492]
	Learning Rate: 0.000684922
	LOSS [training: 0.24069851619615337 | validation: 0.20668517602141562]
	TIME [epoch: 42.8 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23801289388573466		[learning rate: 0.0006825]
	Learning Rate: 0.0006825
	LOSS [training: 0.23801289388573466 | validation: 0.20533340690019788]
	TIME [epoch: 42.8 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24310873573377692		[learning rate: 0.00068009]
	Learning Rate: 0.000680086
	LOSS [training: 0.24310873573377692 | validation: 0.20250236720358647]
	TIME [epoch: 42.8 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23888221489462383		[learning rate: 0.00067768]
	Learning Rate: 0.000677682
	LOSS [training: 0.23888221489462383 | validation: 0.20529855120119161]
	TIME [epoch: 42.8 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23931462671649387		[learning rate: 0.00067529]
	Learning Rate: 0.000675285
	LOSS [training: 0.23931462671649387 | validation: 0.20797912576694405]
	TIME [epoch: 42.8 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24203570362908988		[learning rate: 0.0006729]
	Learning Rate: 0.000672897
	LOSS [training: 0.24203570362908988 | validation: 0.2031061272973293]
	TIME [epoch: 42.8 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24181407258752466		[learning rate: 0.00067052]
	Learning Rate: 0.000670518
	LOSS [training: 0.24181407258752466 | validation: 0.20593651391097115]
	TIME [epoch: 42.8 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24381451733864803		[learning rate: 0.00066815]
	Learning Rate: 0.000668147
	LOSS [training: 0.24381451733864803 | validation: 0.2070279495647082]
	TIME [epoch: 42.8 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23996690366722087		[learning rate: 0.00066578]
	Learning Rate: 0.000665784
	LOSS [training: 0.23996690366722087 | validation: 0.20231118847204987]
	TIME [epoch: 42.8 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24065109428608777		[learning rate: 0.00066343]
	Learning Rate: 0.00066343
	LOSS [training: 0.24065109428608777 | validation: 0.20730587771388698]
	TIME [epoch: 42.8 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2459218161962001		[learning rate: 0.00066108]
	Learning Rate: 0.000661084
	LOSS [training: 0.2459218161962001 | validation: 0.20273775513749093]
	TIME [epoch: 42.8 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23912721316402882		[learning rate: 0.00065875]
	Learning Rate: 0.000658746
	LOSS [training: 0.23912721316402882 | validation: 0.20410296937246536]
	TIME [epoch: 42.8 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24151256369892934		[learning rate: 0.00065642]
	Learning Rate: 0.000656417
	LOSS [training: 0.24151256369892934 | validation: 0.20978789749549]
	TIME [epoch: 42.8 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23980254396074008		[learning rate: 0.0006541]
	Learning Rate: 0.000654095
	LOSS [training: 0.23980254396074008 | validation: 0.20319083328032175]
	TIME [epoch: 42.8 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24205796783702935		[learning rate: 0.00065178]
	Learning Rate: 0.000651782
	LOSS [training: 0.24205796783702935 | validation: 0.20183640756431984]
	TIME [epoch: 42.8 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23817552712549472		[learning rate: 0.00064948]
	Learning Rate: 0.000649477
	LOSS [training: 0.23817552712549472 | validation: 0.20888080123272995]
	TIME [epoch: 42.8 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23853869483846166		[learning rate: 0.00064718]
	Learning Rate: 0.000647181
	LOSS [training: 0.23853869483846166 | validation: 0.2058882679327672]
	TIME [epoch: 42.8 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24335183895071896		[learning rate: 0.00064489]
	Learning Rate: 0.000644892
	LOSS [training: 0.24335183895071896 | validation: 0.2073831863259327]
	TIME [epoch: 42.8 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23766476460694452		[learning rate: 0.00064261]
	Learning Rate: 0.000642612
	LOSS [training: 0.23766476460694452 | validation: 0.20715428632352104]
	TIME [epoch: 42.8 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2359982612248086		[learning rate: 0.00064034]
	Learning Rate: 0.000640339
	LOSS [training: 0.2359982612248086 | validation: 0.20744138167330553]
	TIME [epoch: 42.8 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23646104425909834		[learning rate: 0.00063808]
	Learning Rate: 0.000638075
	LOSS [training: 0.23646104425909834 | validation: 0.20399842256958486]
	TIME [epoch: 42.8 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23894451842883999		[learning rate: 0.00063582]
	Learning Rate: 0.000635819
	LOSS [training: 0.23894451842883999 | validation: 0.20887262707462034]
	TIME [epoch: 42.8 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24013860153807445		[learning rate: 0.00063357]
	Learning Rate: 0.00063357
	LOSS [training: 0.24013860153807445 | validation: 0.20795737938897899]
	TIME [epoch: 42.8 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24281598659221323		[learning rate: 0.00063133]
	Learning Rate: 0.00063133
	LOSS [training: 0.24281598659221323 | validation: 0.20892394678246115]
	TIME [epoch: 42.8 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2441214144123436		[learning rate: 0.0006291]
	Learning Rate: 0.000629098
	LOSS [training: 0.2441214144123436 | validation: 0.2039752722742733]
	TIME [epoch: 42.8 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24002521239629626		[learning rate: 0.00062687]
	Learning Rate: 0.000626873
	LOSS [training: 0.24002521239629626 | validation: 0.2029443633036186]
	TIME [epoch: 42.8 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2444314438111139		[learning rate: 0.00062466]
	Learning Rate: 0.000624656
	LOSS [training: 0.2444314438111139 | validation: 0.20225745651776106]
	TIME [epoch: 42.8 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2415619277167449		[learning rate: 0.00062245]
	Learning Rate: 0.000622447
	LOSS [training: 0.2415619277167449 | validation: 0.20723275972893415]
	TIME [epoch: 42.8 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2426050357159202		[learning rate: 0.00062025]
	Learning Rate: 0.000620246
	LOSS [training: 0.2426050357159202 | validation: 0.20574856655053578]
	TIME [epoch: 42.8 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24077347810914884		[learning rate: 0.00061805]
	Learning Rate: 0.000618053
	LOSS [training: 0.24077347810914884 | validation: 0.2065628766033499]
	TIME [epoch: 42.8 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24296332573979296		[learning rate: 0.00061587]
	Learning Rate: 0.000615867
	LOSS [training: 0.24296332573979296 | validation: 0.20398419149779579]
	TIME [epoch: 42.8 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2402216311781388		[learning rate: 0.00061369]
	Learning Rate: 0.00061369
	LOSS [training: 0.2402216311781388 | validation: 0.20794950041659374]
	TIME [epoch: 42.8 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2406209685743266		[learning rate: 0.00061152]
	Learning Rate: 0.000611519
	LOSS [training: 0.2406209685743266 | validation: 0.20526564750808501]
	TIME [epoch: 42.8 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2448188326013149		[learning rate: 0.00060936]
	Learning Rate: 0.000609357
	LOSS [training: 0.2448188326013149 | validation: 0.2067168021551339]
	TIME [epoch: 42.8 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24012329973864152		[learning rate: 0.0006072]
	Learning Rate: 0.000607202
	LOSS [training: 0.24012329973864152 | validation: 0.20826534236248712]
	TIME [epoch: 42.8 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24099306657156486		[learning rate: 0.00060506]
	Learning Rate: 0.000605055
	LOSS [training: 0.24099306657156486 | validation: 0.20614197166054446]
	TIME [epoch: 42.8 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2398260686280004		[learning rate: 0.00060292]
	Learning Rate: 0.000602915
	LOSS [training: 0.2398260686280004 | validation: 0.20344010696010623]
	TIME [epoch: 42.8 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24332505485964204		[learning rate: 0.00060078]
	Learning Rate: 0.000600784
	LOSS [training: 0.24332505485964204 | validation: 0.20438793450784348]
	TIME [epoch: 42.8 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.234551390259363		[learning rate: 0.00059866]
	Learning Rate: 0.000598659
	LOSS [training: 0.234551390259363 | validation: 0.2062793469003789]
	TIME [epoch: 42.8 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24263140612376732		[learning rate: 0.00059654]
	Learning Rate: 0.000596542
	LOSS [training: 0.24263140612376732 | validation: 0.20879975677152487]
	TIME [epoch: 42.8 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23923052153921143		[learning rate: 0.00059443]
	Learning Rate: 0.000594432
	LOSS [training: 0.23923052153921143 | validation: 0.20867724906004087]
	TIME [epoch: 42.8 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24350409968204287		[learning rate: 0.00059233]
	Learning Rate: 0.00059233
	LOSS [training: 0.24350409968204287 | validation: 0.20720268268000827]
	TIME [epoch: 42.8 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24414862269927065		[learning rate: 0.00059024]
	Learning Rate: 0.000590236
	LOSS [training: 0.24414862269927065 | validation: 0.20441316138078508]
	TIME [epoch: 42.8 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23973469415323914		[learning rate: 0.00058815]
	Learning Rate: 0.000588149
	LOSS [training: 0.23973469415323914 | validation: 0.20842628333034613]
	TIME [epoch: 42.8 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24495151120078948		[learning rate: 0.00058607]
	Learning Rate: 0.000586069
	LOSS [training: 0.24495151120078948 | validation: 0.2073244692089152]
	TIME [epoch: 42.8 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2398124564476437		[learning rate: 0.000584]
	Learning Rate: 0.000583996
	LOSS [training: 0.2398124564476437 | validation: 0.20653138821268097]
	TIME [epoch: 42.8 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24118796826073582		[learning rate: 0.00058193]
	Learning Rate: 0.000581931
	LOSS [training: 0.24118796826073582 | validation: 0.20622565011204713]
	TIME [epoch: 42.8 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2402373398885896		[learning rate: 0.00057987]
	Learning Rate: 0.000579874
	LOSS [training: 0.2402373398885896 | validation: 0.2050390822523794]
	TIME [epoch: 42.8 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24161188346834747		[learning rate: 0.00057782]
	Learning Rate: 0.000577823
	LOSS [training: 0.24161188346834747 | validation: 0.20384111757680895]
	TIME [epoch: 42.8 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2467426517400193		[learning rate: 0.00057578]
	Learning Rate: 0.00057578
	LOSS [training: 0.2467426517400193 | validation: 0.20813536350987008]
	TIME [epoch: 42.8 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24250963441389192		[learning rate: 0.00057374]
	Learning Rate: 0.000573744
	LOSS [training: 0.24250963441389192 | validation: 0.20547864650493763]
	TIME [epoch: 42.8 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23928642412008047		[learning rate: 0.00057171]
	Learning Rate: 0.000571715
	LOSS [training: 0.23928642412008047 | validation: 0.2049498422689398]
	TIME [epoch: 42.8 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24240420510001462		[learning rate: 0.00056969]
	Learning Rate: 0.000569693
	LOSS [training: 0.24240420510001462 | validation: 0.20483137612142882]
	TIME [epoch: 42.8 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2460682577824842		[learning rate: 0.00056768]
	Learning Rate: 0.000567679
	LOSS [training: 0.2460682577824842 | validation: 0.2075340480756044]
	TIME [epoch: 42.8 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24197216453004353		[learning rate: 0.00056567]
	Learning Rate: 0.000565671
	LOSS [training: 0.24197216453004353 | validation: 0.20626924961850723]
	TIME [epoch: 42.8 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24047819541481538		[learning rate: 0.00056367]
	Learning Rate: 0.000563671
	LOSS [training: 0.24047819541481538 | validation: 0.20870245808655508]
	TIME [epoch: 42.8 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23946198435746371		[learning rate: 0.00056168]
	Learning Rate: 0.000561678
	LOSS [training: 0.23946198435746371 | validation: 0.2052657643947624]
	TIME [epoch: 42.8 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2387879719234319		[learning rate: 0.00055969]
	Learning Rate: 0.000559692
	LOSS [training: 0.2387879719234319 | validation: 0.20592152896319735]
	TIME [epoch: 42.8 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24620351172853983		[learning rate: 0.00055771]
	Learning Rate: 0.000557712
	LOSS [training: 0.24620351172853983 | validation: 0.20660719451265286]
	TIME [epoch: 42.8 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23886015180169504		[learning rate: 0.00055574]
	Learning Rate: 0.00055574
	LOSS [training: 0.23886015180169504 | validation: 0.20730227145114521]
	TIME [epoch: 42.8 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24461139798535528		[learning rate: 0.00055377]
	Learning Rate: 0.000553775
	LOSS [training: 0.24461139798535528 | validation: 0.20258245295693458]
	TIME [epoch: 42.8 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2358210468144535		[learning rate: 0.00055182]
	Learning Rate: 0.000551817
	LOSS [training: 0.2358210468144535 | validation: 0.20623745190846482]
	TIME [epoch: 42.8 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24081793618252112		[learning rate: 0.00054987]
	Learning Rate: 0.000549865
	LOSS [training: 0.24081793618252112 | validation: 0.20215056486494073]
	TIME [epoch: 42.8 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23807070884199125		[learning rate: 0.00054792]
	Learning Rate: 0.000547921
	LOSS [training: 0.23807070884199125 | validation: 0.20201143397219648]
	TIME [epoch: 42.8 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24126502370019645		[learning rate: 0.00054598]
	Learning Rate: 0.000545983
	LOSS [training: 0.24126502370019645 | validation: 0.20180748623644953]
	TIME [epoch: 42.8 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24445317220775942		[learning rate: 0.00054405]
	Learning Rate: 0.000544053
	LOSS [training: 0.24445317220775942 | validation: 0.2057511861279416]
	TIME [epoch: 42.8 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24311555801347104		[learning rate: 0.00054213]
	Learning Rate: 0.000542129
	LOSS [training: 0.24311555801347104 | validation: 0.20210722272204257]
	TIME [epoch: 42.8 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2405031524170579		[learning rate: 0.00054021]
	Learning Rate: 0.000540212
	LOSS [training: 0.2405031524170579 | validation: 0.2079968638289726]
	TIME [epoch: 42.8 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24369088483364645		[learning rate: 0.0005383]
	Learning Rate: 0.000538302
	LOSS [training: 0.24369088483364645 | validation: 0.20138958701319445]
	TIME [epoch: 42.8 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2398716571025571		[learning rate: 0.0005364]
	Learning Rate: 0.000536398
	LOSS [training: 0.2398716571025571 | validation: 0.19995400039649672]
	TIME [epoch: 42.8 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.237558589393411		[learning rate: 0.0005345]
	Learning Rate: 0.000534501
	LOSS [training: 0.237558589393411 | validation: 0.20113189064569198]
	TIME [epoch: 42.8 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24419684548842813		[learning rate: 0.00053261]
	Learning Rate: 0.000532611
	LOSS [training: 0.24419684548842813 | validation: 0.20079470722499507]
	TIME [epoch: 42.8 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24464148127063715		[learning rate: 0.00053073]
	Learning Rate: 0.000530728
	LOSS [training: 0.24464148127063715 | validation: 0.20496985796749287]
	TIME [epoch: 42.8 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24030007316554625		[learning rate: 0.00052885]
	Learning Rate: 0.000528851
	LOSS [training: 0.24030007316554625 | validation: 0.20486310326174112]
	TIME [epoch: 42.8 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24150125090997476		[learning rate: 0.00052698]
	Learning Rate: 0.000526981
	LOSS [training: 0.24150125090997476 | validation: 0.2039112042454531]
	TIME [epoch: 42.8 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2389963118522893		[learning rate: 0.00052512]
	Learning Rate: 0.000525117
	LOSS [training: 0.2389963118522893 | validation: 0.203276341351676]
	TIME [epoch: 42.8 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24155969336868702		[learning rate: 0.00052326]
	Learning Rate: 0.000523261
	LOSS [training: 0.24155969336868702 | validation: 0.20404896106845127]
	TIME [epoch: 42.8 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24021346843834965		[learning rate: 0.00052141]
	Learning Rate: 0.00052141
	LOSS [training: 0.24021346843834965 | validation: 0.2029262813436909]
	TIME [epoch: 42.8 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24049044476876558		[learning rate: 0.00051957]
	Learning Rate: 0.000519566
	LOSS [training: 0.24049044476876558 | validation: 0.20170196248243122]
	TIME [epoch: 42.8 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24259111345718534		[learning rate: 0.00051773]
	Learning Rate: 0.000517729
	LOSS [training: 0.24259111345718534 | validation: 0.203499613160585]
	TIME [epoch: 42.8 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23663257441315047		[learning rate: 0.0005159]
	Learning Rate: 0.000515898
	LOSS [training: 0.23663257441315047 | validation: 0.20550098989456025]
	TIME [epoch: 42.8 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24001662583911196		[learning rate: 0.00051407]
	Learning Rate: 0.000514074
	LOSS [training: 0.24001662583911196 | validation: 0.20655992836611015]
	TIME [epoch: 42.8 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2421093515294608		[learning rate: 0.00051226]
	Learning Rate: 0.000512256
	LOSS [training: 0.2421093515294608 | validation: 0.20840322774621223]
	TIME [epoch: 42.8 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2435367943766427		[learning rate: 0.00051044]
	Learning Rate: 0.000510445
	LOSS [training: 0.2435367943766427 | validation: 0.20186768651584536]
	TIME [epoch: 42.8 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23948224183862118		[learning rate: 0.00050864]
	Learning Rate: 0.00050864
	LOSS [training: 0.23948224183862118 | validation: 0.20489824797508166]
	TIME [epoch: 42.8 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2380325128082107		[learning rate: 0.00050684]
	Learning Rate: 0.000506841
	LOSS [training: 0.2380325128082107 | validation: 0.20549880136767468]
	TIME [epoch: 42.8 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23818452433383194		[learning rate: 0.00050505]
	Learning Rate: 0.000505049
	LOSS [training: 0.23818452433383194 | validation: 0.20652993674914288]
	TIME [epoch: 42.8 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24303915338992918		[learning rate: 0.00050326]
	Learning Rate: 0.000503263
	LOSS [training: 0.24303915338992918 | validation: 0.2041925758176773]
	TIME [epoch: 42.8 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23971505102703602		[learning rate: 0.00050148]
	Learning Rate: 0.000501483
	LOSS [training: 0.23971505102703602 | validation: 0.20594181227595354]
	TIME [epoch: 42.8 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24094626587365484		[learning rate: 0.00049971]
	Learning Rate: 0.00049971
	LOSS [training: 0.24094626587365484 | validation: 0.20548894504307658]
	TIME [epoch: 42.8 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24055740722488217		[learning rate: 0.00049794]
	Learning Rate: 0.000497943
	LOSS [training: 0.24055740722488217 | validation: 0.2012757662732721]
	TIME [epoch: 42.8 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24095914671603622		[learning rate: 0.00049618]
	Learning Rate: 0.000496182
	LOSS [training: 0.24095914671603622 | validation: 0.2062788293849902]
	TIME [epoch: 42.8 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24078044279781188		[learning rate: 0.00049443]
	Learning Rate: 0.000494427
	LOSS [training: 0.24078044279781188 | validation: 0.20779792022921698]
	TIME [epoch: 42.7 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2423748136825924		[learning rate: 0.00049268]
	Learning Rate: 0.000492679
	LOSS [training: 0.2423748136825924 | validation: 0.20724269106650922]
	TIME [epoch: 42.8 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23997215129701735		[learning rate: 0.00049094]
	Learning Rate: 0.000490937
	LOSS [training: 0.23997215129701735 | validation: 0.2059628893760383]
	TIME [epoch: 42.8 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2397079067329069		[learning rate: 0.0004892]
	Learning Rate: 0.000489201
	LOSS [training: 0.2397079067329069 | validation: 0.20912361446077826]
	TIME [epoch: 42.8 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23897975997153406		[learning rate: 0.00048747]
	Learning Rate: 0.000487471
	LOSS [training: 0.23897975997153406 | validation: 0.20646408765431148]
	TIME [epoch: 42.7 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2396269784409264		[learning rate: 0.00048575]
	Learning Rate: 0.000485747
	LOSS [training: 0.2396269784409264 | validation: 0.20552805242627178]
	TIME [epoch: 42.8 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23776969238529708		[learning rate: 0.00048403]
	Learning Rate: 0.000484029
	LOSS [training: 0.23776969238529708 | validation: 0.20839774865725946]
	TIME [epoch: 42.8 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24114685651060452		[learning rate: 0.00048232]
	Learning Rate: 0.000482318
	LOSS [training: 0.24114685651060452 | validation: 0.2059079693090263]
	TIME [epoch: 42.8 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2423239190132538		[learning rate: 0.00048061]
	Learning Rate: 0.000480612
	LOSS [training: 0.2423239190132538 | validation: 0.20636255281094]
	TIME [epoch: 42.8 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23852785238813154		[learning rate: 0.00047891]
	Learning Rate: 0.000478913
	LOSS [training: 0.23852785238813154 | validation: 0.20728553701551009]
	TIME [epoch: 42.7 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24031452938733547		[learning rate: 0.00047722]
	Learning Rate: 0.000477219
	LOSS [training: 0.24031452938733547 | validation: 0.20422426418137482]
	TIME [epoch: 42.7 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23650331782143444		[learning rate: 0.00047553]
	Learning Rate: 0.000475532
	LOSS [training: 0.23650331782143444 | validation: 0.20318063148551624]
	TIME [epoch: 42.8 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2407332706745571		[learning rate: 0.00047385]
	Learning Rate: 0.00047385
	LOSS [training: 0.2407332706745571 | validation: 0.20286311041348054]
	TIME [epoch: 42.7 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23854096799252444		[learning rate: 0.00047217]
	Learning Rate: 0.000472175
	LOSS [training: 0.23854096799252444 | validation: 0.20776349548191025]
	TIME [epoch: 42.7 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2419224689011288		[learning rate: 0.0004705]
	Learning Rate: 0.000470505
	LOSS [training: 0.2419224689011288 | validation: 0.20720811247022644]
	TIME [epoch: 42.7 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2376727353399564		[learning rate: 0.00046884]
	Learning Rate: 0.000468841
	LOSS [training: 0.2376727353399564 | validation: 0.20296418756011855]
	TIME [epoch: 42.8 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24122184700083457		[learning rate: 0.00046718]
	Learning Rate: 0.000467183
	LOSS [training: 0.24122184700083457 | validation: 0.20685267800463839]
	TIME [epoch: 42.8 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2408435385731139		[learning rate: 0.00046553]
	Learning Rate: 0.000465531
	LOSS [training: 0.2408435385731139 | validation: 0.20387231319838692]
	TIME [epoch: 42.8 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2410922426722819		[learning rate: 0.00046388]
	Learning Rate: 0.000463885
	LOSS [training: 0.2410922426722819 | validation: 0.20594843055838244]
	TIME [epoch: 42.8 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24188296092424777		[learning rate: 0.00046224]
	Learning Rate: 0.000462245
	LOSS [training: 0.24188296092424777 | validation: 0.20551157329189787]
	TIME [epoch: 42.8 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24018421686930225		[learning rate: 0.00046061]
	Learning Rate: 0.00046061
	LOSS [training: 0.24018421686930225 | validation: 0.20410627120715458]
	TIME [epoch: 42.8 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24041151739474784		[learning rate: 0.00045898]
	Learning Rate: 0.000458981
	LOSS [training: 0.24041151739474784 | validation: 0.2075687360876765]
	TIME [epoch: 42.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240716_142138/states/model_facs_v3_dec1b_2dpca_v12_920.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 27710.256 seconds.
