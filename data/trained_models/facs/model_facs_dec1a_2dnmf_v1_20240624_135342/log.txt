Args:
Namespace(name='model_facs_dec1a_2dnmf_v1', outdir='out/model_training/model_facs_dec1a_2dnmf_v1', training_data='data/training_data/facs/nmf/dec1/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs/nmf/dec1/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=5, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.001, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 976558595

Training model...

Saving initial model state to: out/model_training/model_facs_dec1a_2dnmf_v1_20240624_135342/states/model_facs_dec1a_2dnmf_v1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.6554992508052837		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6554992508052837 | validation: 0.4475240355034301]
	TIME [epoch: 60.3 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dnmf_v1_20240624_135342/states/model_facs_dec1a_2dnmf_v1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4825260662171657		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4825260662171657 | validation: 0.3473367248603581]
	TIME [epoch: 35.2 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dnmf_v1_20240624_135342/states/model_facs_dec1a_2dnmf_v1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31772966580759726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31772966580759726 | validation: 0.4117945480696304]
	TIME [epoch: 35.2 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2805695471198763		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2805695471198763 | validation: 0.22511434061460003]
	TIME [epoch: 35.1 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dnmf_v1_20240624_135342/states/model_facs_dec1a_2dnmf_v1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14875610962938543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14875610962938543 | validation: 0.19458673806197158]
	TIME [epoch: 35.2 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dnmf_v1_20240624_135342/states/model_facs_dec1a_2dnmf_v1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12118839083626162		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12118839083626162 | validation: 0.09802125692224126]
	TIME [epoch: 35.2 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dnmf_v1_20240624_135342/states/model_facs_dec1a_2dnmf_v1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.05991545808594946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05991545808594946 | validation: 0.03664759800268651]
	TIME [epoch: 35.1 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dnmf_v1_20240624_135342/states/model_facs_dec1a_2dnmf_v1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.029648112367296104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.029648112367296104 | validation: 0.022597937105456427]
	TIME [epoch: 35.1 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dnmf_v1_20240624_135342/states/model_facs_dec1a_2dnmf_v1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.016992749742650196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.016992749742650196 | validation: 0.021079722245529828]
	TIME [epoch: 35.1 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dnmf_v1_20240624_135342/states/model_facs_dec1a_2dnmf_v1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.017564494196359075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.017564494196359075 | validation: 0.009994309532387776]
	TIME [epoch: 35.1 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dnmf_v1_20240624_135342/states/model_facs_dec1a_2dnmf_v1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010810664222774954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.010810664222774954 | validation: 0.010451114607409679]
	TIME [epoch: 35.2 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012511632814027488		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.012511632814027488 | validation: 0.011200139521403338]
	TIME [epoch: 35.1 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007520859661859954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.007520859661859954 | validation: 0.007511582863324864]
	TIME [epoch: 35.1 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dnmf_v1_20240624_135342/states/model_facs_dec1a_2dnmf_v1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008173232264093342		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.008173232264093342 | validation: 0.010099427324644675]
	TIME [epoch: 35.1 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010310229305680601		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.010310229305680601 | validation: 0.007828478189961895]
	TIME [epoch: 35.1 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007356444217209266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.007356444217209266 | validation: 0.005642984528120323]
	TIME [epoch: 35.1 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dnmf_v1_20240624_135342/states/model_facs_dec1a_2dnmf_v1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00734527824719251		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.00734527824719251 | validation: 0.006947876404580988]
	TIME [epoch: 35.1 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009672989098474336		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.009672989098474336 | validation: 0.009219212191046992]
	TIME [epoch: 35.1 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007209748488218978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.007209748488218978 | validation: 0.015787626615304674]
	TIME [epoch: 35.1 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008679281689895943		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.008679281689895943 | validation: 0.010752510917254945]
	TIME [epoch: 35.1 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006270504498544513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.006270504498544513 | validation: 0.008634748011318506]
	TIME [epoch: 35.1 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009586080069067363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.009586080069067363 | validation: 0.0057483755859226455]
	TIME [epoch: 35.1 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008489976864275148		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.008489976864275148 | validation: 0.008751172158594262]
	TIME [epoch: 35.1 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009986717027987407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.009986717027987407 | validation: 0.0077503960515030905]
	TIME [epoch: 35.1 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0077501908889827074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0077501908889827074 | validation: 0.00624150235840411]
	TIME [epoch: 35.2 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01005518253145448		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.01005518253145448 | validation: 0.010435237931065874]
	TIME [epoch: 35.1 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007060660308490594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.007060660308490594 | validation: 0.0071475076981673494]
	TIME [epoch: 35.1 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009217533582053038		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.009217533582053038 | validation: 0.009658067587341584]
	TIME [epoch: 35.1 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007860101349478201		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.007860101349478201 | validation: 0.009150029457260251]
	TIME [epoch: 35.1 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00666310938123504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.00666310938123504 | validation: 0.005280940960739709]
	TIME [epoch: 35.1 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dnmf_v1_20240624_135342/states/model_facs_dec1a_2dnmf_v1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008174483593359951		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.008174483593359951 | validation: 0.009712506565970905]
	TIME [epoch: 35.1 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009736045201190752		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.009736045201190752 | validation: 0.010828467368968317]
	TIME [epoch: 35.1 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008305586125322062		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.008305586125322062 | validation: 0.0069911177696863015]
	TIME [epoch: 35.1 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008339446995739127		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.008339446995739127 | validation: 0.006981896057269861]
	TIME [epoch: 35.1 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006091250125403707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.006091250125403707 | validation: 0.006007750811510677]
	TIME [epoch: 35.1 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006475219763635146		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.006475219763635146 | validation: 0.00735830269443683]
	TIME [epoch: 35.1 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01113290764206781		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.01113290764206781 | validation: 0.008487498441286911]
	TIME [epoch: 35.1 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006256056403810457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.006256056403810457 | validation: 0.005641819542533342]
	TIME [epoch: 35.1 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008726009606466627		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.008726009606466627 | validation: 0.01058632281768924]
	TIME [epoch: 35.1 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007163845659487954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.007163845659487954 | validation: 0.0050878763466558445]
	TIME [epoch: 35.1 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dnmf_v1_20240624_135342/states/model_facs_dec1a_2dnmf_v1_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008179399056701946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.008179399056701946 | validation: 0.005695815154852029]
	TIME [epoch: 35.1 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006153550479899981		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.006153550479899981 | validation: 0.0053007615835608405]
	TIME [epoch: 35.1 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007472869587392604		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.007472869587392604 | validation: 0.01111571562962368]
	TIME [epoch: 35.1 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01131517804615833		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.01131517804615833 | validation: 0.005493783497660285]
	TIME [epoch: 35.1 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010192261452588898		[learning rate: 0.0099823]
	Learning Rate: 0.0099823
	LOSS [training: 0.010192261452588898 | validation: 0.01227616298451958]
	TIME [epoch: 35.2 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00969333958971818		[learning rate: 0.0099426]
	Learning Rate: 0.0099426
	LOSS [training: 0.00969333958971818 | validation: 0.006138831610384932]
	TIME [epoch: 35 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008453279973886455		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.008453279973886455 | validation: 0.005446029188141628]
	TIME [epoch: 35.1 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008329048275957297		[learning rate: 0.0098637]
	Learning Rate: 0.00986367
	LOSS [training: 0.008329048275957297 | validation: 0.0064159139455341714]
	TIME [epoch: 35.1 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009890963376328252		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 0.009890963376328252 | validation: 0.007088589661468694]
	TIME [epoch: 35.1 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007405793710528725		[learning rate: 0.0097854]
	Learning Rate: 0.00978536
	LOSS [training: 0.007405793710528725 | validation: 0.012124716032665721]
	TIME [epoch: 35.2 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007986459810875778		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.007986459810875778 | validation: 0.014141307644485008]
	TIME [epoch: 35.1 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010114653233059065		[learning rate: 0.0097077]
	Learning Rate: 0.00970768
	LOSS [training: 0.010114653233059065 | validation: 0.006352246499676509]
	TIME [epoch: 35.1 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006966489247565984		[learning rate: 0.0096691]
	Learning Rate: 0.00966907
	LOSS [training: 0.006966489247565984 | validation: 0.008855950043915138]
	TIME [epoch: 35.1 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010732027530698525		[learning rate: 0.0096306]
	Learning Rate: 0.00963061
	LOSS [training: 0.010732027530698525 | validation: 0.00674429547520079]
	TIME [epoch: 35.1 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006904389920047521		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.006904389920047521 | validation: 0.006068089739331902]
	TIME [epoch: 35.1 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00819680225867267		[learning rate: 0.0095542]
	Learning Rate: 0.00955415
	LOSS [training: 0.00819680225867267 | validation: 0.01812546258271998]
	TIME [epoch: 35.1 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008571138960250975		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 0.008571138960250975 | validation: 0.006132361170414465]
	TIME [epoch: 35.1 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006440619695749433		[learning rate: 0.0094783]
	Learning Rate: 0.00947831
	LOSS [training: 0.006440619695749433 | validation: 0.006835180149308134]
	TIME [epoch: 35.1 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007983883396367207		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.007983883396367207 | validation: 0.014124568921359701]
	TIME [epoch: 35.1 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008265253731304854		[learning rate: 0.0094031]
	Learning Rate: 0.00940306
	LOSS [training: 0.008265253731304854 | validation: 0.006195754078366993]
	TIME [epoch: 35.2 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008809010053242557		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.008809010053242557 | validation: 0.005445514699594406]
	TIME [epoch: 35.1 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0066384316417593976		[learning rate: 0.0093284]
	Learning Rate: 0.00932841
	LOSS [training: 0.0066384316417593976 | validation: 0.007639935049410162]
	TIME [epoch: 35.1 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007484395598089801		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.007484395598089801 | validation: 0.010873741150464406]
	TIME [epoch: 35.1 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00928019878732967		[learning rate: 0.0092544]
	Learning Rate: 0.00925435
	LOSS [training: 0.00928019878732967 | validation: 0.02198387124143786]
	TIME [epoch: 35.1 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01175610737533536		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.01175610737533536 | validation: 0.0056238637316915075]
	TIME [epoch: 35.1 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007630735292322987		[learning rate: 0.0091809]
	Learning Rate: 0.00918089
	LOSS [training: 0.007630735292322987 | validation: 0.007997909260164856]
	TIME [epoch: 35.1 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0069009173836329755		[learning rate: 0.0091444]
	Learning Rate: 0.00914437
	LOSS [training: 0.0069009173836329755 | validation: 0.005323874659662136]
	TIME [epoch: 35.1 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007287855456314032		[learning rate: 0.009108]
	Learning Rate: 0.009108
	LOSS [training: 0.007287855456314032 | validation: 0.006187626419344761]
	TIME [epoch: 35.1 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007062338846145217		[learning rate: 0.0090718]
	Learning Rate: 0.00907178
	LOSS [training: 0.007062338846145217 | validation: 0.006943506419831573]
	TIME [epoch: 35.1 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007169103960292075		[learning rate: 0.0090357]
	Learning Rate: 0.00903569
	LOSS [training: 0.007169103960292075 | validation: 0.0071005283679821795]
	TIME [epoch: 35.1 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0062121231364331625		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.0062121231364331625 | validation: 0.00778714645476696]
	TIME [epoch: 35.1 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006986135090233214		[learning rate: 0.008964]
	Learning Rate: 0.00896396
	LOSS [training: 0.006986135090233214 | validation: 0.006534353342098148]
	TIME [epoch: 35.1 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006769453824208411		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 0.006769453824208411 | validation: 0.006378869575607541]
	TIME [epoch: 35.1 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007871335908981354		[learning rate: 0.0088928]
	Learning Rate: 0.0088928
	LOSS [training: 0.007871335908981354 | validation: 0.00625381671348246]
	TIME [epoch: 35.1 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009983198783538209		[learning rate: 0.0088574]
	Learning Rate: 0.00885743
	LOSS [training: 0.009983198783538209 | validation: 0.0067180733208491005]
	TIME [epoch: 35.1 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009222037537905065		[learning rate: 0.0088222]
	Learning Rate: 0.0088222
	LOSS [training: 0.009222037537905065 | validation: 0.009903393367534367]
	TIME [epoch: 35.1 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009418840157801471		[learning rate: 0.0087871]
	Learning Rate: 0.00878711
	LOSS [training: 0.009418840157801471 | validation: 0.007281459143381759]
	TIME [epoch: 35.1 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007685518562640182		[learning rate: 0.0087522]
	Learning Rate: 0.00875216
	LOSS [training: 0.007685518562640182 | validation: 0.005152580446697272]
	TIME [epoch: 35.1 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007387724490183622		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.007387724490183622 | validation: 0.005462341471692289]
	TIME [epoch: 35.1 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00816957502711264		[learning rate: 0.0086827]
	Learning Rate: 0.00868268
	LOSS [training: 0.00816957502711264 | validation: 0.010331095029259909]
	TIME [epoch: 35.1 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006562463128277449		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.006562463128277449 | validation: 0.011558429901732318]
	TIME [epoch: 35.1 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00835138022622322		[learning rate: 0.0086138]
	Learning Rate: 0.00861375
	LOSS [training: 0.00835138022622322 | validation: 0.005640039397608683]
	TIME [epoch: 35.1 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006317704568034187		[learning rate: 0.0085795]
	Learning Rate: 0.00857949
	LOSS [training: 0.006317704568034187 | validation: 0.013320326608182947]
	TIME [epoch: 35.1 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009192197663056617		[learning rate: 0.0085454]
	Learning Rate: 0.00854537
	LOSS [training: 0.009192197663056617 | validation: 0.0054940617517151855]
	TIME [epoch: 35.1 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008032926114548861		[learning rate: 0.0085114]
	Learning Rate: 0.00851138
	LOSS [training: 0.008032926114548861 | validation: 0.00948302395575703]
	TIME [epoch: 35.1 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008382073967092972		[learning rate: 0.0084775]
	Learning Rate: 0.00847753
	LOSS [training: 0.008382073967092972 | validation: 0.008433737526803587]
	TIME [epoch: 35.1 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009023188974234694		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.009023188974234694 | validation: 0.004911520238396751]
	TIME [epoch: 35 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dnmf_v1_20240624_135342/states/model_facs_dec1a_2dnmf_v1_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0059125266476434514		[learning rate: 0.0084102]
	Learning Rate: 0.00841023
	LOSS [training: 0.0059125266476434514 | validation: 0.005755164290002709]
	TIME [epoch: 35.1 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005643721107730353		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 0.005643721107730353 | validation: 0.010332873643730133]
	TIME [epoch: 35.1 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009244638001515993		[learning rate: 0.0083435]
	Learning Rate: 0.00834346
	LOSS [training: 0.009244638001515993 | validation: 0.014524247548717256]
	TIME [epoch: 35.1 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009251215898471207		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.009251215898471207 | validation: 0.006137940103505879]
	TIME [epoch: 35.1 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007282454437345168		[learning rate: 0.0082772]
	Learning Rate: 0.00827722
	LOSS [training: 0.007282454437345168 | validation: 0.007953768999618407]
	TIME [epoch: 35.1 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010313169599283464		[learning rate: 0.0082443]
	Learning Rate: 0.0082443
	LOSS [training: 0.010313169599283464 | validation: 0.004705530169988347]
	TIME [epoch: 35.1 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dnmf_v1_20240624_135342/states/model_facs_dec1a_2dnmf_v1_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007195835654431439		[learning rate: 0.0082115]
	Learning Rate: 0.00821151
	LOSS [training: 0.007195835654431439 | validation: 0.005317152212875334]
	TIME [epoch: 35.1 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006406316693457873		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.006406316693457873 | validation: 0.00994341840830881]
	TIME [epoch: 35.1 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012381179635043572		[learning rate: 0.0081463]
	Learning Rate: 0.00814632
	LOSS [training: 0.012381179635043572 | validation: 0.012538730699077493]
	TIME [epoch: 35.1 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008070642059544152		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.008070642059544152 | validation: 0.0048580931394544]
	TIME [epoch: 35.1 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006935186838560966		[learning rate: 0.0080816]
	Learning Rate: 0.00808165
	LOSS [training: 0.006935186838560966 | validation: 0.005451538698022218]
	TIME [epoch: 35.1 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008234213960547201		[learning rate: 0.0080495]
	Learning Rate: 0.00804951
	LOSS [training: 0.008234213960547201 | validation: 0.010825661978289927]
	TIME [epoch: 35.1 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010074637774214605		[learning rate: 0.0080175]
	Learning Rate: 0.00801749
	LOSS [training: 0.010074637774214605 | validation: 0.007629515500329776]
	TIME [epoch: 35.2 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005984976847397578		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.005984976847397578 | validation: 0.005555222742113526]
	TIME [epoch: 35 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006073627859611359		[learning rate: 0.0079538]
	Learning Rate: 0.00795384
	LOSS [training: 0.006073627859611359 | validation: 0.012049550376651338]
	TIME [epoch: 35.1 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00871246163737661		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.00871246163737661 | validation: 0.006398191614946831]
	TIME [epoch: 35.1 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007333689499790206		[learning rate: 0.0078907]
	Learning Rate: 0.0078907
	LOSS [training: 0.007333689499790206 | validation: 0.005544541421775029]
	TIME [epoch: 35.1 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008966516705515367		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 0.008966516705515367 | validation: 0.0052182209439327835]
	TIME [epoch: 35.1 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006166733008883372		[learning rate: 0.0078281]
	Learning Rate: 0.00782805
	LOSS [training: 0.006166733008883372 | validation: 0.00989821916844583]
	TIME [epoch: 35 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008798274814845311		[learning rate: 0.0077969]
	Learning Rate: 0.00779692
	LOSS [training: 0.008798274814845311 | validation: 0.006207731843064277]
	TIME [epoch: 35.1 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007350626417944487		[learning rate: 0.0077659]
	Learning Rate: 0.00776591
	LOSS [training: 0.007350626417944487 | validation: 0.007406480949891799]
	TIME [epoch: 35.1 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00684374593208353		[learning rate: 0.007735]
	Learning Rate: 0.00773502
	LOSS [training: 0.00684374593208353 | validation: 0.009045592023461274]
	TIME [epoch: 35 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007370370159029753		[learning rate: 0.0077043]
	Learning Rate: 0.00770426
	LOSS [training: 0.007370370159029753 | validation: 0.006205269177909206]
	TIME [epoch: 35 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006162209252459854		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.006162209252459854 | validation: 0.009332863491807713]
	TIME [epoch: 35.1 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007633753994891201		[learning rate: 0.0076431]
	Learning Rate: 0.00764309
	LOSS [training: 0.007633753994891201 | validation: 0.008149435556704065]
	TIME [epoch: 35.1 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010232936823151528		[learning rate: 0.0076127]
	Learning Rate: 0.00761269
	LOSS [training: 0.010232936823151528 | validation: 0.008099525190854112]
	TIME [epoch: 35 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008034642119269365		[learning rate: 0.0075824]
	Learning Rate: 0.00758242
	LOSS [training: 0.008034642119269365 | validation: 0.007336273672384928]
	TIME [epoch: 35.1 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009001685153546136		[learning rate: 0.0075523]
	Learning Rate: 0.00755226
	LOSS [training: 0.009001685153546136 | validation: 0.011289043561823076]
	TIME [epoch: 35 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00812722988680683		[learning rate: 0.0075222]
	Learning Rate: 0.00752222
	LOSS [training: 0.00812722988680683 | validation: 0.007063086170594984]
	TIME [epoch: 35.1 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007422759330635274		[learning rate: 0.0074923]
	Learning Rate: 0.0074923
	LOSS [training: 0.007422759330635274 | validation: 0.007946669055100148]
	TIME [epoch: 35.1 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006272923009681354		[learning rate: 0.0074625]
	Learning Rate: 0.0074625
	LOSS [training: 0.006272923009681354 | validation: 0.006609160443785886]
	TIME [epoch: 35.1 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007282574907288468		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.007282574907288468 | validation: 0.020660270923702928]
	TIME [epoch: 35.1 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009212169697603363		[learning rate: 0.0074033]
	Learning Rate: 0.00740326
	LOSS [training: 0.009212169697603363 | validation: 0.005271584965462805]
	TIME [epoch: 35 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00681814536501715		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.00681814536501715 | validation: 0.013742799052263222]
	TIME [epoch: 35.1 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00784124683908797		[learning rate: 0.0073445]
	Learning Rate: 0.00734449
	LOSS [training: 0.00784124683908797 | validation: 0.008236709679539206]
	TIME [epoch: 35.1 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007949860319223574		[learning rate: 0.0073153]
	Learning Rate: 0.00731528
	LOSS [training: 0.007949860319223574 | validation: 0.006777534680192968]
	TIME [epoch: 35.1 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006693172105936304		[learning rate: 0.0072862]
	Learning Rate: 0.00728618
	LOSS [training: 0.006693172105936304 | validation: 0.00904210386025157]
	TIME [epoch: 35.1 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006372105827915207		[learning rate: 0.0072572]
	Learning Rate: 0.0072572
	LOSS [training: 0.006372105827915207 | validation: 0.00566418265131686]
	TIME [epoch: 35.1 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005946639275111471		[learning rate: 0.0072283]
	Learning Rate: 0.00722834
	LOSS [training: 0.005946639275111471 | validation: 0.012906856487168994]
	TIME [epoch: 35.1 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011603229605075443		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.011603229605075443 | validation: 0.006561731509518959]
	TIME [epoch: 35.1 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007026605351915066		[learning rate: 0.007171]
	Learning Rate: 0.00717095
	LOSS [training: 0.007026605351915066 | validation: 0.00969029763623678]
	TIME [epoch: 35 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006547442759050398		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.006547442759050398 | validation: 0.007948087578775742]
	TIME [epoch: 35.1 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007606379057954804		[learning rate: 0.007114]
	Learning Rate: 0.00711403
	LOSS [training: 0.007606379057954804 | validation: 0.0049185376625499]
	TIME [epoch: 35 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00756967970379636		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.00756967970379636 | validation: 0.005174009574390115]
	TIME [epoch: 35.1 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006429077891245585		[learning rate: 0.0070575]
	Learning Rate: 0.00705755
	LOSS [training: 0.006429077891245585 | validation: 0.005320783402585234]
	TIME [epoch: 35.1 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007134223062919429		[learning rate: 0.0070295]
	Learning Rate: 0.00702948
	LOSS [training: 0.007134223062919429 | validation: 0.009219035494322823]
	TIME [epoch: 35.1 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006623013960097667		[learning rate: 0.0070015]
	Learning Rate: 0.00700152
	LOSS [training: 0.006623013960097667 | validation: 0.007302891888352159]
	TIME [epoch: 35 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011006718733541037		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.011006718733541037 | validation: 0.005579504812241885]
	TIME [epoch: 35.1 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008284656140545533		[learning rate: 0.0069459]
	Learning Rate: 0.00694594
	LOSS [training: 0.008284656140545533 | validation: 0.005891436554706711]
	TIME [epoch: 35 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005408941771742223		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 0.005408941771742223 | validation: 0.007338758357910345]
	TIME [epoch: 35.1 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00728930634427596		[learning rate: 0.0068908]
	Learning Rate: 0.00689079
	LOSS [training: 0.00728930634427596 | validation: 0.005610125037578975]
	TIME [epoch: 35.1 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006868751446822691		[learning rate: 0.0068634]
	Learning Rate: 0.00686339
	LOSS [training: 0.006868751446822691 | validation: 0.005075793196328826]
	TIME [epoch: 35.1 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005930649726963595		[learning rate: 0.0068361]
	Learning Rate: 0.00683609
	LOSS [training: 0.005930649726963595 | validation: 0.0051889590319021475]
	TIME [epoch: 35.1 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005684704201296187		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.005684704201296187 | validation: 0.00603497489672844]
	TIME [epoch: 35.1 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0093623308398018		[learning rate: 0.0067818]
	Learning Rate: 0.00678182
	LOSS [training: 0.0093623308398018 | validation: 0.010896051980958292]
	TIME [epoch: 35.1 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007338133850586259		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.007338133850586259 | validation: 0.007779026836288679]
	TIME [epoch: 35.1 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006959980838809053		[learning rate: 0.006728]
	Learning Rate: 0.00672798
	LOSS [training: 0.006959980838809053 | validation: 0.004915791386141782]
	TIME [epoch: 35 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006826453453667937		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 0.006826453453667937 | validation: 0.008730140042463771]
	TIME [epoch: 35.1 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007096795553811307		[learning rate: 0.0066746]
	Learning Rate: 0.00667457
	LOSS [training: 0.007096795553811307 | validation: 0.007717536200200864]
	TIME [epoch: 35 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008697077565357834		[learning rate: 0.006648]
	Learning Rate: 0.00664802
	LOSS [training: 0.008697077565357834 | validation: 0.01550973833174073]
	TIME [epoch: 35.1 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010049706268659734		[learning rate: 0.0066216]
	Learning Rate: 0.00662158
	LOSS [training: 0.010049706268659734 | validation: 0.005673616710669243]
	TIME [epoch: 35.1 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005952395404475366		[learning rate: 0.0065952]
	Learning Rate: 0.00659524
	LOSS [training: 0.005952395404475366 | validation: 0.005218436164267383]
	TIME [epoch: 35.1 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00605395615294127		[learning rate: 0.006569]
	Learning Rate: 0.00656901
	LOSS [training: 0.00605395615294127 | validation: 0.004980166266736803]
	TIME [epoch: 35.1 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007041226726251469		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.007041226726251469 | validation: 0.007895143514168762]
	TIME [epoch: 35.1 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006844783999249357		[learning rate: 0.0065169]
	Learning Rate: 0.00651686
	LOSS [training: 0.006844783999249357 | validation: 0.0058383571006379855]
	TIME [epoch: 35.1 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006405781481298937		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 0.006405781481298937 | validation: 0.007658003041507451]
	TIME [epoch: 35 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007126731782433535		[learning rate: 0.0064651]
	Learning Rate: 0.00646512
	LOSS [training: 0.007126731782433535 | validation: 0.005336805533875713]
	TIME [epoch: 35 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005731137633414058		[learning rate: 0.0064394]
	Learning Rate: 0.00643941
	LOSS [training: 0.005731137633414058 | validation: 0.010308075609165647]
	TIME [epoch: 35 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007789610618511331		[learning rate: 0.0064138]
	Learning Rate: 0.0064138
	LOSS [training: 0.007789610618511331 | validation: 0.012955006120353657]
	TIME [epoch: 35.1 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008229969960285442		[learning rate: 0.0063883]
	Learning Rate: 0.00638829
	LOSS [training: 0.008229969960285442 | validation: 0.006518577546921001]
	TIME [epoch: 35.1 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007411373253796826		[learning rate: 0.0063629]
	Learning Rate: 0.00636288
	LOSS [training: 0.007411373253796826 | validation: 0.010971727732806715]
	TIME [epoch: 35 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0059084831351429445		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.0059084831351429445 | validation: 0.004829817759285278]
	TIME [epoch: 35 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0070162912225511555		[learning rate: 0.0063124]
	Learning Rate: 0.00631237
	LOSS [training: 0.0070162912225511555 | validation: 0.009686618029856096]
	TIME [epoch: 35.1 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00621669678559043		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.00621669678559043 | validation: 0.006689248118384743]
	TIME [epoch: 35.1 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006142564841680824		[learning rate: 0.0062623]
	Learning Rate: 0.00626226
	LOSS [training: 0.006142564841680824 | validation: 0.008380879456302233]
	TIME [epoch: 35 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006443474902810634		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.006443474902810634 | validation: 0.0058241165072786235]
	TIME [epoch: 35.2 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0071997053371940884		[learning rate: 0.0062125]
	Learning Rate: 0.00621254
	LOSS [training: 0.0071997053371940884 | validation: 0.007667601005748259]
	TIME [epoch: 35.1 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008617954217073806		[learning rate: 0.0061878]
	Learning Rate: 0.00618783
	LOSS [training: 0.008617954217073806 | validation: 0.005013961668035622]
	TIME [epoch: 35 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008092872315880259		[learning rate: 0.0061632]
	Learning Rate: 0.00616322
	LOSS [training: 0.008092872315880259 | validation: 0.017547064018623843]
	TIME [epoch: 35.1 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008992875195129339		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.008992875195129339 | validation: 0.006365477717351772]
	TIME [epoch: 35.1 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007252803163664334		[learning rate: 0.0061143]
	Learning Rate: 0.00611429
	LOSS [training: 0.007252803163664334 | validation: 0.005119023846013429]
	TIME [epoch: 35 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00620935015612145		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 0.00620935015612145 | validation: 0.007093357355327906]
	TIME [epoch: 35.1 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007766190441350131		[learning rate: 0.0060658]
	Learning Rate: 0.00606575
	LOSS [training: 0.007766190441350131 | validation: 0.005595608219654108]
	TIME [epoch: 35.1 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006546923377061543		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.006546923377061543 | validation: 0.005992101418560739]
	TIME [epoch: 35 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005756508237345064		[learning rate: 0.0060176]
	Learning Rate: 0.0060176
	LOSS [training: 0.005756508237345064 | validation: 0.0077743466328321605]
	TIME [epoch: 35 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00831257407801538		[learning rate: 0.0059937]
	Learning Rate: 0.00599366
	LOSS [training: 0.00831257407801538 | validation: 0.00437557601948888]
	TIME [epoch: 35 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dnmf_v1_20240624_135342/states/model_facs_dec1a_2dnmf_v1_173.pth
	Model improved!!!
EPOCH 174/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006010816356582608		[learning rate: 0.0059698]
	Learning Rate: 0.00596982
	LOSS [training: 0.006010816356582608 | validation: 0.006245078151134602]
	TIME [epoch: 35.1 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006081378154861723		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.006081378154861723 | validation: 0.004438837052298798]
	TIME [epoch: 35 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007899669991995909		[learning rate: 0.0059224]
	Learning Rate: 0.00592243
	LOSS [training: 0.007899669991995909 | validation: 0.00584893714553958]
	TIME [epoch: 35 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006041888239896369		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 0.006041888239896369 | validation: 0.004488719824944712]
	TIME [epoch: 35.1 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007433139709749477		[learning rate: 0.0058754]
	Learning Rate: 0.00587541
	LOSS [training: 0.007433139709749477 | validation: 0.007160094151931161]
	TIME [epoch: 35.1 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00618584697782658		[learning rate: 0.005852]
	Learning Rate: 0.00585205
	LOSS [training: 0.00618584697782658 | validation: 0.004866407244055684]
	TIME [epoch: 35 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006964290762770073		[learning rate: 0.0058288]
	Learning Rate: 0.00582877
	LOSS [training: 0.006964290762770073 | validation: 0.004597447890914813]
	TIME [epoch: 35.1 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006652115229708832		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.006652115229708832 | validation: 0.006692288953201664]
	TIME [epoch: 35.1 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008072577653022843		[learning rate: 0.0057825]
	Learning Rate: 0.0057825
	LOSS [training: 0.008072577653022843 | validation: 0.009121927483300683]
	TIME [epoch: 35 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007549842495460999		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.007549842495460999 | validation: 0.005497102786321966]
	TIME [epoch: 35.1 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005728662978586579		[learning rate: 0.0057366]
	Learning Rate: 0.00573659
	LOSS [training: 0.005728662978586579 | validation: 0.006108282237161409]
	TIME [epoch: 35.1 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005973304227191511		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 0.005973304227191511 | validation: 0.01116999773670833]
	TIME [epoch: 35.1 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009072921845544205		[learning rate: 0.005691]
	Learning Rate: 0.00569105
	LOSS [training: 0.009072921845544205 | validation: 0.01586110824451995]
	TIME [epoch: 35 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008408659868066012		[learning rate: 0.0056684]
	Learning Rate: 0.00566841
	LOSS [training: 0.008408659868066012 | validation: 0.0054655872211494885]
	TIME [epoch: 35 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00895806962328918		[learning rate: 0.0056459]
	Learning Rate: 0.00564587
	LOSS [training: 0.00895806962328918 | validation: 0.008127409471310385]
	TIME [epoch: 35 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00829433984058731		[learning rate: 0.0056234]
	Learning Rate: 0.00562341
	LOSS [training: 0.00829433984058731 | validation: 0.010307870841521441]
	TIME [epoch: 35 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006770741202308598		[learning rate: 0.005601]
	Learning Rate: 0.00560105
	LOSS [training: 0.006770741202308598 | validation: 0.007500988664781216]
	TIME [epoch: 35 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006391615503618726		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.006391615503618726 | validation: 0.007195287254246692]
	TIME [epoch: 35 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00776193594613989		[learning rate: 0.0055566]
	Learning Rate: 0.00555658
	LOSS [training: 0.00776193594613989 | validation: 0.007644077820390054]
	TIME [epoch: 35 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0068585348875001804		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.0068585348875001804 | validation: 0.004603811248289734]
	TIME [epoch: 35 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004891942692542638		[learning rate: 0.0055125]
	Learning Rate: 0.00551247
	LOSS [training: 0.004891942692542638 | validation: 0.005176162527233963]
	TIME [epoch: 35 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006516220138601911		[learning rate: 0.0054905]
	Learning Rate: 0.00549054
	LOSS [training: 0.006516220138601911 | validation: 0.011834945929029356]
	TIME [epoch: 35 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007928465165679383		[learning rate: 0.0054687]
	Learning Rate: 0.00546871
	LOSS [training: 0.007928465165679383 | validation: 0.004643467453960453]
	TIME [epoch: 35 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008359025699537911		[learning rate: 0.005447]
	Learning Rate: 0.00544696
	LOSS [training: 0.008359025699537911 | validation: 0.005015475659201232]
	TIME [epoch: 35.1 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005976410681688762		[learning rate: 0.0054253]
	Learning Rate: 0.00542529
	LOSS [training: 0.005976410681688762 | validation: 0.006115765292621567]
	TIME [epoch: 35.1 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006710833090345014		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.006710833090345014 | validation: 0.00712992144046948]
	TIME [epoch: 35.1 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007244880346852019		[learning rate: 0.0053822]
	Learning Rate: 0.00538222
	LOSS [training: 0.007244880346852019 | validation: 0.00553011762158179]
	TIME [epoch: 35 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004861910090260595		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.004861910090260595 | validation: 0.0068405116507603]
	TIME [epoch: 35.1 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006350601600277831		[learning rate: 0.0053395]
	Learning Rate: 0.00533949
	LOSS [training: 0.006350601600277831 | validation: 0.007096734473796204]
	TIME [epoch: 35.1 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005779942220153315		[learning rate: 0.0053183]
	Learning Rate: 0.00531826
	LOSS [training: 0.005779942220153315 | validation: 0.004287963069505097]
	TIME [epoch: 35.1 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dnmf_v1_20240624_135342/states/model_facs_dec1a_2dnmf_v1_203.pth
	Model improved!!!
EPOCH 204/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00640018059701527		[learning rate: 0.0052971]
	Learning Rate: 0.0052971
	LOSS [training: 0.00640018059701527 | validation: 0.006716313346781062]
	TIME [epoch: 35 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005486867072733443		[learning rate: 0.005276]
	Learning Rate: 0.00527604
	LOSS [training: 0.005486867072733443 | validation: 0.004557186861462355]
	TIME [epoch: 35 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005262542381430323		[learning rate: 0.0052551]
	Learning Rate: 0.00525505
	LOSS [training: 0.005262542381430323 | validation: 0.007237431203936935]
	TIME [epoch: 35 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008425197605692667		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.008425197605692667 | validation: 0.003914624927128081]
	TIME [epoch: 35.1 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dnmf_v1_20240624_135342/states/model_facs_dec1a_2dnmf_v1_207.pth
	Model improved!!!
EPOCH 208/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005609645850870932		[learning rate: 0.0052133]
	Learning Rate: 0.00521333
	LOSS [training: 0.005609645850870932 | validation: 0.003783502615699526]
	TIME [epoch: 35.1 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dnmf_v1_20240624_135342/states/model_facs_dec1a_2dnmf_v1_208.pth
	Model improved!!!
EPOCH 209/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005584491947752414		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 0.005584491947752414 | validation: 0.007332752781743279]
	TIME [epoch: 35.2 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0056516219716072295		[learning rate: 0.0051719]
	Learning Rate: 0.00517194
	LOSS [training: 0.0056516219716072295 | validation: 0.0042209434236656]
	TIME [epoch: 35.2 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005191606790076023		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.005191606790076023 | validation: 0.0070366437776355675]
	TIME [epoch: 35.2 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007146165811584698		[learning rate: 0.0051309]
	Learning Rate: 0.00513089
	LOSS [training: 0.007146165811584698 | validation: 0.004886864207528689]
	TIME [epoch: 35.2 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0055608000300241735		[learning rate: 0.0051105]
	Learning Rate: 0.00511048
	LOSS [training: 0.0055608000300241735 | validation: 0.0122784588183332]
	TIME [epoch: 35.1 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005711207028822763		[learning rate: 0.0050902]
	Learning Rate: 0.00509015
	LOSS [training: 0.005711207028822763 | validation: 0.007396630331028842]
	TIME [epoch: 35.1 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0076018477417809155		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.0076018477417809155 | validation: 0.005628508986335481]
	TIME [epoch: 35.1 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006071622344254941		[learning rate: 0.0050497]
	Learning Rate: 0.00504974
	LOSS [training: 0.006071622344254941 | validation: 0.01746356696219505]
	TIME [epoch: 35.2 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009126697633113013		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 0.009126697633113013 | validation: 0.004329122761762031]
	TIME [epoch: 35.1 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005609017564328792		[learning rate: 0.0050097]
	Learning Rate: 0.00500965
	LOSS [training: 0.005609017564328792 | validation: 0.006264969791501059]
	TIME [epoch: 35.2 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005602603115551292		[learning rate: 0.0049897]
	Learning Rate: 0.00498973
	LOSS [training: 0.005602603115551292 | validation: 0.008361965266011176]
	TIME [epoch: 35.1 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006248717768720615		[learning rate: 0.0049699]
	Learning Rate: 0.00496988
	LOSS [training: 0.006248717768720615 | validation: 0.004564150528930453]
	TIME [epoch: 35.1 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00641621683053965		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.00641621683053965 | validation: 0.00456978481732178]
	TIME [epoch: 35.1 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005030855637023635		[learning rate: 0.0049304]
	Learning Rate: 0.00493043
	LOSS [training: 0.005030855637023635 | validation: 0.008373401856826451]
	TIME [epoch: 35.1 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007762357653721363		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.007762357653721363 | validation: 0.00663580496253529]
	TIME [epoch: 35.1 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008064369401104119		[learning rate: 0.0048913]
	Learning Rate: 0.00489129
	LOSS [training: 0.008064369401104119 | validation: 0.0076234503105368666]
	TIME [epoch: 35.1 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005535395945514981		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.005535395945514981 | validation: 0.006367763962612441]
	TIME [epoch: 35.1 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006851379119744196		[learning rate: 0.0048525]
	Learning Rate: 0.00485245
	LOSS [training: 0.006851379119744196 | validation: 0.004681029178928493]
	TIME [epoch: 35.1 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007296096872828238		[learning rate: 0.0048332]
	Learning Rate: 0.00483316
	LOSS [training: 0.007296096872828238 | validation: 0.0057069700023388275]
	TIME [epoch: 35.1 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005789760513300848		[learning rate: 0.0048139]
	Learning Rate: 0.00481393
	LOSS [training: 0.005789760513300848 | validation: 0.01605776616999695]
	TIME [epoch: 35.1 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011990091178998841		[learning rate: 0.0047948]
	Learning Rate: 0.00479479
	LOSS [training: 0.011990091178998841 | validation: 0.005357158223508983]
	TIME [epoch: 35.1 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007078839312748741		[learning rate: 0.0047757]
	Learning Rate: 0.00477572
	LOSS [training: 0.007078839312748741 | validation: 0.007468915982402113]
	TIME [epoch: 35.1 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005917490955312882		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.005917490955312882 | validation: 0.005127001543965327]
	TIME [epoch: 35.1 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005632872971267628		[learning rate: 0.0047378]
	Learning Rate: 0.0047378
	LOSS [training: 0.005632872971267628 | validation: 0.00871042617259021]
	TIME [epoch: 35.2 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005656599261500735		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 0.005656599261500735 | validation: 0.01033974559729208]
	TIME [epoch: 35.1 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006616890217760144		[learning rate: 0.0047002]
	Learning Rate: 0.00470019
	LOSS [training: 0.006616890217760144 | validation: 0.00789565813023305]
	TIME [epoch: 35.1 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008538570161972776		[learning rate: 0.0046815]
	Learning Rate: 0.0046815
	LOSS [training: 0.008538570161972776 | validation: 0.00820958834940438]
	TIME [epoch: 35.1 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005300784206876619		[learning rate: 0.0046629]
	Learning Rate: 0.00466288
	LOSS [training: 0.005300784206876619 | validation: 0.004968948956834969]
	TIME [epoch: 35.1 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005972765415864774		[learning rate: 0.0046443]
	Learning Rate: 0.00464433
	LOSS [training: 0.005972765415864774 | validation: 0.005494028684958444]
	TIME [epoch: 35.1 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005332120980036794		[learning rate: 0.0046259]
	Learning Rate: 0.00462586
	LOSS [training: 0.005332120980036794 | validation: 0.009577482320657213]
	TIME [epoch: 35.1 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006985680053581423		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.006985680053581423 | validation: 0.0037814196942417234]
	TIME [epoch: 35.1 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dnmf_v1_20240624_135342/states/model_facs_dec1a_2dnmf_v1_239.pth
	Model improved!!!
EPOCH 240/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005619615419022352		[learning rate: 0.0045891]
	Learning Rate: 0.00458913
	LOSS [training: 0.005619615419022352 | validation: 0.005642896350695574]
	TIME [epoch: 35.1 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005624142297562987		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.005624142297562987 | validation: 0.004604898202452184]
	TIME [epoch: 35.1 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005664475484307251		[learning rate: 0.0045527]
	Learning Rate: 0.0045527
	LOSS [training: 0.005664475484307251 | validation: 0.007181513416507199]
	TIME [epoch: 35.1 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0059966667945172605		[learning rate: 0.0045346]
	Learning Rate: 0.00453459
	LOSS [training: 0.0059966667945172605 | validation: 0.00589348478844828]
	TIME [epoch: 35.1 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006050323973215748		[learning rate: 0.0045166]
	Learning Rate: 0.00451656
	LOSS [training: 0.006050323973215748 | validation: 0.005691828149119802]
	TIME [epoch: 35 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007272038556769496		[learning rate: 0.0044986]
	Learning Rate: 0.0044986
	LOSS [training: 0.007272038556769496 | validation: 0.003996014973294023]
	TIME [epoch: 35.1 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0057682517132947465		[learning rate: 0.0044807]
	Learning Rate: 0.0044807
	LOSS [training: 0.0057682517132947465 | validation: 0.006602767489485654]
	TIME [epoch: 35 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006406539927961911		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.006406539927961911 | validation: 0.006920319170341515]
	TIME [epoch: 35 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006877776372283754		[learning rate: 0.0044451]
	Learning Rate: 0.00444513
	LOSS [training: 0.006877776372283754 | validation: 0.005368455911016907]
	TIME [epoch: 35.1 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0062916525064613295		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 0.0062916525064613295 | validation: 0.005213174425473111]
	TIME [epoch: 35.1 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008267421339753203		[learning rate: 0.0044098]
	Learning Rate: 0.00440984
	LOSS [training: 0.008267421339753203 | validation: 0.00829319410890678]
	TIME [epoch: 35.1 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006058441925907366		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.006058441925907366 | validation: 0.004473155407677903]
	TIME [epoch: 35.1 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005428232489592021		[learning rate: 0.0043748]
	Learning Rate: 0.00437483
	LOSS [training: 0.005428232489592021 | validation: 0.005310977152702927]
	TIME [epoch: 35.1 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006674928852483205		[learning rate: 0.0043574]
	Learning Rate: 0.00435743
	LOSS [training: 0.006674928852483205 | validation: 0.009541658165116679]
	TIME [epoch: 35.1 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008043768927944476		[learning rate: 0.0043401]
	Learning Rate: 0.0043401
	LOSS [training: 0.008043768927944476 | validation: 0.005484074209597201]
	TIME [epoch: 35.1 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006277059884489284		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.006277059884489284 | validation: 0.00606000679670248]
	TIME [epoch: 35.1 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006603243803429005		[learning rate: 0.0043056]
	Learning Rate: 0.00430565
	LOSS [training: 0.006603243803429005 | validation: 0.004782818544905215]
	TIME [epoch: 35.1 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004927903418792035		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.004927903418792035 | validation: 0.0049330934259293495]
	TIME [epoch: 35.1 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006281744093980348		[learning rate: 0.0042715]
	Learning Rate: 0.00427147
	LOSS [training: 0.006281744093980348 | validation: 0.00709016914989658]
	TIME [epoch: 35.1 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005310646595137531		[learning rate: 0.0042545]
	Learning Rate: 0.00425448
	LOSS [training: 0.005310646595137531 | validation: 0.0064763771138427375]
	TIME [epoch: 35.1 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0063179169101395235		[learning rate: 0.0042376]
	Learning Rate: 0.00423756
	LOSS [training: 0.0063179169101395235 | validation: 0.00708228867177244]
	TIME [epoch: 35.1 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006248877458517847		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.006248877458517847 | validation: 0.0043826290114941015]
	TIME [epoch: 35.1 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005637490975260138		[learning rate: 0.0042039]
	Learning Rate: 0.00420391
	LOSS [training: 0.005637490975260138 | validation: 0.005237673405149615]
	TIME [epoch: 35.1 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005146277823590144		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.005146277823590144 | validation: 0.004735201311825219]
	TIME [epoch: 35.1 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0043618028077298055		[learning rate: 0.0041705]
	Learning Rate: 0.00417054
	LOSS [training: 0.0043618028077298055 | validation: 0.017342345574276212]
	TIME [epoch: 35.1 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008587802438606134		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 0.008587802438606134 | validation: 0.0048350533408942865]
	TIME [epoch: 35.1 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006017548300140652		[learning rate: 0.0041374]
	Learning Rate: 0.00413743
	LOSS [training: 0.006017548300140652 | validation: 0.004039416701457044]
	TIME [epoch: 35.1 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0048675424973132495		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.0048675424973132495 | validation: 0.0046378553427918945]
	TIME [epoch: 35.1 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005307677144757768		[learning rate: 0.0041046]
	Learning Rate: 0.00410458
	LOSS [training: 0.005307677144757768 | validation: 0.005258560112611339]
	TIME [epoch: 35.1 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005811524656178193		[learning rate: 0.0040883]
	Learning Rate: 0.00408826
	LOSS [training: 0.005811524656178193 | validation: 0.006042673345390229]
	TIME [epoch: 35.1 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005495121800061364		[learning rate: 0.004072]
	Learning Rate: 0.004072
	LOSS [training: 0.005495121800061364 | validation: 0.004718640114836501]
	TIME [epoch: 35.1 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0061945721140054975		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.0061945721140054975 | validation: 0.005691832610162835]
	TIME [epoch: 35.1 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007711641780625526		[learning rate: 0.0040397]
	Learning Rate: 0.00403967
	LOSS [training: 0.007711641780625526 | validation: 0.008171992472451314]
	TIME [epoch: 35 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007068470501760796		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 0.007068470501760796 | validation: 0.005681330078533513]
	TIME [epoch: 35.1 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004831296206871525		[learning rate: 0.0040076]
	Learning Rate: 0.0040076
	LOSS [training: 0.004831296206871525 | validation: 0.007550078077641249]
	TIME [epoch: 35.1 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006370700542714817		[learning rate: 0.0039917]
	Learning Rate: 0.00399166
	LOSS [training: 0.006370700542714817 | validation: 0.005033384578409499]
	TIME [epoch: 35.1 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00704715833536218		[learning rate: 0.0039758]
	Learning Rate: 0.00397579
	LOSS [training: 0.00704715833536218 | validation: 0.0042941924749876305]
	TIME [epoch: 35.1 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005229758707090858		[learning rate: 0.00396]
	Learning Rate: 0.00395997
	LOSS [training: 0.005229758707090858 | validation: 0.005138648762320566]
	TIME [epoch: 35 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0056812252512353206		[learning rate: 0.0039442]
	Learning Rate: 0.00394422
	LOSS [training: 0.0056812252512353206 | validation: 0.006339180893049012]
	TIME [epoch: 35.1 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006231211793790825		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.006231211793790825 | validation: 0.0046444255992839035]
	TIME [epoch: 35.1 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007253514286087932		[learning rate: 0.0039129]
	Learning Rate: 0.00391291
	LOSS [training: 0.007253514286087932 | validation: 0.00505709606080249]
	TIME [epoch: 35.1 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00574083278350947		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.00574083278350947 | validation: 0.004216122118260568]
	TIME [epoch: 35.1 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006344730346584153		[learning rate: 0.0038818]
	Learning Rate: 0.00388185
	LOSS [training: 0.006344730346584153 | validation: 0.004566560413883578]
	TIME [epoch: 35 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004660736366228649		[learning rate: 0.0038664]
	Learning Rate: 0.00386641
	LOSS [training: 0.004660736366228649 | validation: 0.003912192397977137]
	TIME [epoch: 35.1 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006109187805667619		[learning rate: 0.003851]
	Learning Rate: 0.00385103
	LOSS [training: 0.006109187805667619 | validation: 0.005203692457706155]
	TIME [epoch: 35.1 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005787353656887432		[learning rate: 0.0038357]
	Learning Rate: 0.00383571
	LOSS [training: 0.005787353656887432 | validation: 0.006230833701316039]
	TIME [epoch: 35.1 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006637703233222775		[learning rate: 0.0038205]
	Learning Rate: 0.00382046
	LOSS [training: 0.006637703233222775 | validation: 0.004082006947857738]
	TIME [epoch: 35.1 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005330007220325539		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.005330007220325539 | validation: 0.006164640637313733]
	TIME [epoch: 35.1 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005550410213722781		[learning rate: 0.0037901]
	Learning Rate: 0.00379013
	LOSS [training: 0.005550410213722781 | validation: 0.005459439461455911]
	TIME [epoch: 35.1 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006943783039986516		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.006943783039986516 | validation: 0.004871335621722391]
	TIME [epoch: 35.1 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0055327247555438		[learning rate: 0.00376]
	Learning Rate: 0.00376004
	LOSS [training: 0.0055327247555438 | validation: 0.0038955225435786203]
	TIME [epoch: 35.1 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005406564909102965		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.005406564909102965 | validation: 0.0059839244970768535]
	TIME [epoch: 35 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0058737428289868335		[learning rate: 0.0037302]
	Learning Rate: 0.00373019
	LOSS [training: 0.0058737428289868335 | validation: 0.0057069905984434]
	TIME [epoch: 35.1 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005619713185260336		[learning rate: 0.0037154]
	Learning Rate: 0.00371535
	LOSS [training: 0.005619713185260336 | validation: 0.0044002736114787805]
	TIME [epoch: 35.1 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005316621731936151		[learning rate: 0.0037006]
	Learning Rate: 0.00370058
	LOSS [training: 0.005316621731936151 | validation: 0.005126620059329348]
	TIME [epoch: 35.1 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005089841945971898		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.005089841945971898 | validation: 0.004751181633465564]
	TIME [epoch: 35.1 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006986878547917306		[learning rate: 0.0036712]
	Learning Rate: 0.0036712
	LOSS [training: 0.006986878547917306 | validation: 0.007036257268445092]
	TIME [epoch: 35.1 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006819313619127693		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 0.006819313619127693 | validation: 0.004602769223195034]
	TIME [epoch: 35.1 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005063377182393753		[learning rate: 0.0036421]
	Learning Rate: 0.00364205
	LOSS [training: 0.005063377182393753 | validation: 0.004510999166454815]
	TIME [epoch: 35.1 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0057081729922768805		[learning rate: 0.0036276]
	Learning Rate: 0.00362757
	LOSS [training: 0.0057081729922768805 | validation: 0.005145974855018967]
	TIME [epoch: 35.1 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005610775545007624		[learning rate: 0.0036131]
	Learning Rate: 0.00361314
	LOSS [training: 0.005610775545007624 | validation: 0.004600926675491488]
	TIME [epoch: 35.1 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007203644552572364		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.007203644552572364 | validation: 0.004143434942204394]
	TIME [epoch: 35 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006603794592317562		[learning rate: 0.0035845]
	Learning Rate: 0.00358445
	LOSS [training: 0.006603794592317562 | validation: 0.004219593077187809]
	TIME [epoch: 35.1 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004721089206567166		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.004721089206567166 | validation: 0.005579302347971691]
	TIME [epoch: 35.1 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005724073268978369		[learning rate: 0.003556]
	Learning Rate: 0.003556
	LOSS [training: 0.005724073268978369 | validation: 0.00898165355211852]
	TIME [epoch: 35.1 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0057230357092789485		[learning rate: 0.0035419]
	Learning Rate: 0.00354185
	LOSS [training: 0.0057230357092789485 | validation: 0.0040563556167302825]
	TIME [epoch: 35.2 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0053096736906348765		[learning rate: 0.0035278]
	Learning Rate: 0.00352777
	LOSS [training: 0.0053096736906348765 | validation: 0.01164942094780772]
	TIME [epoch: 35.1 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007758823014285159		[learning rate: 0.0035137]
	Learning Rate: 0.00351374
	LOSS [training: 0.007758823014285159 | validation: 0.003711745389216166]
	TIME [epoch: 35.1 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dnmf_v1_20240624_135342/states/model_facs_dec1a_2dnmf_v1_307.pth
	Model improved!!!
EPOCH 308/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007314478122381689		[learning rate: 0.0034998]
	Learning Rate: 0.00349976
	LOSS [training: 0.007314478122381689 | validation: 0.0043134862791360945]
	TIME [epoch: 35.1 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0054773165798644155		[learning rate: 0.0034858]
	Learning Rate: 0.00348584
	LOSS [training: 0.0054773165798644155 | validation: 0.0059974386150278836]
	TIME [epoch: 35 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00496723641643429		[learning rate: 0.003472]
	Learning Rate: 0.00347198
	LOSS [training: 0.00496723641643429 | validation: 0.004706979030716481]
	TIME [epoch: 35 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0057347889990437785		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.0057347889990437785 | validation: 0.00638384490460088]
	TIME [epoch: 35 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005216037827416016		[learning rate: 0.0034444]
	Learning Rate: 0.00344441
	LOSS [training: 0.005216037827416016 | validation: 0.006218642211580976]
	TIME [epoch: 35.1 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005856672305494692		[learning rate: 0.0034307]
	Learning Rate: 0.00343071
	LOSS [training: 0.005856672305494692 | validation: 0.005433778403793217]
	TIME [epoch: 35 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006809911924933824		[learning rate: 0.0034171]
	Learning Rate: 0.00341707
	LOSS [training: 0.006809911924933824 | validation: 0.004490732069929511]
	TIME [epoch: 35.1 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005789409609951938		[learning rate: 0.0034035]
	Learning Rate: 0.00340348
	LOSS [training: 0.005789409609951938 | validation: 0.004507287774183961]
	TIME [epoch: 35 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005383139248119218		[learning rate: 0.0033899]
	Learning Rate: 0.00338994
	LOSS [training: 0.005383139248119218 | validation: 0.004558080382928731]
	TIME [epoch: 35 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004556840567293877		[learning rate: 0.0033765]
	Learning Rate: 0.00337646
	LOSS [training: 0.004556840567293877 | validation: 0.0039013441112470877]
	TIME [epoch: 35 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006016794243132109		[learning rate: 0.003363]
	Learning Rate: 0.00336303
	LOSS [training: 0.006016794243132109 | validation: 0.00394461518609845]
	TIME [epoch: 35.1 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005860190447209899		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.005860190447209899 | validation: 0.004122646892697035]
	TIME [epoch: 35 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008428630573069517		[learning rate: 0.0033363]
	Learning Rate: 0.00333633
	LOSS [training: 0.008428630573069517 | validation: 0.0048417700512682375]
	TIME [epoch: 35 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00558199875926722		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.00558199875926722 | validation: 0.008721684509101083]
	TIME [epoch: 35.1 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007747753808075079		[learning rate: 0.0033098]
	Learning Rate: 0.00330985
	LOSS [training: 0.007747753808075079 | validation: 0.005880399154349606]
	TIME [epoch: 35.1 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005266155861332589		[learning rate: 0.0032967]
	Learning Rate: 0.00329668
	LOSS [training: 0.005266155861332589 | validation: 0.004123377919208133]
	TIME [epoch: 35 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005400620104538817		[learning rate: 0.0032836]
	Learning Rate: 0.00328357
	LOSS [training: 0.005400620104538817 | validation: 0.0046376545987585425]
	TIME [epoch: 35 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005844934593908145		[learning rate: 0.0032705]
	Learning Rate: 0.00327051
	LOSS [training: 0.005844934593908145 | validation: 0.004495198720949589]
	TIME [epoch: 35 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005092905488947609		[learning rate: 0.0032575]
	Learning Rate: 0.0032575
	LOSS [training: 0.005092905488947609 | validation: 0.004987086220515797]
	TIME [epoch: 35 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005098205989991871		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.005098205989991871 | validation: 0.0041179937402748435]
	TIME [epoch: 35 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0049115112340351215		[learning rate: 0.0032316]
	Learning Rate: 0.00323164
	LOSS [training: 0.0049115112340351215 | validation: 0.012474185375954258]
	TIME [epoch: 35 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007614843735825153		[learning rate: 0.0032188]
	Learning Rate: 0.00321879
	LOSS [training: 0.007614843735825153 | validation: 0.004113377207827691]
	TIME [epoch: 35.1 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005401103584275848		[learning rate: 0.003206]
	Learning Rate: 0.00320599
	LOSS [training: 0.005401103584275848 | validation: 0.0042090990188770406]
	TIME [epoch: 35 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0065925925606227335		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.0065925925606227335 | validation: 0.005638584778048817]
	TIME [epoch: 35 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004884301406417219		[learning rate: 0.0031805]
	Learning Rate: 0.00318053
	LOSS [training: 0.004884301406417219 | validation: 0.004233029991085839]
	TIME [epoch: 35 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005303152859428131		[learning rate: 0.0031679]
	Learning Rate: 0.00316788
	LOSS [training: 0.005303152859428131 | validation: 0.004944985773317195]
	TIME [epoch: 35 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005396453021237078		[learning rate: 0.0031553]
	Learning Rate: 0.00315528
	LOSS [training: 0.005396453021237078 | validation: 0.004334803633869222]
	TIME [epoch: 35.1 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005454835172575089		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.005454835172575089 | validation: 0.004787125432552238]
	TIME [epoch: 35 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005677863060852135		[learning rate: 0.0031302]
	Learning Rate: 0.00313023
	LOSS [training: 0.005677863060852135 | validation: 0.0074490339623043186]
	TIME [epoch: 35 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005683206188688268		[learning rate: 0.0031178]
	Learning Rate: 0.00311779
	LOSS [training: 0.005683206188688268 | validation: 0.006650520056410719]
	TIME [epoch: 35.1 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0063790787698713184		[learning rate: 0.0031054]
	Learning Rate: 0.00310538
	LOSS [training: 0.0063790787698713184 | validation: 0.004928266668984863]
	TIME [epoch: 35 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005198502040063256		[learning rate: 0.003093]
	Learning Rate: 0.00309303
	LOSS [training: 0.005198502040063256 | validation: 0.004656054838273218]
	TIME [epoch: 35 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005627298321725593		[learning rate: 0.0030807]
	Learning Rate: 0.00308073
	LOSS [training: 0.005627298321725593 | validation: 0.004690522293789167]
	TIME [epoch: 35.1 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004928455016758849		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.004928455016758849 | validation: 0.0052860626606057795]
	TIME [epoch: 35.1 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005668563211178397		[learning rate: 0.0030563]
	Learning Rate: 0.00305627
	LOSS [training: 0.005668563211178397 | validation: 0.004857925374295161]
	TIME [epoch: 35.1 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006173093959899002		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.006173093959899002 | validation: 0.004940083154796793]
	TIME [epoch: 35.1 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006189630250126211		[learning rate: 0.003032]
	Learning Rate: 0.00303201
	LOSS [training: 0.006189630250126211 | validation: 0.004402351563199481]
	TIME [epoch: 35.1 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005425546733452598		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.005425546733452598 | validation: 0.004091535709884898]
	TIME [epoch: 35.1 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005145047747492953		[learning rate: 0.0030079]
	Learning Rate: 0.00300794
	LOSS [training: 0.005145047747492953 | validation: 0.004282289631708935]
	TIME [epoch: 35.2 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007738613919123087		[learning rate: 0.002996]
	Learning Rate: 0.00299598
	LOSS [training: 0.007738613919123087 | validation: 0.0047452818611302666]
	TIME [epoch: 35.1 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005093049903238307		[learning rate: 0.0029841]
	Learning Rate: 0.00298406
	LOSS [training: 0.005093049903238307 | validation: 0.007616884711509205]
	TIME [epoch: 35.1 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005241395857478595		[learning rate: 0.0029722]
	Learning Rate: 0.00297219
	LOSS [training: 0.005241395857478595 | validation: 0.006935377863179784]
	TIME [epoch: 35.2 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0067052472970855455		[learning rate: 0.0029604]
	Learning Rate: 0.00296037
	LOSS [training: 0.0067052472970855455 | validation: 0.004357492562264071]
	TIME [epoch: 35.1 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005436223830454671		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.005436223830454671 | validation: 0.003901335911668782]
	TIME [epoch: 35.1 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00727465391954385		[learning rate: 0.0029369]
	Learning Rate: 0.00293687
	LOSS [training: 0.00727465391954385 | validation: 0.004311639431752057]
	TIME [epoch: 35.1 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006544764124096571		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.006544764124096571 | validation: 0.003765048508305893]
	TIME [epoch: 35.1 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005471931948624493		[learning rate: 0.0029136]
	Learning Rate: 0.00291355
	LOSS [training: 0.005471931948624493 | validation: 0.0045470662408691395]
	TIME [epoch: 35.1 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006214722633555109		[learning rate: 0.002902]
	Learning Rate: 0.00290197
	LOSS [training: 0.006214722633555109 | validation: 0.005021300365535058]
	TIME [epoch: 35.1 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004992161723385626		[learning rate: 0.0028904]
	Learning Rate: 0.00289042
	LOSS [training: 0.004992161723385626 | validation: 0.0038144633777185263]
	TIME [epoch: 35.1 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004886277300254221		[learning rate: 0.0028789]
	Learning Rate: 0.00287893
	LOSS [training: 0.004886277300254221 | validation: 0.004625047917792502]
	TIME [epoch: 35.1 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005603333701048335		[learning rate: 0.0028675]
	Learning Rate: 0.00286748
	LOSS [training: 0.005603333701048335 | validation: 0.004327358490981235]
	TIME [epoch: 35.1 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005573474879362875		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.005573474879362875 | validation: 0.005429483070835626]
	TIME [epoch: 35.2 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005305409474880172		[learning rate: 0.0028447]
	Learning Rate: 0.00284471
	LOSS [training: 0.005305409474880172 | validation: 0.004187340096550596]
	TIME [epoch: 35.1 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006028852853579088		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.006028852853579088 | validation: 0.004749158526962285]
	TIME [epoch: 35.2 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005551844311953014		[learning rate: 0.0028221]
	Learning Rate: 0.00282213
	LOSS [training: 0.005551844311953014 | validation: 0.005818447817156445]
	TIME [epoch: 35.1 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006077513138801423		[learning rate: 0.0028109]
	Learning Rate: 0.00281091
	LOSS [training: 0.006077513138801423 | validation: 0.00436936550008586]
	TIME [epoch: 35.6 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0048072529163472		[learning rate: 0.0027997]
	Learning Rate: 0.00279973
	LOSS [training: 0.0048072529163472 | validation: 0.004265509277765109]
	TIME [epoch: 36 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005222323048073448		[learning rate: 0.0027886]
	Learning Rate: 0.00278859
	LOSS [training: 0.005222323048073448 | validation: 0.004559622369502865]
	TIME [epoch: 35.9 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004949040004454389		[learning rate: 0.0027775]
	Learning Rate: 0.0027775
	LOSS [training: 0.004949040004454389 | validation: 0.0049223835099173165]
	TIME [epoch: 36.1 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00623014486871552		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.00623014486871552 | validation: 0.004028064178868701]
	TIME [epoch: 36.1 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005364858693712495		[learning rate: 0.0027554]
	Learning Rate: 0.00275545
	LOSS [training: 0.005364858693712495 | validation: 0.004260955675738391]
	TIME [epoch: 36.1 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005119085218440795		[learning rate: 0.0027445]
	Learning Rate: 0.00274449
	LOSS [training: 0.005119085218440795 | validation: 0.0038793834463956415]
	TIME [epoch: 36.1 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004966922764587138		[learning rate: 0.0027336]
	Learning Rate: 0.00273357
	LOSS [training: 0.004966922764587138 | validation: 0.005302367724619188]
	TIME [epoch: 36.1 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005348930683032727		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.005348930683032727 | validation: 0.006541828981430649]
	TIME [epoch: 36.2 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005825008076848405		[learning rate: 0.0027119]
	Learning Rate: 0.00271187
	LOSS [training: 0.005825008076848405 | validation: 0.004404066745309559]
	TIME [epoch: 36 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004920841946996799		[learning rate: 0.0027011]
	Learning Rate: 0.00270109
	LOSS [training: 0.004920841946996799 | validation: 0.003934903634836377]
	TIME [epoch: 35.6 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005184882580627548		[learning rate: 0.0026903]
	Learning Rate: 0.00269034
	LOSS [training: 0.005184882580627548 | validation: 0.00459243586782792]
	TIME [epoch: 35.2 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005379864514419404		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.005379864514419404 | validation: 0.004405243872126445]
	TIME [epoch: 35 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0054316586747347574		[learning rate: 0.002669]
	Learning Rate: 0.00266899
	LOSS [training: 0.0054316586747347574 | validation: 0.0038707936790466275]
	TIME [epoch: 35 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005616941082082564		[learning rate: 0.0026584]
	Learning Rate: 0.00265837
	LOSS [training: 0.005616941082082564 | validation: 0.003769798766555028]
	TIME [epoch: 35 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005980084579672484		[learning rate: 0.0026478]
	Learning Rate: 0.0026478
	LOSS [training: 0.005980084579672484 | validation: 0.004194447719439536]
	TIME [epoch: 35 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005101996653573896		[learning rate: 0.0026373]
	Learning Rate: 0.00263727
	LOSS [training: 0.005101996653573896 | validation: 0.005477507044214792]
	TIME [epoch: 35 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005479244514583526		[learning rate: 0.0026268]
	Learning Rate: 0.00262678
	LOSS [training: 0.005479244514583526 | validation: 0.004583830057818342]
	TIME [epoch: 35 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005094602176100502		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.005094602176100502 | validation: 0.005309296424391464]
	TIME [epoch: 35 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005885643863976329		[learning rate: 0.0026059]
	Learning Rate: 0.00260592
	LOSS [training: 0.005885643863976329 | validation: 0.004710653296486891]
	TIME [epoch: 35.8 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0047195358643122584		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.0047195358643122584 | validation: 0.004021874922722648]
	TIME [epoch: 36 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005310260371316882		[learning rate: 0.0025852]
	Learning Rate: 0.00258523
	LOSS [training: 0.005310260371316882 | validation: 0.005883981091250905]
	TIME [epoch: 36 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005176689522709404		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.005176689522709404 | validation: 0.005803634118912733]
	TIME [epoch: 36.1 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005716549176522213		[learning rate: 0.0025647]
	Learning Rate: 0.00256471
	LOSS [training: 0.005716549176522213 | validation: 0.004890736546795416]
	TIME [epoch: 36.2 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0055521013489330555		[learning rate: 0.0025545]
	Learning Rate: 0.00255451
	LOSS [training: 0.0055521013489330555 | validation: 0.0040787223575246044]
	TIME [epoch: 36.1 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004559406692626326		[learning rate: 0.0025444]
	Learning Rate: 0.00254435
	LOSS [training: 0.004559406692626326 | validation: 0.004981732262587824]
	TIME [epoch: 36.1 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006093359911809676		[learning rate: 0.0025342]
	Learning Rate: 0.00253423
	LOSS [training: 0.006093359911809676 | validation: 0.004093683570374136]
	TIME [epoch: 36.1 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005847290506975833		[learning rate: 0.0025242]
	Learning Rate: 0.00252415
	LOSS [training: 0.005847290506975833 | validation: 0.004674248542907211]
	TIME [epoch: 36 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005208663344097847		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.005208663344097847 | validation: 0.004601861266045213]
	TIME [epoch: 36.1 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005280530171766568		[learning rate: 0.0025041]
	Learning Rate: 0.00250411
	LOSS [training: 0.005280530171766568 | validation: 0.00457965917901273]
	TIME [epoch: 35.4 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0059637682675186005		[learning rate: 0.0024942]
	Learning Rate: 0.00249415
	LOSS [training: 0.0059637682675186005 | validation: 0.005009908915428629]
	TIME [epoch: 35.6 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005206419461510602		[learning rate: 0.0024842]
	Learning Rate: 0.00248423
	LOSS [training: 0.005206419461510602 | validation: 0.004764263544337876]
	TIME [epoch: 35.3 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0058542502576389086		[learning rate: 0.0024744]
	Learning Rate: 0.00247435
	LOSS [training: 0.0058542502576389086 | validation: 0.004564126875835144]
	TIME [epoch: 35.2 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005162830132721239		[learning rate: 0.0024645]
	Learning Rate: 0.00246451
	LOSS [training: 0.005162830132721239 | validation: 0.004203222266682745]
	TIME [epoch: 35 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00510442518064643		[learning rate: 0.0024547]
	Learning Rate: 0.00245471
	LOSS [training: 0.00510442518064643 | validation: 0.004243608878730548]
	TIME [epoch: 35 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005649893436815923		[learning rate: 0.0024449]
	Learning Rate: 0.00244495
	LOSS [training: 0.005649893436815923 | validation: 0.004208220513281611]
	TIME [epoch: 35 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006044827138099946		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.006044827138099946 | validation: 0.00661260462071227]
	TIME [epoch: 35 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005889451295403254		[learning rate: 0.0024255]
	Learning Rate: 0.00242554
	LOSS [training: 0.005889451295403254 | validation: 0.003940019580604552]
	TIME [epoch: 35 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006091482796455263		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.006091482796455263 | validation: 0.004801184684981253]
	TIME [epoch: 36.1 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004980328446935144		[learning rate: 0.0024063]
	Learning Rate: 0.00240628
	LOSS [training: 0.004980328446935144 | validation: 0.003831259949021418]
	TIME [epoch: 36 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005403238361083328		[learning rate: 0.0023967]
	Learning Rate: 0.00239671
	LOSS [training: 0.005403238361083328 | validation: 0.004948959168681677]
	TIME [epoch: 36 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005880386722411876		[learning rate: 0.0023872]
	Learning Rate: 0.00238718
	LOSS [training: 0.005880386722411876 | validation: 0.003915233665792254]
	TIME [epoch: 36.1 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005082841626062857		[learning rate: 0.0023777]
	Learning Rate: 0.00237768
	LOSS [training: 0.005082841626062857 | validation: 0.00518882109135327]
	TIME [epoch: 36.2 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005189364232322107		[learning rate: 0.0023682]
	Learning Rate: 0.00236823
	LOSS [training: 0.005189364232322107 | validation: 0.003995257200297373]
	TIME [epoch: 36.1 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004634546726903988		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.004634546726903988 | validation: 0.004486650771946743]
	TIME [epoch: 35.9 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005370199220462387		[learning rate: 0.0023494]
	Learning Rate: 0.00234942
	LOSS [training: 0.005370199220462387 | validation: 0.005107928493569411]
	TIME [epoch: 35.9 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005001338154382805		[learning rate: 0.0023401]
	Learning Rate: 0.00234008
	LOSS [training: 0.005001338154382805 | validation: 0.004347681258928278]
	TIME [epoch: 36.1 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005256731052351259		[learning rate: 0.0023308]
	Learning Rate: 0.00233077
	LOSS [training: 0.005256731052351259 | validation: 0.004117454131861309]
	TIME [epoch: 35.9 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004760727840720803		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.004760727840720803 | validation: 0.004008801927437125]
	TIME [epoch: 35.4 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006279176497983752		[learning rate: 0.0023123]
	Learning Rate: 0.00231227
	LOSS [training: 0.006279176497983752 | validation: 0.003981111727268179]
	TIME [epoch: 35.3 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004758001651236072		[learning rate: 0.0023031]
	Learning Rate: 0.00230307
	LOSS [training: 0.004758001651236072 | validation: 0.004585543034285423]
	TIME [epoch: 35 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005494990274445217		[learning rate: 0.0022939]
	Learning Rate: 0.00229391
	LOSS [training: 0.005494990274445217 | validation: 0.004044721486262209]
	TIME [epoch: 35 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005110435536431352		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.005110435536431352 | validation: 0.004921823940444559]
	TIME [epoch: 35 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00515336166889711		[learning rate: 0.0022757]
	Learning Rate: 0.0022757
	LOSS [training: 0.00515336166889711 | validation: 0.003958182316927172]
	TIME [epoch: 35 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006811923225469722		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.006811923225469722 | validation: 0.004392183438340328]
	TIME [epoch: 35 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0058957053098257035		[learning rate: 0.0022576]
	Learning Rate: 0.00225764
	LOSS [training: 0.0058957053098257035 | validation: 0.004314551451173605]
	TIME [epoch: 35 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0053648264931051536		[learning rate: 0.0022487]
	Learning Rate: 0.00224866
	LOSS [training: 0.0053648264931051536 | validation: 0.00457020471710861]
	TIME [epoch: 35 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006340023225397544		[learning rate: 0.0022397]
	Learning Rate: 0.00223971
	LOSS [training: 0.006340023225397544 | validation: 0.004066000298098844]
	TIME [epoch: 35 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0054191197097491935		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.0054191197097491935 | validation: 0.0043442723062937245]
	TIME [epoch: 35.9 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005177003308894864		[learning rate: 0.0022219]
	Learning Rate: 0.00222193
	LOSS [training: 0.005177003308894864 | validation: 0.006470320964322594]
	TIME [epoch: 36 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005989743537984306		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.005989743537984306 | validation: 0.004369908839340834]
	TIME [epoch: 36 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005356412054319875		[learning rate: 0.0022043]
	Learning Rate: 0.00220429
	LOSS [training: 0.005356412054319875 | validation: 0.004333227590320195]
	TIME [epoch: 36.1 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006042563768051511		[learning rate: 0.0021955]
	Learning Rate: 0.00219553
	LOSS [training: 0.006042563768051511 | validation: 0.004182997674802724]
	TIME [epoch: 36.1 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006184058889523862		[learning rate: 0.0021868]
	Learning Rate: 0.00218679
	LOSS [training: 0.006184058889523862 | validation: 0.004111130651781103]
	TIME [epoch: 36.2 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004775889848014709		[learning rate: 0.0021781]
	Learning Rate: 0.0021781
	LOSS [training: 0.004775889848014709 | validation: 0.004587150743033548]
	TIME [epoch: 36 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007938217383410615		[learning rate: 0.0021694]
	Learning Rate: 0.00216943
	LOSS [training: 0.007938217383410615 | validation: 0.004531564299048645]
	TIME [epoch: 35.9 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005597306872326039		[learning rate: 0.0021608]
	Learning Rate: 0.0021608
	LOSS [training: 0.005597306872326039 | validation: 0.004420217584498558]
	TIME [epoch: 36 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005319567349628358		[learning rate: 0.0021522]
	Learning Rate: 0.00215221
	LOSS [training: 0.005319567349628358 | validation: 0.003993647241189113]
	TIME [epoch: 36 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004812833733383004		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.004812833733383004 | validation: 0.0044863054357847255]
	TIME [epoch: 35.5 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004740293896587754		[learning rate: 0.0021351]
	Learning Rate: 0.00213512
	LOSS [training: 0.004740293896587754 | validation: 0.004041257223841939]
	TIME [epoch: 35.2 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005424801525666172		[learning rate: 0.0021266]
	Learning Rate: 0.00212663
	LOSS [training: 0.005424801525666172 | validation: 0.003880228217646766]
	TIME [epoch: 35 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00510121035394201		[learning rate: 0.0021182]
	Learning Rate: 0.00211817
	LOSS [training: 0.00510121035394201 | validation: 0.004233890798148417]
	TIME [epoch: 35 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004617379591344115		[learning rate: 0.0021097]
	Learning Rate: 0.00210975
	LOSS [training: 0.004617379591344115 | validation: 0.004394073218469538]
	TIME [epoch: 35 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0060687111436156325		[learning rate: 0.0021014]
	Learning Rate: 0.00210136
	LOSS [training: 0.0060687111436156325 | validation: 0.004645386918790387]
	TIME [epoch: 35 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004778838607353262		[learning rate: 0.002093]
	Learning Rate: 0.002093
	LOSS [training: 0.004778838607353262 | validation: 0.0042672844317443075]
	TIME [epoch: 35 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00569156470847829		[learning rate: 0.0020847]
	Learning Rate: 0.00208468
	LOSS [training: 0.00569156470847829 | validation: 0.0042785159726378245]
	TIME [epoch: 35 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005483329834942478		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.005483329834942478 | validation: 0.004923432142233426]
	TIME [epoch: 35 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005591438062781299		[learning rate: 0.0020681]
	Learning Rate: 0.00206813
	LOSS [training: 0.005591438062781299 | validation: 0.0043549729801704955]
	TIME [epoch: 35 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0056551049734282115		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.0056551049734282115 | validation: 0.004042707554035876]
	TIME [epoch: 36 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005737200790965035		[learning rate: 0.0020517]
	Learning Rate: 0.00205171
	LOSS [training: 0.005737200790965035 | validation: 0.004415142348321064]
	TIME [epoch: 36 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004839155581473126		[learning rate: 0.0020435]
	Learning Rate: 0.00204355
	LOSS [training: 0.004839155581473126 | validation: 0.0041694573979253]
	TIME [epoch: 36 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004889198424121697		[learning rate: 0.0020354]
	Learning Rate: 0.00203542
	LOSS [training: 0.004889198424121697 | validation: 0.004630083688516776]
	TIME [epoch: 36.1 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005331969297305471		[learning rate: 0.0020273]
	Learning Rate: 0.00202732
	LOSS [training: 0.005331969297305471 | validation: 0.004196726636422339]
	TIME [epoch: 36.1 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0053021054393717505		[learning rate: 0.0020193]
	Learning Rate: 0.00201926
	LOSS [training: 0.0053021054393717505 | validation: 0.0039842988301224975]
	TIME [epoch: 36.1 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005094165635873611		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.005094165635873611 | validation: 0.004450120709283136]
	TIME [epoch: 36 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004974175178958144		[learning rate: 0.0020032]
	Learning Rate: 0.00200323
	LOSS [training: 0.004974175178958144 | validation: 0.004667007724186237]
	TIME [epoch: 36 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004890155312756928		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.004890155312756928 | validation: 0.003966898447499916]
	TIME [epoch: 35.8 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004979365957308676		[learning rate: 0.0019873]
	Learning Rate: 0.00198733
	LOSS [training: 0.004979365957308676 | validation: 0.0045424767298001805]
	TIME [epoch: 36 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004982294542766935		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.004982294542766935 | validation: 0.0038491138878932055]
	TIME [epoch: 35.8 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005174948712046727		[learning rate: 0.0019715]
	Learning Rate: 0.00197155
	LOSS [training: 0.005174948712046727 | validation: 0.004596891894099548]
	TIME [epoch: 35.2 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00711416296102508		[learning rate: 0.0019637]
	Learning Rate: 0.00196371
	LOSS [training: 0.00711416296102508 | validation: 0.003857650407912923]
	TIME [epoch: 35.2 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005782698774452941		[learning rate: 0.0019559]
	Learning Rate: 0.0019559
	LOSS [training: 0.005782698774452941 | validation: 0.004167444844842687]
	TIME [epoch: 35.1 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004742332385075038		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.004742332385075038 | validation: 0.004704158384865717]
	TIME [epoch: 35 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00571817472242475		[learning rate: 0.0019404]
	Learning Rate: 0.00194037
	LOSS [training: 0.00571817472242475 | validation: 0.004186975032764809]
	TIME [epoch: 35 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005216899651399694		[learning rate: 0.0019327]
	Learning Rate: 0.00193265
	LOSS [training: 0.005216899651399694 | validation: 0.004204513985477738]
	TIME [epoch: 35 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0057518386028427015		[learning rate: 0.001925]
	Learning Rate: 0.00192497
	LOSS [training: 0.0057518386028427015 | validation: 0.005725472274908121]
	TIME [epoch: 35 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0056699272028192665		[learning rate: 0.0019173]
	Learning Rate: 0.00191731
	LOSS [training: 0.0056699272028192665 | validation: 0.0041112256460640985]
	TIME [epoch: 35 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005613437097739209		[learning rate: 0.0019097]
	Learning Rate: 0.00190968
	LOSS [training: 0.005613437097739209 | validation: 0.004128623728958818]
	TIME [epoch: 36.1 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005026052240213958		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.005026052240213958 | validation: 0.004467270589293704]
	TIME [epoch: 36.1 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005098728085619388		[learning rate: 0.0018945]
	Learning Rate: 0.00189452
	LOSS [training: 0.005098728085619388 | validation: 0.0044020433407199015]
	TIME [epoch: 36 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004994914159841645		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.004994914159841645 | validation: 0.004557397747899597]
	TIME [epoch: 36.1 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005454649468256035		[learning rate: 0.0018795]
	Learning Rate: 0.00187948
	LOSS [training: 0.005454649468256035 | validation: 0.005046220173871907]
	TIME [epoch: 36.1 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004917441373295188		[learning rate: 0.001872]
	Learning Rate: 0.00187201
	LOSS [training: 0.004917441373295188 | validation: 0.004496618309386387]
	TIME [epoch: 36.2 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005413245974816603		[learning rate: 0.0018646]
	Learning Rate: 0.00186456
	LOSS [training: 0.005413245974816603 | validation: 0.004401501413097071]
	TIME [epoch: 36 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0056486734467103665		[learning rate: 0.0018571]
	Learning Rate: 0.00185715
	LOSS [training: 0.0056486734467103665 | validation: 0.003852005656972564]
	TIME [epoch: 35.8 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005037713319386405		[learning rate: 0.0018498]
	Learning Rate: 0.00184976
	LOSS [training: 0.005037713319386405 | validation: 0.004500263349494808]
	TIME [epoch: 35.9 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005369088886006947		[learning rate: 0.0018424]
	Learning Rate: 0.0018424
	LOSS [training: 0.005369088886006947 | validation: 0.004664009137031991]
	TIME [epoch: 35.7 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0047226766693457		[learning rate: 0.0018351]
	Learning Rate: 0.00183508
	LOSS [training: 0.0047226766693457 | validation: 0.004688901536240108]
	TIME [epoch: 35.3 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0062741921727810165		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.0062741921727810165 | validation: 0.004777252794922045]
	TIME [epoch: 35.3 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006175290610350137		[learning rate: 0.0018205]
	Learning Rate: 0.00182051
	LOSS [training: 0.006175290610350137 | validation: 0.003974330405992843]
	TIME [epoch: 35.1 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0048445876920784215		[learning rate: 0.0018133]
	Learning Rate: 0.00181327
	LOSS [training: 0.0048445876920784215 | validation: 0.004278140559882906]
	TIME [epoch: 35.1 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004919825719407125		[learning rate: 0.0018061]
	Learning Rate: 0.00180605
	LOSS [training: 0.004919825719407125 | validation: 0.0038314176400783494]
	TIME [epoch: 35 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0053923789704588025		[learning rate: 0.0017989]
	Learning Rate: 0.00179887
	LOSS [training: 0.0053923789704588025 | validation: 0.004120292126707312]
	TIME [epoch: 35 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0052634954591574325		[learning rate: 0.0017917]
	Learning Rate: 0.00179172
	LOSS [training: 0.0052634954591574325 | validation: 0.004027879840557284]
	TIME [epoch: 35 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005526355354622359		[learning rate: 0.0017846]
	Learning Rate: 0.00178459
	LOSS [training: 0.005526355354622359 | validation: 0.004712272067054194]
	TIME [epoch: 35 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005242746073430931		[learning rate: 0.0017775]
	Learning Rate: 0.00177749
	LOSS [training: 0.005242746073430931 | validation: 0.004048731010316393]
	TIME [epoch: 35.3 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005038455621069676		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.005038455621069676 | validation: 0.004216054736547661]
	TIME [epoch: 36.2 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006013887737061276		[learning rate: 0.0017634]
	Learning Rate: 0.00176338
	LOSS [training: 0.006013887737061276 | validation: 0.004583277247286954]
	TIME [epoch: 36 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006132828355842756		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.006132828355842756 | validation: 0.004072005930575742]
	TIME [epoch: 36.1 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005413181665571163		[learning rate: 0.0017494]
	Learning Rate: 0.00174938
	LOSS [training: 0.005413181665571163 | validation: 0.004275320965195432]
	TIME [epoch: 36.1 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004942141255030352		[learning rate: 0.0017424]
	Learning Rate: 0.00174242
	LOSS [training: 0.004942141255030352 | validation: 0.00402002441663297]
	TIME [epoch: 36.1 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004724643162802625		[learning rate: 0.0017355]
	Learning Rate: 0.00173549
	LOSS [training: 0.004724643162802625 | validation: 0.004620675156309236]
	TIME [epoch: 36.2 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004919613244245403		[learning rate: 0.0017286]
	Learning Rate: 0.00172859
	LOSS [training: 0.004919613244245403 | validation: 0.005559997379382202]
	TIME [epoch: 36 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005098839165999009		[learning rate: 0.0017217]
	Learning Rate: 0.00172172
	LOSS [training: 0.005098839165999009 | validation: 0.0041832898408364775]
	TIME [epoch: 36.2 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005133537808452414		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.005133537808452414 | validation: 0.004313741478299571]
	TIME [epoch: 36 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00472028772688818		[learning rate: 0.001708]
	Learning Rate: 0.00170805
	LOSS [training: 0.00472028772688818 | validation: 0.00465321598545216]
	TIME [epoch: 36 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004806764528842081		[learning rate: 0.0017013]
	Learning Rate: 0.00170125
	LOSS [training: 0.004806764528842081 | validation: 0.003973711975948753]
	TIME [epoch: 35.5 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00488511202995915		[learning rate: 0.0016945]
	Learning Rate: 0.00169449
	LOSS [training: 0.00488511202995915 | validation: 0.0045652169067552425]
	TIME [epoch: 35.1 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006089931566373296		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.006089931566373296 | validation: 0.004111775626816043]
	TIME [epoch: 35 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004995565658125139		[learning rate: 0.001681]
	Learning Rate: 0.00168104
	LOSS [training: 0.004995565658125139 | validation: 0.004237311883360984]
	TIME [epoch: 35 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005193704250006911		[learning rate: 0.0016743]
	Learning Rate: 0.00167435
	LOSS [training: 0.005193704250006911 | validation: 0.0040852236701996334]
	TIME [epoch: 35 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004804772420283179		[learning rate: 0.0016677]
	Learning Rate: 0.00166769
	LOSS [training: 0.004804772420283179 | validation: 0.004027093225381978]
	TIME [epoch: 35 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004604179541285645		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.004604179541285645 | validation: 0.003853938280083407]
	TIME [epoch: 35 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005094302928023802		[learning rate: 0.0016545]
	Learning Rate: 0.00165445
	LOSS [training: 0.005094302928023802 | validation: 0.004599048878726334]
	TIME [epoch: 35 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004962962046002915		[learning rate: 0.0016479]
	Learning Rate: 0.00164787
	LOSS [training: 0.004962962046002915 | validation: 0.003948998547945589]
	TIME [epoch: 35.4 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.006378220367640348		[learning rate: 0.0016413]
	Learning Rate: 0.00164132
	LOSS [training: 0.006378220367640348 | validation: 0.004381604440445925]
	TIME [epoch: 36 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005214081711978337		[learning rate: 0.0016348]
	Learning Rate: 0.00163479
	LOSS [training: 0.005214081711978337 | validation: 0.0041305421090018606]
	TIME [epoch: 36 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005769854930727074		[learning rate: 0.0016283]
	Learning Rate: 0.00162829
	LOSS [training: 0.005769854930727074 | validation: 0.0039006760674370035]
	TIME [epoch: 36.1 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005205209642696706		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.005205209642696706 | validation: 0.00453114980923639]
	TIME [epoch: 36.1 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005258377207880757		[learning rate: 0.0016154]
	Learning Rate: 0.00161536
	LOSS [training: 0.005258377207880757 | validation: 0.004258584955970966]
	TIME [epoch: 36.1 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005549863491451296		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.005549863491451296 | validation: 0.003955985909191556]
	TIME [epoch: 36.1 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005231872310686879		[learning rate: 0.0016025]
	Learning Rate: 0.00160254
	LOSS [training: 0.005231872310686879 | validation: 0.004031366402716934]
	TIME [epoch: 36.1 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004735310486579596		[learning rate: 0.0015962]
	Learning Rate: 0.00159616
	LOSS [training: 0.004735310486579596 | validation: 0.004646342278186636]
	TIME [epoch: 36.1 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.004976797701777288		[learning rate: 0.0015898]
	Learning Rate: 0.00158981
	LOSS [training: 0.004976797701777288 | validation: 0.004070157355789435]
	TIME [epoch: 35.9 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0050990061337368164		[learning rate: 0.0015835]
	Learning Rate: 0.00158349
	LOSS [training: 0.0050990061337368164 | validation: 0.0039055398699115564]
	TIME [epoch: 35.4 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.005339169436031977		[learning rate: 0.0015772]
	Learning Rate: 0.00157719
	LOSS [training: 0.005339169436031977 | validation: 0.0035832301860633598]
	TIME [epoch: 35.4 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dnmf_v1_20240624_135342/states/model_facs_dec1a_2dnmf_v1_508.pth
	Model improved!!!
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 18087.479 seconds.
