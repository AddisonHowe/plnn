Args:
Namespace(name='model_facs_v2_dec2b_2dpca_v1', outdir='out/model_training/model_facs_v2_dec2b_2dpca_v1', training_data='data/training_data/facs_v2/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v2/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=500, ncells_sample=500, model_do_sample=False, dt=0.001, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.3], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2149006321

Training model...

Saving initial model state to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5039448409886459		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5039448409886459 | validation: 0.4798526181305195]
	TIME [epoch: 60.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3584304774117134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3584304774117134 | validation: 0.4561858331424725]
	TIME [epoch: 35.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33257081137152966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33257081137152966 | validation: 0.413602219331788]
	TIME [epoch: 35.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33168719242819006		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33168719242819006 | validation: 0.40234490324582245]
	TIME [epoch: 35.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2957217867929774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2957217867929774 | validation: 0.45321714974926497]
	TIME [epoch: 35.8 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27666772526963035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27666772526963035 | validation: 0.4988248421388334]
	TIME [epoch: 35.8 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2532093875969101		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2532093875969101 | validation: 0.3474865377742613]
	TIME [epoch: 35.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28754283183481316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28754283183481316 | validation: 0.31913962767536896]
	TIME [epoch: 35.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21225684166719647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21225684166719647 | validation: 0.3022617695255846]
	TIME [epoch: 35.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19855070221980803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19855070221980803 | validation: 0.36660038330030836]
	TIME [epoch: 35.7 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23937114363454964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23937114363454964 | validation: 0.31931875994619063]
	TIME [epoch: 35.7 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21053575784039386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21053575784039386 | validation: 0.3028479857378739]
	TIME [epoch: 35.8 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18854281818291924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18854281818291924 | validation: 0.2757866042022488]
	TIME [epoch: 35.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19543616596397245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19543616596397245 | validation: 0.30429973792531534]
	TIME [epoch: 35.8 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18551820857272514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18551820857272514 | validation: 0.270753633441878]
	TIME [epoch: 35.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21188393098912267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21188393098912267 | validation: 0.2762983880407819]
	TIME [epoch: 35.7 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18077199994314128		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18077199994314128 | validation: 0.28675055763840934]
	TIME [epoch: 35.8 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17462289327109723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17462289327109723 | validation: 0.2585851137239549]
	TIME [epoch: 35.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19446992297582727		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19446992297582727 | validation: 0.27099230794856394]
	TIME [epoch: 35.7 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17094015283727795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17094015283727795 | validation: 0.2651338950805624]
	TIME [epoch: 35.8 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17150741741411524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17150741741411524 | validation: 0.2651895685984145]
	TIME [epoch: 35.8 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16831189546515474		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16831189546515474 | validation: 0.30483597691763864]
	TIME [epoch: 35.9 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19832973271055981		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19832973271055981 | validation: 0.25238444633459983]
	TIME [epoch: 35.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15910084772980237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15910084772980237 | validation: 0.24477545835864797]
	TIME [epoch: 35.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16937546230455727		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16937546230455727 | validation: 0.3050511013955731]
	TIME [epoch: 35.8 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17303175239642782		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17303175239642782 | validation: 0.2548702458600644]
	TIME [epoch: 35.8 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15703376782366288		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15703376782366288 | validation: 0.24509729016729132]
	TIME [epoch: 35.8 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16231930596337418		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16231930596337418 | validation: 0.2736556938815816]
	TIME [epoch: 35.9 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17278386972249682		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17278386972249682 | validation: 0.2326527660461914]
	TIME [epoch: 35.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15364755619318538		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15364755619318538 | validation: 0.22592164281714677]
	TIME [epoch: 35.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14790933470107964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14790933470107964 | validation: 0.22523951576382806]
	TIME [epoch: 35.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17611051501096492		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17611051501096492 | validation: 0.23547938412253347]
	TIME [epoch: 35.8 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1465417182881117		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1465417182881117 | validation: 0.22023229507783917]
	TIME [epoch: 35.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14122493099000516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14122493099000516 | validation: 0.2130826260399335]
	TIME [epoch: 35.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14214459913838945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14214459913838945 | validation: 0.2261168415947918]
	TIME [epoch: 35.9 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1681770445998106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1681770445998106 | validation: 0.21255981469116428]
	TIME [epoch: 35.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15565986828577216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15565986828577216 | validation: 0.2510508577678588]
	TIME [epoch: 35.9 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1513872846623627		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1513872846623627 | validation: 0.21122053391609108]
	TIME [epoch: 35.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.151010964975787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.151010964975787 | validation: 0.20713625089931278]
	TIME [epoch: 35.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12682101396951045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12682101396951045 | validation: 0.19336811254461764]
	TIME [epoch: 35.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16320153062225662		[learning rate: 0.0099646]
	Learning Rate: 0.00996464
	LOSS [training: 0.16320153062225662 | validation: 0.24766736078715715]
	TIME [epoch: 35.8 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14487958563696313		[learning rate: 0.0099206]
	Learning Rate: 0.00992061
	LOSS [training: 0.14487958563696313 | validation: 0.2800500734219172]
	TIME [epoch: 35.9 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16826131834593924		[learning rate: 0.0098768]
	Learning Rate: 0.00987678
	LOSS [training: 0.16826131834593924 | validation: 0.20099043992423415]
	TIME [epoch: 35.8 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12739674296129788		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.12739674296129788 | validation: 0.22959273489524162]
	TIME [epoch: 35.7 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15042817483783907		[learning rate: 0.0097897]
	Learning Rate: 0.0097897
	LOSS [training: 0.15042817483783907 | validation: 0.22945886511813063]
	TIME [epoch: 35.6 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13031397549599968		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.13031397549599968 | validation: 0.18055592561056913]
	TIME [epoch: 35.6 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14948709154505718		[learning rate: 0.0097034]
	Learning Rate: 0.00970338
	LOSS [training: 0.14948709154505718 | validation: 0.20816429253680369]
	TIME [epoch: 35.6 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1283077894641591		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.1283077894641591 | validation: 0.19972561003356412]
	TIME [epoch: 35.6 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1544547739235263		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.1544547739235263 | validation: 0.35201046751702075]
	TIME [epoch: 35.6 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15225109474702148		[learning rate: 0.0095753]
	Learning Rate: 0.00957533
	LOSS [training: 0.15225109474702148 | validation: 0.20176800056694044]
	TIME [epoch: 35.6 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.134788478654817		[learning rate: 0.009533]
	Learning Rate: 0.00953303
	LOSS [training: 0.134788478654817 | validation: 0.19759138881200453]
	TIME [epoch: 35.7 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13544681840828682		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.13544681840828682 | validation: 0.20018643596258284]
	TIME [epoch: 35.7 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13014749486547406		[learning rate: 0.009449]
	Learning Rate: 0.00944897
	LOSS [training: 0.13014749486547406 | validation: 0.22791481580805534]
	TIME [epoch: 35.7 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14972787110311386		[learning rate: 0.0094072]
	Learning Rate: 0.00940722
	LOSS [training: 0.14972787110311386 | validation: 0.21168004078244984]
	TIME [epoch: 35.7 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13545683650210608		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.13545683650210608 | validation: 0.21987271253214502]
	TIME [epoch: 35.7 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12096665233846685		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.12096665233846685 | validation: 0.19864705783920253]
	TIME [epoch: 35.7 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14051605435643066		[learning rate: 0.0092831]
	Learning Rate: 0.00928308
	LOSS [training: 0.14051605435643066 | validation: 0.18409300847259363]
	TIME [epoch: 35.7 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12409124977246537		[learning rate: 0.0092421]
	Learning Rate: 0.00924207
	LOSS [training: 0.12409124977246537 | validation: 0.17568016309436674]
	TIME [epoch: 35.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11498624908288657		[learning rate: 0.0092012]
	Learning Rate: 0.00920124
	LOSS [training: 0.11498624908288657 | validation: 0.21391089937508184]
	TIME [epoch: 35.7 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12452952502531436		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.12452952502531436 | validation: 0.20650884096283229]
	TIME [epoch: 35.7 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14214331829141033		[learning rate: 0.0091201]
	Learning Rate: 0.00912011
	LOSS [training: 0.14214331829141033 | validation: 0.1857426790421059]
	TIME [epoch: 35.9 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11213458186672098		[learning rate: 0.0090798]
	Learning Rate: 0.00907981
	LOSS [training: 0.11213458186672098 | validation: 0.1757780919276955]
	TIME [epoch: 35.8 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11231011998028946		[learning rate: 0.0090397]
	Learning Rate: 0.0090397
	LOSS [training: 0.11231011998028946 | validation: 0.18894307361009308]
	TIME [epoch: 35.8 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1271542246443618		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.1271542246443618 | validation: 0.21503228371599048]
	TIME [epoch: 36.2 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12654555502395398		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.12654555502395398 | validation: 0.18190870556544647]
	TIME [epoch: 35.9 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11731285868247246		[learning rate: 0.0089204]
	Learning Rate: 0.00892041
	LOSS [training: 0.11731285868247246 | validation: 0.24150877511144458]
	TIME [epoch: 35.9 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12069089366731736		[learning rate: 0.008881]
	Learning Rate: 0.00888099
	LOSS [training: 0.12069089366731736 | validation: 0.22133816104908932]
	TIME [epoch: 35.9 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13972315029746016		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.13972315029746016 | validation: 0.21588345242147855]
	TIME [epoch: 35.9 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13948613744818372		[learning rate: 0.0088027]
	Learning Rate: 0.00880269
	LOSS [training: 0.13948613744818372 | validation: 0.23073844835711674]
	TIME [epoch: 35.9 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12346513751649568		[learning rate: 0.0087638]
	Learning Rate: 0.0087638
	LOSS [training: 0.12346513751649568 | validation: 0.23588677305824093]
	TIME [epoch: 35.9 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11497364123451492		[learning rate: 0.0087251]
	Learning Rate: 0.00872508
	LOSS [training: 0.11497364123451492 | validation: 0.18656169973072256]
	TIME [epoch: 35.9 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10992603082478798		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.10992603082478798 | validation: 0.1907949920777137]
	TIME [epoch: 35.9 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11135409079964231		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.11135409079964231 | validation: 0.167746664189509]
	TIME [epoch: 35.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11381929534684143		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 0.11381929534684143 | validation: 0.1677802772553453]
	TIME [epoch: 35.9 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10713394323723927		[learning rate: 0.0085719]
	Learning Rate: 0.0085719
	LOSS [training: 0.10713394323723927 | validation: 0.219009550255498]
	TIME [epoch: 35.9 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12926393527677865		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.12926393527677865 | validation: 0.23782496978021686]
	TIME [epoch: 35.8 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13047030502409157		[learning rate: 0.0084963]
	Learning Rate: 0.00849632
	LOSS [training: 0.13047030502409157 | validation: 0.22739529776261783]
	TIME [epoch: 35.9 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13980862554240844		[learning rate: 0.0084588]
	Learning Rate: 0.00845878
	LOSS [training: 0.13980862554240844 | validation: 0.27948597004753717]
	TIME [epoch: 35.9 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20164561818784424		[learning rate: 0.0084214]
	Learning Rate: 0.00842141
	LOSS [training: 0.20164561818784424 | validation: 0.2432780665028991]
	TIME [epoch: 35.9 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1607547033751281		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.1607547033751281 | validation: 0.22768277560844946]
	TIME [epoch: 35.9 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1372182376740492		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.1372182376740492 | validation: 0.1992529003773177]
	TIME [epoch: 35.8 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11968991639617928		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.11968991639617928 | validation: 0.3188384087474807]
	TIME [epoch: 35.9 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13677000903569062		[learning rate: 0.0082736]
	Learning Rate: 0.00827356
	LOSS [training: 0.13677000903569062 | validation: 0.1972269168546494]
	TIME [epoch: 35.8 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12890509399384784		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.12890509399384784 | validation: 0.1746316775202547]
	TIME [epoch: 35.8 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11178493110443988		[learning rate: 0.0082006]
	Learning Rate: 0.00820061
	LOSS [training: 0.11178493110443988 | validation: 0.2057253940651716]
	TIME [epoch: 35.9 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11950519241059701		[learning rate: 0.0081644]
	Learning Rate: 0.00816438
	LOSS [training: 0.11950519241059701 | validation: 0.17211629234108633]
	TIME [epoch: 35.9 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12048316882119647		[learning rate: 0.0081283]
	Learning Rate: 0.0081283
	LOSS [training: 0.12048316882119647 | validation: 0.19862517385715717]
	TIME [epoch: 35.8 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11695390094693565		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.11695390094693565 | validation: 0.19288634000443422]
	TIME [epoch: 35.8 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1257771780639175		[learning rate: 0.0080566]
	Learning Rate: 0.00805664
	LOSS [training: 0.1257771780639175 | validation: 0.18331830457794232]
	TIME [epoch: 35.8 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10700134410405489		[learning rate: 0.008021]
	Learning Rate: 0.00802104
	LOSS [training: 0.10700134410405489 | validation: 0.16508334213106568]
	TIME [epoch: 35.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1293304281007884		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.1293304281007884 | validation: 0.1865864070185773]
	TIME [epoch: 35.8 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10533670029071471		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.10533670029071471 | validation: 0.23299662504148277]
	TIME [epoch: 35.8 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12646201106043026		[learning rate: 0.0079152]
	Learning Rate: 0.00791519
	LOSS [training: 0.12646201106043026 | validation: 0.1903745644576582]
	TIME [epoch: 35.8 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11604058836131514		[learning rate: 0.0078802]
	Learning Rate: 0.00788022
	LOSS [training: 0.11604058836131514 | validation: 0.17215795725428096]
	TIME [epoch: 35.9 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11571921804718147		[learning rate: 0.0078454]
	Learning Rate: 0.00784541
	LOSS [training: 0.11571921804718147 | validation: 0.21041069653828548]
	TIME [epoch: 35.9 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11703510494379402		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.11703510494379402 | validation: 0.168929246616117]
	TIME [epoch: 35.8 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10030941977640954		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.10030941977640954 | validation: 0.16345976061371523]
	TIME [epoch: 35.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1085742356529511		[learning rate: 0.0077419]
	Learning Rate: 0.00774188
	LOSS [training: 0.1085742356529511 | validation: 0.1772762945999084]
	TIME [epoch: 35.8 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1166489291488371		[learning rate: 0.0077077]
	Learning Rate: 0.00770767
	LOSS [training: 0.1166489291488371 | validation: 0.253975471290847]
	TIME [epoch: 35.8 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11225698738290299		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.11225698738290299 | validation: 0.1763735613946234]
	TIME [epoch: 35.9 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11297383425849854		[learning rate: 0.0076397]
	Learning Rate: 0.00763971
	LOSS [training: 0.11297383425849854 | validation: 0.19130429687589293]
	TIME [epoch: 35.9 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12608662894124337		[learning rate: 0.007606]
	Learning Rate: 0.00760596
	LOSS [training: 0.12608662894124337 | validation: 0.18062310110264557]
	TIME [epoch: 35.8 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12120204244733061		[learning rate: 0.0075724]
	Learning Rate: 0.00757235
	LOSS [training: 0.12120204244733061 | validation: 0.18008148717640313]
	TIME [epoch: 35.8 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10838717004523328		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.10838717004523328 | validation: 0.21602659527736592]
	TIME [epoch: 35.8 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1076169299110938		[learning rate: 0.0075056]
	Learning Rate: 0.00750559
	LOSS [training: 0.1076169299110938 | validation: 0.16538356375370586]
	TIME [epoch: 35.9 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10870526278446727		[learning rate: 0.0074724]
	Learning Rate: 0.00747242
	LOSS [training: 0.10870526278446727 | validation: 0.18915554304003102]
	TIME [epoch: 35.8 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12633423642103975		[learning rate: 0.0074394]
	Learning Rate: 0.00743941
	LOSS [training: 0.12633423642103975 | validation: 0.18995163830146822]
	TIME [epoch: 35.8 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10711205367129792		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.10711205367129792 | validation: 0.1767293980632097]
	TIME [epoch: 35.9 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1320150827943181		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.1320150827943181 | validation: 0.17187287074806398]
	TIME [epoch: 35.8 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11635371606165927		[learning rate: 0.0073412]
	Learning Rate: 0.00734124
	LOSS [training: 0.11635371606165927 | validation: 0.18010944855748687]
	TIME [epoch: 35.8 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11077379393801268		[learning rate: 0.0073088]
	Learning Rate: 0.0073088
	LOSS [training: 0.11077379393801268 | validation: 0.22366351394028808]
	TIME [epoch: 35.8 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11474473938306844		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.11474473938306844 | validation: 0.17372203322366886]
	TIME [epoch: 35.8 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10774136539100634		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.10774136539100634 | validation: 0.17471953450037903]
	TIME [epoch: 35.8 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10055799417784447		[learning rate: 0.0072124]
	Learning Rate: 0.00721235
	LOSS [training: 0.10055799417784447 | validation: 0.18017288976942536]
	TIME [epoch: 35.8 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1321710687848609		[learning rate: 0.0071805]
	Learning Rate: 0.00718049
	LOSS [training: 0.1321710687848609 | validation: 0.17206524227478948]
	TIME [epoch: 35.8 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.105109224074979		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.105109224074979 | validation: 0.2110871319462585]
	TIME [epoch: 35.9 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1163522166487417		[learning rate: 0.0071172]
	Learning Rate: 0.00711718
	LOSS [training: 0.1163522166487417 | validation: 0.1728377808896731]
	TIME [epoch: 35.8 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10885342438070286		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.10885342438070286 | validation: 0.17646720988324247]
	TIME [epoch: 35.8 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11321538597001438		[learning rate: 0.0070544]
	Learning Rate: 0.00705442
	LOSS [training: 0.11321538597001438 | validation: 0.18121419836239686]
	TIME [epoch: 35.8 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1160186295333111		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.1160186295333111 | validation: 0.25828062849141736]
	TIME [epoch: 35.8 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12609147146521044		[learning rate: 0.0069922]
	Learning Rate: 0.00699222
	LOSS [training: 0.12609147146521044 | validation: 0.1821097350838844]
	TIME [epoch: 35.9 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1168667011410994		[learning rate: 0.0069613]
	Learning Rate: 0.00696133
	LOSS [training: 0.1168667011410994 | validation: 0.16797261200679398]
	TIME [epoch: 35.8 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.131343332630479		[learning rate: 0.0069306]
	Learning Rate: 0.00693057
	LOSS [training: 0.131343332630479 | validation: 0.24956284641503448]
	TIME [epoch: 35.9 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15473666190489271		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.15473666190489271 | validation: 0.18174596489131184]
	TIME [epoch: 35.8 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11562317283364823		[learning rate: 0.0068695]
	Learning Rate: 0.00686947
	LOSS [training: 0.11562317283364823 | validation: 0.18296582116544508]
	TIME [epoch: 35.8 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10985155123247894		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.10985155123247894 | validation: 0.20014429528952604]
	TIME [epoch: 35.9 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10845408788773292		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.10845408788773292 | validation: 0.15823427940385187]
	TIME [epoch: 35.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_127.pth
	Model improved!!!
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11241902425893982		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.11241902425893982 | validation: 0.16097628669319186]
	TIME [epoch: 35.9 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10408512015288156		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.10408512015288156 | validation: 0.16792649326075493]
	TIME [epoch: 35.8 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10172494979150726		[learning rate: 0.006719]
	Learning Rate: 0.00671905
	LOSS [training: 0.10172494979150726 | validation: 0.2033983576254968]
	TIME [epoch: 35.8 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10805965777951965		[learning rate: 0.0066894]
	Learning Rate: 0.00668936
	LOSS [training: 0.10805965777951965 | validation: 0.16660450628591433]
	TIME [epoch: 35.9 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11179167548221006		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.11179167548221006 | validation: 0.16025907251397503]
	TIME [epoch: 35.8 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12350793691916295		[learning rate: 0.0066304]
	Learning Rate: 0.00663038
	LOSS [training: 0.12350793691916295 | validation: 0.25408875748414284]
	TIME [epoch: 35.8 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12172132024446083		[learning rate: 0.0066011]
	Learning Rate: 0.00660109
	LOSS [training: 0.12172132024446083 | validation: 0.1682355783735969]
	TIME [epoch: 35.8 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11110173528544509		[learning rate: 0.0065719]
	Learning Rate: 0.00657192
	LOSS [training: 0.11110173528544509 | validation: 0.22120258766272688]
	TIME [epoch: 35.8 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15750892380748374		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.15750892380748374 | validation: 0.18502884450694837]
	TIME [epoch: 35.9 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1138320005479693		[learning rate: 0.006514]
	Learning Rate: 0.00651398
	LOSS [training: 0.1138320005479693 | validation: 0.17719251961089882]
	TIME [epoch: 35.8 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10531504246628287		[learning rate: 0.0064852]
	Learning Rate: 0.00648519
	LOSS [training: 0.10531504246628287 | validation: 0.1703205720448308]
	TIME [epoch: 35.8 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10483778188851325		[learning rate: 0.0064565]
	Learning Rate: 0.00645654
	LOSS [training: 0.10483778188851325 | validation: 0.1835718555855725]
	TIME [epoch: 35.8 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10235294814017229		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.10235294814017229 | validation: 0.19773430661039434]
	TIME [epoch: 35.8 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16053830233927033		[learning rate: 0.0063996]
	Learning Rate: 0.00639961
	LOSS [training: 0.16053830233927033 | validation: 0.21641571225439907]
	TIME [epoch: 35.8 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13014310414525895		[learning rate: 0.0063713]
	Learning Rate: 0.00637134
	LOSS [training: 0.13014310414525895 | validation: 0.1949138740353813]
	TIME [epoch: 35.8 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11541308212753103		[learning rate: 0.0063432]
	Learning Rate: 0.00634319
	LOSS [training: 0.11541308212753103 | validation: 0.21503516179635093]
	TIME [epoch: 35.8 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10644955465278125		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.10644955465278125 | validation: 0.1752953029485557]
	TIME [epoch: 35.9 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1025472860225837		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.1025472860225837 | validation: 0.18217872889569672]
	TIME [epoch: 35.8 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09794218063851585		[learning rate: 0.0062595]
	Learning Rate: 0.00625948
	LOSS [training: 0.09794218063851585 | validation: 0.16009508866498257]
	TIME [epoch: 35.8 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10151398186075607		[learning rate: 0.0062318]
	Learning Rate: 0.00623183
	LOSS [training: 0.10151398186075607 | validation: 0.16923374320617451]
	TIME [epoch: 35.8 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10281701783200399		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.10281701783200399 | validation: 0.166183667293253]
	TIME [epoch: 35.9 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10545599218077246		[learning rate: 0.0061769]
	Learning Rate: 0.00617688
	LOSS [training: 0.10545599218077246 | validation: 0.1603788865972811]
	TIME [epoch: 35.9 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1116107038828534		[learning rate: 0.0061496]
	Learning Rate: 0.00614959
	LOSS [training: 0.1116107038828534 | validation: 0.18635221038800753]
	TIME [epoch: 35.8 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11155216049561512		[learning rate: 0.0061224]
	Learning Rate: 0.00612242
	LOSS [training: 0.11155216049561512 | validation: 0.21011343940374078]
	TIME [epoch: 35.9 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1292896450899352		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.1292896450899352 | validation: 0.15705950713073027]
	TIME [epoch: 35.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_152.pth
	Model improved!!!
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09942930577832935		[learning rate: 0.0060684]
	Learning Rate: 0.00606844
	LOSS [training: 0.09942930577832935 | validation: 0.16460687480041877]
	TIME [epoch: 35.9 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10480470673589215		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.10480470673589215 | validation: 0.16172014369900423]
	TIME [epoch: 35.9 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12980089825463553		[learning rate: 0.0060149]
	Learning Rate: 0.00601493
	LOSS [training: 0.12980089825463553 | validation: 0.17791204687706383]
	TIME [epoch: 35.8 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11832614531827464		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.11832614531827464 | validation: 0.19879228904688798]
	TIME [epoch: 35.9 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10884377911079737		[learning rate: 0.0059619]
	Learning Rate: 0.0059619
	LOSS [training: 0.10884377911079737 | validation: 0.16698343572254698]
	TIME [epoch: 35.8 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0999040728233782		[learning rate: 0.0059356]
	Learning Rate: 0.00593556
	LOSS [training: 0.0999040728233782 | validation: 0.17117332175282146]
	TIME [epoch: 35.8 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09867800271847901		[learning rate: 0.0059093]
	Learning Rate: 0.00590933
	LOSS [training: 0.09867800271847901 | validation: 0.16284947917106696]
	TIME [epoch: 35.8 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10691832621184061		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.10691832621184061 | validation: 0.17029353152863444]
	TIME [epoch: 35.8 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10284531631111005		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.10284531631111005 | validation: 0.18959721332790833]
	TIME [epoch: 35.9 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10927550408417656		[learning rate: 0.0058314]
	Learning Rate: 0.00583135
	LOSS [training: 0.10927550408417656 | validation: 0.1696239994443841]
	TIME [epoch: 35.8 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10045422465912161		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.10045422465912161 | validation: 0.16168404901392197]
	TIME [epoch: 35.8 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09950677777447794		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.09950677777447794 | validation: 0.18295952513491098]
	TIME [epoch: 35.8 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11648179996193744		[learning rate: 0.0057544]
	Learning Rate: 0.0057544
	LOSS [training: 0.11648179996193744 | validation: 0.24296987741840487]
	TIME [epoch: 35.8 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11214270429632112		[learning rate: 0.005729]
	Learning Rate: 0.00572897
	LOSS [training: 0.11214270429632112 | validation: 0.1860329096861631]
	TIME [epoch: 35.9 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10242024887671526		[learning rate: 0.0057037]
	Learning Rate: 0.00570366
	LOSS [training: 0.10242024887671526 | validation: 0.1690253815035621]
	TIME [epoch: 35.9 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1017021821852266		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.1017021821852266 | validation: 0.17100671886573854]
	TIME [epoch: 35.8 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1041703064490966		[learning rate: 0.0056534]
	Learning Rate: 0.00565337
	LOSS [training: 0.1041703064490966 | validation: 0.17608711612199834]
	TIME [epoch: 35.9 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10647217193032603		[learning rate: 0.0056284]
	Learning Rate: 0.0056284
	LOSS [training: 0.10647217193032603 | validation: 0.1626304656973383]
	TIME [epoch: 35.8 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10487896325238559		[learning rate: 0.0056035]
	Learning Rate: 0.00560353
	LOSS [training: 0.10487896325238559 | validation: 0.23331994374781767]
	TIME [epoch: 35.8 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11925894524251553		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.11925894524251553 | validation: 0.18905777542183408]
	TIME [epoch: 35.8 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1123339365777416		[learning rate: 0.0055541]
	Learning Rate: 0.00555412
	LOSS [training: 0.1123339365777416 | validation: 0.20756886184704343]
	TIME [epoch: 35.9 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12791435863510375		[learning rate: 0.0055296]
	Learning Rate: 0.00552958
	LOSS [training: 0.12791435863510375 | validation: 0.16028206714825388]
	TIME [epoch: 35.9 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10627532659479762		[learning rate: 0.0055052]
	Learning Rate: 0.00550515
	LOSS [training: 0.10627532659479762 | validation: 0.16594665752909007]
	TIME [epoch: 35.8 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10457803812589679		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.10457803812589679 | validation: 0.16384869646168848]
	TIME [epoch: 35.8 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1052991743788944		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.1052991743788944 | validation: 0.17019336033266658]
	TIME [epoch: 35.9 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09978155314956444		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.09978155314956444 | validation: 0.1652919219036948]
	TIME [epoch: 35.9 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1104160012472184		[learning rate: 0.0054085]
	Learning Rate: 0.0054085
	LOSS [training: 0.1104160012472184 | validation: 0.17684204427585784]
	TIME [epoch: 35.9 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11964700568501944		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.11964700568501944 | validation: 0.18363229962171695]
	TIME [epoch: 35.8 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11097230850885238		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.11097230850885238 | validation: 0.18974337740282213]
	TIME [epoch: 35.8 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11870904101119542		[learning rate: 0.0053371]
	Learning Rate: 0.00533713
	LOSS [training: 0.11870904101119542 | validation: 0.189983543606769]
	TIME [epoch: 35.8 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10161364377919484		[learning rate: 0.0053135]
	Learning Rate: 0.00531355
	LOSS [training: 0.10161364377919484 | validation: 0.18937680012452107]
	TIME [epoch: 35.8 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09982225823550431		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.09982225823550431 | validation: 0.1684666870693345]
	TIME [epoch: 35.8 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10176328175757124		[learning rate: 0.0052667]
	Learning Rate: 0.0052667
	LOSS [training: 0.10176328175757124 | validation: 0.17985890992709233]
	TIME [epoch: 35.8 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1027124718174226		[learning rate: 0.0052434]
	Learning Rate: 0.00524343
	LOSS [training: 0.1027124718174226 | validation: 0.25705189202133427]
	TIME [epoch: 35.8 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1145328556957401		[learning rate: 0.0052203]
	Learning Rate: 0.00522026
	LOSS [training: 0.1145328556957401 | validation: 0.15338340174622964]
	TIME [epoch: 35.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_187.pth
	Model improved!!!
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10205577487997382		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.10205577487997382 | validation: 0.15622492991800213]
	TIME [epoch: 35.8 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1078328567023279		[learning rate: 0.0051742]
	Learning Rate: 0.00517423
	LOSS [training: 0.1078328567023279 | validation: 0.1630124283658616]
	TIME [epoch: 35.9 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09835116559295307		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.09835116559295307 | validation: 0.16467691903936157]
	TIME [epoch: 35.8 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09715083743170141		[learning rate: 0.0051286]
	Learning Rate: 0.00512861
	LOSS [training: 0.09715083743170141 | validation: 0.16952217721588053]
	TIME [epoch: 35.8 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10780177637925784		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.10780177637925784 | validation: 0.17509459768589122]
	TIME [epoch: 35.9 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0971437596524322		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.0971437596524322 | validation: 0.17117341662346755]
	TIME [epoch: 35.8 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09903996445255611		[learning rate: 0.0050609]
	Learning Rate: 0.00506093
	LOSS [training: 0.09903996445255611 | validation: 0.15809090178300553]
	TIME [epoch: 35.9 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11258479854764154		[learning rate: 0.0050386]
	Learning Rate: 0.00503857
	LOSS [training: 0.11258479854764154 | validation: 0.1667488160318955]
	TIME [epoch: 35.8 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10108952960250794		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.10108952960250794 | validation: 0.16321950072211153]
	TIME [epoch: 35.8 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09981130806414343		[learning rate: 0.0049941]
	Learning Rate: 0.00499415
	LOSS [training: 0.09981130806414343 | validation: 0.16056656867978034]
	TIME [epoch: 35.8 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09816004622351007		[learning rate: 0.0049721]
	Learning Rate: 0.00497208
	LOSS [training: 0.09816004622351007 | validation: 0.17479178327672706]
	TIME [epoch: 35.9 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10891601106478303		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.10891601106478303 | validation: 0.15890338266033016]
	TIME [epoch: 35.8 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11120283084109395		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.11120283084109395 | validation: 0.18785283095363722]
	TIME [epoch: 35.9 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1082554258414314		[learning rate: 0.0049065]
	Learning Rate: 0.00490647
	LOSS [training: 0.1082554258414314 | validation: 0.17333024668619534]
	TIME [epoch: 97.7 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09626693622426105		[learning rate: 0.0048848]
	Learning Rate: 0.00488479
	LOSS [training: 0.09626693622426105 | validation: 0.165050854452674]
	TIME [epoch: 75.4 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10335478076614102		[learning rate: 0.0048632]
	Learning Rate: 0.00486321
	LOSS [training: 0.10335478076614102 | validation: 0.16904348767150007]
	TIME [epoch: 75.4 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09964339528795199		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.09964339528795199 | validation: 0.18550956573169863]
	TIME [epoch: 75.3 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09380838723019197		[learning rate: 0.0048203]
	Learning Rate: 0.00482033
	LOSS [training: 0.09380838723019197 | validation: 0.16204485324685006]
	TIME [epoch: 75.5 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09989434965746832		[learning rate: 0.004799]
	Learning Rate: 0.00479903
	LOSS [training: 0.09989434965746832 | validation: 0.1737635445068733]
	TIME [epoch: 75.4 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0981049365586035		[learning rate: 0.0047778]
	Learning Rate: 0.00477783
	LOSS [training: 0.0981049365586035 | validation: 0.18056785765991115]
	TIME [epoch: 75.3 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09924428600722292		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.09924428600722292 | validation: 0.16508011557592106]
	TIME [epoch: 75.3 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09929857751292981		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.09929857751292981 | validation: 0.150023565943293]
	TIME [epoch: 75.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_209.pth
	Model improved!!!
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0960407149170493		[learning rate: 0.0047148]
	Learning Rate: 0.00471478
	LOSS [training: 0.0960407149170493 | validation: 0.19363333901870652]
	TIME [epoch: 75.3 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09628065413119259		[learning rate: 0.0046939]
	Learning Rate: 0.00469395
	LOSS [training: 0.09628065413119259 | validation: 0.15778373963898745]
	TIME [epoch: 75.3 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09936096296924847		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.09936096296924847 | validation: 0.19252187102577886]
	TIME [epoch: 75.3 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10954872770758697		[learning rate: 0.0046526]
	Learning Rate: 0.00465256
	LOSS [training: 0.10954872770758697 | validation: 0.1916108242473397]
	TIME [epoch: 75.3 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14299408192759472		[learning rate: 0.004632]
	Learning Rate: 0.00463201
	LOSS [training: 0.14299408192759472 | validation: 0.19307329885263758]
	TIME [epoch: 75.3 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11119448940507323		[learning rate: 0.0046115]
	Learning Rate: 0.00461154
	LOSS [training: 0.11119448940507323 | validation: 0.17310695907070478]
	TIME [epoch: 75 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1042562308958842		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.1042562308958842 | validation: 0.15805035753562363]
	TIME [epoch: 75 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09721831052169858		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.09721831052169858 | validation: 0.17000176264799455]
	TIME [epoch: 75 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10012591678612806		[learning rate: 0.0045507]
	Learning Rate: 0.00455069
	LOSS [training: 0.10012591678612806 | validation: 0.16158912929443286]
	TIME [epoch: 75 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09466577944880554		[learning rate: 0.0045306]
	Learning Rate: 0.00453058
	LOSS [training: 0.09466577944880554 | validation: 0.17360128180663775]
	TIME [epoch: 75 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10223107004465168		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.10223107004465168 | validation: 0.1552583617968941]
	TIME [epoch: 75 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09831063483600191		[learning rate: 0.0044906]
	Learning Rate: 0.00449063
	LOSS [training: 0.09831063483600191 | validation: 0.16286023778883038]
	TIME [epoch: 75 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10080115510453913		[learning rate: 0.0044708]
	Learning Rate: 0.00447079
	LOSS [training: 0.10080115510453913 | validation: 0.17011386949656068]
	TIME [epoch: 75 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10138607440245755		[learning rate: 0.004451]
	Learning Rate: 0.00445104
	LOSS [training: 0.10138607440245755 | validation: 0.16727074565844]
	TIME [epoch: 75 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09502563080533805		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.09502563080533805 | validation: 0.16155628951966067]
	TIME [epoch: 75 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0927972064181813		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.0927972064181813 | validation: 0.155262373378124]
	TIME [epoch: 75 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09635846154220121		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.09635846154220121 | validation: 0.1656006456177929]
	TIME [epoch: 74.9 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09673354483327617		[learning rate: 0.0043729]
	Learning Rate: 0.0043729
	LOSS [training: 0.09673354483327617 | validation: 0.18308734849007657]
	TIME [epoch: 74.9 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09378565584825706		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.09378565584825706 | validation: 0.17736260931689096]
	TIME [epoch: 75 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0941668058187964		[learning rate: 0.0043343]
	Learning Rate: 0.00433434
	LOSS [training: 0.0941668058187964 | validation: 0.22447858294517484]
	TIME [epoch: 75 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09947271810710637		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 0.09947271810710637 | validation: 0.16166499677751994]
	TIME [epoch: 75 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10581803981265685		[learning rate: 0.0042961]
	Learning Rate: 0.00429612
	LOSS [training: 0.10581803981265685 | validation: 0.15976636786547077]
	TIME [epoch: 75 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09349809591214336		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.09349809591214336 | validation: 0.161107767332396]
	TIME [epoch: 75 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09962633309193958		[learning rate: 0.0042582]
	Learning Rate: 0.00425825
	LOSS [training: 0.09962633309193958 | validation: 0.15911484455628672]
	TIME [epoch: 75 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09543758316757875		[learning rate: 0.0042394]
	Learning Rate: 0.00423943
	LOSS [training: 0.09543758316757875 | validation: 0.15519825712135354]
	TIME [epoch: 75 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09629399340550246		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.09629399340550246 | validation: 0.1540596323032918]
	TIME [epoch: 74.9 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09946832786852029		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.09946832786852029 | validation: 0.16475435536161975]
	TIME [epoch: 75 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09760698299392055		[learning rate: 0.0041835]
	Learning Rate: 0.00418349
	LOSS [training: 0.09760698299392055 | validation: 0.16920577457138486]
	TIME [epoch: 75 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09823166776734604		[learning rate: 0.004165]
	Learning Rate: 0.004165
	LOSS [training: 0.09823166776734604 | validation: 0.16854207709184693]
	TIME [epoch: 75 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09941267720107408		[learning rate: 0.0041466]
	Learning Rate: 0.0041466
	LOSS [training: 0.09941267720107408 | validation: 0.19901116865767704]
	TIME [epoch: 75 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09448166902631241		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.09448166902631241 | validation: 0.16250156222116308]
	TIME [epoch: 75 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09670560180971785		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.09670560180971785 | validation: 0.15840563376432074]
	TIME [epoch: 75 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09351071558592464		[learning rate: 0.0040919]
	Learning Rate: 0.00409188
	LOSS [training: 0.09351071558592464 | validation: 0.17021738168316475]
	TIME [epoch: 75 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09888625945949969		[learning rate: 0.0040738]
	Learning Rate: 0.0040738
	LOSS [training: 0.09888625945949969 | validation: 0.14973693934157797]
	TIME [epoch: 75 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_243.pth
	Model improved!!!
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0962116784676114		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.0962116784676114 | validation: 0.17214911703770788]
	TIME [epoch: 75 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09467705377522716		[learning rate: 0.0040379]
	Learning Rate: 0.00403788
	LOSS [training: 0.09467705377522716 | validation: 0.20039849342898255]
	TIME [epoch: 75 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0930936160947882		[learning rate: 0.00402]
	Learning Rate: 0.00402004
	LOSS [training: 0.0930936160947882 | validation: 0.17783346817579804]
	TIME [epoch: 75 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09344842703468861		[learning rate: 0.0040023]
	Learning Rate: 0.00400228
	LOSS [training: 0.09344842703468861 | validation: 0.16594258953305993]
	TIME [epoch: 74.9 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09614190783005094		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.09614190783005094 | validation: 0.15445004491929182]
	TIME [epoch: 75 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09413298250599422		[learning rate: 0.003967]
	Learning Rate: 0.00396699
	LOSS [training: 0.09413298250599422 | validation: 0.16089235120086956]
	TIME [epoch: 74.9 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09192740320243749		[learning rate: 0.0039495]
	Learning Rate: 0.00394947
	LOSS [training: 0.09192740320243749 | validation: 0.1797737794071839]
	TIME [epoch: 75 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09751324925619813		[learning rate: 0.003932]
	Learning Rate: 0.00393202
	LOSS [training: 0.09751324925619813 | validation: 0.16754471029718893]
	TIME [epoch: 75 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09323121332696306		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.09323121332696306 | validation: 0.16336488856735243]
	TIME [epoch: 75 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09321633315219072		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.09321633315219072 | validation: 0.14724332682581467]
	TIME [epoch: 75 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_253.pth
	Model improved!!!
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09256953459265246		[learning rate: 0.0038801]
	Learning Rate: 0.00388013
	LOSS [training: 0.09256953459265246 | validation: 0.1655329648248532]
	TIME [epoch: 75 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09545346511866146		[learning rate: 0.003863]
	Learning Rate: 0.00386299
	LOSS [training: 0.09545346511866146 | validation: 0.15725354154246987]
	TIME [epoch: 75 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09537191333163218		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.09537191333163218 | validation: 0.16353630363839863]
	TIME [epoch: 75 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08713001761503689		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.08713001761503689 | validation: 0.1534773082528269]
	TIME [epoch: 75 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09495091411108389		[learning rate: 0.003812]
	Learning Rate: 0.00381201
	LOSS [training: 0.09495091411108389 | validation: 0.16194869328542288]
	TIME [epoch: 75 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09649993008636479		[learning rate: 0.0037952]
	Learning Rate: 0.00379517
	LOSS [training: 0.09649993008636479 | validation: 0.17022667635644514]
	TIME [epoch: 75 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08986772934798598		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.08986772934798598 | validation: 0.16889708867484401]
	TIME [epoch: 75 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09291486428743471		[learning rate: 0.0037617]
	Learning Rate: 0.0037617
	LOSS [training: 0.09291486428743471 | validation: 0.1779986053643089]
	TIME [epoch: 75.1 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09719424429602214		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.09719424429602214 | validation: 0.18671258935109689]
	TIME [epoch: 75 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0879875088283594		[learning rate: 0.0037285]
	Learning Rate: 0.00372854
	LOSS [training: 0.0879875088283594 | validation: 0.15482755754913913]
	TIME [epoch: 75 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08923151385124335		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.08923151385124335 | validation: 0.1625794823718315]
	TIME [epoch: 75 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09291141519155961		[learning rate: 0.0036957]
	Learning Rate: 0.00369566
	LOSS [training: 0.09291141519155961 | validation: 0.2130999102358178]
	TIME [epoch: 75 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09480839861859187		[learning rate: 0.0036793]
	Learning Rate: 0.00367933
	LOSS [training: 0.09480839861859187 | validation: 0.16594038147316587]
	TIME [epoch: 75 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09236795287966537		[learning rate: 0.0036631]
	Learning Rate: 0.00366308
	LOSS [training: 0.09236795287966537 | validation: 0.15434311198585113]
	TIME [epoch: 75 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09024160670780361		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.09024160670780361 | validation: 0.1584929421695465]
	TIME [epoch: 75.1 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09196328291501975		[learning rate: 0.0036308]
	Learning Rate: 0.00363078
	LOSS [training: 0.09196328291501975 | validation: 0.16738967628307438]
	TIME [epoch: 75 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09842048105156423		[learning rate: 0.0036147]
	Learning Rate: 0.00361474
	LOSS [training: 0.09842048105156423 | validation: 0.1500846668773874]
	TIME [epoch: 75.1 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0941617170745247		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.0941617170745247 | validation: 0.14870179182057147]
	TIME [epoch: 75 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09837013015662398		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.09837013015662398 | validation: 0.15603376003223518]
	TIME [epoch: 75 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09495597634617736		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.09495597634617736 | validation: 0.15131379833086012]
	TIME [epoch: 75 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08771948856462694		[learning rate: 0.0035513]
	Learning Rate: 0.00355128
	LOSS [training: 0.08771948856462694 | validation: 0.15156469781048626]
	TIME [epoch: 75.1 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09143831406834793		[learning rate: 0.0035356]
	Learning Rate: 0.00353559
	LOSS [training: 0.09143831406834793 | validation: 0.14845473660324998]
	TIME [epoch: 75 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09306915368163225		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.09306915368163225 | validation: 0.14983042463550886]
	TIME [epoch: 75 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09413088258097892		[learning rate: 0.0035044]
	Learning Rate: 0.00350441
	LOSS [training: 0.09413088258097892 | validation: 0.1553128788374783]
	TIME [epoch: 75 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11322647051300827		[learning rate: 0.0034889]
	Learning Rate: 0.00348893
	LOSS [training: 0.11322647051300827 | validation: 0.18153778113766122]
	TIME [epoch: 75 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1024912474545894		[learning rate: 0.0034735]
	Learning Rate: 0.00347352
	LOSS [training: 0.1024912474545894 | validation: 0.16286771392335542]
	TIME [epoch: 75 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09307495619505074		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.09307495619505074 | validation: 0.15723450797054564]
	TIME [epoch: 75 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09015897078953654		[learning rate: 0.0034429]
	Learning Rate: 0.00344289
	LOSS [training: 0.09015897078953654 | validation: 0.16911993655708915]
	TIME [epoch: 75.1 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.088035045696323		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 0.088035045696323 | validation: 0.1613645182479749]
	TIME [epoch: 75 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08901710987013792		[learning rate: 0.0034125]
	Learning Rate: 0.00341253
	LOSS [training: 0.08901710987013792 | validation: 0.16250736340457905]
	TIME [epoch: 75.1 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0917491330465081		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.0917491330465081 | validation: 0.1473971578009058]
	TIME [epoch: 75 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09013529285919122		[learning rate: 0.0033824]
	Learning Rate: 0.00338245
	LOSS [training: 0.09013529285919122 | validation: 0.1689801319554048]
	TIME [epoch: 75.1 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09014957011103218		[learning rate: 0.0033675]
	Learning Rate: 0.0033675
	LOSS [training: 0.09014957011103218 | validation: 0.16529614087998795]
	TIME [epoch: 75 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09431581279649753		[learning rate: 0.0033526]
	Learning Rate: 0.00335262
	LOSS [training: 0.09431581279649753 | validation: 0.1495919884950312]
	TIME [epoch: 75 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0879480840951695		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.0879480840951695 | validation: 0.16132820514434698]
	TIME [epoch: 75 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1022100331557287		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.1022100331557287 | validation: 0.19190597116317193]
	TIME [epoch: 75.1 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10322891563240018		[learning rate: 0.0033084]
	Learning Rate: 0.00330838
	LOSS [training: 0.10322891563240018 | validation: 0.22493089266028807]
	TIME [epoch: 75 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09371570871753011		[learning rate: 0.0032938]
	Learning Rate: 0.00329376
	LOSS [training: 0.09371570871753011 | validation: 0.15988463062504435]
	TIME [epoch: 75.1 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09195189911515775		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.09195189911515775 | validation: 0.1640545485229137]
	TIME [epoch: 75 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08915576005250994		[learning rate: 0.0032647]
	Learning Rate: 0.00326472
	LOSS [training: 0.08915576005250994 | validation: 0.15882433938892448]
	TIME [epoch: 75 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08813310294003304		[learning rate: 0.0032503]
	Learning Rate: 0.0032503
	LOSS [training: 0.08813310294003304 | validation: 0.15668682618605964]
	TIME [epoch: 75 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08955824126240286		[learning rate: 0.0032359]
	Learning Rate: 0.00323594
	LOSS [training: 0.08955824126240286 | validation: 0.16126966639590673]
	TIME [epoch: 75 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09891609530812465		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.09891609530812465 | validation: 0.15059406002312453]
	TIME [epoch: 75 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09301882452754946		[learning rate: 0.0032074]
	Learning Rate: 0.00320741
	LOSS [training: 0.09301882452754946 | validation: 0.15809938129740864]
	TIME [epoch: 75 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11668838646165189		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.11668838646165189 | validation: 0.18656328741535627]
	TIME [epoch: 75 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.110064007063154		[learning rate: 0.0031791]
	Learning Rate: 0.00317913
	LOSS [training: 0.110064007063154 | validation: 0.16317792665644149]
	TIME [epoch: 75 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09556864079916338		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.09556864079916338 | validation: 0.15131048172042325]
	TIME [epoch: 75 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09075309558439773		[learning rate: 0.0031511]
	Learning Rate: 0.0031511
	LOSS [training: 0.09075309558439773 | validation: 0.1512755001013865]
	TIME [epoch: 75 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08730155897799351		[learning rate: 0.0031372]
	Learning Rate: 0.00313717
	LOSS [training: 0.08730155897799351 | validation: 0.1515065076052831]
	TIME [epoch: 75 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08586559720910396		[learning rate: 0.0031233]
	Learning Rate: 0.00312331
	LOSS [training: 0.08586559720910396 | validation: 0.14906303943721919]
	TIME [epoch: 75 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09287258787428031		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.09287258787428031 | validation: 0.1430820067605186]
	TIME [epoch: 75 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_304.pth
	Model improved!!!
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08990268422521963		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.08990268422521963 | validation: 0.15423030043510438]
	TIME [epoch: 75 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09094137557975059		[learning rate: 0.0030821]
	Learning Rate: 0.0030821
	LOSS [training: 0.09094137557975059 | validation: 0.16533639465645972]
	TIME [epoch: 75.4 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08943647720839759		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.08943647720839759 | validation: 0.14975832212792556]
	TIME [epoch: 75.6 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09468270654857318		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.09468270654857318 | validation: 0.14941745933242817]
	TIME [epoch: 75.4 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08649807997473428		[learning rate: 0.0030414]
	Learning Rate: 0.00304142
	LOSS [training: 0.08649807997473428 | validation: 0.1682636521666448]
	TIME [epoch: 75.4 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08877455408850166		[learning rate: 0.003028]
	Learning Rate: 0.00302799
	LOSS [training: 0.08877455408850166 | validation: 0.1835055578348267]
	TIME [epoch: 75.3 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09046509373825187		[learning rate: 0.0030146]
	Learning Rate: 0.00301461
	LOSS [training: 0.09046509373825187 | validation: 0.1500501052490229]
	TIME [epoch: 75.4 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0870617920247383		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.0870617920247383 | validation: 0.16528727572218]
	TIME [epoch: 75.4 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08528283446841994		[learning rate: 0.002988]
	Learning Rate: 0.00298803
	LOSS [training: 0.08528283446841994 | validation: 0.15805983097476595]
	TIME [epoch: 75.4 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08816007000558615		[learning rate: 0.0029748]
	Learning Rate: 0.00297483
	LOSS [training: 0.08816007000558615 | validation: 0.15977827533463235]
	TIME [epoch: 75.3 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09029268392412833		[learning rate: 0.0029617]
	Learning Rate: 0.00296168
	LOSS [training: 0.09029268392412833 | validation: 0.1647211019578047]
	TIME [epoch: 75.4 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09086732899729297		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.09086732899729297 | validation: 0.1601255731853728]
	TIME [epoch: 75.3 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08859771705248146		[learning rate: 0.0029356]
	Learning Rate: 0.00293557
	LOSS [training: 0.08859771705248146 | validation: 0.18605224161245199]
	TIME [epoch: 75.4 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09261333104563232		[learning rate: 0.0029226]
	Learning Rate: 0.0029226
	LOSS [training: 0.09261333104563232 | validation: 0.17416693716800147]
	TIME [epoch: 75.4 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0863353022668913		[learning rate: 0.0029097]
	Learning Rate: 0.00290969
	LOSS [training: 0.0863353022668913 | validation: 0.16515841215212781]
	TIME [epoch: 75.4 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09075443883741244		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.09075443883741244 | validation: 0.1528139777578815]
	TIME [epoch: 75.5 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08915292011767188		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.08915292011767188 | validation: 0.14657071812084263]
	TIME [epoch: 75.5 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08725077726558403		[learning rate: 0.0028713]
	Learning Rate: 0.00287129
	LOSS [training: 0.08725077726558403 | validation: 0.16445257073296546]
	TIME [epoch: 75.5 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09264328597929535		[learning rate: 0.0028586]
	Learning Rate: 0.0028586
	LOSS [training: 0.09264328597929535 | validation: 0.17440579821947197]
	TIME [epoch: 75.5 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08958210133381943		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.08958210133381943 | validation: 0.15498619529830482]
	TIME [epoch: 75.4 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.091316286666007		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.091316286666007 | validation: 0.16074621134354936]
	TIME [epoch: 75.5 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08551387529949786		[learning rate: 0.0028209]
	Learning Rate: 0.00282088
	LOSS [training: 0.08551387529949786 | validation: 0.16481962747388348]
	TIME [epoch: 75.5 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08561508714942034		[learning rate: 0.0028084]
	Learning Rate: 0.00280842
	LOSS [training: 0.08561508714942034 | validation: 0.1536714687732012]
	TIME [epoch: 75.5 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08577137622681823		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.08577137622681823 | validation: 0.14544560850278063]
	TIME [epoch: 75.5 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08658175013264077		[learning rate: 0.0027837]
	Learning Rate: 0.00278366
	LOSS [training: 0.08658175013264077 | validation: 0.15115048049531665]
	TIME [epoch: 75.5 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08592169989577039		[learning rate: 0.0027714]
	Learning Rate: 0.00277136
	LOSS [training: 0.08592169989577039 | validation: 0.16145520547882344]
	TIME [epoch: 75.5 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08899318620022953		[learning rate: 0.0027591]
	Learning Rate: 0.00275911
	LOSS [training: 0.08899318620022953 | validation: 0.15556387572338737]
	TIME [epoch: 75.5 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08701068518451262		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.08701068518451262 | validation: 0.15858600741985604]
	TIME [epoch: 75.5 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09112359778321236		[learning rate: 0.0027348]
	Learning Rate: 0.00273478
	LOSS [training: 0.09112359778321236 | validation: 0.14984310623894168]
	TIME [epoch: 75.5 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08402577175797254		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.08402577175797254 | validation: 0.1689755156003096]
	TIME [epoch: 75.4 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08996012389957683		[learning rate: 0.0027107]
	Learning Rate: 0.00271067
	LOSS [training: 0.08996012389957683 | validation: 0.17240731866718795]
	TIME [epoch: 75.3 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08850260593560162		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.08850260593560162 | validation: 0.17114155042422197]
	TIME [epoch: 75 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08898191237744177		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.08898191237744177 | validation: 0.14774626423421253]
	TIME [epoch: 75 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08476690293466123		[learning rate: 0.0026749]
	Learning Rate: 0.0026749
	LOSS [training: 0.08476690293466123 | validation: 0.16325256544248015]
	TIME [epoch: 75 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08590528370280984		[learning rate: 0.0026631]
	Learning Rate: 0.00266308
	LOSS [training: 0.08590528370280984 | validation: 0.1458281526161749]
	TIME [epoch: 75 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08647449046441863		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.08647449046441863 | validation: 0.15990626945775238]
	TIME [epoch: 75 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08725984448286335		[learning rate: 0.0026396]
	Learning Rate: 0.0026396
	LOSS [training: 0.08725984448286335 | validation: 0.16718751270981752]
	TIME [epoch: 75 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08554638198848645		[learning rate: 0.0026279]
	Learning Rate: 0.00262794
	LOSS [training: 0.08554638198848645 | validation: 0.14921212330800648]
	TIME [epoch: 75 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08805309629326627		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.08805309629326627 | validation: 0.15496872541312884]
	TIME [epoch: 75 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08967866781874481		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.08967866781874481 | validation: 0.1505305092402317]
	TIME [epoch: 75 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08425426322462538		[learning rate: 0.0025933]
	Learning Rate: 0.00259326
	LOSS [training: 0.08425426322462538 | validation: 0.15206013537645274]
	TIME [epoch: 75 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08539184796763301		[learning rate: 0.0025818]
	Learning Rate: 0.0025818
	LOSS [training: 0.08539184796763301 | validation: 0.16143005121041998]
	TIME [epoch: 75 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0888048196631159		[learning rate: 0.0025704]
	Learning Rate: 0.0025704
	LOSS [training: 0.0888048196631159 | validation: 0.15762954978125868]
	TIME [epoch: 75 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08977421871848365		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.08977421871848365 | validation: 0.14722228141625893]
	TIME [epoch: 75 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08602910606439627		[learning rate: 0.0025477]
	Learning Rate: 0.00254773
	LOSS [training: 0.08602910606439627 | validation: 0.14147464485170386]
	TIME [epoch: 75 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_349.pth
	Model improved!!!
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08732302635331707		[learning rate: 0.0025365]
	Learning Rate: 0.00253648
	LOSS [training: 0.08732302635331707 | validation: 0.14994387427902045]
	TIME [epoch: 75 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08558964772267785		[learning rate: 0.0025253]
	Learning Rate: 0.00252527
	LOSS [training: 0.08558964772267785 | validation: 0.14317382500450973]
	TIME [epoch: 75 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08729236220945032		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.08729236220945032 | validation: 0.15192659425592833]
	TIME [epoch: 75 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08627793165887868		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.08627793165887868 | validation: 0.1427917533582528]
	TIME [epoch: 75 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0849114618920717		[learning rate: 0.0024919]
	Learning Rate: 0.00249194
	LOSS [training: 0.0849114618920717 | validation: 0.1503268898464732]
	TIME [epoch: 75.1 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08489084863391357		[learning rate: 0.0024809]
	Learning Rate: 0.00248093
	LOSS [training: 0.08489084863391357 | validation: 0.15199397808289708]
	TIME [epoch: 75.1 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08688663437282537		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.08688663437282537 | validation: 0.14551241388851355]
	TIME [epoch: 75.1 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08308607592713683		[learning rate: 0.0024591]
	Learning Rate: 0.00245906
	LOSS [training: 0.08308607592713683 | validation: 0.1455873181971841]
	TIME [epoch: 75.1 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08423415126268799		[learning rate: 0.0024482]
	Learning Rate: 0.0024482
	LOSS [training: 0.08423415126268799 | validation: 0.15750364019388155]
	TIME [epoch: 75 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0848809851813473		[learning rate: 0.0024374]
	Learning Rate: 0.00243738
	LOSS [training: 0.0848809851813473 | validation: 0.1531021051098237]
	TIME [epoch: 75 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08212874559030844		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.08212874559030844 | validation: 0.15568596075307534]
	TIME [epoch: 75.1 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08217555979316729		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.08217555979316729 | validation: 0.15582530498831543]
	TIME [epoch: 75.1 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08528587958792981		[learning rate: 0.0024052]
	Learning Rate: 0.00240521
	LOSS [training: 0.08528587958792981 | validation: 0.15540912769998627]
	TIME [epoch: 75.1 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0883843044122799		[learning rate: 0.0023946]
	Learning Rate: 0.00239459
	LOSS [training: 0.0883843044122799 | validation: 0.16379826515024706]
	TIME [epoch: 75.1 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08853401793306359		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.08853401793306359 | validation: 0.15572228850254355]
	TIME [epoch: 75.1 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0853714726617486		[learning rate: 0.0023735]
	Learning Rate: 0.00237347
	LOSS [training: 0.0853714726617486 | validation: 0.15862003009449957]
	TIME [epoch: 75.1 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08085578140345907		[learning rate: 0.002363]
	Learning Rate: 0.00236299
	LOSS [training: 0.08085578140345907 | validation: 0.15719962716606717]
	TIME [epoch: 75.1 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08722115620897641		[learning rate: 0.0023525]
	Learning Rate: 0.00235255
	LOSS [training: 0.08722115620897641 | validation: 0.15237956618052584]
	TIME [epoch: 75.1 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0834882155892447		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.0834882155892447 | validation: 0.15523257670250254]
	TIME [epoch: 75.1 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08159261770129009		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.08159261770129009 | validation: 0.1580626167304809]
	TIME [epoch: 75.1 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08888970791440637		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.08888970791440637 | validation: 0.148665314625514]
	TIME [epoch: 75.1 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0800952395550453		[learning rate: 0.0023112]
	Learning Rate: 0.00231125
	LOSS [training: 0.0800952395550453 | validation: 0.14426465360575905]
	TIME [epoch: 75.1 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08334459905007606		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.08334459905007606 | validation: 0.1417146057592136]
	TIME [epoch: 75.1 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08275257556357837		[learning rate: 0.0022909]
	Learning Rate: 0.00229087
	LOSS [training: 0.08275257556357837 | validation: 0.14410077171639668]
	TIME [epoch: 75.1 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08571824263804081		[learning rate: 0.0022807]
	Learning Rate: 0.00228075
	LOSS [training: 0.08571824263804081 | validation: 0.15306829007578626]
	TIME [epoch: 75.1 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08410209067523913		[learning rate: 0.0022707]
	Learning Rate: 0.00227067
	LOSS [training: 0.08410209067523913 | validation: 0.1662580133662922]
	TIME [epoch: 75.1 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08458166769439167		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.08458166769439167 | validation: 0.154099827882613]
	TIME [epoch: 75 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08306958048379985		[learning rate: 0.0022506]
	Learning Rate: 0.00225065
	LOSS [training: 0.08306958048379985 | validation: 0.14841307961630468]
	TIME [epoch: 75.1 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08063336207190706		[learning rate: 0.0022407]
	Learning Rate: 0.0022407
	LOSS [training: 0.08063336207190706 | validation: 0.14042613544269847]
	TIME [epoch: 75.2 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_378.pth
	Model improved!!!
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08305871132276232		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.08305871132276232 | validation: 0.15119799704635162]
	TIME [epoch: 75.1 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08452224761492723		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.08452224761492723 | validation: 0.15001541225745235]
	TIME [epoch: 75.1 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08407815430078167		[learning rate: 0.0022111]
	Learning Rate: 0.00221114
	LOSS [training: 0.08407815430078167 | validation: 0.14717690406328895]
	TIME [epoch: 75.1 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0833524560996962		[learning rate: 0.0022014]
	Learning Rate: 0.00220137
	LOSS [training: 0.0833524560996962 | validation: 0.15484995216275688]
	TIME [epoch: 75.1 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08245339880701154		[learning rate: 0.0021916]
	Learning Rate: 0.00219164
	LOSS [training: 0.08245339880701154 | validation: 0.1549865137161653]
	TIME [epoch: 75.1 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08159966187130793		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.08159966187130793 | validation: 0.15528176975357688]
	TIME [epoch: 75.1 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08094423788380992		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.08094423788380992 | validation: 0.145467388596508]
	TIME [epoch: 75 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08456990304429071		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: 0.08456990304429071 | validation: 0.1536982619582945]
	TIME [epoch: 75.1 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08439629092208081		[learning rate: 0.0021532]
	Learning Rate: 0.00215316
	LOSS [training: 0.08439629092208081 | validation: 0.14564990235014855]
	TIME [epoch: 75.1 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08390348410166593		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.08390348410166593 | validation: 0.14613327968751408]
	TIME [epoch: 75.1 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08325415817478002		[learning rate: 0.0021342]
	Learning Rate: 0.00213418
	LOSS [training: 0.08325415817478002 | validation: 0.1603068347668292]
	TIME [epoch: 75.1 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08051503675787135		[learning rate: 0.0021247]
	Learning Rate: 0.00212475
	LOSS [training: 0.08051503675787135 | validation: 0.15836610747556937]
	TIME [epoch: 75 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08117153302849137		[learning rate: 0.0021154]
	Learning Rate: 0.00211536
	LOSS [training: 0.08117153302849137 | validation: 0.14590912906335468]
	TIME [epoch: 75.1 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08489445348772424		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.08489445348772424 | validation: 0.159713432021174]
	TIME [epoch: 75 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08555130748025826		[learning rate: 0.0020967]
	Learning Rate: 0.00209671
	LOSS [training: 0.08555130748025826 | validation: 0.14350238733799414]
	TIME [epoch: 75.1 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08100091961834852		[learning rate: 0.0020874]
	Learning Rate: 0.00208745
	LOSS [training: 0.08100091961834852 | validation: 0.14649984058294283]
	TIME [epoch: 75.1 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0802908497891141		[learning rate: 0.0020782]
	Learning Rate: 0.00207822
	LOSS [training: 0.0802908497891141 | validation: 0.15193790038932276]
	TIME [epoch: 75.1 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0816132674268817		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.0816132674268817 | validation: 0.16054100812213562]
	TIME [epoch: 75.1 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08254499677075151		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.08254499677075151 | validation: 0.16244235673862756]
	TIME [epoch: 75 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08475182007141371		[learning rate: 0.0020508]
	Learning Rate: 0.0020508
	LOSS [training: 0.08475182007141371 | validation: 0.15052051553703572]
	TIME [epoch: 75.1 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08012068538991221		[learning rate: 0.0020417]
	Learning Rate: 0.00204174
	LOSS [training: 0.08012068538991221 | validation: 0.14750344289235354]
	TIME [epoch: 75 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08363912195234548		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.08363912195234548 | validation: 0.1481371214002669]
	TIME [epoch: 75.1 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08067874944574696		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.08067874944574696 | validation: 0.14968024676633054]
	TIME [epoch: 75.1 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0814797415947136		[learning rate: 0.0020148]
	Learning Rate: 0.00201479
	LOSS [training: 0.0814797415947136 | validation: 0.15788698036534107]
	TIME [epoch: 75.1 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08490054462876107		[learning rate: 0.0020059]
	Learning Rate: 0.00200589
	LOSS [training: 0.08490054462876107 | validation: 0.153088620116283]
	TIME [epoch: 75 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0829569293616428		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.0829569293616428 | validation: 0.14918009073720856]
	TIME [epoch: 75.1 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08474289666111154		[learning rate: 0.0019882]
	Learning Rate: 0.00198821
	LOSS [training: 0.08474289666111154 | validation: 0.1433350645504842]
	TIME [epoch: 75.1 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08072740778055747		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.08072740778055747 | validation: 0.15237860769488412]
	TIME [epoch: 75 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08182740576147471		[learning rate: 0.0019707]
	Learning Rate: 0.00197068
	LOSS [training: 0.08182740576147471 | validation: 0.16474298511733507]
	TIME [epoch: 75.1 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08419520066683128		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.08419520066683128 | validation: 0.14731979414000687]
	TIME [epoch: 75.1 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08331721524099664		[learning rate: 0.0019533]
	Learning Rate: 0.0019533
	LOSS [training: 0.08331721524099664 | validation: 0.14385599596735776]
	TIME [epoch: 75.1 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08066296071718818		[learning rate: 0.0019447]
	Learning Rate: 0.00194467
	LOSS [training: 0.08066296071718818 | validation: 0.15724057402118827]
	TIME [epoch: 75.1 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08001457302173928		[learning rate: 0.0019361]
	Learning Rate: 0.00193608
	LOSS [training: 0.08001457302173928 | validation: 0.1510642869648673]
	TIME [epoch: 75.1 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08005137064821127		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.08005137064821127 | validation: 0.15334691580802165]
	TIME [epoch: 75.1 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0831961289101861		[learning rate: 0.001919]
	Learning Rate: 0.00191901
	LOSS [training: 0.0831961289101861 | validation: 0.16009248021502379]
	TIME [epoch: 75.1 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08328684769991611		[learning rate: 0.0019105]
	Learning Rate: 0.00191053
	LOSS [training: 0.08328684769991611 | validation: 0.15574181303645462]
	TIME [epoch: 75.1 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08372364806363218		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.08372364806363218 | validation: 0.16076336804971]
	TIME [epoch: 75.1 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08234630575431019		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.08234630575431019 | validation: 0.15363968855035146]
	TIME [epoch: 75.1 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0788132168705894		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.0788132168705894 | validation: 0.14972247124479382]
	TIME [epoch: 75.1 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0830074395874078		[learning rate: 0.001877]
	Learning Rate: 0.00187699
	LOSS [training: 0.0830074395874078 | validation: 0.14999054456923638]
	TIME [epoch: 75.1 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0821130993864031		[learning rate: 0.0018687]
	Learning Rate: 0.0018687
	LOSS [training: 0.0821130993864031 | validation: 0.14091792305865314]
	TIME [epoch: 75.1 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08287204541816384		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.08287204541816384 | validation: 0.1591758173125712]
	TIME [epoch: 75.1 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08236803190089056		[learning rate: 0.0018522]
	Learning Rate: 0.00185222
	LOSS [training: 0.08236803190089056 | validation: 0.14328003798709565]
	TIME [epoch: 75.1 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08018020919142586		[learning rate: 0.001844]
	Learning Rate: 0.00184404
	LOSS [training: 0.08018020919142586 | validation: 0.15233709173927942]
	TIME [epoch: 75.1 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08173532840188284		[learning rate: 0.0018359]
	Learning Rate: 0.00183589
	LOSS [training: 0.08173532840188284 | validation: 0.143601313403583]
	TIME [epoch: 75.1 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08184184980173873		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.08184184980173873 | validation: 0.15190778733958016]
	TIME [epoch: 75.1 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08415583372661327		[learning rate: 0.0018197]
	Learning Rate: 0.0018197
	LOSS [training: 0.08415583372661327 | validation: 0.15139911539354678]
	TIME [epoch: 75.1 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0826369324199783		[learning rate: 0.0018117]
	Learning Rate: 0.00181166
	LOSS [training: 0.0826369324199783 | validation: 0.15095943319524013]
	TIME [epoch: 75 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08191402078359972		[learning rate: 0.0018037]
	Learning Rate: 0.00180366
	LOSS [training: 0.08191402078359972 | validation: 0.14994834322904815]
	TIME [epoch: 75.1 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08271525667114403		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.08271525667114403 | validation: 0.1455359388884649]
	TIME [epoch: 75.1 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08169208707060692		[learning rate: 0.0017878]
	Learning Rate: 0.00178775
	LOSS [training: 0.08169208707060692 | validation: 0.14468871439993214]
	TIME [epoch: 75.1 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07822758576840383		[learning rate: 0.0017799]
	Learning Rate: 0.00177985
	LOSS [training: 0.07822758576840383 | validation: 0.1518913287771555]
	TIME [epoch: 75.1 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08061748297908175		[learning rate: 0.001772]
	Learning Rate: 0.00177199
	LOSS [training: 0.08061748297908175 | validation: 0.15109247535410178]
	TIME [epoch: 75.1 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08547844895011746		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.08547844895011746 | validation: 0.152278090957976]
	TIME [epoch: 75.1 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07977466620601181		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.07977466620601181 | validation: 0.14750962638366524]
	TIME [epoch: 75.1 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08132882505579948		[learning rate: 0.0017486]
	Learning Rate: 0.00174861
	LOSS [training: 0.08132882505579948 | validation: 0.1414773031974448]
	TIME [epoch: 75 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08033185753528815		[learning rate: 0.0017409]
	Learning Rate: 0.00174088
	LOSS [training: 0.08033185753528815 | validation: 0.14328870985647377]
	TIME [epoch: 75.1 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08165105524548102		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.08165105524548102 | validation: 0.15878083304125412]
	TIME [epoch: 75 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07901519272691912		[learning rate: 0.0017255]
	Learning Rate: 0.00172553
	LOSS [training: 0.07901519272691912 | validation: 0.14736619118090738]
	TIME [epoch: 75.1 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07764804442197491		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: 0.07764804442197491 | validation: 0.1473998457567367]
	TIME [epoch: 75 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08067096993843827		[learning rate: 0.0017103]
	Learning Rate: 0.00171032
	LOSS [training: 0.08067096993843827 | validation: 0.15317740601172908]
	TIME [epoch: 75.1 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0801417542089096		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.0801417542089096 | validation: 0.1469695328242578]
	TIME [epoch: 75.1 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0797887063391218		[learning rate: 0.0016952]
	Learning Rate: 0.00169524
	LOSS [training: 0.0797887063391218 | validation: 0.1499089125546048]
	TIME [epoch: 75 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0799052694920908		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.0799052694920908 | validation: 0.1453088989121935]
	TIME [epoch: 75 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08129998471957034		[learning rate: 0.0016803]
	Learning Rate: 0.00168029
	LOSS [training: 0.08129998471957034 | validation: 0.15126594447557648]
	TIME [epoch: 75.1 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08128212366185301		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.08128212366185301 | validation: 0.14345587515871738]
	TIME [epoch: 75.1 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08003341541370833		[learning rate: 0.0016655]
	Learning Rate: 0.00166548
	LOSS [training: 0.08003341541370833 | validation: 0.15053985824671318]
	TIME [epoch: 75.1 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08332307500312594		[learning rate: 0.0016581]
	Learning Rate: 0.00165812
	LOSS [training: 0.08332307500312594 | validation: 0.14496409193351167]
	TIME [epoch: 75 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08158156614529796		[learning rate: 0.0016508]
	Learning Rate: 0.00165079
	LOSS [training: 0.08158156614529796 | validation: 0.1503938971760407]
	TIME [epoch: 75.1 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07927532473983237		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.07927532473983237 | validation: 0.14340269297706132]
	TIME [epoch: 75.1 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08322373909498552		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.08322373909498552 | validation: 0.1443980809671758]
	TIME [epoch: 75.1 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08568926160868343		[learning rate: 0.001629]
	Learning Rate: 0.00162901
	LOSS [training: 0.08568926160868343 | validation: 0.14389137502916477]
	TIME [epoch: 75.1 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07814738851427049		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.07814738851427049 | validation: 0.14978390771157335]
	TIME [epoch: 75.1 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08285598065554944		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.08285598065554944 | validation: 0.15064000828309548]
	TIME [epoch: 75.1 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07956048767017218		[learning rate: 0.0016075]
	Learning Rate: 0.00160751
	LOSS [training: 0.07956048767017218 | validation: 0.15924790177854603]
	TIME [epoch: 75.1 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08472584398752933		[learning rate: 0.0016004]
	Learning Rate: 0.00160041
	LOSS [training: 0.08472584398752933 | validation: 0.16017612772965312]
	TIME [epoch: 75 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08037999894197644		[learning rate: 0.0015933]
	Learning Rate: 0.00159334
	LOSS [training: 0.08037999894197644 | validation: 0.152326485620092]
	TIME [epoch: 75 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0800842010868406		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.0800842010868406 | validation: 0.14766541565706098]
	TIME [epoch: 75.1 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0795956148921814		[learning rate: 0.0015793]
	Learning Rate: 0.00157929
	LOSS [training: 0.0795956148921814 | validation: 0.14230807147790842]
	TIME [epoch: 75 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08185938621834067		[learning rate: 0.0015723]
	Learning Rate: 0.00157231
	LOSS [training: 0.08185938621834067 | validation: 0.14541460893821803]
	TIME [epoch: 75 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08002883477270825		[learning rate: 0.0015654]
	Learning Rate: 0.00156536
	LOSS [training: 0.08002883477270825 | validation: 0.1380894658165783]
	TIME [epoch: 75 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_459.pth
	Model improved!!!
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08126951271145151		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.08126951271145151 | validation: 0.14647301007025693]
	TIME [epoch: 75.2 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0806024725798209		[learning rate: 0.0015516]
	Learning Rate: 0.00155156
	LOSS [training: 0.0806024725798209 | validation: 0.14736096869635695]
	TIME [epoch: 75.1 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0819299209386198		[learning rate: 0.0015447]
	Learning Rate: 0.00154471
	LOSS [training: 0.0819299209386198 | validation: 0.1454490488844749]
	TIME [epoch: 75.1 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08382077900961724		[learning rate: 0.0015379]
	Learning Rate: 0.00153788
	LOSS [training: 0.08382077900961724 | validation: 0.1554648327261734]
	TIME [epoch: 75.1 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0792629874126286		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.0792629874126286 | validation: 0.15839590203400367]
	TIME [epoch: 75.1 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0822527029629482		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.0822527029629482 | validation: 0.15295990786095306]
	TIME [epoch: 75.1 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08167559915006585		[learning rate: 0.0015176]
	Learning Rate: 0.00151759
	LOSS [training: 0.08167559915006585 | validation: 0.1574006443410085]
	TIME [epoch: 75 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08302456857984705		[learning rate: 0.0015109]
	Learning Rate: 0.00151088
	LOSS [training: 0.08302456857984705 | validation: 0.15071967419768695]
	TIME [epoch: 75.1 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08317433619199985		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.08317433619199985 | validation: 0.14793454828849842]
	TIME [epoch: 75.1 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08068080238729536		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.08068080238729536 | validation: 0.15439350943040425]
	TIME [epoch: 75.1 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08192931772586408		[learning rate: 0.0014909]
	Learning Rate: 0.00149094
	LOSS [training: 0.08192931772586408 | validation: 0.14197193566385755]
	TIME [epoch: 75.1 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07916223923120369		[learning rate: 0.0014844]
	Learning Rate: 0.00148436
	LOSS [training: 0.07916223923120369 | validation: 0.1538353310085061]
	TIME [epoch: 75.1 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07965772053173992		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.07965772053173992 | validation: 0.1447678224413287]
	TIME [epoch: 75.1 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08089236392268581		[learning rate: 0.0014713]
	Learning Rate: 0.00147127
	LOSS [training: 0.08089236392268581 | validation: 0.1493046620361793]
	TIME [epoch: 75.1 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07752450985204869		[learning rate: 0.0014648]
	Learning Rate: 0.00146477
	LOSS [training: 0.07752450985204869 | validation: 0.1416524085684167]
	TIME [epoch: 75.1 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08136010910540749		[learning rate: 0.0014583]
	Learning Rate: 0.0014583
	LOSS [training: 0.08136010910540749 | validation: 0.1490310845382659]
	TIME [epoch: 75.1 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08027078073573406		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.08027078073573406 | validation: 0.1440806256315756]
	TIME [epoch: 75.1 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07838733062271588		[learning rate: 0.0014454]
	Learning Rate: 0.00144544
	LOSS [training: 0.07838733062271588 | validation: 0.14840624432769325]
	TIME [epoch: 75.1 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0819651678679022		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.0819651678679022 | validation: 0.14419889704185346]
	TIME [epoch: 75.1 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07953467099767045		[learning rate: 0.0014327]
	Learning Rate: 0.0014327
	LOSS [training: 0.07953467099767045 | validation: 0.15182643231594858]
	TIME [epoch: 75.1 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08128311410851621		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.08128311410851621 | validation: 0.15230384075122103]
	TIME [epoch: 75.1 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.079962410621332		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.079962410621332 | validation: 0.15074472311088552]
	TIME [epoch: 75.1 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08026965669999472		[learning rate: 0.0014138]
	Learning Rate: 0.00141379
	LOSS [training: 0.08026965669999472 | validation: 0.14935133850993476]
	TIME [epoch: 75.1 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08268623342024092		[learning rate: 0.0014075]
	Learning Rate: 0.00140754
	LOSS [training: 0.08268623342024092 | validation: 0.14304689179804783]
	TIME [epoch: 75.1 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07935002115691055		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.07935002115691055 | validation: 0.14892928733199265]
	TIME [epoch: 75.1 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07972165880730944		[learning rate: 0.0013951]
	Learning Rate: 0.00139513
	LOSS [training: 0.07972165880730944 | validation: 0.14882189075836183]
	TIME [epoch: 75 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0837865814868569		[learning rate: 0.001389]
	Learning Rate: 0.00138897
	LOSS [training: 0.0837865814868569 | validation: 0.14992090604459232]
	TIME [epoch: 75 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08047999662506836		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.08047999662506836 | validation: 0.14522015993974677]
	TIME [epoch: 75 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08023694706290586		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.08023694706290586 | validation: 0.1496644391790941]
	TIME [epoch: 75.1 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0807092342105375		[learning rate: 0.0013706]
	Learning Rate: 0.00137064
	LOSS [training: 0.0807092342105375 | validation: 0.14842383590127559]
	TIME [epoch: 75 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0795023546632999		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: 0.0795023546632999 | validation: 0.14115602342519798]
	TIME [epoch: 75.1 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08005154121682281		[learning rate: 0.0013586]
	Learning Rate: 0.00135855
	LOSS [training: 0.08005154121682281 | validation: 0.1424087590193866]
	TIME [epoch: 75 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07974443283721627		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.07974443283721627 | validation: 0.15187809873972757]
	TIME [epoch: 75 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08032003413845504		[learning rate: 0.0013466]
	Learning Rate: 0.00134658
	LOSS [training: 0.08032003413845504 | validation: 0.1478391543226228]
	TIME [epoch: 75.1 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07895741184179954		[learning rate: 0.0013406]
	Learning Rate: 0.00134063
	LOSS [training: 0.07895741184179954 | validation: 0.14793455562622349]
	TIME [epoch: 75 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07976943700364529		[learning rate: 0.0013347]
	Learning Rate: 0.0013347
	LOSS [training: 0.07976943700364529 | validation: 0.15637588494579893]
	TIME [epoch: 75.1 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08048713762239913		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.08048713762239913 | validation: 0.14962484795600717]
	TIME [epoch: 75.1 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07813237047791408		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.07813237047791408 | validation: 0.14405926508376737]
	TIME [epoch: 75.1 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08120183782350883		[learning rate: 0.0013171]
	Learning Rate: 0.00131709
	LOSS [training: 0.08120183782350883 | validation: 0.1599022729801062]
	TIME [epoch: 75.1 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07893971483504555		[learning rate: 0.0013113]
	Learning Rate: 0.00131127
	LOSS [training: 0.07893971483504555 | validation: 0.14957663491445408]
	TIME [epoch: 75.1 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0808029819337129		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.0808029819337129 | validation: 0.14802965956039285]
	TIME [epoch: 75.1 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08109952120239165		[learning rate: 0.0012997]
	Learning Rate: 0.00129971
	LOSS [training: 0.08109952120239165 | validation: 0.15006417298441355]
	TIME [epoch: 175 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08115973450684869		[learning rate: 0.001294]
	Learning Rate: 0.00129397
	LOSS [training: 0.08115973450684869 | validation: 0.1475757096329728]
	TIME [epoch: 154 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08037127893793934		[learning rate: 0.0012882]
	Learning Rate: 0.00128825
	LOSS [training: 0.08037127893793934 | validation: 0.14226565683771167]
	TIME [epoch: 154 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08107214197080653		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.08107214197080653 | validation: 0.14981237556778423]
	TIME [epoch: 154 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0795886714412115		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.0795886714412115 | validation: 0.14277147871823703]
	TIME [epoch: 154 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08097445472079076		[learning rate: 0.0012712]
	Learning Rate: 0.00127125
	LOSS [training: 0.08097445472079076 | validation: 0.15823241396694912]
	TIME [epoch: 154 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0844629398674584		[learning rate: 0.0012656]
	Learning Rate: 0.00126563
	LOSS [training: 0.0844629398674584 | validation: 0.1624966241614106]
	TIME [epoch: 154 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08065807548234954		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.08065807548234954 | validation: 0.15100354552404022]
	TIME [epoch: 154 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0798127553841723		[learning rate: 0.0012545]
	Learning Rate: 0.00125447
	LOSS [training: 0.0798127553841723 | validation: 0.15093785013745004]
	TIME [epoch: 154 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08006498931388405		[learning rate: 0.0012489]
	Learning Rate: 0.00124893
	LOSS [training: 0.08006498931388405 | validation: 0.1480322059685009]
	TIME [epoch: 154 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08005292922113197		[learning rate: 0.0012434]
	Learning Rate: 0.00124341
	LOSS [training: 0.08005292922113197 | validation: 0.14354721680271199]
	TIME [epoch: 154 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07819812847593272		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.07819812847593272 | validation: 0.15537568106157174]
	TIME [epoch: 154 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07950504192147498		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.07950504192147498 | validation: 0.15254722760149264]
	TIME [epoch: 154 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08107501645916042		[learning rate: 0.001227]
	Learning Rate: 0.001227
	LOSS [training: 0.08107501645916042 | validation: 0.15344552178500168]
	TIME [epoch: 154 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08356610305837645		[learning rate: 0.0012216]
	Learning Rate: 0.00122158
	LOSS [training: 0.08356610305837645 | validation: 0.15671935780854077]
	TIME [epoch: 154 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07908453686593384		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.07908453686593384 | validation: 0.15682958818773376]
	TIME [epoch: 154 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08091273420405069		[learning rate: 0.0012108]
	Learning Rate: 0.00121081
	LOSS [training: 0.08091273420405069 | validation: 0.15499900973206138]
	TIME [epoch: 154 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0806526854274121		[learning rate: 0.0012055]
	Learning Rate: 0.00120546
	LOSS [training: 0.0806526854274121 | validation: 0.15197537572304756]
	TIME [epoch: 154 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07778130782691173		[learning rate: 0.0012001]
	Learning Rate: 0.00120014
	LOSS [training: 0.07778130782691173 | validation: 0.14556660726674214]
	TIME [epoch: 154 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07818209939433834		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.07818209939433834 | validation: 0.14922751547023175]
	TIME [epoch: 154 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07905021676630267		[learning rate: 0.0011896]
	Learning Rate: 0.00118956
	LOSS [training: 0.07905021676630267 | validation: 0.14958391549442873]
	TIME [epoch: 154 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0791137228292091		[learning rate: 0.0011843]
	Learning Rate: 0.0011843
	LOSS [training: 0.0791137228292091 | validation: 0.1480037335867157]
	TIME [epoch: 154 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07847434901280274		[learning rate: 0.0011791]
	Learning Rate: 0.00117907
	LOSS [training: 0.07847434901280274 | validation: 0.14631980219964275]
	TIME [epoch: 154 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08071428912828078		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.08071428912828078 | validation: 0.14814697934700824]
	TIME [epoch: 154 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08094407041175991		[learning rate: 0.0011687]
	Learning Rate: 0.00116867
	LOSS [training: 0.08094407041175991 | validation: 0.15061507062379814]
	TIME [epoch: 154 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08320817767764459		[learning rate: 0.0011635]
	Learning Rate: 0.00116351
	LOSS [training: 0.08320817767764459 | validation: 0.14484669169303682]
	TIME [epoch: 154 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07789207398356666		[learning rate: 0.0011584]
	Learning Rate: 0.00115837
	LOSS [training: 0.07789207398356666 | validation: 0.15521571327256153]
	TIME [epoch: 154 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07911320078179974		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.07911320078179974 | validation: 0.14524694015451922]
	TIME [epoch: 154 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07883316893568358		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.07883316893568358 | validation: 0.14063636447378453]
	TIME [epoch: 154 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07987315107557048		[learning rate: 0.0011431]
	Learning Rate: 0.00114308
	LOSS [training: 0.07987315107557048 | validation: 0.15103014911917084]
	TIME [epoch: 154 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0810358952384618		[learning rate: 0.001138]
	Learning Rate: 0.00113803
	LOSS [training: 0.0810358952384618 | validation: 0.15170815804519128]
	TIME [epoch: 154 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07906298409824777		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.07906298409824777 | validation: 0.15494487390001702]
	TIME [epoch: 154 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07954749552151967		[learning rate: 0.001128]
	Learning Rate: 0.001128
	LOSS [training: 0.07954749552151967 | validation: 0.15114213436862262]
	TIME [epoch: 154 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07537815707926165		[learning rate: 0.001123]
	Learning Rate: 0.00112301
	LOSS [training: 0.07537815707926165 | validation: 0.14658351085748852]
	TIME [epoch: 154 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08184418887884873		[learning rate: 0.0011181]
	Learning Rate: 0.00111805
	LOSS [training: 0.08184418887884873 | validation: 0.1457270263756782]
	TIME [epoch: 154 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07773044376990666		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.07773044376990666 | validation: 0.14504051200263152]
	TIME [epoch: 154 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07929324836821826		[learning rate: 0.0011082]
	Learning Rate: 0.00110819
	LOSS [training: 0.07929324836821826 | validation: 0.14590647656053762]
	TIME [epoch: 154 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07964113830434465		[learning rate: 0.0011033]
	Learning Rate: 0.0011033
	LOSS [training: 0.07964113830434465 | validation: 0.14710109120562537]
	TIME [epoch: 154 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08068442736927764		[learning rate: 0.0010984]
	Learning Rate: 0.00109842
	LOSS [training: 0.08068442736927764 | validation: 0.14735968477793165]
	TIME [epoch: 154 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07775505451981253		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.07775505451981253 | validation: 0.1494854155131893]
	TIME [epoch: 154 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07837192489829022		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.07837192489829022 | validation: 0.15192979189050118]
	TIME [epoch: 154 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0801624707456332		[learning rate: 0.0010839]
	Learning Rate: 0.00108393
	LOSS [training: 0.0801624707456332 | validation: 0.15244281134847631]
	TIME [epoch: 154 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07982081846766667		[learning rate: 0.0010791]
	Learning Rate: 0.00107914
	LOSS [training: 0.07982081846766667 | validation: 0.14202793924271892]
	TIME [epoch: 154 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08081558563266628		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.08081558563266628 | validation: 0.13692096772319634]
	TIME [epoch: 154 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v1_20240712_121611/states/model_facs_v2_dec2b_2dpca_v1_544.pth
	Model improved!!!
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08063708070181896		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.08063708070181896 | validation: 0.1463760645605668]
	TIME [epoch: 154 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0810939382364991		[learning rate: 0.0010649]
	Learning Rate: 0.0010649
	LOSS [training: 0.0810939382364991 | validation: 0.15648164936613004]
	TIME [epoch: 154 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08238141137098695		[learning rate: 0.0010602]
	Learning Rate: 0.00106019
	LOSS [training: 0.08238141137098695 | validation: 0.14749261488255705]
	TIME [epoch: 154 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07802361016906731		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.07802361016906731 | validation: 0.14932421229309042]
	TIME [epoch: 154 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07852625255522867		[learning rate: 0.0010508]
	Learning Rate: 0.00105084
	LOSS [training: 0.07852625255522867 | validation: 0.14603850813056796]
	TIME [epoch: 154 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07681323695860112		[learning rate: 0.0010462]
	Learning Rate: 0.0010462
	LOSS [training: 0.07681323695860112 | validation: 0.1502710917989156]
	TIME [epoch: 154 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08104970642987333		[learning rate: 0.0010416]
	Learning Rate: 0.00104158
	LOSS [training: 0.08104970642987333 | validation: 0.15049337841490595]
	TIME [epoch: 154 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0796335619404704		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.0796335619404704 | validation: 0.15632186351404553]
	TIME [epoch: 154 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0801860749651126		[learning rate: 0.0010324]
	Learning Rate: 0.0010324
	LOSS [training: 0.0801860749651126 | validation: 0.1498996542138955]
	TIME [epoch: 154 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07812485262367105		[learning rate: 0.0010278]
	Learning Rate: 0.00102783
	LOSS [training: 0.07812485262367105 | validation: 0.14718859457060898]
	TIME [epoch: 154 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07909129108978848		[learning rate: 0.0010233]
	Learning Rate: 0.00102329
	LOSS [training: 0.07909129108978848 | validation: 0.14750532962421395]
	TIME [epoch: 154 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07943653866917406		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.07943653866917406 | validation: 0.1427775073940352]
	TIME [epoch: 154 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08013617936647818		[learning rate: 0.0010143]
	Learning Rate: 0.00101427
	LOSS [training: 0.08013617936647818 | validation: 0.14424925610584963]
	TIME [epoch: 154 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07799721264187978		[learning rate: 0.0010098]
	Learning Rate: 0.00100979
	LOSS [training: 0.07799721264187978 | validation: 0.14644027057277534]
	TIME [epoch: 154 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07733296200940583		[learning rate: 0.0010053]
	Learning Rate: 0.00100533
	LOSS [training: 0.07733296200940583 | validation: 0.14781401978735953]
	TIME [epoch: 154 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07813789620840325		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.07813789620840325 | validation: 0.15264571741206145]
	TIME [epoch: 154 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08068126822799507		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.08068126822799507 | validation: 0.1411534216092513]
	TIME [epoch: 154 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08254350612583641		[learning rate: 0.00099206]
	Learning Rate: 0.000992061
	LOSS [training: 0.08254350612583641 | validation: 0.14998616706536927]
	TIME [epoch: 154 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07999868789946178		[learning rate: 0.00098768]
	Learning Rate: 0.000987678
	LOSS [training: 0.07999868789946178 | validation: 0.15118006991871102]
	TIME [epoch: 154 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07829963761476766		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.07829963761476766 | validation: 0.1441643278836003]
	TIME [epoch: 154 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07807249729122676		[learning rate: 0.00097897]
	Learning Rate: 0.00097897
	LOSS [training: 0.07807249729122676 | validation: 0.1486615855877898]
	TIME [epoch: 154 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0792277519663659		[learning rate: 0.00097464]
	Learning Rate: 0.000974644
	LOSS [training: 0.0792277519663659 | validation: 0.1565494261710143]
	TIME [epoch: 154 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07706917843008941		[learning rate: 0.00097034]
	Learning Rate: 0.000970338
	LOSS [training: 0.07706917843008941 | validation: 0.143868095634728]
	TIME [epoch: 154 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0802028223826329		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.0802028223826329 | validation: 0.1497474699906554]
	TIME [epoch: 154 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07777495709871064		[learning rate: 0.00096178]
	Learning Rate: 0.000961783
	LOSS [training: 0.07777495709871064 | validation: 0.14412047985373777]
	TIME [epoch: 154 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0819477818363016		[learning rate: 0.00095753]
	Learning Rate: 0.000957533
	LOSS [training: 0.0819477818363016 | validation: 0.14607554004255371]
	TIME [epoch: 154 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07798006497588246		[learning rate: 0.0009533]
	Learning Rate: 0.000953303
	LOSS [training: 0.07798006497588246 | validation: 0.15178730205286864]
	TIME [epoch: 154 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08070323756711834		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.08070323756711834 | validation: 0.14293100753466792]
	TIME [epoch: 154 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08010777894094047		[learning rate: 0.0009449]
	Learning Rate: 0.000944897
	LOSS [training: 0.08010777894094047 | validation: 0.141932933964052]
	TIME [epoch: 154 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07890858268016529		[learning rate: 0.00094072]
	Learning Rate: 0.000940723
	LOSS [training: 0.07890858268016529 | validation: 0.13941482949033762]
	TIME [epoch: 154 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08131640247231793		[learning rate: 0.00093657]
	Learning Rate: 0.000936566
	LOSS [training: 0.08131640247231793 | validation: 0.13860863053509487]
	TIME [epoch: 154 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07922732417734286		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.07922732417734286 | validation: 0.14652145146405132]
	TIME [epoch: 154 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07942377852847739		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.07942377852847739 | validation: 0.1502059223747624]
	TIME [epoch: 154 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07937008475716564		[learning rate: 0.00092421]
	Learning Rate: 0.000924207
	LOSS [training: 0.07937008475716564 | validation: 0.13968639861574375]
	TIME [epoch: 154 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0798230566409954		[learning rate: 0.00092012]
	Learning Rate: 0.000920124
	LOSS [training: 0.0798230566409954 | validation: 0.14277802368498022]
	TIME [epoch: 154 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07951966679509848		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.07951966679509848 | validation: 0.1429639014112412]
	TIME [epoch: 154 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07899617983036766		[learning rate: 0.00091201]
	Learning Rate: 0.000912011
	LOSS [training: 0.07899617983036766 | validation: 0.14864211211207642]
	TIME [epoch: 154 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07691608042403318		[learning rate: 0.00090798]
	Learning Rate: 0.000907981
	LOSS [training: 0.07691608042403318 | validation: 0.15231995918259]
	TIME [epoch: 154 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07901576226960468		[learning rate: 0.00090397]
	Learning Rate: 0.00090397
	LOSS [training: 0.07901576226960468 | validation: 0.1480873089722391]
	TIME [epoch: 154 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07726859177820325		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.07726859177820325 | validation: 0.1427229916752071]
	TIME [epoch: 154 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08038796438041892		[learning rate: 0.000896]
	Learning Rate: 0.000895999
	LOSS [training: 0.08038796438041892 | validation: 0.1459464182310243]
	TIME [epoch: 154 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08049627322085726		[learning rate: 0.00089204]
	Learning Rate: 0.000892041
	LOSS [training: 0.08049627322085726 | validation: 0.1441333347696314]
	TIME [epoch: 154 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07938189668981019		[learning rate: 0.0008881]
	Learning Rate: 0.000888099
	LOSS [training: 0.07938189668981019 | validation: 0.14476314004198032]
	TIME [epoch: 154 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07790167956918914		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.07790167956918914 | validation: 0.14602751700414612]
	TIME [epoch: 154 sec]
EPOCH 589/2000:
	Training over batches...
